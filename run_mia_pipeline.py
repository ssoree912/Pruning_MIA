#!/usr/bin/env python3
"""
DWA í”„ë£¨ë‹ëœ ëª¨ë¸ì— ëŒ€í•œ ì „ì²´ MIA íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Usage:
python run_mia_pipeline.py --dataset cifar10 --device cuda:0

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
1. MIAìš© ë°ì´í„° ë¶„í•  ì¤€ë¹„ (í•„ìš”ì‹œ)
2. DWA í›ˆë ¨ ê²°ê³¼ì—ì„œ ëª¨ë¸ ì°¾ê¸°
3. ëª¨ë“  DWA ëª¨ë¸ì— ëŒ€í•´ MIA í‰ê°€ ìˆ˜í–‰
4. ê²°ê³¼ ìš”ì•½ ë° ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path
from datetime import datetime

def run_command(cmd, cwd=None):
    """ëª…ë ¹ì–´ ì‹¤í–‰"""
    print(f"ğŸ”§ Running: {' '.join(cmd)}")
    try:
        result = subprocess.run(cmd, cwd=cwd, check=True, capture_output=True, text=True)
        if result.stdout:
            print(result.stdout)
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Command failed: {e}")
        if e.stdout:
            print("STDOUT:", e.stdout)
        if e.stderr:
            print("STDERR:", e.stderr)
        return False

def check_dwa_results(runs_dir):
    """DWA í›ˆë ¨ ê²°ê³¼ í™•ì¸"""
    runs_path = Path(runs_dir)
    dwa_path = runs_path / 'dwa'
    
    if not dwa_path.exists():
        print(f"âŒ No DWA results found in {runs_dir}")
        print("ë¨¼ì € train_dwa.pyë¥¼ ì‹¤í–‰í•´ì„œ DWA ëª¨ë¸ë“¤ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
        return False, 0
    
    # DWA ëª¨ë¸ ê°œìˆ˜ ì„¸ê¸°
    model_count = 0
    for mode_dir in dwa_path.iterdir():
        if mode_dir.is_dir():
            for sparsity_dir in mode_dir.iterdir():
                if sparsity_dir.is_dir() and sparsity_dir.name.startswith('sparsity_'):
                    for dataset_dir in sparsity_dir.iterdir():
                        if dataset_dir.is_dir():
                            if (dataset_dir / 'best_model.pth').exists():
                                model_count += 1
    
    print(f"âœ… Found {model_count} trained DWA models in {runs_dir}")
    return True, model_count

def main():
    parser = argparse.ArgumentParser(description='DWA MIA Evaluation Pipeline')
    parser.add_argument('--dataset', type=str, default='cifar10', 
                       choices=['cifar10', 'cifar100'], help='Dataset name')
    parser.add_argument('--runs_dir', type=str, default='./runs', 
                       help='DWA training results directory')
    parser.add_argument('--output_dir', type=str, default='./mia_results',
                       help='MIA results output directory')
    parser.add_argument('--device', type=str, default='cuda:0', help='Device to use')
    parser.add_argument('--batch_size', type=int, default=128, help='Batch size')
    parser.add_argument('--datapath', type=str, default='~/Datasets', help='Dataset path')
    parser.add_argument('--skip_data_prep', action='store_true', 
                       help='Skip MIA data preparation step')
    
    args = parser.parse_args()
    
    print("ğŸš€ DWA MIA Evaluation Pipeline")
    print("=" * 50)
    print(f"Dataset: {args.dataset}")
    print(f"DWA Results: {args.runs_dir}")
    print(f"Output: {args.output_dir}")
    print(f"Device: {args.device}")
    print("=" * 50)
    
    # Step 1: DWA í›ˆë ¨ ê²°ê³¼ í™•ì¸
    print("\nğŸ“‹ Step 1: Checking DWA training results...")
    has_results, model_count = check_dwa_results(args.runs_dir)
    if not has_results:
        print("\nğŸ’¡ DWA ëª¨ë¸ì„ ë¨¼ì € í›ˆë ¨í•˜ë ¤ë©´:")
        print("   python train_dwa.py --dwa-modes reactivate_only kill_active_plain_dead kill_and_reactivate")
        return
    
    if model_count == 0:
        print("âŒ No trained models found. Please run train_dwa.py first.")
        return
    
    # Step 2: MIA ë°ì´í„° ì¤€ë¹„
    if not args.skip_data_prep:
        print(f"\nğŸ“Š Step 2: Preparing MIA data splits for {args.dataset}...")
        prep_cmd = [
            sys.executable, 'scripts/prepare_mia_data.py',
            '--dataset', args.dataset,
            '--output_dir', './mia_data'
        ]
        
        if not run_command(prep_cmd):
            print("âŒ MIA data preparation failed")
            return
    else:
        print("\nâ­ï¸  Step 2: Skipping MIA data preparation")
    
    # Step 3: MIA í‰ê°€ ì‹¤í–‰
    print(f"\nğŸ¯ Step 3: Running MIA evaluation on {model_count} models...")
    eval_cmd = [
        sys.executable, 'evaluate_dwa_mia.py',
        '--runs_dir', args.runs_dir,
        '--output_dir', args.output_dir, 
        '--device', args.device,
        '--batch_size', str(args.batch_size),
        '--dataset', args.dataset,
        '--datapath', args.datapath
    ]
    
    if not run_command(eval_cmd):
        print("âŒ MIA evaluation failed")
        return
    
    # Step 4: ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“ˆ Step 4: Generating summary...")
    
    output_path = Path(args.output_dir)
    if output_path.exists():
        # ìµœì‹  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        csv_files = list(output_path.glob('dwa_mia_results_*.csv'))
        if csv_files:
            latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)
            print(f"ğŸ“ Latest results: {latest_csv}")
            
            # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
            try:
                import pandas as pd
                df = pd.read_csv(latest_csv)
                
                print(f"\nğŸ“Š MIA Attack Success Summary ({len(df)} models):")
                print("-" * 60)
                
                # ì£¼ìš” ê³µê²© ì„±ê³µë¥  í†µê³„
                attack_cols = ['attack_conf_gt', 'attack_entropy', 'attack_modified_entropy', 'attack_conf_top1']
                df['best_attack'] = df[attack_cols].max(axis=1)
                
                # DWA ëª¨ë“œë³„ í‰ê· 
                summary = df.groupby(['dwa_mode', 'sparsity_actual']).agg({
                    'best_attack': ['mean', 'std'],
                    'confidence_gap': ['mean', 'std'],
                    'best_acc1': 'mean'
                }).round(3)
                
                print(summary)
                
                # ìµœê³ /ìµœì € ê³µê²© ì„±ê³µë¥ 
                best_idx = df['best_attack'].idxmax()
                worst_idx = df['best_attack'].idxmin()
                
                print(f"\nğŸ”¥ Highest vulnerability:")
                print(f"   {df.loc[best_idx, 'dwa_mode']} (sparsity={df.loc[best_idx, 'sparsity_actual']:.3f}): {df.loc[best_idx, 'best_attack']:.3f}")
                print(f"ğŸ›¡ï¸  Lowest vulnerability:")
                print(f"   {df.loc[worst_idx, 'dwa_mode']} (sparsity={df.loc[worst_idx, 'sparsity_actual']:.3f}): {df.loc[worst_idx, 'best_attack']:.3f}")
                
            except ImportError:
                print("ğŸ“„ For detailed analysis, install pandas: pip install pandas")
                print(f"ğŸ“ Raw results available at: {latest_csv}")
    
    print(f"\nâœ… MIA evaluation pipeline completed successfully!")
    print(f"ğŸ“ Results saved in: {args.output_dir}")

if __name__ == '__main__':
    main()