2025-08-27 16:57:34,121 - INFO - Starting experiment: dpf_sparsity0.7_seed42
2025-08-27 16:57:34,121 - INFO - Save directory: ./runs/dpf/sparsity0.7/seed42
2025-08-27 16:57:34,121 - INFO - Hyperparameters:
2025-08-27 16:57:34,121 - INFO -   name: dpf_sparsity0.7_seed42
2025-08-27 16:57:34,121 - INFO -   description: DPF pruning 70% (seed=42)
2025-08-27 16:57:34,121 - INFO -   save_dir: ./runs
2025-08-27 16:57:34,121 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 16:57:34,121 - INFO -   model: {'arch': 'resnet', 'layers': 18, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 16:57:34,121 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 16:57:34,122 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.7, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 16:57:34,122 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 16:57:34,122 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 16:57:34,156 - INFO - System Information:
2025-08-27 16:57:34,157 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 16:57:34,157 - INFO -   python_version: 3.9.18
2025-08-27 16:57:34,157 - INFO -   pytorch_version: 2.1.0
2025-08-27 16:57:34,157 - INFO -   cuda_available: True
2025-08-27 16:57:34,157 - INFO -   cpu_count: 4
2025-08-27 16:57:34,157 - INFO -   memory_total_gb: 11.0
2025-08-27 16:57:34,157 - INFO -   timestamp: 1756281454.156505
2025-08-27 16:57:34,157 - INFO -   cuda_version: 11.8
2025-08-27 16:57:34,157 - INFO -   gpu_count: 1
2025-08-27 16:57:34,157 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 16:57:34,193 - INFO - Starting experiment: dpf_sparsity0.7_seed42
2025-08-27 16:57:34,193 - INFO - Model: resnet-18
2025-08-27 16:57:34,193 - INFO - Dataset: cifar10
2025-08-27 16:57:34,193 - INFO - Pruning: dpf (70.00%)
2025-08-27 18:16:16,632 - INFO - Starting experiment: dpf_sparsity0.7_seed42
2025-08-27 18:16:16,632 - INFO - Save directory: ./runs/dpf/sparsity0.7/seed42
2025-08-27 18:16:16,632 - INFO - Hyperparameters:
2025-08-27 18:16:16,633 - INFO -   name: dpf_sparsity0.7_seed42
2025-08-27 18:16:16,633 - INFO -   description: DPF pruning 70% (seed=42)
2025-08-27 18:16:16,633 - INFO -   save_dir: ./runs
2025-08-27 18:16:16,633 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 18:16:16,633 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 18:16:16,633 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 18:16:16,633 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.7, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 18:16:16,633 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 18:16:16,633 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 18:16:16,670 - INFO - System Information:
2025-08-27 18:16:16,670 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 18:16:16,670 - INFO -   python_version: 3.9.18
2025-08-27 18:16:16,670 - INFO -   pytorch_version: 2.1.0
2025-08-27 18:16:16,670 - INFO -   cuda_available: True
2025-08-27 18:16:16,670 - INFO -   cpu_count: 4
2025-08-27 18:16:16,670 - INFO -   memory_total_gb: 11.0
2025-08-27 18:16:16,670 - INFO -   timestamp: 1756286176.6701424
2025-08-27 18:16:16,671 - INFO -   cuda_version: 11.8
2025-08-27 18:16:16,671 - INFO -   gpu_count: 1
2025-08-27 18:16:16,671 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 18:16:16,677 - INFO - Starting experiment: dpf_sparsity0.7_seed42
2025-08-27 18:16:16,677 - INFO - Model: resnet-20
2025-08-27 18:16:16,677 - INFO - Dataset: cifar10
2025-08-27 18:16:16,677 - INFO - Pruning: dpf (70.00%)
2025-08-27 18:16:16,801 - INFO - Model Information:
2025-08-27 18:16:16,802 - INFO -   Type: pruned
2025-08-27 18:16:16,802 - INFO -   Total parameters: 544,948
2025-08-27 18:16:16,802 - INFO -   Trainable parameters: 274,692
2025-08-27 18:16:16,802 - INFO -   Sparsity: 70.00%
2025-08-27 18:16:18,123 - INFO - Starting training...
2025-08-27 18:16:18,124 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 18:16:18,853 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:16:18,853 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:16:19,381 - INFO - Epoch: [0][0/391] Time 1.257 (1.257) Data 0.561 (0.561) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 18:16:21,307 - INFO - Epoch: [0][100/391] Time 0.037 (0.032) Data 0.007 (0.008) Loss 1.7310 (1.9380) Acc@1 38.281 (26.369) Acc@5 88.281 (81.080)
2025-08-27 18:16:22,528 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:16:22,528 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:16:23,329 - INFO - Epoch: [0][200/391] Time 0.018 (0.026) Data 0.000 (0.005) Loss 1.5681 (1.8020) Acc@1 40.625 (31.608) Acc@5 90.625 (85.156)
2025-08-27 18:16:25,229 - INFO - Epoch: [0][300/391] Time 0.022 (0.024) Data 0.000 (0.004) Loss 1.4460 (1.7118) Acc@1 45.312 (35.582) Acc@5 91.406 (87.264)
2025-08-27 18:16:25,632 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:16:25,632 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:16:27,347 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 1.4573 (1.4573) Acc@1 46.094 (46.094) Acc@5 93.750 (93.750)
2025-08-27 18:16:28,309 - INFO - Epoch 0:
2025-08-27 18:16:28,309 - INFO -   Train: acc1: 38.6340 | acc5: 88.6060 | loss: 1.6414 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 18:16:28,309 - INFO -   Val:   acc1: 45.7700 | acc5: 92.7000 | loss: 1.5645
2025-08-27 18:16:28,309 - INFO -   LR: 0.100000
2025-08-27 18:16:28,812 - INFO - Checkpoint saved: epoch=0, metric=45.7700
2025-08-27 18:16:28,844 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 18:16:29,043 - INFO - Epoch: [1][0/391] Time 0.199 (0.199) Data 0.169 (0.169) Loss 1.4662 (1.4662) Acc@1 49.219 (49.219) Acc@5 90.625 (90.625)
2025-08-27 18:16:30,807 - INFO - Pruning info: sparsity=0.028
2025-08-27 18:16:30,807 - INFO -   Reactivation rate: 0.0079
2025-08-27 18:16:31,023 - INFO - Epoch: [1][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 1.1411 (1.2535) Acc@1 59.375 (54.811) Acc@5 93.750 (94.516)
2025-08-27 18:16:33,004 - INFO - Epoch: [1][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 1.0086 (1.2042) Acc@1 60.938 (56.596) Acc@5 96.875 (95.188)
2025-08-27 18:16:33,988 - INFO - Pruning info: sparsity=0.028
2025-08-27 18:16:33,988 - INFO -   Reactivation rate: 0.0054
2025-08-27 18:16:34,948 - INFO - Epoch: [1][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 1.0674 (1.1645) Acc@1 57.812 (57.955) Acc@5 96.094 (95.463)
2025-08-27 18:16:36,789 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 1.1869 (1.1869) Acc@1 57.031 (57.031) Acc@5 98.438 (98.438)
2025-08-27 18:16:37,628 - INFO - Epoch 1:
2025-08-27 18:16:37,628 - INFO -   Train: acc1: 59.2860 | acc5: 95.7640 | loss: 1.1311 | sparsity: 0.0276 | reactivation_rate: 0.0062
2025-08-27 18:16:37,628 - INFO -   Val:   acc1: 57.5300 | acc5: 96.1900 | loss: 1.1908
2025-08-27 18:16:37,628 - INFO -   LR: 0.100000
2025-08-27 18:16:37,673 - INFO - Checkpoint saved: epoch=1, metric=57.5300
2025-08-27 18:16:37,704 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 18:16:37,895 - INFO - Epoch: [2][0/391] Time 0.189 (0.189) Data 0.173 (0.173) Loss 0.9557 (0.9557) Acc@1 66.406 (66.406) Acc@5 98.438 (98.438)
2025-08-27 18:16:38,240 - INFO - Pruning info: sparsity=0.055
2025-08-27 18:16:38,241 - INFO -   Reactivation rate: 0.0132
2025-08-27 18:16:39,838 - INFO - Epoch: [2][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.8099 (0.9810) Acc@1 70.312 (65.501) Acc@5 97.656 (97.014)
2025-08-27 18:16:41,276 - INFO - Pruning info: sparsity=0.055
2025-08-27 18:16:41,276 - INFO -   Reactivation rate: 0.0067
2025-08-27 18:16:41,684 - INFO - Epoch: [2][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.8011 (0.9417) Acc@1 71.094 (66.764) Acc@5 98.438 (97.264)
2025-08-27 18:16:43,765 - INFO - Epoch: [2][300/391] Time 0.017 (0.020) Data 0.000 (0.001) Loss 0.9163 (0.9292) Acc@1 65.625 (67.289) Acc@5 99.219 (97.319)
2025-08-27 18:16:44,552 - INFO - Pruning info: sparsity=0.055
2025-08-27 18:16:44,552 - INFO -   Reactivation rate: 0.0053
2025-08-27 18:16:45,719 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.8272 (0.8272) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 18:16:46,572 - INFO - Epoch 2:
2025-08-27 18:16:46,572 - INFO -   Train: acc1: 68.0260 | acc5: 97.3900 | loss: 0.9089 | sparsity: 0.0545 | reactivation_rate: 0.0070
2025-08-27 18:16:46,572 - INFO -   Val:   acc1: 67.8700 | acc5: 97.0200 | loss: 0.9389
2025-08-27 18:16:46,572 - INFO -   LR: 0.100000
2025-08-27 18:16:46,616 - INFO - Checkpoint saved: epoch=2, metric=67.8700
2025-08-27 18:16:46,648 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 18:16:46,844 - INFO - Epoch: [3][0/391] Time 0.196 (0.196) Data 0.170 (0.170) Loss 0.8519 (0.8519) Acc@1 66.406 (66.406) Acc@5 96.875 (96.875)
2025-08-27 18:16:48,828 - INFO - Epoch: [3][100/391] Time 0.012 (0.022) Data 0.000 (0.003) Loss 0.8257 (0.7950) Acc@1 71.094 (72.254) Acc@5 96.875 (98.074)
2025-08-27 18:16:48,966 - INFO - Pruning info: sparsity=0.081
2025-08-27 18:16:48,966 - INFO -   Reactivation rate: 0.0082
2025-08-27 18:16:50,824 - INFO - Epoch: [3][200/391] Time 0.028 (0.021) Data 0.012 (0.002) Loss 0.7277 (0.7851) Acc@1 70.312 (72.742) Acc@5 97.656 (98.162)
2025-08-27 18:16:52,113 - INFO - Pruning info: sparsity=0.081
2025-08-27 18:16:52,113 - INFO -   Reactivation rate: 0.0056
2025-08-27 18:16:52,743 - INFO - Epoch: [3][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.7644 (0.7777) Acc@1 74.219 (73.009) Acc@5 99.219 (98.149)
2025-08-27 18:16:54,588 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.9302 (0.9302) Acc@1 71.875 (71.875) Acc@5 96.875 (96.875)
2025-08-27 18:16:55,419 - INFO - Epoch 3:
2025-08-27 18:16:55,419 - INFO -   Train: acc1: 73.1180 | acc5: 98.1220 | loss: 0.7753 | sparsity: 0.0807 | reactivation_rate: 0.0069
2025-08-27 18:16:55,419 - INFO -   Val:   acc1: 68.7200 | acc5: 96.3100 | loss: 0.9529
2025-08-27 18:16:55,419 - INFO -   LR: 0.100000
2025-08-27 18:16:55,462 - INFO - Checkpoint saved: epoch=3, metric=68.7200
2025-08-27 18:16:55,494 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 18:16:55,669 - INFO - Epoch: [4][0/391] Time 0.175 (0.175) Data 0.144 (0.144) Loss 0.7020 (0.7020) Acc@1 71.094 (71.094) Acc@5 99.219 (99.219)
2025-08-27 18:16:56,371 - INFO - Pruning info: sparsity=0.106
2025-08-27 18:16:56,371 - INFO -   Reactivation rate: 0.0112
2025-08-27 18:16:57,672 - INFO - Epoch: [4][100/391] Time 0.027 (0.022) Data 0.000 (0.002) Loss 0.7375 (0.7170) Acc@1 80.469 (74.884) Acc@5 96.875 (98.275)
2025-08-27 18:16:59,566 - INFO - Pruning info: sparsity=0.106
2025-08-27 18:16:59,566 - INFO -   Reactivation rate: 0.0064
2025-08-27 18:16:59,665 - INFO - Epoch: [4][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.7124 (0.7042) Acc@1 70.312 (75.595) Acc@5 98.438 (98.348)
2025-08-27 18:17:01,671 - INFO - Epoch: [4][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.7056 (0.7024) Acc@1 76.562 (75.732) Acc@5 96.875 (98.331)
2025-08-27 18:17:02,736 - INFO - Pruning info: sparsity=0.106
2025-08-27 18:17:02,736 - INFO -   Reactivation rate: 0.0048
2025-08-27 18:17:03,558 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 1.2475 (1.2475) Acc@1 64.062 (64.062) Acc@5 94.531 (94.531)
2025-08-27 18:17:04,438 - INFO - Epoch 4:
2025-08-27 18:17:04,438 - INFO -   Train: acc1: 75.8260 | acc5: 98.3800 | loss: 0.6973 | sparsity: 0.1061 | reactivation_rate: 0.0067
2025-08-27 18:17:04,438 - INFO -   Val:   acc1: 63.1500 | acc5: 95.5600 | loss: 1.2214
2025-08-27 18:17:04,438 - INFO -   LR: 0.100000
2025-08-27 18:17:04,464 - INFO - training time: 00h 00m 46.34s
2025-08-27 18:17:04,464 - INFO - 
Training completed!
2025-08-27 18:17:04,464 - INFO - Best accuracy: 68.7200
2025-08-27 18:17:04,464 - INFO - Total training time: 0.01 hours
2025-08-27 18:17:04,464 - INFO - total_experiment time: 00h 00m 47.83s
2025-08-27 18:17:04,465 - INFO - Experiment completed successfully
2025-08-27 18:17:04,465 - INFO - Total time: 0.01 hours
2025-08-27 21:48:20,720 - INFO - Starting experiment: dpf_sparsity0.7_seed42
2025-08-27 21:48:20,720 - INFO - Save directory: ./runs/dpf/sparsity0.7/seed42
2025-08-27 21:48:20,720 - INFO - Hyperparameters:
2025-08-27 21:48:20,720 - INFO -   name: dpf_sparsity0.7_seed42
2025-08-27 21:48:20,720 - INFO -   description: DPF pruning 70% (seed=42)
2025-08-27 21:48:20,720 - INFO -   save_dir: ./runs
2025-08-27 21:48:20,720 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 21:48:20,720 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 21:48:20,720 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 21:48:20,720 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.7, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 21:48:20,720 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 21:48:20,720 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 21:48:20,760 - INFO - System Information:
2025-08-27 21:48:20,760 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 21:48:20,760 - INFO -   python_version: 3.9.18
2025-08-27 21:48:20,760 - INFO -   pytorch_version: 2.1.0
2025-08-27 21:48:20,760 - INFO -   cuda_available: True
2025-08-27 21:48:20,760 - INFO -   cpu_count: 4
2025-08-27 21:48:20,760 - INFO -   memory_total_gb: 11.0
2025-08-27 21:48:20,760 - INFO -   timestamp: 1756298900.7599418
2025-08-27 21:48:20,760 - INFO -   cuda_version: 11.8
2025-08-27 21:48:20,760 - INFO -   gpu_count: 1
2025-08-27 21:48:20,760 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 21:48:20,767 - INFO - Starting experiment: dpf_sparsity0.7_seed42
2025-08-27 21:48:20,767 - INFO - Model: resnet-20
2025-08-27 21:48:20,767 - INFO - Dataset: cifar10
2025-08-27 21:48:20,767 - INFO - Pruning: dpf (70.00%)
2025-08-27 21:48:20,900 - INFO - Model Information:
2025-08-27 21:48:20,900 - INFO -   Type: pruned
2025-08-27 21:48:20,900 - INFO -   Total parameters: 544,948
2025-08-27 21:48:20,900 - INFO -   Trainable parameters: 274,692
2025-08-27 21:48:20,900 - INFO -   Sparsity: 70.00%
2025-08-27 21:48:21,917 - INFO - Starting training...
2025-08-27 21:48:21,917 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 21:48:22,613 - INFO - Pruning info: sparsity=0.000
2025-08-27 21:48:22,613 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:23,125 - INFO - Epoch: [0][0/391] Time 1.208 (1.208) Data 0.570 (0.570) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 21:48:24,879 - INFO - Epoch: [0][100/391] Time 0.020 (0.029) Data 0.000 (0.008) Loss 1.6890 (1.9250) Acc@1 42.969 (26.895) Acc@5 85.938 (80.995)
2025-08-27 21:48:25,944 - INFO - Pruning info: sparsity=0.000
2025-08-27 21:48:25,944 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:26,700 - INFO - Epoch: [0][200/391] Time 0.024 (0.024) Data 0.000 (0.005) Loss 1.4030 (1.7625) Acc@1 43.750 (33.240) Acc@5 95.312 (85.568)
2025-08-27 21:48:28,674 - INFO - Epoch: [0][300/391] Time 0.030 (0.022) Data 0.000 (0.004) Loss 1.3675 (1.6451) Acc@1 50.000 (38.359) Acc@5 92.969 (88.045)
2025-08-27 21:48:29,041 - INFO - Pruning info: sparsity=0.000
2025-08-27 21:48:29,041 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:30,554 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 1.4491 (1.4491) Acc@1 47.656 (47.656) Acc@5 93.750 (93.750)
2025-08-27 21:48:31,505 - INFO - Epoch 0:
2025-08-27 21:48:31,506 - INFO -   Train: acc1: 41.8220 | acc5: 89.4260 | loss: 1.5649 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 21:48:31,506 - INFO -   Val:   acc1: 48.4400 | acc5: 91.8000 | loss: 1.4944
2025-08-27 21:48:31,506 - INFO -   LR: 0.100000
2025-08-27 21:48:31,568 - INFO - Checkpoint saved: epoch=0, metric=48.4400
2025-08-27 21:48:31,598 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 21:48:31,781 - INFO - Epoch: [1][0/391] Time 0.182 (0.182) Data 0.157 (0.157) Loss 1.4618 (1.4618) Acc@1 45.312 (45.312) Acc@5 92.188 (92.188)
2025-08-27 21:48:33,436 - INFO - Pruning info: sparsity=0.028
2025-08-27 21:48:33,437 - INFO -   Reactivation rate: 0.0079
2025-08-27 21:48:33,652 - INFO - Epoch: [1][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 1.0200 (1.1704) Acc@1 59.375 (58.137) Acc@5 98.438 (95.297)
2025-08-27 21:48:35,389 - INFO - Epoch: [1][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.8996 (1.1346) Acc@1 68.750 (59.515) Acc@5 97.656 (95.604)
2025-08-27 21:48:36,262 - INFO - Pruning info: sparsity=0.028
2025-08-27 21:48:36,262 - INFO -   Reactivation rate: 0.0050
2025-08-27 21:48:37,185 - INFO - Epoch: [1][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 1.0258 (1.1025) Acc@1 63.281 (60.559) Acc@5 96.094 (95.912)
2025-08-27 21:48:38,923 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.9522 (0.9522) Acc@1 64.062 (64.062) Acc@5 98.438 (98.438)
2025-08-27 21:48:39,746 - INFO - Epoch 1:
2025-08-27 21:48:39,746 - INFO -   Train: acc1: 61.4480 | acc5: 96.1360 | loss: 1.0767 | sparsity: 0.0276 | reactivation_rate: 0.0061
2025-08-27 21:48:39,746 - INFO -   Val:   acc1: 64.1000 | acc5: 97.0900 | loss: 1.0082
2025-08-27 21:48:39,746 - INFO -   LR: 0.100000
2025-08-27 21:49:00,674 - INFO - Checkpoint saved: epoch=1, metric=64.1000
2025-08-27 21:49:00,707 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 21:49:00,881 - INFO - Epoch: [2][0/391] Time 0.174 (0.174) Data 0.150 (0.150) Loss 0.9481 (0.9481) Acc@1 66.406 (66.406) Acc@5 96.094 (96.094)
2025-08-27 21:49:01,213 - INFO - Pruning info: sparsity=0.055
2025-08-27 21:49:01,213 - INFO -   Reactivation rate: 0.0121
2025-08-27 21:49:02,754 - INFO - Epoch: [2][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.9532 (0.9493) Acc@1 67.188 (66.313) Acc@5 94.531 (97.022)
2025-08-27 21:49:04,099 - INFO - Pruning info: sparsity=0.055
2025-08-27 21:49:04,100 - INFO -   Reactivation rate: 0.0065
2025-08-27 21:49:04,521 - INFO - Epoch: [2][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.8157 (0.9209) Acc@1 75.000 (67.180) Acc@5 99.219 (97.318)
2025-08-27 21:49:06,375 - INFO - Epoch: [2][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.8027 (0.9056) Acc@1 70.312 (67.803) Acc@5 100.000 (97.475)
2025-08-27 21:49:07,071 - INFO - Pruning info: sparsity=0.055
2025-08-27 21:49:07,071 - INFO -   Reactivation rate: 0.0050
2025-08-27 21:49:08,113 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 1.3314 (1.3314) Acc@1 60.156 (60.156) Acc@5 96.875 (96.875)
2025-08-27 21:49:08,977 - INFO - Epoch 2:
2025-08-27 21:49:08,977 - INFO -   Train: acc1: 68.3200 | acc5: 97.5260 | loss: 0.8900 | sparsity: 0.0545 | reactivation_rate: 0.0065
2025-08-27 21:49:08,977 - INFO -   Val:   acc1: 58.2000 | acc5: 94.3100 | loss: 1.4560
2025-08-27 21:49:08,977 - INFO -   LR: 0.100000
2025-08-27 21:49:08,987 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 21:49:09,148 - INFO - Epoch: [3][0/391] Time 0.160 (0.160) Data 0.140 (0.140) Loss 0.9026 (0.9026) Acc@1 64.062 (64.062) Acc@5 98.438 (98.438)
2025-08-27 21:49:10,928 - INFO - Epoch: [3][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.8544 (0.7891) Acc@1 66.406 (72.308) Acc@5 96.875 (98.198)
2025-08-27 21:49:11,033 - INFO - Pruning info: sparsity=0.081
2025-08-27 21:49:11,033 - INFO -   Reactivation rate: 0.0081
2025-08-27 21:49:12,796 - INFO - Epoch: [3][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.7367 (0.7789) Acc@1 75.000 (72.703) Acc@5 98.438 (98.173)
2025-08-27 21:49:14,020 - INFO - Pruning info: sparsity=0.081
2025-08-27 21:49:14,020 - INFO -   Reactivation rate: 0.0054
2025-08-27 21:49:14,692 - INFO - Epoch: [3][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.8469 (0.7735) Acc@1 71.875 (72.955) Acc@5 97.656 (98.209)
2025-08-27 21:49:16,462 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.8747 (0.8747) Acc@1 70.312 (70.312) Acc@5 96.094 (96.094)
2025-08-27 21:49:17,364 - INFO - Epoch 3:
2025-08-27 21:49:17,364 - INFO -   Train: acc1: 72.9100 | acc5: 98.1940 | loss: 0.7756 | sparsity: 0.0807 | reactivation_rate: 0.0067
2025-08-27 21:49:17,364 - INFO -   Val:   acc1: 68.3800 | acc5: 96.9600 | loss: 0.9840
2025-08-27 21:49:17,364 - INFO -   LR: 0.100000
2025-08-27 21:49:17,407 - INFO - Checkpoint saved: epoch=3, metric=68.3800
2025-08-27 21:49:17,438 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 21:49:17,622 - INFO - Epoch: [4][0/391] Time 0.183 (0.183) Data 0.159 (0.159) Loss 0.7896 (0.7896) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-27 21:49:18,295 - INFO - Pruning info: sparsity=0.106
2025-08-27 21:49:18,296 - INFO -   Reactivation rate: 0.0112
2025-08-27 21:49:19,427 - INFO - Epoch: [4][100/391] Time 0.033 (0.020) Data 0.002 (0.004) Loss 0.7666 (0.7414) Acc@1 75.000 (74.010) Acc@5 97.656 (98.414)
2025-08-27 21:49:21,192 - INFO - Pruning info: sparsity=0.106
2025-08-27 21:49:21,193 - INFO -   Reactivation rate: 0.0065
2025-08-27 21:49:21,308 - INFO - Epoch: [4][200/391] Time 0.026 (0.019) Data 0.004 (0.003) Loss 0.6737 (0.7166) Acc@1 74.219 (75.039) Acc@5 99.219 (98.371)
2025-08-27 21:49:23,133 - INFO - Epoch: [4][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.7453 (0.7149) Acc@1 75.000 (75.042) Acc@5 97.656 (98.362)
2025-08-27 21:49:24,094 - INFO - Pruning info: sparsity=0.106
2025-08-27 21:49:24,095 - INFO -   Reactivation rate: 0.0048
2025-08-27 21:49:24,880 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.8618 (0.8618) Acc@1 71.875 (71.875) Acc@5 97.656 (97.656)
2025-08-27 21:49:25,719 - INFO - Epoch 4:
2025-08-27 21:49:25,719 - INFO -   Train: acc1: 75.2560 | acc5: 98.3860 | loss: 0.7104 | sparsity: 0.1061 | reactivation_rate: 0.0067
2025-08-27 21:49:25,719 - INFO -   Val:   acc1: 65.8300 | acc5: 97.1100 | loss: 1.0402
2025-08-27 21:49:25,719 - INFO -   LR: 0.100000
2025-08-27 21:49:25,726 - INFO - 
Epoch: 5, lr = 0.1
2025-08-27 21:49:25,930 - INFO - Epoch: [5][0/391] Time 0.202 (0.202) Data 0.178 (0.178) Loss 0.7352 (0.7352) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 21:49:27,712 - INFO - Epoch: [5][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.6135 (0.6938) Acc@1 79.688 (75.828) Acc@5 100.000 (98.693)
2025-08-27 21:49:28,139 - INFO - Pruning info: sparsity=0.131
2025-08-27 21:49:28,140 - INFO -   Reactivation rate: 0.0077
2025-08-27 21:49:29,542 - INFO - Epoch: [5][200/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.7210 (0.6764) Acc@1 75.781 (76.539) Acc@5 98.438 (98.644)
2025-08-27 21:49:31,072 - INFO - Pruning info: sparsity=0.131
2025-08-27 21:49:31,072 - INFO -   Reactivation rate: 0.0052
2025-08-27 21:49:31,379 - INFO - Epoch: [5][300/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.7623 (0.6714) Acc@1 74.219 (76.864) Acc@5 97.656 (98.619)
2025-08-27 21:49:33,155 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.9729 (0.9729) Acc@1 69.531 (69.531) Acc@5 96.094 (96.094)
2025-08-27 21:49:34,009 - INFO - Epoch 5:
2025-08-27 21:49:34,009 - INFO -   Train: acc1: 76.9600 | acc5: 98.6180 | loss: 0.6691 | sparsity: 0.1309 | reactivation_rate: 0.0067
2025-08-27 21:49:34,009 - INFO -   Val:   acc1: 65.6300 | acc5: 96.1500 | loss: 1.0797
2025-08-27 21:49:34,009 - INFO -   LR: 0.100000
2025-08-27 21:49:34,020 - INFO - 
Epoch: 6, lr = 0.1
2025-08-27 21:49:34,191 - INFO - Epoch: [6][0/391] Time 0.170 (0.170) Data 0.140 (0.140) Loss 0.5742 (0.5742) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 21:49:35,121 - INFO - Pruning info: sparsity=0.155
2025-08-27 21:49:35,121 - INFO -   Reactivation rate: 0.0100
2025-08-27 21:49:35,960 - INFO - Epoch: [6][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.6103 (0.6289) Acc@1 75.781 (78.434) Acc@5 99.219 (98.778)
2025-08-27 21:49:37,828 - INFO - Epoch: [6][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6033 (0.6284) Acc@1 78.125 (78.265) Acc@5 99.219 (98.733)
2025-08-27 21:49:38,095 - INFO - Pruning info: sparsity=0.155
2025-08-27 21:49:38,095 - INFO -   Reactivation rate: 0.0060
2025-08-27 21:49:39,773 - INFO - Epoch: [6][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.6587 (0.6376) Acc@1 77.344 (77.987) Acc@5 97.656 (98.754)
2025-08-27 21:49:41,133 - INFO - Pruning info: sparsity=0.155
2025-08-27 21:49:41,134 - INFO -   Reactivation rate: 0.0045
2025-08-27 21:49:41,567 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.7266 (0.7266) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 21:49:42,454 - INFO - Epoch 6:
2025-08-27 21:49:42,455 - INFO -   Train: acc1: 77.9800 | acc5: 98.7580 | loss: 0.6370 | sparsity: 0.1549 | reactivation_rate: 0.0065
2025-08-27 21:49:42,455 - INFO -   Val:   acc1: 72.4300 | acc5: 97.0800 | loss: 0.8199
2025-08-27 21:49:42,455 - INFO -   LR: 0.100000
2025-08-27 21:49:42,500 - INFO - Checkpoint saved: epoch=6, metric=72.4300
2025-08-27 21:49:42,532 - INFO - 
Epoch: 7, lr = 0.1
2025-08-27 21:49:42,716 - INFO - Epoch: [7][0/391] Time 0.183 (0.183) Data 0.142 (0.142) Loss 0.6716 (0.6716) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 21:49:44,516 - INFO - Epoch: [7][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.6190 (0.6172) Acc@1 78.125 (78.906) Acc@5 98.438 (98.693)
2025-08-27 21:49:45,279 - INFO - Pruning info: sparsity=0.178
2025-08-27 21:49:45,279 - INFO -   Reactivation rate: 0.0074
2025-08-27 21:49:46,345 - INFO - Epoch: [7][200/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.4847 (0.6115) Acc@1 87.500 (78.937) Acc@5 100.000 (98.776)
2025-08-27 21:49:48,275 - INFO - Epoch: [7][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.4176 (0.6112) Acc@1 85.938 (78.956) Acc@5 99.219 (98.744)
2025-08-27 21:49:48,315 - INFO - Pruning info: sparsity=0.178
2025-08-27 21:49:48,315 - INFO -   Reactivation rate: 0.0048
2025-08-27 21:49:50,055 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6926 (0.6926) Acc@1 76.562 (76.562) Acc@5 96.094 (96.094)
2025-08-27 21:49:50,916 - INFO - Epoch 7:
2025-08-27 21:49:50,916 - INFO -   Train: acc1: 78.9740 | acc5: 98.7660 | loss: 0.6096 | sparsity: 0.1783 | reactivation_rate: 0.0065
2025-08-27 21:49:50,916 - INFO -   Val:   acc1: 73.1400 | acc5: 97.8900 | loss: 0.8354
2025-08-27 21:49:50,916 - INFO -   LR: 0.100000
2025-08-27 21:49:50,963 - INFO - Checkpoint saved: epoch=7, metric=73.1400
2025-08-27 21:49:50,995 - INFO - 
Epoch: 8, lr = 0.1
2025-08-27 21:49:51,185 - INFO - Epoch: [8][0/391] Time 0.189 (0.189) Data 0.161 (0.161) Loss 0.5396 (0.5396) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:49:52,478 - INFO - Pruning info: sparsity=0.201
2025-08-27 21:49:52,478 - INFO -   Reactivation rate: 0.0087
2025-08-27 21:49:53,084 - INFO - Epoch: [8][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.5704 (0.5920) Acc@1 78.906 (79.657) Acc@5 100.000 (98.685)
2025-08-27 21:49:54,884 - INFO - Epoch: [8][200/391] Time 0.033 (0.019) Data 0.000 (0.003) Loss 0.4794 (0.5889) Acc@1 82.812 (79.719) Acc@5 99.219 (98.822)
2025-08-27 21:49:55,430 - INFO - Pruning info: sparsity=0.201
2025-08-27 21:49:55,430 - INFO -   Reactivation rate: 0.0056
2025-08-27 21:49:56,676 - INFO - Epoch: [8][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.7481 (0.5930) Acc@1 77.344 (79.597) Acc@5 97.656 (98.845)
2025-08-27 21:49:58,529 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 1.0619 (1.0619) Acc@1 66.406 (66.406) Acc@5 98.438 (98.438)
2025-08-27 21:49:59,378 - INFO - Epoch 8:
2025-08-27 21:49:59,378 - INFO -   Train: acc1: 79.7000 | acc5: 98.9020 | loss: 0.5894 | sparsity: 0.2010 | reactivation_rate: 0.0063
2025-08-27 21:49:59,378 - INFO -   Val:   acc1: 66.5400 | acc5: 96.7900 | loss: 1.0954
2025-08-27 21:49:59,378 - INFO -   LR: 0.100000
2025-08-27 21:49:59,387 - INFO - 
Epoch: 9, lr = 0.1
2025-08-27 21:49:59,557 - INFO - Epoch: [9][0/391] Time 0.169 (0.169) Data 0.151 (0.151) Loss 0.5002 (0.5002) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-27 21:49:59,563 - INFO - Pruning info: sparsity=0.223
2025-08-27 21:49:59,563 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:50:01,293 - INFO - Epoch: [9][100/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.5123 (0.5621) Acc@1 84.375 (80.569) Acc@5 96.875 (98.956)
2025-08-27 21:50:02,389 - INFO - Pruning info: sparsity=0.223
2025-08-27 21:50:02,390 - INFO -   Reactivation rate: 0.0064
2025-08-27 21:50:03,120 - INFO - Epoch: [9][200/391] Time 0.018 (0.019) Data 0.005 (0.003) Loss 0.4881 (0.5692) Acc@1 85.938 (80.302) Acc@5 99.219 (98.974)
2025-08-27 21:50:04,973 - INFO - Epoch: [9][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.7009 (0.5753) Acc@1 78.125 (80.165) Acc@5 98.438 (98.951)
2025-08-27 21:50:05,390 - INFO - Pruning info: sparsity=0.223
2025-08-27 21:50:05,390 - INFO -   Reactivation rate: 0.0048
2025-08-27 21:50:06,783 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.9857 (0.9857) Acc@1 67.969 (67.969) Acc@5 98.438 (98.438)
2025-08-27 21:50:07,626 - INFO - Epoch 9:
2025-08-27 21:50:07,627 - INFO -   Train: acc1: 80.0740 | acc5: 98.9620 | loss: 0.5763 | sparsity: 0.2230 | reactivation_rate: 0.0061
2025-08-27 21:50:07,627 - INFO -   Val:   acc1: 69.8800 | acc5: 97.1300 | loss: 0.9331
2025-08-27 21:50:07,627 - INFO -   LR: 0.100000
2025-08-27 21:50:07,638 - INFO - 
Epoch: 10, lr = 0.1
2025-08-27 21:50:07,801 - INFO - Epoch: [10][0/391] Time 0.162 (0.162) Data 0.145 (0.145) Loss 0.5462 (0.5462) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 21:50:09,388 - INFO - Pruning info: sparsity=0.244
2025-08-27 21:50:09,388 - INFO -   Reactivation rate: 0.0078
2025-08-27 21:50:09,582 - INFO - Epoch: [10][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3573 (0.5386) Acc@1 85.938 (81.405) Acc@5 100.000 (98.979)
2025-08-27 21:50:11,407 - INFO - Epoch: [10][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4896 (0.5452) Acc@1 86.719 (81.040) Acc@5 99.219 (99.032)
2025-08-27 21:50:12,298 - INFO - Pruning info: sparsity=0.244
2025-08-27 21:50:12,298 - INFO -   Reactivation rate: 0.0049
2025-08-27 21:50:13,246 - INFO - Epoch: [10][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.7840 (0.5516) Acc@1 76.562 (80.949) Acc@5 97.656 (99.024)
2025-08-27 21:50:14,999 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.7586 (0.7586) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 21:50:15,847 - INFO - Epoch 10:
2025-08-27 21:50:15,847 - INFO -   Train: acc1: 80.8860 | acc5: 99.0160 | loss: 0.5532 | sparsity: 0.2443 | reactivation_rate: 0.0059
2025-08-27 21:50:15,848 - INFO -   Val:   acc1: 74.6700 | acc5: 98.6100 | loss: 0.7649
2025-08-27 21:50:15,848 - INFO -   LR: 0.100000
2025-08-27 21:50:15,891 - INFO - Checkpoint saved: epoch=10, metric=74.6700
2025-08-27 21:50:15,923 - INFO - 
Epoch: 11, lr = 0.1
2025-08-27 21:50:16,079 - INFO - Epoch: [11][0/391] Time 0.155 (0.155) Data 0.132 (0.132) Loss 0.5760 (0.5760) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 21:50:16,432 - INFO - Pruning info: sparsity=0.265
2025-08-27 21:50:16,432 - INFO -   Reactivation rate: 0.0112
2025-08-27 21:50:18,029 - INFO - Epoch: [11][100/391] Time 0.043 (0.021) Data 0.025 (0.003) Loss 0.5157 (0.5398) Acc@1 82.812 (81.188) Acc@5 99.219 (99.265)
2025-08-27 21:50:19,401 - INFO - Pruning info: sparsity=0.265
2025-08-27 21:50:19,402 - INFO -   Reactivation rate: 0.0056
2025-08-27 21:50:19,773 - INFO - Epoch: [11][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.6038 (0.5420) Acc@1 79.688 (81.075) Acc@5 98.438 (99.172)
2025-08-27 21:50:21,533 - INFO - Epoch: [11][300/391] Time 0.022 (0.019) Data 0.009 (0.003) Loss 0.6688 (0.5443) Acc@1 78.125 (81.115) Acc@5 99.219 (99.112)
2025-08-27 21:50:22,173 - INFO - Pruning info: sparsity=0.265
2025-08-27 21:50:22,173 - INFO -   Reactivation rate: 0.0040
2025-08-27 21:50:23,229 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.7640 (0.7640) Acc@1 72.656 (72.656) Acc@5 99.219 (99.219)
2025-08-27 21:50:24,063 - INFO - Epoch 11:
2025-08-27 21:50:24,064 - INFO -   Train: acc1: 81.1400 | acc5: 99.0740 | loss: 0.5457 | sparsity: 0.2650 | reactivation_rate: 0.0056
2025-08-27 21:50:24,064 - INFO -   Val:   acc1: 73.4500 | acc5: 97.6700 | loss: 0.8119
2025-08-27 21:50:24,064 - INFO -   LR: 0.100000
2025-08-27 21:50:24,072 - INFO - 
Epoch: 12, lr = 0.1
2025-08-27 21:50:24,254 - INFO - Epoch: [12][0/391] Time 0.181 (0.181) Data 0.157 (0.157) Loss 0.5392 (0.5392) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:50:26,013 - INFO - Epoch: [12][100/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4926 (0.5394) Acc@1 82.031 (81.436) Acc@5 99.219 (99.141)
2025-08-27 21:50:26,161 - INFO - Pruning info: sparsity=0.285
2025-08-27 21:50:26,161 - INFO -   Reactivation rate: 0.0070
2025-08-27 21:50:27,778 - INFO - Epoch: [12][200/391] Time 0.020 (0.018) Data 0.008 (0.003) Loss 0.7151 (0.5300) Acc@1 75.000 (81.884) Acc@5 98.438 (99.129)
2025-08-27 21:50:29,002 - INFO - Pruning info: sparsity=0.285
2025-08-27 21:50:29,003 - INFO -   Reactivation rate: 0.0044
2025-08-27 21:50:29,563 - INFO - Epoch: [12][300/391] Time 0.026 (0.018) Data 0.008 (0.003) Loss 0.5633 (0.5401) Acc@1 77.344 (81.551) Acc@5 100.000 (99.073)
2025-08-27 21:50:31,296 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6591 (0.6591) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-27 21:50:32,135 - INFO - Epoch 12:
2025-08-27 21:50:32,135 - INFO -   Train: acc1: 81.5880 | acc5: 99.0580 | loss: 0.5400 | sparsity: 0.2851 | reactivation_rate: 0.0056
2025-08-27 21:50:32,136 - INFO -   Val:   acc1: 72.5200 | acc5: 97.7800 | loss: 0.8493
2025-08-27 21:50:32,136 - INFO -   LR: 0.100000
2025-08-27 21:50:32,143 - INFO - 
Epoch: 13, lr = 0.1
2025-08-27 21:50:32,324 - INFO - Epoch: [13][0/391] Time 0.180 (0.180) Data 0.163 (0.163) Loss 0.5491 (0.5491) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:50:32,926 - INFO - Pruning info: sparsity=0.305
2025-08-27 21:50:32,926 - INFO -   Reactivation rate: 0.0089
2025-08-27 21:50:34,037 - INFO - Epoch: [13][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4249 (0.5123) Acc@1 87.500 (82.851) Acc@5 99.219 (99.110)
2025-08-27 21:50:35,738 - INFO - Pruning info: sparsity=0.305
2025-08-27 21:50:35,750 - INFO -   Reactivation rate: 0.0049
2025-08-27 21:50:35,818 - INFO - Epoch: [13][200/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.3696 (0.5191) Acc@1 87.500 (82.338) Acc@5 99.219 (99.106)
2025-08-27 21:50:37,567 - INFO - Epoch: [13][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.5730 (0.5241) Acc@1 82.812 (82.078) Acc@5 100.000 (99.099)
2025-08-27 21:50:38,584 - INFO - Pruning info: sparsity=0.305
2025-08-27 21:50:38,584 - INFO -   Reactivation rate: 0.0036
2025-08-27 21:50:39,328 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.7222 (0.7222) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 21:50:40,166 - INFO - Epoch 13:
2025-08-27 21:50:40,166 - INFO -   Train: acc1: 81.9720 | acc5: 99.0540 | loss: 0.5277 | sparsity: 0.3046 | reactivation_rate: 0.0053
2025-08-27 21:50:40,166 - INFO -   Val:   acc1: 73.7000 | acc5: 98.7200 | loss: 0.8069
2025-08-27 21:50:40,167 - INFO -   LR: 0.100000
2025-08-27 21:50:40,176 - INFO - 
Epoch: 14, lr = 0.1
2025-08-27 21:50:40,347 - INFO - Epoch: [14][0/391] Time 0.170 (0.170) Data 0.150 (0.150) Loss 0.5385 (0.5385) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:50:42,137 - INFO - Epoch: [14][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5481 (0.5113) Acc@1 85.156 (82.704) Acc@5 98.438 (99.118)
2025-08-27 21:50:42,582 - INFO - Pruning info: sparsity=0.323
2025-08-27 21:50:42,582 - INFO -   Reactivation rate: 0.0061
2025-08-27 21:50:43,965 - INFO - Epoch: [14][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5478 (0.5129) Acc@1 82.031 (82.587) Acc@5 99.219 (99.098)
2025-08-27 21:50:45,515 - INFO - Pruning info: sparsity=0.323
2025-08-27 21:50:45,516 - INFO -   Reactivation rate: 0.0043
2025-08-27 21:50:45,761 - INFO - Epoch: [14][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3964 (0.5166) Acc@1 86.719 (82.353) Acc@5 100.000 (99.131)
2025-08-27 21:50:47,530 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7298 (0.7298) Acc@1 73.438 (73.438) Acc@5 96.875 (96.875)
2025-08-27 21:50:48,407 - INFO - Epoch 14:
2025-08-27 21:50:48,407 - INFO -   Train: acc1: 82.2300 | acc5: 99.1100 | loss: 0.5187 | sparsity: 0.3234 | reactivation_rate: 0.0052
2025-08-27 21:50:48,407 - INFO -   Val:   acc1: 75.2700 | acc5: 97.8900 | loss: 0.7380
2025-08-27 21:50:48,407 - INFO -   LR: 0.100000
2025-08-27 21:50:48,452 - INFO - Checkpoint saved: epoch=14, metric=75.2700
2025-08-27 21:50:48,483 - INFO - 
Epoch: 15, lr = 0.1
2025-08-27 21:50:48,665 - INFO - Epoch: [15][0/391] Time 0.181 (0.181) Data 0.148 (0.148) Loss 0.4136 (0.4136) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:50:49,734 - INFO - Pruning info: sparsity=0.342
2025-08-27 21:50:49,734 - INFO -   Reactivation rate: 0.0078
2025-08-27 21:50:50,577 - INFO - Epoch: [15][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.4666 (0.4989) Acc@1 85.156 (83.137) Acc@5 99.219 (99.080)
2025-08-27 21:50:52,350 - INFO - Epoch: [15][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4896 (0.5073) Acc@1 79.688 (82.564) Acc@5 100.000 (99.122)
2025-08-27 21:50:52,601 - INFO - Pruning info: sparsity=0.342
2025-08-27 21:50:52,602 - INFO -   Reactivation rate: 0.0045
2025-08-27 21:50:54,131 - INFO - Epoch: [15][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.5232 (0.5139) Acc@1 83.594 (82.327) Acc@5 100.000 (99.143)
2025-08-27 21:50:55,517 - INFO - Pruning info: sparsity=0.342
2025-08-27 21:50:55,518 - INFO -   Reactivation rate: 0.0034
2025-08-27 21:50:55,959 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.6588 (0.6588) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 21:50:56,826 - INFO - Epoch 15:
2025-08-27 21:50:56,826 - INFO -   Train: acc1: 82.3720 | acc5: 99.1560 | loss: 0.5131 | sparsity: 0.3416 | reactivation_rate: 0.0051
2025-08-27 21:50:56,826 - INFO -   Val:   acc1: 78.2100 | acc5: 98.7100 | loss: 0.6530
2025-08-27 21:50:56,826 - INFO -   LR: 0.100000
2025-08-27 21:50:56,870 - INFO - Checkpoint saved: epoch=15, metric=78.2100
2025-08-27 21:50:56,902 - INFO - 
Epoch: 16, lr = 0.1
2025-08-27 21:50:57,097 - INFO - Epoch: [16][0/391] Time 0.195 (0.195) Data 0.157 (0.157) Loss 0.6113 (0.6113) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 21:50:58,933 - INFO - Epoch: [16][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.4878 (0.5001) Acc@1 85.156 (82.635) Acc@5 99.219 (99.219)
2025-08-27 21:50:59,718 - INFO - Pruning info: sparsity=0.359
2025-08-27 21:50:59,718 - INFO -   Reactivation rate: 0.0050
2025-08-27 21:51:00,732 - INFO - Epoch: [16][200/391] Time 0.025 (0.019) Data 0.000 (0.004) Loss 0.5199 (0.5018) Acc@1 80.469 (82.575) Acc@5 100.000 (99.203)
2025-08-27 21:51:02,526 - INFO - Epoch: [16][300/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.6280 (0.5043) Acc@1 78.906 (82.548) Acc@5 99.219 (99.164)
2025-08-27 21:51:02,584 - INFO - Pruning info: sparsity=0.359
2025-08-27 21:51:02,598 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:51:04,307 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.6185 (0.6185) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 21:51:05,155 - INFO - Epoch 16:
2025-08-27 21:51:05,155 - INFO -   Train: acc1: 82.5940 | acc5: 99.1680 | loss: 0.5046 | sparsity: 0.3592 | reactivation_rate: 0.0049
2025-08-27 21:51:05,155 - INFO -   Val:   acc1: 79.1700 | acc5: 99.0400 | loss: 0.6127
2025-08-27 21:51:05,155 - INFO -   LR: 0.100000
2025-08-27 21:51:05,201 - INFO - Checkpoint saved: epoch=16, metric=79.1700
2025-08-27 21:51:05,233 - INFO - 
Epoch: 17, lr = 0.1
2025-08-27 21:51:05,406 - INFO - Epoch: [17][0/391] Time 0.173 (0.173) Data 0.150 (0.150) Loss 0.5221 (0.5221) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:51:06,750 - INFO - Pruning info: sparsity=0.376
2025-08-27 21:51:06,750 - INFO -   Reactivation rate: 0.0066
2025-08-27 21:51:07,240 - INFO - Epoch: [17][100/391] Time 0.013 (0.020) Data 0.002 (0.004) Loss 0.4184 (0.4803) Acc@1 84.375 (83.385) Acc@5 100.000 (99.304)
2025-08-27 21:51:09,120 - INFO - Epoch: [17][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4903 (0.4920) Acc@1 85.156 (83.057) Acc@5 100.000 (99.192)
2025-08-27 21:51:09,674 - INFO - Pruning info: sparsity=0.376
2025-08-27 21:51:09,674 - INFO -   Reactivation rate: 0.0042
2025-08-27 21:51:10,944 - INFO - Epoch: [17][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4410 (0.5044) Acc@1 85.156 (82.693) Acc@5 100.000 (99.190)
2025-08-27 21:51:12,718 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.6386 (0.6386) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 21:51:13,551 - INFO - Epoch 17:
2025-08-27 21:51:13,551 - INFO -   Train: acc1: 82.6520 | acc5: 99.1680 | loss: 0.5042 | sparsity: 0.3763 | reactivation_rate: 0.0048
2025-08-27 21:51:13,551 - INFO -   Val:   acc1: 73.4600 | acc5: 96.9200 | loss: 0.8319
2025-08-27 21:51:13,551 - INFO -   LR: 0.100000
2025-08-27 21:51:15,221 - INFO - 
Epoch: 18, lr = 0.1
2025-08-27 21:51:15,392 - INFO - Epoch: [18][0/391] Time 0.170 (0.170) Data 0.141 (0.141) Loss 0.5236 (0.5236) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:51:15,427 - INFO - Pruning info: sparsity=0.393
2025-08-27 21:51:15,427 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:51:17,333 - INFO - Epoch: [18][100/391] Time 0.012 (0.021) Data 0.000 (0.005) Loss 0.4478 (0.4847) Acc@1 83.594 (83.493) Acc@5 98.438 (99.172)
2025-08-27 21:51:18,426 - INFO - Pruning info: sparsity=0.393
2025-08-27 21:51:18,427 - INFO -   Reactivation rate: 0.0046
2025-08-27 21:51:19,180 - INFO - Epoch: [18][200/391] Time 0.037 (0.020) Data 0.024 (0.004) Loss 0.4928 (0.4880) Acc@1 85.156 (83.310) Acc@5 97.656 (99.207)
2025-08-27 21:51:20,933 - INFO - Epoch: [18][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5556 (0.4916) Acc@1 79.688 (83.207) Acc@5 98.438 (99.162)
2025-08-27 21:51:21,367 - INFO - Pruning info: sparsity=0.393
2025-08-27 21:51:21,367 - INFO -   Reactivation rate: 0.0035
2025-08-27 21:51:22,791 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6666 (0.6666) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-27 21:51:23,646 - INFO - Epoch 18:
2025-08-27 21:51:23,646 - INFO -   Train: acc1: 83.1580 | acc5: 99.1460 | loss: 0.4915 | sparsity: 0.3927 | reactivation_rate: 0.0045
2025-08-27 21:51:23,646 - INFO -   Val:   acc1: 75.4600 | acc5: 98.0000 | loss: 0.7370
2025-08-27 21:51:23,646 - INFO -   LR: 0.100000
2025-08-27 21:51:24,132 - INFO - 
Epoch: 19, lr = 0.1
2025-08-27 21:51:24,302 - INFO - Epoch: [19][0/391] Time 0.169 (0.169) Data 0.152 (0.152) Loss 0.4113 (0.4113) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:51:25,876 - INFO - Pruning info: sparsity=0.409
2025-08-27 21:51:25,876 - INFO -   Reactivation rate: 0.0061
2025-08-27 21:51:26,057 - INFO - Epoch: [19][100/391] Time 0.021 (0.019) Data 0.001 (0.003) Loss 0.4446 (0.4851) Acc@1 86.719 (83.509) Acc@5 100.000 (99.250)
2025-08-27 21:51:27,908 - INFO - Epoch: [19][200/391] Time 0.039 (0.019) Data 0.025 (0.003) Loss 0.4927 (0.4920) Acc@1 82.031 (83.096) Acc@5 99.219 (99.262)
2025-08-27 21:51:28,771 - INFO - Pruning info: sparsity=0.409
2025-08-27 21:51:28,771 - INFO -   Reactivation rate: 0.0038
2025-08-27 21:51:29,652 - INFO - Epoch: [19][300/391] Time 0.020 (0.018) Data 0.005 (0.003) Loss 0.3630 (0.4932) Acc@1 89.844 (82.960) Acc@5 99.219 (99.234)
2025-08-27 21:51:31,438 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.7581 (0.7581) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 21:51:32,312 - INFO - Epoch 19:
2025-08-27 21:51:32,312 - INFO -   Train: acc1: 83.1320 | acc5: 99.2480 | loss: 0.4881 | sparsity: 0.4086 | reactivation_rate: 0.0045
2025-08-27 21:51:32,312 - INFO -   Val:   acc1: 72.7300 | acc5: 97.9900 | loss: 0.8573
2025-08-27 21:51:32,312 - INFO -   LR: 0.100000
2025-08-27 21:51:32,324 - INFO - 
Epoch: 20, lr = 0.1
2025-08-27 21:51:32,531 - INFO - Epoch: [20][0/391] Time 0.206 (0.206) Data 0.152 (0.152) Loss 0.4068 (0.4068) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:51:32,865 - INFO - Pruning info: sparsity=0.424
2025-08-27 21:51:32,878 - INFO -   Reactivation rate: 0.0084
2025-08-27 21:51:34,414 - INFO - Epoch: [20][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4129 (0.4872) Acc@1 85.938 (83.184) Acc@5 99.219 (99.304)
2025-08-27 21:51:35,914 - INFO - Pruning info: sparsity=0.424
2025-08-27 21:51:35,914 - INFO -   Reactivation rate: 0.0042
2025-08-27 21:51:36,336 - INFO - Epoch: [20][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.4395 (0.4928) Acc@1 86.719 (82.995) Acc@5 99.219 (99.238)
2025-08-27 21:51:38,149 - INFO - Epoch: [20][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.5157 (0.4879) Acc@1 83.594 (83.165) Acc@5 97.656 (99.221)
2025-08-27 21:51:38,859 - INFO - Pruning info: sparsity=0.424
2025-08-27 21:51:38,859 - INFO -   Reactivation rate: 0.0031
2025-08-27 21:51:39,879 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.7899 (0.7899) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-27 21:51:40,727 - INFO - Epoch 20:
2025-08-27 21:51:40,727 - INFO -   Train: acc1: 83.0500 | acc5: 99.2020 | loss: 0.4911 | sparsity: 0.4239 | reactivation_rate: 0.0043
2025-08-27 21:51:40,727 - INFO -   Val:   acc1: 72.5000 | acc5: 98.1100 | loss: 0.8943
2025-08-27 21:51:40,727 - INFO -   LR: 0.100000
2025-08-27 21:51:40,814 - INFO - 
Epoch: 21, lr = 0.1
2025-08-27 21:51:40,982 - INFO - Epoch: [21][0/391] Time 0.166 (0.166) Data 0.147 (0.147) Loss 0.4016 (0.4016) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:51:42,774 - INFO - Epoch: [21][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4064 (0.4596) Acc@1 85.938 (84.104) Acc@5 99.219 (99.281)
2025-08-27 21:51:42,937 - INFO - Pruning info: sparsity=0.439
2025-08-27 21:51:42,937 - INFO -   Reactivation rate: 0.0053
2025-08-27 21:51:44,634 - INFO - Epoch: [21][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4742 (0.4658) Acc@1 81.250 (83.866) Acc@5 99.219 (99.277)
2025-08-27 21:51:45,867 - INFO - Pruning info: sparsity=0.439
2025-08-27 21:51:45,868 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:51:46,493 - INFO - Epoch: [21][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4610 (0.4733) Acc@1 85.156 (83.729) Acc@5 99.219 (99.255)
2025-08-27 21:51:48,298 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.5399 (0.5399) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-27 21:51:49,144 - INFO - Epoch 21:
2025-08-27 21:51:49,145 - INFO -   Train: acc1: 83.5040 | acc5: 99.2720 | loss: 0.4792 | sparsity: 0.4387 | reactivation_rate: 0.0042
2025-08-27 21:51:49,145 - INFO -   Val:   acc1: 78.3500 | acc5: 98.7000 | loss: 0.6466
2025-08-27 21:51:49,145 - INFO -   LR: 0.100000
2025-08-27 21:51:49,153 - INFO - 
Epoch: 22, lr = 0.1
2025-08-27 21:51:49,317 - INFO - Epoch: [22][0/391] Time 0.163 (0.163) Data 0.148 (0.148) Loss 0.3926 (0.3926) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:51:50,014 - INFO - Pruning info: sparsity=0.453
2025-08-27 21:51:50,028 - INFO -   Reactivation rate: 0.0066
2025-08-27 21:51:51,142 - INFO - Epoch: [22][100/391] Time 0.030 (0.020) Data 0.017 (0.005) Loss 0.4135 (0.4641) Acc@1 87.500 (84.290) Acc@5 98.438 (99.234)
2025-08-27 21:51:52,940 - INFO - Pruning info: sparsity=0.453
2025-08-27 21:51:52,945 - INFO -   Reactivation rate: 0.0035
2025-08-27 21:51:53,000 - INFO - Epoch: [22][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.4339 (0.4644) Acc@1 85.156 (84.235) Acc@5 99.219 (99.246)
2025-08-27 21:51:54,768 - INFO - Epoch: [22][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3838 (0.4653) Acc@1 85.938 (84.232) Acc@5 99.219 (99.237)
2025-08-27 21:51:55,812 - INFO - Pruning info: sparsity=0.453
2025-08-27 21:51:55,812 - INFO -   Reactivation rate: 0.0028
2025-08-27 21:51:56,525 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 1.0787 (1.0787) Acc@1 69.531 (69.531) Acc@5 99.219 (99.219)
2025-08-27 21:51:57,381 - INFO - Epoch 22:
2025-08-27 21:51:57,381 - INFO -   Train: acc1: 84.0840 | acc5: 99.2160 | loss: 0.4690 | sparsity: 0.4530 | reactivation_rate: 0.0040
2025-08-27 21:51:57,381 - INFO -   Val:   acc1: 72.2700 | acc5: 98.2900 | loss: 0.9547
2025-08-27 21:51:57,381 - INFO -   LR: 0.100000
2025-08-27 21:51:57,390 - INFO - 
Epoch: 23, lr = 0.1
2025-08-27 21:51:57,573 - INFO - Epoch: [23][0/391] Time 0.182 (0.182) Data 0.161 (0.161) Loss 0.3801 (0.3801) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:51:59,366 - INFO - Epoch: [23][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.5248 (0.4678) Acc@1 82.031 (84.104) Acc@5 99.219 (99.304)
2025-08-27 21:51:59,829 - INFO - Pruning info: sparsity=0.467
2025-08-27 21:51:59,829 - INFO -   Reactivation rate: 0.0044
2025-08-27 21:52:01,166 - INFO - Epoch: [23][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4534 (0.4798) Acc@1 85.938 (83.613) Acc@5 98.438 (99.258)
2025-08-27 21:52:02,719 - INFO - Pruning info: sparsity=0.467
2025-08-27 21:52:02,720 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:52:02,975 - INFO - Epoch: [23][300/391] Time 0.040 (0.019) Data 0.027 (0.003) Loss 0.4392 (0.4780) Acc@1 85.156 (83.734) Acc@5 100.000 (99.281)
2025-08-27 21:52:04,724 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7311 (0.7311) Acc@1 76.562 (76.562) Acc@5 97.656 (97.656)
2025-08-27 21:52:05,582 - INFO - Epoch 23:
2025-08-27 21:52:05,582 - INFO -   Train: acc1: 83.7760 | acc5: 99.2740 | loss: 0.4757 | sparsity: 0.4667 | reactivation_rate: 0.0038
2025-08-27 21:52:05,582 - INFO -   Val:   acc1: 77.6700 | acc5: 98.5900 | loss: 0.6757
2025-08-27 21:52:05,582 - INFO -   LR: 0.100000
2025-08-27 21:52:05,593 - INFO - 
Epoch: 24, lr = 0.1
2025-08-27 21:52:05,780 - INFO - Epoch: [24][0/391] Time 0.186 (0.186) Data 0.157 (0.157) Loss 0.4769 (0.4769) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:52:06,792 - INFO - Pruning info: sparsity=0.480
2025-08-27 21:52:06,792 - INFO -   Reactivation rate: 0.0056
2025-08-27 21:52:07,611 - INFO - Epoch: [24][100/391] Time 0.029 (0.020) Data 0.000 (0.004) Loss 0.4910 (0.4732) Acc@1 78.125 (83.810) Acc@5 99.219 (99.397)
2025-08-27 21:52:09,443 - INFO - Epoch: [24][200/391] Time 0.030 (0.019) Data 0.000 (0.003) Loss 0.4935 (0.4751) Acc@1 83.594 (83.706) Acc@5 99.219 (99.331)
2025-08-27 21:52:09,691 - INFO - Pruning info: sparsity=0.480
2025-08-27 21:52:09,691 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:52:11,241 - INFO - Epoch: [24][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.6512 (0.4752) Acc@1 80.469 (83.591) Acc@5 100.000 (99.325)
2025-08-27 21:52:12,609 - INFO - Pruning info: sparsity=0.480
2025-08-27 21:52:12,609 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:52:13,017 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.7081 (0.7081) Acc@1 73.438 (73.438) Acc@5 98.438 (98.438)
2025-08-27 21:52:13,857 - INFO - Epoch 24:
2025-08-27 21:52:13,857 - INFO -   Train: acc1: 83.7040 | acc5: 99.2640 | loss: 0.4744 | sparsity: 0.4799 | reactivation_rate: 0.0038
2025-08-27 21:52:13,857 - INFO -   Val:   acc1: 79.1500 | acc5: 98.9100 | loss: 0.6204
2025-08-27 21:52:13,857 - INFO -   LR: 0.100000
2025-08-27 21:52:13,868 - INFO - 
Epoch: 25, lr = 0.1
2025-08-27 21:52:14,054 - INFO - Epoch: [25][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.4733 (0.4733) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:52:15,907 - INFO - Epoch: [25][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.5884 (0.4542) Acc@1 82.031 (84.305) Acc@5 98.438 (99.404)
2025-08-27 21:52:16,831 - INFO - Pruning info: sparsity=0.493
2025-08-27 21:52:16,832 - INFO -   Reactivation rate: 0.0039
2025-08-27 21:52:17,820 - INFO - Epoch: [25][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.6340 (0.4618) Acc@1 79.688 (84.041) Acc@5 98.438 (99.324)
2025-08-27 21:52:19,697 - INFO - Epoch: [25][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5006 (0.4629) Acc@1 83.594 (84.006) Acc@5 100.000 (99.299)
2025-08-27 21:52:19,773 - INFO - Pruning info: sparsity=0.493
2025-08-27 21:52:19,774 - INFO -   Reactivation rate: 0.0028
2025-08-27 21:52:21,516 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.6330 (0.6330) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 21:52:22,416 - INFO - Epoch 25:
2025-08-27 21:52:22,416 - INFO -   Train: acc1: 83.9660 | acc5: 99.2880 | loss: 0.4655 | sparsity: 0.4926 | reactivation_rate: 0.0036
2025-08-27 21:52:22,416 - INFO -   Val:   acc1: 79.3100 | acc5: 98.4300 | loss: 0.6336
2025-08-27 21:52:22,416 - INFO -   LR: 0.100000
2025-08-27 21:52:22,461 - INFO - Checkpoint saved: epoch=25, metric=79.3100
2025-08-27 21:52:22,494 - INFO - 
Epoch: 26, lr = 0.1
2025-08-27 21:52:22,669 - INFO - Epoch: [26][0/391] Time 0.174 (0.174) Data 0.156 (0.156) Loss 0.3509 (0.3509) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:52:24,008 - INFO - Pruning info: sparsity=0.505
2025-08-27 21:52:24,009 - INFO -   Reactivation rate: 0.0050
2025-08-27 21:52:24,506 - INFO - Epoch: [26][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.4600 (0.4576) Acc@1 85.156 (84.468) Acc@5 99.219 (99.366)
2025-08-27 21:52:26,437 - INFO - Epoch: [26][200/391] Time 0.026 (0.020) Data 0.006 (0.003) Loss 0.5425 (0.4613) Acc@1 82.812 (84.387) Acc@5 100.000 (99.324)
2025-08-27 21:52:27,028 - INFO - Pruning info: sparsity=0.505
2025-08-27 21:52:27,028 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:52:28,226 - INFO - Epoch: [26][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.6869 (0.4684) Acc@1 78.125 (84.022) Acc@5 98.438 (99.315)
2025-08-27 21:52:29,982 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5734 (0.5734) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:52:30,838 - INFO - Epoch 26:
2025-08-27 21:52:30,839 - INFO -   Train: acc1: 84.1460 | acc5: 99.3300 | loss: 0.4642 | sparsity: 0.5048 | reactivation_rate: 0.0035
2025-08-27 21:52:30,839 - INFO -   Val:   acc1: 77.1700 | acc5: 98.4300 | loss: 0.7368
2025-08-27 21:52:30,839 - INFO -   LR: 0.100000
2025-08-27 21:52:30,851 - INFO - 
Epoch: 27, lr = 0.1
2025-08-27 21:52:31,018 - INFO - Epoch: [27][0/391] Time 0.165 (0.165) Data 0.141 (0.141) Loss 0.4453 (0.4453) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:52:31,077 - INFO - Pruning info: sparsity=0.516
2025-08-27 21:52:31,077 - INFO -   Reactivation rate: 0.0011
2025-08-27 21:52:32,847 - INFO - Epoch: [27][100/391] Time 0.015 (0.020) Data 0.004 (0.004) Loss 0.6010 (0.4470) Acc@1 78.125 (84.754) Acc@5 100.000 (99.141)
2025-08-27 21:52:33,992 - INFO - Pruning info: sparsity=0.516
2025-08-27 21:52:33,992 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:52:34,645 - INFO - Epoch: [27][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3714 (0.4499) Acc@1 88.281 (84.597) Acc@5 99.219 (99.223)
2025-08-27 21:52:36,504 - INFO - Epoch: [27][300/391] Time 0.037 (0.019) Data 0.027 (0.003) Loss 0.4362 (0.4533) Acc@1 85.938 (84.422) Acc@5 99.219 (99.250)
2025-08-27 21:52:36,941 - INFO - Pruning info: sparsity=0.516
2025-08-27 21:52:36,941 - INFO -   Reactivation rate: 0.0026
2025-08-27 21:52:38,254 - INFO - Test: [0/79] Time 0.107 (0.107) Loss 0.6216 (0.6216) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-27 21:52:39,140 - INFO - Epoch 27:
2025-08-27 21:52:39,140 - INFO -   Train: acc1: 84.2580 | acc5: 99.2600 | loss: 0.4591 | sparsity: 0.5165 | reactivation_rate: 0.0033
2025-08-27 21:52:39,140 - INFO -   Val:   acc1: 76.7900 | acc5: 97.9500 | loss: 0.7282
2025-08-27 21:52:39,140 - INFO -   LR: 0.100000
2025-08-27 21:52:39,150 - INFO - 
Epoch: 28, lr = 0.1
2025-08-27 21:52:39,345 - INFO - Epoch: [28][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.2985 (0.2985) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:52:41,025 - INFO - Pruning info: sparsity=0.528
2025-08-27 21:52:41,025 - INFO -   Reactivation rate: 0.0042
2025-08-27 21:52:41,162 - INFO - Epoch: [28][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4184 (0.4457) Acc@1 85.938 (84.824) Acc@5 100.000 (99.335)
2025-08-27 21:52:43,020 - INFO - Epoch: [28][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4967 (0.4578) Acc@1 85.156 (84.161) Acc@5 100.000 (99.359)
2025-08-27 21:52:43,973 - INFO - Pruning info: sparsity=0.528
2025-08-27 21:52:43,974 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:52:44,832 - INFO - Epoch: [28][300/391] Time 0.046 (0.019) Data 0.024 (0.004) Loss 0.4319 (0.4574) Acc@1 85.938 (84.193) Acc@5 100.000 (99.356)
2025-08-27 21:52:46,536 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.5405 (0.5405) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:52:47,420 - INFO - Epoch 28:
2025-08-27 21:52:47,421 - INFO -   Train: acc1: 84.2120 | acc5: 99.3260 | loss: 0.4582 | sparsity: 0.5277 | reactivation_rate: 0.0032
2025-08-27 21:52:47,421 - INFO -   Val:   acc1: 81.1700 | acc5: 99.0500 | loss: 0.5547
2025-08-27 21:52:47,421 - INFO -   LR: 0.100000
2025-08-27 21:52:47,466 - INFO - Checkpoint saved: epoch=28, metric=81.1700
2025-08-27 21:52:47,499 - INFO - 
Epoch: 29, lr = 0.1
2025-08-27 21:52:47,688 - INFO - Epoch: [29][0/391] Time 0.188 (0.188) Data 0.161 (0.161) Loss 0.5699 (0.5699) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 21:52:48,067 - INFO - Pruning info: sparsity=0.538
2025-08-27 21:52:48,067 - INFO -   Reactivation rate: 0.0057
2025-08-27 21:52:49,607 - INFO - Epoch: [29][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4520 (0.4485) Acc@1 85.938 (84.499) Acc@5 99.219 (99.459)
2025-08-27 21:52:50,983 - INFO - Pruning info: sparsity=0.538
2025-08-27 21:52:50,984 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:52:51,371 - INFO - Epoch: [29][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.4664 (0.4525) Acc@1 85.156 (84.472) Acc@5 100.000 (99.390)
2025-08-27 21:52:53,319 - INFO - Epoch: [29][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4321 (0.4548) Acc@1 83.594 (84.432) Acc@5 99.219 (99.400)
2025-08-27 21:52:54,054 - INFO - Pruning info: sparsity=0.538
2025-08-27 21:52:54,054 - INFO -   Reactivation rate: 0.0021
2025-08-27 21:52:55,083 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.7166 (0.7166) Acc@1 74.219 (74.219) Acc@5 98.438 (98.438)
2025-08-27 21:52:55,928 - INFO - Epoch 29:
2025-08-27 21:52:55,928 - INFO -   Train: acc1: 84.4380 | acc5: 99.3320 | loss: 0.4551 | sparsity: 0.5385 | reactivation_rate: 0.0031
2025-08-27 21:52:55,928 - INFO -   Val:   acc1: 76.5400 | acc5: 98.4500 | loss: 0.7341
2025-08-27 21:52:55,928 - INFO -   LR: 0.100000
2025-08-27 21:52:55,939 - INFO - 
Epoch: 30, lr = 0.1
2025-08-27 21:52:56,145 - INFO - Epoch: [30][0/391] Time 0.204 (0.204) Data 0.181 (0.181) Loss 0.4286 (0.4286) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:52:57,996 - INFO - Epoch: [30][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3795 (0.4537) Acc@1 84.375 (84.483) Acc@5 100.000 (99.358)
2025-08-27 21:52:58,170 - INFO - Pruning info: sparsity=0.549
2025-08-27 21:52:58,182 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:52:59,892 - INFO - Epoch: [30][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.5126 (0.4543) Acc@1 82.812 (84.441) Acc@5 99.219 (99.312)
2025-08-27 21:53:01,141 - INFO - Pruning info: sparsity=0.549
2025-08-27 21:53:01,141 - INFO -   Reactivation rate: 0.0025
2025-08-27 21:53:01,725 - INFO - Epoch: [30][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4913 (0.4536) Acc@1 84.375 (84.507) Acc@5 98.438 (99.356)
2025-08-27 21:53:03,512 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.7877 (0.7877) Acc@1 78.125 (78.125) Acc@5 97.656 (97.656)
2025-08-27 21:53:04,338 - INFO - Epoch 30:
2025-08-27 21:53:04,338 - INFO -   Train: acc1: 84.4340 | acc5: 99.3720 | loss: 0.4546 | sparsity: 0.5488 | reactivation_rate: 0.0030
2025-08-27 21:53:04,338 - INFO -   Val:   acc1: 77.2700 | acc5: 98.7200 | loss: 0.7246
2025-08-27 21:53:04,338 - INFO -   LR: 0.100000
2025-08-27 21:53:04,384 - INFO - 
Epoch: 31, lr = 0.1
2025-08-27 21:53:04,562 - INFO - Epoch: [31][0/391] Time 0.177 (0.177) Data 0.151 (0.151) Loss 0.6530 (0.6530) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-27 21:53:05,227 - INFO - Pruning info: sparsity=0.559
2025-08-27 21:53:05,227 - INFO -   Reactivation rate: 0.0046
2025-08-27 21:53:06,330 - INFO - Epoch: [31][100/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.3839 (0.4445) Acc@1 87.500 (84.715) Acc@5 99.219 (99.466)
2025-08-27 21:53:08,084 - INFO - Pruning info: sparsity=0.559
2025-08-27 21:53:08,084 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:53:08,119 - INFO - Epoch: [31][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3862 (0.4451) Acc@1 86.719 (84.756) Acc@5 99.219 (99.401)
2025-08-27 21:53:09,922 - INFO - Epoch: [31][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4634 (0.4474) Acc@1 82.031 (84.694) Acc@5 98.438 (99.351)
2025-08-27 21:53:10,922 - INFO - Pruning info: sparsity=0.559
2025-08-27 21:53:10,923 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:53:11,671 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.4828 (0.4828) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:53:12,514 - INFO - Epoch 31:
2025-08-27 21:53:12,514 - INFO -   Train: acc1: 84.6060 | acc5: 99.3440 | loss: 0.4493 | sparsity: 0.5587 | reactivation_rate: 0.0029
2025-08-27 21:53:12,514 - INFO -   Val:   acc1: 80.0400 | acc5: 98.6100 | loss: 0.6077
2025-08-27 21:53:12,514 - INFO -   LR: 0.100000
2025-08-27 21:53:12,525 - INFO - 
Epoch: 32, lr = 0.1
2025-08-27 21:53:12,738 - INFO - Epoch: [32][0/391] Time 0.212 (0.212) Data 0.173 (0.173) Loss 0.5712 (0.5712) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:53:14,589 - INFO - Epoch: [32][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.3808 (0.4226) Acc@1 85.938 (85.651) Acc@5 99.219 (99.420)
2025-08-27 21:53:15,112 - INFO - Pruning info: sparsity=0.568
2025-08-27 21:53:15,113 - INFO -   Reactivation rate: 0.0029
2025-08-27 21:53:16,452 - INFO - Epoch: [32][200/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4420 (0.4400) Acc@1 82.812 (84.989) Acc@5 100.000 (99.413)
2025-08-27 21:53:18,023 - INFO - Pruning info: sparsity=0.568
2025-08-27 21:53:18,023 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:53:18,251 - INFO - Epoch: [32][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4261 (0.4423) Acc@1 86.719 (84.910) Acc@5 100.000 (99.398)
2025-08-27 21:53:20,014 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6161 (0.6161) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 21:53:20,900 - INFO - Epoch 32:
2025-08-27 21:53:20,900 - INFO -   Train: acc1: 84.7460 | acc5: 99.3840 | loss: 0.4471 | sparsity: 0.5681 | reactivation_rate: 0.0027
2025-08-27 21:53:20,900 - INFO -   Val:   acc1: 80.4500 | acc5: 99.0000 | loss: 0.6031
2025-08-27 21:53:20,901 - INFO -   LR: 0.100000
2025-08-27 21:53:20,911 - INFO - 
Epoch: 33, lr = 0.1
2025-08-27 21:53:21,096 - INFO - Epoch: [33][0/391] Time 0.183 (0.183) Data 0.158 (0.158) Loss 0.3841 (0.3841) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 21:53:22,121 - INFO - Pruning info: sparsity=0.577
2025-08-27 21:53:22,122 - INFO -   Reactivation rate: 0.0042
2025-08-27 21:53:22,873 - INFO - Epoch: [33][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4941 (0.4430) Acc@1 80.469 (84.553) Acc@5 98.438 (99.327)
2025-08-27 21:53:24,780 - INFO - Epoch: [33][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4756 (0.4327) Acc@1 84.375 (84.981) Acc@5 98.438 (99.382)
2025-08-27 21:53:25,088 - INFO - Pruning info: sparsity=0.577
2025-08-27 21:53:25,088 - INFO -   Reactivation rate: 0.0024
2025-08-27 21:53:26,588 - INFO - Epoch: [33][300/391] Time 0.024 (0.019) Data 0.002 (0.003) Loss 0.4290 (0.4371) Acc@1 87.500 (84.982) Acc@5 98.438 (99.413)
2025-08-27 21:53:28,022 - INFO - Pruning info: sparsity=0.577
2025-08-27 21:53:28,022 - INFO -   Reactivation rate: 0.0018
2025-08-27 21:53:28,413 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.4826 (0.4826) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:53:29,270 - INFO - Epoch 33:
2025-08-27 21:53:29,271 - INFO -   Train: acc1: 84.8860 | acc5: 99.3840 | loss: 0.4422 | sparsity: 0.5771 | reactivation_rate: 0.0027
2025-08-27 21:53:29,271 - INFO -   Val:   acc1: 81.4900 | acc5: 99.2500 | loss: 0.5397
2025-08-27 21:53:29,271 - INFO -   LR: 0.100000
2025-08-27 21:53:29,323 - INFO - Checkpoint saved: epoch=33, metric=81.4900
2025-08-27 21:53:29,355 - INFO - 
Epoch: 34, lr = 0.1
2025-08-27 21:53:29,525 - INFO - Epoch: [34][0/391] Time 0.169 (0.169) Data 0.148 (0.148) Loss 0.5013 (0.5013) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:53:31,343 - INFO - Epoch: [34][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.5156 (0.4388) Acc@1 84.375 (85.032) Acc@5 99.219 (99.335)
2025-08-27 21:53:32,160 - INFO - Pruning info: sparsity=0.586
2025-08-27 21:53:32,161 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:53:33,116 - INFO - Epoch: [34][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4605 (0.4434) Acc@1 81.250 (84.764) Acc@5 99.219 (99.331)
2025-08-27 21:53:34,921 - INFO - Epoch: [34][300/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.4967 (0.4430) Acc@1 81.250 (84.764) Acc@5 98.438 (99.336)
2025-08-27 21:53:35,039 - INFO - Pruning info: sparsity=0.586
2025-08-27 21:53:35,040 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:53:36,715 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.7335 (0.7335) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-27 21:53:37,535 - INFO - Epoch 34:
2025-08-27 21:53:37,535 - INFO -   Train: acc1: 84.5680 | acc5: 99.3160 | loss: 0.4478 | sparsity: 0.5856 | reactivation_rate: 0.0026
2025-08-27 21:53:37,535 - INFO -   Val:   acc1: 75.4100 | acc5: 98.4000 | loss: 0.8107
2025-08-27 21:53:37,535 - INFO -   LR: 0.100000
2025-08-27 21:53:37,548 - INFO - 
Epoch: 35, lr = 0.1
2025-08-27 21:53:37,682 - INFO - Epoch: [35][0/391] Time 0.133 (0.133) Data 0.117 (0.117) Loss 0.3126 (0.3126) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 21:53:39,176 - INFO - Pruning info: sparsity=0.594
2025-08-27 21:53:39,176 - INFO -   Reactivation rate: 0.0036
2025-08-27 21:53:39,634 - INFO - Epoch: [35][100/391] Time 0.039 (0.021) Data 0.025 (0.004) Loss 0.5119 (0.4388) Acc@1 81.250 (85.048) Acc@5 99.219 (99.319)
2025-08-27 21:53:41,433 - INFO - Epoch: [35][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3597 (0.4339) Acc@1 86.719 (85.009) Acc@5 100.000 (99.347)
2025-08-27 21:53:42,080 - INFO - Pruning info: sparsity=0.594
2025-08-27 21:53:42,080 - INFO -   Reactivation rate: 0.0022
2025-08-27 21:53:43,262 - INFO - Epoch: [35][300/391] Time 0.021 (0.019) Data 0.002 (0.003) Loss 0.4363 (0.4390) Acc@1 88.281 (84.762) Acc@5 99.219 (99.333)
2025-08-27 21:53:44,989 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6967 (0.6967) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-27 21:53:45,867 - INFO - Epoch 35:
2025-08-27 21:53:45,867 - INFO -   Train: acc1: 84.7080 | acc5: 99.3320 | loss: 0.4415 | sparsity: 0.5938 | reactivation_rate: 0.0025
2025-08-27 21:53:45,867 - INFO -   Val:   acc1: 76.3200 | acc5: 98.6200 | loss: 0.7308
2025-08-27 21:53:45,867 - INFO -   LR: 0.100000
2025-08-27 21:53:45,878 - INFO - 
Epoch: 36, lr = 0.1
2025-08-27 21:53:46,048 - INFO - Epoch: [36][0/391] Time 0.168 (0.168) Data 0.137 (0.137) Loss 0.3674 (0.3674) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 21:53:46,104 - INFO - Pruning info: sparsity=0.602
2025-08-27 21:53:46,105 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:53:47,844 - INFO - Epoch: [36][100/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.3901 (0.4385) Acc@1 84.375 (84.800) Acc@5 100.000 (99.420)
2025-08-27 21:53:48,969 - INFO - Pruning info: sparsity=0.602
2025-08-27 21:53:48,969 - INFO -   Reactivation rate: 0.0024
2025-08-27 21:53:49,666 - INFO - Epoch: [36][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3297 (0.4438) Acc@1 90.625 (84.659) Acc@5 100.000 (99.359)
2025-08-27 21:53:51,396 - INFO - Epoch: [36][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.5400 (0.4447) Acc@1 79.688 (84.622) Acc@5 99.219 (99.338)
2025-08-27 21:53:51,796 - INFO - Pruning info: sparsity=0.602
2025-08-27 21:53:51,796 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:53:53,130 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6477 (0.6477) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 21:53:53,931 - INFO - Epoch 36:
2025-08-27 21:53:53,931 - INFO -   Train: acc1: 84.7080 | acc5: 99.3620 | loss: 0.4427 | sparsity: 0.6016 | reactivation_rate: 0.0024
2025-08-27 21:53:53,931 - INFO -   Val:   acc1: 76.8500 | acc5: 98.0200 | loss: 0.7453
2025-08-27 21:53:53,931 - INFO -   LR: 0.100000
2025-08-27 21:53:53,942 - INFO - 
Epoch: 37, lr = 0.1
2025-08-27 21:53:54,125 - INFO - Epoch: [37][0/391] Time 0.182 (0.182) Data 0.158 (0.158) Loss 0.3426 (0.3426) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 21:53:55,752 - INFO - Pruning info: sparsity=0.609
2025-08-27 21:53:55,752 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:53:55,884 - INFO - Epoch: [37][100/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.4355 (0.4376) Acc@1 86.719 (84.994) Acc@5 99.219 (99.281)
2025-08-27 21:53:57,615 - INFO - Epoch: [37][200/391] Time 0.028 (0.018) Data 0.009 (0.003) Loss 0.4121 (0.4491) Acc@1 86.719 (84.589) Acc@5 99.219 (99.234)
2025-08-27 21:53:58,526 - INFO - Pruning info: sparsity=0.609
2025-08-27 21:53:58,526 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:53:59,376 - INFO - Epoch: [37][300/391] Time 0.019 (0.018) Data 0.000 (0.003) Loss 0.5784 (0.4462) Acc@1 80.469 (84.684) Acc@5 99.219 (99.286)
2025-08-27 21:54:01,123 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4585 (0.4585) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:54:01,993 - INFO - Epoch 37:
2025-08-27 21:54:01,994 - INFO -   Train: acc1: 84.7180 | acc5: 99.3000 | loss: 0.4467 | sparsity: 0.6090 | reactivation_rate: 0.0024
2025-08-27 21:54:01,994 - INFO -   Val:   acc1: 82.4100 | acc5: 99.2800 | loss: 0.5050
2025-08-27 21:54:01,994 - INFO -   LR: 0.100000
2025-08-27 21:54:02,039 - INFO - Checkpoint saved: epoch=37, metric=82.4100
2025-08-27 21:54:02,071 - INFO - 
Epoch: 38, lr = 0.1
2025-08-27 21:54:02,227 - INFO - Epoch: [38][0/391] Time 0.155 (0.155) Data 0.139 (0.139) Loss 0.2969 (0.2969) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:54:02,656 - INFO - Pruning info: sparsity=0.616
2025-08-27 21:54:02,661 - INFO -   Reactivation rate: 0.0044
2025-08-27 21:54:04,000 - INFO - Epoch: [38][100/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.4596 (0.4312) Acc@1 83.594 (85.644) Acc@5 98.438 (99.397)
2025-08-27 21:54:05,481 - INFO - Pruning info: sparsity=0.616
2025-08-27 21:54:05,481 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:54:05,812 - INFO - Epoch: [38][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2952 (0.4382) Acc@1 88.281 (85.032) Acc@5 100.000 (99.382)
2025-08-27 21:54:07,579 - INFO - Epoch: [38][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.5167 (0.4408) Acc@1 82.031 (84.954) Acc@5 100.000 (99.369)
2025-08-27 21:54:08,354 - INFO - Pruning info: sparsity=0.616
2025-08-27 21:54:08,358 - INFO -   Reactivation rate: 0.0017
2025-08-27 21:54:09,311 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6337 (0.6337) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:54:10,180 - INFO - Epoch 38:
2025-08-27 21:54:10,180 - INFO -   Train: acc1: 84.9740 | acc5: 99.3660 | loss: 0.4399 | sparsity: 0.6160 | reactivation_rate: 0.0023
2025-08-27 21:54:10,180 - INFO -   Val:   acc1: 78.3500 | acc5: 98.9500 | loss: 0.6475
2025-08-27 21:54:10,180 - INFO -   LR: 0.100000
2025-08-27 21:54:10,193 - INFO - 
Epoch: 39, lr = 0.1
2025-08-27 21:54:10,379 - INFO - Epoch: [39][0/391] Time 0.185 (0.185) Data 0.163 (0.163) Loss 0.4041 (0.4041) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 21:54:12,232 - INFO - Epoch: [39][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4459 (0.4367) Acc@1 83.594 (85.017) Acc@5 100.000 (99.335)
2025-08-27 21:54:12,440 - INFO - Pruning info: sparsity=0.623
2025-08-27 21:54:12,440 - INFO -   Reactivation rate: 0.0026
2025-08-27 21:54:14,042 - INFO - Epoch: [39][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.5033 (0.4393) Acc@1 81.250 (84.787) Acc@5 98.438 (99.425)
2025-08-27 21:54:15,260 - INFO - Pruning info: sparsity=0.623
2025-08-27 21:54:15,260 - INFO -   Reactivation rate: 0.0018
2025-08-27 21:54:15,809 - INFO - Epoch: [39][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5935 (0.4371) Acc@1 82.031 (84.842) Acc@5 97.656 (99.411)
2025-08-27 21:54:17,545 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4892 (0.4892) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 21:54:18,405 - INFO - Epoch 39:
2025-08-27 21:54:18,406 - INFO -   Train: acc1: 84.9000 | acc5: 99.3500 | loss: 0.4391 | sparsity: 0.6226 | reactivation_rate: 0.0022
2025-08-27 21:54:18,406 - INFO -   Val:   acc1: 81.4300 | acc5: 99.1400 | loss: 0.5672
2025-08-27 21:54:18,406 - INFO -   LR: 0.100000
2025-08-27 21:54:18,417 - INFO - 
Epoch: 40, lr = 0.1
2025-08-27 21:54:18,597 - INFO - Epoch: [40][0/391] Time 0.179 (0.179) Data 0.148 (0.148) Loss 0.4003 (0.4003) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:54:19,317 - INFO - Pruning info: sparsity=0.629
2025-08-27 21:54:19,317 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:54:20,400 - INFO - Epoch: [40][100/391] Time 0.027 (0.020) Data 0.004 (0.004) Loss 0.3928 (0.4355) Acc@1 85.156 (84.746) Acc@5 99.219 (99.505)
2025-08-27 21:54:22,317 - INFO - Pruning info: sparsity=0.629
2025-08-27 21:54:22,318 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:54:22,331 - INFO - Epoch: [40][200/391] Time 0.048 (0.019) Data 0.029 (0.003) Loss 0.3717 (0.4320) Acc@1 89.062 (85.211) Acc@5 99.219 (99.433)
2025-08-27 21:54:24,243 - INFO - Epoch: [40][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4795 (0.4386) Acc@1 85.938 (85.034) Acc@5 98.438 (99.398)
2025-08-27 21:54:25,371 - INFO - Pruning info: sparsity=0.629
2025-08-27 21:54:25,371 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:54:26,077 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.7311 (0.7311) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:54:26,927 - INFO - Epoch 40:
2025-08-27 21:54:26,927 - INFO -   Train: acc1: 85.0260 | acc5: 99.3920 | loss: 0.4383 | sparsity: 0.6289 | reactivation_rate: 0.0022
2025-08-27 21:54:26,927 - INFO -   Val:   acc1: 77.7700 | acc5: 98.9300 | loss: 0.6805
2025-08-27 21:54:26,927 - INFO -   LR: 0.100000
2025-08-27 21:54:26,974 - INFO - 
Epoch: 41, lr = 0.1
2025-08-27 21:54:27,150 - INFO - Epoch: [41][0/391] Time 0.174 (0.174) Data 0.158 (0.158) Loss 0.3052 (0.3052) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:54:29,000 - INFO - Epoch: [41][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4397 (0.4226) Acc@1 83.594 (85.442) Acc@5 100.000 (99.335)
2025-08-27 21:54:29,505 - INFO - Pruning info: sparsity=0.635
2025-08-27 21:54:29,506 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:54:30,776 - INFO - Epoch: [41][200/391] Time 0.048 (0.019) Data 0.030 (0.003) Loss 0.4161 (0.4293) Acc@1 84.375 (85.281) Acc@5 98.438 (99.343)
2025-08-27 21:54:32,391 - INFO - Pruning info: sparsity=0.635
2025-08-27 21:54:32,391 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:54:32,599 - INFO - Epoch: [41][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3656 (0.4338) Acc@1 86.719 (85.138) Acc@5 100.000 (99.325)
2025-08-27 21:54:34,395 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.5327 (0.5327) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 21:54:35,275 - INFO - Epoch 41:
2025-08-27 21:54:35,275 - INFO -   Train: acc1: 84.9460 | acc5: 99.3220 | loss: 0.4380 | sparsity: 0.6348 | reactivation_rate: 0.0020
2025-08-27 21:54:35,275 - INFO -   Val:   acc1: 79.2900 | acc5: 98.8400 | loss: 0.6070
2025-08-27 21:54:35,275 - INFO -   LR: 0.100000
2025-08-27 21:54:35,285 - INFO - 
Epoch: 42, lr = 0.1
2025-08-27 21:54:35,484 - INFO - Epoch: [42][0/391] Time 0.197 (0.197) Data 0.172 (0.172) Loss 0.3762 (0.3762) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:54:36,535 - INFO - Pruning info: sparsity=0.640
2025-08-27 21:54:36,535 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:54:37,301 - INFO - Epoch: [42][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.6529 (0.4156) Acc@1 74.219 (85.752) Acc@5 97.656 (99.381)
2025-08-27 21:54:39,262 - INFO - Epoch: [42][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.5735 (0.4296) Acc@1 78.125 (85.308) Acc@5 99.219 (99.374)
2025-08-27 21:54:39,538 - INFO - Pruning info: sparsity=0.640
2025-08-27 21:54:39,550 - INFO -   Reactivation rate: 0.0017
2025-08-27 21:54:41,100 - INFO - Epoch: [42][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2681 (0.4407) Acc@1 91.406 (84.941) Acc@5 99.219 (99.343)
2025-08-27 21:54:42,505 - INFO - Pruning info: sparsity=0.640
2025-08-27 21:54:42,505 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:54:42,906 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5797 (0.5797) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:54:43,746 - INFO - Epoch 42:
2025-08-27 21:54:43,746 - INFO -   Train: acc1: 84.8920 | acc5: 99.3420 | loss: 0.4404 | sparsity: 0.6404 | reactivation_rate: 0.0020
2025-08-27 21:54:43,746 - INFO -   Val:   acc1: 81.0700 | acc5: 99.1000 | loss: 0.5641
2025-08-27 21:54:43,746 - INFO -   LR: 0.100000
2025-08-27 21:54:43,761 - INFO - 
Epoch: 43, lr = 0.1
2025-08-27 21:54:43,941 - INFO - Epoch: [43][0/391] Time 0.179 (0.179) Data 0.160 (0.160) Loss 0.2856 (0.2856) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 21:54:45,849 - INFO - Epoch: [43][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.4113 (0.4362) Acc@1 85.938 (84.932) Acc@5 100.000 (99.404)
2025-08-27 21:54:46,677 - INFO - Pruning info: sparsity=0.646
2025-08-27 21:54:46,678 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:54:47,654 - INFO - Epoch: [43][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3116 (0.4278) Acc@1 85.938 (85.312) Acc@5 100.000 (99.363)
2025-08-27 21:54:49,449 - INFO - Epoch: [43][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3200 (0.4286) Acc@1 91.406 (85.307) Acc@5 100.000 (99.354)
2025-08-27 21:54:49,569 - INFO - Pruning info: sparsity=0.646
2025-08-27 21:54:49,569 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:54:51,261 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5154 (0.5154) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:54:52,109 - INFO - Epoch 43:
2025-08-27 21:54:52,109 - INFO -   Train: acc1: 85.1520 | acc5: 99.3460 | loss: 0.4327 | sparsity: 0.6456 | reactivation_rate: 0.0018
2025-08-27 21:54:52,109 - INFO -   Val:   acc1: 82.1600 | acc5: 99.1000 | loss: 0.5277
2025-08-27 21:54:52,109 - INFO -   LR: 0.100000
2025-08-27 21:54:52,120 - INFO - 
Epoch: 44, lr = 0.1
2025-08-27 21:54:52,313 - INFO - Epoch: [44][0/391] Time 0.192 (0.192) Data 0.169 (0.169) Loss 0.3619 (0.3619) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:54:53,709 - INFO - Pruning info: sparsity=0.651
2025-08-27 21:54:53,709 - INFO -   Reactivation rate: 0.0026
2025-08-27 21:54:54,198 - INFO - Epoch: [44][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.3420 (0.4295) Acc@1 88.281 (85.017) Acc@5 100.000 (99.404)
2025-08-27 21:54:56,013 - INFO - Epoch: [44][200/391] Time 0.013 (0.019) Data 0.002 (0.003) Loss 0.3839 (0.4305) Acc@1 89.844 (85.269) Acc@5 99.219 (99.398)
2025-08-27 21:54:56,651 - INFO - Pruning info: sparsity=0.651
2025-08-27 21:54:56,651 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:54:57,869 - INFO - Epoch: [44][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.3747 (0.4293) Acc@1 85.938 (85.237) Acc@5 99.219 (99.421)
2025-08-27 21:54:59,639 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6193 (0.6193) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 21:55:00,476 - INFO - Epoch 44:
2025-08-27 21:55:00,476 - INFO -   Train: acc1: 85.2300 | acc5: 99.3820 | loss: 0.4312 | sparsity: 0.6506 | reactivation_rate: 0.0018
2025-08-27 21:55:00,476 - INFO -   Val:   acc1: 80.9700 | acc5: 99.0700 | loss: 0.5851
2025-08-27 21:55:00,476 - INFO -   LR: 0.100000
2025-08-27 21:55:00,489 - INFO - 
Epoch: 45, lr = 0.1
2025-08-27 21:55:00,670 - INFO - Epoch: [45][0/391] Time 0.180 (0.180) Data 0.153 (0.153) Loss 0.3319 (0.3319) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:55:00,756 - INFO - Pruning info: sparsity=0.655
2025-08-27 21:55:00,756 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:55:02,569 - INFO - Epoch: [45][100/391] Time 0.023 (0.021) Data 0.000 (0.004) Loss 0.6984 (0.4239) Acc@1 75.781 (85.404) Acc@5 98.438 (99.366)
2025-08-27 21:55:03,744 - INFO - Pruning info: sparsity=0.655
2025-08-27 21:55:03,744 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:55:04,404 - INFO - Epoch: [45][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3378 (0.4268) Acc@1 86.719 (85.370) Acc@5 100.000 (99.320)
2025-08-27 21:55:06,297 - INFO - Epoch: [45][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4333 (0.4307) Acc@1 86.719 (85.247) Acc@5 98.438 (99.307)
2025-08-27 21:55:06,698 - INFO - Pruning info: sparsity=0.655
2025-08-27 21:55:06,698 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:55:08,052 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3749 (0.3749) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:55:08,919 - INFO - Epoch 45:
2025-08-27 21:55:08,919 - INFO -   Train: acc1: 85.2460 | acc5: 99.3140 | loss: 0.4309 | sparsity: 0.6552 | reactivation_rate: 0.0017
2025-08-27 21:55:08,919 - INFO -   Val:   acc1: 82.8200 | acc5: 99.0400 | loss: 0.5187
2025-08-27 21:55:08,919 - INFO -   LR: 0.100000
2025-08-27 21:55:08,967 - INFO - Checkpoint saved: epoch=45, metric=82.8200
2025-08-27 21:55:08,998 - INFO - 
Epoch: 46, lr = 0.1
2025-08-27 21:55:09,175 - INFO - Epoch: [46][0/391] Time 0.175 (0.175) Data 0.148 (0.148) Loss 0.3617 (0.3617) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 21:55:10,928 - INFO - Pruning info: sparsity=0.660
2025-08-27 21:55:10,928 - INFO -   Reactivation rate: 0.0022
2025-08-27 21:55:11,013 - INFO - Epoch: [46][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.5696 (0.4181) Acc@1 78.906 (85.729) Acc@5 99.219 (99.319)
2025-08-27 21:55:12,942 - INFO - Epoch: [46][200/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.4177 (0.4269) Acc@1 85.156 (85.257) Acc@5 99.219 (99.382)
2025-08-27 21:55:13,923 - INFO - Pruning info: sparsity=0.660
2025-08-27 21:55:13,923 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:55:14,747 - INFO - Epoch: [46][300/391] Time 0.036 (0.019) Data 0.020 (0.004) Loss 0.3421 (0.4285) Acc@1 89.844 (85.216) Acc@5 100.000 (99.380)
2025-08-27 21:55:16,496 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6554 (0.6554) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 21:55:17,362 - INFO - Epoch 46:
2025-08-27 21:55:17,363 - INFO -   Train: acc1: 85.1020 | acc5: 99.3480 | loss: 0.4334 | sparsity: 0.6595 | reactivation_rate: 0.0017
2025-08-27 21:55:17,363 - INFO -   Val:   acc1: 79.3600 | acc5: 98.8000 | loss: 0.6415
2025-08-27 21:55:17,363 - INFO -   LR: 0.100000
2025-08-27 21:55:17,375 - INFO - 
Epoch: 47, lr = 0.1
2025-08-27 21:55:17,554 - INFO - Epoch: [47][0/391] Time 0.178 (0.178) Data 0.148 (0.148) Loss 0.4943 (0.4943) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:55:18,001 - INFO - Pruning info: sparsity=0.664
2025-08-27 21:55:18,001 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:55:19,372 - INFO - Epoch: [47][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3844 (0.4216) Acc@1 85.156 (85.659) Acc@5 100.000 (99.312)
2025-08-27 21:55:20,855 - INFO - Pruning info: sparsity=0.664
2025-08-27 21:55:20,856 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:55:21,207 - INFO - Epoch: [47][200/391] Time 0.020 (0.019) Data 0.006 (0.003) Loss 0.4584 (0.4270) Acc@1 83.594 (85.463) Acc@5 100.000 (99.374)
2025-08-27 21:55:23,075 - INFO - Epoch: [47][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3907 (0.4321) Acc@1 85.156 (85.239) Acc@5 100.000 (99.341)
2025-08-27 21:55:23,865 - INFO - Pruning info: sparsity=0.664
2025-08-27 21:55:23,865 - INFO -   Reactivation rate: 0.0011
2025-08-27 21:55:24,864 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5303 (0.5303) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:55:25,709 - INFO - Epoch 47:
2025-08-27 21:55:25,709 - INFO -   Train: acc1: 85.1400 | acc5: 99.3440 | loss: 0.4347 | sparsity: 0.6636 | reactivation_rate: 0.0016
2025-08-27 21:55:25,709 - INFO -   Val:   acc1: 79.5500 | acc5: 99.1600 | loss: 0.6001
2025-08-27 21:55:25,709 - INFO -   LR: 0.100000
2025-08-27 21:55:25,722 - INFO - 
Epoch: 48, lr = 0.1
2025-08-27 21:55:25,904 - INFO - Epoch: [48][0/391] Time 0.180 (0.180) Data 0.155 (0.155) Loss 0.4912 (0.4912) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:55:27,785 - INFO - Epoch: [48][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4222 (0.4035) Acc@1 85.938 (86.146) Acc@5 100.000 (99.513)
2025-08-27 21:55:28,021 - INFO - Pruning info: sparsity=0.667
2025-08-27 21:55:28,021 - INFO -   Reactivation rate: 0.0017
2025-08-27 21:55:29,623 - INFO - Epoch: [48][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.4852 (0.4131) Acc@1 82.031 (85.856) Acc@5 99.219 (99.460)
2025-08-27 21:55:30,942 - INFO - Pruning info: sparsity=0.667
2025-08-27 21:55:30,942 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:55:31,430 - INFO - Epoch: [48][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4218 (0.4239) Acc@1 88.281 (85.452) Acc@5 100.000 (99.450)
2025-08-27 21:55:33,231 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.6344 (0.6344) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 21:55:34,070 - INFO - Epoch 48:
2025-08-27 21:55:34,070 - INFO -   Train: acc1: 85.2560 | acc5: 99.4360 | loss: 0.4289 | sparsity: 0.6673 | reactivation_rate: 0.0015
2025-08-27 21:55:34,070 - INFO -   Val:   acc1: 77.3500 | acc5: 98.5200 | loss: 0.7282
2025-08-27 21:55:34,070 - INFO -   LR: 0.100000
2025-08-27 21:55:34,082 - INFO - 
Epoch: 49, lr = 0.1
2025-08-27 21:55:34,258 - INFO - Epoch: [49][0/391] Time 0.175 (0.175) Data 0.158 (0.158) Loss 0.5688 (0.5688) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:55:34,959 - INFO - Pruning info: sparsity=0.671
2025-08-27 21:55:34,959 - INFO -   Reactivation rate: 0.0024
2025-08-27 21:55:36,109 - INFO - Epoch: [49][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4268 (0.4164) Acc@1 84.375 (85.435) Acc@5 100.000 (99.513)
2025-08-27 21:55:37,986 - INFO - Epoch: [49][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3053 (0.4190) Acc@1 88.281 (85.444) Acc@5 99.219 (99.444)
2025-08-27 21:55:37,992 - INFO - Pruning info: sparsity=0.671
2025-08-27 21:55:37,992 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:55:39,830 - INFO - Epoch: [49][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3822 (0.4285) Acc@1 84.375 (85.115) Acc@5 100.000 (99.351)
2025-08-27 21:55:40,946 - INFO - Pruning info: sparsity=0.671
2025-08-27 21:55:40,946 - INFO -   Reactivation rate: 0.0011
2025-08-27 21:55:41,655 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5247 (0.5247) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 21:55:42,567 - INFO - Epoch 49:
2025-08-27 21:55:42,567 - INFO -   Train: acc1: 85.2760 | acc5: 99.3820 | loss: 0.4261 | sparsity: 0.6708 | reactivation_rate: 0.0015
2025-08-27 21:55:42,568 - INFO -   Val:   acc1: 81.6500 | acc5: 99.0400 | loss: 0.5480
2025-08-27 21:55:42,568 - INFO -   LR: 0.100000
2025-08-27 21:55:42,581 - INFO - 
Epoch: 50, lr = 0.1
2025-08-27 21:55:42,739 - INFO - Epoch: [50][0/391] Time 0.157 (0.157) Data 0.142 (0.142) Loss 0.2930 (0.2930) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:55:44,592 - INFO - Epoch: [50][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.5004 (0.4261) Acc@1 81.250 (85.226) Acc@5 99.219 (99.567)
2025-08-27 21:55:45,127 - INFO - Pruning info: sparsity=0.674
2025-08-27 21:55:45,127 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:55:46,369 - INFO - Epoch: [50][200/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.2791 (0.4257) Acc@1 89.844 (85.281) Acc@5 100.000 (99.499)
2025-08-27 21:55:47,968 - INFO - Pruning info: sparsity=0.674
2025-08-27 21:55:47,968 - INFO -   Reactivation rate: 0.0011
2025-08-27 21:55:48,165 - INFO - Epoch: [50][300/391] Time 0.013 (0.019) Data 0.002 (0.003) Loss 0.3555 (0.4254) Acc@1 86.719 (85.382) Acc@5 100.000 (99.460)
2025-08-27 21:55:50,000 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.4571 (0.4571) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 21:55:50,846 - INFO - Epoch 50:
2025-08-27 21:55:50,846 - INFO -   Train: acc1: 85.3520 | acc5: 99.4380 | loss: 0.4257 | sparsity: 0.6741 | reactivation_rate: 0.0014
2025-08-27 21:55:50,846 - INFO -   Val:   acc1: 82.8300 | acc5: 99.1900 | loss: 0.4994
2025-08-27 21:55:50,846 - INFO -   LR: 0.100000
2025-08-27 21:55:50,893 - INFO - Checkpoint saved: epoch=50, metric=82.8300
2025-08-27 21:55:50,926 - INFO - 
Epoch: 51, lr = 0.1
2025-08-27 21:55:51,121 - INFO - Epoch: [51][0/391] Time 0.195 (0.195) Data 0.173 (0.173) Loss 0.5002 (0.5002) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 21:55:52,142 - INFO - Pruning info: sparsity=0.677
2025-08-27 21:55:52,142 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:55:52,900 - INFO - Epoch: [51][100/391] Time 0.023 (0.020) Data 0.010 (0.004) Loss 0.4421 (0.4149) Acc@1 85.938 (85.651) Acc@5 99.219 (99.451)
2025-08-27 21:55:54,894 - INFO - Epoch: [51][200/391] Time 0.016 (0.020) Data 0.003 (0.003) Loss 0.5606 (0.4199) Acc@1 81.250 (85.498) Acc@5 99.219 (99.401)
2025-08-27 21:55:55,255 - INFO - Pruning info: sparsity=0.677
2025-08-27 21:55:55,255 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:55:56,731 - INFO - Epoch: [51][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3032 (0.4228) Acc@1 89.844 (85.509) Acc@5 100.000 (99.403)
2025-08-27 21:55:58,178 - INFO - Pruning info: sparsity=0.677
2025-08-27 21:55:58,184 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:55:58,527 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.6389 (0.6389) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 21:55:59,367 - INFO - Epoch 51:
2025-08-27 21:55:59,367 - INFO -   Train: acc1: 85.4120 | acc5: 99.3820 | loss: 0.4265 | sparsity: 0.6771 | reactivation_rate: 0.0014
2025-08-27 21:55:59,367 - INFO -   Val:   acc1: 78.9800 | acc5: 98.7500 | loss: 0.6464
2025-08-27 21:55:59,367 - INFO -   LR: 0.100000
2025-08-27 21:55:59,379 - INFO - 
Epoch: 52, lr = 0.1
2025-08-27 21:55:59,544 - INFO - Epoch: [52][0/391] Time 0.164 (0.164) Data 0.144 (0.144) Loss 0.4368 (0.4368) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:56:01,465 - INFO - Epoch: [52][100/391] Time 0.030 (0.021) Data 0.000 (0.003) Loss 0.4585 (0.4059) Acc@1 79.688 (86.061) Acc@5 100.000 (99.428)
2025-08-27 21:56:02,408 - INFO - Pruning info: sparsity=0.680
2025-08-27 21:56:02,408 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:56:03,359 - INFO - Epoch: [52][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4319 (0.4256) Acc@1 82.812 (85.354) Acc@5 100.000 (99.382)
2025-08-27 21:56:05,191 - INFO - Epoch: [52][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.3425 (0.4277) Acc@1 85.938 (85.203) Acc@5 100.000 (99.408)
2025-08-27 21:56:05,305 - INFO - Pruning info: sparsity=0.680
2025-08-27 21:56:05,305 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:56:06,908 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.6324 (0.6324) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:56:07,773 - INFO - Epoch 52:
2025-08-27 21:56:07,773 - INFO -   Train: acc1: 85.2020 | acc5: 99.4140 | loss: 0.4292 | sparsity: 0.6798 | reactivation_rate: 0.0013
2025-08-27 21:56:07,773 - INFO -   Val:   acc1: 79.5600 | acc5: 98.7000 | loss: 0.6685
2025-08-27 21:56:07,773 - INFO -   LR: 0.100000
2025-08-27 21:56:07,788 - INFO - 
Epoch: 53, lr = 0.1
2025-08-27 21:56:07,953 - INFO - Epoch: [53][0/391] Time 0.164 (0.164) Data 0.137 (0.137) Loss 0.4431 (0.4431) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:56:09,313 - INFO - Pruning info: sparsity=0.682
2025-08-27 21:56:09,313 - INFO -   Reactivation rate: 0.0017
2025-08-27 21:56:09,753 - INFO - Epoch: [53][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4587 (0.4227) Acc@1 82.031 (85.520) Acc@5 98.438 (99.474)
2025-08-27 21:56:11,568 - INFO - Epoch: [53][200/391] Time 0.026 (0.019) Data 0.001 (0.003) Loss 0.4351 (0.4305) Acc@1 85.938 (85.389) Acc@5 100.000 (99.452)
2025-08-27 21:56:12,213 - INFO - Pruning info: sparsity=0.682
2025-08-27 21:56:12,213 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:56:13,360 - INFO - Epoch: [53][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.3708 (0.4302) Acc@1 86.719 (85.180) Acc@5 99.219 (99.445)
2025-08-27 21:56:15,052 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.8652 (0.8652) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 21:56:15,860 - INFO - Epoch 53:
2025-08-27 21:56:15,860 - INFO -   Train: acc1: 85.1660 | acc5: 99.4420 | loss: 0.4318 | sparsity: 0.6823 | reactivation_rate: 0.0012
2025-08-27 21:56:15,860 - INFO -   Val:   acc1: 77.0300 | acc5: 98.8000 | loss: 0.7380
2025-08-27 21:56:15,860 - INFO -   LR: 0.100000
2025-08-27 21:56:15,872 - INFO - 
Epoch: 54, lr = 0.1
2025-08-27 21:56:16,046 - INFO - Epoch: [54][0/391] Time 0.173 (0.173) Data 0.155 (0.155) Loss 0.4292 (0.4292) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:56:16,147 - INFO - Pruning info: sparsity=0.685
2025-08-27 21:56:16,147 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:56:17,792 - INFO - Epoch: [54][100/391] Time 0.027 (0.019) Data 0.016 (0.004) Loss 0.2840 (0.4181) Acc@1 92.188 (85.551) Acc@5 99.219 (99.420)
2025-08-27 21:56:18,972 - INFO - Pruning info: sparsity=0.685
2025-08-27 21:56:18,972 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:56:19,576 - INFO - Epoch: [54][200/391] Time 0.011 (0.018) Data 0.000 (0.004) Loss 0.4174 (0.4226) Acc@1 82.031 (85.386) Acc@5 100.000 (99.433)
2025-08-27 21:56:21,351 - INFO - Epoch: [54][300/391] Time 0.031 (0.018) Data 0.019 (0.003) Loss 0.3998 (0.4199) Acc@1 85.156 (85.483) Acc@5 100.000 (99.439)
2025-08-27 21:56:21,806 - INFO - Pruning info: sparsity=0.685
2025-08-27 21:56:21,806 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:56:23,059 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.5840 (0.5840) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:56:23,896 - INFO - Epoch 54:
2025-08-27 21:56:23,897 - INFO -   Train: acc1: 85.3700 | acc5: 99.3880 | loss: 0.4247 | sparsity: 0.6846 | reactivation_rate: 0.0012
2025-08-27 21:56:23,897 - INFO -   Val:   acc1: 79.4400 | acc5: 98.8000 | loss: 0.6407
2025-08-27 21:56:23,897 - INFO -   LR: 0.100000
2025-08-27 21:56:23,907 - INFO - 
Epoch: 55, lr = 0.1
2025-08-27 21:56:24,087 - INFO - Epoch: [55][0/391] Time 0.179 (0.179) Data 0.162 (0.162) Loss 0.3615 (0.3615) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:56:25,723 - INFO - Pruning info: sparsity=0.687
2025-08-27 21:56:25,724 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:56:25,837 - INFO - Epoch: [55][100/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.4675 (0.4222) Acc@1 84.375 (85.388) Acc@5 100.000 (99.420)
2025-08-27 21:56:27,617 - INFO - Epoch: [55][200/391] Time 0.019 (0.018) Data 0.001 (0.003) Loss 0.4655 (0.4241) Acc@1 80.469 (85.242) Acc@5 100.000 (99.390)
2025-08-27 21:56:28,585 - INFO - Pruning info: sparsity=0.687
2025-08-27 21:56:28,586 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:56:29,395 - INFO - Epoch: [55][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.3929 (0.4251) Acc@1 85.938 (85.328) Acc@5 99.219 (99.421)
2025-08-27 21:56:31,085 - INFO - Test: [0/79] Time 0.111 (0.111) Loss 1.1220 (1.1220) Acc@1 67.969 (67.969) Acc@5 98.438 (98.438)
2025-08-27 21:56:31,905 - INFO - Epoch 55:
2025-08-27 21:56:31,905 - INFO -   Train: acc1: 85.2940 | acc5: 99.4140 | loss: 0.4263 | sparsity: 0.6867 | reactivation_rate: 0.0011
2025-08-27 21:56:31,905 - INFO -   Val:   acc1: 70.6000 | acc5: 98.8800 | loss: 1.0345
2025-08-27 21:56:31,905 - INFO -   LR: 0.100000
2025-08-27 21:56:31,917 - INFO - 
Epoch: 56, lr = 0.1
2025-08-27 21:56:32,094 - INFO - Epoch: [56][0/391] Time 0.176 (0.176) Data 0.154 (0.154) Loss 0.4098 (0.4098) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:56:32,556 - INFO - Pruning info: sparsity=0.689
2025-08-27 21:56:32,557 - INFO -   Reactivation rate: 0.0018
2025-08-27 21:56:33,882 - INFO - Epoch: [56][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.5035 (0.4127) Acc@1 81.250 (85.760) Acc@5 100.000 (99.451)
2025-08-27 21:56:35,389 - INFO - Pruning info: sparsity=0.689
2025-08-27 21:56:35,389 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:56:35,698 - INFO - Epoch: [56][200/391] Time 0.027 (0.019) Data 0.001 (0.003) Loss 0.4861 (0.4273) Acc@1 82.031 (85.296) Acc@5 99.219 (99.460)
2025-08-27 21:56:37,430 - INFO - Epoch: [56][300/391] Time 0.032 (0.018) Data 0.017 (0.003) Loss 0.3949 (0.4264) Acc@1 85.156 (85.398) Acc@5 99.219 (99.463)
2025-08-27 21:56:38,216 - INFO - Pruning info: sparsity=0.689
2025-08-27 21:56:38,217 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:56:39,165 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5456 (0.5456) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:56:39,988 - INFO - Epoch 56:
2025-08-27 21:56:39,988 - INFO -   Train: acc1: 85.3540 | acc5: 99.4440 | loss: 0.4278 | sparsity: 0.6886 | reactivation_rate: 0.0011
2025-08-27 21:56:39,988 - INFO -   Val:   acc1: 79.7900 | acc5: 98.9800 | loss: 0.6001
2025-08-27 21:56:39,988 - INFO -   LR: 0.100000
2025-08-27 21:56:40,001 - INFO - 
Epoch: 57, lr = 0.1
2025-08-27 21:56:40,148 - INFO - Epoch: [57][0/391] Time 0.146 (0.146) Data 0.120 (0.120) Loss 0.3690 (0.3690) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 21:56:41,936 - INFO - Epoch: [57][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3725 (0.4166) Acc@1 86.719 (85.899) Acc@5 99.219 (99.358)
2025-08-27 21:56:42,126 - INFO - Pruning info: sparsity=0.690
2025-08-27 21:56:42,127 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:56:43,780 - INFO - Epoch: [57][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.3768 (0.4306) Acc@1 88.281 (85.362) Acc@5 99.219 (99.366)
2025-08-27 21:56:45,016 - INFO - Pruning info: sparsity=0.690
2025-08-27 21:56:45,016 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:56:45,497 - INFO - Epoch: [57][300/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.3765 (0.4276) Acc@1 85.938 (85.481) Acc@5 99.219 (99.385)
2025-08-27 21:56:47,243 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5891 (0.5891) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 21:56:48,083 - INFO - Epoch 57:
2025-08-27 21:56:48,083 - INFO -   Train: acc1: 85.3260 | acc5: 99.3640 | loss: 0.4304 | sparsity: 0.6903 | reactivation_rate: 0.0010
2025-08-27 21:56:48,084 - INFO -   Val:   acc1: 79.1300 | acc5: 98.7300 | loss: 0.6694
2025-08-27 21:56:48,084 - INFO -   LR: 0.100000
2025-08-27 21:56:48,096 - INFO - 
Epoch: 58, lr = 0.1
2025-08-27 21:56:48,282 - INFO - Epoch: [58][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.4498 (0.4498) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:56:48,989 - INFO - Pruning info: sparsity=0.692
2025-08-27 21:56:48,989 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:56:50,065 - INFO - Epoch: [58][100/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.3089 (0.4239) Acc@1 89.844 (85.713) Acc@5 100.000 (99.420)
2025-08-27 21:56:51,838 - INFO - Epoch: [58][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4773 (0.4279) Acc@1 83.594 (85.424) Acc@5 98.438 (99.394)
2025-08-27 21:56:51,854 - INFO - Pruning info: sparsity=0.692
2025-08-27 21:56:51,854 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:56:53,589 - INFO - Epoch: [58][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4280 (0.4297) Acc@1 85.938 (85.216) Acc@5 100.000 (99.380)
2025-08-27 21:56:54,703 - INFO - Pruning info: sparsity=0.692
2025-08-27 21:56:54,703 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:56:55,334 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.5637 (0.5637) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:56:56,151 - INFO - Epoch 58:
2025-08-27 21:56:56,151 - INFO -   Train: acc1: 85.3800 | acc5: 99.4260 | loss: 0.4275 | sparsity: 0.6918 | reactivation_rate: 0.0010
2025-08-27 21:56:56,151 - INFO -   Val:   acc1: 81.0000 | acc5: 99.0200 | loss: 0.5659
2025-08-27 21:56:56,151 - INFO -   LR: 0.100000
2025-08-27 21:56:56,163 - INFO - 
Epoch: 59, lr = 0.1
2025-08-27 21:56:56,338 - INFO - Epoch: [59][0/391] Time 0.174 (0.174) Data 0.155 (0.155) Loss 0.4305 (0.4305) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 21:56:58,163 - INFO - Epoch: [59][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4468 (0.4067) Acc@1 82.812 (85.999) Acc@5 98.438 (99.451)
2025-08-27 21:56:58,706 - INFO - Pruning info: sparsity=0.693
2025-08-27 21:56:58,707 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:56:59,954 - INFO - Epoch: [59][200/391] Time 0.021 (0.019) Data 0.001 (0.003) Loss 0.4525 (0.4161) Acc@1 85.938 (85.735) Acc@5 97.656 (99.436)
2025-08-27 21:57:01,578 - INFO - Pruning info: sparsity=0.693
2025-08-27 21:57:01,578 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:57:01,795 - INFO - Epoch: [59][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4584 (0.4236) Acc@1 84.375 (85.437) Acc@5 100.000 (99.421)
2025-08-27 21:57:03,536 - INFO - Test: [0/79] Time 0.110 (0.110) Loss 0.4811 (0.4811) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 21:57:04,391 - INFO - Epoch 59:
2025-08-27 21:57:04,392 - INFO -   Train: acc1: 85.5200 | acc5: 99.4000 | loss: 0.4234 | sparsity: 0.6932 | reactivation_rate: 0.0009
2025-08-27 21:57:04,392 - INFO -   Val:   acc1: 82.1500 | acc5: 99.2500 | loss: 0.5235
2025-08-27 21:57:04,392 - INFO -   LR: 0.100000
2025-08-27 21:57:04,404 - INFO - 
Epoch: 60, lr = 0.1
2025-08-27 21:57:04,603 - INFO - Epoch: [60][0/391] Time 0.198 (0.198) Data 0.170 (0.170) Loss 0.4758 (0.4758) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:57:05,682 - INFO - Pruning info: sparsity=0.694
2025-08-27 21:57:05,683 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:57:06,443 - INFO - Epoch: [60][100/391] Time 0.015 (0.020) Data 0.003 (0.005) Loss 0.4616 (0.4197) Acc@1 81.250 (85.574) Acc@5 99.219 (99.474)
2025-08-27 21:57:08,230 - INFO - Epoch: [60][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.3145 (0.4280) Acc@1 85.938 (85.106) Acc@5 100.000 (99.421)
2025-08-27 21:57:08,571 - INFO - Pruning info: sparsity=0.694
2025-08-27 21:57:08,578 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:57:10,049 - INFO - Epoch: [60][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4029 (0.4230) Acc@1 85.938 (85.413) Acc@5 100.000 (99.403)
2025-08-27 21:57:11,515 - INFO - Pruning info: sparsity=0.694
2025-08-27 21:57:11,515 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:57:11,854 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.8975 (0.8975) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-27 21:57:12,728 - INFO - Epoch 60:
2025-08-27 21:57:12,728 - INFO -   Train: acc1: 85.3040 | acc5: 99.4420 | loss: 0.4254 | sparsity: 0.6944 | reactivation_rate: 0.0009
2025-08-27 21:57:12,728 - INFO -   Val:   acc1: 70.6800 | acc5: 96.1900 | loss: 1.0393
2025-08-27 21:57:12,728 - INFO -   LR: 0.100000
2025-08-27 21:57:12,775 - INFO - 
Epoch: 61, lr = 0.1
2025-08-27 21:57:12,965 - INFO - Epoch: [61][0/391] Time 0.189 (0.189) Data 0.156 (0.156) Loss 0.4343 (0.4343) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:57:14,886 - INFO - Epoch: [61][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.4004 (0.3891) Acc@1 86.719 (86.440) Acc@5 100.000 (99.536)
2025-08-27 21:57:15,724 - INFO - Pruning info: sparsity=0.695
2025-08-27 21:57:15,725 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:57:16,636 - INFO - Epoch: [61][200/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.4437 (0.4231) Acc@1 83.594 (85.316) Acc@5 100.000 (99.460)
2025-08-27 21:57:18,554 - INFO - Epoch: [61][300/391] Time 0.016 (0.019) Data 0.004 (0.002) Loss 0.4612 (0.4252) Acc@1 85.156 (85.377) Acc@5 99.219 (99.432)
2025-08-27 21:57:18,721 - INFO - Pruning info: sparsity=0.695
2025-08-27 21:57:18,721 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:57:20,370 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5523 (0.5523) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:57:21,179 - INFO - Epoch 61:
2025-08-27 21:57:21,179 - INFO -   Train: acc1: 85.2300 | acc5: 99.3860 | loss: 0.4308 | sparsity: 0.6954 | reactivation_rate: 0.0008
2025-08-27 21:57:21,179 - INFO -   Val:   acc1: 80.5600 | acc5: 99.0400 | loss: 0.5964
2025-08-27 21:57:21,179 - INFO -   LR: 0.100000
2025-08-27 21:57:21,208 - INFO - 
Epoch: 62, lr = 0.1
2025-08-27 21:57:21,390 - INFO - Epoch: [62][0/391] Time 0.180 (0.180) Data 0.158 (0.158) Loss 0.2912 (0.2912) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 21:57:22,786 - INFO - Pruning info: sparsity=0.696
2025-08-27 21:57:22,787 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:57:23,229 - INFO - Epoch: [62][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3636 (0.3985) Acc@1 87.500 (86.061) Acc@5 100.000 (99.505)
2025-08-27 21:57:25,018 - INFO - Epoch: [62][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.3886 (0.4073) Acc@1 85.156 (85.801) Acc@5 99.219 (99.514)
2025-08-27 21:57:25,780 - INFO - Pruning info: sparsity=0.696
2025-08-27 21:57:25,780 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:57:26,888 - INFO - Epoch: [62][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3330 (0.4155) Acc@1 86.719 (85.688) Acc@5 100.000 (99.429)
2025-08-27 21:57:28,659 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.6034 (0.6034) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 21:57:29,503 - INFO - Epoch 62:
2025-08-27 21:57:29,503 - INFO -   Train: acc1: 85.3920 | acc5: 99.3960 | loss: 0.4245 | sparsity: 0.6964 | reactivation_rate: 0.0007
2025-08-27 21:57:29,503 - INFO -   Val:   acc1: 79.7500 | acc5: 98.9300 | loss: 0.6255
2025-08-27 21:57:29,503 - INFO -   LR: 0.100000
2025-08-27 21:57:29,515 - INFO - 
Epoch: 63, lr = 0.1
2025-08-27 21:57:29,689 - INFO - Epoch: [63][0/391] Time 0.173 (0.173) Data 0.144 (0.144) Loss 0.4077 (0.4077) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 21:57:29,795 - INFO - Pruning info: sparsity=0.697
2025-08-27 21:57:29,795 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:57:31,622 - INFO - Epoch: [63][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3366 (0.4074) Acc@1 89.844 (85.945) Acc@5 100.000 (99.327)
2025-08-27 21:57:32,881 - INFO - Pruning info: sparsity=0.697
2025-08-27 21:57:32,882 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:57:33,515 - INFO - Epoch: [63][200/391] Time 0.014 (0.020) Data 0.004 (0.004) Loss 0.4497 (0.4146) Acc@1 84.375 (85.599) Acc@5 100.000 (99.417)
2025-08-27 21:57:35,322 - INFO - Epoch: [63][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3267 (0.4222) Acc@1 87.500 (85.346) Acc@5 99.219 (99.380)
2025-08-27 21:57:35,837 - INFO - Pruning info: sparsity=0.697
2025-08-27 21:57:35,837 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:57:37,074 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 1.2388 (1.2388) Acc@1 63.281 (63.281) Acc@5 99.219 (99.219)
2025-08-27 21:57:38,021 - INFO - Epoch 63:
2025-08-27 21:57:38,021 - INFO -   Train: acc1: 85.2780 | acc5: 99.4100 | loss: 0.4248 | sparsity: 0.6971 | reactivation_rate: 0.0006
2025-08-27 21:57:38,021 - INFO -   Val:   acc1: 65.2000 | acc5: 98.4000 | loss: 1.3605
2025-08-27 21:57:38,021 - INFO -   LR: 0.100000
2025-08-27 21:57:38,034 - INFO - 
Epoch: 64, lr = 0.1
2025-08-27 21:57:38,207 - INFO - Epoch: [64][0/391] Time 0.173 (0.173) Data 0.141 (0.141) Loss 0.3831 (0.3831) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:57:39,949 - INFO - Pruning info: sparsity=0.698
2025-08-27 21:57:39,949 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:57:40,018 - INFO - Epoch: [64][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4172 (0.4123) Acc@1 85.156 (86.100) Acc@5 100.000 (99.482)
2025-08-27 21:57:41,984 - INFO - Epoch: [64][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4247 (0.4207) Acc@1 87.500 (85.654) Acc@5 99.219 (99.398)
2025-08-27 21:57:43,032 - INFO - Pruning info: sparsity=0.698
2025-08-27 21:57:43,032 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:57:43,835 - INFO - Epoch: [64][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5105 (0.4211) Acc@1 81.250 (85.655) Acc@5 100.000 (99.419)
2025-08-27 21:57:45,642 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5846 (0.5846) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 21:57:46,537 - INFO - Epoch 64:
2025-08-27 21:57:46,538 - INFO -   Train: acc1: 85.5800 | acc5: 99.4140 | loss: 0.4229 | sparsity: 0.6978 | reactivation_rate: 0.0006
2025-08-27 21:57:46,538 - INFO -   Val:   acc1: 83.2100 | acc5: 98.8300 | loss: 0.5148
2025-08-27 21:57:46,538 - INFO -   LR: 0.100000
2025-08-27 21:57:46,586 - INFO - Checkpoint saved: epoch=64, metric=83.2100
2025-08-27 21:57:46,749 - INFO - 
Epoch: 65, lr = 0.1
2025-08-27 21:57:46,934 - INFO - Epoch: [65][0/391] Time 0.184 (0.184) Data 0.143 (0.143) Loss 0.3557 (0.3557) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:57:47,367 - INFO - Pruning info: sparsity=0.698
2025-08-27 21:57:47,367 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:57:48,848 - INFO - Epoch: [65][100/391] Time 0.027 (0.021) Data 0.009 (0.003) Loss 0.4124 (0.4229) Acc@1 83.594 (85.357) Acc@5 100.000 (99.489)
2025-08-27 21:57:50,487 - INFO - Pruning info: sparsity=0.698
2025-08-27 21:57:50,487 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:57:50,729 - INFO - Epoch: [65][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4146 (0.4257) Acc@1 87.500 (85.448) Acc@5 100.000 (99.401)
2025-08-27 21:57:52,666 - INFO - Epoch: [65][300/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4183 (0.4249) Acc@1 83.594 (85.359) Acc@5 99.219 (99.393)
2025-08-27 21:57:53,510 - INFO - Pruning info: sparsity=0.698
2025-08-27 21:57:53,510 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:57:54,502 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5479 (0.5479) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 21:57:55,347 - INFO - Epoch 65:
2025-08-27 21:57:55,347 - INFO -   Train: acc1: 85.2900 | acc5: 99.4200 | loss: 0.4296 | sparsity: 0.6983 | reactivation_rate: 0.0005
2025-08-27 21:57:55,347 - INFO -   Val:   acc1: 79.4500 | acc5: 98.9200 | loss: 0.6264
2025-08-27 21:57:55,347 - INFO -   LR: 0.100000
2025-08-27 21:57:55,361 - INFO - 
Epoch: 66, lr = 0.1
2025-08-27 21:57:55,548 - INFO - Epoch: [66][0/391] Time 0.186 (0.186) Data 0.163 (0.163) Loss 0.3912 (0.3912) Acc@1 85.938 (85.938) Acc@5 97.656 (97.656)
2025-08-27 21:57:57,322 - INFO - Epoch: [66][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2817 (0.3956) Acc@1 91.406 (86.440) Acc@5 100.000 (99.513)
2025-08-27 21:57:57,539 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:57:57,539 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:57:59,073 - INFO - Epoch: [66][200/391] Time 0.017 (0.018) Data 0.004 (0.003) Loss 0.5206 (0.4092) Acc@1 82.031 (85.953) Acc@5 99.219 (99.401)
2025-08-27 21:58:00,378 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:58:00,379 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:58:00,873 - INFO - Epoch: [66][300/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.5078 (0.4220) Acc@1 82.812 (85.499) Acc@5 98.438 (99.377)
2025-08-27 21:58:02,702 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.4826 (0.4826) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:58:03,534 - INFO - Epoch 66:
2025-08-27 21:58:03,534 - INFO -   Train: acc1: 85.5500 | acc5: 99.4100 | loss: 0.4210 | sparsity: 0.6988 | reactivation_rate: 0.0005
2025-08-27 21:58:03,535 - INFO -   Val:   acc1: 80.8100 | acc5: 99.1400 | loss: 0.5752
2025-08-27 21:58:03,535 - INFO -   LR: 0.100000
2025-08-27 21:58:03,547 - INFO - 
Epoch: 67, lr = 0.1
2025-08-27 21:58:03,747 - INFO - Epoch: [67][0/391] Time 0.199 (0.199) Data 0.179 (0.179) Loss 0.3741 (0.3741) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-27 21:58:04,453 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:58:04,453 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:58:05,577 - INFO - Epoch: [67][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.3497 (0.4127) Acc@1 89.844 (85.891) Acc@5 99.219 (99.451)
2025-08-27 21:58:07,487 - INFO - Epoch: [67][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4232 (0.4195) Acc@1 84.375 (85.619) Acc@5 100.000 (99.433)
2025-08-27 21:58:07,525 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:58:07,525 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:58:09,355 - INFO - Epoch: [67][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4033 (0.4138) Acc@1 86.719 (85.743) Acc@5 99.219 (99.447)
2025-08-27 21:58:10,588 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:58:10,588 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:11,246 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.4131 (0.4131) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:58:12,081 - INFO - Epoch 67:
2025-08-27 21:58:12,081 - INFO -   Train: acc1: 85.5140 | acc5: 99.4280 | loss: 0.4209 | sparsity: 0.6991 | reactivation_rate: 0.0004
2025-08-27 21:58:12,081 - INFO -   Val:   acc1: 81.8500 | acc5: 98.9700 | loss: 0.5722
2025-08-27 21:58:12,081 - INFO -   LR: 0.100000
2025-08-27 21:58:12,097 - INFO - 
Epoch: 68, lr = 0.1
2025-08-27 21:58:12,253 - INFO - Epoch: [68][0/391] Time 0.155 (0.155) Data 0.131 (0.131) Loss 0.3490 (0.3490) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 21:58:14,011 - INFO - Epoch: [68][100/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.5766 (0.4232) Acc@1 82.812 (85.837) Acc@5 99.219 (99.474)
2025-08-27 21:58:14,560 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:58:14,561 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:58:15,929 - INFO - Epoch: [68][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.3924 (0.4235) Acc@1 85.156 (85.549) Acc@5 100.000 (99.417)
2025-08-27 21:58:17,592 - INFO - Pruning info: sparsity=0.699
2025-08-27 21:58:17,593 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:17,745 - INFO - Epoch: [68][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4406 (0.4190) Acc@1 89.062 (85.647) Acc@5 98.438 (99.429)
2025-08-27 21:58:19,535 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5626 (0.5626) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 21:58:20,398 - INFO - Epoch 68:
2025-08-27 21:58:20,398 - INFO -   Train: acc1: 85.4420 | acc5: 99.4300 | loss: 0.4217 | sparsity: 0.6994 | reactivation_rate: 0.0004
2025-08-27 21:58:20,398 - INFO -   Val:   acc1: 80.4400 | acc5: 98.8200 | loss: 0.6141
2025-08-27 21:58:20,398 - INFO -   LR: 0.100000
2025-08-27 21:58:20,413 - INFO - 
Epoch: 69, lr = 0.1
2025-08-27 21:58:20,604 - INFO - Epoch: [69][0/391] Time 0.191 (0.191) Data 0.165 (0.165) Loss 0.4190 (0.4190) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 21:58:21,748 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:21,748 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:58:22,434 - INFO - Epoch: [69][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.4212 (0.4183) Acc@1 86.719 (85.396) Acc@5 99.219 (99.489)
2025-08-27 21:58:24,418 - INFO - Epoch: [69][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3992 (0.4222) Acc@1 85.938 (85.335) Acc@5 99.219 (99.382)
2025-08-27 21:58:24,767 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:24,772 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:26,342 - INFO - Epoch: [69][300/391] Time 0.019 (0.020) Data 0.002 (0.003) Loss 0.4114 (0.4262) Acc@1 84.375 (85.221) Acc@5 100.000 (99.419)
2025-08-27 21:58:27,809 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:27,813 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:28,106 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.8010 (0.8010) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-27 21:58:28,991 - INFO - Epoch 69:
2025-08-27 21:58:28,991 - INFO -   Train: acc1: 85.1520 | acc5: 99.4260 | loss: 0.4270 | sparsity: 0.6996 | reactivation_rate: 0.0004
2025-08-27 21:58:28,991 - INFO -   Val:   acc1: 76.1900 | acc5: 98.6300 | loss: 0.7738
2025-08-27 21:58:28,991 - INFO -   LR: 0.100000
2025-08-27 21:58:29,004 - INFO - 
Epoch: 70, lr = 0.1
2025-08-27 21:58:29,184 - INFO - Epoch: [70][0/391] Time 0.179 (0.179) Data 0.151 (0.151) Loss 0.4724 (0.4724) Acc@1 87.500 (87.500) Acc@5 97.656 (97.656)
2025-08-27 21:58:30,965 - INFO - Epoch: [70][100/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.4225 (0.4105) Acc@1 85.938 (86.007) Acc@5 100.000 (99.435)
2025-08-27 21:58:31,804 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:31,804 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:58:32,717 - INFO - Epoch: [70][200/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.3968 (0.4277) Acc@1 83.594 (85.397) Acc@5 99.219 (99.390)
2025-08-27 21:58:34,540 - INFO - Epoch: [70][300/391] Time 0.018 (0.018) Data 0.000 (0.003) Loss 0.2306 (0.4263) Acc@1 92.188 (85.398) Acc@5 100.000 (99.377)
2025-08-27 21:58:34,749 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:34,750 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:36,386 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.7431 (0.7431) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 21:58:37,252 - INFO - Epoch 70:
2025-08-27 21:58:37,252 - INFO -   Train: acc1: 85.5260 | acc5: 99.4180 | loss: 0.4225 | sparsity: 0.6998 | reactivation_rate: 0.0003
2025-08-27 21:58:37,252 - INFO -   Val:   acc1: 76.4100 | acc5: 98.1200 | loss: 0.7800
2025-08-27 21:58:37,252 - INFO -   LR: 0.100000
2025-08-27 21:58:37,298 - INFO - 
Epoch: 71, lr = 0.1
2025-08-27 21:58:37,491 - INFO - Epoch: [71][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.2759 (0.2759) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:58:38,939 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:38,939 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:39,345 - INFO - Epoch: [71][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4029 (0.4163) Acc@1 87.500 (85.628) Acc@5 98.438 (99.451)
2025-08-27 21:58:41,131 - INFO - Epoch: [71][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3632 (0.4173) Acc@1 89.844 (85.331) Acc@5 99.219 (99.448)
2025-08-27 21:58:41,865 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:41,865 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:58:42,966 - INFO - Epoch: [71][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3437 (0.4203) Acc@1 88.281 (85.416) Acc@5 100.000 (99.458)
2025-08-27 21:58:44,779 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.4573 (0.4573) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 21:58:45,617 - INFO - Epoch 71:
2025-08-27 21:58:45,618 - INFO -   Train: acc1: 85.2080 | acc5: 99.3980 | loss: 0.4262 | sparsity: 0.6999 | reactivation_rate: 0.0003
2025-08-27 21:58:45,618 - INFO -   Val:   acc1: 82.4100 | acc5: 99.2600 | loss: 0.5157
2025-08-27 21:58:45,618 - INFO -   LR: 0.100000
2025-08-27 21:58:45,630 - INFO - 
Epoch: 72, lr = 0.1
2025-08-27 21:58:45,802 - INFO - Epoch: [72][0/391] Time 0.171 (0.171) Data 0.140 (0.140) Loss 0.4858 (0.4858) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:58:45,932 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:45,933 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:58:47,680 - INFO - Epoch: [72][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.3615 (0.4085) Acc@1 89.062 (86.092) Acc@5 99.219 (99.466)
2025-08-27 21:58:48,945 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:48,951 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:58:49,499 - INFO - Epoch: [72][200/391] Time 0.026 (0.019) Data 0.007 (0.003) Loss 0.5880 (0.4210) Acc@1 82.031 (85.533) Acc@5 100.000 (99.401)
2025-08-27 21:58:51,297 - INFO - Epoch: [72][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.5706 (0.4233) Acc@1 85.156 (85.533) Acc@5 99.219 (99.364)
2025-08-27 21:58:51,789 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:51,790 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:58:53,019 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.3755 (0.3755) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:58:53,859 - INFO - Epoch 72:
2025-08-27 21:58:53,859 - INFO -   Train: acc1: 85.5300 | acc5: 99.3580 | loss: 0.4229 | sparsity: 0.7000 | reactivation_rate: 0.0002
2025-08-27 21:58:53,859 - INFO -   Val:   acc1: 83.2300 | acc5: 99.3500 | loss: 0.4897
2025-08-27 21:58:53,859 - INFO -   LR: 0.100000
2025-08-27 21:58:53,907 - INFO - Checkpoint saved: epoch=72, metric=83.2300
2025-08-27 21:58:53,939 - INFO - 
Epoch: 73, lr = 0.1
2025-08-27 21:58:54,132 - INFO - Epoch: [73][0/391] Time 0.192 (0.192) Data 0.166 (0.166) Loss 0.3468 (0.3468) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 21:58:55,862 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:55,862 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:58:55,941 - INFO - Epoch: [73][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2570 (0.4132) Acc@1 90.625 (85.512) Acc@5 100.000 (99.304)
2025-08-27 21:58:57,784 - INFO - Epoch: [73][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4550 (0.4214) Acc@1 84.375 (85.378) Acc@5 100.000 (99.359)
2025-08-27 21:58:58,813 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:58:58,813 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:58:59,625 - INFO - Epoch: [73][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.3144 (0.4253) Acc@1 91.406 (85.255) Acc@5 99.219 (99.354)
2025-08-27 21:59:01,399 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.9227 (0.9227) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 21:59:02,271 - INFO - Epoch 73:
2025-08-27 21:59:02,272 - INFO -   Train: acc1: 85.3520 | acc5: 99.3620 | loss: 0.4246 | sparsity: 0.7000 | reactivation_rate: 0.0002
2025-08-27 21:59:02,272 - INFO -   Val:   acc1: 74.5600 | acc5: 98.2500 | loss: 0.8813
2025-08-27 21:59:02,272 - INFO -   LR: 0.100000
2025-08-27 21:59:02,286 - INFO - 
Epoch: 74, lr = 0.1
2025-08-27 21:59:02,445 - INFO - Epoch: [74][0/391] Time 0.158 (0.158) Data 0.136 (0.136) Loss 0.5218 (0.5218) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:59:02,905 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:02,905 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:59:04,298 - INFO - Epoch: [74][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3562 (0.4287) Acc@1 87.500 (85.326) Acc@5 100.000 (99.358)
2025-08-27 21:59:05,866 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:05,871 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:06,097 - INFO - Epoch: [74][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4727 (0.4270) Acc@1 82.812 (85.269) Acc@5 100.000 (99.366)
2025-08-27 21:59:07,949 - INFO - Epoch: [74][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3009 (0.4258) Acc@1 89.062 (85.299) Acc@5 100.000 (99.437)
2025-08-27 21:59:08,753 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:08,754 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:59:09,667 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5942 (0.5942) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-27 21:59:10,522 - INFO - Epoch 74:
2025-08-27 21:59:10,522 - INFO -   Train: acc1: 85.1900 | acc5: 99.4400 | loss: 0.4274 | sparsity: 0.7000 | reactivation_rate: 0.0002
2025-08-27 21:59:10,522 - INFO -   Val:   acc1: 80.3000 | acc5: 99.1200 | loss: 0.5851
2025-08-27 21:59:10,522 - INFO -   LR: 0.100000
2025-08-27 21:59:10,534 - INFO - 
Epoch: 75, lr = 0.1
2025-08-27 21:59:10,719 - INFO - Epoch: [75][0/391] Time 0.184 (0.184) Data 0.158 (0.158) Loss 0.3324 (0.3324) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:59:12,493 - INFO - Epoch: [75][100/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4750 (0.4073) Acc@1 84.375 (85.574) Acc@5 99.219 (99.590)
2025-08-27 21:59:12,749 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:12,750 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:14,325 - INFO - Epoch: [75][200/391] Time 0.033 (0.019) Data 0.021 (0.004) Loss 0.2530 (0.4138) Acc@1 92.188 (85.428) Acc@5 99.219 (99.475)
2025-08-27 21:59:15,793 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:15,793 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:16,198 - INFO - Epoch: [75][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5348 (0.4170) Acc@1 83.594 (85.450) Acc@5 96.094 (99.434)
2025-08-27 21:59:18,052 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.7544 (0.7544) Acc@1 75.781 (75.781) Acc@5 96.094 (96.094)
2025-08-27 21:59:18,879 - INFO - Epoch 75:
2025-08-27 21:59:18,879 - INFO -   Train: acc1: 85.4060 | acc5: 99.4300 | loss: 0.4189 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 21:59:18,879 - INFO -   Val:   acc1: 77.3600 | acc5: 97.7900 | loss: 0.7231
2025-08-27 21:59:18,880 - INFO -   LR: 0.100000
2025-08-27 21:59:18,893 - INFO - 
Epoch: 76, lr = 0.1
2025-08-27 21:59:19,066 - INFO - Epoch: [76][0/391] Time 0.172 (0.172) Data 0.133 (0.133) Loss 0.4935 (0.4935) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:59:19,884 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:19,884 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:20,897 - INFO - Epoch: [76][100/391] Time 0.033 (0.020) Data 0.017 (0.004) Loss 0.4513 (0.4149) Acc@1 83.594 (85.976) Acc@5 100.000 (99.428)
2025-08-27 21:59:22,777 - INFO - Epoch: [76][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4601 (0.4168) Acc@1 85.938 (85.658) Acc@5 98.438 (99.448)
2025-08-27 21:59:22,843 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:22,843 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:24,574 - INFO - Epoch: [76][300/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.3681 (0.4191) Acc@1 88.281 (85.579) Acc@5 99.219 (99.424)
2025-08-27 21:59:25,807 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:25,807 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:26,421 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5125 (0.5125) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:59:27,279 - INFO - Epoch 76:
2025-08-27 21:59:27,279 - INFO -   Train: acc1: 85.5380 | acc5: 99.4200 | loss: 0.4202 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 21:59:27,279 - INFO -   Val:   acc1: 81.1100 | acc5: 98.9400 | loss: 0.5718
2025-08-27 21:59:27,279 - INFO -   LR: 0.100000
2025-08-27 21:59:27,292 - INFO - 
Epoch: 77, lr = 0.1
2025-08-27 21:59:27,491 - INFO - Epoch: [77][0/391] Time 0.198 (0.198) Data 0.174 (0.174) Loss 0.3143 (0.3143) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:59:29,316 - INFO - Epoch: [77][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.4127 (0.4243) Acc@1 83.594 (85.241) Acc@5 99.219 (99.466)
2025-08-27 21:59:29,904 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:29,907 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:31,155 - INFO - Epoch: [77][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3919 (0.4311) Acc@1 87.500 (84.861) Acc@5 99.219 (99.444)
2025-08-27 21:59:32,827 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:32,827 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:33,003 - INFO - Epoch: [77][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4127 (0.4240) Acc@1 89.062 (85.250) Acc@5 99.219 (99.452)
2025-08-27 21:59:34,767 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6733 (0.6733) Acc@1 75.781 (75.781) Acc@5 96.875 (96.875)
2025-08-27 21:59:35,586 - INFO - Epoch 77:
2025-08-27 21:59:35,586 - INFO -   Train: acc1: 85.2940 | acc5: 99.4280 | loss: 0.4254 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 21:59:35,586 - INFO -   Val:   acc1: 80.2600 | acc5: 98.8300 | loss: 0.6135
2025-08-27 21:59:35,586 - INFO -   LR: 0.100000
2025-08-27 21:59:35,600 - INFO - 
Epoch: 78, lr = 0.1
2025-08-27 21:59:35,752 - INFO - Epoch: [78][0/391] Time 0.151 (0.151) Data 0.133 (0.133) Loss 0.4716 (0.4716) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:59:36,972 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:36,972 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:37,615 - INFO - Epoch: [78][100/391] Time 0.017 (0.020) Data 0.005 (0.003) Loss 0.3853 (0.4044) Acc@1 85.938 (86.092) Acc@5 98.438 (99.474)
2025-08-27 21:59:39,454 - INFO - Epoch: [78][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.4586 (0.4223) Acc@1 83.594 (85.580) Acc@5 100.000 (99.444)
2025-08-27 21:59:39,835 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:39,835 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:41,300 - INFO - Epoch: [78][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4689 (0.4260) Acc@1 83.594 (85.338) Acc@5 100.000 (99.447)
2025-08-27 21:59:42,844 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:42,847 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:43,139 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.6369 (0.6369) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 21:59:44,036 - INFO - Epoch 78:
2025-08-27 21:59:44,036 - INFO -   Train: acc1: 85.2300 | acc5: 99.4160 | loss: 0.4280 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 21:59:44,036 - INFO -   Val:   acc1: 76.4700 | acc5: 98.3200 | loss: 0.7893
2025-08-27 21:59:44,036 - INFO -   LR: 0.100000
2025-08-27 21:59:44,051 - INFO - 
Epoch: 79, lr = 0.1
2025-08-27 21:59:44,237 - INFO - Epoch: [79][0/391] Time 0.186 (0.186) Data 0.169 (0.169) Loss 0.4575 (0.4575) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-27 21:59:46,075 - INFO - Epoch: [79][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.5324 (0.4290) Acc@1 84.375 (85.442) Acc@5 97.656 (99.428)
2025-08-27 21:59:46,985 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:46,985 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:47,953 - INFO - Epoch: [79][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4115 (0.4279) Acc@1 84.375 (85.238) Acc@5 100.000 (99.464)
2025-08-27 21:59:49,711 - INFO - Epoch: [79][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4944 (0.4288) Acc@1 84.375 (85.307) Acc@5 99.219 (99.455)
2025-08-27 21:59:49,898 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:49,912 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:51,469 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.3622 (0.3622) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 21:59:52,334 - INFO - Epoch 79:
2025-08-27 21:59:52,334 - INFO -   Train: acc1: 85.1220 | acc5: 99.4500 | loss: 0.4333 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 21:59:52,334 - INFO -   Val:   acc1: 84.0400 | acc5: 99.2800 | loss: 0.4754
2025-08-27 21:59:52,335 - INFO -   LR: 0.100000
2025-08-27 21:59:52,385 - INFO - Checkpoint saved: epoch=79, metric=84.0400
2025-08-27 21:59:52,416 - INFO - 
Epoch: 80, lr = 0.1
2025-08-27 21:59:52,629 - INFO - Epoch: [80][0/391] Time 0.212 (0.212) Data 0.175 (0.175) Loss 0.3121 (0.3121) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:59:54,070 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:54,070 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:54,420 - INFO - Epoch: [80][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.4824 (0.4065) Acc@1 83.594 (85.976) Acc@5 99.219 (99.435)
2025-08-27 21:59:56,301 - INFO - Epoch: [80][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3563 (0.4188) Acc@1 89.844 (85.634) Acc@5 99.219 (99.394)
2025-08-27 21:59:56,983 - INFO - Pruning info: sparsity=0.700
2025-08-27 21:59:56,984 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:59:58,060 - INFO - Epoch: [80][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.4959 (0.4201) Acc@1 82.812 (85.647) Acc@5 98.438 (99.395)
2025-08-27 21:59:59,911 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.4572 (0.4572) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:00:00,803 - INFO - Epoch 80:
2025-08-27 22:00:00,803 - INFO -   Train: acc1: 85.5300 | acc5: 99.3820 | loss: 0.4228 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 22:00:00,803 - INFO -   Val:   acc1: 80.3800 | acc5: 98.9900 | loss: 0.5723
2025-08-27 22:00:00,803 - INFO -   LR: 0.100000
2025-08-27 22:00:00,851 - INFO - 
Epoch: 81, lr = 0.1
2025-08-27 22:00:01,027 - INFO - Epoch: [81][0/391] Time 0.176 (0.176) Data 0.153 (0.153) Loss 0.4012 (0.4012) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:00:01,206 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:01,207 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:02,838 - INFO - Epoch: [81][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4047 (0.4089) Acc@1 85.938 (86.015) Acc@5 99.219 (99.304)
2025-08-27 22:00:04,165 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:04,165 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:04,704 - INFO - Epoch: [81][200/391] Time 0.013 (0.019) Data 0.001 (0.004) Loss 0.3954 (0.4227) Acc@1 85.156 (85.514) Acc@5 100.000 (99.289)
2025-08-27 22:00:06,560 - INFO - Epoch: [81][300/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.4743 (0.4228) Acc@1 82.812 (85.478) Acc@5 99.219 (99.320)
2025-08-27 22:00:07,124 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:07,124 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:08,417 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6791 (0.6791) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:00:09,232 - INFO - Epoch 81:
2025-08-27 22:00:09,232 - INFO -   Train: acc1: 85.4120 | acc5: 99.3480 | loss: 0.4244 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 22:00:09,232 - INFO -   Val:   acc1: 78.9100 | acc5: 98.5400 | loss: 0.6328
2025-08-27 22:00:09,232 - INFO -   LR: 0.100000
2025-08-27 22:00:09,246 - INFO - 
Epoch: 82, lr = 0.1
2025-08-27 22:00:09,434 - INFO - Epoch: [82][0/391] Time 0.187 (0.187) Data 0.166 (0.166) Loss 0.5057 (0.5057) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 22:00:11,190 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:11,196 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:11,239 - INFO - Epoch: [82][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.3907 (0.4185) Acc@1 85.156 (85.566) Acc@5 99.219 (99.343)
2025-08-27 22:00:13,022 - INFO - Epoch: [82][200/391] Time 0.023 (0.019) Data 0.011 (0.003) Loss 0.4374 (0.4255) Acc@1 84.375 (85.351) Acc@5 100.000 (99.339)
2025-08-27 22:00:14,059 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:14,059 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:14,829 - INFO - Epoch: [82][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4179 (0.4230) Acc@1 86.719 (85.499) Acc@5 99.219 (99.315)
2025-08-27 22:00:16,769 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5275 (0.5275) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:00:17,647 - INFO - Epoch 82:
2025-08-27 22:00:17,647 - INFO -   Train: acc1: 85.4740 | acc5: 99.3700 | loss: 0.4216 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 22:00:17,647 - INFO -   Val:   acc1: 78.6200 | acc5: 98.8100 | loss: 0.6326
2025-08-27 22:00:17,647 - INFO -   LR: 0.100000
2025-08-27 22:00:17,660 - INFO - 
Epoch: 83, lr = 0.1
2025-08-27 22:00:17,800 - INFO - Epoch: [83][0/391] Time 0.139 (0.139) Data 0.110 (0.110) Loss 0.4952 (0.4952) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:00:18,365 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:18,365 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:19,676 - INFO - Epoch: [83][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4857 (0.4167) Acc@1 83.594 (85.644) Acc@5 100.000 (99.373)
2025-08-27 22:00:21,287 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:21,288 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:21,526 - INFO - Epoch: [83][200/391] Time 0.031 (0.019) Data 0.020 (0.003) Loss 0.3764 (0.4174) Acc@1 89.062 (85.564) Acc@5 99.219 (99.429)
2025-08-27 22:00:23,354 - INFO - Epoch: [83][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5623 (0.4203) Acc@1 80.469 (85.385) Acc@5 97.656 (99.411)
2025-08-27 22:00:24,185 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:24,185 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:25,105 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.6225 (0.6225) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 22:00:25,938 - INFO - Epoch 83:
2025-08-27 22:00:25,938 - INFO -   Train: acc1: 85.3220 | acc5: 99.4100 | loss: 0.4249 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 22:00:25,938 - INFO -   Val:   acc1: 77.7600 | acc5: 98.5500 | loss: 0.6666
2025-08-27 22:00:25,938 - INFO -   LR: 0.100000
2025-08-27 22:00:25,951 - INFO - 
Epoch: 84, lr = 0.1
2025-08-27 22:00:26,121 - INFO - Epoch: [84][0/391] Time 0.169 (0.169) Data 0.151 (0.151) Loss 0.3677 (0.3677) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:00:27,966 - INFO - Epoch: [84][100/391] Time 0.030 (0.020) Data 0.000 (0.004) Loss 0.4420 (0.4186) Acc@1 85.938 (85.512) Acc@5 99.219 (99.497)
2025-08-27 22:00:28,225 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:28,225 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:29,745 - INFO - Epoch: [84][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.5186 (0.4209) Acc@1 81.250 (85.366) Acc@5 98.438 (99.444)
2025-08-27 22:00:31,125 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:31,125 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:00:31,563 - INFO - Epoch: [84][300/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.4263 (0.4220) Acc@1 88.281 (85.395) Acc@5 100.000 (99.445)
2025-08-27 22:00:33,273 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.6307 (0.6307) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 22:00:34,108 - INFO - Epoch 84:
2025-08-27 22:00:34,109 - INFO -   Train: acc1: 85.3000 | acc5: 99.4200 | loss: 0.4257 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-27 22:00:34,109 - INFO -   Val:   acc1: 77.0500 | acc5: 98.9400 | loss: 0.6941
2025-08-27 22:00:34,109 - INFO -   LR: 0.100000
2025-08-27 22:00:34,123 - INFO - 
Epoch: 85, lr = 0.1
2025-08-27 22:00:34,301 - INFO - Epoch: [85][0/391] Time 0.176 (0.176) Data 0.156 (0.156) Loss 0.5675 (0.5675) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 22:00:35,124 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:35,125 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:36,088 - INFO - Epoch: [85][100/391] Time 0.019 (0.019) Data 0.007 (0.004) Loss 0.4683 (0.4085) Acc@1 82.031 (85.852) Acc@5 99.219 (99.489)
2025-08-27 22:00:37,892 - INFO - Epoch: [85][200/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.4002 (0.4148) Acc@1 88.281 (85.658) Acc@5 99.219 (99.464)
2025-08-27 22:00:37,950 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:37,950 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:39,637 - INFO - Epoch: [85][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.4268 (0.4153) Acc@1 86.719 (85.694) Acc@5 100.000 (99.421)
2025-08-27 22:00:40,734 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:40,734 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:41,334 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.4665 (0.4665) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:00:42,175 - INFO - Epoch 85:
2025-08-27 22:00:42,176 - INFO -   Train: acc1: 85.6100 | acc5: 99.4340 | loss: 0.4183 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:00:42,176 - INFO -   Val:   acc1: 80.3900 | acc5: 99.2000 | loss: 0.5599
2025-08-27 22:00:42,176 - INFO -   LR: 0.100000
2025-08-27 22:00:42,190 - INFO - 
Epoch: 86, lr = 0.1
2025-08-27 22:00:42,380 - INFO - Epoch: [86][0/391] Time 0.189 (0.189) Data 0.165 (0.165) Loss 0.2314 (0.2314) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:00:44,224 - INFO - Epoch: [86][100/391] Time 0.031 (0.020) Data 0.003 (0.004) Loss 0.3992 (0.4198) Acc@1 86.719 (85.613) Acc@5 100.000 (99.428)
2025-08-27 22:00:44,808 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:44,808 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:45,997 - INFO - Epoch: [86][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.3738 (0.4262) Acc@1 85.156 (85.401) Acc@5 98.438 (99.440)
2025-08-27 22:00:47,641 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:47,642 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:47,783 - INFO - Epoch: [86][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4601 (0.4260) Acc@1 87.500 (85.268) Acc@5 99.219 (99.460)
2025-08-27 22:00:49,480 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6963 (0.6963) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:00:50,280 - INFO - Epoch 86:
2025-08-27 22:00:50,280 - INFO -   Train: acc1: 85.3820 | acc5: 99.4640 | loss: 0.4246 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:00:50,280 - INFO -   Val:   acc1: 77.3700 | acc5: 99.1200 | loss: 0.7460
2025-08-27 22:00:50,280 - INFO -   LR: 0.100000
2025-08-27 22:00:50,295 - INFO - 
Epoch: 87, lr = 0.1
2025-08-27 22:00:50,451 - INFO - Epoch: [87][0/391] Time 0.155 (0.155) Data 0.126 (0.126) Loss 0.4132 (0.4132) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:00:51,619 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:51,619 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:52,254 - INFO - Epoch: [87][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2834 (0.4283) Acc@1 92.188 (85.404) Acc@5 100.000 (99.358)
2025-08-27 22:00:54,023 - INFO - Epoch: [87][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.2970 (0.4260) Acc@1 91.406 (85.428) Acc@5 99.219 (99.436)
2025-08-27 22:00:54,445 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:54,445 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:55,795 - INFO - Epoch: [87][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4672 (0.4212) Acc@1 82.031 (85.564) Acc@5 97.656 (99.406)
2025-08-27 22:00:57,254 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:00:57,254 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:00:57,530 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6199 (0.6199) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:00:58,347 - INFO - Epoch 87:
2025-08-27 22:00:58,347 - INFO -   Train: acc1: 85.4840 | acc5: 99.4320 | loss: 0.4225 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:00:58,347 - INFO -   Val:   acc1: 79.8200 | acc5: 98.9100 | loss: 0.6057
2025-08-27 22:00:58,347 - INFO -   LR: 0.100000
2025-08-27 22:00:58,360 - INFO - 
Epoch: 88, lr = 0.1
2025-08-27 22:00:58,500 - INFO - Epoch: [88][0/391] Time 0.139 (0.139) Data 0.123 (0.123) Loss 0.5143 (0.5143) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 22:01:00,275 - INFO - Epoch: [88][100/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4670 (0.4203) Acc@1 81.250 (85.334) Acc@5 100.000 (99.474)
2025-08-27 22:01:01,229 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:01,229 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:02,072 - INFO - Epoch: [88][200/391] Time 0.017 (0.018) Data 0.000 (0.003) Loss 0.3968 (0.4167) Acc@1 87.500 (85.498) Acc@5 100.000 (99.471)
2025-08-27 22:01:03,964 - INFO - Epoch: [88][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5524 (0.4190) Acc@1 78.906 (85.429) Acc@5 99.219 (99.463)
2025-08-27 22:01:04,143 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:04,143 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:05,714 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4596 (0.4596) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:01:06,533 - INFO - Epoch 88:
2025-08-27 22:01:06,533 - INFO -   Train: acc1: 85.4340 | acc5: 99.4600 | loss: 0.4208 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:06,533 - INFO -   Val:   acc1: 82.5100 | acc5: 99.1000 | loss: 0.5251
2025-08-27 22:01:06,533 - INFO -   LR: 0.100000
2025-08-27 22:01:06,548 - INFO - 
Epoch: 89, lr = 0.1
2025-08-27 22:01:06,712 - INFO - Epoch: [89][0/391] Time 0.163 (0.163) Data 0.145 (0.145) Loss 0.4462 (0.4462) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:01:08,188 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:08,188 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:08,541 - INFO - Epoch: [89][100/391] Time 0.014 (0.020) Data 0.001 (0.005) Loss 0.5083 (0.4055) Acc@1 82.812 (85.914) Acc@5 99.219 (99.428)
2025-08-27 22:01:10,366 - INFO - Epoch: [89][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.4326 (0.4160) Acc@1 85.938 (85.611) Acc@5 98.438 (99.421)
2025-08-27 22:01:11,096 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:11,096 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:12,235 - INFO - Epoch: [89][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.5945 (0.4245) Acc@1 76.562 (85.343) Acc@5 98.438 (99.408)
2025-08-27 22:01:13,980 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.8411 (0.8411) Acc@1 74.219 (74.219) Acc@5 96.875 (96.875)
2025-08-27 22:01:14,821 - INFO - Epoch 89:
2025-08-27 22:01:14,821 - INFO -   Train: acc1: 85.2920 | acc5: 99.4180 | loss: 0.4257 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:14,821 - INFO -   Val:   acc1: 73.0600 | acc5: 98.2400 | loss: 0.9049
2025-08-27 22:01:14,821 - INFO -   LR: 0.100000
2025-08-27 22:01:14,836 - INFO - 
Epoch: 90, lr = 0.1
2025-08-27 22:01:15,014 - INFO - Epoch: [90][0/391] Time 0.177 (0.177) Data 0.150 (0.150) Loss 0.4802 (0.4802) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:01:15,202 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:15,202 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:16,822 - INFO - Epoch: [90][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.5751 (0.4105) Acc@1 79.688 (85.953) Acc@5 98.438 (99.397)
2025-08-27 22:01:18,133 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:18,133 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:18,687 - INFO - Epoch: [90][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4864 (0.4234) Acc@1 83.594 (85.529) Acc@5 99.219 (99.398)
2025-08-27 22:01:20,418 - INFO - Epoch: [90][300/391] Time 0.016 (0.019) Data 0.006 (0.003) Loss 0.4422 (0.4217) Acc@1 85.938 (85.527) Acc@5 98.438 (99.395)
2025-08-27 22:01:20,986 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:20,986 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:22,183 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.7308 (0.7308) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:01:23,041 - INFO - Epoch 90:
2025-08-27 22:01:23,041 - INFO -   Train: acc1: 85.4240 | acc5: 99.3940 | loss: 0.4244 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:23,041 - INFO -   Val:   acc1: 75.2700 | acc5: 96.8500 | loss: 0.8189
2025-08-27 22:01:23,041 - INFO -   LR: 0.100000
2025-08-27 22:01:23,088 - INFO - 
Epoch: 91, lr = 0.1
2025-08-27 22:01:23,265 - INFO - Epoch: [91][0/391] Time 0.175 (0.175) Data 0.152 (0.152) Loss 0.5035 (0.5035) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:01:24,968 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:24,969 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:25,003 - INFO - Epoch: [91][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.4827 (0.3936) Acc@1 83.594 (86.239) Acc@5 100.000 (99.551)
2025-08-27 22:01:26,754 - INFO - Epoch: [91][200/391] Time 0.025 (0.018) Data 0.014 (0.003) Loss 0.4708 (0.4157) Acc@1 83.594 (85.685) Acc@5 100.000 (99.436)
2025-08-27 22:01:27,785 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:27,786 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:28,547 - INFO - Epoch: [91][300/391] Time 0.026 (0.018) Data 0.000 (0.002) Loss 0.4148 (0.4219) Acc@1 84.375 (85.522) Acc@5 100.000 (99.400)
2025-08-27 22:01:30,275 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.7701 (0.7701) Acc@1 77.344 (77.344) Acc@5 96.875 (96.875)
2025-08-27 22:01:31,105 - INFO - Epoch 91:
2025-08-27 22:01:31,105 - INFO -   Train: acc1: 85.4540 | acc5: 99.4000 | loss: 0.4258 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:31,105 - INFO -   Val:   acc1: 73.3400 | acc5: 97.6100 | loss: 0.8878
2025-08-27 22:01:31,105 - INFO -   LR: 0.100000
2025-08-27 22:01:31,118 - INFO - 
Epoch: 92, lr = 0.1
2025-08-27 22:01:31,271 - INFO - Epoch: [92][0/391] Time 0.152 (0.152) Data 0.135 (0.135) Loss 0.4489 (0.4489) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:01:31,741 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:31,741 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:33,053 - INFO - Epoch: [92][100/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.5906 (0.4159) Acc@1 82.031 (85.837) Acc@5 100.000 (99.327)
2025-08-27 22:01:34,567 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:34,568 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:34,747 - INFO - Epoch: [92][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3115 (0.4153) Acc@1 86.719 (85.650) Acc@5 100.000 (99.409)
2025-08-27 22:01:36,516 - INFO - Epoch: [92][300/391] Time 0.034 (0.018) Data 0.000 (0.003) Loss 0.3731 (0.4203) Acc@1 85.156 (85.434) Acc@5 100.000 (99.408)
2025-08-27 22:01:37,352 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:37,352 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:38,249 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5790 (0.5790) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:01:39,063 - INFO - Epoch 92:
2025-08-27 22:01:39,063 - INFO -   Train: acc1: 85.4260 | acc5: 99.4280 | loss: 0.4211 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:39,063 - INFO -   Val:   acc1: 79.9400 | acc5: 99.0100 | loss: 0.5907
2025-08-27 22:01:39,063 - INFO -   LR: 0.100000
2025-08-27 22:01:39,078 - INFO - 
Epoch: 93, lr = 0.1
2025-08-27 22:01:39,235 - INFO - Epoch: [93][0/391] Time 0.156 (0.156) Data 0.133 (0.133) Loss 0.3668 (0.3668) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:01:41,070 - INFO - Epoch: [93][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3474 (0.4280) Acc@1 89.844 (85.458) Acc@5 100.000 (99.397)
2025-08-27 22:01:41,401 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:41,401 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:42,972 - INFO - Epoch: [93][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4143 (0.4217) Acc@1 86.719 (85.650) Acc@5 100.000 (99.417)
2025-08-27 22:01:44,334 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:44,339 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:44,756 - INFO - Epoch: [93][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4083 (0.4244) Acc@1 85.156 (85.483) Acc@5 98.438 (99.429)
2025-08-27 22:01:46,701 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.7682 (0.7682) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:01:47,526 - INFO - Epoch 93:
2025-08-27 22:01:47,526 - INFO -   Train: acc1: 85.3740 | acc5: 99.3980 | loss: 0.4264 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:47,526 - INFO -   Val:   acc1: 75.5000 | acc5: 97.6700 | loss: 0.7983
2025-08-27 22:01:47,526 - INFO -   LR: 0.100000
2025-08-27 22:01:47,542 - INFO - 
Epoch: 94, lr = 0.1
2025-08-27 22:01:47,685 - INFO - Epoch: [94][0/391] Time 0.142 (0.142) Data 0.122 (0.122) Loss 0.4189 (0.4189) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:01:48,517 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:48,517 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:49,519 - INFO - Epoch: [94][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4047 (0.4202) Acc@1 86.719 (85.295) Acc@5 100.000 (99.404)
2025-08-27 22:01:51,350 - INFO - Epoch: [94][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4226 (0.4168) Acc@1 85.938 (85.463) Acc@5 100.000 (99.409)
2025-08-27 22:01:51,434 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:51,434 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:53,210 - INFO - Epoch: [94][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.3591 (0.4188) Acc@1 87.500 (85.535) Acc@5 100.000 (99.385)
2025-08-27 22:01:54,369 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:54,369 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:54,953 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6308 (0.6308) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:01:55,837 - INFO - Epoch 94:
2025-08-27 22:01:55,837 - INFO -   Train: acc1: 85.3660 | acc5: 99.3700 | loss: 0.4234 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:01:55,837 - INFO -   Val:   acc1: 78.7400 | acc5: 98.8900 | loss: 0.6329
2025-08-27 22:01:55,837 - INFO -   LR: 0.100000
2025-08-27 22:01:55,851 - INFO - 
Epoch: 95, lr = 0.1
2025-08-27 22:01:56,036 - INFO - Epoch: [95][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.3226 (0.3226) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:01:57,902 - INFO - Epoch: [95][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.5727 (0.4188) Acc@1 75.781 (85.597) Acc@5 100.000 (99.373)
2025-08-27 22:01:58,553 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:01:58,557 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:01:59,719 - INFO - Epoch: [95][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4574 (0.4205) Acc@1 80.469 (85.514) Acc@5 100.000 (99.409)
2025-08-27 22:02:01,574 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:01,574 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:01,682 - INFO - Epoch: [95][300/391] Time 0.037 (0.019) Data 0.013 (0.003) Loss 0.3220 (0.4224) Acc@1 89.844 (85.444) Acc@5 100.000 (99.380)
2025-08-27 22:02:03,376 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6632 (0.6632) Acc@1 75.781 (75.781) Acc@5 96.875 (96.875)
2025-08-27 22:02:04,220 - INFO - Epoch 95:
2025-08-27 22:02:04,220 - INFO -   Train: acc1: 85.4820 | acc5: 99.3860 | loss: 0.4215 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:04,220 - INFO -   Val:   acc1: 74.9400 | acc5: 98.0700 | loss: 0.8041
2025-08-27 22:02:04,220 - INFO -   LR: 0.100000
2025-08-27 22:02:04,236 - INFO - 
Epoch: 96, lr = 0.1
2025-08-27 22:02:04,425 - INFO - Epoch: [96][0/391] Time 0.188 (0.188) Data 0.152 (0.152) Loss 0.5204 (0.5204) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 22:02:05,567 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:05,567 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:06,277 - INFO - Epoch: [96][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.4170 (0.4212) Acc@1 85.938 (85.388) Acc@5 98.438 (99.428)
2025-08-27 22:02:08,122 - INFO - Epoch: [96][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4601 (0.4246) Acc@1 83.594 (85.273) Acc@5 99.219 (99.440)
2025-08-27 22:02:08,533 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:08,534 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:09,966 - INFO - Epoch: [96][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4112 (0.4298) Acc@1 86.719 (85.159) Acc@5 99.219 (99.455)
2025-08-27 22:02:11,434 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:11,434 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:11,694 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5663 (0.5663) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:02:12,516 - INFO - Epoch 96:
2025-08-27 22:02:12,516 - INFO -   Train: acc1: 85.3240 | acc5: 99.4700 | loss: 0.4264 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:12,516 - INFO -   Val:   acc1: 81.4100 | acc5: 98.9500 | loss: 0.5950
2025-08-27 22:02:12,516 - INFO -   LR: 0.100000
2025-08-27 22:02:12,533 - INFO - 
Epoch: 97, lr = 0.1
2025-08-27 22:02:12,732 - INFO - Epoch: [97][0/391] Time 0.185 (0.185) Data 0.150 (0.150) Loss 0.4181 (0.4181) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:02:14,477 - INFO - Epoch: [97][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3903 (0.4266) Acc@1 85.156 (85.419) Acc@5 100.000 (99.451)
2025-08-27 22:02:15,435 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:15,435 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:16,287 - INFO - Epoch: [97][200/391] Time 0.018 (0.019) Data 0.005 (0.003) Loss 0.4248 (0.4264) Acc@1 85.938 (85.164) Acc@5 98.438 (99.452)
2025-08-27 22:02:18,181 - INFO - Epoch: [97][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3669 (0.4273) Acc@1 87.500 (85.260) Acc@5 100.000 (99.387)
2025-08-27 22:02:18,395 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:18,395 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:19,932 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.4806 (0.4806) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:02:20,785 - INFO - Epoch 97:
2025-08-27 22:02:20,785 - INFO -   Train: acc1: 85.1520 | acc5: 99.3660 | loss: 0.4295 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:20,785 - INFO -   Val:   acc1: 82.9600 | acc5: 99.3000 | loss: 0.5289
2025-08-27 22:02:20,785 - INFO -   LR: 0.100000
2025-08-27 22:02:20,800 - INFO - 
Epoch: 98, lr = 0.1
2025-08-27 22:02:20,995 - INFO - Epoch: [98][0/391] Time 0.194 (0.194) Data 0.168 (0.168) Loss 0.4566 (0.4566) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:02:22,471 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:22,472 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:22,821 - INFO - Epoch: [98][100/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.4441 (0.4174) Acc@1 85.938 (85.868) Acc@5 100.000 (99.366)
2025-08-27 22:02:24,721 - INFO - Epoch: [98][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.5405 (0.4215) Acc@1 82.031 (85.615) Acc@5 98.438 (99.401)
2025-08-27 22:02:25,458 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:25,458 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:26,515 - INFO - Epoch: [98][300/391] Time 0.041 (0.019) Data 0.029 (0.003) Loss 0.3633 (0.4235) Acc@1 85.938 (85.496) Acc@5 100.000 (99.398)
2025-08-27 22:02:28,286 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5236 (0.5236) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:02:29,135 - INFO - Epoch 98:
2025-08-27 22:02:29,135 - INFO -   Train: acc1: 85.3780 | acc5: 99.4020 | loss: 0.4277 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:29,135 - INFO -   Val:   acc1: 81.7200 | acc5: 98.8200 | loss: 0.5521
2025-08-27 22:02:29,135 - INFO -   LR: 0.100000
2025-08-27 22:02:29,149 - INFO - 
Epoch: 99, lr = 0.1
2025-08-27 22:02:29,295 - INFO - Epoch: [99][0/391] Time 0.144 (0.144) Data 0.124 (0.124) Loss 0.4738 (0.4738) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:02:29,524 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:29,524 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:31,119 - INFO - Epoch: [99][100/391] Time 0.023 (0.019) Data 0.009 (0.004) Loss 0.3800 (0.4175) Acc@1 86.719 (85.628) Acc@5 100.000 (99.435)
2025-08-27 22:02:32,478 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:32,478 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:32,993 - INFO - Epoch: [99][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3201 (0.4283) Acc@1 90.625 (85.222) Acc@5 99.219 (99.452)
2025-08-27 22:02:34,752 - INFO - Epoch: [99][300/391] Time 0.018 (0.019) Data 0.006 (0.003) Loss 0.3866 (0.4256) Acc@1 85.156 (85.307) Acc@5 99.219 (99.429)
2025-08-27 22:02:35,271 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:35,271 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:36,463 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4724 (0.4724) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:02:37,279 - INFO - Epoch 99:
2025-08-27 22:02:37,279 - INFO -   Train: acc1: 85.3560 | acc5: 99.4300 | loss: 0.4232 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:37,279 - INFO -   Val:   acc1: 81.0600 | acc5: 99.2000 | loss: 0.5756
2025-08-27 22:02:37,279 - INFO -   LR: 0.010000
2025-08-27 22:02:37,294 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-27 22:02:37,459 - INFO - Epoch: [100][0/391] Time 0.164 (0.164) Data 0.141 (0.141) Loss 0.4273 (0.4273) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-27 22:02:39,277 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:39,278 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:39,290 - INFO - Epoch: [100][100/391] Time 0.047 (0.020) Data 0.031 (0.004) Loss 0.2043 (0.3311) Acc@1 93.750 (88.606) Acc@5 100.000 (99.629)
2025-08-27 22:02:41,159 - INFO - Epoch: [100][200/391] Time 0.018 (0.019) Data 0.001 (0.003) Loss 0.3087 (0.3147) Acc@1 86.719 (89.338) Acc@5 100.000 (99.674)
2025-08-27 22:02:42,142 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:42,142 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:42,842 - INFO - Epoch: [100][300/391] Time 0.021 (0.018) Data 0.010 (0.003) Loss 0.2053 (0.3032) Acc@1 92.969 (89.787) Acc@5 100.000 (99.691)
2025-08-27 22:02:44,594 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2526 (0.2526) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:02:45,419 - INFO - Epoch 100:
2025-08-27 22:02:45,420 - INFO -   Train: acc1: 89.9660 | acc5: 99.6760 | loss: 0.2966 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:45,420 - INFO -   Val:   acc1: 89.0800 | acc5: 99.7200 | loss: 0.3119
2025-08-27 22:02:45,420 - INFO -   LR: 0.010000
2025-08-27 22:02:45,468 - INFO - Checkpoint saved: epoch=100, metric=89.0800
2025-08-27 22:02:45,498 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-27 22:02:45,647 - INFO - Epoch: [101][0/391] Time 0.148 (0.148) Data 0.126 (0.126) Loss 0.3047 (0.3047) Acc@1 92.188 (92.188) Acc@5 97.656 (97.656)
2025-08-27 22:02:46,161 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:46,162 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:47,574 - INFO - Epoch: [101][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.1682 (0.2583) Acc@1 95.312 (91.422) Acc@5 100.000 (99.760)
2025-08-27 22:02:49,138 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:49,138 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:49,377 - INFO - Epoch: [101][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.2083 (0.2553) Acc@1 92.969 (91.465) Acc@5 98.438 (99.763)
2025-08-27 22:02:51,118 - INFO - Epoch: [101][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.2737 (0.2540) Acc@1 91.406 (91.393) Acc@5 100.000 (99.774)
2025-08-27 22:02:51,947 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:51,948 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:52,805 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2418 (0.2418) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:02:53,623 - INFO - Epoch 101:
2025-08-27 22:02:53,623 - INFO -   Train: acc1: 91.2580 | acc5: 99.7720 | loss: 0.2572 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:02:53,623 - INFO -   Val:   acc1: 89.0800 | acc5: 99.6600 | loss: 0.3088
2025-08-27 22:02:53,623 - INFO -   LR: 0.010000
2025-08-27 22:02:53,637 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-27 22:02:53,814 - INFO - Epoch: [102][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.2048 (0.2048) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:02:55,638 - INFO - Epoch: [102][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2550 (0.2471) Acc@1 91.406 (91.770) Acc@5 100.000 (99.667)
2025-08-27 22:02:55,935 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:55,935 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:57,386 - INFO - Epoch: [102][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1969 (0.2414) Acc@1 92.188 (91.775) Acc@5 100.000 (99.759)
2025-08-27 22:02:58,815 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:02:58,815 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:02:59,237 - INFO - Epoch: [102][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2560 (0.2398) Acc@1 92.969 (91.770) Acc@5 100.000 (99.782)
2025-08-27 22:03:00,951 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2091 (0.2091) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:03:01,786 - INFO - Epoch 102:
2025-08-27 22:03:01,786 - INFO -   Train: acc1: 91.8140 | acc5: 99.7960 | loss: 0.2388 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:01,787 - INFO -   Val:   acc1: 89.4900 | acc5: 99.6800 | loss: 0.3028
2025-08-27 22:03:01,787 - INFO -   LR: 0.010000
2025-08-27 22:03:01,834 - INFO - Checkpoint saved: epoch=102, metric=89.4900
2025-08-27 22:03:01,864 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-27 22:03:02,032 - INFO - Epoch: [103][0/391] Time 0.167 (0.167) Data 0.149 (0.149) Loss 0.3206 (0.3206) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:03:02,808 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:02,809 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:03,772 - INFO - Epoch: [103][100/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.2817 (0.2285) Acc@1 89.844 (92.474) Acc@5 100.000 (99.814)
2025-08-27 22:03:05,565 - INFO - Epoch: [103][200/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.2846 (0.2293) Acc@1 89.844 (92.277) Acc@5 100.000 (99.813)
2025-08-27 22:03:05,671 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:05,671 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:07,496 - INFO - Epoch: [103][300/391] Time 0.034 (0.019) Data 0.009 (0.002) Loss 0.4264 (0.2295) Acc@1 84.375 (92.263) Acc@5 98.438 (99.792)
2025-08-27 22:03:08,716 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:08,716 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:09,235 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2329 (0.2329) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:03:10,069 - INFO - Epoch 103:
2025-08-27 22:03:10,069 - INFO -   Train: acc1: 92.1100 | acc5: 99.7980 | loss: 0.2311 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:10,069 - INFO -   Val:   acc1: 89.6900 | acc5: 99.7000 | loss: 0.3041
2025-08-27 22:03:10,069 - INFO -   LR: 0.010000
2025-08-27 22:03:10,117 - INFO - Checkpoint saved: epoch=103, metric=89.6900
2025-08-27 22:03:10,150 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-27 22:03:10,318 - INFO - Epoch: [104][0/391] Time 0.166 (0.166) Data 0.128 (0.128) Loss 0.2164 (0.2164) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:03:12,113 - INFO - Epoch: [104][100/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2005 (0.2217) Acc@1 92.969 (92.334) Acc@5 100.000 (99.838)
2025-08-27 22:03:12,735 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:12,736 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:13,991 - INFO - Epoch: [104][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.1665 (0.2217) Acc@1 96.875 (92.265) Acc@5 99.219 (99.821)
2025-08-27 22:03:15,675 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:15,676 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:15,743 - INFO - Epoch: [104][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1668 (0.2219) Acc@1 93.750 (92.377) Acc@5 100.000 (99.831)
2025-08-27 22:03:17,596 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2720 (0.2720) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:03:18,454 - INFO - Epoch 104:
2025-08-27 22:03:18,454 - INFO -   Train: acc1: 92.2780 | acc5: 99.8320 | loss: 0.2242 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:18,454 - INFO -   Val:   acc1: 89.6700 | acc5: 99.7600 | loss: 0.3024
2025-08-27 22:03:18,454 - INFO -   LR: 0.010000
2025-08-27 22:03:18,469 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-27 22:03:18,641 - INFO - Epoch: [105][0/391] Time 0.170 (0.170) Data 0.152 (0.152) Loss 0.1705 (0.1705) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:03:19,771 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:19,771 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:20,436 - INFO - Epoch: [105][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2419 (0.2070) Acc@1 89.062 (92.946) Acc@5 100.000 (99.861)
2025-08-27 22:03:22,249 - INFO - Epoch: [105][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1404 (0.2133) Acc@1 95.312 (92.638) Acc@5 100.000 (99.860)
2025-08-27 22:03:22,706 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:22,706 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:24,128 - INFO - Epoch: [105][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2129 (0.2165) Acc@1 96.094 (92.507) Acc@5 99.219 (99.842)
2025-08-27 22:03:25,696 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:25,697 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:25,947 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2395 (0.2395) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:03:26,813 - INFO - Epoch 105:
2025-08-27 22:03:26,813 - INFO -   Train: acc1: 92.4740 | acc5: 99.8480 | loss: 0.2177 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:26,813 - INFO -   Val:   acc1: 89.7700 | acc5: 99.7000 | loss: 0.3072
2025-08-27 22:03:26,813 - INFO -   LR: 0.010000
2025-08-27 22:03:26,862 - INFO - Checkpoint saved: epoch=105, metric=89.7700
2025-08-27 22:03:26,895 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-27 22:03:27,078 - INFO - Epoch: [106][0/391] Time 0.182 (0.182) Data 0.163 (0.163) Loss 0.1624 (0.1624) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:03:28,869 - INFO - Epoch: [106][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1462 (0.2122) Acc@1 91.406 (92.907) Acc@5 100.000 (99.799)
2025-08-27 22:03:29,861 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:29,861 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:30,644 - INFO - Epoch: [106][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1877 (0.2102) Acc@1 92.188 (92.739) Acc@5 100.000 (99.825)
2025-08-27 22:03:32,464 - INFO - Epoch: [106][300/391] Time 0.018 (0.018) Data 0.000 (0.003) Loss 0.4284 (0.2118) Acc@1 86.719 (92.759) Acc@5 100.000 (99.839)
2025-08-27 22:03:32,695 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:32,695 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:34,269 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.1962 (0.1962) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:03:35,107 - INFO - Epoch 106:
2025-08-27 22:03:35,107 - INFO -   Train: acc1: 92.6220 | acc5: 99.8280 | loss: 0.2162 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:35,108 - INFO -   Val:   acc1: 89.8600 | acc5: 99.7300 | loss: 0.3035
2025-08-27 22:03:35,108 - INFO -   LR: 0.010000
2025-08-27 22:03:35,158 - INFO - Checkpoint saved: epoch=106, metric=89.8600
2025-08-27 22:03:35,190 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-27 22:03:35,366 - INFO - Epoch: [107][0/391] Time 0.174 (0.174) Data 0.142 (0.142) Loss 0.1498 (0.1498) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:03:36,884 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:36,885 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:37,170 - INFO - Epoch: [107][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2019 (0.2029) Acc@1 89.844 (93.116) Acc@5 100.000 (99.884)
2025-08-27 22:03:39,091 - INFO - Epoch: [107][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3613 (0.2066) Acc@1 87.500 (92.942) Acc@5 99.219 (99.852)
2025-08-27 22:03:39,880 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:39,881 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:40,968 - INFO - Epoch: [107][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2410 (0.2070) Acc@1 91.406 (92.893) Acc@5 99.219 (99.847)
2025-08-27 22:03:42,767 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2706 (0.2706) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:03:43,603 - INFO - Epoch 107:
2025-08-27 22:03:43,604 - INFO -   Train: acc1: 92.8260 | acc5: 99.8360 | loss: 0.2090 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:43,604 - INFO -   Val:   acc1: 89.5900 | acc5: 99.6800 | loss: 0.3075
2025-08-27 22:03:43,604 - INFO -   LR: 0.010000
2025-08-27 22:03:43,617 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-27 22:03:43,801 - INFO - Epoch: [108][0/391] Time 0.183 (0.183) Data 0.145 (0.145) Loss 0.1593 (0.1593) Acc@1 93.750 (93.750) Acc@5 98.438 (98.438)
2025-08-27 22:03:44,007 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:44,008 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:45,591 - INFO - Epoch: [108][100/391] Time 0.026 (0.020) Data 0.000 (0.004) Loss 0.2849 (0.1999) Acc@1 89.062 (93.495) Acc@5 100.000 (99.830)
2025-08-27 22:03:46,931 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:46,931 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:47,467 - INFO - Epoch: [108][200/391] Time 0.021 (0.019) Data 0.001 (0.004) Loss 0.2330 (0.2039) Acc@1 89.062 (93.116) Acc@5 100.000 (99.852)
2025-08-27 22:03:49,379 - INFO - Epoch: [108][300/391] Time 0.027 (0.019) Data 0.009 (0.004) Loss 0.1937 (0.2049) Acc@1 94.531 (93.052) Acc@5 100.000 (99.865)
2025-08-27 22:03:49,953 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:49,953 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:51,186 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2583 (0.2583) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:03:52,025 - INFO - Epoch 108:
2025-08-27 22:03:52,025 - INFO -   Train: acc1: 92.9980 | acc5: 99.8560 | loss: 0.2055 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:03:52,025 - INFO -   Val:   acc1: 89.7400 | acc5: 99.7200 | loss: 0.3009
2025-08-27 22:03:52,025 - INFO -   LR: 0.010000
2025-08-27 22:03:52,041 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-27 22:03:52,225 - INFO - Epoch: [109][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.1985 (0.1985) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:03:54,010 - INFO - Epoch: [109][100/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.2165 (0.2033) Acc@1 92.969 (92.884) Acc@5 100.000 (99.814)
2025-08-27 22:03:54,021 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:54,022 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:55,779 - INFO - Epoch: [109][200/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.2058 (0.1997) Acc@1 92.188 (93.031) Acc@5 99.219 (99.829)
2025-08-27 22:03:56,830 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:03:56,831 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:03:57,620 - INFO - Epoch: [109][300/391] Time 0.030 (0.019) Data 0.005 (0.003) Loss 0.2214 (0.2021) Acc@1 89.844 (92.997) Acc@5 100.000 (99.831)
2025-08-27 22:03:59,457 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2262 (0.2262) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:04:00,306 - INFO - Epoch 109:
2025-08-27 22:04:00,306 - INFO -   Train: acc1: 92.9240 | acc5: 99.8460 | loss: 0.2053 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:00,306 - INFO -   Val:   acc1: 89.8200 | acc5: 99.6500 | loss: 0.3073
2025-08-27 22:04:00,306 - INFO -   LR: 0.010000
2025-08-27 22:04:00,321 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-27 22:04:00,507 - INFO - Epoch: [110][0/391] Time 0.184 (0.184) Data 0.151 (0.151) Loss 0.1275 (0.1275) Acc@1 96.875 (96.875) Acc@5 99.219 (99.219)
2025-08-27 22:04:01,039 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:01,039 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:02,338 - INFO - Epoch: [110][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2493 (0.1975) Acc@1 92.969 (93.247) Acc@5 100.000 (99.814)
2025-08-27 22:04:03,983 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:03,984 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:04,148 - INFO - Epoch: [110][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1437 (0.1982) Acc@1 96.094 (93.186) Acc@5 100.000 (99.868)
2025-08-27 22:04:06,046 - INFO - Epoch: [110][300/391] Time 0.030 (0.019) Data 0.018 (0.003) Loss 0.1976 (0.1999) Acc@1 92.969 (93.140) Acc@5 100.000 (99.860)
2025-08-27 22:04:06,941 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:06,941 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:07,878 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2608 (0.2608) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:04:08,718 - INFO - Epoch 110:
2025-08-27 22:04:08,718 - INFO -   Train: acc1: 93.1340 | acc5: 99.8520 | loss: 0.1997 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:08,718 - INFO -   Val:   acc1: 89.4000 | acc5: 99.6800 | loss: 0.3193
2025-08-27 22:04:08,718 - INFO -   LR: 0.010000
2025-08-27 22:04:08,768 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-27 22:04:08,945 - INFO - Epoch: [111][0/391] Time 0.176 (0.176) Data 0.142 (0.142) Loss 0.1561 (0.1561) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:04:10,757 - INFO - Epoch: [111][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.1849 (0.1860) Acc@1 93.750 (93.781) Acc@5 100.000 (99.845)
2025-08-27 22:04:11,096 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:11,096 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:12,535 - INFO - Epoch: [111][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2113 (0.1942) Acc@1 91.406 (93.424) Acc@5 100.000 (99.860)
2025-08-27 22:04:14,040 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:14,040 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:14,424 - INFO - Epoch: [111][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2118 (0.1969) Acc@1 91.406 (93.166) Acc@5 100.000 (99.857)
2025-08-27 22:04:16,178 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2597 (0.2597) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:04:17,044 - INFO - Epoch 111:
2025-08-27 22:04:17,044 - INFO -   Train: acc1: 93.0660 | acc5: 99.8540 | loss: 0.1983 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:17,045 - INFO -   Val:   acc1: 89.5400 | acc5: 99.7100 | loss: 0.3143
2025-08-27 22:04:17,045 - INFO -   LR: 0.010000
2025-08-27 22:04:17,062 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-27 22:04:17,248 - INFO - Epoch: [112][0/391] Time 0.184 (0.184) Data 0.148 (0.148) Loss 0.1884 (0.1884) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:04:18,094 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:18,095 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:19,063 - INFO - Epoch: [112][100/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.2274 (0.1883) Acc@1 92.969 (93.371) Acc@5 100.000 (99.907)
2025-08-27 22:04:20,850 - INFO - Epoch: [112][200/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.2179 (0.1883) Acc@1 91.406 (93.482) Acc@5 100.000 (99.899)
2025-08-27 22:04:21,000 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:21,001 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:22,600 - INFO - Epoch: [112][300/391] Time 0.013 (0.018) Data 0.000 (0.002) Loss 0.1266 (0.1888) Acc@1 95.312 (93.493) Acc@5 100.000 (99.904)
2025-08-27 22:04:23,801 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:23,801 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:24,334 - INFO - Test: [0/79] Time 0.107 (0.107) Loss 0.2707 (0.2707) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:04:25,206 - INFO - Epoch 112:
2025-08-27 22:04:25,206 - INFO -   Train: acc1: 93.1940 | acc5: 99.8840 | loss: 0.1962 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:25,206 - INFO -   Val:   acc1: 88.8600 | acc5: 99.6700 | loss: 0.3328
2025-08-27 22:04:25,206 - INFO -   LR: 0.010000
2025-08-27 22:04:25,222 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-27 22:04:25,404 - INFO - Epoch: [113][0/391] Time 0.181 (0.181) Data 0.158 (0.158) Loss 0.2021 (0.2021) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:04:27,219 - INFO - Epoch: [113][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1976 (0.1852) Acc@1 92.188 (93.626) Acc@5 100.000 (99.884)
2025-08-27 22:04:27,881 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:27,881 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:29,044 - INFO - Epoch: [113][200/391] Time 0.020 (0.019) Data 0.007 (0.003) Loss 0.1691 (0.1859) Acc@1 93.750 (93.664) Acc@5 100.000 (99.899)
2025-08-27 22:04:30,777 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:30,778 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:30,839 - INFO - Epoch: [113][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2181 (0.1874) Acc@1 92.969 (93.646) Acc@5 100.000 (99.904)
2025-08-27 22:04:32,717 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2583 (0.2583) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:04:33,589 - INFO - Epoch 113:
2025-08-27 22:04:33,589 - INFO -   Train: acc1: 93.4700 | acc5: 99.8820 | loss: 0.1917 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:33,589 - INFO -   Val:   acc1: 89.6300 | acc5: 99.7600 | loss: 0.3186
2025-08-27 22:04:33,589 - INFO -   LR: 0.010000
2025-08-27 22:04:33,604 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-27 22:04:33,763 - INFO - Epoch: [114][0/391] Time 0.158 (0.158) Data 0.141 (0.141) Loss 0.0940 (0.0940) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:04:35,013 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:35,013 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:35,673 - INFO - Epoch: [114][100/391] Time 0.023 (0.020) Data 0.007 (0.003) Loss 0.2338 (0.1892) Acc@1 92.969 (93.433) Acc@5 99.219 (99.899)
2025-08-27 22:04:37,489 - INFO - Epoch: [114][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.2042 (0.1918) Acc@1 94.531 (93.354) Acc@5 100.000 (99.845)
2025-08-27 22:04:37,967 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:37,967 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:39,285 - INFO - Epoch: [114][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.1142 (0.1921) Acc@1 97.656 (93.361) Acc@5 100.000 (99.860)
2025-08-27 22:04:40,868 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:40,868 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:41,094 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2815 (0.2815) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:04:41,919 - INFO - Epoch 114:
2025-08-27 22:04:41,919 - INFO -   Train: acc1: 93.2420 | acc5: 99.8640 | loss: 0.1943 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:41,919 - INFO -   Val:   acc1: 88.6900 | acc5: 99.6600 | loss: 0.3396
2025-08-27 22:04:41,919 - INFO -   LR: 0.010000
2025-08-27 22:04:41,935 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-27 22:04:42,106 - INFO - Epoch: [115][0/391] Time 0.170 (0.170) Data 0.149 (0.149) Loss 0.2154 (0.2154) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:04:44,035 - INFO - Epoch: [115][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.2402 (0.1786) Acc@1 92.188 (93.897) Acc@5 100.000 (99.930)
2025-08-27 22:04:44,989 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:44,989 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:45,821 - INFO - Epoch: [115][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2587 (0.1826) Acc@1 89.844 (93.692) Acc@5 99.219 (99.899)
2025-08-27 22:04:47,614 - INFO - Epoch: [115][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1551 (0.1872) Acc@1 94.531 (93.496) Acc@5 100.000 (99.881)
2025-08-27 22:04:47,918 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:47,925 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:49,432 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2091 (0.2091) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:04:50,281 - INFO - Epoch 115:
2025-08-27 22:04:50,281 - INFO -   Train: acc1: 93.3180 | acc5: 99.8600 | loss: 0.1911 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:50,281 - INFO -   Val:   acc1: 89.3200 | acc5: 99.6700 | loss: 0.3214
2025-08-27 22:04:50,281 - INFO -   LR: 0.010000
2025-08-27 22:04:50,793 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-27 22:04:50,978 - INFO - Epoch: [116][0/391] Time 0.184 (0.184) Data 0.146 (0.146) Loss 0.2497 (0.2497) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:04:52,422 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:52,422 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:52,719 - INFO - Epoch: [116][100/391] Time 0.036 (0.019) Data 0.000 (0.004) Loss 0.1885 (0.1899) Acc@1 92.188 (93.456) Acc@5 99.219 (99.892)
2025-08-27 22:04:54,451 - INFO - Epoch: [116][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1469 (0.1907) Acc@1 94.531 (93.513) Acc@5 100.000 (99.891)
2025-08-27 22:04:55,237 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:55,237 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:04:56,206 - INFO - Epoch: [116][300/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.1986 (0.1908) Acc@1 92.188 (93.540) Acc@5 100.000 (99.868)
2025-08-27 22:04:57,905 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2886 (0.2886) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:04:58,748 - INFO - Epoch 116:
2025-08-27 22:04:58,748 - INFO -   Train: acc1: 93.3560 | acc5: 99.8580 | loss: 0.1937 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:04:58,748 - INFO -   Val:   acc1: 89.2000 | acc5: 99.7000 | loss: 0.3264
2025-08-27 22:04:58,748 - INFO -   LR: 0.010000
2025-08-27 22:04:58,764 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-27 22:04:58,937 - INFO - Epoch: [117][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 0.2170 (0.2170) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:04:59,164 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:04:59,164 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:00,675 - INFO - Epoch: [117][100/391] Time 0.027 (0.019) Data 0.016 (0.004) Loss 0.1733 (0.1815) Acc@1 95.312 (93.943) Acc@5 100.000 (99.884)
2025-08-27 22:05:01,976 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:01,976 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:02,485 - INFO - Epoch: [117][200/391] Time 0.029 (0.018) Data 0.000 (0.004) Loss 0.2677 (0.1842) Acc@1 92.969 (93.801) Acc@5 99.219 (99.876)
2025-08-27 22:05:04,271 - INFO - Epoch: [117][300/391] Time 0.017 (0.018) Data 0.002 (0.003) Loss 0.2810 (0.1888) Acc@1 91.406 (93.527) Acc@5 100.000 (99.878)
2025-08-27 22:05:04,820 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:04,821 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:05,986 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2361 (0.2361) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:05:06,807 - INFO - Epoch 117:
2025-08-27 22:05:06,808 - INFO -   Train: acc1: 93.4840 | acc5: 99.8760 | loss: 0.1900 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:06,808 - INFO -   Val:   acc1: 89.2500 | acc5: 99.6800 | loss: 0.3276
2025-08-27 22:05:06,808 - INFO -   LR: 0.010000
2025-08-27 22:05:06,823 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-27 22:05:07,004 - INFO - Epoch: [118][0/391] Time 0.180 (0.180) Data 0.151 (0.151) Loss 0.1637 (0.1637) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:05:08,799 - INFO - Epoch: [118][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2027 (0.1820) Acc@1 92.188 (93.704) Acc@5 100.000 (99.907)
2025-08-27 22:05:08,815 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:08,815 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:10,519 - INFO - Epoch: [118][200/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.1679 (0.1835) Acc@1 94.531 (93.645) Acc@5 100.000 (99.887)
2025-08-27 22:05:11,651 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:11,652 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:12,307 - INFO - Epoch: [118][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.2238 (0.1851) Acc@1 88.281 (93.571) Acc@5 100.000 (99.878)
2025-08-27 22:05:14,017 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2735 (0.2735) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:05:14,845 - INFO - Epoch 118:
2025-08-27 22:05:14,846 - INFO -   Train: acc1: 93.4500 | acc5: 99.8680 | loss: 0.1883 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:14,846 - INFO -   Val:   acc1: 89.5100 | acc5: 99.7200 | loss: 0.3163
2025-08-27 22:05:14,846 - INFO -   LR: 0.010000
2025-08-27 22:05:14,862 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-27 22:05:15,079 - INFO - Epoch: [119][0/391] Time 0.217 (0.217) Data 0.192 (0.192) Loss 0.1769 (0.1769) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-27 22:05:15,601 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:15,601 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:16,878 - INFO - Epoch: [119][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.0684 (0.1808) Acc@1 98.438 (93.533) Acc@5 100.000 (99.892)
2025-08-27 22:05:18,520 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:18,520 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:18,696 - INFO - Epoch: [119][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1911 (0.1840) Acc@1 95.312 (93.591) Acc@5 100.000 (99.891)
2025-08-27 22:05:20,479 - INFO - Epoch: [119][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2210 (0.1844) Acc@1 93.750 (93.607) Acc@5 100.000 (99.891)
2025-08-27 22:05:21,406 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:21,406 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:22,205 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.3349 (0.3349) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:05:23,054 - INFO - Epoch 119:
2025-08-27 22:05:23,054 - INFO -   Train: acc1: 93.5020 | acc5: 99.8740 | loss: 0.1869 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:23,054 - INFO -   Val:   acc1: 89.0300 | acc5: 99.7300 | loss: 0.3354
2025-08-27 22:05:23,054 - INFO -   LR: 0.010000
2025-08-27 22:05:23,069 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-27 22:05:23,250 - INFO - Epoch: [120][0/391] Time 0.180 (0.180) Data 0.160 (0.160) Loss 0.1528 (0.1528) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:05:25,098 - INFO - Epoch: [120][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.1786 (0.1826) Acc@1 93.750 (93.796) Acc@5 100.000 (99.907)
2025-08-27 22:05:25,431 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:25,433 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:26,939 - INFO - Epoch: [120][200/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.1478 (0.1876) Acc@1 95.312 (93.626) Acc@5 100.000 (99.899)
2025-08-27 22:05:28,424 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:28,424 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:28,829 - INFO - Epoch: [120][300/391] Time 0.025 (0.019) Data 0.009 (0.004) Loss 0.1568 (0.1893) Acc@1 94.531 (93.540) Acc@5 100.000 (99.888)
2025-08-27 22:05:30,603 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2468 (0.2468) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:05:31,461 - INFO - Epoch 120:
2025-08-27 22:05:31,461 - INFO -   Train: acc1: 93.5040 | acc5: 99.8960 | loss: 0.1903 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:31,461 - INFO -   Val:   acc1: 89.3700 | acc5: 99.7600 | loss: 0.3216
2025-08-27 22:05:31,461 - INFO -   LR: 0.010000
2025-08-27 22:05:31,512 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-27 22:05:31,690 - INFO - Epoch: [121][0/391] Time 0.177 (0.177) Data 0.159 (0.159) Loss 0.2230 (0.2230) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:05:32,529 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:32,529 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:33,495 - INFO - Epoch: [121][100/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.1544 (0.1787) Acc@1 95.312 (94.059) Acc@5 100.000 (99.923)
2025-08-27 22:05:35,340 - INFO - Epoch: [121][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1808 (0.1840) Acc@1 94.531 (93.723) Acc@5 99.219 (99.872)
2025-08-27 22:05:35,494 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:35,494 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:37,158 - INFO - Epoch: [121][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.2426 (0.1899) Acc@1 94.531 (93.519) Acc@5 100.000 (99.860)
2025-08-27 22:05:38,396 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:38,397 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:38,928 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2817 (0.2817) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:05:39,792 - INFO - Epoch 121:
2025-08-27 22:05:39,792 - INFO -   Train: acc1: 93.4840 | acc5: 99.8640 | loss: 0.1900 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:39,792 - INFO -   Val:   acc1: 89.2000 | acc5: 99.6800 | loss: 0.3287
2025-08-27 22:05:39,792 - INFO -   LR: 0.010000
2025-08-27 22:05:39,809 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-27 22:05:39,993 - INFO - Epoch: [122][0/391] Time 0.182 (0.182) Data 0.163 (0.163) Loss 0.1147 (0.1147) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:05:41,798 - INFO - Epoch: [122][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.2115 (0.1758) Acc@1 92.188 (93.881) Acc@5 99.219 (99.915)
2025-08-27 22:05:42,497 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:42,497 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:43,666 - INFO - Epoch: [122][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1940 (0.1856) Acc@1 93.750 (93.532) Acc@5 100.000 (99.891)
2025-08-27 22:05:45,504 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:45,504 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:45,553 - INFO - Epoch: [122][300/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.2696 (0.1871) Acc@1 92.188 (93.514) Acc@5 100.000 (99.894)
2025-08-27 22:05:47,293 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3125 (0.3125) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:05:48,186 - INFO - Epoch 122:
2025-08-27 22:05:48,186 - INFO -   Train: acc1: 93.4540 | acc5: 99.8900 | loss: 0.1890 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:48,186 - INFO -   Val:   acc1: 89.4500 | acc5: 99.6700 | loss: 0.3179
2025-08-27 22:05:48,187 - INFO -   LR: 0.010000
2025-08-27 22:05:48,203 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-27 22:05:48,385 - INFO - Epoch: [123][0/391] Time 0.181 (0.181) Data 0.154 (0.154) Loss 0.1567 (0.1567) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:05:49,582 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:49,582 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:50,272 - INFO - Epoch: [123][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.1256 (0.1905) Acc@1 96.875 (93.472) Acc@5 100.000 (99.884)
2025-08-27 22:05:52,121 - INFO - Epoch: [123][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2054 (0.1846) Acc@1 90.625 (93.598) Acc@5 100.000 (99.868)
2025-08-27 22:05:52,648 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:52,648 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:54,052 - INFO - Epoch: [123][300/391] Time 0.021 (0.019) Data 0.005 (0.003) Loss 0.1713 (0.1859) Acc@1 96.094 (93.599) Acc@5 100.000 (99.883)
2025-08-27 22:05:55,783 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:55,783 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:05:55,989 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.3026 (0.3026) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:05:56,878 - INFO - Epoch 123:
2025-08-27 22:05:56,878 - INFO -   Train: acc1: 93.4520 | acc5: 99.8720 | loss: 0.1886 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:05:56,878 - INFO -   Val:   acc1: 88.9900 | acc5: 99.5200 | loss: 0.3372
2025-08-27 22:05:56,878 - INFO -   LR: 0.010000
2025-08-27 22:05:56,893 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-27 22:05:57,082 - INFO - Epoch: [124][0/391] Time 0.188 (0.188) Data 0.157 (0.157) Loss 0.1267 (0.1267) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:05:58,900 - INFO - Epoch: [124][100/391] Time 0.044 (0.020) Data 0.034 (0.005) Loss 0.2649 (0.1768) Acc@1 88.281 (93.881) Acc@5 100.000 (99.899)
2025-08-27 22:05:59,961 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:05:59,961 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:00,761 - INFO - Epoch: [124][200/391] Time 0.021 (0.019) Data 0.001 (0.004) Loss 0.2076 (0.1822) Acc@1 93.750 (93.812) Acc@5 100.000 (99.860)
2025-08-27 22:06:02,613 - INFO - Epoch: [124][300/391] Time 0.022 (0.019) Data 0.001 (0.004) Loss 0.1306 (0.1872) Acc@1 95.312 (93.553) Acc@5 100.000 (99.862)
2025-08-27 22:06:02,860 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:02,860 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:04,365 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2471 (0.2471) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:06:05,212 - INFO - Epoch 124:
2025-08-27 22:06:05,212 - INFO -   Train: acc1: 93.4060 | acc5: 99.8580 | loss: 0.1901 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:05,212 - INFO -   Val:   acc1: 89.7500 | acc5: 99.7400 | loss: 0.3087
2025-08-27 22:06:05,212 - INFO -   LR: 0.010000
2025-08-27 22:06:05,231 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-27 22:06:05,426 - INFO - Epoch: [125][0/391] Time 0.194 (0.194) Data 0.168 (0.168) Loss 0.2122 (0.2122) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:06:07,075 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:07,075 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:07,363 - INFO - Epoch: [125][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.1050 (0.1822) Acc@1 97.656 (93.580) Acc@5 100.000 (99.923)
2025-08-27 22:06:09,150 - INFO - Epoch: [125][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1159 (0.1871) Acc@1 95.312 (93.532) Acc@5 100.000 (99.899)
2025-08-27 22:06:09,991 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:09,991 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:11,011 - INFO - Epoch: [125][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1927 (0.1852) Acc@1 92.969 (93.612) Acc@5 99.219 (99.891)
2025-08-27 22:06:12,974 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3036 (0.3036) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:06:13,864 - INFO - Epoch 125:
2025-08-27 22:06:13,864 - INFO -   Train: acc1: 93.5320 | acc5: 99.9000 | loss: 0.1873 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:13,864 - INFO -   Val:   acc1: 89.2800 | acc5: 99.6300 | loss: 0.3306
2025-08-27 22:06:13,864 - INFO -   LR: 0.010000
2025-08-27 22:06:13,881 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-27 22:06:14,031 - INFO - Epoch: [126][0/391] Time 0.149 (0.149) Data 0.129 (0.129) Loss 0.2182 (0.2182) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:06:14,326 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:14,326 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:15,884 - INFO - Epoch: [126][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1525 (0.1836) Acc@1 96.094 (93.502) Acc@5 100.000 (99.892)
2025-08-27 22:06:17,207 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:17,221 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:17,702 - INFO - Epoch: [126][200/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.1766 (0.1873) Acc@1 93.750 (93.435) Acc@5 100.000 (99.876)
2025-08-27 22:06:19,517 - INFO - Epoch: [126][300/391] Time 0.061 (0.019) Data 0.030 (0.003) Loss 0.1999 (0.1876) Acc@1 92.188 (93.452) Acc@5 100.000 (99.875)
2025-08-27 22:06:20,234 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:20,234 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:21,370 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4098 (0.4098) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:06:22,229 - INFO - Epoch 126:
2025-08-27 22:06:22,230 - INFO -   Train: acc1: 93.4440 | acc5: 99.8660 | loss: 0.1888 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:22,230 - INFO -   Val:   acc1: 88.5100 | acc5: 99.6700 | loss: 0.3689
2025-08-27 22:06:22,230 - INFO -   LR: 0.010000
2025-08-27 22:06:22,247 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-27 22:06:22,425 - INFO - Epoch: [127][0/391] Time 0.177 (0.177) Data 0.155 (0.155) Loss 0.1194 (0.1194) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:06:24,243 - INFO - Epoch: [127][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.1840 (0.1793) Acc@1 92.188 (94.005) Acc@5 100.000 (99.907)
2025-08-27 22:06:24,299 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:24,299 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:26,033 - INFO - Epoch: [127][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2337 (0.1810) Acc@1 92.188 (93.777) Acc@5 100.000 (99.907)
2025-08-27 22:06:27,138 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:27,138 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:27,830 - INFO - Epoch: [127][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.2043 (0.1839) Acc@1 94.531 (93.638) Acc@5 100.000 (99.896)
2025-08-27 22:06:29,686 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4189 (0.4189) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:06:30,572 - INFO - Epoch 127:
2025-08-27 22:06:30,572 - INFO -   Train: acc1: 93.5060 | acc5: 99.8980 | loss: 0.1881 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:30,572 - INFO -   Val:   acc1: 88.0800 | acc5: 99.4900 | loss: 0.3704
2025-08-27 22:06:30,572 - INFO -   LR: 0.010000
2025-08-27 22:06:30,589 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-27 22:06:30,785 - INFO - Epoch: [128][0/391] Time 0.195 (0.195) Data 0.155 (0.155) Loss 0.1824 (0.1824) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:06:31,301 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:31,301 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:32,625 - INFO - Epoch: [128][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1970 (0.1809) Acc@1 93.750 (93.719) Acc@5 100.000 (99.915)
2025-08-27 22:06:34,300 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:34,301 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:34,443 - INFO - Epoch: [128][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1339 (0.1804) Acc@1 96.094 (93.750) Acc@5 100.000 (99.907)
2025-08-27 22:06:36,399 - INFO - Epoch: [128][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.1483 (0.1873) Acc@1 93.750 (93.506) Acc@5 100.000 (99.901)
2025-08-27 22:06:37,433 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:37,433 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:38,328 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3086 (0.3086) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:06:39,173 - INFO - Epoch 128:
2025-08-27 22:06:39,173 - INFO -   Train: acc1: 93.4660 | acc5: 99.8900 | loss: 0.1895 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:39,173 - INFO -   Val:   acc1: 88.3700 | acc5: 99.7200 | loss: 0.3574
2025-08-27 22:06:39,173 - INFO -   LR: 0.010000
2025-08-27 22:06:39,189 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-27 22:06:39,382 - INFO - Epoch: [129][0/391] Time 0.192 (0.192) Data 0.167 (0.167) Loss 0.1745 (0.1745) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-27 22:06:41,251 - INFO - Epoch: [129][100/391] Time 0.027 (0.020) Data 0.015 (0.004) Loss 0.1764 (0.1934) Acc@1 95.312 (93.263) Acc@5 100.000 (99.892)
2025-08-27 22:06:41,588 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:41,588 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:43,028 - INFO - Epoch: [129][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2004 (0.1927) Acc@1 92.969 (93.190) Acc@5 100.000 (99.876)
2025-08-27 22:06:44,475 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:44,476 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:44,845 - INFO - Epoch: [129][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2048 (0.1925) Acc@1 92.969 (93.215) Acc@5 100.000 (99.878)
2025-08-27 22:06:46,608 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3328 (0.3328) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:06:47,467 - INFO - Epoch 129:
2025-08-27 22:06:47,467 - INFO -   Train: acc1: 93.1240 | acc5: 99.8840 | loss: 0.1953 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:47,468 - INFO -   Val:   acc1: 87.9400 | acc5: 99.5900 | loss: 0.3833
2025-08-27 22:06:47,468 - INFO -   LR: 0.010000
2025-08-27 22:06:47,483 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-27 22:06:47,665 - INFO - Epoch: [130][0/391] Time 0.181 (0.181) Data 0.161 (0.161) Loss 0.1960 (0.1960) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:06:48,527 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:48,528 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:49,432 - INFO - Epoch: [130][100/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1540 (0.1813) Acc@1 92.969 (93.812) Acc@5 100.000 (99.876)
2025-08-27 22:06:51,274 - INFO - Epoch: [130][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1865 (0.1835) Acc@1 93.750 (93.688) Acc@5 100.000 (99.880)
2025-08-27 22:06:51,431 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:51,431 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:53,011 - INFO - Epoch: [130][300/391] Time 0.020 (0.018) Data 0.000 (0.003) Loss 0.1944 (0.1892) Acc@1 92.969 (93.483) Acc@5 100.000 (99.849)
2025-08-27 22:06:54,260 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:54,264 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:54,775 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2691 (0.2691) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:06:55,616 - INFO - Epoch 130:
2025-08-27 22:06:55,616 - INFO -   Train: acc1: 93.4900 | acc5: 99.8520 | loss: 0.1892 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:06:55,616 - INFO -   Val:   acc1: 88.6800 | acc5: 99.7000 | loss: 0.3392
2025-08-27 22:06:55,616 - INFO -   LR: 0.010000
2025-08-27 22:06:55,665 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-27 22:06:55,848 - INFO - Epoch: [131][0/391] Time 0.182 (0.182) Data 0.161 (0.161) Loss 0.1412 (0.1412) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:06:57,682 - INFO - Epoch: [131][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1386 (0.1888) Acc@1 96.094 (93.193) Acc@5 100.000 (99.923)
2025-08-27 22:06:58,341 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:06:58,341 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:06:59,501 - INFO - Epoch: [131][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1589 (0.1903) Acc@1 93.750 (93.303) Acc@5 99.219 (99.914)
2025-08-27 22:07:01,460 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:01,460 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:01,506 - INFO - Epoch: [131][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.2275 (0.1918) Acc@1 92.969 (93.301) Acc@5 100.000 (99.888)
2025-08-27 22:07:03,292 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.3215 (0.3215) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:07:04,131 - INFO - Epoch 131:
2025-08-27 22:07:04,131 - INFO -   Train: acc1: 93.3360 | acc5: 99.8820 | loss: 0.1922 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:04,131 - INFO -   Val:   acc1: 88.1200 | acc5: 99.5200 | loss: 0.3701
2025-08-27 22:07:04,131 - INFO -   LR: 0.010000
2025-08-27 22:07:04,150 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-27 22:07:04,305 - INFO - Epoch: [132][0/391] Time 0.155 (0.155) Data 0.138 (0.138) Loss 0.2048 (0.2048) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 22:07:05,491 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:05,491 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:06,098 - INFO - Epoch: [132][100/391] Time 0.035 (0.019) Data 0.000 (0.004) Loss 0.1607 (0.1864) Acc@1 95.312 (93.325) Acc@5 100.000 (99.853)
2025-08-27 22:07:07,904 - INFO - Epoch: [132][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1723 (0.1848) Acc@1 92.969 (93.497) Acc@5 100.000 (99.887)
2025-08-27 22:07:08,385 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:08,385 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:09,702 - INFO - Epoch: [132][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1763 (0.1872) Acc@1 95.312 (93.418) Acc@5 100.000 (99.894)
2025-08-27 22:07:11,239 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:11,240 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:11,440 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.3151 (0.3151) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-27 22:07:12,292 - INFO - Epoch 132:
2025-08-27 22:07:12,292 - INFO -   Train: acc1: 93.3000 | acc5: 99.8800 | loss: 0.1916 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:12,292 - INFO -   Val:   acc1: 88.7100 | acc5: 99.6500 | loss: 0.3618
2025-08-27 22:07:12,292 - INFO -   LR: 0.010000
2025-08-27 22:07:12,308 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-27 22:07:12,469 - INFO - Epoch: [133][0/391] Time 0.160 (0.160) Data 0.134 (0.134) Loss 0.1268 (0.1268) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:07:14,289 - INFO - Epoch: [133][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1613 (0.1875) Acc@1 94.531 (93.626) Acc@5 100.000 (99.899)
2025-08-27 22:07:15,304 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:15,305 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:16,144 - INFO - Epoch: [133][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.2009 (0.1881) Acc@1 92.969 (93.478) Acc@5 100.000 (99.887)
2025-08-27 22:07:18,027 - INFO - Epoch: [133][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2298 (0.1899) Acc@1 91.406 (93.389) Acc@5 100.000 (99.881)
2025-08-27 22:07:18,357 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:18,357 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:19,855 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.4089 (0.4089) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:07:20,689 - INFO - Epoch 133:
2025-08-27 22:07:20,689 - INFO -   Train: acc1: 93.2580 | acc5: 99.8860 | loss: 0.1924 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:20,689 - INFO -   Val:   acc1: 88.5300 | acc5: 99.6300 | loss: 0.3592
2025-08-27 22:07:20,689 - INFO -   LR: 0.010000
2025-08-27 22:07:20,708 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-27 22:07:20,859 - INFO - Epoch: [134][0/391] Time 0.150 (0.150) Data 0.134 (0.134) Loss 0.1530 (0.1530) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:07:22,452 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:22,452 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:22,751 - INFO - Epoch: [134][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1770 (0.1836) Acc@1 94.531 (93.735) Acc@5 100.000 (99.899)
2025-08-27 22:07:24,474 - INFO - Epoch: [134][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1626 (0.1836) Acc@1 94.531 (93.641) Acc@5 99.219 (99.914)
2025-08-27 22:07:25,323 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:25,323 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:26,341 - INFO - Epoch: [134][300/391] Time 0.028 (0.019) Data 0.015 (0.003) Loss 0.2419 (0.1898) Acc@1 92.969 (93.394) Acc@5 100.000 (99.912)
2025-08-27 22:07:28,219 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.3295 (0.3295) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:07:29,124 - INFO - Epoch 134:
2025-08-27 22:07:29,124 - INFO -   Train: acc1: 93.3560 | acc5: 99.9080 | loss: 0.1906 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:29,124 - INFO -   Val:   acc1: 88.7700 | acc5: 99.6400 | loss: 0.3459
2025-08-27 22:07:29,124 - INFO -   LR: 0.010000
2025-08-27 22:07:29,140 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-27 22:07:29,316 - INFO - Epoch: [135][0/391] Time 0.175 (0.175) Data 0.147 (0.147) Loss 0.3018 (0.3018) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:07:29,570 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:29,570 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:31,128 - INFO - Epoch: [135][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.2093 (0.1901) Acc@1 93.750 (93.263) Acc@5 100.000 (99.907)
2025-08-27 22:07:32,515 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:32,515 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:33,022 - INFO - Epoch: [135][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2134 (0.1890) Acc@1 92.188 (93.400) Acc@5 100.000 (99.918)
2025-08-27 22:07:34,852 - INFO - Epoch: [135][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2468 (0.1922) Acc@1 85.938 (93.283) Acc@5 100.000 (99.904)
2025-08-27 22:07:35,499 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:35,499 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:36,616 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.3522 (0.3522) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:07:37,463 - INFO - Epoch 135:
2025-08-27 22:07:37,463 - INFO -   Train: acc1: 93.2500 | acc5: 99.8960 | loss: 0.1924 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:37,463 - INFO -   Val:   acc1: 88.8800 | acc5: 99.7100 | loss: 0.3454
2025-08-27 22:07:37,463 - INFO -   LR: 0.010000
2025-08-27 22:07:37,479 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-27 22:07:37,661 - INFO - Epoch: [136][0/391] Time 0.181 (0.181) Data 0.163 (0.163) Loss 0.1220 (0.1220) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:07:39,451 - INFO - Epoch: [136][100/391] Time 0.012 (0.019) Data 0.000 (0.005) Loss 0.1412 (0.1924) Acc@1 95.312 (93.325) Acc@5 100.000 (99.845)
2025-08-27 22:07:39,539 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:39,539 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:41,320 - INFO - Epoch: [136][200/391] Time 0.015 (0.019) Data 0.000 (0.005) Loss 0.2278 (0.1904) Acc@1 92.969 (93.493) Acc@5 100.000 (99.872)
2025-08-27 22:07:42,498 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:42,498 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:43,241 - INFO - Epoch: [136][300/391] Time 0.015 (0.019) Data 0.000 (0.005) Loss 0.2498 (0.1913) Acc@1 90.625 (93.374) Acc@5 100.000 (99.878)
2025-08-27 22:07:45,099 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3445 (0.3445) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:07:45,980 - INFO - Epoch 136:
2025-08-27 22:07:45,980 - INFO -   Train: acc1: 93.3880 | acc5: 99.8900 | loss: 0.1907 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:45,980 - INFO -   Val:   acc1: 89.0400 | acc5: 99.7200 | loss: 0.3457
2025-08-27 22:07:45,980 - INFO -   LR: 0.010000
2025-08-27 22:07:45,996 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-27 22:07:46,181 - INFO - Epoch: [137][0/391] Time 0.184 (0.184) Data 0.162 (0.162) Loss 0.1860 (0.1860) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:07:46,742 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:46,756 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:48,051 - INFO - Epoch: [137][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.1303 (0.1785) Acc@1 96.875 (93.936) Acc@5 100.000 (99.884)
2025-08-27 22:07:49,702 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:49,702 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:49,837 - INFO - Epoch: [137][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1135 (0.1864) Acc@1 95.312 (93.614) Acc@5 100.000 (99.872)
2025-08-27 22:07:51,619 - INFO - Epoch: [137][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.3493 (0.1912) Acc@1 88.281 (93.397) Acc@5 100.000 (99.868)
2025-08-27 22:07:52,562 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:52,562 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:53,351 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2771 (0.2771) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:07:54,188 - INFO - Epoch 137:
2025-08-27 22:07:54,189 - INFO -   Train: acc1: 93.1560 | acc5: 99.8640 | loss: 0.1975 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:07:54,189 - INFO -   Val:   acc1: 88.6200 | acc5: 99.6200 | loss: 0.3525
2025-08-27 22:07:54,189 - INFO -   LR: 0.010000
2025-08-27 22:07:54,207 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-27 22:07:54,375 - INFO - Epoch: [138][0/391] Time 0.167 (0.167) Data 0.142 (0.142) Loss 0.1731 (0.1731) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:07:56,261 - INFO - Epoch: [138][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1852 (0.1904) Acc@1 94.531 (93.487) Acc@5 99.219 (99.907)
2025-08-27 22:07:56,631 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:56,632 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:58,108 - INFO - Epoch: [138][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1809 (0.1913) Acc@1 91.406 (93.416) Acc@5 100.000 (99.868)
2025-08-27 22:07:59,557 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:07:59,558 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:07:59,935 - INFO - Epoch: [138][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2000 (0.1936) Acc@1 91.406 (93.298) Acc@5 100.000 (99.886)
2025-08-27 22:08:01,692 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3116 (0.3116) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:08:02,557 - INFO - Epoch 138:
2025-08-27 22:08:02,557 - INFO -   Train: acc1: 93.2460 | acc5: 99.8860 | loss: 0.1957 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:02,557 - INFO -   Val:   acc1: 88.6300 | acc5: 99.5800 | loss: 0.3625
2025-08-27 22:08:02,557 - INFO -   LR: 0.010000
2025-08-27 22:08:02,577 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-27 22:08:02,765 - INFO - Epoch: [139][0/391] Time 0.187 (0.187) Data 0.164 (0.164) Loss 0.3090 (0.3090) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:08:03,778 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:03,779 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:04,671 - INFO - Epoch: [139][100/391] Time 0.018 (0.021) Data 0.002 (0.004) Loss 0.2023 (0.1790) Acc@1 91.406 (93.889) Acc@5 100.000 (99.876)
2025-08-27 22:08:06,485 - INFO - Epoch: [139][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1512 (0.1839) Acc@1 93.750 (93.622) Acc@5 100.000 (99.887)
2025-08-27 22:08:06,685 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:06,685 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:08,416 - INFO - Epoch: [139][300/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.3157 (0.1862) Acc@1 88.281 (93.532) Acc@5 100.000 (99.894)
2025-08-27 22:08:09,655 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:09,655 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:10,176 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2070 (0.2070) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:08:11,019 - INFO - Epoch 139:
2025-08-27 22:08:11,019 - INFO -   Train: acc1: 93.4460 | acc5: 99.8880 | loss: 0.1902 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:11,019 - INFO -   Val:   acc1: 89.1600 | acc5: 99.5900 | loss: 0.3477
2025-08-27 22:08:11,019 - INFO -   LR: 0.010000
2025-08-27 22:08:11,036 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-27 22:08:11,193 - INFO - Epoch: [140][0/391] Time 0.156 (0.156) Data 0.137 (0.137) Loss 0.1626 (0.1626) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:08:12,996 - INFO - Epoch: [140][100/391] Time 0.015 (0.019) Data 0.005 (0.004) Loss 0.1734 (0.1781) Acc@1 95.312 (93.843) Acc@5 100.000 (99.899)
2025-08-27 22:08:13,760 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:13,764 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:14,912 - INFO - Epoch: [140][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2165 (0.1875) Acc@1 94.531 (93.517) Acc@5 99.219 (99.891)
2025-08-27 22:08:16,703 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:16,703 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:16,727 - INFO - Epoch: [140][300/391] Time 0.030 (0.019) Data 0.000 (0.003) Loss 0.1651 (0.1898) Acc@1 95.312 (93.392) Acc@5 100.000 (99.901)
2025-08-27 22:08:18,537 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.4140 (0.4140) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:08:19,385 - INFO - Epoch 140:
2025-08-27 22:08:19,385 - INFO -   Train: acc1: 93.2780 | acc5: 99.9000 | loss: 0.1923 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:19,385 - INFO -   Val:   acc1: 88.6600 | acc5: 99.5700 | loss: 0.3685
2025-08-27 22:08:19,385 - INFO -   LR: 0.010000
2025-08-27 22:08:19,436 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-27 22:08:19,626 - INFO - Epoch: [141][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.2564 (0.2564) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:08:20,884 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:20,884 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:21,449 - INFO - Epoch: [141][100/391] Time 0.022 (0.020) Data 0.001 (0.004) Loss 0.1503 (0.1870) Acc@1 95.312 (93.611) Acc@5 100.000 (99.876)
2025-08-27 22:08:23,269 - INFO - Epoch: [141][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1765 (0.1870) Acc@1 93.750 (93.544) Acc@5 100.000 (99.895)
2025-08-27 22:08:23,820 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:23,821 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:25,151 - INFO - Epoch: [141][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.1532 (0.1916) Acc@1 94.531 (93.381) Acc@5 100.000 (99.899)
2025-08-27 22:08:26,714 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:26,714 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:26,891 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.3067 (0.3067) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:08:27,788 - INFO - Epoch 141:
2025-08-27 22:08:27,788 - INFO -   Train: acc1: 93.3240 | acc5: 99.9020 | loss: 0.1941 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:27,788 - INFO -   Val:   acc1: 88.9500 | acc5: 99.6700 | loss: 0.3376
2025-08-27 22:08:27,788 - INFO -   LR: 0.010000
2025-08-27 22:08:27,805 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-27 22:08:27,990 - INFO - Epoch: [142][0/391] Time 0.184 (0.184) Data 0.164 (0.164) Loss 0.1375 (0.1375) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:08:29,885 - INFO - Epoch: [142][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.2028 (0.1878) Acc@1 92.969 (93.533) Acc@5 100.000 (99.845)
2025-08-27 22:08:30,879 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:30,879 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:31,664 - INFO - Epoch: [142][200/391] Time 0.030 (0.019) Data 0.019 (0.003) Loss 0.1567 (0.1885) Acc@1 93.750 (93.517) Acc@5 100.000 (99.864)
2025-08-27 22:08:33,517 - INFO - Epoch: [142][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1681 (0.1898) Acc@1 93.750 (93.446) Acc@5 100.000 (99.875)
2025-08-27 22:08:33,834 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:33,834 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:35,310 - INFO - Test: [0/79] Time 0.168 (0.168) Loss 0.2981 (0.2981) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:08:36,168 - INFO - Epoch 142:
2025-08-27 22:08:36,168 - INFO -   Train: acc1: 93.3560 | acc5: 99.8720 | loss: 0.1919 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:36,168 - INFO -   Val:   acc1: 88.5800 | acc5: 99.6400 | loss: 0.3494
2025-08-27 22:08:36,168 - INFO -   LR: 0.010000
2025-08-27 22:08:36,187 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-27 22:08:36,383 - INFO - Epoch: [143][0/391] Time 0.195 (0.195) Data 0.161 (0.161) Loss 0.2779 (0.2779) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:08:38,003 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:38,004 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:38,253 - INFO - Epoch: [143][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.1652 (0.1852) Acc@1 92.188 (93.410) Acc@5 100.000 (99.907)
2025-08-27 22:08:40,092 - INFO - Epoch: [143][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1352 (0.1881) Acc@1 96.094 (93.350) Acc@5 100.000 (99.883)
2025-08-27 22:08:40,910 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:40,911 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:41,952 - INFO - Epoch: [143][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1592 (0.1894) Acc@1 95.312 (93.283) Acc@5 99.219 (99.883)
2025-08-27 22:08:43,721 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3177 (0.3177) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:08:44,570 - INFO - Epoch 143:
2025-08-27 22:08:44,570 - INFO -   Train: acc1: 93.2020 | acc5: 99.8820 | loss: 0.1924 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:44,570 - INFO -   Val:   acc1: 88.5700 | acc5: 99.6000 | loss: 0.3614
2025-08-27 22:08:44,570 - INFO -   LR: 0.010000
2025-08-27 22:08:44,585 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-27 22:08:44,765 - INFO - Epoch: [144][0/391] Time 0.179 (0.179) Data 0.146 (0.146) Loss 0.2540 (0.2540) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:08:45,010 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:45,010 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:46,541 - INFO - Epoch: [144][100/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.2305 (0.1948) Acc@1 92.188 (93.216) Acc@5 99.219 (99.845)
2025-08-27 22:08:47,974 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:47,974 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:48,481 - INFO - Epoch: [144][200/391] Time 0.034 (0.019) Data 0.000 (0.004) Loss 0.2381 (0.1970) Acc@1 92.188 (93.081) Acc@5 100.000 (99.864)
2025-08-27 22:08:50,310 - INFO - Epoch: [144][300/391] Time 0.025 (0.019) Data 0.009 (0.004) Loss 0.1713 (0.2003) Acc@1 95.312 (93.065) Acc@5 100.000 (99.873)
2025-08-27 22:08:50,945 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:50,945 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:52,089 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.3175 (0.3175) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:08:52,994 - INFO - Epoch 144:
2025-08-27 22:08:52,994 - INFO -   Train: acc1: 93.1140 | acc5: 99.8620 | loss: 0.2004 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:08:52,994 - INFO -   Val:   acc1: 88.5400 | acc5: 99.5300 | loss: 0.3534
2025-08-27 22:08:52,994 - INFO -   LR: 0.010000
2025-08-27 22:08:53,011 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-27 22:08:53,202 - INFO - Epoch: [145][0/391] Time 0.190 (0.190) Data 0.162 (0.162) Loss 0.1694 (0.1694) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:08:55,032 - INFO - Epoch: [145][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.1271 (0.1780) Acc@1 96.875 (94.152) Acc@5 100.000 (99.915)
2025-08-27 22:08:55,124 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:55,124 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:56,844 - INFO - Epoch: [145][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1422 (0.1817) Acc@1 95.312 (93.789) Acc@5 100.000 (99.903)
2025-08-27 22:08:57,985 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:08:57,985 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:08:58,658 - INFO - Epoch: [145][300/391] Time 0.037 (0.019) Data 0.025 (0.003) Loss 0.1515 (0.1903) Acc@1 94.531 (93.462) Acc@5 100.000 (99.886)
2025-08-27 22:09:00,396 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3114 (0.3114) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:09:01,259 - INFO - Epoch 145:
2025-08-27 22:09:01,259 - INFO -   Train: acc1: 93.3280 | acc5: 99.8900 | loss: 0.1931 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:01,259 - INFO -   Val:   acc1: 88.0000 | acc5: 99.5300 | loss: 0.3961
2025-08-27 22:09:01,259 - INFO -   LR: 0.010000
2025-08-27 22:09:01,275 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-27 22:09:01,422 - INFO - Epoch: [146][0/391] Time 0.146 (0.146) Data 0.127 (0.127) Loss 0.2106 (0.2106) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:09:02,032 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:02,032 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:03,274 - INFO - Epoch: [146][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1544 (0.1784) Acc@1 94.531 (94.021) Acc@5 100.000 (99.907)
2025-08-27 22:09:04,981 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:04,981 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:05,096 - INFO - Epoch: [146][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1540 (0.1858) Acc@1 92.969 (93.528) Acc@5 100.000 (99.895)
2025-08-27 22:09:06,883 - INFO - Epoch: [146][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1839 (0.1882) Acc@1 94.531 (93.384) Acc@5 100.000 (99.899)
2025-08-27 22:09:07,845 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:07,846 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:08,668 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3244 (0.3244) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:09:09,519 - INFO - Epoch 146:
2025-08-27 22:09:09,519 - INFO -   Train: acc1: 93.3320 | acc5: 99.9060 | loss: 0.1898 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:09,519 - INFO -   Val:   acc1: 88.9100 | acc5: 99.6100 | loss: 0.3464
2025-08-27 22:09:09,519 - INFO -   LR: 0.010000
2025-08-27 22:09:09,537 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-27 22:09:09,724 - INFO - Epoch: [147][0/391] Time 0.186 (0.186) Data 0.160 (0.160) Loss 0.0947 (0.0947) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:09:11,520 - INFO - Epoch: [147][100/391] Time 0.032 (0.020) Data 0.022 (0.005) Loss 0.1740 (0.1842) Acc@1 93.750 (93.417) Acc@5 100.000 (99.892)
2025-08-27 22:09:11,948 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:11,948 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:13,402 - INFO - Epoch: [147][200/391] Time 0.013 (0.019) Data 0.000 (0.005) Loss 0.2652 (0.1931) Acc@1 92.969 (93.116) Acc@5 99.219 (99.876)
2025-08-27 22:09:14,928 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:14,928 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:15,262 - INFO - Epoch: [147][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1883 (0.1946) Acc@1 94.531 (93.122) Acc@5 100.000 (99.883)
2025-08-27 22:09:17,013 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3622 (0.3622) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:09:17,842 - INFO - Epoch 147:
2025-08-27 22:09:17,842 - INFO -   Train: acc1: 93.1200 | acc5: 99.8920 | loss: 0.1949 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:17,842 - INFO -   Val:   acc1: 88.5000 | acc5: 99.6400 | loss: 0.3642
2025-08-27 22:09:17,842 - INFO -   LR: 0.010000
2025-08-27 22:09:17,862 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-27 22:09:18,060 - INFO - Epoch: [148][0/391] Time 0.198 (0.198) Data 0.169 (0.169) Loss 0.1794 (0.1794) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:09:19,040 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:19,041 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:19,949 - INFO - Epoch: [148][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.2298 (0.1816) Acc@1 91.406 (93.588) Acc@5 100.000 (99.915)
2025-08-27 22:09:21,778 - INFO - Epoch: [148][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1777 (0.1839) Acc@1 92.969 (93.622) Acc@5 100.000 (99.876)
2025-08-27 22:09:21,977 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:21,977 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:23,588 - INFO - Epoch: [148][300/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.1817 (0.1896) Acc@1 94.531 (93.293) Acc@5 100.000 (99.883)
2025-08-27 22:09:24,895 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:24,895 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:25,391 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3783 (0.3783) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:09:26,239 - INFO - Epoch 148:
2025-08-27 22:09:26,239 - INFO -   Train: acc1: 93.2860 | acc5: 99.8740 | loss: 0.1911 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:26,240 - INFO -   Val:   acc1: 88.6900 | acc5: 99.5400 | loss: 0.3555
2025-08-27 22:09:26,240 - INFO -   LR: 0.010000
2025-08-27 22:09:26,259 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-27 22:09:26,413 - INFO - Epoch: [149][0/391] Time 0.153 (0.153) Data 0.129 (0.129) Loss 0.2228 (0.2228) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:09:28,257 - INFO - Epoch: [149][100/391] Time 0.020 (0.020) Data 0.006 (0.003) Loss 0.2525 (0.1833) Acc@1 92.188 (93.796) Acc@5 100.000 (99.876)
2025-08-27 22:09:28,966 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:28,966 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:30,102 - INFO - Epoch: [149][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2312 (0.1896) Acc@1 90.625 (93.427) Acc@5 100.000 (99.880)
2025-08-27 22:09:31,987 - INFO - Epoch: [149][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2052 (0.1920) Acc@1 92.188 (93.275) Acc@5 99.219 (99.881)
2025-08-27 22:09:31,994 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:31,994 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:33,813 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.2705 (0.2705) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:09:34,678 - INFO - Epoch 149:
2025-08-27 22:09:34,679 - INFO -   Train: acc1: 93.2580 | acc5: 99.8780 | loss: 0.1919 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:34,679 - INFO -   Val:   acc1: 88.2000 | acc5: 99.7300 | loss: 0.3524
2025-08-27 22:09:34,679 - INFO -   LR: 0.001000
2025-08-27 22:09:34,699 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-27 22:09:34,872 - INFO - Epoch: [150][0/391] Time 0.172 (0.172) Data 0.149 (0.149) Loss 0.1956 (0.1956) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:09:36,203 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:36,203 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:36,758 - INFO - Epoch: [150][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.1486 (0.1630) Acc@1 93.750 (94.454) Acc@5 100.000 (99.915)
2025-08-27 22:09:38,595 - INFO - Epoch: [150][200/391] Time 0.024 (0.019) Data 0.012 (0.003) Loss 0.1190 (0.1558) Acc@1 96.094 (94.803) Acc@5 100.000 (99.934)
2025-08-27 22:09:39,107 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:39,107 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:40,429 - INFO - Epoch: [150][300/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.1539 (0.1530) Acc@1 94.531 (94.887) Acc@5 100.000 (99.945)
2025-08-27 22:09:42,105 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:42,106 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:42,282 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2124 (0.2124) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:09:43,182 - INFO - Epoch 150:
2025-08-27 22:09:43,182 - INFO -   Train: acc1: 94.9860 | acc5: 99.9440 | loss: 0.1502 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:43,182 - INFO -   Val:   acc1: 90.8100 | acc5: 99.7300 | loss: 0.2812
2025-08-27 22:09:43,182 - INFO -   LR: 0.001000
2025-08-27 22:09:43,236 - INFO - Checkpoint saved: epoch=150, metric=90.8100
2025-08-27 22:09:43,268 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-27 22:09:43,441 - INFO - Epoch: [151][0/391] Time 0.170 (0.170) Data 0.154 (0.154) Loss 0.1254 (0.1254) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:09:45,320 - INFO - Epoch: [151][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0984 (0.1262) Acc@1 96.094 (95.862) Acc@5 100.000 (99.992)
2025-08-27 22:09:46,475 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:46,476 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:47,191 - INFO - Epoch: [151][200/391] Time 0.023 (0.019) Data 0.011 (0.003) Loss 0.2302 (0.1307) Acc@1 89.844 (95.794) Acc@5 100.000 (99.969)
2025-08-27 22:09:49,044 - INFO - Epoch: [151][300/391] Time 0.040 (0.019) Data 0.026 (0.003) Loss 0.0837 (0.1314) Acc@1 96.875 (95.671) Acc@5 100.000 (99.953)
2025-08-27 22:09:49,368 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:49,369 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:50,846 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2271 (0.2271) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:09:51,670 - INFO - Epoch 151:
2025-08-27 22:09:51,670 - INFO -   Train: acc1: 95.6420 | acc5: 99.9500 | loss: 0.1316 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:51,670 - INFO -   Val:   acc1: 90.9200 | acc5: 99.7000 | loss: 0.2812
2025-08-27 22:09:51,670 - INFO -   LR: 0.001000
2025-08-27 22:09:51,721 - INFO - Checkpoint saved: epoch=151, metric=90.9200
2025-08-27 22:09:51,755 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-27 22:09:51,957 - INFO - Epoch: [152][0/391] Time 0.201 (0.201) Data 0.176 (0.176) Loss 0.1937 (0.1937) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:09:53,540 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:53,540 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:53,743 - INFO - Epoch: [152][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1102 (0.1316) Acc@1 96.875 (95.622) Acc@5 100.000 (99.915)
2025-08-27 22:09:55,554 - INFO - Epoch: [152][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.0624 (0.1285) Acc@1 98.438 (95.775) Acc@5 100.000 (99.926)
2025-08-27 22:09:56,418 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:09:56,418 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:09:57,398 - INFO - Epoch: [152][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.0978 (0.1293) Acc@1 96.094 (95.720) Acc@5 100.000 (99.935)
2025-08-27 22:09:59,095 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2470 (0.2470) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:09:59,954 - INFO - Epoch 152:
2025-08-27 22:09:59,954 - INFO -   Train: acc1: 95.6920 | acc5: 99.9380 | loss: 0.1295 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:09:59,954 - INFO -   Val:   acc1: 90.9100 | acc5: 99.7600 | loss: 0.2807
2025-08-27 22:09:59,954 - INFO -   LR: 0.001000
2025-08-27 22:09:59,972 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-27 22:10:00,163 - INFO - Epoch: [153][0/391] Time 0.190 (0.190) Data 0.170 (0.170) Loss 0.1751 (0.1751) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:10:00,465 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:00,465 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:01,938 - INFO - Epoch: [153][100/391] Time 0.028 (0.019) Data 0.017 (0.004) Loss 0.1537 (0.1248) Acc@1 93.750 (95.924) Acc@5 100.000 (99.938)
2025-08-27 22:10:03,309 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:03,309 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:03,665 - INFO - Epoch: [153][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1229 (0.1244) Acc@1 97.656 (95.938) Acc@5 100.000 (99.934)
2025-08-27 22:10:05,447 - INFO - Epoch: [153][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1076 (0.1224) Acc@1 96.094 (96.091) Acc@5 100.000 (99.940)
2025-08-27 22:10:06,169 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:06,170 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:07,270 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2387 (0.2387) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:10:08,101 - INFO - Epoch 153:
2025-08-27 22:10:08,101 - INFO -   Train: acc1: 96.0600 | acc5: 99.9440 | loss: 0.1221 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:08,101 - INFO -   Val:   acc1: 90.8200 | acc5: 99.7500 | loss: 0.2792
2025-08-27 22:10:08,101 - INFO -   LR: 0.001000
2025-08-27 22:10:08,120 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-27 22:10:08,288 - INFO - Epoch: [154][0/391] Time 0.167 (0.167) Data 0.144 (0.144) Loss 0.1367 (0.1367) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:10:10,108 - INFO - Epoch: [154][100/391] Time 0.027 (0.020) Data 0.000 (0.003) Loss 0.1219 (0.1196) Acc@1 96.094 (95.993) Acc@5 100.000 (99.954)
2025-08-27 22:10:10,188 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:10,188 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:11,986 - INFO - Epoch: [154][200/391] Time 0.022 (0.019) Data 0.007 (0.002) Loss 0.1863 (0.1230) Acc@1 94.531 (95.931) Acc@5 100.000 (99.965)
2025-08-27 22:10:13,132 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:13,132 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:13,783 - INFO - Epoch: [154][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.1232 (0.1215) Acc@1 95.312 (96.024) Acc@5 100.000 (99.958)
2025-08-27 22:10:15,583 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2299 (0.2299) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:10:16,435 - INFO - Epoch 154:
2025-08-27 22:10:16,435 - INFO -   Train: acc1: 96.0240 | acc5: 99.9560 | loss: 0.1212 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:16,435 - INFO -   Val:   acc1: 90.7700 | acc5: 99.7600 | loss: 0.2815
2025-08-27 22:10:16,435 - INFO -   LR: 0.001000
2025-08-27 22:10:16,452 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-27 22:10:16,637 - INFO - Epoch: [155][0/391] Time 0.184 (0.184) Data 0.167 (0.167) Loss 0.1124 (0.1124) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:10:17,280 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:17,281 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:18,510 - INFO - Epoch: [155][100/391] Time 0.024 (0.020) Data 0.005 (0.004) Loss 0.0757 (0.1155) Acc@1 98.438 (96.140) Acc@5 100.000 (99.946)
2025-08-27 22:10:20,283 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:20,284 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:20,377 - INFO - Epoch: [155][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1634 (0.1160) Acc@1 93.750 (96.265) Acc@5 100.000 (99.965)
2025-08-27 22:10:22,242 - INFO - Epoch: [155][300/391] Time 0.021 (0.019) Data 0.010 (0.003) Loss 0.0921 (0.1173) Acc@1 96.875 (96.164) Acc@5 100.000 (99.966)
2025-08-27 22:10:23,277 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:23,277 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:24,167 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.2562 (0.2562) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:10:25,061 - INFO - Epoch 155:
2025-08-27 22:10:25,061 - INFO -   Train: acc1: 96.1400 | acc5: 99.9720 | loss: 0.1178 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:25,061 - INFO -   Val:   acc1: 90.9400 | acc5: 99.7800 | loss: 0.2829
2025-08-27 22:10:25,061 - INFO -   LR: 0.001000
2025-08-27 22:10:25,113 - INFO - Checkpoint saved: epoch=155, metric=90.9400
2025-08-27 22:10:25,143 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-27 22:10:25,310 - INFO - Epoch: [156][0/391] Time 0.166 (0.166) Data 0.140 (0.140) Loss 0.1071 (0.1071) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:10:27,195 - INFO - Epoch: [156][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1374 (0.1173) Acc@1 97.656 (96.171) Acc@5 100.000 (99.954)
2025-08-27 22:10:27,630 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:27,630 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:29,043 - INFO - Epoch: [156][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1022 (0.1138) Acc@1 95.312 (96.393) Acc@5 100.000 (99.949)
2025-08-27 22:10:30,623 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:30,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:30,950 - INFO - Epoch: [156][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.1118 (0.1163) Acc@1 96.094 (96.213) Acc@5 100.000 (99.953)
2025-08-27 22:10:32,692 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2409 (0.2409) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:10:33,522 - INFO - Epoch 156:
2025-08-27 22:10:33,523 - INFO -   Train: acc1: 96.2820 | acc5: 99.9500 | loss: 0.1157 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:33,523 - INFO -   Val:   acc1: 90.6500 | acc5: 99.7700 | loss: 0.2842
2025-08-27 22:10:33,523 - INFO -   LR: 0.001000
2025-08-27 22:10:33,539 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-27 22:10:33,718 - INFO - Epoch: [157][0/391] Time 0.178 (0.178) Data 0.148 (0.148) Loss 0.1331 (0.1331) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:10:34,662 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:34,663 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:35,524 - INFO - Epoch: [157][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.0583 (0.1158) Acc@1 99.219 (96.287) Acc@5 100.000 (99.946)
2025-08-27 22:10:37,389 - INFO - Epoch: [157][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0906 (0.1174) Acc@1 96.875 (96.284) Acc@5 100.000 (99.961)
2025-08-27 22:10:37,609 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:37,609 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:39,188 - INFO - Epoch: [157][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1400 (0.1160) Acc@1 94.531 (96.348) Acc@5 100.000 (99.956)
2025-08-27 22:10:40,505 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:40,505 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:40,907 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.2514 (0.2514) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:10:41,772 - INFO - Epoch 157:
2025-08-27 22:10:41,772 - INFO -   Train: acc1: 96.3420 | acc5: 99.9580 | loss: 0.1149 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:41,772 - INFO -   Val:   acc1: 90.6900 | acc5: 99.7700 | loss: 0.2857
2025-08-27 22:10:41,772 - INFO -   LR: 0.001000
2025-08-27 22:10:41,793 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-27 22:10:41,966 - INFO - Epoch: [158][0/391] Time 0.172 (0.172) Data 0.148 (0.148) Loss 0.0847 (0.0847) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:10:43,768 - INFO - Epoch: [158][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1093 (0.1180) Acc@1 98.438 (96.334) Acc@5 100.000 (99.938)
2025-08-27 22:10:44,511 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:44,511 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:45,510 - INFO - Epoch: [158][200/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.0943 (0.1155) Acc@1 98.438 (96.273) Acc@5 100.000 (99.953)
2025-08-27 22:10:47,285 - INFO - Epoch: [158][300/391] Time 0.020 (0.018) Data 0.009 (0.003) Loss 0.0956 (0.1129) Acc@1 96.094 (96.361) Acc@5 100.000 (99.964)
2025-08-27 22:10:47,303 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:47,303 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:49,005 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2460 (0.2460) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:10:49,812 - INFO - Epoch 158:
2025-08-27 22:10:49,813 - INFO -   Train: acc1: 96.3280 | acc5: 99.9640 | loss: 0.1133 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:49,813 - INFO -   Val:   acc1: 90.8500 | acc5: 99.7800 | loss: 0.2852
2025-08-27 22:10:49,813 - INFO -   LR: 0.001000
2025-08-27 22:10:49,832 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-27 22:10:50,017 - INFO - Epoch: [159][0/391] Time 0.184 (0.184) Data 0.154 (0.154) Loss 0.1417 (0.1417) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-27 22:10:51,383 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:51,383 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:51,958 - INFO - Epoch: [159][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1206 (0.1137) Acc@1 96.094 (96.334) Acc@5 100.000 (99.907)
2025-08-27 22:10:53,800 - INFO - Epoch: [159][200/391] Time 0.019 (0.020) Data 0.008 (0.003) Loss 0.0532 (0.1121) Acc@1 98.438 (96.393) Acc@5 100.000 (99.946)
2025-08-27 22:10:54,386 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:54,386 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:55,574 - INFO - Epoch: [159][300/391] Time 0.020 (0.019) Data 0.009 (0.003) Loss 0.1185 (0.1123) Acc@1 95.312 (96.333) Acc@5 100.000 (99.953)
2025-08-27 22:10:57,310 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2686 (0.2686) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:10:58,137 - INFO - Epoch 159:
2025-08-27 22:10:58,137 - INFO -   Train: acc1: 96.3120 | acc5: 99.9600 | loss: 0.1125 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:10:58,137 - INFO -   Val:   acc1: 90.6700 | acc5: 99.7900 | loss: 0.2873
2025-08-27 22:10:58,137 - INFO -   LR: 0.001000
2025-08-27 22:10:58,155 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-27 22:10:58,317 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:10:58,317 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:10:58,337 - INFO - Epoch: [160][0/391] Time 0.181 (0.181) Data 0.154 (0.154) Loss 0.0729 (0.0729) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:11:00,151 - INFO - Epoch: [160][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0785 (0.1059) Acc@1 97.656 (96.821) Acc@5 100.000 (99.938)
2025-08-27 22:11:01,338 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:01,338 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:02,021 - INFO - Epoch: [160][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1448 (0.1110) Acc@1 93.750 (96.595) Acc@5 100.000 (99.949)
2025-08-27 22:11:03,903 - INFO - Epoch: [160][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.1044 (0.1119) Acc@1 98.438 (96.457) Acc@5 99.219 (99.951)
2025-08-27 22:11:04,216 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:04,216 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:05,572 - INFO - Test: [0/79] Time 0.103 (0.103) Loss 0.2608 (0.2608) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:11:06,435 - INFO - Epoch 160:
2025-08-27 22:11:06,435 - INFO -   Train: acc1: 96.4800 | acc5: 99.9600 | loss: 0.1110 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:06,435 - INFO -   Val:   acc1: 90.7400 | acc5: 99.7900 | loss: 0.2872
2025-08-27 22:11:06,435 - INFO -   LR: 0.001000
2025-08-27 22:11:06,486 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-27 22:11:06,645 - INFO - Epoch: [161][0/391] Time 0.157 (0.157) Data 0.137 (0.137) Loss 0.1230 (0.1230) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:11:08,224 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:08,225 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:08,443 - INFO - Epoch: [161][100/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1036 (0.1073) Acc@1 96.875 (96.434) Acc@5 100.000 (99.977)
2025-08-27 22:11:10,266 - INFO - Epoch: [161][200/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.0661 (0.1082) Acc@1 99.219 (96.428) Acc@5 100.000 (99.961)
2025-08-27 22:11:11,104 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:11,104 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:12,039 - INFO - Epoch: [161][300/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.0940 (0.1094) Acc@1 96.094 (96.423) Acc@5 100.000 (99.958)
2025-08-27 22:11:13,829 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2451 (0.2451) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:11:14,678 - INFO - Epoch 161:
2025-08-27 22:11:14,678 - INFO -   Train: acc1: 96.4180 | acc5: 99.9600 | loss: 0.1096 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:14,678 - INFO -   Val:   acc1: 90.8900 | acc5: 99.7800 | loss: 0.2889
2025-08-27 22:11:14,678 - INFO -   LR: 0.001000
2025-08-27 22:11:14,698 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-27 22:11:14,878 - INFO - Epoch: [162][0/391] Time 0.180 (0.180) Data 0.155 (0.155) Loss 0.0749 (0.0749) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:11:15,152 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:15,152 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:16,666 - INFO - Epoch: [162][100/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.1014 (0.0995) Acc@1 97.656 (96.906) Acc@5 100.000 (99.961)
2025-08-27 22:11:18,028 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:18,028 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:18,410 - INFO - Epoch: [162][200/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.0939 (0.1020) Acc@1 97.656 (96.723) Acc@5 100.000 (99.961)
2025-08-27 22:11:20,210 - INFO - Epoch: [162][300/391] Time 0.018 (0.018) Data 0.000 (0.003) Loss 0.1000 (0.1048) Acc@1 98.438 (96.628) Acc@5 100.000 (99.969)
2025-08-27 22:11:20,857 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:20,857 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:21,922 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2522 (0.2522) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:11:22,806 - INFO - Epoch 162:
2025-08-27 22:11:22,806 - INFO -   Train: acc1: 96.5880 | acc5: 99.9640 | loss: 0.1063 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:22,806 - INFO -   Val:   acc1: 90.8600 | acc5: 99.7500 | loss: 0.2865
2025-08-27 22:11:22,806 - INFO -   LR: 0.001000
2025-08-27 22:11:22,823 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-27 22:11:22,995 - INFO - Epoch: [163][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 0.1001 (0.1001) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:11:24,817 - INFO - Epoch: [163][100/391] Time 0.022 (0.020) Data 0.001 (0.004) Loss 0.0685 (0.1047) Acc@1 99.219 (96.589) Acc@5 100.000 (99.961)
2025-08-27 22:11:24,926 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:24,926 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:26,621 - INFO - Epoch: [163][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0768 (0.1053) Acc@1 99.219 (96.580) Acc@5 100.000 (99.969)
2025-08-27 22:11:27,897 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:27,897 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:28,499 - INFO - Epoch: [163][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.0959 (0.1079) Acc@1 96.094 (96.506) Acc@5 100.000 (99.969)
2025-08-27 22:11:30,258 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2647 (0.2647) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:11:31,104 - INFO - Epoch 163:
2025-08-27 22:11:31,104 - INFO -   Train: acc1: 96.5280 | acc5: 99.9680 | loss: 0.1085 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:31,104 - INFO -   Val:   acc1: 90.7300 | acc5: 99.7400 | loss: 0.2869
2025-08-27 22:11:31,104 - INFO -   LR: 0.001000
2025-08-27 22:11:31,124 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-27 22:11:31,310 - INFO - Epoch: [164][0/391] Time 0.185 (0.185) Data 0.157 (0.157) Loss 0.1595 (0.1595) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:11:31,989 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:31,989 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:33,190 - INFO - Epoch: [164][100/391] Time 0.028 (0.020) Data 0.009 (0.004) Loss 0.1088 (0.1076) Acc@1 96.094 (96.573) Acc@5 100.000 (99.961)
2025-08-27 22:11:34,900 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:34,900 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:34,977 - INFO - Epoch: [164][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0838 (0.1070) Acc@1 96.875 (96.479) Acc@5 100.000 (99.965)
2025-08-27 22:11:36,805 - INFO - Epoch: [164][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1067 (0.1046) Acc@1 96.094 (96.595) Acc@5 100.000 (99.969)
2025-08-27 22:11:37,912 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:37,913 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:38,661 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.2550 (0.2550) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:11:39,532 - INFO - Epoch 164:
2025-08-27 22:11:39,532 - INFO -   Train: acc1: 96.5900 | acc5: 99.9680 | loss: 0.1045 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:39,532 - INFO -   Val:   acc1: 90.7000 | acc5: 99.7500 | loss: 0.2862
2025-08-27 22:11:39,533 - INFO -   LR: 0.001000
2025-08-27 22:11:39,552 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-27 22:11:39,721 - INFO - Epoch: [165][0/391] Time 0.168 (0.168) Data 0.149 (0.149) Loss 0.1602 (0.1602) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:11:41,566 - INFO - Epoch: [165][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.0742 (0.1089) Acc@1 96.875 (96.411) Acc@5 100.000 (99.969)
2025-08-27 22:11:42,016 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:42,017 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:43,430 - INFO - Epoch: [165][200/391] Time 0.044 (0.019) Data 0.018 (0.002) Loss 0.0754 (0.1054) Acc@1 99.219 (96.622) Acc@5 100.000 (99.977)
2025-08-27 22:11:44,898 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:44,898 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:45,164 - INFO - Epoch: [165][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.1277 (0.1065) Acc@1 96.875 (96.574) Acc@5 100.000 (99.969)
2025-08-27 22:11:46,958 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2804 (0.2804) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:11:47,788 - INFO - Epoch 165:
2025-08-27 22:11:47,788 - INFO -   Train: acc1: 96.5900 | acc5: 99.9640 | loss: 0.1064 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:47,788 - INFO -   Val:   acc1: 90.7500 | acc5: 99.7700 | loss: 0.2917
2025-08-27 22:11:47,788 - INFO -   LR: 0.001000
2025-08-27 22:11:47,806 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-27 22:11:47,970 - INFO - Epoch: [166][0/391] Time 0.163 (0.163) Data 0.136 (0.136) Loss 0.1235 (0.1235) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:11:49,088 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:49,088 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:49,958 - INFO - Epoch: [166][100/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.0685 (0.0994) Acc@1 98.438 (96.743) Acc@5 100.000 (99.969)
2025-08-27 22:11:51,744 - INFO - Epoch: [166][200/391] Time 0.040 (0.020) Data 0.026 (0.003) Loss 0.1094 (0.1011) Acc@1 96.875 (96.774) Acc@5 100.000 (99.961)
2025-08-27 22:11:51,996 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:51,996 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:53,665 - INFO - Epoch: [166][300/391] Time 0.033 (0.019) Data 0.021 (0.003) Loss 0.0679 (0.1022) Acc@1 98.438 (96.727) Acc@5 100.000 (99.956)
2025-08-27 22:11:55,046 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:55,047 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:11:55,482 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2716 (0.2716) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:11:56,302 - INFO - Epoch 166:
2025-08-27 22:11:56,303 - INFO -   Train: acc1: 96.6800 | acc5: 99.9560 | loss: 0.1038 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:11:56,303 - INFO -   Val:   acc1: 90.7800 | acc5: 99.7500 | loss: 0.2931
2025-08-27 22:11:56,303 - INFO -   LR: 0.001000
2025-08-27 22:11:56,322 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-27 22:11:56,530 - INFO - Epoch: [167][0/391] Time 0.208 (0.208) Data 0.182 (0.182) Loss 0.0650 (0.0650) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:11:58,399 - INFO - Epoch: [167][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1097 (0.1022) Acc@1 96.875 (96.705) Acc@5 100.000 (99.938)
2025-08-27 22:11:59,190 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:11:59,190 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:00,239 - INFO - Epoch: [167][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.0682 (0.1025) Acc@1 98.438 (96.650) Acc@5 100.000 (99.946)
2025-08-27 22:12:02,072 - INFO - Epoch: [167][300/391] Time 0.040 (0.019) Data 0.000 (0.003) Loss 0.0938 (0.1039) Acc@1 97.656 (96.610) Acc@5 100.000 (99.943)
2025-08-27 22:12:02,112 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:02,112 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:03,862 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2542 (0.2542) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:12:04,669 - INFO - Epoch 167:
2025-08-27 22:12:04,669 - INFO -   Train: acc1: 96.6680 | acc5: 99.9480 | loss: 0.1028 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:04,669 - INFO -   Val:   acc1: 90.6900 | acc5: 99.7600 | loss: 0.2934
2025-08-27 22:12:04,669 - INFO -   LR: 0.001000
2025-08-27 22:12:04,691 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-27 22:12:04,876 - INFO - Epoch: [168][0/391] Time 0.184 (0.184) Data 0.160 (0.160) Loss 0.1664 (0.1664) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:12:06,179 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:06,180 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:06,745 - INFO - Epoch: [168][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.0639 (0.1022) Acc@1 96.875 (96.860) Acc@5 100.000 (99.930)
2025-08-27 22:12:08,570 - INFO - Epoch: [168][200/391] Time 0.041 (0.019) Data 0.000 (0.003) Loss 0.1282 (0.1058) Acc@1 95.312 (96.615) Acc@5 100.000 (99.946)
2025-08-27 22:12:09,095 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:09,095 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:10,327 - INFO - Epoch: [168][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1100 (0.1046) Acc@1 96.094 (96.639) Acc@5 100.000 (99.953)
2025-08-27 22:12:12,072 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2613 (0.2613) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:12:12,899 - INFO - Epoch 168:
2025-08-27 22:12:12,899 - INFO -   Train: acc1: 96.6100 | acc5: 99.9600 | loss: 0.1052 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:12,899 - INFO -   Val:   acc1: 90.9000 | acc5: 99.7300 | loss: 0.2904
2025-08-27 22:12:12,899 - INFO -   LR: 0.001000
2025-08-27 22:12:12,918 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-27 22:12:13,084 - INFO - Epoch: [169][0/391] Time 0.165 (0.165) Data 0.136 (0.136) Loss 0.0884 (0.0884) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:12:13,091 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:13,106 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:14,882 - INFO - Epoch: [169][100/391] Time 0.030 (0.019) Data 0.016 (0.004) Loss 0.0687 (0.0977) Acc@1 97.656 (96.798) Acc@5 100.000 (99.969)
2025-08-27 22:12:15,981 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:15,981 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:16,792 - INFO - Epoch: [169][200/391] Time 0.030 (0.019) Data 0.017 (0.003) Loss 0.0901 (0.1006) Acc@1 95.312 (96.657) Acc@5 100.000 (99.961)
2025-08-27 22:12:18,676 - INFO - Epoch: [169][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.0866 (0.1001) Acc@1 96.875 (96.704) Acc@5 100.000 (99.969)
2025-08-27 22:12:19,002 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:19,003 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:20,456 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2845 (0.2845) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:12:21,306 - INFO - Epoch 169:
2025-08-27 22:12:21,306 - INFO -   Train: acc1: 96.7060 | acc5: 99.9660 | loss: 0.1009 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:21,306 - INFO -   Val:   acc1: 90.8600 | acc5: 99.7100 | loss: 0.2927
2025-08-27 22:12:21,306 - INFO -   LR: 0.001000
2025-08-27 22:12:21,324 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-27 22:12:21,501 - INFO - Epoch: [170][0/391] Time 0.176 (0.176) Data 0.158 (0.158) Loss 0.1112 (0.1112) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:12:23,177 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:23,178 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:23,387 - INFO - Epoch: [170][100/391] Time 0.019 (0.020) Data 0.005 (0.003) Loss 0.0658 (0.1007) Acc@1 99.219 (96.852) Acc@5 100.000 (99.969)
2025-08-27 22:12:25,159 - INFO - Epoch: [170][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.1110 (0.1022) Acc@1 96.875 (96.727) Acc@5 100.000 (99.973)
2025-08-27 22:12:26,086 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:26,086 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:27,126 - INFO - Epoch: [170][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1088 (0.1026) Acc@1 96.094 (96.678) Acc@5 99.219 (99.974)
2025-08-27 22:12:28,904 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2858 (0.2858) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:12:29,775 - INFO - Epoch 170:
2025-08-27 22:12:29,775 - INFO -   Train: acc1: 96.6860 | acc5: 99.9720 | loss: 0.1020 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:29,775 - INFO -   Val:   acc1: 90.7100 | acc5: 99.7300 | loss: 0.2931
2025-08-27 22:12:29,775 - INFO -   LR: 0.001000
2025-08-27 22:12:29,828 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-27 22:12:30,036 - INFO - Epoch: [171][0/391] Time 0.207 (0.207) Data 0.173 (0.173) Loss 0.0866 (0.0866) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:12:30,428 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:30,428 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:31,903 - INFO - Epoch: [171][100/391] Time 0.021 (0.021) Data 0.000 (0.005) Loss 0.1267 (0.0961) Acc@1 95.312 (96.852) Acc@5 100.000 (99.961)
2025-08-27 22:12:33,338 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:33,338 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:33,702 - INFO - Epoch: [171][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1436 (0.0980) Acc@1 96.094 (96.836) Acc@5 100.000 (99.953)
2025-08-27 22:12:35,559 - INFO - Epoch: [171][300/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.0756 (0.0975) Acc@1 97.656 (96.859) Acc@5 100.000 (99.961)
2025-08-27 22:12:36,259 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:36,260 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:37,357 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2784 (0.2784) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:12:38,201 - INFO - Epoch 171:
2025-08-27 22:12:38,201 - INFO -   Train: acc1: 96.8420 | acc5: 99.9640 | loss: 0.0974 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:38,201 - INFO -   Val:   acc1: 90.7900 | acc5: 99.7100 | loss: 0.2973
2025-08-27 22:12:38,202 - INFO -   LR: 0.001000
2025-08-27 22:12:38,220 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-27 22:12:38,403 - INFO - Epoch: [172][0/391] Time 0.181 (0.181) Data 0.164 (0.164) Loss 0.1176 (0.1176) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:12:40,207 - INFO - Epoch: [172][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1057 (0.0974) Acc@1 97.656 (96.883) Acc@5 100.000 (99.946)
2025-08-27 22:12:40,354 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:40,354 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:42,010 - INFO - Epoch: [172][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.0781 (0.0960) Acc@1 97.656 (96.968) Acc@5 100.000 (99.969)
2025-08-27 22:12:43,206 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:43,206 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:43,816 - INFO - Epoch: [172][300/391] Time 0.030 (0.019) Data 0.010 (0.003) Loss 0.0602 (0.0974) Acc@1 98.438 (96.906) Acc@5 100.000 (99.961)
2025-08-27 22:12:45,624 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2581 (0.2581) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:12:46,461 - INFO - Epoch 172:
2025-08-27 22:12:46,461 - INFO -   Train: acc1: 96.9080 | acc5: 99.9680 | loss: 0.0970 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:46,461 - INFO -   Val:   acc1: 90.8000 | acc5: 99.7300 | loss: 0.2929
2025-08-27 22:12:46,461 - INFO -   LR: 0.001000
2025-08-27 22:12:46,478 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-27 22:12:46,684 - INFO - Epoch: [173][0/391] Time 0.205 (0.205) Data 0.149 (0.149) Loss 0.1388 (0.1388) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:12:47,311 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:47,312 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:48,489 - INFO - Epoch: [173][100/391] Time 0.025 (0.020) Data 0.000 (0.005) Loss 0.1309 (0.0977) Acc@1 95.312 (96.790) Acc@5 100.000 (99.954)
2025-08-27 22:12:50,268 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:50,269 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:50,321 - INFO - Epoch: [173][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.0815 (0.0973) Acc@1 97.656 (96.883) Acc@5 100.000 (99.961)
2025-08-27 22:12:52,136 - INFO - Epoch: [173][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1125 (0.0988) Acc@1 96.875 (96.795) Acc@5 100.000 (99.964)
2025-08-27 22:12:53,172 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:53,172 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:53,944 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2920 (0.2920) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:12:54,779 - INFO - Epoch 173:
2025-08-27 22:12:54,779 - INFO -   Train: acc1: 96.7540 | acc5: 99.9640 | loss: 0.0999 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:12:54,779 - INFO -   Val:   acc1: 90.6800 | acc5: 99.7300 | loss: 0.2937
2025-08-27 22:12:54,779 - INFO -   LR: 0.001000
2025-08-27 22:12:54,799 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-27 22:12:54,958 - INFO - Epoch: [174][0/391] Time 0.159 (0.159) Data 0.137 (0.137) Loss 0.0607 (0.0607) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:12:56,776 - INFO - Epoch: [174][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.0924 (0.0958) Acc@1 98.438 (96.929) Acc@5 100.000 (99.985)
2025-08-27 22:12:57,305 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:12:57,305 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:12:58,713 - INFO - Epoch: [174][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1000 (0.0974) Acc@1 96.094 (96.848) Acc@5 100.000 (99.977)
2025-08-27 22:13:00,252 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:00,252 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:00,519 - INFO - Epoch: [174][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0621 (0.0983) Acc@1 99.219 (96.782) Acc@5 100.000 (99.977)
2025-08-27 22:13:02,324 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.2782 (0.2782) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:13:03,177 - INFO - Epoch 174:
2025-08-27 22:13:03,177 - INFO -   Train: acc1: 96.7540 | acc5: 99.9720 | loss: 0.0987 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:03,177 - INFO -   Val:   acc1: 90.6200 | acc5: 99.7500 | loss: 0.2951
2025-08-27 22:13:03,177 - INFO -   LR: 0.001000
2025-08-27 22:13:03,195 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-27 22:13:03,399 - INFO - Epoch: [175][0/391] Time 0.203 (0.203) Data 0.167 (0.167) Loss 0.0749 (0.0749) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:13:04,351 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:04,352 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:05,144 - INFO - Epoch: [175][100/391] Time 0.030 (0.019) Data 0.000 (0.004) Loss 0.1140 (0.0946) Acc@1 96.094 (97.138) Acc@5 100.000 (99.961)
2025-08-27 22:13:07,034 - INFO - Epoch: [175][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.0695 (0.0945) Acc@1 99.219 (97.132) Acc@5 100.000 (99.957)
2025-08-27 22:13:07,324 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:07,325 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:08,859 - INFO - Epoch: [175][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1510 (0.0951) Acc@1 95.312 (97.033) Acc@5 100.000 (99.969)
2025-08-27 22:13:10,226 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:10,227 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:10,630 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2763 (0.2763) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:13:11,485 - INFO - Epoch 175:
2025-08-27 22:13:11,485 - INFO -   Train: acc1: 96.9540 | acc5: 99.9680 | loss: 0.0960 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:11,485 - INFO -   Val:   acc1: 90.8200 | acc5: 99.7200 | loss: 0.2959
2025-08-27 22:13:11,485 - INFO -   LR: 0.001000
2025-08-27 22:13:11,506 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-27 22:13:11,696 - INFO - Epoch: [176][0/391] Time 0.189 (0.189) Data 0.162 (0.162) Loss 0.0913 (0.0913) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:13:13,517 - INFO - Epoch: [176][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.1135 (0.0937) Acc@1 96.094 (97.006) Acc@5 100.000 (99.985)
2025-08-27 22:13:14,371 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:14,371 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:15,442 - INFO - Epoch: [176][200/391] Time 0.031 (0.020) Data 0.007 (0.003) Loss 0.1074 (0.0944) Acc@1 97.656 (97.054) Acc@5 100.000 (99.984)
2025-08-27 22:13:17,309 - INFO - Epoch: [176][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.0766 (0.0954) Acc@1 97.656 (97.007) Acc@5 100.000 (99.979)
2025-08-27 22:13:17,373 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:17,373 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:19,082 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2696 (0.2696) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:13:19,948 - INFO - Epoch 176:
2025-08-27 22:13:19,948 - INFO -   Train: acc1: 96.9260 | acc5: 99.9780 | loss: 0.0963 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:19,948 - INFO -   Val:   acc1: 90.6800 | acc5: 99.7100 | loss: 0.2999
2025-08-27 22:13:19,948 - INFO -   LR: 0.001000
2025-08-27 22:13:19,970 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-27 22:13:20,154 - INFO - Epoch: [177][0/391] Time 0.183 (0.183) Data 0.156 (0.156) Loss 0.1124 (0.1124) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:13:21,407 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:21,408 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:21,925 - INFO - Epoch: [177][100/391] Time 0.019 (0.019) Data 0.007 (0.005) Loss 0.0471 (0.0948) Acc@1 99.219 (97.037) Acc@5 100.000 (99.961)
2025-08-27 22:13:23,718 - INFO - Epoch: [177][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0302 (0.0937) Acc@1 99.219 (97.042) Acc@5 100.000 (99.969)
2025-08-27 22:13:24,413 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:24,413 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:25,639 - INFO - Epoch: [177][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1402 (0.0965) Acc@1 94.531 (96.875) Acc@5 100.000 (99.969)
2025-08-27 22:13:27,492 - INFO - Test: [0/79] Time 0.117 (0.117) Loss 0.2838 (0.2838) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:13:28,353 - INFO - Epoch 177:
2025-08-27 22:13:28,353 - INFO -   Train: acc1: 96.9180 | acc5: 99.9700 | loss: 0.0957 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:28,353 - INFO -   Val:   acc1: 90.6100 | acc5: 99.7100 | loss: 0.3009
2025-08-27 22:13:28,353 - INFO -   LR: 0.001000
2025-08-27 22:13:28,372 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-27 22:13:28,539 - INFO - Epoch: [178][0/391] Time 0.166 (0.166) Data 0.142 (0.142) Loss 0.0468 (0.0468) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:13:28,566 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:28,566 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:30,389 - INFO - Epoch: [178][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0443 (0.0969) Acc@1 99.219 (96.697) Acc@5 100.000 (99.977)
2025-08-27 22:13:31,473 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:31,473 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:32,147 - INFO - Epoch: [178][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1069 (0.0978) Acc@1 97.656 (96.708) Acc@5 99.219 (99.977)
2025-08-27 22:13:33,944 - INFO - Epoch: [178][300/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.1055 (0.0967) Acc@1 94.531 (96.808) Acc@5 100.000 (99.977)
2025-08-27 22:13:34,352 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:34,353 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:35,752 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2819 (0.2819) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:13:36,606 - INFO - Epoch 178:
2025-08-27 22:13:36,606 - INFO -   Train: acc1: 96.7980 | acc5: 99.9760 | loss: 0.0967 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:36,607 - INFO -   Val:   acc1: 90.5700 | acc5: 99.6800 | loss: 0.3023
2025-08-27 22:13:36,607 - INFO -   LR: 0.001000
2025-08-27 22:13:36,628 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-27 22:13:36,816 - INFO - Epoch: [179][0/391] Time 0.188 (0.188) Data 0.168 (0.168) Loss 0.1044 (0.1044) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:13:38,458 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:38,458 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:38,665 - INFO - Epoch: [179][100/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.0669 (0.0901) Acc@1 97.656 (97.177) Acc@5 100.000 (99.977)
2025-08-27 22:13:40,483 - INFO - Epoch: [179][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1312 (0.0907) Acc@1 95.312 (97.167) Acc@5 100.000 (99.973)
2025-08-27 22:13:41,391 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:41,391 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:42,256 - INFO - Epoch: [179][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1001 (0.0932) Acc@1 96.875 (97.067) Acc@5 100.000 (99.971)
2025-08-27 22:13:44,096 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2886 (0.2886) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:13:44,986 - INFO - Epoch 179:
2025-08-27 22:13:44,987 - INFO -   Train: acc1: 97.0220 | acc5: 99.9660 | loss: 0.0942 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:44,987 - INFO -   Val:   acc1: 90.8700 | acc5: 99.6800 | loss: 0.2989
2025-08-27 22:13:44,987 - INFO -   LR: 0.001000
2025-08-27 22:13:45,007 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-27 22:13:45,165 - INFO - Epoch: [180][0/391] Time 0.157 (0.157) Data 0.130 (0.130) Loss 0.1575 (0.1575) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:13:45,595 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:45,595 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:47,115 - INFO - Epoch: [180][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.0972 (0.0946) Acc@1 96.094 (96.890) Acc@5 100.000 (99.992)
2025-08-27 22:13:48,606 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:48,606 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:49,055 - INFO - Epoch: [180][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.0928 (0.0965) Acc@1 97.656 (96.821) Acc@5 100.000 (99.984)
2025-08-27 22:13:50,949 - INFO - Epoch: [180][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1209 (0.0953) Acc@1 97.656 (96.922) Acc@5 100.000 (99.979)
2025-08-27 22:13:51,791 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:51,791 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:52,830 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2987 (0.2987) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:13:53,666 - INFO - Epoch 180:
2025-08-27 22:13:53,666 - INFO -   Train: acc1: 96.9620 | acc5: 99.9760 | loss: 0.0949 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:13:53,666 - INFO -   Val:   acc1: 90.6900 | acc5: 99.7400 | loss: 0.2997
2025-08-27 22:13:53,666 - INFO -   LR: 0.001000
2025-08-27 22:13:53,719 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-27 22:13:53,906 - INFO - Epoch: [181][0/391] Time 0.186 (0.186) Data 0.161 (0.161) Loss 0.0985 (0.0985) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:13:55,827 - INFO - Epoch: [181][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.1519 (0.0946) Acc@1 93.750 (96.983) Acc@5 100.000 (99.977)
2025-08-27 22:13:56,010 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:56,011 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:57,619 - INFO - Epoch: [181][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0951 (0.0934) Acc@1 97.656 (97.019) Acc@5 100.000 (99.988)
2025-08-27 22:13:58,843 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:13:58,843 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:13:59,434 - INFO - Epoch: [181][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.1071 (0.0948) Acc@1 96.094 (96.968) Acc@5 100.000 (99.979)
2025-08-27 22:14:01,182 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3252 (0.3252) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:14:02,023 - INFO - Epoch 181:
2025-08-27 22:14:02,023 - INFO -   Train: acc1: 96.9660 | acc5: 99.9760 | loss: 0.0942 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:02,023 - INFO -   Val:   acc1: 90.5100 | acc5: 99.7300 | loss: 0.3024
2025-08-27 22:14:02,023 - INFO -   LR: 0.001000
2025-08-27 22:14:02,043 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-27 22:14:02,222 - INFO - Epoch: [182][0/391] Time 0.178 (0.178) Data 0.156 (0.156) Loss 0.0940 (0.0940) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:14:02,876 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:02,876 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:04,018 - INFO - Epoch: [182][100/391] Time 0.032 (0.020) Data 0.020 (0.005) Loss 0.0452 (0.0881) Acc@1 99.219 (97.246) Acc@5 100.000 (99.977)
2025-08-27 22:14:05,832 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:05,833 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:05,886 - INFO - Epoch: [182][200/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.0872 (0.0899) Acc@1 96.875 (97.116) Acc@5 100.000 (99.977)
2025-08-27 22:14:07,760 - INFO - Epoch: [182][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.0717 (0.0919) Acc@1 97.656 (97.059) Acc@5 100.000 (99.966)
2025-08-27 22:14:08,870 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:08,883 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:09,586 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3159 (0.3159) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:14:10,430 - INFO - Epoch 182:
2025-08-27 22:14:10,430 - INFO -   Train: acc1: 97.0320 | acc5: 99.9720 | loss: 0.0924 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:10,430 - INFO -   Val:   acc1: 90.6700 | acc5: 99.7300 | loss: 0.3025
2025-08-27 22:14:10,430 - INFO -   LR: 0.001000
2025-08-27 22:14:10,498 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-27 22:14:10,635 - INFO - Epoch: [183][0/391] Time 0.136 (0.136) Data 0.120 (0.120) Loss 0.0836 (0.0836) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:14:12,495 - INFO - Epoch: [183][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1391 (0.0947) Acc@1 94.531 (96.844) Acc@5 100.000 (99.977)
2025-08-27 22:14:12,984 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:12,984 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:14,318 - INFO - Epoch: [183][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.0341 (0.0937) Acc@1 100.000 (96.918) Acc@5 100.000 (99.973)
2025-08-27 22:14:15,890 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:15,890 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:16,107 - INFO - Epoch: [183][300/391] Time 0.034 (0.019) Data 0.024 (0.003) Loss 0.1192 (0.0947) Acc@1 96.094 (96.826) Acc@5 100.000 (99.971)
2025-08-27 22:14:17,881 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2938 (0.2938) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:14:18,737 - INFO - Epoch 183:
2025-08-27 22:14:18,737 - INFO -   Train: acc1: 96.8340 | acc5: 99.9740 | loss: 0.0948 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:18,737 - INFO -   Val:   acc1: 90.7500 | acc5: 99.6900 | loss: 0.2991
2025-08-27 22:14:18,737 - INFO -   LR: 0.001000
2025-08-27 22:14:18,756 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-27 22:14:18,944 - INFO - Epoch: [184][0/391] Time 0.187 (0.187) Data 0.171 (0.171) Loss 0.0793 (0.0793) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:14:19,937 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:19,937 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:20,723 - INFO - Epoch: [184][100/391] Time 0.025 (0.019) Data 0.000 (0.004) Loss 0.1270 (0.0891) Acc@1 95.312 (97.115) Acc@5 100.000 (99.992)
2025-08-27 22:14:22,552 - INFO - Epoch: [184][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.1119 (0.0911) Acc@1 95.312 (97.093) Acc@5 100.000 (99.992)
2025-08-27 22:14:22,796 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:22,796 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:24,319 - INFO - Epoch: [184][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.1257 (0.0914) Acc@1 95.312 (97.083) Acc@5 100.000 (99.979)
2025-08-27 22:14:25,724 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:25,724 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:26,141 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3012 (0.3012) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:14:27,027 - INFO - Epoch 184:
2025-08-27 22:14:27,027 - INFO -   Train: acc1: 97.0840 | acc5: 99.9760 | loss: 0.0918 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:27,027 - INFO -   Val:   acc1: 90.6300 | acc5: 99.6800 | loss: 0.3056
2025-08-27 22:14:27,027 - INFO -   LR: 0.001000
2025-08-27 22:14:27,046 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-27 22:14:27,235 - INFO - Epoch: [185][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.1424 (0.1424) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-27 22:14:29,134 - INFO - Epoch: [185][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.0944 (0.0930) Acc@1 96.094 (97.030) Acc@5 100.000 (99.961)
2025-08-27 22:14:29,993 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:29,993 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:30,980 - INFO - Epoch: [185][200/391] Time 0.026 (0.020) Data 0.016 (0.003) Loss 0.1028 (0.0917) Acc@1 97.656 (97.054) Acc@5 100.000 (99.973)
2025-08-27 22:14:32,788 - INFO - Epoch: [185][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1320 (0.0913) Acc@1 96.875 (97.127) Acc@5 100.000 (99.964)
2025-08-27 22:14:32,866 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:32,867 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:34,611 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2791 (0.2791) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:14:35,474 - INFO - Epoch 185:
2025-08-27 22:14:35,475 - INFO -   Train: acc1: 97.1280 | acc5: 99.9620 | loss: 0.0920 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:35,475 - INFO -   Val:   acc1: 90.6300 | acc5: 99.7200 | loss: 0.3033
2025-08-27 22:14:35,475 - INFO -   LR: 0.001000
2025-08-27 22:14:35,494 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-27 22:14:35,675 - INFO - Epoch: [186][0/391] Time 0.180 (0.180) Data 0.160 (0.160) Loss 0.0761 (0.0761) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:14:37,000 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:37,000 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:37,498 - INFO - Epoch: [186][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1247 (0.0948) Acc@1 96.094 (96.867) Acc@5 99.219 (99.946)
2025-08-27 22:14:39,277 - INFO - Epoch: [186][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1014 (0.0928) Acc@1 96.094 (96.898) Acc@5 100.000 (99.969)
2025-08-27 22:14:39,884 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:39,885 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:41,046 - INFO - Epoch: [186][300/391] Time 0.024 (0.018) Data 0.000 (0.003) Loss 0.0889 (0.0929) Acc@1 97.656 (96.940) Acc@5 100.000 (99.971)
2025-08-27 22:14:42,786 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2860 (0.2860) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:14:43,615 - INFO - Epoch 186:
2025-08-27 22:14:43,615 - INFO -   Train: acc1: 96.9240 | acc5: 99.9740 | loss: 0.0935 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:43,615 - INFO -   Val:   acc1: 90.6200 | acc5: 99.7300 | loss: 0.3033
2025-08-27 22:14:43,615 - INFO -   LR: 0.001000
2025-08-27 22:14:43,633 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-27 22:14:43,814 - INFO - Epoch: [187][0/391] Time 0.180 (0.180) Data 0.159 (0.159) Loss 0.0721 (0.0721) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:14:43,874 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:43,874 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:45,609 - INFO - Epoch: [187][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.0869 (0.0931) Acc@1 96.875 (96.821) Acc@5 100.000 (99.961)
2025-08-27 22:14:46,653 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:46,653 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:47,364 - INFO - Epoch: [187][200/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.0934 (0.0945) Acc@1 97.656 (96.856) Acc@5 100.000 (99.961)
2025-08-27 22:14:49,111 - INFO - Epoch: [187][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.0370 (0.0936) Acc@1 99.219 (96.896) Acc@5 100.000 (99.966)
2025-08-27 22:14:49,494 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:49,500 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:50,860 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3335 (0.3335) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:14:51,719 - INFO - Epoch 187:
2025-08-27 22:14:51,720 - INFO -   Train: acc1: 96.8900 | acc5: 99.9660 | loss: 0.0939 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:14:51,720 - INFO -   Val:   acc1: 90.6300 | acc5: 99.7500 | loss: 0.3026
2025-08-27 22:14:51,720 - INFO -   LR: 0.001000
2025-08-27 22:14:51,740 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-27 22:14:51,918 - INFO - Epoch: [188][0/391] Time 0.177 (0.177) Data 0.147 (0.147) Loss 0.0678 (0.0678) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:14:53,600 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:53,601 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:53,801 - INFO - Epoch: [188][100/391] Time 0.025 (0.020) Data 0.000 (0.005) Loss 0.0751 (0.0921) Acc@1 97.656 (96.999) Acc@5 100.000 (99.969)
2025-08-27 22:14:55,636 - INFO - Epoch: [188][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1122 (0.0903) Acc@1 95.312 (97.058) Acc@5 100.000 (99.973)
2025-08-27 22:14:56,568 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:14:56,568 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:14:57,457 - INFO - Epoch: [188][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.0869 (0.0911) Acc@1 96.094 (97.013) Acc@5 100.000 (99.977)
2025-08-27 22:14:59,251 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3096 (0.3096) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:15:00,084 - INFO - Epoch 188:
2025-08-27 22:15:00,084 - INFO -   Train: acc1: 96.9900 | acc5: 99.9740 | loss: 0.0914 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:00,084 - INFO -   Val:   acc1: 90.6500 | acc5: 99.7100 | loss: 0.3052
2025-08-27 22:15:00,084 - INFO -   LR: 0.001000
2025-08-27 22:15:00,104 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-27 22:15:00,265 - INFO - Epoch: [189][0/391] Time 0.160 (0.160) Data 0.142 (0.142) Loss 0.0830 (0.0830) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:15:00,686 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:00,686 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:02,204 - INFO - Epoch: [189][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1131 (0.0940) Acc@1 96.875 (96.883) Acc@5 100.000 (99.969)
2025-08-27 22:15:03,756 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:03,757 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:04,122 - INFO - Epoch: [189][200/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.1232 (0.0915) Acc@1 94.531 (96.984) Acc@5 100.000 (99.981)
2025-08-27 22:15:05,960 - INFO - Epoch: [189][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.0761 (0.0910) Acc@1 98.438 (97.028) Acc@5 100.000 (99.984)
2025-08-27 22:15:06,752 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:06,753 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:07,866 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.3116 (0.3116) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:15:08,721 - INFO - Epoch 189:
2025-08-27 22:15:08,721 - INFO -   Train: acc1: 96.9920 | acc5: 99.9760 | loss: 0.0914 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:08,721 - INFO -   Val:   acc1: 90.6500 | acc5: 99.7400 | loss: 0.3051
2025-08-27 22:15:08,721 - INFO -   LR: 0.001000
2025-08-27 22:15:08,743 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-27 22:15:08,934 - INFO - Epoch: [190][0/391] Time 0.191 (0.191) Data 0.164 (0.164) Loss 0.0939 (0.0939) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:15:10,754 - INFO - Epoch: [190][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1364 (0.0923) Acc@1 94.531 (97.076) Acc@5 100.000 (99.977)
2025-08-27 22:15:10,944 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:10,944 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:12,604 - INFO - Epoch: [190][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.0856 (0.0901) Acc@1 96.094 (97.046) Acc@5 100.000 (99.984)
2025-08-27 22:15:13,946 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:13,947 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:14,520 - INFO - Epoch: [190][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0837 (0.0911) Acc@1 96.094 (97.070) Acc@5 100.000 (99.979)
2025-08-27 22:15:16,308 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.3220 (0.3220) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:15:17,149 - INFO - Epoch 190:
2025-08-27 22:15:17,149 - INFO -   Train: acc1: 97.1020 | acc5: 99.9740 | loss: 0.0911 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:17,149 - INFO -   Val:   acc1: 90.6600 | acc5: 99.7000 | loss: 0.3042
2025-08-27 22:15:17,149 - INFO -   LR: 0.001000
2025-08-27 22:15:17,205 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-27 22:15:17,391 - INFO - Epoch: [191][0/391] Time 0.186 (0.186) Data 0.166 (0.166) Loss 0.1077 (0.1077) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:15:18,071 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:18,071 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:19,187 - INFO - Epoch: [191][100/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.0545 (0.0887) Acc@1 98.438 (97.153) Acc@5 100.000 (99.977)
2025-08-27 22:15:20,918 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:20,918 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:20,943 - INFO - Epoch: [191][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.0488 (0.0897) Acc@1 98.438 (97.120) Acc@5 100.000 (99.977)
2025-08-27 22:15:22,788 - INFO - Epoch: [191][300/391] Time 0.034 (0.019) Data 0.019 (0.003) Loss 0.0978 (0.0892) Acc@1 95.312 (97.158) Acc@5 100.000 (99.977)
2025-08-27 22:15:23,923 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:23,924 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:24,672 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.3189 (0.3189) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:15:25,691 - INFO - Epoch 191:
2025-08-27 22:15:25,691 - INFO -   Train: acc1: 97.1000 | acc5: 99.9720 | loss: 0.0906 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:25,691 - INFO -   Val:   acc1: 90.5900 | acc5: 99.7100 | loss: 0.3120
2025-08-27 22:15:25,691 - INFO -   LR: 0.001000
2025-08-27 22:15:25,711 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-27 22:15:25,894 - INFO - Epoch: [192][0/391] Time 0.182 (0.182) Data 0.152 (0.152) Loss 0.0507 (0.0507) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:15:27,799 - INFO - Epoch: [192][100/391] Time 0.025 (0.021) Data 0.000 (0.005) Loss 0.1361 (0.0899) Acc@1 95.312 (97.138) Acc@5 100.000 (99.969)
2025-08-27 22:15:28,294 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:28,295 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:29,643 - INFO - Epoch: [192][200/391] Time 0.027 (0.020) Data 0.000 (0.004) Loss 0.1288 (0.0900) Acc@1 94.531 (97.073) Acc@5 100.000 (99.973)
2025-08-27 22:15:31,257 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:31,271 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:31,535 - INFO - Epoch: [192][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.0651 (0.0888) Acc@1 98.438 (97.171) Acc@5 100.000 (99.979)
2025-08-27 22:15:33,298 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2988 (0.2988) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:15:34,152 - INFO - Epoch 192:
2025-08-27 22:15:34,152 - INFO -   Train: acc1: 97.1240 | acc5: 99.9800 | loss: 0.0898 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:34,152 - INFO -   Val:   acc1: 90.6000 | acc5: 99.7500 | loss: 0.3069
2025-08-27 22:15:34,153 - INFO -   LR: 0.001000
2025-08-27 22:15:34,171 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-27 22:15:34,353 - INFO - Epoch: [193][0/391] Time 0.181 (0.181) Data 0.151 (0.151) Loss 0.1368 (0.1368) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:15:35,338 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:35,338 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:36,134 - INFO - Epoch: [193][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1035 (0.0868) Acc@1 96.875 (97.208) Acc@5 100.000 (99.969)
2025-08-27 22:15:37,960 - INFO - Epoch: [193][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0926 (0.0895) Acc@1 96.094 (97.097) Acc@5 100.000 (99.957)
2025-08-27 22:15:38,285 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:38,286 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:39,770 - INFO - Epoch: [193][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.0799 (0.0896) Acc@1 96.094 (97.085) Acc@5 100.000 (99.969)
2025-08-27 22:15:41,058 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:41,059 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:41,457 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2767 (0.2767) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:15:42,270 - INFO - Epoch 193:
2025-08-27 22:15:42,270 - INFO -   Train: acc1: 97.0800 | acc5: 99.9680 | loss: 0.0895 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:42,270 - INFO -   Val:   acc1: 90.7200 | acc5: 99.7300 | loss: 0.3068
2025-08-27 22:15:42,270 - INFO -   LR: 0.001000
2025-08-27 22:15:42,289 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-27 22:15:42,463 - INFO - Epoch: [194][0/391] Time 0.172 (0.172) Data 0.148 (0.148) Loss 0.0359 (0.0359) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 22:15:44,286 - INFO - Epoch: [194][100/391] Time 0.026 (0.020) Data 0.013 (0.004) Loss 0.0549 (0.0886) Acc@1 97.656 (97.308) Acc@5 100.000 (99.977)
2025-08-27 22:15:45,136 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:45,137 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:46,081 - INFO - Epoch: [194][200/391] Time 0.013 (0.019) Data 0.001 (0.004) Loss 0.0719 (0.0883) Acc@1 96.875 (97.159) Acc@5 100.000 (99.981)
2025-08-27 22:15:47,973 - INFO - Epoch: [194][300/391] Time 0.031 (0.019) Data 0.000 (0.004) Loss 0.0843 (0.0884) Acc@1 96.094 (97.179) Acc@5 100.000 (99.979)
2025-08-27 22:15:48,068 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:48,068 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:49,702 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2980 (0.2980) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:15:50,535 - INFO - Epoch 194:
2025-08-27 22:15:50,536 - INFO -   Train: acc1: 97.1220 | acc5: 99.9760 | loss: 0.0894 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:50,536 - INFO -   Val:   acc1: 90.7100 | acc5: 99.7200 | loss: 0.3129
2025-08-27 22:15:50,536 - INFO -   LR: 0.001000
2025-08-27 22:15:50,556 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-27 22:15:50,736 - INFO - Epoch: [195][0/391] Time 0.179 (0.179) Data 0.163 (0.163) Loss 0.0723 (0.0723) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 22:15:52,151 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:52,151 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:52,639 - INFO - Epoch: [195][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.0475 (0.0895) Acc@1 98.438 (97.184) Acc@5 100.000 (99.961)
2025-08-27 22:15:54,431 - INFO - Epoch: [195][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1113 (0.0887) Acc@1 96.094 (97.104) Acc@5 100.000 (99.969)
2025-08-27 22:15:55,061 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:55,062 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:15:56,295 - INFO - Epoch: [195][300/391] Time 0.023 (0.019) Data 0.012 (0.003) Loss 0.0927 (0.0888) Acc@1 96.094 (97.080) Acc@5 100.000 (99.977)
2025-08-27 22:15:58,097 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3025 (0.3025) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:15:58,976 - INFO - Epoch 195:
2025-08-27 22:15:58,976 - INFO -   Train: acc1: 97.0360 | acc5: 99.9780 | loss: 0.0897 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:15:58,976 - INFO -   Val:   acc1: 90.6900 | acc5: 99.7200 | loss: 0.3067
2025-08-27 22:15:58,976 - INFO -   LR: 0.001000
2025-08-27 22:15:58,997 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-27 22:15:59,179 - INFO - Epoch: [196][0/391] Time 0.181 (0.181) Data 0.154 (0.154) Loss 0.1380 (0.1380) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:15:59,259 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:15:59,259 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:01,117 - INFO - Epoch: [196][100/391] Time 0.031 (0.021) Data 0.000 (0.003) Loss 0.0977 (0.0913) Acc@1 96.094 (96.929) Acc@5 100.000 (99.985)
2025-08-27 22:16:02,228 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:02,228 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:02,896 - INFO - Epoch: [196][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.0937 (0.0884) Acc@1 96.094 (97.077) Acc@5 100.000 (99.984)
2025-08-27 22:16:04,709 - INFO - Epoch: [196][300/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.0815 (0.0890) Acc@1 97.656 (97.041) Acc@5 100.000 (99.984)
2025-08-27 22:16:05,134 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:05,134 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:06,510 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3323 (0.3323) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:16:07,346 - INFO - Epoch 196:
2025-08-27 22:16:07,346 - INFO -   Train: acc1: 97.0780 | acc5: 99.9780 | loss: 0.0897 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:16:07,347 - INFO -   Val:   acc1: 90.4500 | acc5: 99.6700 | loss: 0.3140
2025-08-27 22:16:07,347 - INFO -   LR: 0.001000
2025-08-27 22:16:07,368 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-27 22:16:07,548 - INFO - Epoch: [197][0/391] Time 0.179 (0.179) Data 0.154 (0.154) Loss 0.0956 (0.0956) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:16:09,193 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:09,193 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:09,335 - INFO - Epoch: [197][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1189 (0.0892) Acc@1 96.875 (97.208) Acc@5 99.219 (99.969)
2025-08-27 22:16:11,208 - INFO - Epoch: [197][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1311 (0.0870) Acc@1 96.875 (97.252) Acc@5 100.000 (99.977)
2025-08-27 22:16:12,203 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:12,203 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:13,013 - INFO - Epoch: [197][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.0892 (0.0858) Acc@1 97.656 (97.308) Acc@5 100.000 (99.984)
2025-08-27 22:16:14,845 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3222 (0.3222) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:16:15,698 - INFO - Epoch 197:
2025-08-27 22:16:15,698 - INFO -   Train: acc1: 97.2660 | acc5: 99.9800 | loss: 0.0860 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:16:15,698 - INFO -   Val:   acc1: 90.7700 | acc5: 99.6800 | loss: 0.3070
2025-08-27 22:16:15,698 - INFO -   LR: 0.001000
2025-08-27 22:16:15,719 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-27 22:16:15,906 - INFO - Epoch: [198][0/391] Time 0.186 (0.186) Data 0.162 (0.162) Loss 0.0648 (0.0648) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:16:16,294 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:16,294 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:17,711 - INFO - Epoch: [198][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1287 (0.0893) Acc@1 94.531 (97.285) Acc@5 100.000 (99.977)
2025-08-27 22:16:19,215 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:19,215 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:19,531 - INFO - Epoch: [198][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0484 (0.0905) Acc@1 100.000 (97.135) Acc@5 100.000 (99.977)
2025-08-27 22:16:21,327 - INFO - Epoch: [198][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1061 (0.0889) Acc@1 96.094 (97.168) Acc@5 100.000 (99.971)
2025-08-27 22:16:22,087 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:22,088 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:23,147 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3140 (0.3140) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:16:24,016 - INFO - Epoch 198:
2025-08-27 22:16:24,016 - INFO -   Train: acc1: 97.1760 | acc5: 99.9740 | loss: 0.0887 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:16:24,016 - INFO -   Val:   acc1: 90.5800 | acc5: 99.6900 | loss: 0.3088
2025-08-27 22:16:24,016 - INFO -   LR: 0.001000
2025-08-27 22:16:24,035 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-27 22:16:24,211 - INFO - Epoch: [199][0/391] Time 0.174 (0.174) Data 0.149 (0.149) Loss 0.0601 (0.0601) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:16:26,040 - INFO - Epoch: [199][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.0866 (0.0852) Acc@1 96.875 (97.200) Acc@5 100.000 (99.985)
2025-08-27 22:16:26,267 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:26,267 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:27,911 - INFO - Epoch: [199][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.0639 (0.0866) Acc@1 99.219 (97.104) Acc@5 100.000 (99.984)
2025-08-27 22:16:29,156 - INFO - Pruning info: sparsity=0.700
2025-08-27 22:16:29,156 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:29,667 - INFO - Epoch: [199][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1213 (0.0868) Acc@1 96.875 (97.145) Acc@5 99.219 (99.982)
2025-08-27 22:16:31,532 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3199 (0.3199) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:16:32,370 - INFO - Epoch 199:
2025-08-27 22:16:32,370 - INFO -   Train: acc1: 97.0720 | acc5: 99.9780 | loss: 0.0886 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-27 22:16:32,370 - INFO -   Val:   acc1: 90.6400 | acc5: 99.7500 | loss: 0.3114
2025-08-27 22:16:32,370 - INFO -   LR: 0.001000
2025-08-27 22:16:32,391 - INFO - training time: 00h 28m 10.47s
2025-08-27 22:16:32,391 - INFO - 
Training completed!
2025-08-27 22:16:32,391 - INFO - Best accuracy: 90.9400
2025-08-27 22:16:32,392 - INFO - Total training time: 0.47 hours
2025-08-27 22:16:32,392 - INFO - total_experiment time: 00h 28m 11.67s
2025-08-27 22:16:32,393 - INFO - Experiment completed successfully
2025-08-27 22:16:32,393 - INFO - Total time: 0.47 hours
