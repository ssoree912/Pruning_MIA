2025-08-28 01:37:11,005 - INFO - Starting experiment: dpf_sparsity0.7
2025-08-28 01:37:11,005 - INFO - Save directory: ./runs/dpf/sparsity0.7/seed42
2025-08-28 01:37:11,006 - INFO - Hyperparameters:
2025-08-28 01:37:11,006 - INFO -   name: dpf_sparsity0.7
2025-08-28 01:37:11,006 - INFO -   description: 
2025-08-28 01:37:11,006 - INFO -   save_dir: ./runs
2025-08-28 01:37:11,006 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 01:37:11,006 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 01:37:11,006 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 01:37:11,006 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.7, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 01:37:11,006 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 01:37:11,006 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 01:37:11,077 - INFO - System Information:
2025-08-28 01:37:11,077 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 01:37:11,077 - INFO -   python_version: 3.9.18
2025-08-28 01:37:11,077 - INFO -   pytorch_version: 2.1.0
2025-08-28 01:37:11,077 - INFO -   cuda_available: True
2025-08-28 01:37:11,077 - INFO -   cpu_count: 4
2025-08-28 01:37:11,077 - INFO -   memory_total_gb: 11.0
2025-08-28 01:37:11,077 - INFO -   timestamp: 1756312631.0773082
2025-08-28 01:37:11,077 - INFO -   cuda_version: 11.8
2025-08-28 01:37:11,077 - INFO -   gpu_count: 1
2025-08-28 01:37:11,078 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 01:37:11,083 - INFO - Starting experiment: dpf_sparsity0.7
2025-08-28 01:37:11,083 - INFO - Model: resnet-20
2025-08-28 01:37:11,083 - INFO - Dataset: cifar10
2025-08-28 01:37:11,083 - INFO - Pruning: dpf (70.00%)
2025-08-28 01:37:11,242 - INFO - Model Information:
2025-08-28 01:37:11,242 - INFO -   Type: pruned
2025-08-28 01:37:11,243 - INFO -   Total parameters: 544,948
2025-08-28 01:37:11,243 - INFO -   Trainable parameters: 274,692
2025-08-28 01:37:11,243 - INFO -   Sparsity: 70.00%
2025-08-28 01:37:12,223 - INFO - Starting training...
2025-08-28 01:37:12,223 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 01:37:13,013 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:37:13,014 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:37:13,514 - INFO - Epoch: [0][0/391] Time 1.290 (1.290) Data 0.659 (0.659) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 01:37:15,444 - INFO - Epoch: [0][100/391] Time 0.024 (0.032) Data 0.000 (0.008) Loss 1.7035 (1.9177) Acc@1 39.844 (27.050) Acc@5 88.281 (81.706)
2025-08-28 01:37:16,620 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:37:16,621 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:37:17,410 - INFO - Epoch: [0][200/391] Time 0.019 (0.026) Data 0.000 (0.005) Loss 1.4953 (1.7718) Acc@1 42.188 (32.805) Acc@5 93.750 (85.922)
2025-08-28 01:37:19,467 - INFO - Epoch: [0][300/391] Time 0.035 (0.024) Data 0.009 (0.003) Loss 1.3491 (1.6700) Acc@1 54.688 (37.298) Acc@5 93.750 (88.071)
2025-08-28 01:37:19,812 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:37:19,813 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:37:21,583 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 1.5140 (1.5140) Acc@1 46.875 (46.875) Acc@5 94.531 (94.531)
2025-08-28 01:37:22,529 - INFO - Epoch 0:
2025-08-28 01:37:22,529 - INFO -   Train: acc1: 40.6140 | acc5: 89.3900 | loss: 1.5936 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 01:37:22,529 - INFO -   Val:   acc1: 47.2500 | acc5: 93.4800 | loss: 1.5197
2025-08-28 01:37:22,529 - INFO -   LR: 0.100000
2025-08-28 01:37:22,580 - INFO - Checkpoint saved: epoch=0, metric=47.2500
2025-08-28 01:37:22,611 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 01:37:22,793 - INFO - Epoch: [1][0/391] Time 0.181 (0.181) Data 0.145 (0.145) Loss 1.3407 (1.3407) Acc@1 53.906 (53.906) Acc@5 92.969 (92.969)
2025-08-28 01:37:24,520 - INFO - Pruning info: sparsity=0.028
2025-08-28 01:37:24,520 - INFO -   Reactivation rate: 0.0082
2025-08-28 01:37:24,759 - INFO - Epoch: [1][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 1.1728 (1.2023) Acc@1 51.562 (56.629) Acc@5 96.875 (94.910)
2025-08-28 01:37:26,664 - INFO - Epoch: [1][200/391] Time 0.022 (0.020) Data 0.006 (0.003) Loss 0.9174 (1.1473) Acc@1 65.625 (58.800) Acc@5 97.656 (95.332)
2025-08-28 01:37:27,560 - INFO - Pruning info: sparsity=0.028
2025-08-28 01:37:27,561 - INFO -   Reactivation rate: 0.0055
2025-08-28 01:37:28,475 - INFO - Epoch: [1][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.9632 (1.1079) Acc@1 67.188 (60.169) Acc@5 95.312 (95.725)
2025-08-28 01:37:30,390 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 1.0931 (1.0931) Acc@1 59.375 (59.375) Acc@5 98.438 (98.438)
2025-08-28 01:37:31,238 - INFO - Epoch 1:
2025-08-28 01:37:31,238 - INFO -   Train: acc1: 61.3500 | acc5: 95.9680 | loss: 1.0782 | sparsity: 0.0276 | reactivation_rate: 0.0064
2025-08-28 01:37:31,238 - INFO -   Val:   acc1: 59.7100 | acc5: 96.8500 | loss: 1.1578
2025-08-28 01:37:31,238 - INFO -   LR: 0.100000
2025-08-28 01:37:31,315 - INFO - Checkpoint saved: epoch=1, metric=59.7100
2025-08-28 01:37:31,350 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 01:37:31,533 - INFO - Epoch: [2][0/391] Time 0.182 (0.182) Data 0.157 (0.157) Loss 0.9463 (0.9463) Acc@1 67.969 (67.969) Acc@5 96.094 (96.094)
2025-08-28 01:37:31,845 - INFO - Pruning info: sparsity=0.055
2025-08-28 01:37:31,845 - INFO -   Reactivation rate: 0.0131
2025-08-28 01:37:33,431 - INFO - Epoch: [2][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.8371 (0.9334) Acc@1 73.438 (66.963) Acc@5 96.875 (97.169)
2025-08-28 01:37:34,901 - INFO - Pruning info: sparsity=0.055
2025-08-28 01:37:34,901 - INFO -   Reactivation rate: 0.0067
2025-08-28 01:37:35,315 - INFO - Epoch: [2][200/391] Time 0.011 (0.020) Data 0.001 (0.003) Loss 0.7824 (0.8982) Acc@1 72.656 (68.280) Acc@5 98.438 (97.489)
2025-08-28 01:37:37,166 - INFO - Epoch: [2][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.8462 (0.8879) Acc@1 70.312 (68.872) Acc@5 100.000 (97.477)
2025-08-28 01:37:37,831 - INFO - Pruning info: sparsity=0.055
2025-08-28 01:37:37,831 - INFO -   Reactivation rate: 0.0051
2025-08-28 01:37:38,941 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 1.2905 (1.2905) Acc@1 60.938 (60.938) Acc@5 96.094 (96.094)
2025-08-28 01:37:39,854 - INFO - Epoch 2:
2025-08-28 01:37:39,854 - INFO -   Train: acc1: 69.5260 | acc5: 97.5500 | loss: 0.8688 | sparsity: 0.0545 | reactivation_rate: 0.0068
2025-08-28 01:37:39,854 - INFO -   Val:   acc1: 59.4900 | acc5: 94.4900 | loss: 1.3101
2025-08-28 01:37:39,854 - INFO -   LR: 0.100000
2025-08-28 01:37:39,862 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 01:37:40,028 - INFO - Epoch: [3][0/391] Time 0.165 (0.165) Data 0.138 (0.138) Loss 0.7864 (0.7864) Acc@1 72.656 (72.656) Acc@5 96.875 (96.875)
2025-08-28 01:37:41,949 - INFO - Epoch: [3][100/391] Time 0.027 (0.021) Data 0.007 (0.004) Loss 0.7833 (0.7635) Acc@1 69.531 (73.414) Acc@5 96.875 (98.159)
2025-08-28 01:37:42,070 - INFO - Pruning info: sparsity=0.081
2025-08-28 01:37:42,071 - INFO -   Reactivation rate: 0.0083
2025-08-28 01:37:43,950 - INFO - Epoch: [3][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.7326 (0.7548) Acc@1 75.781 (73.900) Acc@5 96.094 (98.208)
2025-08-28 01:37:45,198 - INFO - Pruning info: sparsity=0.081
2025-08-28 01:37:45,199 - INFO -   Reactivation rate: 0.0055
2025-08-28 01:37:45,868 - INFO - Epoch: [3][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.7866 (0.7495) Acc@1 75.000 (74.125) Acc@5 96.875 (98.251)
2025-08-28 01:37:47,760 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 1.1458 (1.1458) Acc@1 64.062 (64.062) Acc@5 96.094 (96.094)
2025-08-28 01:37:48,611 - INFO - Epoch 3:
2025-08-28 01:37:48,611 - INFO -   Train: acc1: 74.0560 | acc5: 98.2160 | loss: 0.7505 | sparsity: 0.0807 | reactivation_rate: 0.0069
2025-08-28 01:37:48,611 - INFO -   Val:   acc1: 64.5000 | acc5: 96.2500 | loss: 1.1412
2025-08-28 01:37:48,612 - INFO -   LR: 0.100000
2025-08-28 01:37:48,654 - INFO - Checkpoint saved: epoch=3, metric=64.5000
2025-08-28 01:37:48,685 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 01:37:48,872 - INFO - Epoch: [4][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.6730 (0.6730) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 01:37:49,520 - INFO - Pruning info: sparsity=0.106
2025-08-28 01:37:49,520 - INFO -   Reactivation rate: 0.0110
2025-08-28 01:37:50,789 - INFO - Epoch: [4][100/391] Time 0.024 (0.021) Data 0.000 (0.002) Loss 0.7780 (0.6991) Acc@1 78.125 (75.580) Acc@5 95.312 (98.499)
2025-08-28 01:37:52,594 - INFO - Pruning info: sparsity=0.106
2025-08-28 01:37:52,594 - INFO -   Reactivation rate: 0.0063
2025-08-28 01:37:52,692 - INFO - Epoch: [4][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.7448 (0.6858) Acc@1 71.094 (76.310) Acc@5 100.000 (98.465)
2025-08-28 01:37:54,679 - INFO - Epoch: [4][300/391] Time 0.014 (0.020) Data 0.000 (0.001) Loss 0.7280 (0.6845) Acc@1 70.312 (76.448) Acc@5 97.656 (98.476)
2025-08-28 01:37:55,792 - INFO - Pruning info: sparsity=0.106
2025-08-28 01:37:55,792 - INFO -   Reactivation rate: 0.0049
2025-08-28 01:37:56,589 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.7408 (0.7408) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-28 01:37:57,447 - INFO - Epoch 4:
2025-08-28 01:37:57,448 - INFO -   Train: acc1: 76.6080 | acc5: 98.4940 | loss: 0.6799 | sparsity: 0.1061 | reactivation_rate: 0.0067
2025-08-28 01:37:57,448 - INFO -   Val:   acc1: 73.1500 | acc5: 98.1000 | loss: 0.8029
2025-08-28 01:37:57,448 - INFO -   LR: 0.100000
2025-08-28 01:37:57,494 - INFO - Checkpoint saved: epoch=4, metric=73.1500
2025-08-28 01:37:57,528 - INFO - training time: 00h 00m 45.30s
2025-08-28 01:37:57,528 - INFO - 
Training completed!
2025-08-28 01:37:57,528 - INFO - Best accuracy: 73.1500
2025-08-28 01:37:57,528 - INFO - Total training time: 0.01 hours
2025-08-28 01:37:57,528 - INFO - total_experiment time: 00h 00m 46.52s
2025-08-28 01:37:57,529 - INFO - Experiment completed successfully
2025-08-28 01:37:57,529 - INFO - Total time: 0.01 hours
2025-08-28 05:09:42,287 - INFO - Starting experiment: dpf_sparsity0.7
2025-08-28 05:09:42,288 - INFO - Save directory: ./runs/dpf/sparsity0.7/seed42
2025-08-28 05:09:42,288 - INFO - Hyperparameters:
2025-08-28 05:09:42,288 - INFO -   name: dpf_sparsity0.7
2025-08-28 05:09:42,288 - INFO -   description: 
2025-08-28 05:09:42,288 - INFO -   save_dir: ./runs
2025-08-28 05:09:42,288 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 05:09:42,288 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 05:09:42,288 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 05:09:42,288 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.7, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 05:09:42,288 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 05:09:42,288 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 05:09:42,334 - INFO - System Information:
2025-08-28 05:09:42,334 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 05:09:42,334 - INFO -   python_version: 3.9.18
2025-08-28 05:09:42,334 - INFO -   pytorch_version: 2.1.0
2025-08-28 05:09:42,334 - INFO -   cuda_available: True
2025-08-28 05:09:42,334 - INFO -   cpu_count: 4
2025-08-28 05:09:42,334 - INFO -   memory_total_gb: 11.0
2025-08-28 05:09:42,335 - INFO -   timestamp: 1756325382.3344338
2025-08-28 05:09:42,335 - INFO -   cuda_version: 11.8
2025-08-28 05:09:42,335 - INFO -   gpu_count: 1
2025-08-28 05:09:42,335 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 05:09:42,357 - INFO - Starting experiment: dpf_sparsity0.7
2025-08-28 05:09:42,358 - INFO - Model: resnet-20
2025-08-28 05:09:42,358 - INFO - Dataset: cifar10
2025-08-28 05:09:42,358 - INFO - Pruning: dpf (70.00%)
2025-08-28 05:09:42,496 - INFO - Model Information:
2025-08-28 05:09:42,496 - INFO -   Type: pruned
2025-08-28 05:09:42,496 - INFO -   Total parameters: 544,948
2025-08-28 05:09:42,496 - INFO -   Trainable parameters: 274,692
2025-08-28 05:09:42,496 - INFO -   Sparsity: 70.00%
2025-08-28 05:09:43,636 - INFO - Starting training...
2025-08-28 05:09:43,636 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 05:09:44,407 - INFO - Pruning info: sparsity=0.000
2025-08-28 05:09:44,407 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:44,959 - INFO - Epoch: [0][0/391] Time 1.322 (1.322) Data 0.623 (0.623) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 05:09:46,819 - INFO - Epoch: [0][100/391] Time 0.042 (0.031) Data 0.031 (0.009) Loss 1.6994 (1.9415) Acc@1 39.062 (26.129) Acc@5 90.625 (80.221)
2025-08-28 05:09:47,900 - INFO - Pruning info: sparsity=0.000
2025-08-28 05:09:47,900 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:48,667 - INFO - Epoch: [0][200/391] Time 0.011 (0.025) Data 0.000 (0.006) Loss 1.4387 (1.7900) Acc@1 40.625 (32.070) Acc@5 93.750 (84.709)
2025-08-28 05:09:50,581 - INFO - Epoch: [0][300/391] Time 0.013 (0.023) Data 0.000 (0.004) Loss 1.3150 (1.6779) Acc@1 53.906 (36.890) Acc@5 93.750 (87.246)
2025-08-28 05:09:50,947 - INFO - Pruning info: sparsity=0.000
2025-08-28 05:09:50,947 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:52,608 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 1.5415 (1.5415) Acc@1 44.531 (44.531) Acc@5 92.188 (92.188)
2025-08-28 05:09:53,503 - INFO - Epoch 0:
2025-08-28 05:09:53,503 - INFO -   Train: acc1: 40.3040 | acc5: 88.8020 | loss: 1.5947 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 05:09:53,503 - INFO -   Val:   acc1: 43.7600 | acc5: 91.6300 | loss: 1.5998
2025-08-28 05:09:53,503 - INFO -   LR: 0.100000
2025-08-28 05:09:53,546 - INFO - Checkpoint saved: epoch=0, metric=43.7600
2025-08-28 05:09:53,578 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 05:09:53,750 - INFO - Epoch: [1][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 1.3939 (1.3939) Acc@1 45.312 (45.312) Acc@5 92.969 (92.969)
2025-08-28 05:09:55,348 - INFO - Pruning info: sparsity=0.028
2025-08-28 05:09:55,348 - INFO -   Reactivation rate: 0.0078
2025-08-28 05:09:55,553 - INFO - Epoch: [1][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 1.1364 (1.1954) Acc@1 56.250 (56.327) Acc@5 96.094 (95.142)
2025-08-28 05:09:57,398 - INFO - Epoch: [1][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.9431 (1.1544) Acc@1 62.500 (58.069) Acc@5 98.438 (95.511)
2025-08-28 05:09:58,299 - INFO - Pruning info: sparsity=0.028
2025-08-28 05:09:58,299 - INFO -   Reactivation rate: 0.0051
2025-08-28 05:09:59,253 - INFO - Epoch: [1][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.9449 (1.1202) Acc@1 67.188 (59.494) Acc@5 96.875 (95.855)
2025-08-28 05:10:00,999 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 1.0694 (1.0694) Acc@1 59.375 (59.375) Acc@5 97.656 (97.656)
2025-08-28 05:10:01,832 - INFO - Epoch 1:
2025-08-28 05:10:01,832 - INFO -   Train: acc1: 60.5940 | acc5: 96.1060 | loss: 1.0927 | sparsity: 0.0276 | reactivation_rate: 0.0061
2025-08-28 05:10:01,832 - INFO -   Val:   acc1: 61.5700 | acc5: 96.5400 | loss: 1.1184
2025-08-28 05:10:01,832 - INFO -   LR: 0.100000
2025-08-28 05:10:01,874 - INFO - Checkpoint saved: epoch=1, metric=61.5700
2025-08-28 05:10:01,905 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 05:10:02,088 - INFO - Epoch: [2][0/391] Time 0.182 (0.182) Data 0.145 (0.145) Loss 0.9232 (0.9232) Acc@1 67.188 (67.188) Acc@5 97.656 (97.656)
2025-08-28 05:10:02,397 - INFO - Pruning info: sparsity=0.055
2025-08-28 05:10:02,397 - INFO -   Reactivation rate: 0.0120
2025-08-28 05:10:03,900 - INFO - Epoch: [2][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.8903 (0.9466) Acc@1 67.188 (66.267) Acc@5 98.438 (97.401)
2025-08-28 05:10:05,263 - INFO - Pruning info: sparsity=0.055
2025-08-28 05:10:05,263 - INFO -   Reactivation rate: 0.0064
2025-08-28 05:10:05,738 - INFO - Epoch: [2][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.8412 (0.9213) Acc@1 68.750 (66.966) Acc@5 97.656 (97.493)
2025-08-28 05:10:07,587 - INFO - Epoch: [2][300/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.8720 (0.9065) Acc@1 66.406 (67.748) Acc@5 99.219 (97.519)
2025-08-28 05:10:08,291 - INFO - Pruning info: sparsity=0.055
2025-08-28 05:10:08,291 - INFO -   Reactivation rate: 0.0048
2025-08-28 05:10:09,396 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 1.3899 (1.3899) Acc@1 64.062 (64.062) Acc@5 92.969 (92.969)
2025-08-28 05:10:10,241 - INFO - Epoch 2:
2025-08-28 05:10:10,241 - INFO -   Train: acc1: 68.3540 | acc5: 97.5740 | loss: 0.8919 | sparsity: 0.0545 | reactivation_rate: 0.0066
2025-08-28 05:10:10,241 - INFO -   Val:   acc1: 60.1400 | acc5: 93.5300 | loss: 1.3400
2025-08-28 05:10:10,241 - INFO -   LR: 0.100000
2025-08-28 05:10:10,251 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 05:10:10,434 - INFO - Epoch: [3][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.8555 (0.8555) Acc@1 71.875 (71.875) Acc@5 96.875 (96.875)
2025-08-28 05:10:12,243 - INFO - Epoch: [3][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.8809 (0.7850) Acc@1 69.531 (72.850) Acc@5 97.656 (98.175)
2025-08-28 05:10:12,397 - INFO - Pruning info: sparsity=0.081
2025-08-28 05:10:12,397 - INFO -   Reactivation rate: 0.0081
2025-08-28 05:10:14,270 - INFO - Epoch: [3][200/391] Time 0.031 (0.020) Data 0.005 (0.003) Loss 0.7963 (0.7772) Acc@1 73.438 (73.150) Acc@5 95.312 (98.111)
2025-08-28 05:10:15,453 - INFO - Pruning info: sparsity=0.081
2025-08-28 05:10:15,453 - INFO -   Reactivation rate: 0.0057
2025-08-28 05:10:16,038 - INFO - Epoch: [3][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.7441 (0.7728) Acc@1 75.000 (73.321) Acc@5 98.438 (98.116)
2025-08-28 05:10:17,888 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 1.0100 (1.0100) Acc@1 64.062 (64.062) Acc@5 97.656 (97.656)
2025-08-28 05:10:18,727 - INFO - Epoch 3:
2025-08-28 05:10:18,727 - INFO -   Train: acc1: 73.2120 | acc5: 98.1040 | loss: 0.7745 | sparsity: 0.0807 | reactivation_rate: 0.0069
2025-08-28 05:10:18,728 - INFO -   Val:   acc1: 65.8700 | acc5: 96.4500 | loss: 1.0373
2025-08-28 05:10:18,728 - INFO -   LR: 0.100000
2025-08-28 05:10:18,773 - INFO - Checkpoint saved: epoch=3, metric=65.8700
2025-08-28 05:10:18,804 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 05:10:18,988 - INFO - Epoch: [4][0/391] Time 0.183 (0.183) Data 0.157 (0.157) Loss 0.7745 (0.7745) Acc@1 69.531 (69.531) Acc@5 99.219 (99.219)
2025-08-28 05:10:19,627 - INFO - Pruning info: sparsity=0.106
2025-08-28 05:10:19,627 - INFO -   Reactivation rate: 0.0109
2025-08-28 05:10:20,843 - INFO - Epoch: [4][100/391] Time 0.030 (0.020) Data 0.000 (0.005) Loss 0.6273 (0.7288) Acc@1 78.125 (74.853) Acc@5 99.219 (98.368)
2025-08-28 05:10:22,679 - INFO - Pruning info: sparsity=0.106
2025-08-28 05:10:22,679 - INFO -   Reactivation rate: 0.0063
2025-08-28 05:10:22,780 - INFO - Epoch: [4][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.6974 (0.7166) Acc@1 73.438 (75.155) Acc@5 99.219 (98.403)
2025-08-28 05:10:24,716 - INFO - Epoch: [4][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.6739 (0.7090) Acc@1 74.219 (75.459) Acc@5 99.219 (98.435)
2025-08-28 05:10:25,764 - INFO - Pruning info: sparsity=0.106
2025-08-28 05:10:25,764 - INFO -   Reactivation rate: 0.0049
2025-08-28 05:10:26,585 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 1.1966 (1.1966) Acc@1 61.719 (61.719) Acc@5 96.094 (96.094)
2025-08-28 05:10:27,428 - INFO - Epoch 4:
2025-08-28 05:10:27,428 - INFO -   Train: acc1: 75.5860 | acc5: 98.4860 | loss: 0.7039 | sparsity: 0.1061 | reactivation_rate: 0.0067
2025-08-28 05:10:27,428 - INFO -   Val:   acc1: 63.3700 | acc5: 96.0600 | loss: 1.2732
2025-08-28 05:10:27,428 - INFO -   LR: 0.100000
2025-08-28 05:10:27,438 - INFO - 
Epoch: 5, lr = 0.1
2025-08-28 05:10:27,624 - INFO - Epoch: [5][0/391] Time 0.185 (0.185) Data 0.159 (0.159) Loss 0.6772 (0.6772) Acc@1 71.875 (71.875) Acc@5 99.219 (99.219)
2025-08-28 05:10:29,577 - INFO - Epoch: [5][100/391] Time 0.014 (0.021) Data 0.002 (0.005) Loss 0.6101 (0.6911) Acc@1 78.906 (76.122) Acc@5 99.219 (98.677)
2025-08-28 05:10:29,972 - INFO - Pruning info: sparsity=0.131
2025-08-28 05:10:29,972 - INFO -   Reactivation rate: 0.0077
2025-08-28 05:10:31,492 - INFO - Epoch: [5][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.7044 (0.6774) Acc@1 74.219 (76.547) Acc@5 96.875 (98.593)
2025-08-28 05:10:33,109 - INFO - Pruning info: sparsity=0.131
2025-08-28 05:10:33,109 - INFO -   Reactivation rate: 0.0055
2025-08-28 05:10:33,447 - INFO - Epoch: [5][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.6919 (0.6717) Acc@1 72.656 (76.736) Acc@5 98.438 (98.583)
2025-08-28 05:10:35,287 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 1.1078 (1.1078) Acc@1 67.969 (67.969) Acc@5 96.094 (96.094)
2025-08-28 05:10:36,117 - INFO - Epoch 5:
2025-08-28 05:10:36,117 - INFO -   Train: acc1: 76.7740 | acc5: 98.5980 | loss: 0.6692 | sparsity: 0.1309 | reactivation_rate: 0.0067
2025-08-28 05:10:36,117 - INFO -   Val:   acc1: 64.5700 | acc5: 96.2000 | loss: 1.1500
2025-08-28 05:10:36,117 - INFO -   LR: 0.100000
2025-08-28 05:10:36,125 - INFO - 
Epoch: 6, lr = 0.1
2025-08-28 05:10:36,313 - INFO - Epoch: [6][0/391] Time 0.187 (0.187) Data 0.153 (0.153) Loss 0.5562 (0.5562) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:10:37,318 - INFO - Pruning info: sparsity=0.155
2025-08-28 05:10:37,319 - INFO -   Reactivation rate: 0.0101
2025-08-28 05:10:38,150 - INFO - Epoch: [6][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.6211 (0.6256) Acc@1 77.344 (78.303) Acc@5 98.438 (98.778)
2025-08-28 05:10:39,944 - INFO - Epoch: [6][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.6385 (0.6301) Acc@1 80.469 (78.242) Acc@5 97.656 (98.710)
2025-08-28 05:10:40,190 - INFO - Pruning info: sparsity=0.155
2025-08-28 05:10:40,191 - INFO -   Reactivation rate: 0.0061
2025-08-28 05:10:41,802 - INFO - Epoch: [6][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.6923 (0.6309) Acc@1 71.875 (78.325) Acc@5 98.438 (98.715)
2025-08-28 05:10:43,245 - INFO - Pruning info: sparsity=0.155
2025-08-28 05:10:43,246 - INFO -   Reactivation rate: 0.0045
2025-08-28 05:10:43,674 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7063 (0.7063) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 05:10:44,521 - INFO - Epoch 6:
2025-08-28 05:10:44,522 - INFO -   Train: acc1: 78.2780 | acc5: 98.7140 | loss: 0.6316 | sparsity: 0.1549 | reactivation_rate: 0.0065
2025-08-28 05:10:44,522 - INFO -   Val:   acc1: 73.8800 | acc5: 98.4100 | loss: 0.8158
2025-08-28 05:10:44,522 - INFO -   LR: 0.100000
2025-08-28 05:10:44,568 - INFO - Checkpoint saved: epoch=6, metric=73.8800
2025-08-28 05:10:44,599 - INFO - 
Epoch: 7, lr = 0.1
2025-08-28 05:10:44,767 - INFO - Epoch: [7][0/391] Time 0.167 (0.167) Data 0.128 (0.128) Loss 0.6835 (0.6835) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 05:10:46,608 - INFO - Epoch: [7][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.6507 (0.6159) Acc@1 77.344 (78.782) Acc@5 99.219 (98.639)
2025-08-28 05:10:47,391 - INFO - Pruning info: sparsity=0.178
2025-08-28 05:10:47,391 - INFO -   Reactivation rate: 0.0072
2025-08-28 05:10:48,466 - INFO - Epoch: [7][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5770 (0.6152) Acc@1 82.812 (78.724) Acc@5 99.219 (98.745)
2025-08-28 05:10:50,289 - INFO - Epoch: [7][300/391] Time 0.025 (0.019) Data 0.003 (0.002) Loss 0.4963 (0.6127) Acc@1 84.375 (78.745) Acc@5 99.219 (98.775)
2025-08-28 05:10:50,320 - INFO - Pruning info: sparsity=0.178
2025-08-28 05:10:50,320 - INFO -   Reactivation rate: 0.0049
2025-08-28 05:10:52,095 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.8773 (0.8773) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-28 05:10:52,973 - INFO - Epoch 7:
2025-08-28 05:10:52,973 - INFO -   Train: acc1: 78.7000 | acc5: 98.8140 | loss: 0.6122 | sparsity: 0.1783 | reactivation_rate: 0.0064
2025-08-28 05:10:52,973 - INFO -   Val:   acc1: 69.8600 | acc5: 96.7800 | loss: 0.9811
2025-08-28 05:10:52,973 - INFO -   LR: 0.100000
2025-08-28 05:10:52,980 - INFO - 
Epoch: 8, lr = 0.1
2025-08-28 05:10:53,164 - INFO - Epoch: [8][0/391] Time 0.183 (0.183) Data 0.154 (0.154) Loss 0.5781 (0.5781) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 05:10:54,499 - INFO - Pruning info: sparsity=0.201
2025-08-28 05:10:54,499 - INFO -   Reactivation rate: 0.0087
2025-08-28 05:10:54,975 - INFO - Epoch: [8][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.5624 (0.5944) Acc@1 78.125 (79.270) Acc@5 100.000 (98.731)
2025-08-28 05:10:56,871 - INFO - Epoch: [8][200/391] Time 0.029 (0.019) Data 0.000 (0.004) Loss 0.4397 (0.5767) Acc@1 85.938 (79.991) Acc@5 99.219 (98.877)
2025-08-28 05:10:57,459 - INFO - Pruning info: sparsity=0.201
2025-08-28 05:10:57,460 - INFO -   Reactivation rate: 0.0057
2025-08-28 05:10:58,696 - INFO - Epoch: [8][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.6480 (0.5856) Acc@1 83.594 (79.799) Acc@5 98.438 (98.897)
2025-08-28 05:11:00,477 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.9516 (0.9516) Acc@1 67.969 (67.969) Acc@5 99.219 (99.219)
2025-08-28 05:11:01,322 - INFO - Epoch 8:
2025-08-28 05:11:01,323 - INFO -   Train: acc1: 79.9460 | acc5: 98.9160 | loss: 0.5827 | sparsity: 0.2010 | reactivation_rate: 0.0063
2025-08-28 05:11:01,323 - INFO -   Val:   acc1: 68.3600 | acc5: 97.9100 | loss: 0.9581
2025-08-28 05:11:01,323 - INFO -   LR: 0.100000
2025-08-28 05:11:01,332 - INFO - 
Epoch: 9, lr = 0.1
2025-08-28 05:11:01,510 - INFO - Epoch: [9][0/391] Time 0.177 (0.177) Data 0.149 (0.149) Loss 0.4772 (0.4772) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-28 05:11:01,527 - INFO - Pruning info: sparsity=0.223
2025-08-28 05:11:01,528 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:11:03,357 - INFO - Epoch: [9][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4631 (0.5673) Acc@1 84.375 (80.036) Acc@5 99.219 (99.002)
2025-08-28 05:11:04,532 - INFO - Pruning info: sparsity=0.223
2025-08-28 05:11:04,532 - INFO -   Reactivation rate: 0.0063
2025-08-28 05:11:05,215 - INFO - Epoch: [9][200/391] Time 0.016 (0.019) Data 0.001 (0.003) Loss 0.4749 (0.5653) Acc@1 85.156 (80.477) Acc@5 98.438 (99.021)
2025-08-28 05:11:07,041 - INFO - Epoch: [9][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.6681 (0.5686) Acc@1 76.562 (80.290) Acc@5 97.656 (98.988)
2025-08-28 05:11:07,430 - INFO - Pruning info: sparsity=0.223
2025-08-28 05:11:07,430 - INFO -   Reactivation rate: 0.0046
2025-08-28 05:11:08,804 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 1.0624 (1.0624) Acc@1 64.844 (64.844) Acc@5 97.656 (97.656)
2025-08-28 05:11:09,640 - INFO - Epoch 9:
2025-08-28 05:11:09,640 - INFO -   Train: acc1: 80.2440 | acc5: 98.9940 | loss: 0.5702 | sparsity: 0.2230 | reactivation_rate: 0.0062
2025-08-28 05:11:09,640 - INFO -   Val:   acc1: 69.0800 | acc5: 97.1600 | loss: 0.9872
2025-08-28 05:11:09,640 - INFO -   LR: 0.100000
2025-08-28 05:11:09,651 - INFO - 
Epoch: 10, lr = 0.1
2025-08-28 05:11:09,846 - INFO - Epoch: [10][0/391] Time 0.194 (0.194) Data 0.177 (0.177) Loss 0.5735 (0.5735) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 05:11:11,482 - INFO - Pruning info: sparsity=0.244
2025-08-28 05:11:11,482 - INFO -   Reactivation rate: 0.0076
2025-08-28 05:11:11,689 - INFO - Epoch: [10][100/391] Time 0.027 (0.020) Data 0.000 (0.003) Loss 0.4555 (0.5453) Acc@1 85.156 (81.033) Acc@5 99.219 (99.141)
2025-08-28 05:11:13,572 - INFO - Epoch: [10][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.4678 (0.5413) Acc@1 84.375 (81.141) Acc@5 100.000 (99.164)
2025-08-28 05:11:14,518 - INFO - Pruning info: sparsity=0.244
2025-08-28 05:11:14,518 - INFO -   Reactivation rate: 0.0051
2025-08-28 05:11:15,464 - INFO - Epoch: [10][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.7600 (0.5490) Acc@1 78.125 (80.913) Acc@5 97.656 (99.097)
2025-08-28 05:11:17,364 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.9214 (0.9214) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 05:11:18,253 - INFO - Epoch 10:
2025-08-28 05:11:18,254 - INFO -   Train: acc1: 80.8540 | acc5: 99.0580 | loss: 0.5507 | sparsity: 0.2443 | reactivation_rate: 0.0059
2025-08-28 05:11:18,254 - INFO -   Val:   acc1: 72.1800 | acc5: 98.0200 | loss: 0.8768
2025-08-28 05:11:18,254 - INFO -   LR: 0.100000
2025-08-28 05:11:18,299 - INFO - 
Epoch: 11, lr = 0.1
2025-08-28 05:11:18,463 - INFO - Epoch: [11][0/391] Time 0.162 (0.162) Data 0.144 (0.144) Loss 0.6054 (0.6054) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 05:11:18,754 - INFO - Pruning info: sparsity=0.265
2025-08-28 05:11:18,754 - INFO -   Reactivation rate: 0.0116
2025-08-28 05:11:20,342 - INFO - Epoch: [11][100/391] Time 0.029 (0.020) Data 0.013 (0.004) Loss 0.5167 (0.5370) Acc@1 82.031 (81.451) Acc@5 99.219 (99.110)
2025-08-28 05:11:21,831 - INFO - Pruning info: sparsity=0.265
2025-08-28 05:11:21,831 - INFO -   Reactivation rate: 0.0054
2025-08-28 05:11:22,242 - INFO - Epoch: [11][200/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.6201 (0.5359) Acc@1 78.125 (81.405) Acc@5 99.219 (99.059)
2025-08-28 05:11:24,025 - INFO - Epoch: [11][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.6784 (0.5382) Acc@1 78.125 (81.512) Acc@5 100.000 (99.073)
2025-08-28 05:11:24,729 - INFO - Pruning info: sparsity=0.265
2025-08-28 05:11:24,729 - INFO -   Reactivation rate: 0.0042
2025-08-28 05:11:25,773 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6340 (0.6340) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-28 05:11:26,609 - INFO - Epoch 11:
2025-08-28 05:11:26,609 - INFO -   Train: acc1: 81.4340 | acc5: 99.0660 | loss: 0.5405 | sparsity: 0.2650 | reactivation_rate: 0.0058
2025-08-28 05:11:26,609 - INFO -   Val:   acc1: 74.3900 | acc5: 98.0400 | loss: 0.7877
2025-08-28 05:11:26,609 - INFO -   LR: 0.100000
2025-08-28 05:11:26,654 - INFO - Checkpoint saved: epoch=11, metric=74.3900
2025-08-28 05:11:26,686 - INFO - 
Epoch: 12, lr = 0.1
2025-08-28 05:11:26,880 - INFO - Epoch: [12][0/391] Time 0.194 (0.194) Data 0.176 (0.176) Loss 0.4842 (0.4842) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:11:28,734 - INFO - Epoch: [12][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.4953 (0.5382) Acc@1 82.812 (81.111) Acc@5 100.000 (99.080)
2025-08-28 05:11:28,835 - INFO - Pruning info: sparsity=0.285
2025-08-28 05:11:28,835 - INFO -   Reactivation rate: 0.0071
2025-08-28 05:11:30,491 - INFO - Epoch: [12][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6666 (0.5294) Acc@1 78.125 (81.646) Acc@5 98.438 (99.005)
2025-08-28 05:11:31,704 - INFO - Pruning info: sparsity=0.285
2025-08-28 05:11:31,704 - INFO -   Reactivation rate: 0.0044
2025-08-28 05:11:32,368 - INFO - Epoch: [12][300/391] Time 0.037 (0.019) Data 0.000 (0.003) Loss 0.5751 (0.5320) Acc@1 79.688 (81.580) Acc@5 99.219 (99.084)
2025-08-28 05:11:34,088 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5554 (0.5554) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:11:35,011 - INFO - Epoch 12:
2025-08-28 05:11:35,012 - INFO -   Train: acc1: 81.7000 | acc5: 99.0820 | loss: 0.5302 | sparsity: 0.2851 | reactivation_rate: 0.0057
2025-08-28 05:11:35,012 - INFO -   Val:   acc1: 78.4900 | acc5: 98.9300 | loss: 0.6532
2025-08-28 05:11:35,012 - INFO -   LR: 0.100000
2025-08-28 05:11:35,059 - INFO - Checkpoint saved: epoch=12, metric=78.4900
2025-08-28 05:11:35,092 - INFO - 
Epoch: 13, lr = 0.1
2025-08-28 05:11:35,270 - INFO - Epoch: [13][0/391] Time 0.177 (0.177) Data 0.153 (0.153) Loss 0.5498 (0.5498) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 05:11:35,958 - INFO - Pruning info: sparsity=0.305
2025-08-28 05:11:35,958 - INFO -   Reactivation rate: 0.0088
2025-08-28 05:11:37,134 - INFO - Epoch: [13][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.5044 (0.5070) Acc@1 84.375 (82.588) Acc@5 99.219 (99.172)
2025-08-28 05:11:39,024 - INFO - Pruning info: sparsity=0.305
2025-08-28 05:11:39,024 - INFO -   Reactivation rate: 0.0051
2025-08-28 05:11:39,086 - INFO - Epoch: [13][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3353 (0.5173) Acc@1 89.062 (82.175) Acc@5 100.000 (99.227)
2025-08-28 05:11:40,918 - INFO - Epoch: [13][300/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.5303 (0.5199) Acc@1 78.906 (82.057) Acc@5 99.219 (99.162)
2025-08-28 05:11:42,010 - INFO - Pruning info: sparsity=0.305
2025-08-28 05:11:42,010 - INFO -   Reactivation rate: 0.0038
2025-08-28 05:11:42,719 - INFO - Test: [0/79] Time 0.115 (0.115) Loss 0.7911 (0.7911) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-28 05:11:43,569 - INFO - Epoch 13:
2025-08-28 05:11:43,569 - INFO -   Train: acc1: 81.9900 | acc5: 99.1280 | loss: 0.5237 | sparsity: 0.3046 | reactivation_rate: 0.0053
2025-08-28 05:11:43,569 - INFO -   Val:   acc1: 76.0200 | acc5: 98.5500 | loss: 0.7350
2025-08-28 05:11:43,569 - INFO -   LR: 0.100000
2025-08-28 05:11:43,579 - INFO - 
Epoch: 14, lr = 0.1
2025-08-28 05:11:43,753 - INFO - Epoch: [14][0/391] Time 0.173 (0.173) Data 0.153 (0.153) Loss 0.4809 (0.4809) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 05:11:45,567 - INFO - Epoch: [14][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.7010 (0.5130) Acc@1 78.125 (82.596) Acc@5 98.438 (99.110)
2025-08-28 05:11:46,007 - INFO - Pruning info: sparsity=0.323
2025-08-28 05:11:46,007 - INFO -   Reactivation rate: 0.0059
2025-08-28 05:11:47,402 - INFO - Epoch: [14][200/391] Time 0.037 (0.019) Data 0.015 (0.003) Loss 0.6035 (0.5142) Acc@1 82.812 (82.568) Acc@5 99.219 (99.141)
2025-08-28 05:11:48,939 - INFO - Pruning info: sparsity=0.323
2025-08-28 05:11:48,939 - INFO -   Reactivation rate: 0.0043
2025-08-28 05:11:49,224 - INFO - Epoch: [14][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4032 (0.5166) Acc@1 87.500 (82.262) Acc@5 100.000 (99.128)
2025-08-28 05:11:50,980 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.8074 (0.8074) Acc@1 75.000 (75.000) Acc@5 96.094 (96.094)
2025-08-28 05:11:51,846 - INFO - Epoch 14:
2025-08-28 05:11:51,847 - INFO -   Train: acc1: 82.2480 | acc5: 99.1240 | loss: 0.5177 | sparsity: 0.3234 | reactivation_rate: 0.0052
2025-08-28 05:11:51,847 - INFO -   Val:   acc1: 74.1200 | acc5: 97.3100 | loss: 0.8060
2025-08-28 05:11:51,847 - INFO -   LR: 0.100000
2025-08-28 05:11:51,858 - INFO - 
Epoch: 15, lr = 0.1
2025-08-28 05:11:52,033 - INFO - Epoch: [15][0/391] Time 0.175 (0.175) Data 0.151 (0.151) Loss 0.4060 (0.4060) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-28 05:11:53,056 - INFO - Pruning info: sparsity=0.342
2025-08-28 05:11:53,056 - INFO -   Reactivation rate: 0.0076
2025-08-28 05:11:53,856 - INFO - Epoch: [15][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4228 (0.4956) Acc@1 87.500 (82.990) Acc@5 100.000 (99.172)
2025-08-28 05:11:55,703 - INFO - Epoch: [15][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6480 (0.5077) Acc@1 74.219 (82.552) Acc@5 100.000 (99.137)
2025-08-28 05:11:55,988 - INFO - Pruning info: sparsity=0.342
2025-08-28 05:11:55,988 - INFO -   Reactivation rate: 0.0047
2025-08-28 05:11:57,557 - INFO - Epoch: [15][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4571 (0.5074) Acc@1 85.938 (82.524) Acc@5 98.438 (99.156)
2025-08-28 05:11:58,916 - INFO - Pruning info: sparsity=0.342
2025-08-28 05:11:58,916 - INFO -   Reactivation rate: 0.0035
2025-08-28 05:11:59,313 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.6410 (0.6410) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 05:12:00,159 - INFO - Epoch 15:
2025-08-28 05:12:00,159 - INFO -   Train: acc1: 82.4980 | acc5: 99.1260 | loss: 0.5091 | sparsity: 0.3416 | reactivation_rate: 0.0051
2025-08-28 05:12:00,159 - INFO -   Val:   acc1: 78.9700 | acc5: 98.7900 | loss: 0.6284
2025-08-28 05:12:00,159 - INFO -   LR: 0.100000
2025-08-28 05:12:00,202 - INFO - Checkpoint saved: epoch=15, metric=78.9700
2025-08-28 05:12:00,235 - INFO - 
Epoch: 16, lr = 0.1
2025-08-28 05:12:00,429 - INFO - Epoch: [16][0/391] Time 0.192 (0.192) Data 0.169 (0.169) Loss 0.7055 (0.7055) Acc@1 73.438 (73.438) Acc@5 98.438 (98.438)
2025-08-28 05:12:02,266 - INFO - Epoch: [16][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.5581 (0.4993) Acc@1 80.469 (82.712) Acc@5 98.438 (99.157)
2025-08-28 05:12:03,008 - INFO - Pruning info: sparsity=0.359
2025-08-28 05:12:03,009 - INFO -   Reactivation rate: 0.0053
2025-08-28 05:12:04,104 - INFO - Epoch: [16][200/391] Time 0.015 (0.019) Data 0.002 (0.003) Loss 0.5198 (0.4999) Acc@1 81.250 (82.618) Acc@5 99.219 (99.141)
2025-08-28 05:12:05,914 - INFO - Epoch: [16][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5427 (0.5036) Acc@1 79.688 (82.509) Acc@5 99.219 (99.141)
2025-08-28 05:12:05,983 - INFO - Pruning info: sparsity=0.359
2025-08-28 05:12:05,984 - INFO -   Reactivation rate: 0.0036
2025-08-28 05:12:07,721 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6805 (0.6805) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-28 05:12:08,605 - INFO - Epoch 16:
2025-08-28 05:12:08,605 - INFO -   Train: acc1: 82.5980 | acc5: 99.1360 | loss: 0.5012 | sparsity: 0.3592 | reactivation_rate: 0.0049
2025-08-28 05:12:08,605 - INFO -   Val:   acc1: 76.8000 | acc5: 98.3200 | loss: 0.7066
2025-08-28 05:12:08,605 - INFO -   LR: 0.100000
2025-08-28 05:12:08,616 - INFO - 
Epoch: 17, lr = 0.1
2025-08-28 05:12:08,800 - INFO - Epoch: [17][0/391] Time 0.183 (0.183) Data 0.155 (0.155) Loss 0.4663 (0.4663) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:12:10,147 - INFO - Pruning info: sparsity=0.376
2025-08-28 05:12:10,147 - INFO -   Reactivation rate: 0.0067
2025-08-28 05:12:10,629 - INFO - Epoch: [17][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4244 (0.4792) Acc@1 79.688 (83.346) Acc@5 100.000 (99.281)
2025-08-28 05:12:12,655 - INFO - Epoch: [17][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4701 (0.4906) Acc@1 82.031 (83.209) Acc@5 100.000 (99.215)
2025-08-28 05:12:13,229 - INFO - Pruning info: sparsity=0.376
2025-08-28 05:12:13,229 - INFO -   Reactivation rate: 0.0042
2025-08-28 05:12:14,473 - INFO - Epoch: [17][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4492 (0.4983) Acc@1 85.156 (82.885) Acc@5 99.219 (99.185)
2025-08-28 05:12:16,362 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.8038 (0.8038) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 05:12:17,192 - INFO - Epoch 17:
2025-08-28 05:12:17,193 - INFO -   Train: acc1: 82.8820 | acc5: 99.1820 | loss: 0.4986 | sparsity: 0.3763 | reactivation_rate: 0.0047
2025-08-28 05:12:17,193 - INFO -   Val:   acc1: 75.0200 | acc5: 98.5900 | loss: 0.7604
2025-08-28 05:12:17,193 - INFO -   LR: 0.100000
2025-08-28 05:12:17,203 - INFO - 
Epoch: 18, lr = 0.1
2025-08-28 05:12:17,374 - INFO - Epoch: [18][0/391] Time 0.170 (0.170) Data 0.148 (0.148) Loss 0.4888 (0.4888) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:12:17,399 - INFO - Pruning info: sparsity=0.393
2025-08-28 05:12:17,400 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:12:19,304 - INFO - Epoch: [18][100/391] Time 0.024 (0.021) Data 0.000 (0.005) Loss 0.3947 (0.4866) Acc@1 87.500 (83.284) Acc@5 99.219 (99.234)
2025-08-28 05:12:20,390 - INFO - Pruning info: sparsity=0.393
2025-08-28 05:12:20,390 - INFO -   Reactivation rate: 0.0046
2025-08-28 05:12:21,015 - INFO - Epoch: [18][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5125 (0.4861) Acc@1 82.812 (83.329) Acc@5 96.875 (99.227)
2025-08-28 05:12:22,850 - INFO - Epoch: [18][300/391] Time 0.015 (0.019) Data 0.001 (0.003) Loss 0.7247 (0.4873) Acc@1 75.000 (83.251) Acc@5 97.656 (99.211)
2025-08-28 05:12:23,258 - INFO - Pruning info: sparsity=0.393
2025-08-28 05:12:23,258 - INFO -   Reactivation rate: 0.0033
2025-08-28 05:12:24,635 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.5631 (0.5631) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 05:12:25,479 - INFO - Epoch 18:
2025-08-28 05:12:25,479 - INFO -   Train: acc1: 83.1960 | acc5: 99.2120 | loss: 0.4886 | sparsity: 0.3927 | reactivation_rate: 0.0046
2025-08-28 05:12:25,479 - INFO -   Val:   acc1: 78.7700 | acc5: 98.6700 | loss: 0.6466
2025-08-28 05:12:25,479 - INFO -   LR: 0.100000
2025-08-28 05:12:25,490 - INFO - 
Epoch: 19, lr = 0.1
2025-08-28 05:12:25,624 - INFO - Epoch: [19][0/391] Time 0.134 (0.134) Data 0.115 (0.115) Loss 0.3333 (0.3333) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:12:27,392 - INFO - Pruning info: sparsity=0.409
2025-08-28 05:12:27,393 - INFO -   Reactivation rate: 0.0059
2025-08-28 05:12:27,592 - INFO - Epoch: [19][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.4019 (0.4676) Acc@1 82.812 (83.903) Acc@5 100.000 (99.335)
2025-08-28 05:12:29,445 - INFO - Epoch: [19][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3866 (0.4774) Acc@1 84.375 (83.458) Acc@5 99.219 (99.300)
2025-08-28 05:12:30,431 - INFO - Pruning info: sparsity=0.409
2025-08-28 05:12:30,431 - INFO -   Reactivation rate: 0.0037
2025-08-28 05:12:31,327 - INFO - Epoch: [19][300/391] Time 0.018 (0.019) Data 0.002 (0.003) Loss 0.3379 (0.4827) Acc@1 91.406 (83.215) Acc@5 100.000 (99.302)
2025-08-28 05:12:33,128 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5635 (0.5635) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:12:33,949 - INFO - Epoch 19:
2025-08-28 05:12:33,950 - INFO -   Train: acc1: 83.3460 | acc5: 99.2720 | loss: 0.4819 | sparsity: 0.4086 | reactivation_rate: 0.0045
2025-08-28 05:12:33,950 - INFO -   Val:   acc1: 77.0600 | acc5: 98.6700 | loss: 0.6963
2025-08-28 05:12:33,950 - INFO -   LR: 0.100000
2025-08-28 05:12:33,957 - INFO - 
Epoch: 20, lr = 0.1
2025-08-28 05:12:34,152 - INFO - Epoch: [20][0/391] Time 0.193 (0.193) Data 0.176 (0.176) Loss 0.4335 (0.4335) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:12:34,517 - INFO - Pruning info: sparsity=0.424
2025-08-28 05:12:34,517 - INFO -   Reactivation rate: 0.0086
2025-08-28 05:12:35,996 - INFO - Epoch: [20][100/391] Time 0.035 (0.020) Data 0.000 (0.004) Loss 0.3870 (0.4676) Acc@1 91.406 (84.112) Acc@5 98.438 (99.296)
2025-08-28 05:12:37,445 - INFO - Pruning info: sparsity=0.424
2025-08-28 05:12:37,445 - INFO -   Reactivation rate: 0.0042
2025-08-28 05:12:37,819 - INFO - Epoch: [20][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5066 (0.4830) Acc@1 83.594 (83.613) Acc@5 99.219 (99.258)
2025-08-28 05:12:39,623 - INFO - Epoch: [20][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5396 (0.4782) Acc@1 83.594 (83.747) Acc@5 97.656 (99.237)
2025-08-28 05:12:40,390 - INFO - Pruning info: sparsity=0.424
2025-08-28 05:12:40,391 - INFO -   Reactivation rate: 0.0032
2025-08-28 05:12:41,486 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.7058 (0.7058) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-28 05:12:42,305 - INFO - Epoch 20:
2025-08-28 05:12:42,305 - INFO -   Train: acc1: 83.5200 | acc5: 99.2300 | loss: 0.4815 | sparsity: 0.4239 | reactivation_rate: 0.0043
2025-08-28 05:12:42,306 - INFO -   Val:   acc1: 77.8000 | acc5: 98.4300 | loss: 0.6876
2025-08-28 05:12:42,306 - INFO -   LR: 0.100000
2025-08-28 05:12:42,362 - INFO - 
Epoch: 21, lr = 0.1
2025-08-28 05:12:42,527 - INFO - Epoch: [21][0/391] Time 0.165 (0.165) Data 0.142 (0.142) Loss 0.3010 (0.3010) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:12:44,361 - INFO - Epoch: [21][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.3682 (0.4713) Acc@1 87.500 (84.035) Acc@5 100.000 (99.304)
2025-08-28 05:12:44,509 - INFO - Pruning info: sparsity=0.439
2025-08-28 05:12:44,509 - INFO -   Reactivation rate: 0.0051
2025-08-28 05:12:46,231 - INFO - Epoch: [21][200/391] Time 0.038 (0.019) Data 0.018 (0.004) Loss 0.5858 (0.4753) Acc@1 78.125 (83.811) Acc@5 100.000 (99.246)
2025-08-28 05:12:47,545 - INFO - Pruning info: sparsity=0.439
2025-08-28 05:12:47,545 - INFO -   Reactivation rate: 0.0032
2025-08-28 05:12:48,067 - INFO - Epoch: [21][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4856 (0.4761) Acc@1 80.469 (83.640) Acc@5 99.219 (99.258)
2025-08-28 05:12:49,890 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.6343 (0.6343) Acc@1 81.250 (81.250) Acc@5 96.875 (96.875)
2025-08-28 05:12:50,742 - INFO - Epoch 21:
2025-08-28 05:12:50,742 - INFO -   Train: acc1: 83.5120 | acc5: 99.2320 | loss: 0.4809 | sparsity: 0.4387 | reactivation_rate: 0.0041
2025-08-28 05:12:50,742 - INFO -   Val:   acc1: 77.7400 | acc5: 98.3300 | loss: 0.6739
2025-08-28 05:12:50,742 - INFO -   LR: 0.100000
2025-08-28 05:12:50,753 - INFO - 
Epoch: 22, lr = 0.1
2025-08-28 05:12:50,941 - INFO - Epoch: [22][0/391] Time 0.187 (0.187) Data 0.154 (0.154) Loss 0.3800 (0.3800) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:12:51,680 - INFO - Pruning info: sparsity=0.453
2025-08-28 05:12:51,680 - INFO -   Reactivation rate: 0.0065
2025-08-28 05:12:52,837 - INFO - Epoch: [22][100/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.4796 (0.4583) Acc@1 83.594 (84.383) Acc@5 99.219 (99.226)
2025-08-28 05:12:54,783 - INFO - Pruning info: sparsity=0.453
2025-08-28 05:12:54,784 - INFO -   Reactivation rate: 0.0039
2025-08-28 05:12:54,854 - INFO - Epoch: [22][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5386 (0.4674) Acc@1 79.688 (84.103) Acc@5 99.219 (99.172)
2025-08-28 05:12:56,680 - INFO - Epoch: [22][300/391] Time 0.022 (0.020) Data 0.010 (0.002) Loss 0.3406 (0.4665) Acc@1 86.719 (84.064) Acc@5 100.000 (99.201)
2025-08-28 05:12:57,777 - INFO - Pruning info: sparsity=0.453
2025-08-28 05:12:57,778 - INFO -   Reactivation rate: 0.0028
2025-08-28 05:12:58,484 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.8407 (0.8407) Acc@1 75.781 (75.781) Acc@5 96.094 (96.094)
2025-08-28 05:12:59,316 - INFO - Epoch 22:
2025-08-28 05:12:59,317 - INFO -   Train: acc1: 83.9080 | acc5: 99.2120 | loss: 0.4721 | sparsity: 0.4530 | reactivation_rate: 0.0040
2025-08-28 05:12:59,317 - INFO -   Val:   acc1: 70.8700 | acc5: 97.4500 | loss: 0.9119
2025-08-28 05:12:59,317 - INFO -   LR: 0.100000
2025-08-28 05:12:59,328 - INFO - 
Epoch: 23, lr = 0.1
2025-08-28 05:12:59,509 - INFO - Epoch: [23][0/391] Time 0.179 (0.179) Data 0.151 (0.151) Loss 0.4517 (0.4517) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 05:13:01,350 - INFO - Epoch: [23][100/391] Time 0.011 (0.020) Data 0.000 (0.006) Loss 0.5055 (0.4614) Acc@1 83.594 (83.841) Acc@5 99.219 (99.234)
2025-08-28 05:13:01,815 - INFO - Pruning info: sparsity=0.467
2025-08-28 05:13:01,815 - INFO -   Reactivation rate: 0.0044
2025-08-28 05:13:03,239 - INFO - Epoch: [23][200/391] Time 0.020 (0.019) Data 0.000 (0.005) Loss 0.4705 (0.4745) Acc@1 83.594 (83.660) Acc@5 98.438 (99.230)
2025-08-28 05:13:04,842 - INFO - Pruning info: sparsity=0.467
2025-08-28 05:13:04,842 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:13:05,106 - INFO - Epoch: [23][300/391] Time 0.025 (0.019) Data 0.012 (0.004) Loss 0.5039 (0.4740) Acc@1 81.250 (83.778) Acc@5 100.000 (99.255)
2025-08-28 05:13:06,933 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.4399 (0.4399) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:13:07,762 - INFO - Epoch 23:
2025-08-28 05:13:07,762 - INFO -   Train: acc1: 83.7500 | acc5: 99.2460 | loss: 0.4762 | sparsity: 0.4667 | reactivation_rate: 0.0039
2025-08-28 05:13:07,762 - INFO -   Val:   acc1: 79.4100 | acc5: 98.6300 | loss: 0.6291
2025-08-28 05:13:07,762 - INFO -   LR: 0.100000
2025-08-28 05:13:07,807 - INFO - Checkpoint saved: epoch=23, metric=79.4100
2025-08-28 05:13:07,885 - INFO - 
Epoch: 24, lr = 0.1
2025-08-28 05:13:08,065 - INFO - Epoch: [24][0/391] Time 0.179 (0.179) Data 0.152 (0.152) Loss 0.4113 (0.4113) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:13:09,243 - INFO - Pruning info: sparsity=0.480
2025-08-28 05:13:09,243 - INFO -   Reactivation rate: 0.0057
2025-08-28 05:13:10,052 - INFO - Epoch: [24][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.5117 (0.4687) Acc@1 81.250 (83.462) Acc@5 98.438 (99.335)
2025-08-28 05:13:11,887 - INFO - Epoch: [24][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4964 (0.4691) Acc@1 84.375 (83.551) Acc@5 98.438 (99.285)
2025-08-28 05:13:12,150 - INFO - Pruning info: sparsity=0.480
2025-08-28 05:13:12,150 - INFO -   Reactivation rate: 0.0032
2025-08-28 05:13:13,739 - INFO - Epoch: [24][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.5735 (0.4661) Acc@1 78.125 (83.737) Acc@5 100.000 (99.312)
2025-08-28 05:13:15,096 - INFO - Pruning info: sparsity=0.480
2025-08-28 05:13:15,096 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:13:15,494 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5277 (0.5277) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:13:16,314 - INFO - Epoch 24:
2025-08-28 05:13:16,314 - INFO -   Train: acc1: 83.8140 | acc5: 99.2720 | loss: 0.4658 | sparsity: 0.4799 | reactivation_rate: 0.0037
2025-08-28 05:13:16,314 - INFO -   Val:   acc1: 82.0200 | acc5: 99.2400 | loss: 0.5461
2025-08-28 05:13:16,314 - INFO -   LR: 0.100000
2025-08-28 05:13:16,361 - INFO - Checkpoint saved: epoch=24, metric=82.0200
2025-08-28 05:13:16,393 - INFO - 
Epoch: 25, lr = 0.1
2025-08-28 05:13:16,553 - INFO - Epoch: [25][0/391] Time 0.159 (0.159) Data 0.140 (0.140) Loss 0.4074 (0.4074) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:13:18,404 - INFO - Epoch: [25][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5902 (0.4523) Acc@1 79.688 (84.568) Acc@5 96.875 (99.358)
2025-08-28 05:13:19,242 - INFO - Pruning info: sparsity=0.493
2025-08-28 05:13:19,242 - INFO -   Reactivation rate: 0.0038
2025-08-28 05:13:20,358 - INFO - Epoch: [25][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.5386 (0.4666) Acc@1 81.250 (83.916) Acc@5 99.219 (99.366)
2025-08-28 05:13:22,259 - INFO - Epoch: [25][300/391] Time 0.020 (0.019) Data 0.001 (0.004) Loss 0.5332 (0.4657) Acc@1 80.469 (84.014) Acc@5 99.219 (99.364)
2025-08-28 05:13:22,351 - INFO - Pruning info: sparsity=0.493
2025-08-28 05:13:22,351 - INFO -   Reactivation rate: 0.0028
2025-08-28 05:13:24,093 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6568 (0.6568) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 05:13:24,943 - INFO - Epoch 25:
2025-08-28 05:13:24,943 - INFO -   Train: acc1: 83.9560 | acc5: 99.3340 | loss: 0.4666 | sparsity: 0.4926 | reactivation_rate: 0.0036
2025-08-28 05:13:24,943 - INFO -   Val:   acc1: 76.5100 | acc5: 98.4200 | loss: 0.6990
2025-08-28 05:13:24,943 - INFO -   LR: 0.100000
2025-08-28 05:13:24,953 - INFO - 
Epoch: 26, lr = 0.1
2025-08-28 05:13:25,155 - INFO - Epoch: [26][0/391] Time 0.202 (0.202) Data 0.177 (0.177) Loss 0.3730 (0.3730) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:13:26,558 - INFO - Pruning info: sparsity=0.505
2025-08-28 05:13:26,558 - INFO -   Reactivation rate: 0.0050
2025-08-28 05:13:27,042 - INFO - Epoch: [26][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.4900 (0.4696) Acc@1 85.156 (83.903) Acc@5 98.438 (99.350)
2025-08-28 05:13:28,879 - INFO - Epoch: [26][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4512 (0.4623) Acc@1 84.375 (84.169) Acc@5 100.000 (99.355)
2025-08-28 05:13:29,573 - INFO - Pruning info: sparsity=0.505
2025-08-28 05:13:29,573 - INFO -   Reactivation rate: 0.0029
2025-08-28 05:13:30,751 - INFO - Epoch: [26][300/391] Time 0.018 (0.019) Data 0.006 (0.003) Loss 0.6497 (0.4668) Acc@1 76.562 (84.056) Acc@5 100.000 (99.367)
2025-08-28 05:13:32,538 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 1.1319 (1.1319) Acc@1 68.750 (68.750) Acc@5 98.438 (98.438)
2025-08-28 05:13:33,367 - INFO - Epoch 26:
2025-08-28 05:13:33,367 - INFO -   Train: acc1: 84.2180 | acc5: 99.3860 | loss: 0.4603 | sparsity: 0.5048 | reactivation_rate: 0.0035
2025-08-28 05:13:33,367 - INFO -   Val:   acc1: 70.8500 | acc5: 97.9700 | loss: 1.0296
2025-08-28 05:13:33,367 - INFO -   LR: 0.100000
2025-08-28 05:13:33,377 - INFO - 
Epoch: 27, lr = 0.1
2025-08-28 05:13:33,547 - INFO - Epoch: [27][0/391] Time 0.169 (0.169) Data 0.149 (0.149) Loss 0.4225 (0.4225) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:13:33,594 - INFO - Pruning info: sparsity=0.516
2025-08-28 05:13:33,594 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:13:35,402 - INFO - Epoch: [27][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4890 (0.4371) Acc@1 84.375 (85.218) Acc@5 99.219 (99.319)
2025-08-28 05:13:36,530 - INFO - Pruning info: sparsity=0.516
2025-08-28 05:13:36,530 - INFO -   Reactivation rate: 0.0034
2025-08-28 05:13:37,245 - INFO - Epoch: [27][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.4309 (0.4461) Acc@1 85.938 (84.841) Acc@5 98.438 (99.355)
2025-08-28 05:13:39,040 - INFO - Epoch: [27][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4747 (0.4504) Acc@1 84.375 (84.559) Acc@5 97.656 (99.367)
2025-08-28 05:13:39,468 - INFO - Pruning info: sparsity=0.516
2025-08-28 05:13:39,468 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:13:40,871 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5315 (0.5315) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 05:13:41,701 - INFO - Epoch 27:
2025-08-28 05:13:41,701 - INFO -   Train: acc1: 84.3520 | acc5: 99.3540 | loss: 0.4552 | sparsity: 0.5165 | reactivation_rate: 0.0033
2025-08-28 05:13:41,702 - INFO -   Val:   acc1: 79.3400 | acc5: 99.0900 | loss: 0.5849
2025-08-28 05:13:41,702 - INFO -   LR: 0.100000
2025-08-28 05:13:41,711 - INFO - 
Epoch: 28, lr = 0.1
2025-08-28 05:13:41,902 - INFO - Epoch: [28][0/391] Time 0.190 (0.190) Data 0.172 (0.172) Loss 0.3095 (0.3095) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:13:43,579 - INFO - Pruning info: sparsity=0.528
2025-08-28 05:13:43,579 - INFO -   Reactivation rate: 0.0043
2025-08-28 05:13:43,717 - INFO - Epoch: [28][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4734 (0.4430) Acc@1 85.938 (84.808) Acc@5 99.219 (99.404)
2025-08-28 05:13:45,592 - INFO - Epoch: [28][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4598 (0.4540) Acc@1 85.938 (84.212) Acc@5 98.438 (99.359)
2025-08-28 05:13:46,522 - INFO - Pruning info: sparsity=0.528
2025-08-28 05:13:46,522 - INFO -   Reactivation rate: 0.0027
2025-08-28 05:13:47,408 - INFO - Epoch: [28][300/391] Time 0.032 (0.019) Data 0.000 (0.003) Loss 0.4773 (0.4557) Acc@1 86.719 (84.167) Acc@5 100.000 (99.336)
2025-08-28 05:13:49,159 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5533 (0.5533) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 05:13:49,981 - INFO - Epoch 28:
2025-08-28 05:13:49,981 - INFO -   Train: acc1: 84.0540 | acc5: 99.3520 | loss: 0.4582 | sparsity: 0.5277 | reactivation_rate: 0.0032
2025-08-28 05:13:49,981 - INFO -   Val:   acc1: 80.1000 | acc5: 99.1400 | loss: 0.5875
2025-08-28 05:13:49,981 - INFO -   LR: 0.100000
2025-08-28 05:13:49,990 - INFO - 
Epoch: 29, lr = 0.1
2025-08-28 05:13:50,198 - INFO - Epoch: [29][0/391] Time 0.207 (0.207) Data 0.185 (0.185) Loss 0.6134 (0.6134) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-28 05:13:50,593 - INFO - Pruning info: sparsity=0.538
2025-08-28 05:13:50,593 - INFO -   Reactivation rate: 0.0056
2025-08-28 05:13:51,983 - INFO - Epoch: [29][100/391] Time 0.019 (0.020) Data 0.006 (0.004) Loss 0.4196 (0.4430) Acc@1 85.156 (84.785) Acc@5 99.219 (99.304)
2025-08-28 05:13:53,452 - INFO - Pruning info: sparsity=0.538
2025-08-28 05:13:53,453 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:13:53,850 - INFO - Epoch: [29][200/391] Time 0.031 (0.019) Data 0.013 (0.003) Loss 0.4282 (0.4510) Acc@1 84.375 (84.550) Acc@5 100.000 (99.331)
2025-08-28 05:13:55,700 - INFO - Epoch: [29][300/391] Time 0.026 (0.019) Data 0.009 (0.003) Loss 0.4776 (0.4544) Acc@1 82.812 (84.385) Acc@5 99.219 (99.338)
2025-08-28 05:13:56,389 - INFO - Pruning info: sparsity=0.538
2025-08-28 05:13:56,389 - INFO -   Reactivation rate: 0.0022
2025-08-28 05:13:57,434 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5014 (0.5014) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:13:58,256 - INFO - Epoch 29:
2025-08-28 05:13:58,256 - INFO -   Train: acc1: 84.3620 | acc5: 99.3300 | loss: 0.4547 | sparsity: 0.5385 | reactivation_rate: 0.0031
2025-08-28 05:13:58,256 - INFO -   Val:   acc1: 83.6400 | acc5: 99.2600 | loss: 0.4777
2025-08-28 05:13:58,256 - INFO -   LR: 0.100000
2025-08-28 05:13:58,301 - INFO - Checkpoint saved: epoch=29, metric=83.6400
2025-08-28 05:13:58,332 - INFO - 
Epoch: 30, lr = 0.1
2025-08-28 05:13:58,522 - INFO - Epoch: [30][0/391] Time 0.189 (0.189) Data 0.172 (0.172) Loss 0.3789 (0.3789) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:14:00,343 - INFO - Epoch: [30][100/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.4695 (0.4532) Acc@1 84.375 (84.421) Acc@5 100.000 (99.420)
2025-08-28 05:14:00,511 - INFO - Pruning info: sparsity=0.549
2025-08-28 05:14:00,511 - INFO -   Reactivation rate: 0.0037
2025-08-28 05:14:02,128 - INFO - Epoch: [30][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4512 (0.4496) Acc@1 84.375 (84.604) Acc@5 99.219 (99.386)
2025-08-28 05:14:03,474 - INFO - Pruning info: sparsity=0.549
2025-08-28 05:14:03,474 - INFO -   Reactivation rate: 0.0024
2025-08-28 05:14:04,039 - INFO - Epoch: [30][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4982 (0.4517) Acc@1 85.938 (84.474) Acc@5 98.438 (99.349)
2025-08-28 05:14:05,869 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6145 (0.6145) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-28 05:14:06,721 - INFO - Epoch 30:
2025-08-28 05:14:06,721 - INFO -   Train: acc1: 84.4440 | acc5: 99.3480 | loss: 0.4521 | sparsity: 0.5488 | reactivation_rate: 0.0030
2025-08-28 05:14:06,721 - INFO -   Val:   acc1: 79.8100 | acc5: 98.6400 | loss: 0.6026
2025-08-28 05:14:06,721 - INFO -   LR: 0.100000
2025-08-28 05:14:06,765 - INFO - 
Epoch: 31, lr = 0.1
2025-08-28 05:14:06,939 - INFO - Epoch: [31][0/391] Time 0.173 (0.173) Data 0.149 (0.149) Loss 0.5802 (0.5802) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 05:14:07,630 - INFO - Pruning info: sparsity=0.559
2025-08-28 05:14:07,630 - INFO -   Reactivation rate: 0.0049
2025-08-28 05:14:08,829 - INFO - Epoch: [31][100/391] Time 0.060 (0.020) Data 0.036 (0.004) Loss 0.3320 (0.4394) Acc@1 87.500 (84.963) Acc@5 100.000 (99.428)
2025-08-28 05:14:10,600 - INFO - Pruning info: sparsity=0.559
2025-08-28 05:14:10,600 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:14:10,623 - INFO - Epoch: [31][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5025 (0.4450) Acc@1 82.812 (84.760) Acc@5 97.656 (99.374)
2025-08-28 05:14:12,478 - INFO - Epoch: [31][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4219 (0.4511) Acc@1 85.938 (84.601) Acc@5 98.438 (99.359)
2025-08-28 05:14:13,548 - INFO - Pruning info: sparsity=0.559
2025-08-28 05:14:13,548 - INFO -   Reactivation rate: 0.0021
2025-08-28 05:14:14,352 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.7634 (0.7634) Acc@1 71.875 (71.875) Acc@5 97.656 (97.656)
2025-08-28 05:14:15,210 - INFO - Epoch 31:
2025-08-28 05:14:15,210 - INFO -   Train: acc1: 84.5240 | acc5: 99.3760 | loss: 0.4504 | sparsity: 0.5587 | reactivation_rate: 0.0029
2025-08-28 05:14:15,210 - INFO -   Val:   acc1: 74.7500 | acc5: 98.0700 | loss: 0.8019
2025-08-28 05:14:15,210 - INFO -   LR: 0.100000
2025-08-28 05:14:15,220 - INFO - 
Epoch: 32, lr = 0.1
2025-08-28 05:14:15,419 - INFO - Epoch: [32][0/391] Time 0.198 (0.198) Data 0.157 (0.157) Loss 0.5971 (0.5971) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 05:14:17,268 - INFO - Epoch: [32][100/391] Time 0.015 (0.020) Data 0.005 (0.005) Loss 0.4295 (0.4310) Acc@1 85.938 (85.032) Acc@5 98.438 (99.412)
2025-08-28 05:14:17,822 - INFO - Pruning info: sparsity=0.568
2025-08-28 05:14:17,822 - INFO -   Reactivation rate: 0.0031
2025-08-28 05:14:19,142 - INFO - Epoch: [32][200/391] Time 0.028 (0.019) Data 0.005 (0.005) Loss 0.4798 (0.4333) Acc@1 84.375 (85.125) Acc@5 99.219 (99.394)
2025-08-28 05:14:20,860 - INFO - Pruning info: sparsity=0.568
2025-08-28 05:14:20,860 - INFO -   Reactivation rate: 0.0021
2025-08-28 05:14:21,124 - INFO - Epoch: [32][300/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.3789 (0.4401) Acc@1 88.281 (84.886) Acc@5 100.000 (99.377)
2025-08-28 05:14:22,913 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5232 (0.5232) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 05:14:23,740 - INFO - Epoch 32:
2025-08-28 05:14:23,740 - INFO -   Train: acc1: 84.7380 | acc5: 99.3520 | loss: 0.4445 | sparsity: 0.5681 | reactivation_rate: 0.0028
2025-08-28 05:14:23,740 - INFO -   Val:   acc1: 80.3900 | acc5: 99.0900 | loss: 0.5948
2025-08-28 05:14:23,740 - INFO -   LR: 0.100000
2025-08-28 05:14:23,752 - INFO - 
Epoch: 33, lr = 0.1
2025-08-28 05:14:23,910 - INFO - Epoch: [33][0/391] Time 0.156 (0.156) Data 0.129 (0.129) Loss 0.3815 (0.3815) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 05:14:24,979 - INFO - Pruning info: sparsity=0.577
2025-08-28 05:14:24,979 - INFO -   Reactivation rate: 0.0042
2025-08-28 05:14:25,790 - INFO - Epoch: [33][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.3922 (0.4514) Acc@1 85.156 (84.506) Acc@5 99.219 (99.381)
2025-08-28 05:14:27,648 - INFO - Epoch: [33][200/391] Time 0.038 (0.019) Data 0.015 (0.003) Loss 0.6078 (0.4398) Acc@1 82.812 (84.888) Acc@5 98.438 (99.339)
2025-08-28 05:14:27,960 - INFO - Pruning info: sparsity=0.577
2025-08-28 05:14:27,960 - INFO -   Reactivation rate: 0.0024
2025-08-28 05:14:29,476 - INFO - Epoch: [33][300/391] Time 0.014 (0.019) Data 0.002 (0.003) Loss 0.3874 (0.4381) Acc@1 88.281 (85.024) Acc@5 100.000 (99.338)
2025-08-28 05:14:30,887 - INFO - Pruning info: sparsity=0.577
2025-08-28 05:14:30,888 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:14:31,288 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.6380 (0.6380) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-28 05:14:32,124 - INFO - Epoch 33:
2025-08-28 05:14:32,124 - INFO -   Train: acc1: 84.7400 | acc5: 99.3440 | loss: 0.4446 | sparsity: 0.5771 | reactivation_rate: 0.0027
2025-08-28 05:14:32,124 - INFO -   Val:   acc1: 78.8400 | acc5: 98.7100 | loss: 0.6417
2025-08-28 05:14:32,124 - INFO -   LR: 0.100000
2025-08-28 05:14:32,135 - INFO - 
Epoch: 34, lr = 0.1
2025-08-28 05:14:32,344 - INFO - Epoch: [34][0/391] Time 0.208 (0.208) Data 0.182 (0.182) Loss 0.4697 (0.4697) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:14:34,172 - INFO - Epoch: [34][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4936 (0.4267) Acc@1 82.031 (85.396) Acc@5 98.438 (99.358)
2025-08-28 05:14:35,009 - INFO - Pruning info: sparsity=0.586
2025-08-28 05:14:35,009 - INFO -   Reactivation rate: 0.0027
2025-08-28 05:14:35,993 - INFO - Epoch: [34][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3578 (0.4330) Acc@1 84.375 (85.129) Acc@5 100.000 (99.331)
2025-08-28 05:14:37,862 - INFO - Epoch: [34][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5002 (0.4362) Acc@1 85.938 (85.006) Acc@5 98.438 (99.382)
2025-08-28 05:14:37,950 - INFO - Pruning info: sparsity=0.586
2025-08-28 05:14:37,950 - INFO -   Reactivation rate: 0.0020
2025-08-28 05:14:39,695 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.4798 (0.4798) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 05:14:40,523 - INFO - Epoch 34:
2025-08-28 05:14:40,524 - INFO -   Train: acc1: 84.8060 | acc5: 99.3540 | loss: 0.4434 | sparsity: 0.5856 | reactivation_rate: 0.0026
2025-08-28 05:14:40,524 - INFO -   Val:   acc1: 80.3000 | acc5: 98.7700 | loss: 0.5950
2025-08-28 05:14:40,524 - INFO -   LR: 0.100000
2025-08-28 05:14:40,533 - INFO - 
Epoch: 35, lr = 0.1
2025-08-28 05:14:40,715 - INFO - Epoch: [35][0/391] Time 0.181 (0.181) Data 0.164 (0.164) Loss 0.3799 (0.3799) Acc@1 89.062 (89.062) Acc@5 98.438 (98.438)
2025-08-28 05:14:42,056 - INFO - Pruning info: sparsity=0.594
2025-08-28 05:14:42,056 - INFO -   Reactivation rate: 0.0036
2025-08-28 05:14:42,574 - INFO - Epoch: [35][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.5528 (0.4378) Acc@1 82.031 (85.009) Acc@5 97.656 (99.366)
2025-08-28 05:14:44,427 - INFO - Epoch: [35][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3821 (0.4324) Acc@1 87.500 (85.141) Acc@5 99.219 (99.382)
2025-08-28 05:14:45,015 - INFO - Pruning info: sparsity=0.594
2025-08-28 05:14:45,015 - INFO -   Reactivation rate: 0.0022
2025-08-28 05:14:46,245 - INFO - Epoch: [35][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3950 (0.4350) Acc@1 86.719 (85.086) Acc@5 99.219 (99.362)
2025-08-28 05:14:48,027 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.4272 (0.4272) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 05:14:48,881 - INFO - Epoch 35:
2025-08-28 05:14:48,882 - INFO -   Train: acc1: 84.9980 | acc5: 99.3580 | loss: 0.4372 | sparsity: 0.5938 | reactivation_rate: 0.0026
2025-08-28 05:14:48,882 - INFO -   Val:   acc1: 81.1000 | acc5: 98.9800 | loss: 0.5657
2025-08-28 05:14:48,882 - INFO -   LR: 0.100000
2025-08-28 05:14:48,893 - INFO - 
Epoch: 36, lr = 0.1
2025-08-28 05:14:49,067 - INFO - Epoch: [36][0/391] Time 0.173 (0.173) Data 0.145 (0.145) Loss 0.3478 (0.3478) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-28 05:14:49,163 - INFO - Pruning info: sparsity=0.602
2025-08-28 05:14:49,163 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:14:51,062 - INFO - Epoch: [36][100/391] Time 0.031 (0.021) Data 0.000 (0.003) Loss 0.3909 (0.4251) Acc@1 85.938 (85.257) Acc@5 100.000 (99.544)
2025-08-28 05:14:52,251 - INFO - Pruning info: sparsity=0.602
2025-08-28 05:14:52,251 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:14:52,912 - INFO - Epoch: [36][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3333 (0.4292) Acc@1 90.625 (85.145) Acc@5 100.000 (99.429)
2025-08-28 05:14:54,753 - INFO - Epoch: [36][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.4906 (0.4304) Acc@1 82.031 (85.110) Acc@5 98.438 (99.416)
2025-08-28 05:14:55,233 - INFO - Pruning info: sparsity=0.602
2025-08-28 05:14:55,234 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:14:56,606 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.6857 (0.6857) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:14:57,445 - INFO - Epoch 36:
2025-08-28 05:14:57,445 - INFO -   Train: acc1: 85.0900 | acc5: 99.4080 | loss: 0.4335 | sparsity: 0.6016 | reactivation_rate: 0.0025
2025-08-28 05:14:57,445 - INFO -   Val:   acc1: 72.8400 | acc5: 98.7600 | loss: 0.8516
2025-08-28 05:14:57,445 - INFO -   LR: 0.100000
2025-08-28 05:14:57,456 - INFO - 
Epoch: 37, lr = 0.1
2025-08-28 05:14:57,636 - INFO - Epoch: [37][0/391] Time 0.179 (0.179) Data 0.162 (0.162) Loss 0.3968 (0.3968) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:14:59,386 - INFO - Pruning info: sparsity=0.609
2025-08-28 05:14:59,386 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:14:59,510 - INFO - Epoch: [37][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4446 (0.4285) Acc@1 82.031 (85.156) Acc@5 100.000 (99.482)
2025-08-28 05:15:01,436 - INFO - Epoch: [37][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.4074 (0.4480) Acc@1 86.719 (84.363) Acc@5 98.438 (99.417)
2025-08-28 05:15:02,401 - INFO - Pruning info: sparsity=0.609
2025-08-28 05:15:02,401 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:15:03,374 - INFO - Epoch: [37][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5622 (0.4437) Acc@1 80.469 (84.679) Acc@5 99.219 (99.403)
2025-08-28 05:15:05,259 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.6837 (0.6837) Acc@1 78.906 (78.906) Acc@5 96.875 (96.875)
2025-08-28 05:15:06,090 - INFO - Epoch 37:
2025-08-28 05:15:06,090 - INFO -   Train: acc1: 84.7100 | acc5: 99.3740 | loss: 0.4443 | sparsity: 0.6090 | reactivation_rate: 0.0023
2025-08-28 05:15:06,090 - INFO -   Val:   acc1: 78.6600 | acc5: 98.6800 | loss: 0.6365
2025-08-28 05:15:06,090 - INFO -   LR: 0.100000
2025-08-28 05:15:06,101 - INFO - 
Epoch: 38, lr = 0.1
2025-08-28 05:15:06,289 - INFO - Epoch: [38][0/391] Time 0.187 (0.187) Data 0.157 (0.157) Loss 0.3743 (0.3743) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:15:06,671 - INFO - Pruning info: sparsity=0.616
2025-08-28 05:15:06,671 - INFO -   Reactivation rate: 0.0043
2025-08-28 05:15:08,139 - INFO - Epoch: [38][100/391] Time 0.022 (0.020) Data 0.010 (0.003) Loss 0.4938 (0.4268) Acc@1 84.375 (85.272) Acc@5 99.219 (99.373)
2025-08-28 05:15:09,690 - INFO - Pruning info: sparsity=0.616
2025-08-28 05:15:09,690 - INFO -   Reactivation rate: 0.0021
2025-08-28 05:15:10,000 - INFO - Epoch: [38][200/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.4742 (0.4319) Acc@1 84.375 (84.981) Acc@5 99.219 (99.413)
2025-08-28 05:15:11,831 - INFO - Epoch: [38][300/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.4799 (0.4380) Acc@1 82.031 (84.873) Acc@5 99.219 (99.395)
2025-08-28 05:15:12,562 - INFO - Pruning info: sparsity=0.616
2025-08-28 05:15:12,562 - INFO -   Reactivation rate: 0.0016
2025-08-28 05:15:13,667 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.4815 (0.4815) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:15:14,516 - INFO - Epoch 38:
2025-08-28 05:15:14,517 - INFO -   Train: acc1: 84.8080 | acc5: 99.3960 | loss: 0.4388 | sparsity: 0.6160 | reactivation_rate: 0.0022
2025-08-28 05:15:14,517 - INFO -   Val:   acc1: 80.5000 | acc5: 98.9800 | loss: 0.5624
2025-08-28 05:15:14,517 - INFO -   LR: 0.100000
2025-08-28 05:15:14,529 - INFO - 
Epoch: 39, lr = 0.1
2025-08-28 05:15:14,711 - INFO - Epoch: [39][0/391] Time 0.182 (0.182) Data 0.155 (0.155) Loss 0.3912 (0.3912) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:15:16,565 - INFO - Epoch: [39][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4165 (0.4265) Acc@1 84.375 (85.179) Acc@5 98.438 (99.397)
2025-08-28 05:15:16,730 - INFO - Pruning info: sparsity=0.623
2025-08-28 05:15:16,730 - INFO -   Reactivation rate: 0.0026
2025-08-28 05:15:18,360 - INFO - Epoch: [39][200/391] Time 0.036 (0.019) Data 0.000 (0.003) Loss 0.4457 (0.4324) Acc@1 83.594 (84.923) Acc@5 100.000 (99.448)
2025-08-28 05:15:19,620 - INFO - Pruning info: sparsity=0.623
2025-08-28 05:15:19,621 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:15:20,161 - INFO - Epoch: [39][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.5117 (0.4343) Acc@1 82.031 (84.956) Acc@5 97.656 (99.439)
2025-08-28 05:15:21,968 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.4387 (0.4387) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:15:22,817 - INFO - Epoch 39:
2025-08-28 05:15:22,817 - INFO -   Train: acc1: 84.9460 | acc5: 99.4220 | loss: 0.4376 | sparsity: 0.6226 | reactivation_rate: 0.0022
2025-08-28 05:15:22,817 - INFO -   Val:   acc1: 83.4600 | acc5: 99.2300 | loss: 0.4897
2025-08-28 05:15:22,817 - INFO -   LR: 0.100000
2025-08-28 05:15:22,829 - INFO - 
Epoch: 40, lr = 0.1
2025-08-28 05:15:23,014 - INFO - Epoch: [40][0/391] Time 0.184 (0.184) Data 0.166 (0.166) Loss 0.3803 (0.3803) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-28 05:15:23,727 - INFO - Pruning info: sparsity=0.629
2025-08-28 05:15:23,727 - INFO -   Reactivation rate: 0.0037
2025-08-28 05:15:24,883 - INFO - Epoch: [40][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.4019 (0.4289) Acc@1 85.938 (85.056) Acc@5 99.219 (99.404)
2025-08-28 05:15:26,669 - INFO - Pruning info: sparsity=0.629
2025-08-28 05:15:26,670 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:15:26,682 - INFO - Epoch: [40][200/391] Time 0.018 (0.019) Data 0.001 (0.003) Loss 0.4495 (0.4257) Acc@1 86.719 (85.176) Acc@5 99.219 (99.429)
2025-08-28 05:15:28,483 - INFO - Epoch: [40][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4830 (0.4321) Acc@1 82.812 (85.029) Acc@5 99.219 (99.408)
2025-08-28 05:15:29,605 - INFO - Pruning info: sparsity=0.629
2025-08-28 05:15:29,605 - INFO -   Reactivation rate: 0.0016
2025-08-28 05:15:30,293 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.5035 (0.5035) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:15:31,138 - INFO - Epoch 40:
2025-08-28 05:15:31,138 - INFO -   Train: acc1: 84.9200 | acc5: 99.4020 | loss: 0.4355 | sparsity: 0.6289 | reactivation_rate: 0.0022
2025-08-28 05:15:31,138 - INFO -   Val:   acc1: 82.5100 | acc5: 99.2700 | loss: 0.5241
2025-08-28 05:15:31,138 - INFO -   LR: 0.100000
2025-08-28 05:15:31,183 - INFO - 
Epoch: 41, lr = 0.1
2025-08-28 05:15:31,386 - INFO - Epoch: [41][0/391] Time 0.202 (0.202) Data 0.167 (0.167) Loss 0.4062 (0.4062) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:15:33,294 - INFO - Epoch: [41][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.4614 (0.4102) Acc@1 83.594 (85.829) Acc@5 100.000 (99.435)
2025-08-28 05:15:33,768 - INFO - Pruning info: sparsity=0.635
2025-08-28 05:15:33,768 - INFO -   Reactivation rate: 0.0024
2025-08-28 05:15:35,109 - INFO - Epoch: [41][200/391] Time 0.020 (0.020) Data 0.000 (0.005) Loss 0.4645 (0.4229) Acc@1 83.594 (85.479) Acc@5 99.219 (99.382)
2025-08-28 05:15:36,688 - INFO - Pruning info: sparsity=0.635
2025-08-28 05:15:36,688 - INFO -   Reactivation rate: 0.0016
2025-08-28 05:15:36,938 - INFO - Epoch: [41][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.3260 (0.4252) Acc@1 87.500 (85.496) Acc@5 99.219 (99.377)
2025-08-28 05:15:38,709 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5977 (0.5977) Acc@1 80.469 (80.469) Acc@5 96.875 (96.875)
2025-08-28 05:15:39,549 - INFO - Epoch 41:
2025-08-28 05:15:39,549 - INFO -   Train: acc1: 85.2420 | acc5: 99.3940 | loss: 0.4325 | sparsity: 0.6348 | reactivation_rate: 0.0021
2025-08-28 05:15:39,549 - INFO -   Val:   acc1: 78.1600 | acc5: 98.5700 | loss: 0.6493
2025-08-28 05:15:39,549 - INFO -   LR: 0.100000
2025-08-28 05:15:39,560 - INFO - 
Epoch: 42, lr = 0.1
2025-08-28 05:15:39,748 - INFO - Epoch: [42][0/391] Time 0.187 (0.187) Data 0.168 (0.168) Loss 0.4047 (0.4047) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:15:40,806 - INFO - Pruning info: sparsity=0.640
2025-08-28 05:15:40,807 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:15:41,628 - INFO - Epoch: [42][100/391] Time 0.029 (0.020) Data 0.000 (0.004) Loss 0.6512 (0.4172) Acc@1 71.875 (85.667) Acc@5 98.438 (99.397)
2025-08-28 05:15:43,536 - INFO - Epoch: [42][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.6402 (0.4209) Acc@1 79.688 (85.623) Acc@5 97.656 (99.452)
2025-08-28 05:15:43,900 - INFO - Pruning info: sparsity=0.640
2025-08-28 05:15:43,901 - INFO -   Reactivation rate: 0.0018
2025-08-28 05:15:45,406 - INFO - Epoch: [42][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.3576 (0.4297) Acc@1 87.500 (85.247) Acc@5 100.000 (99.437)
2025-08-28 05:15:46,772 - INFO - Pruning info: sparsity=0.640
2025-08-28 05:15:46,772 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:15:47,161 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5150 (0.5150) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 05:15:48,028 - INFO - Epoch 42:
2025-08-28 05:15:48,028 - INFO -   Train: acc1: 85.2580 | acc5: 99.4260 | loss: 0.4305 | sparsity: 0.6404 | reactivation_rate: 0.0020
2025-08-28 05:15:48,028 - INFO -   Val:   acc1: 80.9000 | acc5: 99.0900 | loss: 0.5728
2025-08-28 05:15:48,028 - INFO -   LR: 0.100000
2025-08-28 05:15:48,042 - INFO - 
Epoch: 43, lr = 0.1
2025-08-28 05:15:48,223 - INFO - Epoch: [43][0/391] Time 0.181 (0.181) Data 0.154 (0.154) Loss 0.2799 (0.2799) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:15:50,079 - INFO - Epoch: [43][100/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.3827 (0.4398) Acc@1 86.719 (84.568) Acc@5 99.219 (99.497)
2025-08-28 05:15:50,910 - INFO - Pruning info: sparsity=0.646
2025-08-28 05:15:50,910 - INFO -   Reactivation rate: 0.0020
2025-08-28 05:15:51,942 - INFO - Epoch: [43][200/391] Time 0.033 (0.019) Data 0.008 (0.002) Loss 0.3042 (0.4301) Acc@1 86.719 (85.110) Acc@5 100.000 (99.409)
2025-08-28 05:15:53,683 - INFO - Epoch: [43][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.3100 (0.4313) Acc@1 89.844 (85.154) Acc@5 100.000 (99.408)
2025-08-28 05:15:53,819 - INFO - Pruning info: sparsity=0.646
2025-08-28 05:15:53,819 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:15:55,506 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.7037 (0.7037) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 05:15:56,369 - INFO - Epoch 43:
2025-08-28 05:15:56,370 - INFO -   Train: acc1: 85.1580 | acc5: 99.4100 | loss: 0.4330 | sparsity: 0.6456 | reactivation_rate: 0.0019
2025-08-28 05:15:56,370 - INFO -   Val:   acc1: 79.8000 | acc5: 99.2100 | loss: 0.6250
2025-08-28 05:15:56,370 - INFO -   LR: 0.100000
2025-08-28 05:15:56,381 - INFO - 
Epoch: 44, lr = 0.1
2025-08-28 05:15:56,562 - INFO - Epoch: [44][0/391] Time 0.180 (0.180) Data 0.150 (0.150) Loss 0.3620 (0.3620) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:15:57,988 - INFO - Pruning info: sparsity=0.651
2025-08-28 05:15:57,988 - INFO -   Reactivation rate: 0.0024
2025-08-28 05:15:58,468 - INFO - Epoch: [44][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.3633 (0.4223) Acc@1 88.281 (85.334) Acc@5 99.219 (99.536)
2025-08-28 05:16:00,252 - INFO - Epoch: [44][200/391] Time 0.025 (0.019) Data 0.012 (0.003) Loss 0.4381 (0.4276) Acc@1 86.719 (85.222) Acc@5 99.219 (99.479)
2025-08-28 05:16:00,894 - INFO - Pruning info: sparsity=0.651
2025-08-28 05:16:00,894 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:16:02,088 - INFO - Epoch: [44][300/391] Time 0.028 (0.019) Data 0.011 (0.003) Loss 0.3147 (0.4254) Acc@1 89.062 (85.385) Acc@5 100.000 (99.473)
2025-08-28 05:16:03,861 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.8020 (0.8020) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-28 05:16:04,703 - INFO - Epoch 44:
2025-08-28 05:16:04,704 - INFO -   Train: acc1: 85.3600 | acc5: 99.4580 | loss: 0.4260 | sparsity: 0.6506 | reactivation_rate: 0.0018
2025-08-28 05:16:04,704 - INFO -   Val:   acc1: 76.8000 | acc5: 98.7200 | loss: 0.7472
2025-08-28 05:16:04,704 - INFO -   LR: 0.100000
2025-08-28 05:16:04,716 - INFO - 
Epoch: 45, lr = 0.1
2025-08-28 05:16:04,884 - INFO - Epoch: [45][0/391] Time 0.167 (0.167) Data 0.143 (0.143) Loss 0.3309 (0.3309) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:16:04,971 - INFO - Pruning info: sparsity=0.655
2025-08-28 05:16:04,971 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:16:06,836 - INFO - Epoch: [45][100/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.6170 (0.4201) Acc@1 76.562 (85.992) Acc@5 99.219 (99.412)
2025-08-28 05:16:07,979 - INFO - Pruning info: sparsity=0.655
2025-08-28 05:16:07,979 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:16:08,642 - INFO - Epoch: [45][200/391] Time 0.025 (0.020) Data 0.005 (0.002) Loss 0.3306 (0.4225) Acc@1 87.500 (85.654) Acc@5 100.000 (99.374)
2025-08-28 05:16:10,449 - INFO - Epoch: [45][300/391] Time 0.018 (0.019) Data 0.003 (0.002) Loss 0.3872 (0.4252) Acc@1 85.156 (85.556) Acc@5 100.000 (99.382)
2025-08-28 05:16:10,894 - INFO - Pruning info: sparsity=0.655
2025-08-28 05:16:10,895 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:16:12,242 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6980 (0.6980) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-28 05:16:13,145 - INFO - Epoch 45:
2025-08-28 05:16:13,145 - INFO -   Train: acc1: 85.5880 | acc5: 99.3700 | loss: 0.4254 | sparsity: 0.6552 | reactivation_rate: 0.0018
2025-08-28 05:16:13,145 - INFO -   Val:   acc1: 79.5300 | acc5: 98.7700 | loss: 0.6433
2025-08-28 05:16:13,145 - INFO -   LR: 0.100000
2025-08-28 05:16:13,156 - INFO - 
Epoch: 46, lr = 0.1
2025-08-28 05:16:13,337 - INFO - Epoch: [46][0/391] Time 0.180 (0.180) Data 0.157 (0.157) Loss 0.3188 (0.3188) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-28 05:16:15,098 - INFO - Pruning info: sparsity=0.660
2025-08-28 05:16:15,098 - INFO -   Reactivation rate: 0.0021
2025-08-28 05:16:15,246 - INFO - Epoch: [46][100/391] Time 0.024 (0.021) Data 0.010 (0.004) Loss 0.4256 (0.4037) Acc@1 82.031 (86.015) Acc@5 100.000 (99.528)
2025-08-28 05:16:17,049 - INFO - Epoch: [46][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3917 (0.4259) Acc@1 90.625 (85.444) Acc@5 99.219 (99.460)
2025-08-28 05:16:18,111 - INFO - Pruning info: sparsity=0.660
2025-08-28 05:16:18,111 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:16:18,958 - INFO - Epoch: [46][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3144 (0.4255) Acc@1 89.844 (85.361) Acc@5 100.000 (99.445)
2025-08-28 05:16:20,791 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.5661 (0.5661) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 05:16:21,662 - INFO - Epoch 46:
2025-08-28 05:16:21,662 - INFO -   Train: acc1: 85.0300 | acc5: 99.4440 | loss: 0.4318 | sparsity: 0.6595 | reactivation_rate: 0.0017
2025-08-28 05:16:21,662 - INFO -   Val:   acc1: 81.2200 | acc5: 99.2000 | loss: 0.5448
2025-08-28 05:16:21,662 - INFO -   LR: 0.100000
2025-08-28 05:16:21,675 - INFO - 
Epoch: 47, lr = 0.1
2025-08-28 05:16:21,869 - INFO - Epoch: [47][0/391] Time 0.192 (0.192) Data 0.154 (0.154) Loss 0.4380 (0.4380) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 05:16:22,299 - INFO - Pruning info: sparsity=0.664
2025-08-28 05:16:22,299 - INFO -   Reactivation rate: 0.0031
2025-08-28 05:16:23,761 - INFO - Epoch: [47][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4916 (0.4070) Acc@1 83.594 (86.100) Acc@5 99.219 (99.443)
2025-08-28 05:16:25,282 - INFO - Pruning info: sparsity=0.664
2025-08-28 05:16:25,282 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:16:25,645 - INFO - Epoch: [47][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4799 (0.4206) Acc@1 85.938 (85.576) Acc@5 99.219 (99.386)
2025-08-28 05:16:27,438 - INFO - Epoch: [47][300/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.3814 (0.4275) Acc@1 84.375 (85.289) Acc@5 100.000 (99.374)
2025-08-28 05:16:28,202 - INFO - Pruning info: sparsity=0.664
2025-08-28 05:16:28,202 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:16:29,262 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.4495 (0.4495) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:16:30,076 - INFO - Epoch 47:
2025-08-28 05:16:30,076 - INFO -   Train: acc1: 85.2500 | acc5: 99.3660 | loss: 0.4305 | sparsity: 0.6636 | reactivation_rate: 0.0016
2025-08-28 05:16:30,076 - INFO -   Val:   acc1: 80.7800 | acc5: 99.0000 | loss: 0.5616
2025-08-28 05:16:30,076 - INFO -   LR: 0.100000
2025-08-28 05:16:30,086 - INFO - 
Epoch: 48, lr = 0.1
2025-08-28 05:16:30,265 - INFO - Epoch: [48][0/391] Time 0.178 (0.178) Data 0.144 (0.144) Loss 0.4230 (0.4230) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:16:32,149 - INFO - Epoch: [48][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.4502 (0.4018) Acc@1 85.156 (86.023) Acc@5 100.000 (99.621)
2025-08-28 05:16:32,325 - INFO - Pruning info: sparsity=0.667
2025-08-28 05:16:32,325 - INFO -   Reactivation rate: 0.0018
2025-08-28 05:16:33,932 - INFO - Epoch: [48][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4111 (0.4133) Acc@1 87.500 (85.634) Acc@5 98.438 (99.475)
2025-08-28 05:16:35,322 - INFO - Pruning info: sparsity=0.667
2025-08-28 05:16:35,323 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:16:35,876 - INFO - Epoch: [48][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3921 (0.4203) Acc@1 86.719 (85.455) Acc@5 100.000 (99.458)
2025-08-28 05:16:37,616 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.7874 (0.7874) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 05:16:38,439 - INFO - Epoch 48:
2025-08-28 05:16:38,439 - INFO -   Train: acc1: 85.3020 | acc5: 99.4120 | loss: 0.4262 | sparsity: 0.6673 | reactivation_rate: 0.0015
2025-08-28 05:16:38,439 - INFO -   Val:   acc1: 78.1600 | acc5: 98.5000 | loss: 0.6819
2025-08-28 05:16:38,439 - INFO -   LR: 0.100000
2025-08-28 05:16:38,452 - INFO - 
Epoch: 49, lr = 0.1
2025-08-28 05:16:38,625 - INFO - Epoch: [49][0/391] Time 0.172 (0.172) Data 0.150 (0.150) Loss 0.5907 (0.5907) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 05:16:39,373 - INFO - Pruning info: sparsity=0.671
2025-08-28 05:16:39,373 - INFO -   Reactivation rate: 0.0023
2025-08-28 05:16:40,523 - INFO - Epoch: [49][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.4156 (0.4044) Acc@1 83.594 (85.837) Acc@5 100.000 (99.520)
2025-08-28 05:16:42,363 - INFO - Epoch: [49][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4038 (0.4134) Acc@1 84.375 (85.658) Acc@5 100.000 (99.460)
2025-08-28 05:16:42,368 - INFO - Pruning info: sparsity=0.671
2025-08-28 05:16:42,369 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:16:44,143 - INFO - Epoch: [49][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4605 (0.4240) Acc@1 85.156 (85.309) Acc@5 100.000 (99.432)
2025-08-28 05:16:45,295 - INFO - Pruning info: sparsity=0.671
2025-08-28 05:16:45,296 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:16:45,952 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4696 (0.4696) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:16:46,792 - INFO - Epoch 49:
2025-08-28 05:16:46,793 - INFO -   Train: acc1: 85.3080 | acc5: 99.4240 | loss: 0.4237 | sparsity: 0.6708 | reactivation_rate: 0.0015
2025-08-28 05:16:46,793 - INFO -   Val:   acc1: 81.4500 | acc5: 99.1700 | loss: 0.5771
2025-08-28 05:16:46,793 - INFO -   LR: 0.100000
2025-08-28 05:16:46,804 - INFO - 
Epoch: 50, lr = 0.1
2025-08-28 05:16:47,007 - INFO - Epoch: [50][0/391] Time 0.201 (0.201) Data 0.183 (0.183) Loss 0.2709 (0.2709) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:16:48,842 - INFO - Epoch: [50][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.5843 (0.4175) Acc@1 78.906 (85.582) Acc@5 100.000 (99.497)
2025-08-28 05:16:49,409 - INFO - Pruning info: sparsity=0.674
2025-08-28 05:16:49,409 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:16:50,687 - INFO - Epoch: [50][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3592 (0.4254) Acc@1 89.062 (85.242) Acc@5 100.000 (99.401)
2025-08-28 05:16:52,325 - INFO - Pruning info: sparsity=0.674
2025-08-28 05:16:52,325 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:16:52,501 - INFO - Epoch: [50][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4506 (0.4243) Acc@1 81.250 (85.395) Acc@5 99.219 (99.408)
2025-08-28 05:16:54,397 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.7855 (0.7855) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 05:16:55,236 - INFO - Epoch 50:
2025-08-28 05:16:55,236 - INFO -   Train: acc1: 85.3620 | acc5: 99.3860 | loss: 0.4272 | sparsity: 0.6741 | reactivation_rate: 0.0014
2025-08-28 05:16:55,236 - INFO -   Val:   acc1: 78.1900 | acc5: 99.0600 | loss: 0.6614
2025-08-28 05:16:55,236 - INFO -   LR: 0.100000
2025-08-28 05:16:55,283 - INFO - 
Epoch: 51, lr = 0.1
2025-08-28 05:16:55,456 - INFO - Epoch: [51][0/391] Time 0.172 (0.172) Data 0.141 (0.141) Loss 0.4811 (0.4811) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:16:56,601 - INFO - Pruning info: sparsity=0.677
2025-08-28 05:16:56,601 - INFO -   Reactivation rate: 0.0020
2025-08-28 05:16:57,330 - INFO - Epoch: [51][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3594 (0.4140) Acc@1 89.062 (85.597) Acc@5 99.219 (99.489)
2025-08-28 05:16:59,196 - INFO - Epoch: [51][200/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.4309 (0.4201) Acc@1 86.719 (85.549) Acc@5 100.000 (99.460)
2025-08-28 05:16:59,589 - INFO - Pruning info: sparsity=0.677
2025-08-28 05:16:59,589 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:17:01,217 - INFO - Epoch: [51][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3313 (0.4203) Acc@1 88.281 (85.455) Acc@5 99.219 (99.460)
2025-08-28 05:17:02,705 - INFO - Pruning info: sparsity=0.677
2025-08-28 05:17:02,705 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:17:03,076 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.7703 (0.7703) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 05:17:03,945 - INFO - Epoch 51:
2025-08-28 05:17:03,945 - INFO -   Train: acc1: 85.4140 | acc5: 99.3940 | loss: 0.4239 | sparsity: 0.6771 | reactivation_rate: 0.0014
2025-08-28 05:17:03,945 - INFO -   Val:   acc1: 79.1900 | acc5: 98.6800 | loss: 0.6446
2025-08-28 05:17:03,945 - INFO -   LR: 0.100000
2025-08-28 05:17:03,956 - INFO - 
Epoch: 52, lr = 0.1
2025-08-28 05:17:04,146 - INFO - Epoch: [52][0/391] Time 0.190 (0.190) Data 0.165 (0.165) Loss 0.3541 (0.3541) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:17:05,956 - INFO - Epoch: [52][100/391] Time 0.035 (0.020) Data 0.000 (0.004) Loss 0.4405 (0.3972) Acc@1 84.375 (86.796) Acc@5 100.000 (99.474)
2025-08-28 05:17:06,815 - INFO - Pruning info: sparsity=0.680
2025-08-28 05:17:06,816 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:17:07,800 - INFO - Epoch: [52][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4679 (0.4248) Acc@1 80.469 (85.452) Acc@5 100.000 (99.394)
2025-08-28 05:17:09,759 - INFO - Epoch: [52][300/391] Time 0.042 (0.019) Data 0.013 (0.003) Loss 0.4020 (0.4235) Acc@1 85.938 (85.408) Acc@5 99.219 (99.416)
2025-08-28 05:17:09,890 - INFO - Pruning info: sparsity=0.680
2025-08-28 05:17:09,890 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:17:11,571 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6225 (0.6225) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 05:17:12,439 - INFO - Epoch 52:
2025-08-28 05:17:12,440 - INFO -   Train: acc1: 85.4100 | acc5: 99.3960 | loss: 0.4241 | sparsity: 0.6798 | reactivation_rate: 0.0013
2025-08-28 05:17:12,440 - INFO -   Val:   acc1: 79.4900 | acc5: 99.1100 | loss: 0.6133
2025-08-28 05:17:12,440 - INFO -   LR: 0.100000
2025-08-28 05:17:12,451 - INFO - 
Epoch: 53, lr = 0.1
2025-08-28 05:17:12,658 - INFO - Epoch: [53][0/391] Time 0.207 (0.207) Data 0.181 (0.181) Loss 0.5359 (0.5359) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 05:17:14,064 - INFO - Pruning info: sparsity=0.682
2025-08-28 05:17:14,065 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:17:14,479 - INFO - Epoch: [53][100/391] Time 0.025 (0.020) Data 0.012 (0.005) Loss 0.4025 (0.4252) Acc@1 85.938 (85.412) Acc@5 99.219 (99.404)
2025-08-28 05:17:16,377 - INFO - Epoch: [53][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4360 (0.4278) Acc@1 85.156 (85.347) Acc@5 100.000 (99.448)
2025-08-28 05:17:17,045 - INFO - Pruning info: sparsity=0.682
2025-08-28 05:17:17,045 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:17:18,218 - INFO - Epoch: [53][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.3543 (0.4259) Acc@1 89.844 (85.260) Acc@5 99.219 (99.471)
2025-08-28 05:17:20,013 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 1.1302 (1.1302) Acc@1 66.406 (66.406) Acc@5 99.219 (99.219)
2025-08-28 05:17:20,868 - INFO - Epoch 53:
2025-08-28 05:17:20,869 - INFO -   Train: acc1: 85.1960 | acc5: 99.4560 | loss: 0.4284 | sparsity: 0.6823 | reactivation_rate: 0.0012
2025-08-28 05:17:20,869 - INFO -   Val:   acc1: 70.5100 | acc5: 97.7700 | loss: 1.0486
2025-08-28 05:17:20,869 - INFO -   LR: 0.100000
2025-08-28 05:17:20,882 - INFO - 
Epoch: 54, lr = 0.1
2025-08-28 05:17:21,069 - INFO - Epoch: [54][0/391] Time 0.185 (0.185) Data 0.161 (0.161) Loss 0.3747 (0.3747) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:17:21,186 - INFO - Pruning info: sparsity=0.685
2025-08-28 05:17:21,189 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:17:22,995 - INFO - Epoch: [54][100/391] Time 0.016 (0.021) Data 0.000 (0.005) Loss 0.3192 (0.4241) Acc@1 86.719 (85.381) Acc@5 99.219 (99.482)
2025-08-28 05:17:24,262 - INFO - Pruning info: sparsity=0.685
2025-08-28 05:17:24,263 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:17:24,867 - INFO - Epoch: [54][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.5385 (0.4212) Acc@1 78.906 (85.677) Acc@5 100.000 (99.433)
2025-08-28 05:17:26,750 - INFO - Epoch: [54][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.3842 (0.4164) Acc@1 85.156 (85.727) Acc@5 99.219 (99.442)
2025-08-28 05:17:27,210 - INFO - Pruning info: sparsity=0.685
2025-08-28 05:17:27,210 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:17:28,621 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.6931 (0.6931) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 05:17:29,512 - INFO - Epoch 54:
2025-08-28 05:17:29,512 - INFO -   Train: acc1: 85.5500 | acc5: 99.4160 | loss: 0.4221 | sparsity: 0.6846 | reactivation_rate: 0.0012
2025-08-28 05:17:29,512 - INFO -   Val:   acc1: 76.4300 | acc5: 97.6800 | loss: 0.7580
2025-08-28 05:17:29,512 - INFO -   LR: 0.100000
2025-08-28 05:17:29,704 - INFO - 
Epoch: 55, lr = 0.1
2025-08-28 05:17:29,922 - INFO - Epoch: [55][0/391] Time 0.217 (0.217) Data 0.193 (0.193) Loss 0.3069 (0.3069) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:17:31,727 - INFO - Pruning info: sparsity=0.687
2025-08-28 05:17:31,727 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:17:31,816 - INFO - Epoch: [55][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.5373 (0.4193) Acc@1 82.031 (85.659) Acc@5 100.000 (99.358)
2025-08-28 05:17:33,664 - INFO - Epoch: [55][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.5433 (0.4226) Acc@1 79.688 (85.522) Acc@5 100.000 (99.355)
2025-08-28 05:17:34,628 - INFO - Pruning info: sparsity=0.687
2025-08-28 05:17:34,629 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:17:35,467 - INFO - Epoch: [55][300/391] Time 0.029 (0.019) Data 0.014 (0.003) Loss 0.3876 (0.4211) Acc@1 88.281 (85.509) Acc@5 100.000 (99.395)
2025-08-28 05:17:37,315 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5918 (0.5918) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 05:17:38,184 - INFO - Epoch 55:
2025-08-28 05:17:38,185 - INFO -   Train: acc1: 85.4000 | acc5: 99.3820 | loss: 0.4244 | sparsity: 0.6867 | reactivation_rate: 0.0012
2025-08-28 05:17:38,185 - INFO -   Val:   acc1: 80.5500 | acc5: 99.1700 | loss: 0.5944
2025-08-28 05:17:38,185 - INFO -   LR: 0.100000
2025-08-28 05:17:38,197 - INFO - 
Epoch: 56, lr = 0.1
2025-08-28 05:17:38,350 - INFO - Epoch: [56][0/391] Time 0.152 (0.152) Data 0.135 (0.135) Loss 0.3315 (0.3315) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:17:38,815 - INFO - Pruning info: sparsity=0.689
2025-08-28 05:17:38,815 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:17:40,210 - INFO - Epoch: [56][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4808 (0.4181) Acc@1 83.594 (85.930) Acc@5 100.000 (99.397)
2025-08-28 05:17:41,764 - INFO - Pruning info: sparsity=0.689
2025-08-28 05:17:41,765 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:17:42,099 - INFO - Epoch: [56][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.4132 (0.4207) Acc@1 85.156 (85.630) Acc@5 99.219 (99.413)
2025-08-28 05:17:44,043 - INFO - Epoch: [56][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4213 (0.4208) Acc@1 85.938 (85.592) Acc@5 100.000 (99.413)
2025-08-28 05:17:44,842 - INFO - Pruning info: sparsity=0.689
2025-08-28 05:17:44,843 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:17:45,795 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.4949 (0.4949) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 05:17:46,663 - INFO - Epoch 56:
2025-08-28 05:17:46,663 - INFO -   Train: acc1: 85.4400 | acc5: 99.3780 | loss: 0.4245 | sparsity: 0.6886 | reactivation_rate: 0.0011
2025-08-28 05:17:46,663 - INFO -   Val:   acc1: 79.5100 | acc5: 98.8900 | loss: 0.6312
2025-08-28 05:17:46,663 - INFO -   LR: 0.100000
2025-08-28 05:17:46,676 - INFO - 
Epoch: 57, lr = 0.1
2025-08-28 05:17:46,842 - INFO - Epoch: [57][0/391] Time 0.166 (0.166) Data 0.148 (0.148) Loss 0.3106 (0.3106) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:17:48,710 - INFO - Epoch: [57][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4314 (0.4117) Acc@1 85.156 (86.023) Acc@5 99.219 (99.466)
2025-08-28 05:17:48,936 - INFO - Pruning info: sparsity=0.690
2025-08-28 05:17:48,936 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:17:50,482 - INFO - Epoch: [57][200/391] Time 0.018 (0.019) Data 0.007 (0.003) Loss 0.4097 (0.4198) Acc@1 85.156 (85.630) Acc@5 99.219 (99.444)
2025-08-28 05:17:51,924 - INFO - Pruning info: sparsity=0.690
2025-08-28 05:17:51,924 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:17:52,456 - INFO - Epoch: [57][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.4496 (0.4169) Acc@1 81.250 (85.696) Acc@5 99.219 (99.450)
2025-08-28 05:17:54,399 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6414 (0.6414) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:17:55,250 - INFO - Epoch 57:
2025-08-28 05:17:55,250 - INFO -   Train: acc1: 85.6780 | acc5: 99.4240 | loss: 0.4182 | sparsity: 0.6903 | reactivation_rate: 0.0010
2025-08-28 05:17:55,250 - INFO -   Val:   acc1: 79.6500 | acc5: 98.8900 | loss: 0.6407
2025-08-28 05:17:55,250 - INFO -   LR: 0.100000
2025-08-28 05:17:55,262 - INFO - 
Epoch: 58, lr = 0.1
2025-08-28 05:17:55,436 - INFO - Epoch: [58][0/391] Time 0.173 (0.173) Data 0.148 (0.148) Loss 0.4365 (0.4365) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:17:56,216 - INFO - Pruning info: sparsity=0.692
2025-08-28 05:17:56,216 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:17:57,316 - INFO - Epoch: [58][100/391] Time 0.015 (0.020) Data 0.002 (0.004) Loss 0.4014 (0.4260) Acc@1 86.719 (85.481) Acc@5 100.000 (99.389)
2025-08-28 05:17:59,176 - INFO - Epoch: [58][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4676 (0.4302) Acc@1 82.031 (85.432) Acc@5 99.219 (99.351)
2025-08-28 05:17:59,210 - INFO - Pruning info: sparsity=0.692
2025-08-28 05:17:59,210 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:18:01,033 - INFO - Epoch: [58][300/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.4181 (0.4284) Acc@1 82.812 (85.312) Acc@5 100.000 (99.336)
2025-08-28 05:18:02,175 - INFO - Pruning info: sparsity=0.692
2025-08-28 05:18:02,175 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:18:02,782 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.8916 (0.8916) Acc@1 72.656 (72.656) Acc@5 97.656 (97.656)
2025-08-28 05:18:03,639 - INFO - Epoch 58:
2025-08-28 05:18:03,640 - INFO -   Train: acc1: 85.3580 | acc5: 99.3760 | loss: 0.4252 | sparsity: 0.6918 | reactivation_rate: 0.0010
2025-08-28 05:18:03,640 - INFO -   Val:   acc1: 74.6000 | acc5: 98.0800 | loss: 0.8463
2025-08-28 05:18:03,640 - INFO -   LR: 0.100000
2025-08-28 05:18:03,654 - INFO - 
Epoch: 59, lr = 0.1
2025-08-28 05:18:03,833 - INFO - Epoch: [59][0/391] Time 0.178 (0.178) Data 0.154 (0.154) Loss 0.4950 (0.4950) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:18:05,806 - INFO - Epoch: [59][100/391] Time 0.018 (0.021) Data 0.002 (0.003) Loss 0.3754 (0.4053) Acc@1 89.062 (86.007) Acc@5 100.000 (99.513)
2025-08-28 05:18:06,385 - INFO - Pruning info: sparsity=0.693
2025-08-28 05:18:06,385 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:18:07,593 - INFO - Epoch: [59][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4281 (0.4194) Acc@1 85.938 (85.580) Acc@5 98.438 (99.479)
2025-08-28 05:18:09,311 - INFO - Pruning info: sparsity=0.693
2025-08-28 05:18:09,311 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:18:09,488 - INFO - Epoch: [59][300/391] Time 0.039 (0.019) Data 0.005 (0.002) Loss 0.4546 (0.4237) Acc@1 82.812 (85.416) Acc@5 98.438 (99.455)
2025-08-28 05:18:11,236 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6695 (0.6695) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 05:18:12,101 - INFO - Epoch 59:
2025-08-28 05:18:12,102 - INFO -   Train: acc1: 85.5740 | acc5: 99.4800 | loss: 0.4212 | sparsity: 0.6932 | reactivation_rate: 0.0009
2025-08-28 05:18:12,102 - INFO -   Val:   acc1: 76.5000 | acc5: 98.3400 | loss: 0.7871
2025-08-28 05:18:12,102 - INFO -   LR: 0.100000
2025-08-28 05:18:12,115 - INFO - 
Epoch: 60, lr = 0.1
2025-08-28 05:18:12,298 - INFO - Epoch: [60][0/391] Time 0.183 (0.183) Data 0.166 (0.166) Loss 0.4874 (0.4874) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:18:13,422 - INFO - Pruning info: sparsity=0.694
2025-08-28 05:18:13,422 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:18:14,149 - INFO - Epoch: [60][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4491 (0.4064) Acc@1 83.594 (85.914) Acc@5 100.000 (99.466)
2025-08-28 05:18:16,083 - INFO - Epoch: [60][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2984 (0.4202) Acc@1 90.625 (85.428) Acc@5 100.000 (99.394)
2025-08-28 05:18:16,409 - INFO - Pruning info: sparsity=0.694
2025-08-28 05:18:16,409 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:18:17,947 - INFO - Epoch: [60][300/391] Time 0.032 (0.019) Data 0.000 (0.003) Loss 0.4705 (0.4194) Acc@1 82.031 (85.491) Acc@5 100.000 (99.372)
2025-08-28 05:18:19,456 - INFO - Pruning info: sparsity=0.694
2025-08-28 05:18:19,456 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:18:19,808 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.6344 (0.6344) Acc@1 75.781 (75.781) Acc@5 100.000 (100.000)
2025-08-28 05:18:20,696 - INFO - Epoch 60:
2025-08-28 05:18:20,696 - INFO -   Train: acc1: 85.4080 | acc5: 99.3900 | loss: 0.4217 | sparsity: 0.6944 | reactivation_rate: 0.0009
2025-08-28 05:18:20,696 - INFO -   Val:   acc1: 77.7900 | acc5: 98.5700 | loss: 0.6991
2025-08-28 05:18:20,696 - INFO -   LR: 0.100000
2025-08-28 05:18:20,747 - INFO - 
Epoch: 61, lr = 0.1
2025-08-28 05:18:20,926 - INFO - Epoch: [61][0/391] Time 0.178 (0.178) Data 0.157 (0.157) Loss 0.4256 (0.4256) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:18:22,744 - INFO - Epoch: [61][100/391] Time 0.023 (0.020) Data 0.012 (0.005) Loss 0.3839 (0.3892) Acc@1 88.281 (86.378) Acc@5 99.219 (99.536)
2025-08-28 05:18:23,676 - INFO - Pruning info: sparsity=0.695
2025-08-28 05:18:23,676 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:18:24,580 - INFO - Epoch: [61][200/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.4062 (0.4143) Acc@1 85.938 (85.630) Acc@5 100.000 (99.436)
2025-08-28 05:18:26,414 - INFO - Epoch: [61][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.5064 (0.4157) Acc@1 82.031 (85.691) Acc@5 98.438 (99.483)
2025-08-28 05:18:26,585 - INFO - Pruning info: sparsity=0.695
2025-08-28 05:18:26,585 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:18:28,220 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.4564 (0.4564) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-28 05:18:29,110 - INFO - Epoch 61:
2025-08-28 05:18:29,110 - INFO -   Train: acc1: 85.4440 | acc5: 99.4380 | loss: 0.4222 | sparsity: 0.6954 | reactivation_rate: 0.0008
2025-08-28 05:18:29,110 - INFO -   Val:   acc1: 79.9800 | acc5: 98.8400 | loss: 0.6094
2025-08-28 05:18:29,110 - INFO -   LR: 0.100000
2025-08-28 05:18:29,124 - INFO - 
Epoch: 62, lr = 0.1
2025-08-28 05:18:29,313 - INFO - Epoch: [62][0/391] Time 0.188 (0.188) Data 0.170 (0.170) Loss 0.3125 (0.3125) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:18:30,729 - INFO - Pruning info: sparsity=0.696
2025-08-28 05:18:30,730 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:18:31,203 - INFO - Epoch: [62][100/391] Time 0.034 (0.021) Data 0.013 (0.004) Loss 0.3851 (0.3995) Acc@1 85.938 (85.883) Acc@5 100.000 (99.590)
2025-08-28 05:18:33,003 - INFO - Epoch: [62][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.3684 (0.4060) Acc@1 87.500 (85.739) Acc@5 99.219 (99.553)
2025-08-28 05:18:33,685 - INFO - Pruning info: sparsity=0.696
2025-08-28 05:18:33,685 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:18:34,816 - INFO - Epoch: [62][300/391] Time 0.025 (0.019) Data 0.005 (0.003) Loss 0.3599 (0.4108) Acc@1 83.594 (85.738) Acc@5 100.000 (99.458)
2025-08-28 05:18:36,590 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6282 (0.6282) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 05:18:37,438 - INFO - Epoch 62:
2025-08-28 05:18:37,438 - INFO -   Train: acc1: 85.6380 | acc5: 99.4480 | loss: 0.4165 | sparsity: 0.6964 | reactivation_rate: 0.0007
2025-08-28 05:18:37,438 - INFO -   Val:   acc1: 78.4700 | acc5: 98.4500 | loss: 0.6853
2025-08-28 05:18:37,438 - INFO -   LR: 0.100000
2025-08-28 05:18:37,451 - INFO - 
Epoch: 63, lr = 0.1
2025-08-28 05:18:37,638 - INFO - Epoch: [63][0/391] Time 0.186 (0.186) Data 0.159 (0.159) Loss 0.4234 (0.4234) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:18:37,755 - INFO - Pruning info: sparsity=0.697
2025-08-28 05:18:37,756 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:18:39,496 - INFO - Epoch: [63][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4119 (0.4006) Acc@1 83.594 (85.798) Acc@5 98.438 (99.520)
2025-08-28 05:18:40,783 - INFO - Pruning info: sparsity=0.697
2025-08-28 05:18:40,783 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:18:41,366 - INFO - Epoch: [63][200/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.4777 (0.4149) Acc@1 83.594 (85.506) Acc@5 100.000 (99.460)
2025-08-28 05:18:43,113 - INFO - Epoch: [63][300/391] Time 0.019 (0.019) Data 0.006 (0.002) Loss 0.3808 (0.4170) Acc@1 85.156 (85.387) Acc@5 100.000 (99.463)
2025-08-28 05:18:43,611 - INFO - Pruning info: sparsity=0.697
2025-08-28 05:18:43,611 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:18:44,885 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5533 (0.5533) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:18:45,775 - INFO - Epoch 63:
2025-08-28 05:18:45,776 - INFO -   Train: acc1: 85.2040 | acc5: 99.4620 | loss: 0.4244 | sparsity: 0.6971 | reactivation_rate: 0.0007
2025-08-28 05:18:45,776 - INFO -   Val:   acc1: 80.1500 | acc5: 98.8800 | loss: 0.6047
2025-08-28 05:18:45,776 - INFO -   LR: 0.100000
2025-08-28 05:18:45,792 - INFO - 
Epoch: 64, lr = 0.1
2025-08-28 05:18:45,978 - INFO - Epoch: [64][0/391] Time 0.186 (0.186) Data 0.151 (0.151) Loss 0.3506 (0.3506) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:18:47,718 - INFO - Pruning info: sparsity=0.698
2025-08-28 05:18:47,718 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:18:47,795 - INFO - Epoch: [64][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4438 (0.4113) Acc@1 81.250 (85.852) Acc@5 100.000 (99.544)
2025-08-28 05:18:49,660 - INFO - Epoch: [64][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4437 (0.4236) Acc@1 82.812 (85.238) Acc@5 100.000 (99.491)
2025-08-28 05:18:50,678 - INFO - Pruning info: sparsity=0.698
2025-08-28 05:18:50,679 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:18:51,505 - INFO - Epoch: [64][300/391] Time 0.012 (0.019) Data 0.001 (0.003) Loss 0.6140 (0.4216) Acc@1 78.125 (85.387) Acc@5 99.219 (99.460)
2025-08-28 05:18:53,330 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.5216 (0.5216) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:18:54,367 - INFO - Epoch 64:
2025-08-28 05:18:54,367 - INFO -   Train: acc1: 85.2760 | acc5: 99.4500 | loss: 0.4226 | sparsity: 0.6978 | reactivation_rate: 0.0006
2025-08-28 05:18:54,367 - INFO -   Val:   acc1: 81.8400 | acc5: 99.1100 | loss: 0.5452
2025-08-28 05:18:54,367 - INFO -   LR: 0.100000
2025-08-28 05:18:54,379 - INFO - 
Epoch: 65, lr = 0.1
2025-08-28 05:18:54,575 - INFO - Epoch: [65][0/391] Time 0.195 (0.195) Data 0.167 (0.167) Loss 0.3182 (0.3182) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:18:55,045 - INFO - Pruning info: sparsity=0.698
2025-08-28 05:18:55,045 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:18:56,493 - INFO - Epoch: [65][100/391] Time 0.014 (0.021) Data 0.000 (0.005) Loss 0.4631 (0.4206) Acc@1 82.031 (85.659) Acc@5 99.219 (99.389)
2025-08-28 05:18:57,994 - INFO - Pruning info: sparsity=0.698
2025-08-28 05:18:57,994 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:18:58,251 - INFO - Epoch: [65][200/391] Time 0.016 (0.019) Data 0.004 (0.004) Loss 0.5941 (0.4164) Acc@1 79.688 (85.794) Acc@5 100.000 (99.405)
2025-08-28 05:19:00,108 - INFO - Epoch: [65][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3443 (0.4171) Acc@1 89.844 (85.699) Acc@5 99.219 (99.398)
2025-08-28 05:19:00,906 - INFO - Pruning info: sparsity=0.698
2025-08-28 05:19:00,906 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:19:01,933 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.4721 (0.4721) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:19:02,829 - INFO - Epoch 65:
2025-08-28 05:19:02,829 - INFO -   Train: acc1: 85.7520 | acc5: 99.3980 | loss: 0.4184 | sparsity: 0.6983 | reactivation_rate: 0.0006
2025-08-28 05:19:02,829 - INFO -   Val:   acc1: 81.9400 | acc5: 98.9600 | loss: 0.5488
2025-08-28 05:19:02,830 - INFO -   LR: 0.100000
2025-08-28 05:19:02,844 - INFO - 
Epoch: 66, lr = 0.1
2025-08-28 05:19:03,028 - INFO - Epoch: [66][0/391] Time 0.183 (0.183) Data 0.156 (0.156) Loss 0.3568 (0.3568) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-28 05:19:04,923 - INFO - Epoch: [66][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.2850 (0.4028) Acc@1 90.625 (86.200) Acc@5 100.000 (99.412)
2025-08-28 05:19:05,144 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:05,145 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:19:06,735 - INFO - Epoch: [66][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5627 (0.4067) Acc@1 75.000 (86.077) Acc@5 100.000 (99.390)
2025-08-28 05:19:08,091 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:08,091 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:19:08,592 - INFO - Epoch: [66][300/391] Time 0.024 (0.019) Data 0.011 (0.003) Loss 0.5986 (0.4221) Acc@1 78.906 (85.535) Acc@5 99.219 (99.387)
2025-08-28 05:19:10,387 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5996 (0.5996) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:19:11,246 - INFO - Epoch 66:
2025-08-28 05:19:11,246 - INFO -   Train: acc1: 85.5180 | acc5: 99.4020 | loss: 0.4211 | sparsity: 0.6988 | reactivation_rate: 0.0005
2025-08-28 05:19:11,246 - INFO -   Val:   acc1: 80.8700 | acc5: 99.1400 | loss: 0.5869
2025-08-28 05:19:11,246 - INFO -   LR: 0.100000
2025-08-28 05:19:11,261 - INFO - 
Epoch: 67, lr = 0.1
2025-08-28 05:19:11,433 - INFO - Epoch: [67][0/391] Time 0.170 (0.170) Data 0.152 (0.152) Loss 0.3495 (0.3495) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:19:12,246 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:12,247 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:19:13,292 - INFO - Epoch: [67][100/391] Time 0.021 (0.020) Data 0.010 (0.004) Loss 0.3808 (0.4092) Acc@1 88.281 (85.992) Acc@5 99.219 (99.474)
2025-08-28 05:19:15,098 - INFO - Epoch: [67][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4199 (0.4239) Acc@1 84.375 (85.405) Acc@5 100.000 (99.421)
2025-08-28 05:19:15,165 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:15,166 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:19:16,938 - INFO - Epoch: [67][300/391] Time 0.017 (0.019) Data 0.005 (0.004) Loss 0.3810 (0.4161) Acc@1 88.281 (85.553) Acc@5 98.438 (99.426)
2025-08-28 05:19:18,077 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:18,078 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:19:18,717 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6711 (0.6711) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-28 05:19:19,570 - INFO - Epoch 67:
2025-08-28 05:19:19,570 - INFO -   Train: acc1: 85.4360 | acc5: 99.4060 | loss: 0.4206 | sparsity: 0.6991 | reactivation_rate: 0.0005
2025-08-28 05:19:19,570 - INFO -   Val:   acc1: 80.4200 | acc5: 98.9700 | loss: 0.6303
2025-08-28 05:19:19,570 - INFO -   LR: 0.100000
2025-08-28 05:19:19,586 - INFO - 
Epoch: 68, lr = 0.1
2025-08-28 05:19:19,745 - INFO - Epoch: [68][0/391] Time 0.158 (0.158) Data 0.135 (0.135) Loss 0.3680 (0.3680) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:19:21,563 - INFO - Epoch: [68][100/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.4641 (0.4154) Acc@1 85.156 (85.504) Acc@5 99.219 (99.482)
2025-08-28 05:19:22,132 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:22,132 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:19:23,381 - INFO - Epoch: [68][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4598 (0.4231) Acc@1 84.375 (85.409) Acc@5 98.438 (99.390)
2025-08-28 05:19:25,075 - INFO - Pruning info: sparsity=0.699
2025-08-28 05:19:25,075 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:19:25,226 - INFO - Epoch: [68][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.4468 (0.4181) Acc@1 86.719 (85.551) Acc@5 99.219 (99.411)
2025-08-28 05:19:27,014 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 1.3220 (1.3220) Acc@1 64.844 (64.844) Acc@5 95.312 (95.312)
2025-08-28 05:19:27,878 - INFO - Epoch 68:
2025-08-28 05:19:27,878 - INFO -   Train: acc1: 85.5280 | acc5: 99.4060 | loss: 0.4168 | sparsity: 0.6994 | reactivation_rate: 0.0004
2025-08-28 05:19:27,878 - INFO -   Val:   acc1: 69.9600 | acc5: 97.1500 | loss: 1.0810
2025-08-28 05:19:27,878 - INFO -   LR: 0.100000
2025-08-28 05:19:27,889 - INFO - 
Epoch: 69, lr = 0.1
2025-08-28 05:19:28,046 - INFO - Epoch: [69][0/391] Time 0.156 (0.156) Data 0.140 (0.140) Loss 0.5414 (0.5414) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 05:19:29,199 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:29,199 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:19:29,931 - INFO - Epoch: [69][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3698 (0.4205) Acc@1 85.938 (85.056) Acc@5 100.000 (99.459)
2025-08-28 05:19:31,801 - INFO - Epoch: [69][200/391] Time 0.034 (0.019) Data 0.022 (0.004) Loss 0.4018 (0.4139) Acc@1 85.938 (85.514) Acc@5 100.000 (99.378)
2025-08-28 05:19:32,220 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:32,220 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:19:33,716 - INFO - Epoch: [69][300/391] Time 0.025 (0.019) Data 0.006 (0.004) Loss 0.5279 (0.4181) Acc@1 84.375 (85.483) Acc@5 100.000 (99.403)
2025-08-28 05:19:35,192 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:35,193 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:19:35,515 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.9382 (0.9382) Acc@1 75.000 (75.000) Acc@5 96.875 (96.875)
2025-08-28 05:19:36,394 - INFO - Epoch 69:
2025-08-28 05:19:36,395 - INFO -   Train: acc1: 85.3360 | acc5: 99.4280 | loss: 0.4218 | sparsity: 0.6996 | reactivation_rate: 0.0004
2025-08-28 05:19:36,395 - INFO -   Val:   acc1: 73.0200 | acc5: 97.9800 | loss: 0.8888
2025-08-28 05:19:36,395 - INFO -   LR: 0.100000
2025-08-28 05:19:36,407 - INFO - 
Epoch: 70, lr = 0.1
2025-08-28 05:19:36,600 - INFO - Epoch: [70][0/391] Time 0.192 (0.192) Data 0.172 (0.172) Loss 0.4725 (0.4725) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-28 05:19:38,518 - INFO - Epoch: [70][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.3866 (0.4039) Acc@1 89.062 (85.984) Acc@5 100.000 (99.544)
2025-08-28 05:19:39,366 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:39,366 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:19:40,313 - INFO - Epoch: [70][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.3249 (0.4195) Acc@1 90.625 (85.432) Acc@5 99.219 (99.448)
2025-08-28 05:19:42,177 - INFO - Epoch: [70][300/391] Time 0.022 (0.019) Data 0.010 (0.003) Loss 0.2395 (0.4194) Acc@1 92.969 (85.481) Acc@5 100.000 (99.460)
2025-08-28 05:19:42,367 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:42,367 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:19:44,022 - INFO - Test: [0/79] Time 0.164 (0.164) Loss 0.8248 (0.8248) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-28 05:19:44,871 - INFO - Epoch 70:
2025-08-28 05:19:44,871 - INFO -   Train: acc1: 85.5720 | acc5: 99.4500 | loss: 0.4178 | sparsity: 0.6998 | reactivation_rate: 0.0003
2025-08-28 05:19:44,871 - INFO -   Val:   acc1: 73.8400 | acc5: 98.5900 | loss: 0.8581
2025-08-28 05:19:44,871 - INFO -   LR: 0.100000
2025-08-28 05:19:44,918 - INFO - 
Epoch: 71, lr = 0.1
2025-08-28 05:19:45,102 - INFO - Epoch: [71][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.3090 (0.3090) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:19:46,535 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:46,536 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:19:46,904 - INFO - Epoch: [71][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4331 (0.4075) Acc@1 85.156 (86.131) Acc@5 100.000 (99.513)
2025-08-28 05:19:48,794 - INFO - Epoch: [71][200/391] Time 0.027 (0.019) Data 0.017 (0.006) Loss 0.3596 (0.4178) Acc@1 89.062 (85.708) Acc@5 100.000 (99.487)
2025-08-28 05:19:49,551 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:49,551 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:19:50,648 - INFO - Epoch: [71][300/391] Time 0.013 (0.019) Data 0.000 (0.005) Loss 0.4936 (0.4198) Acc@1 80.469 (85.559) Acc@5 99.219 (99.486)
2025-08-28 05:19:52,385 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.6194 (0.6194) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 05:19:53,263 - INFO - Epoch 71:
2025-08-28 05:19:53,263 - INFO -   Train: acc1: 85.4700 | acc5: 99.4620 | loss: 0.4208 | sparsity: 0.6999 | reactivation_rate: 0.0003
2025-08-28 05:19:53,263 - INFO -   Val:   acc1: 79.2100 | acc5: 98.6100 | loss: 0.6469
2025-08-28 05:19:53,263 - INFO -   LR: 0.100000
2025-08-28 05:19:53,279 - INFO - 
Epoch: 72, lr = 0.1
2025-08-28 05:19:53,456 - INFO - Epoch: [72][0/391] Time 0.176 (0.176) Data 0.138 (0.138) Loss 0.4722 (0.4722) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 05:19:53,588 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:53,588 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:19:55,233 - INFO - Epoch: [72][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3532 (0.4029) Acc@1 86.719 (86.262) Acc@5 100.000 (99.489)
2025-08-28 05:19:56,481 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:56,481 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:19:57,113 - INFO - Epoch: [72][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5146 (0.4205) Acc@1 78.906 (85.584) Acc@5 100.000 (99.436)
2025-08-28 05:19:58,978 - INFO - Epoch: [72][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.6206 (0.4198) Acc@1 80.469 (85.561) Acc@5 97.656 (99.434)
2025-08-28 05:19:59,515 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:19:59,515 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:20:00,743 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5688 (0.5688) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 05:20:01,617 - INFO - Epoch 72:
2025-08-28 05:20:01,617 - INFO -   Train: acc1: 85.3500 | acc5: 99.4260 | loss: 0.4229 | sparsity: 0.7000 | reactivation_rate: 0.0002
2025-08-28 05:20:01,617 - INFO -   Val:   acc1: 77.8900 | acc5: 98.5500 | loss: 0.7288
2025-08-28 05:20:01,618 - INFO -   LR: 0.100000
2025-08-28 05:20:01,632 - INFO - 
Epoch: 73, lr = 0.1
2025-08-28 05:20:01,789 - INFO - Epoch: [73][0/391] Time 0.157 (0.157) Data 0.140 (0.140) Loss 0.3723 (0.3723) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:20:03,597 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:03,597 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:20:03,658 - INFO - Epoch: [73][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2727 (0.3967) Acc@1 93.750 (86.224) Acc@5 100.000 (99.536)
2025-08-28 05:20:05,473 - INFO - Epoch: [73][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.4737 (0.4061) Acc@1 85.156 (86.035) Acc@5 99.219 (99.487)
2025-08-28 05:20:06,491 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:06,491 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:20:07,282 - INFO - Epoch: [73][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.3683 (0.4107) Acc@1 84.375 (85.854) Acc@5 100.000 (99.486)
2025-08-28 05:20:09,059 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.6819 (0.6819) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:20:09,910 - INFO - Epoch 73:
2025-08-28 05:20:09,910 - INFO -   Train: acc1: 85.7320 | acc5: 99.4560 | loss: 0.4150 | sparsity: 0.7000 | reactivation_rate: 0.0002
2025-08-28 05:20:09,910 - INFO -   Val:   acc1: 79.1500 | acc5: 98.8700 | loss: 0.6816
2025-08-28 05:20:09,910 - INFO -   LR: 0.100000
2025-08-28 05:20:09,925 - INFO - 
Epoch: 74, lr = 0.1
2025-08-28 05:20:10,142 - INFO - Epoch: [74][0/391] Time 0.216 (0.216) Data 0.192 (0.192) Loss 0.5508 (0.5508) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:20:10,546 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:10,547 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:20:11,941 - INFO - Epoch: [74][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.3287 (0.4283) Acc@1 88.281 (85.009) Acc@5 100.000 (99.296)
2025-08-28 05:20:13,503 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:13,503 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:20:13,795 - INFO - Epoch: [74][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3885 (0.4159) Acc@1 84.375 (85.506) Acc@5 100.000 (99.401)
2025-08-28 05:20:15,566 - INFO - Epoch: [74][300/391] Time 0.039 (0.019) Data 0.028 (0.003) Loss 0.3529 (0.4183) Acc@1 90.625 (85.572) Acc@5 99.219 (99.398)
2025-08-28 05:20:16,359 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:16,359 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:20:17,295 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6462 (0.6462) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 05:20:18,139 - INFO - Epoch 74:
2025-08-28 05:20:18,139 - INFO -   Train: acc1: 85.5120 | acc5: 99.4080 | loss: 0.4219 | sparsity: 0.7000 | reactivation_rate: 0.0002
2025-08-28 05:20:18,139 - INFO -   Val:   acc1: 79.1000 | acc5: 98.5300 | loss: 0.6463
2025-08-28 05:20:18,140 - INFO -   LR: 0.100000
2025-08-28 05:20:18,155 - INFO - 
Epoch: 75, lr = 0.1
2025-08-28 05:20:18,316 - INFO - Epoch: [75][0/391] Time 0.160 (0.160) Data 0.143 (0.143) Loss 0.3148 (0.3148) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:20:20,176 - INFO - Epoch: [75][100/391] Time 0.016 (0.020) Data 0.003 (0.004) Loss 0.5501 (0.4163) Acc@1 81.250 (85.605) Acc@5 98.438 (99.459)
2025-08-28 05:20:20,483 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:20,483 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:22,015 - INFO - Epoch: [75][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.3289 (0.4130) Acc@1 89.844 (85.774) Acc@5 100.000 (99.452)
2025-08-28 05:20:23,307 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:23,308 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:23,780 - INFO - Epoch: [75][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6225 (0.4164) Acc@1 77.344 (85.543) Acc@5 97.656 (99.471)
2025-08-28 05:20:25,492 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6865 (0.6865) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-28 05:20:26,405 - INFO - Epoch 75:
2025-08-28 05:20:26,405 - INFO -   Train: acc1: 85.6260 | acc5: 99.4600 | loss: 0.4161 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:20:26,405 - INFO -   Val:   acc1: 80.1800 | acc5: 99.0100 | loss: 0.5963
2025-08-28 05:20:26,405 - INFO -   LR: 0.100000
2025-08-28 05:20:26,420 - INFO - 
Epoch: 76, lr = 0.1
2025-08-28 05:20:26,613 - INFO - Epoch: [76][0/391] Time 0.191 (0.191) Data 0.155 (0.155) Loss 0.4543 (0.4543) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:20:27,451 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:27,452 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:28,437 - INFO - Epoch: [76][100/391] Time 0.016 (0.020) Data 0.002 (0.003) Loss 0.4123 (0.4094) Acc@1 85.938 (86.007) Acc@5 99.219 (99.412)
2025-08-28 05:20:30,309 - INFO - Epoch: [76][200/391] Time 0.021 (0.019) Data 0.009 (0.003) Loss 0.4701 (0.4126) Acc@1 86.719 (85.634) Acc@5 98.438 (99.433)
2025-08-28 05:20:30,369 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:30,369 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:32,152 - INFO - Epoch: [76][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4451 (0.4191) Acc@1 87.500 (85.369) Acc@5 100.000 (99.432)
2025-08-28 05:20:33,376 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:33,376 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:34,006 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6667 (0.6667) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 05:20:34,861 - INFO - Epoch 76:
2025-08-28 05:20:34,862 - INFO -   Train: acc1: 85.4660 | acc5: 99.4040 | loss: 0.4177 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:20:34,862 - INFO -   Val:   acc1: 77.6200 | acc5: 98.5500 | loss: 0.7179
2025-08-28 05:20:34,862 - INFO -   LR: 0.100000
2025-08-28 05:20:34,875 - INFO - 
Epoch: 77, lr = 0.1
2025-08-28 05:20:35,067 - INFO - Epoch: [77][0/391] Time 0.192 (0.192) Data 0.164 (0.164) Loss 0.3117 (0.3117) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:20:36,877 - INFO - Epoch: [77][100/391] Time 0.017 (0.020) Data 0.006 (0.005) Loss 0.4708 (0.4103) Acc@1 82.812 (85.435) Acc@5 98.438 (99.536)
2025-08-28 05:20:37,515 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:37,515 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:38,730 - INFO - Epoch: [77][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4609 (0.4229) Acc@1 84.375 (85.044) Acc@5 99.219 (99.421)
2025-08-28 05:20:40,401 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:40,401 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:40,535 - INFO - Epoch: [77][300/391] Time 0.030 (0.019) Data 0.011 (0.003) Loss 0.3658 (0.4192) Acc@1 86.719 (85.315) Acc@5 100.000 (99.424)
2025-08-28 05:20:42,377 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.6105 (0.6105) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 05:20:43,225 - INFO - Epoch 77:
2025-08-28 05:20:43,225 - INFO -   Train: acc1: 85.2620 | acc5: 99.4220 | loss: 0.4231 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:20:43,225 - INFO -   Val:   acc1: 79.8900 | acc5: 99.2300 | loss: 0.6324
2025-08-28 05:20:43,225 - INFO -   LR: 0.100000
2025-08-28 05:20:43,241 - INFO - 
Epoch: 78, lr = 0.1
2025-08-28 05:20:43,454 - INFO - Epoch: [78][0/391] Time 0.212 (0.212) Data 0.193 (0.193) Loss 0.4511 (0.4511) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:20:44,677 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:44,677 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:45,328 - INFO - Epoch: [78][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3792 (0.4012) Acc@1 88.281 (86.502) Acc@5 100.000 (99.428)
2025-08-28 05:20:47,229 - INFO - Epoch: [78][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4373 (0.4142) Acc@1 88.281 (86.015) Acc@5 98.438 (99.409)
2025-08-28 05:20:47,621 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:47,621 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:49,052 - INFO - Epoch: [78][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4196 (0.4198) Acc@1 84.375 (85.655) Acc@5 100.000 (99.406)
2025-08-28 05:20:50,521 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:50,521 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:50,836 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5547 (0.5547) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:20:51,686 - INFO - Epoch 78:
2025-08-28 05:20:51,686 - INFO -   Train: acc1: 85.5960 | acc5: 99.3980 | loss: 0.4217 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:20:51,686 - INFO -   Val:   acc1: 82.3100 | acc5: 99.0900 | loss: 0.5296
2025-08-28 05:20:51,686 - INFO -   LR: 0.100000
2025-08-28 05:20:51,703 - INFO - 
Epoch: 79, lr = 0.1
2025-08-28 05:20:51,867 - INFO - Epoch: [79][0/391] Time 0.162 (0.162) Data 0.134 (0.134) Loss 0.3821 (0.3821) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:20:53,824 - INFO - Epoch: [79][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.5406 (0.4135) Acc@1 81.250 (85.868) Acc@5 98.438 (99.397)
2025-08-28 05:20:54,712 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:54,712 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:55,661 - INFO - Epoch: [79][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3875 (0.4086) Acc@1 86.719 (85.949) Acc@5 100.000 (99.464)
2025-08-28 05:20:57,458 - INFO - Epoch: [79][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5034 (0.4121) Acc@1 83.594 (85.839) Acc@5 98.438 (99.445)
2025-08-28 05:20:57,664 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:20:57,664 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:20:59,290 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5408 (0.5408) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:21:00,128 - INFO - Epoch 79:
2025-08-28 05:21:00,129 - INFO -   Train: acc1: 85.5500 | acc5: 99.4360 | loss: 0.4185 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:00,129 - INFO -   Val:   acc1: 78.6200 | acc5: 98.8000 | loss: 0.6564
2025-08-28 05:21:00,129 - INFO -   LR: 0.100000
2025-08-28 05:21:00,141 - INFO - 
Epoch: 80, lr = 0.1
2025-08-28 05:21:00,331 - INFO - Epoch: [80][0/391] Time 0.190 (0.190) Data 0.163 (0.163) Loss 0.3286 (0.3286) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:21:01,763 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:01,763 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:02,135 - INFO - Epoch: [80][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.5293 (0.4054) Acc@1 82.031 (86.394) Acc@5 98.438 (99.466)
2025-08-28 05:21:03,994 - INFO - Epoch: [80][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3547 (0.4154) Acc@1 89.062 (85.794) Acc@5 98.438 (99.456)
2025-08-28 05:21:04,711 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:04,712 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:05,821 - INFO - Epoch: [80][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4097 (0.4180) Acc@1 87.500 (85.717) Acc@5 100.000 (99.442)
2025-08-28 05:21:07,634 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.4323 (0.4323) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:21:08,506 - INFO - Epoch 80:
2025-08-28 05:21:08,506 - INFO -   Train: acc1: 85.5560 | acc5: 99.4020 | loss: 0.4217 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:08,506 - INFO -   Val:   acc1: 82.3800 | acc5: 99.3400 | loss: 0.5118
2025-08-28 05:21:08,506 - INFO -   LR: 0.100000
2025-08-28 05:21:08,556 - INFO - 
Epoch: 81, lr = 0.1
2025-08-28 05:21:08,741 - INFO - Epoch: [81][0/391] Time 0.184 (0.184) Data 0.164 (0.164) Loss 0.4723 (0.4723) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 05:21:08,864 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:08,864 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:10,569 - INFO - Epoch: [81][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.3938 (0.4015) Acc@1 86.719 (86.146) Acc@5 100.000 (99.389)
2025-08-28 05:21:11,857 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:11,857 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:12,531 - INFO - Epoch: [81][200/391] Time 0.036 (0.020) Data 0.013 (0.003) Loss 0.4495 (0.4101) Acc@1 82.031 (85.825) Acc@5 100.000 (99.425)
2025-08-28 05:21:14,336 - INFO - Epoch: [81][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3795 (0.4171) Acc@1 85.938 (85.675) Acc@5 100.000 (99.419)
2025-08-28 05:21:14,863 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:14,864 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:16,115 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.7190 (0.7190) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 05:21:16,975 - INFO - Epoch 81:
2025-08-28 05:21:16,975 - INFO -   Train: acc1: 85.5660 | acc5: 99.4060 | loss: 0.4188 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:16,975 - INFO -   Val:   acc1: 76.2100 | acc5: 98.9800 | loss: 0.7526
2025-08-28 05:21:16,975 - INFO -   LR: 0.100000
2025-08-28 05:21:16,991 - INFO - 
Epoch: 82, lr = 0.1
2025-08-28 05:21:17,188 - INFO - Epoch: [82][0/391] Time 0.196 (0.196) Data 0.167 (0.167) Loss 0.4523 (0.4523) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 05:21:18,944 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:18,945 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:19,008 - INFO - Epoch: [82][100/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.3653 (0.4122) Acc@1 87.500 (85.504) Acc@5 98.438 (99.420)
2025-08-28 05:21:20,857 - INFO - Epoch: [82][200/391] Time 0.024 (0.019) Data 0.012 (0.003) Loss 0.4320 (0.4199) Acc@1 83.594 (85.285) Acc@5 100.000 (99.413)
2025-08-28 05:21:21,891 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:21,892 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:22,661 - INFO - Epoch: [82][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4221 (0.4203) Acc@1 83.594 (85.317) Acc@5 100.000 (99.419)
2025-08-28 05:21:24,521 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.5045 (0.5045) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 05:21:25,386 - INFO - Epoch 82:
2025-08-28 05:21:25,386 - INFO -   Train: acc1: 85.4440 | acc5: 99.4160 | loss: 0.4184 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:25,386 - INFO -   Val:   acc1: 80.2800 | acc5: 99.1200 | loss: 0.5911
2025-08-28 05:21:25,386 - INFO -   LR: 0.100000
2025-08-28 05:21:25,402 - INFO - 
Epoch: 83, lr = 0.1
2025-08-28 05:21:25,581 - INFO - Epoch: [83][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.4560 (0.4560) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:21:26,128 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:26,128 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:27,492 - INFO - Epoch: [83][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.3871 (0.4009) Acc@1 85.156 (86.092) Acc@5 100.000 (99.497)
2025-08-28 05:21:29,067 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:29,067 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:29,309 - INFO - Epoch: [83][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3984 (0.4054) Acc@1 82.812 (85.836) Acc@5 100.000 (99.436)
2025-08-28 05:21:31,190 - INFO - Epoch: [83][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5645 (0.4164) Acc@1 83.594 (85.629) Acc@5 97.656 (99.377)
2025-08-28 05:21:32,015 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:32,015 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:32,907 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.8194 (0.8194) Acc@1 74.219 (74.219) Acc@5 98.438 (98.438)
2025-08-28 05:21:33,775 - INFO - Epoch 83:
2025-08-28 05:21:33,775 - INFO -   Train: acc1: 85.5600 | acc5: 99.4000 | loss: 0.4195 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:33,775 - INFO -   Val:   acc1: 73.7500 | acc5: 97.7600 | loss: 0.8408
2025-08-28 05:21:33,775 - INFO -   LR: 0.100000
2025-08-28 05:21:33,789 - INFO - 
Epoch: 84, lr = 0.1
2025-08-28 05:21:33,980 - INFO - Epoch: [84][0/391] Time 0.190 (0.190) Data 0.173 (0.173) Loss 0.4844 (0.4844) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 05:21:35,845 - INFO - Epoch: [84][100/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.3541 (0.4236) Acc@1 87.500 (85.597) Acc@5 98.438 (99.489)
2025-08-28 05:21:36,149 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:36,149 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:37,741 - INFO - Epoch: [84][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.4248 (0.4188) Acc@1 83.594 (85.568) Acc@5 100.000 (99.483)
2025-08-28 05:21:39,160 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:39,160 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:39,597 - INFO - Epoch: [84][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3658 (0.4170) Acc@1 88.281 (85.660) Acc@5 99.219 (99.447)
2025-08-28 05:21:41,495 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5928 (0.5928) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 05:21:42,382 - INFO - Epoch 84:
2025-08-28 05:21:42,382 - INFO -   Train: acc1: 85.5300 | acc5: 99.4140 | loss: 0.4217 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:42,383 - INFO -   Val:   acc1: 79.4100 | acc5: 99.2300 | loss: 0.6116
2025-08-28 05:21:42,383 - INFO -   LR: 0.100000
2025-08-28 05:21:42,397 - INFO - 
Epoch: 85, lr = 0.1
2025-08-28 05:21:42,588 - INFO - Epoch: [85][0/391] Time 0.190 (0.190) Data 0.161 (0.161) Loss 0.5126 (0.5126) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 05:21:43,415 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:43,416 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:44,460 - INFO - Epoch: [85][100/391] Time 0.011 (0.020) Data 0.000 (0.007) Loss 0.4976 (0.4163) Acc@1 85.938 (86.007) Acc@5 98.438 (99.288)
2025-08-28 05:21:46,327 - INFO - Epoch: [85][200/391] Time 0.019 (0.020) Data 0.000 (0.005) Loss 0.3670 (0.4113) Acc@1 83.594 (85.961) Acc@5 100.000 (99.347)
2025-08-28 05:21:46,414 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:46,414 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:48,279 - INFO - Epoch: [85][300/391] Time 0.026 (0.020) Data 0.000 (0.004) Loss 0.5229 (0.4112) Acc@1 81.250 (85.963) Acc@5 99.219 (99.400)
2025-08-28 05:21:49,467 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:49,467 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:21:50,081 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.4832 (0.4832) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-28 05:21:50,949 - INFO - Epoch 85:
2025-08-28 05:21:50,950 - INFO -   Train: acc1: 85.7800 | acc5: 99.3820 | loss: 0.4175 | sparsity: 0.7000 | reactivation_rate: 0.0001
2025-08-28 05:21:50,950 - INFO -   Val:   acc1: 81.8200 | acc5: 99.2100 | loss: 0.5318
2025-08-28 05:21:50,950 - INFO -   LR: 0.100000
2025-08-28 05:21:50,963 - INFO - 
Epoch: 86, lr = 0.1
2025-08-28 05:21:51,126 - INFO - Epoch: [86][0/391] Time 0.162 (0.162) Data 0.136 (0.136) Loss 0.2504 (0.2504) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:21:53,020 - INFO - Epoch: [86][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4671 (0.4187) Acc@1 82.812 (85.381) Acc@5 97.656 (99.497)
2025-08-28 05:21:53,622 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:53,622 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:21:54,923 - INFO - Epoch: [86][200/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.4129 (0.4194) Acc@1 83.594 (85.323) Acc@5 100.000 (99.491)
2025-08-28 05:21:56,650 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:21:56,650 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:21:56,792 - INFO - Epoch: [86][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4426 (0.4203) Acc@1 85.156 (85.387) Acc@5 99.219 (99.463)
2025-08-28 05:21:58,557 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6278 (0.6278) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 05:21:59,414 - INFO - Epoch 86:
2025-08-28 05:21:59,414 - INFO -   Train: acc1: 85.4540 | acc5: 99.4480 | loss: 0.4194 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:21:59,414 - INFO -   Val:   acc1: 75.0600 | acc5: 98.2500 | loss: 0.8461
2025-08-28 05:21:59,414 - INFO -   LR: 0.100000
2025-08-28 05:21:59,428 - INFO - 
Epoch: 87, lr = 0.1
2025-08-28 05:21:59,632 - INFO - Epoch: [87][0/391] Time 0.203 (0.203) Data 0.174 (0.174) Loss 0.3814 (0.3814) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 05:22:00,736 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:00,736 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:22:01,476 - INFO - Epoch: [87][100/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.2838 (0.4229) Acc@1 89.844 (85.404) Acc@5 100.000 (99.404)
2025-08-28 05:22:03,317 - INFO - Epoch: [87][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2656 (0.4220) Acc@1 92.188 (85.459) Acc@5 99.219 (99.444)
2025-08-28 05:22:03,753 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:03,753 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:05,246 - INFO - Epoch: [87][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5443 (0.4189) Acc@1 82.031 (85.696) Acc@5 99.219 (99.393)
2025-08-28 05:22:06,742 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:06,742 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:07,024 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.5565 (0.5565) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:22:07,918 - INFO - Epoch 87:
2025-08-28 05:22:07,918 - INFO -   Train: acc1: 85.6420 | acc5: 99.4160 | loss: 0.4177 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:07,918 - INFO -   Val:   acc1: 80.8400 | acc5: 99.1500 | loss: 0.5811
2025-08-28 05:22:07,918 - INFO -   LR: 0.100000
2025-08-28 05:22:07,932 - INFO - 
Epoch: 88, lr = 0.1
2025-08-28 05:22:08,134 - INFO - Epoch: [88][0/391] Time 0.201 (0.201) Data 0.174 (0.174) Loss 0.3996 (0.3996) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:22:09,963 - INFO - Epoch: [88][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.3955 (0.4216) Acc@1 84.375 (85.404) Acc@5 100.000 (99.420)
2025-08-28 05:22:10,855 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:10,856 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:11,743 - INFO - Epoch: [88][200/391] Time 0.036 (0.019) Data 0.000 (0.004) Loss 0.3768 (0.4163) Acc@1 85.156 (85.572) Acc@5 100.000 (99.452)
2025-08-28 05:22:13,590 - INFO - Epoch: [88][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5663 (0.4156) Acc@1 77.344 (85.639) Acc@5 99.219 (99.458)
2025-08-28 05:22:13,757 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:13,757 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:15,381 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5295 (0.5295) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:22:16,225 - INFO - Epoch 88:
2025-08-28 05:22:16,225 - INFO -   Train: acc1: 85.5140 | acc5: 99.4700 | loss: 0.4189 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:16,225 - INFO -   Val:   acc1: 81.2600 | acc5: 99.1100 | loss: 0.5787
2025-08-28 05:22:16,226 - INFO -   LR: 0.100000
2025-08-28 05:22:16,239 - INFO - 
Epoch: 89, lr = 0.1
2025-08-28 05:22:16,434 - INFO - Epoch: [89][0/391] Time 0.193 (0.193) Data 0.175 (0.175) Loss 0.4380 (0.4380) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:22:17,954 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:17,954 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:18,342 - INFO - Epoch: [89][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.4796 (0.4094) Acc@1 82.812 (85.520) Acc@5 99.219 (99.366)
2025-08-28 05:22:20,124 - INFO - Epoch: [89][200/391] Time 0.024 (0.019) Data 0.013 (0.003) Loss 0.4503 (0.4167) Acc@1 86.719 (85.592) Acc@5 98.438 (99.398)
2025-08-28 05:22:20,902 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:20,902 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:22,004 - INFO - Epoch: [89][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.6540 (0.4196) Acc@1 79.688 (85.530) Acc@5 99.219 (99.403)
2025-08-28 05:22:23,801 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.7184 (0.7184) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-28 05:22:24,649 - INFO - Epoch 89:
2025-08-28 05:22:24,649 - INFO -   Train: acc1: 85.5340 | acc5: 99.3880 | loss: 0.4205 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:24,649 - INFO -   Val:   acc1: 76.6100 | acc5: 98.2400 | loss: 0.7647
2025-08-28 05:22:24,649 - INFO -   LR: 0.100000
2025-08-28 05:22:24,667 - INFO - 
Epoch: 90, lr = 0.1
2025-08-28 05:22:24,842 - INFO - Epoch: [90][0/391] Time 0.174 (0.174) Data 0.158 (0.158) Loss 0.4467 (0.4467) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:22:24,988 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:24,988 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:26,759 - INFO - Epoch: [90][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4537 (0.4113) Acc@1 83.594 (85.922) Acc@5 99.219 (99.397)
2025-08-28 05:22:27,993 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:27,994 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:28,563 - INFO - Epoch: [90][200/391] Time 0.024 (0.019) Data 0.002 (0.003) Loss 0.4195 (0.4135) Acc@1 86.719 (85.809) Acc@5 100.000 (99.433)
2025-08-28 05:22:30,374 - INFO - Epoch: [90][300/391] Time 0.023 (0.019) Data 0.005 (0.003) Loss 0.4792 (0.4131) Acc@1 82.812 (85.764) Acc@5 98.438 (99.465)
2025-08-28 05:22:30,886 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:30,886 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:32,116 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.5487 (0.5487) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:22:32,991 - INFO - Epoch 90:
2025-08-28 05:22:32,992 - INFO -   Train: acc1: 85.6380 | acc5: 99.4320 | loss: 0.4164 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:32,992 - INFO -   Val:   acc1: 80.8700 | acc5: 98.8300 | loss: 0.5892
2025-08-28 05:22:32,992 - INFO -   LR: 0.100000
2025-08-28 05:22:33,040 - INFO - 
Epoch: 91, lr = 0.1
2025-08-28 05:22:33,227 - INFO - Epoch: [91][0/391] Time 0.185 (0.185) Data 0.143 (0.143) Loss 0.4199 (0.4199) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-28 05:22:35,039 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:35,039 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:35,078 - INFO - Epoch: [91][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4347 (0.3981) Acc@1 85.938 (86.355) Acc@5 98.438 (99.520)
2025-08-28 05:22:36,889 - INFO - Epoch: [91][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.6153 (0.4159) Acc@1 82.031 (85.712) Acc@5 99.219 (99.433)
2025-08-28 05:22:38,040 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:38,041 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:38,778 - INFO - Epoch: [91][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4006 (0.4173) Acc@1 84.375 (85.592) Acc@5 100.000 (99.421)
2025-08-28 05:22:40,587 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6970 (0.6970) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-28 05:22:41,436 - INFO - Epoch 91:
2025-08-28 05:22:41,437 - INFO -   Train: acc1: 85.4120 | acc5: 99.4080 | loss: 0.4249 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:41,437 - INFO -   Val:   acc1: 75.6100 | acc5: 98.4600 | loss: 0.7748
2025-08-28 05:22:41,437 - INFO -   LR: 0.100000
2025-08-28 05:22:41,451 - INFO - 
Epoch: 92, lr = 0.1
2025-08-28 05:22:41,615 - INFO - Epoch: [92][0/391] Time 0.163 (0.163) Data 0.139 (0.139) Loss 0.3977 (0.3977) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:22:42,140 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:42,141 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:43,495 - INFO - Epoch: [92][100/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.4126 (0.4109) Acc@1 86.719 (85.945) Acc@5 100.000 (99.582)
2025-08-28 05:22:45,120 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:45,120 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:45,319 - INFO - Epoch: [92][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3368 (0.4115) Acc@1 86.719 (85.743) Acc@5 100.000 (99.522)
2025-08-28 05:22:47,140 - INFO - Epoch: [92][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3586 (0.4177) Acc@1 89.062 (85.468) Acc@5 100.000 (99.481)
2025-08-28 05:22:47,978 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:47,979 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:48,916 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6327 (0.6327) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 05:22:49,813 - INFO - Epoch 92:
2025-08-28 05:22:49,813 - INFO -   Train: acc1: 85.5840 | acc5: 99.4880 | loss: 0.4163 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:49,813 - INFO -   Val:   acc1: 79.0200 | acc5: 98.9500 | loss: 0.6381
2025-08-28 05:22:49,813 - INFO -   LR: 0.100000
2025-08-28 05:22:49,826 - INFO - 
Epoch: 93, lr = 0.1
2025-08-28 05:22:50,024 - INFO - Epoch: [93][0/391] Time 0.196 (0.196) Data 0.178 (0.178) Loss 0.3701 (0.3701) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:22:51,887 - INFO - Epoch: [93][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.3374 (0.4200) Acc@1 90.625 (85.412) Acc@5 100.000 (99.482)
2025-08-28 05:22:52,189 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:52,189 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:53,778 - INFO - Epoch: [93][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3105 (0.4138) Acc@1 89.844 (85.759) Acc@5 100.000 (99.456)
2025-08-28 05:22:55,155 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:55,155 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:22:55,572 - INFO - Epoch: [93][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4046 (0.4200) Acc@1 82.031 (85.517) Acc@5 99.219 (99.447)
2025-08-28 05:22:57,414 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.7960 (0.7960) Acc@1 71.875 (71.875) Acc@5 98.438 (98.438)
2025-08-28 05:22:58,278 - INFO - Epoch 93:
2025-08-28 05:22:58,279 - INFO -   Train: acc1: 85.5320 | acc5: 99.4240 | loss: 0.4207 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:22:58,279 - INFO -   Val:   acc1: 74.6200 | acc5: 96.7500 | loss: 0.8873
2025-08-28 05:22:58,279 - INFO -   LR: 0.100000
2025-08-28 05:22:58,291 - INFO - 
Epoch: 94, lr = 0.1
2025-08-28 05:22:58,481 - INFO - Epoch: [94][0/391] Time 0.188 (0.188) Data 0.165 (0.165) Loss 0.4052 (0.4052) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:22:59,478 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:22:59,478 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:00,488 - INFO - Epoch: [94][100/391] Time 0.019 (0.022) Data 0.008 (0.006) Loss 0.2719 (0.4172) Acc@1 92.969 (85.613) Acc@5 100.000 (99.497)
2025-08-28 05:23:02,304 - INFO - Epoch: [94][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.4209 (0.4151) Acc@1 87.500 (85.755) Acc@5 99.219 (99.468)
2025-08-28 05:23:02,385 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:02,385 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:04,180 - INFO - Epoch: [94][300/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4762 (0.4165) Acc@1 85.938 (85.665) Acc@5 98.438 (99.439)
2025-08-28 05:23:05,429 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:05,429 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:06,029 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.4739 (0.4739) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 05:23:06,889 - INFO - Epoch 94:
2025-08-28 05:23:06,889 - INFO -   Train: acc1: 85.5600 | acc5: 99.4340 | loss: 0.4190 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:06,889 - INFO -   Val:   acc1: 79.5700 | acc5: 98.9300 | loss: 0.5952
2025-08-28 05:23:06,889 - INFO -   LR: 0.100000
2025-08-28 05:23:06,905 - INFO - 
Epoch: 95, lr = 0.1
2025-08-28 05:23:07,219 - INFO - Epoch: [95][0/391] Time 0.313 (0.313) Data 0.291 (0.291) Loss 0.3588 (0.3588) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:23:09,226 - INFO - Epoch: [95][100/391] Time 0.019 (0.023) Data 0.000 (0.005) Loss 0.5344 (0.4093) Acc@1 80.469 (85.860) Acc@5 100.000 (99.474)
2025-08-28 05:23:09,842 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:09,842 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:11,046 - INFO - Epoch: [95][200/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.5666 (0.4097) Acc@1 79.688 (85.887) Acc@5 96.875 (99.487)
2025-08-28 05:23:12,791 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:12,791 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:12,868 - INFO - Epoch: [95][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3554 (0.4159) Acc@1 89.062 (85.836) Acc@5 100.000 (99.460)
2025-08-28 05:23:14,637 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6910 (0.6910) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 05:23:15,495 - INFO - Epoch 95:
2025-08-28 05:23:15,495 - INFO -   Train: acc1: 85.7120 | acc5: 99.4420 | loss: 0.4178 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:15,495 - INFO -   Val:   acc1: 75.5700 | acc5: 98.3800 | loss: 0.7737
2025-08-28 05:23:15,495 - INFO -   LR: 0.100000
2025-08-28 05:23:15,510 - INFO - 
Epoch: 96, lr = 0.1
2025-08-28 05:23:15,722 - INFO - Epoch: [96][0/391] Time 0.211 (0.211) Data 0.179 (0.179) Loss 0.5234 (0.5234) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-28 05:23:16,919 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:16,919 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:17,539 - INFO - Epoch: [96][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4421 (0.4084) Acc@1 84.375 (85.821) Acc@5 99.219 (99.412)
2025-08-28 05:23:19,380 - INFO - Epoch: [96][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5618 (0.4192) Acc@1 78.125 (85.541) Acc@5 100.000 (99.370)
2025-08-28 05:23:19,799 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:19,799 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:21,196 - INFO - Epoch: [96][300/391] Time 0.021 (0.019) Data 0.008 (0.003) Loss 0.3489 (0.4246) Acc@1 91.406 (85.309) Acc@5 99.219 (99.354)
2025-08-28 05:23:22,748 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:22,748 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:23,022 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6070 (0.6070) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 05:23:23,923 - INFO - Epoch 96:
2025-08-28 05:23:23,923 - INFO -   Train: acc1: 85.2960 | acc5: 99.3760 | loss: 0.4238 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:23,923 - INFO -   Val:   acc1: 79.6100 | acc5: 99.1900 | loss: 0.6210
2025-08-28 05:23:23,923 - INFO -   LR: 0.100000
2025-08-28 05:23:23,937 - INFO - 
Epoch: 97, lr = 0.1
2025-08-28 05:23:24,132 - INFO - Epoch: [97][0/391] Time 0.194 (0.194) Data 0.175 (0.175) Loss 0.4126 (0.4126) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:23:26,038 - INFO - Epoch: [97][100/391] Time 0.020 (0.021) Data 0.008 (0.003) Loss 0.4077 (0.4033) Acc@1 85.938 (86.030) Acc@5 98.438 (99.567)
2025-08-28 05:23:27,029 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:27,029 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:27,969 - INFO - Epoch: [97][200/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.4849 (0.4137) Acc@1 82.812 (85.580) Acc@5 99.219 (99.541)
2025-08-28 05:23:29,781 - INFO - Epoch: [97][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.3372 (0.4134) Acc@1 88.281 (85.642) Acc@5 100.000 (99.491)
2025-08-28 05:23:29,991 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:29,991 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:31,596 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6134 (0.6134) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 05:23:32,447 - INFO - Epoch 97:
2025-08-28 05:23:32,447 - INFO -   Train: acc1: 85.4000 | acc5: 99.4580 | loss: 0.4200 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:32,447 - INFO -   Val:   acc1: 81.0600 | acc5: 99.0100 | loss: 0.5942
2025-08-28 05:23:32,447 - INFO -   LR: 0.100000
2025-08-28 05:23:32,462 - INFO - 
Epoch: 98, lr = 0.1
2025-08-28 05:23:32,632 - INFO - Epoch: [98][0/391] Time 0.169 (0.169) Data 0.144 (0.144) Loss 0.4626 (0.4626) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:23:34,225 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:34,226 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:34,606 - INFO - Epoch: [98][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.3426 (0.4140) Acc@1 90.625 (85.783) Acc@5 100.000 (99.451)
2025-08-28 05:23:36,523 - INFO - Epoch: [98][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.5842 (0.4205) Acc@1 82.031 (85.607) Acc@5 97.656 (99.440)
2025-08-28 05:23:37,285 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:37,285 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:38,398 - INFO - Epoch: [98][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3478 (0.4187) Acc@1 89.844 (85.673) Acc@5 99.219 (99.434)
2025-08-28 05:23:40,187 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.4996 (0.4996) Acc@1 84.375 (84.375) Acc@5 96.875 (96.875)
2025-08-28 05:23:41,050 - INFO - Epoch 98:
2025-08-28 05:23:41,051 - INFO -   Train: acc1: 85.6200 | acc5: 99.4460 | loss: 0.4207 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:41,051 - INFO -   Val:   acc1: 82.1300 | acc5: 98.9800 | loss: 0.5267
2025-08-28 05:23:41,051 - INFO -   LR: 0.100000
2025-08-28 05:23:41,066 - INFO - 
Epoch: 99, lr = 0.1
2025-08-28 05:23:41,231 - INFO - Epoch: [99][0/391] Time 0.165 (0.165) Data 0.134 (0.134) Loss 0.4097 (0.4097) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:23:41,464 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:41,464 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:43,155 - INFO - Epoch: [99][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.5293 (0.4130) Acc@1 82.812 (85.767) Acc@5 98.438 (99.451)
2025-08-28 05:23:44,410 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:44,410 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:44,946 - INFO - Epoch: [99][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3625 (0.4185) Acc@1 88.281 (85.592) Acc@5 100.000 (99.460)
2025-08-28 05:23:46,846 - INFO - Epoch: [99][300/391] Time 0.020 (0.019) Data 0.002 (0.003) Loss 0.3986 (0.4209) Acc@1 89.062 (85.522) Acc@5 98.438 (99.445)
2025-08-28 05:23:47,370 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:47,370 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:48,577 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.4420 (0.4420) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:23:49,408 - INFO - Epoch 99:
2025-08-28 05:23:49,408 - INFO -   Train: acc1: 85.4620 | acc5: 99.4500 | loss: 0.4213 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:49,408 - INFO -   Val:   acc1: 82.7100 | acc5: 99.1800 | loss: 0.5165
2025-08-28 05:23:49,408 - INFO -   LR: 0.010000
2025-08-28 05:23:49,423 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-28 05:23:49,604 - INFO - Epoch: [100][0/391] Time 0.180 (0.180) Data 0.154 (0.154) Loss 0.3936 (0.3936) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:23:51,422 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:51,422 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:51,435 - INFO - Epoch: [100][100/391] Time 0.017 (0.020) Data 0.000 (0.005) Loss 0.2639 (0.3307) Acc@1 92.969 (88.807) Acc@5 100.000 (99.660)
2025-08-28 05:23:53,206 - INFO - Epoch: [100][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3014 (0.3135) Acc@1 89.062 (89.381) Acc@5 99.219 (99.685)
2025-08-28 05:23:54,295 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:54,296 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:55,081 - INFO - Epoch: [100][300/391] Time 0.027 (0.019) Data 0.013 (0.004) Loss 0.1875 (0.3012) Acc@1 93.750 (89.846) Acc@5 100.000 (99.678)
2025-08-28 05:23:56,828 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2478 (0.2478) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:23:57,683 - INFO - Epoch 100:
2025-08-28 05:23:57,683 - INFO -   Train: acc1: 90.0340 | acc5: 99.6700 | loss: 0.2943 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:23:57,683 - INFO -   Val:   acc1: 89.2600 | acc5: 99.6600 | loss: 0.3175
2025-08-28 05:23:57,683 - INFO -   LR: 0.010000
2025-08-28 05:23:57,735 - INFO - Checkpoint saved: epoch=100, metric=89.2600
2025-08-28 05:23:57,767 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-28 05:23:57,936 - INFO - Epoch: [101][0/391] Time 0.168 (0.168) Data 0.152 (0.152) Loss 0.2988 (0.2988) Acc@1 91.406 (91.406) Acc@5 98.438 (98.438)
2025-08-28 05:23:58,502 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:23:58,502 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:23:59,866 - INFO - Epoch: [101][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.1836 (0.2522) Acc@1 93.750 (91.391) Acc@5 100.000 (99.722)
2025-08-28 05:24:01,488 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:01,488 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:01,710 - INFO - Epoch: [101][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.2121 (0.2488) Acc@1 92.188 (91.663) Acc@5 100.000 (99.755)
2025-08-28 05:24:03,574 - INFO - Epoch: [101][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.2233 (0.2495) Acc@1 92.969 (91.526) Acc@5 100.000 (99.756)
2025-08-28 05:24:04,449 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:04,450 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:05,350 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2463 (0.2463) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:24:06,219 - INFO - Epoch 101:
2025-08-28 05:24:06,220 - INFO -   Train: acc1: 91.4700 | acc5: 99.7620 | loss: 0.2507 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:06,220 - INFO -   Val:   acc1: 89.2000 | acc5: 99.7200 | loss: 0.3152
2025-08-28 05:24:06,220 - INFO -   LR: 0.010000
2025-08-28 05:24:06,237 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-28 05:24:06,425 - INFO - Epoch: [102][0/391] Time 0.187 (0.187) Data 0.156 (0.156) Loss 0.2232 (0.2232) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:24:08,233 - INFO - Epoch: [102][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.2462 (0.2418) Acc@1 92.188 (91.855) Acc@5 100.000 (99.783)
2025-08-28 05:24:08,533 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:08,533 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:10,071 - INFO - Epoch: [102][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2090 (0.2391) Acc@1 91.406 (91.880) Acc@5 100.000 (99.790)
2025-08-28 05:24:11,546 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:11,546 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:11,932 - INFO - Epoch: [102][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2383 (0.2390) Acc@1 92.188 (91.850) Acc@5 100.000 (99.787)
2025-08-28 05:24:13,754 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2441 (0.2441) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:24:14,630 - INFO - Epoch 102:
2025-08-28 05:24:14,630 - INFO -   Train: acc1: 91.9240 | acc5: 99.8040 | loss: 0.2368 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:14,630 - INFO -   Val:   acc1: 89.6500 | acc5: 99.7300 | loss: 0.3015
2025-08-28 05:24:14,630 - INFO -   LR: 0.010000
2025-08-28 05:24:14,681 - INFO - Checkpoint saved: epoch=102, metric=89.6500
2025-08-28 05:24:14,712 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-28 05:24:14,877 - INFO - Epoch: [103][0/391] Time 0.165 (0.165) Data 0.135 (0.135) Loss 0.2851 (0.2851) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:24:15,722 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:15,722 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:16,696 - INFO - Epoch: [103][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2647 (0.2201) Acc@1 89.062 (92.567) Acc@5 100.000 (99.791)
2025-08-28 05:24:18,489 - INFO - Epoch: [103][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2294 (0.2232) Acc@1 92.969 (92.580) Acc@5 100.000 (99.813)
2025-08-28 05:24:18,606 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:18,607 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:20,320 - INFO - Epoch: [103][300/391] Time 0.029 (0.019) Data 0.000 (0.002) Loss 0.4282 (0.2234) Acc@1 88.281 (92.569) Acc@5 97.656 (99.798)
2025-08-28 05:24:21,568 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:21,568 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:22,145 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2717 (0.2717) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:24:23,013 - INFO - Epoch 103:
2025-08-28 05:24:23,014 - INFO -   Train: acc1: 92.4760 | acc5: 99.8000 | loss: 0.2251 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:23,014 - INFO -   Val:   acc1: 89.7300 | acc5: 99.7500 | loss: 0.3041
2025-08-28 05:24:23,014 - INFO -   LR: 0.010000
2025-08-28 05:24:23,064 - INFO - Checkpoint saved: epoch=103, metric=89.7300
2025-08-28 05:24:23,095 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-28 05:24:23,272 - INFO - Epoch: [104][0/391] Time 0.176 (0.176) Data 0.156 (0.156) Loss 0.2956 (0.2956) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:24:25,148 - INFO - Epoch: [104][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1779 (0.2205) Acc@1 91.406 (92.327) Acc@5 100.000 (99.876)
2025-08-28 05:24:25,798 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:25,798 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:27,031 - INFO - Epoch: [104][200/391] Time 0.024 (0.020) Data 0.001 (0.003) Loss 0.2615 (0.2217) Acc@1 87.500 (92.327) Acc@5 99.219 (99.825)
2025-08-28 05:24:28,774 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:28,774 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:28,855 - INFO - Epoch: [104][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.1771 (0.2220) Acc@1 95.312 (92.437) Acc@5 100.000 (99.813)
2025-08-28 05:24:30,724 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2430 (0.2430) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:24:31,605 - INFO - Epoch 104:
2025-08-28 05:24:31,605 - INFO -   Train: acc1: 92.4180 | acc5: 99.8120 | loss: 0.2229 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:31,606 - INFO -   Val:   acc1: 90.1600 | acc5: 99.7300 | loss: 0.2977
2025-08-28 05:24:31,606 - INFO -   LR: 0.010000
2025-08-28 05:24:31,656 - INFO - Checkpoint saved: epoch=104, metric=90.1600
2025-08-28 05:24:31,690 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-28 05:24:31,847 - INFO - Epoch: [105][0/391] Time 0.156 (0.156) Data 0.136 (0.136) Loss 0.1543 (0.1543) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:24:33,173 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:33,173 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:33,834 - INFO - Epoch: [105][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.2433 (0.2041) Acc@1 91.406 (93.224) Acc@5 100.000 (99.853)
2025-08-28 05:24:35,675 - INFO - Epoch: [105][200/391] Time 0.021 (0.020) Data 0.004 (0.004) Loss 0.1243 (0.2094) Acc@1 96.875 (92.973) Acc@5 100.000 (99.852)
2025-08-28 05:24:36,134 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:36,135 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:37,460 - INFO - Epoch: [105][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.2692 (0.2132) Acc@1 89.844 (92.810) Acc@5 100.000 (99.849)
2025-08-28 05:24:39,090 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:39,090 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:39,330 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2551 (0.2551) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:24:40,149 - INFO - Epoch 105:
2025-08-28 05:24:40,149 - INFO -   Train: acc1: 92.7820 | acc5: 99.8560 | loss: 0.2129 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:40,149 - INFO -   Val:   acc1: 89.4100 | acc5: 99.6900 | loss: 0.3235
2025-08-28 05:24:40,149 - INFO -   LR: 0.010000
2025-08-28 05:24:40,163 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-28 05:24:40,356 - INFO - Epoch: [106][0/391] Time 0.192 (0.192) Data 0.164 (0.164) Loss 0.1684 (0.1684) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:24:42,178 - INFO - Epoch: [106][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1431 (0.2057) Acc@1 93.750 (93.046) Acc@5 100.000 (99.830)
2025-08-28 05:24:43,170 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:43,170 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:44,051 - INFO - Epoch: [106][200/391] Time 0.052 (0.019) Data 0.042 (0.003) Loss 0.1982 (0.2069) Acc@1 94.531 (92.930) Acc@5 100.000 (99.856)
2025-08-28 05:24:45,939 - INFO - Epoch: [106][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4196 (0.2084) Acc@1 85.938 (92.883) Acc@5 100.000 (99.862)
2025-08-28 05:24:46,262 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:46,262 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:47,871 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2237 (0.2237) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:24:48,688 - INFO - Epoch 106:
2025-08-28 05:24:48,688 - INFO -   Train: acc1: 92.7800 | acc5: 99.8500 | loss: 0.2118 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:48,688 - INFO -   Val:   acc1: 90.1100 | acc5: 99.7500 | loss: 0.2980
2025-08-28 05:24:48,688 - INFO -   LR: 0.010000
2025-08-28 05:24:48,743 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-28 05:24:48,929 - INFO - Epoch: [107][0/391] Time 0.184 (0.184) Data 0.166 (0.166) Loss 0.1575 (0.1575) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:24:50,523 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:50,523 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:50,913 - INFO - Epoch: [107][100/391] Time 0.034 (0.021) Data 0.013 (0.005) Loss 0.1299 (0.2057) Acc@1 96.094 (93.000) Acc@5 100.000 (99.876)
2025-08-28 05:24:52,706 - INFO - Epoch: [107][200/391] Time 0.033 (0.020) Data 0.020 (0.003) Loss 0.2932 (0.2077) Acc@1 89.062 (92.852) Acc@5 100.000 (99.872)
2025-08-28 05:24:53,484 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:53,484 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:54,546 - INFO - Epoch: [107][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2423 (0.2057) Acc@1 90.625 (92.982) Acc@5 100.000 (99.868)
2025-08-28 05:24:56,337 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2525 (0.2525) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:24:57,203 - INFO - Epoch 107:
2025-08-28 05:24:57,203 - INFO -   Train: acc1: 92.9420 | acc5: 99.8720 | loss: 0.2073 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:24:57,203 - INFO -   Val:   acc1: 90.0800 | acc5: 99.7000 | loss: 0.3032
2025-08-28 05:24:57,203 - INFO -   LR: 0.010000
2025-08-28 05:24:57,220 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-28 05:24:57,411 - INFO - Epoch: [108][0/391] Time 0.189 (0.189) Data 0.161 (0.161) Loss 0.1088 (0.1088) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:24:57,576 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:24:57,576 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:24:59,243 - INFO - Epoch: [108][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2656 (0.2014) Acc@1 88.281 (93.077) Acc@5 100.000 (99.876)
2025-08-28 05:25:00,585 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:00,585 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:01,173 - INFO - Epoch: [108][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2134 (0.2042) Acc@1 92.969 (93.070) Acc@5 100.000 (99.868)
2025-08-28 05:25:02,961 - INFO - Epoch: [108][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.1796 (0.2033) Acc@1 96.094 (93.091) Acc@5 100.000 (99.875)
2025-08-28 05:25:03,521 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:03,521 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:04,742 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2691 (0.2691) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:25:05,604 - INFO - Epoch 108:
2025-08-28 05:25:05,605 - INFO -   Train: acc1: 93.1760 | acc5: 99.8660 | loss: 0.2023 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:05,605 - INFO -   Val:   acc1: 90.3400 | acc5: 99.7800 | loss: 0.2956
2025-08-28 05:25:05,605 - INFO -   LR: 0.010000
2025-08-28 05:25:05,653 - INFO - Checkpoint saved: epoch=108, metric=90.3400
2025-08-28 05:25:05,686 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-28 05:25:05,858 - INFO - Epoch: [109][0/391] Time 0.171 (0.171) Data 0.146 (0.146) Loss 0.1465 (0.1465) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:25:07,774 - INFO - Epoch: [109][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.2300 (0.1991) Acc@1 91.406 (93.193) Acc@5 100.000 (99.868)
2025-08-28 05:25:07,780 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:07,780 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:09,672 - INFO - Epoch: [109][200/391] Time 0.058 (0.020) Data 0.037 (0.003) Loss 0.1789 (0.1976) Acc@1 91.406 (93.116) Acc@5 100.000 (99.860)
2025-08-28 05:25:10,827 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:10,827 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:11,587 - INFO - Epoch: [109][300/391] Time 0.033 (0.020) Data 0.020 (0.003) Loss 0.1983 (0.1994) Acc@1 92.969 (93.114) Acc@5 100.000 (99.836)
2025-08-28 05:25:13,451 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2190 (0.2190) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:25:14,296 - INFO - Epoch 109:
2025-08-28 05:25:14,296 - INFO -   Train: acc1: 93.1060 | acc5: 99.8400 | loss: 0.2011 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:14,296 - INFO -   Val:   acc1: 90.0300 | acc5: 99.7400 | loss: 0.3063
2025-08-28 05:25:14,296 - INFO -   LR: 0.010000
2025-08-28 05:25:14,311 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-28 05:25:14,513 - INFO - Epoch: [110][0/391] Time 0.201 (0.201) Data 0.165 (0.165) Loss 0.1106 (0.1106) Acc@1 97.656 (97.656) Acc@5 99.219 (99.219)
2025-08-28 05:25:15,044 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:15,044 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:16,411 - INFO - Epoch: [110][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.2098 (0.1881) Acc@1 92.188 (93.487) Acc@5 100.000 (99.868)
2025-08-28 05:25:17,999 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:18,000 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:18,190 - INFO - Epoch: [110][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1958 (0.1938) Acc@1 93.750 (93.342) Acc@5 100.000 (99.880)
2025-08-28 05:25:19,993 - INFO - Epoch: [110][300/391] Time 0.017 (0.019) Data 0.005 (0.003) Loss 0.1973 (0.1963) Acc@1 94.531 (93.272) Acc@5 100.000 (99.868)
2025-08-28 05:25:20,889 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:20,889 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:21,817 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2129 (0.2129) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:25:22,660 - INFO - Epoch 110:
2025-08-28 05:25:22,660 - INFO -   Train: acc1: 93.2340 | acc5: 99.8640 | loss: 0.1963 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:22,660 - INFO -   Val:   acc1: 89.4800 | acc5: 99.7400 | loss: 0.3203
2025-08-28 05:25:22,660 - INFO -   LR: 0.010000
2025-08-28 05:25:22,709 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-28 05:25:22,892 - INFO - Epoch: [111][0/391] Time 0.182 (0.182) Data 0.163 (0.163) Loss 0.1467 (0.1467) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:25:24,769 - INFO - Epoch: [111][100/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.1870 (0.1832) Acc@1 91.406 (93.696) Acc@5 100.000 (99.892)
2025-08-28 05:25:25,108 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:25,108 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:26,610 - INFO - Epoch: [111][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1659 (0.1917) Acc@1 94.531 (93.435) Acc@5 100.000 (99.883)
2025-08-28 05:25:28,095 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:28,095 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:28,486 - INFO - Epoch: [111][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2342 (0.1961) Acc@1 91.406 (93.283) Acc@5 100.000 (99.875)
2025-08-28 05:25:30,244 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2833 (0.2833) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:25:31,086 - INFO - Epoch 111:
2025-08-28 05:25:31,086 - INFO -   Train: acc1: 93.2960 | acc5: 99.8640 | loss: 0.1958 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:31,086 - INFO -   Val:   acc1: 89.8500 | acc5: 99.7500 | loss: 0.3132
2025-08-28 05:25:31,086 - INFO -   LR: 0.010000
2025-08-28 05:25:31,101 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-28 05:25:31,284 - INFO - Epoch: [112][0/391] Time 0.182 (0.182) Data 0.146 (0.146) Loss 0.1537 (0.1537) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:25:32,176 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:32,176 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:33,183 - INFO - Epoch: [112][100/391] Time 0.023 (0.021) Data 0.001 (0.004) Loss 0.2150 (0.1840) Acc@1 92.188 (93.704) Acc@5 100.000 (99.899)
2025-08-28 05:25:35,049 - INFO - Epoch: [112][200/391] Time 0.029 (0.020) Data 0.000 (0.004) Loss 0.1772 (0.1860) Acc@1 93.750 (93.571) Acc@5 100.000 (99.911)
2025-08-28 05:25:35,169 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:35,169 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:36,894 - INFO - Epoch: [112][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.0966 (0.1856) Acc@1 96.875 (93.527) Acc@5 100.000 (99.899)
2025-08-28 05:25:38,184 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:38,184 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:38,741 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2354 (0.2354) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:25:39,613 - INFO - Epoch 112:
2025-08-28 05:25:39,613 - INFO -   Train: acc1: 93.3720 | acc5: 99.8800 | loss: 0.1909 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:39,614 - INFO -   Val:   acc1: 89.6100 | acc5: 99.7200 | loss: 0.3169
2025-08-28 05:25:39,614 - INFO -   LR: 0.010000
2025-08-28 05:25:39,628 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-28 05:25:39,830 - INFO - Epoch: [113][0/391] Time 0.201 (0.201) Data 0.165 (0.165) Loss 0.1778 (0.1778) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:25:41,698 - INFO - Epoch: [113][100/391] Time 0.020 (0.020) Data 0.000 (0.005) Loss 0.1274 (0.1857) Acc@1 96.094 (93.696) Acc@5 100.000 (99.868)
2025-08-28 05:25:42,387 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:42,387 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:43,582 - INFO - Epoch: [113][200/391] Time 0.039 (0.020) Data 0.026 (0.004) Loss 0.2081 (0.1839) Acc@1 91.406 (93.781) Acc@5 100.000 (99.883)
2025-08-28 05:25:45,323 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:45,323 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:45,388 - INFO - Epoch: [113][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2222 (0.1858) Acc@1 91.406 (93.646) Acc@5 100.000 (99.896)
2025-08-28 05:25:47,131 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2653 (0.2653) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:25:47,999 - INFO - Epoch 113:
2025-08-28 05:25:48,000 - INFO -   Train: acc1: 93.5260 | acc5: 99.8880 | loss: 0.1888 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:48,000 - INFO -   Val:   acc1: 90.4000 | acc5: 99.7500 | loss: 0.3095
2025-08-28 05:25:48,000 - INFO -   LR: 0.010000
2025-08-28 05:25:48,049 - INFO - Checkpoint saved: epoch=113, metric=90.4000
2025-08-28 05:25:48,081 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-28 05:25:48,270 - INFO - Epoch: [114][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.1147 (0.1147) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:25:49,473 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:49,473 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:50,117 - INFO - Epoch: [114][100/391] Time 0.049 (0.020) Data 0.018 (0.005) Loss 0.2080 (0.1881) Acc@1 91.406 (93.487) Acc@5 100.000 (99.892)
2025-08-28 05:25:51,923 - INFO - Epoch: [114][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2508 (0.1886) Acc@1 90.625 (93.497) Acc@5 100.000 (99.868)
2025-08-28 05:25:52,391 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:52,392 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:53,803 - INFO - Epoch: [114][300/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.1105 (0.1892) Acc@1 98.438 (93.418) Acc@5 100.000 (99.873)
2025-08-28 05:25:55,365 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:55,365 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:25:55,591 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.3173 (0.3173) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:25:56,458 - INFO - Epoch 114:
2025-08-28 05:25:56,459 - INFO -   Train: acc1: 93.3000 | acc5: 99.8660 | loss: 0.1929 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:25:56,459 - INFO -   Val:   acc1: 89.5200 | acc5: 99.6700 | loss: 0.3326
2025-08-28 05:25:56,459 - INFO -   LR: 0.010000
2025-08-28 05:25:56,475 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-28 05:25:56,677 - INFO - Epoch: [115][0/391] Time 0.200 (0.200) Data 0.179 (0.179) Loss 0.2035 (0.2035) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:25:58,487 - INFO - Epoch: [115][100/391] Time 0.032 (0.020) Data 0.000 (0.003) Loss 0.2842 (0.1757) Acc@1 89.844 (93.959) Acc@5 99.219 (99.892)
2025-08-28 05:25:59,448 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:25:59,448 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:00,264 - INFO - Epoch: [115][200/391] Time 0.018 (0.019) Data 0.004 (0.002) Loss 0.1987 (0.1777) Acc@1 92.188 (93.921) Acc@5 100.000 (99.891)
2025-08-28 05:26:02,166 - INFO - Epoch: [115][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.2187 (0.1838) Acc@1 90.625 (93.724) Acc@5 100.000 (99.868)
2025-08-28 05:26:02,395 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:02,395 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:03,936 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2379 (0.2379) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:26:04,798 - INFO - Epoch 115:
2025-08-28 05:26:04,799 - INFO -   Train: acc1: 93.5940 | acc5: 99.8600 | loss: 0.1862 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:04,799 - INFO -   Val:   acc1: 89.9600 | acc5: 99.7400 | loss: 0.3081
2025-08-28 05:26:04,799 - INFO -   LR: 0.010000
2025-08-28 05:26:05,391 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-28 05:26:05,528 - INFO - Epoch: [116][0/391] Time 0.136 (0.136) Data 0.113 (0.113) Loss 0.2391 (0.2391) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:26:07,096 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:07,096 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:07,403 - INFO - Epoch: [116][100/391] Time 0.028 (0.020) Data 0.000 (0.004) Loss 0.2053 (0.1822) Acc@1 94.531 (93.765) Acc@5 100.000 (99.923)
2025-08-28 05:26:09,273 - INFO - Epoch: [116][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.1818 (0.1859) Acc@1 93.750 (93.618) Acc@5 100.000 (99.899)
2025-08-28 05:26:10,047 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:10,047 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:11,128 - INFO - Epoch: [116][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1907 (0.1837) Acc@1 90.625 (93.649) Acc@5 100.000 (99.899)
2025-08-28 05:26:12,950 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2462 (0.2462) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:26:13,813 - INFO - Epoch 116:
2025-08-28 05:26:13,813 - INFO -   Train: acc1: 93.5720 | acc5: 99.8920 | loss: 0.1861 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:13,813 - INFO -   Val:   acc1: 89.9600 | acc5: 99.7100 | loss: 0.3069
2025-08-28 05:26:13,813 - INFO -   LR: 0.010000
2025-08-28 05:26:13,829 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-28 05:26:14,006 - INFO - Epoch: [117][0/391] Time 0.176 (0.176) Data 0.156 (0.156) Loss 0.2009 (0.2009) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:26:14,222 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:14,223 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:15,853 - INFO - Epoch: [117][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.1673 (0.1770) Acc@1 94.531 (94.121) Acc@5 100.000 (99.915)
2025-08-28 05:26:17,171 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:17,171 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:17,689 - INFO - Epoch: [117][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2628 (0.1797) Acc@1 92.969 (94.022) Acc@5 99.219 (99.895)
2025-08-28 05:26:19,568 - INFO - Epoch: [117][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2165 (0.1840) Acc@1 92.969 (93.786) Acc@5 100.000 (99.891)
2025-08-28 05:26:20,165 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:20,165 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:21,347 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2552 (0.2552) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:26:22,207 - INFO - Epoch 117:
2025-08-28 05:26:22,207 - INFO -   Train: acc1: 93.6440 | acc5: 99.8920 | loss: 0.1864 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:22,207 - INFO -   Val:   acc1: 88.9800 | acc5: 99.6100 | loss: 0.3411
2025-08-28 05:26:22,207 - INFO -   LR: 0.010000
2025-08-28 05:26:22,221 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-28 05:26:22,370 - INFO - Epoch: [118][0/391] Time 0.148 (0.148) Data 0.126 (0.126) Loss 0.1376 (0.1376) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:26:24,288 - INFO - Epoch: [118][100/391] Time 0.027 (0.020) Data 0.001 (0.003) Loss 0.1967 (0.1840) Acc@1 93.750 (94.021) Acc@5 100.000 (99.868)
2025-08-28 05:26:24,312 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:24,312 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:26,073 - INFO - Epoch: [118][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1506 (0.1843) Acc@1 94.531 (93.812) Acc@5 100.000 (99.876)
2025-08-28 05:26:27,259 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:27,259 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:27,915 - INFO - Epoch: [118][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.1916 (0.1835) Acc@1 91.406 (93.794) Acc@5 100.000 (99.888)
2025-08-28 05:26:29,700 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2139 (0.2139) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:26:30,533 - INFO - Epoch 118:
2025-08-28 05:26:30,533 - INFO -   Train: acc1: 93.6900 | acc5: 99.8960 | loss: 0.1859 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:30,533 - INFO -   Val:   acc1: 89.4700 | acc5: 99.7700 | loss: 0.3238
2025-08-28 05:26:30,533 - INFO -   LR: 0.010000
2025-08-28 05:26:30,550 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-28 05:26:30,713 - INFO - Epoch: [119][0/391] Time 0.161 (0.161) Data 0.136 (0.136) Loss 0.2339 (0.2339) Acc@1 92.969 (92.969) Acc@5 98.438 (98.438)
2025-08-28 05:26:31,285 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:31,285 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:32,634 - INFO - Epoch: [119][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.0945 (0.1839) Acc@1 96.094 (93.735) Acc@5 100.000 (99.907)
2025-08-28 05:26:34,288 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:34,288 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:34,500 - INFO - Epoch: [119][200/391] Time 0.028 (0.020) Data 0.016 (0.003) Loss 0.2473 (0.1849) Acc@1 91.406 (93.692) Acc@5 100.000 (99.914)
2025-08-28 05:26:36,290 - INFO - Epoch: [119][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.2624 (0.1842) Acc@1 92.188 (93.753) Acc@5 100.000 (99.914)
2025-08-28 05:26:37,210 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:37,211 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:38,074 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2820 (0.2820) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:26:38,910 - INFO - Epoch 119:
2025-08-28 05:26:38,910 - INFO -   Train: acc1: 93.6800 | acc5: 99.9040 | loss: 0.1854 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:38,910 - INFO -   Val:   acc1: 89.4900 | acc5: 99.6800 | loss: 0.3375
2025-08-28 05:26:38,910 - INFO -   LR: 0.010000
2025-08-28 05:26:38,926 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-28 05:26:39,120 - INFO - Epoch: [120][0/391] Time 0.193 (0.193) Data 0.168 (0.168) Loss 0.1799 (0.1799) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:26:41,022 - INFO - Epoch: [120][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.1640 (0.1810) Acc@1 96.094 (93.789) Acc@5 100.000 (99.899)
2025-08-28 05:26:41,332 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:41,332 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:42,885 - INFO - Epoch: [120][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1765 (0.1843) Acc@1 92.188 (93.777) Acc@5 100.000 (99.911)
2025-08-28 05:26:44,353 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:44,353 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:44,761 - INFO - Epoch: [120][300/391] Time 0.042 (0.019) Data 0.009 (0.003) Loss 0.1819 (0.1848) Acc@1 94.531 (93.695) Acc@5 100.000 (99.899)
2025-08-28 05:26:46,592 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3203 (0.3203) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 05:26:47,485 - INFO - Epoch 120:
2025-08-28 05:26:47,485 - INFO -   Train: acc1: 93.5680 | acc5: 99.8980 | loss: 0.1874 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:47,485 - INFO -   Val:   acc1: 88.9600 | acc5: 99.7400 | loss: 0.3383
2025-08-28 05:26:47,485 - INFO -   LR: 0.010000
2025-08-28 05:26:47,536 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-28 05:26:47,703 - INFO - Epoch: [121][0/391] Time 0.166 (0.166) Data 0.146 (0.146) Loss 0.1841 (0.1841) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:26:48,569 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:48,569 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:49,531 - INFO - Epoch: [121][100/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.1837 (0.1783) Acc@1 93.750 (94.021) Acc@5 100.000 (99.899)
2025-08-28 05:26:51,370 - INFO - Epoch: [121][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1708 (0.1822) Acc@1 92.188 (93.680) Acc@5 100.000 (99.899)
2025-08-28 05:26:51,556 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:51,557 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:53,282 - INFO - Epoch: [121][300/391] Time 0.052 (0.019) Data 0.029 (0.003) Loss 0.2562 (0.1856) Acc@1 92.969 (93.527) Acc@5 100.000 (99.896)
2025-08-28 05:26:54,501 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:54,501 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:55,070 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2463 (0.2463) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:26:55,950 - INFO - Epoch 121:
2025-08-28 05:26:55,951 - INFO -   Train: acc1: 93.5840 | acc5: 99.8940 | loss: 0.1864 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:26:55,951 - INFO -   Val:   acc1: 88.5800 | acc5: 99.6000 | loss: 0.3527
2025-08-28 05:26:55,951 - INFO -   LR: 0.010000
2025-08-28 05:26:55,965 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-28 05:26:56,150 - INFO - Epoch: [122][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.1425 (0.1425) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:26:58,027 - INFO - Epoch: [122][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2468 (0.1774) Acc@1 89.062 (93.796) Acc@5 100.000 (99.892)
2025-08-28 05:26:58,721 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:26:58,721 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:26:59,896 - INFO - Epoch: [122][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.1653 (0.1842) Acc@1 92.969 (93.653) Acc@5 99.219 (99.899)
2025-08-28 05:27:01,692 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:01,692 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:01,742 - INFO - Epoch: [122][300/391] Time 0.014 (0.019) Data 0.003 (0.003) Loss 0.2262 (0.1837) Acc@1 89.844 (93.698) Acc@5 100.000 (99.873)
2025-08-28 05:27:03,575 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2845 (0.2845) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:27:04,434 - INFO - Epoch 122:
2025-08-28 05:27:04,434 - INFO -   Train: acc1: 93.5880 | acc5: 99.8840 | loss: 0.1855 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:04,434 - INFO -   Val:   acc1: 89.6300 | acc5: 99.6900 | loss: 0.3267
2025-08-28 05:27:04,434 - INFO -   LR: 0.010000
2025-08-28 05:27:04,451 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-28 05:27:04,646 - INFO - Epoch: [123][0/391] Time 0.195 (0.195) Data 0.168 (0.168) Loss 0.1447 (0.1447) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:27:05,882 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:05,883 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:06,523 - INFO - Epoch: [123][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1877 (0.1877) Acc@1 92.969 (93.502) Acc@5 100.000 (99.930)
2025-08-28 05:27:08,343 - INFO - Epoch: [123][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1858 (0.1829) Acc@1 93.750 (93.664) Acc@5 100.000 (99.918)
2025-08-28 05:27:08,829 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:08,829 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:10,227 - INFO - Epoch: [123][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.2206 (0.1820) Acc@1 91.406 (93.623) Acc@5 100.000 (99.914)
2025-08-28 05:27:11,835 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:11,835 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:12,057 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2599 (0.2599) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:27:12,906 - INFO - Epoch 123:
2025-08-28 05:27:12,906 - INFO -   Train: acc1: 93.5020 | acc5: 99.9060 | loss: 0.1856 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:12,906 - INFO -   Val:   acc1: 89.7600 | acc5: 99.6500 | loss: 0.3267
2025-08-28 05:27:12,906 - INFO -   LR: 0.010000
2025-08-28 05:27:12,924 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-28 05:27:13,082 - INFO - Epoch: [124][0/391] Time 0.156 (0.156) Data 0.135 (0.135) Loss 0.2000 (0.2000) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:27:15,001 - INFO - Epoch: [124][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.2262 (0.1751) Acc@1 93.750 (93.866) Acc@5 100.000 (99.915)
2025-08-28 05:27:15,976 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:15,976 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:16,760 - INFO - Epoch: [124][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1637 (0.1816) Acc@1 91.406 (93.731) Acc@5 100.000 (99.907)
2025-08-28 05:27:18,646 - INFO - Epoch: [124][300/391] Time 0.029 (0.019) Data 0.002 (0.003) Loss 0.1514 (0.1833) Acc@1 93.750 (93.695) Acc@5 100.000 (99.912)
2025-08-28 05:27:18,945 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:18,945 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:20,487 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2940 (0.2940) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:27:21,316 - INFO - Epoch 124:
2025-08-28 05:27:21,316 - INFO -   Train: acc1: 93.5260 | acc5: 99.8980 | loss: 0.1867 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:21,316 - INFO -   Val:   acc1: 89.5500 | acc5: 99.6500 | loss: 0.3185
2025-08-28 05:27:21,316 - INFO -   LR: 0.010000
2025-08-28 05:27:21,386 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-28 05:27:21,539 - INFO - Epoch: [125][0/391] Time 0.153 (0.153) Data 0.132 (0.132) Loss 0.2262 (0.2262) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:27:23,262 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:23,262 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:23,582 - INFO - Epoch: [125][100/391] Time 0.023 (0.022) Data 0.000 (0.004) Loss 0.1598 (0.1773) Acc@1 93.750 (93.943) Acc@5 100.000 (99.838)
2025-08-28 05:27:25,553 - INFO - Epoch: [125][200/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.1033 (0.1764) Acc@1 96.875 (94.065) Acc@5 100.000 (99.872)
2025-08-28 05:27:26,363 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:26,363 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:27,376 - INFO - Epoch: [125][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1039 (0.1774) Acc@1 96.875 (94.048) Acc@5 100.000 (99.868)
2025-08-28 05:27:29,226 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2407 (0.2407) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:27:30,045 - INFO - Epoch 125:
2025-08-28 05:27:30,045 - INFO -   Train: acc1: 93.9560 | acc5: 99.8760 | loss: 0.1793 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:30,045 - INFO -   Val:   acc1: 89.3600 | acc5: 99.7500 | loss: 0.3326
2025-08-28 05:27:30,045 - INFO -   LR: 0.010000
2025-08-28 05:27:30,064 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-28 05:27:30,254 - INFO - Epoch: [126][0/391] Time 0.189 (0.189) Data 0.158 (0.158) Loss 0.2212 (0.2212) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:27:30,477 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:30,477 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:32,052 - INFO - Epoch: [126][100/391] Time 0.021 (0.020) Data 0.005 (0.004) Loss 0.1519 (0.1812) Acc@1 95.312 (93.595) Acc@5 100.000 (99.899)
2025-08-28 05:27:33,518 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:33,518 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:34,003 - INFO - Epoch: [126][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1589 (0.1832) Acc@1 94.531 (93.571) Acc@5 100.000 (99.911)
2025-08-28 05:27:36,006 - INFO - Epoch: [126][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1679 (0.1848) Acc@1 94.531 (93.568) Acc@5 100.000 (99.904)
2025-08-28 05:27:36,671 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:36,671 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:37,945 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2588 (0.2588) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:27:38,803 - INFO - Epoch 126:
2025-08-28 05:27:38,804 - INFO -   Train: acc1: 93.4520 | acc5: 99.8900 | loss: 0.1869 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:38,804 - INFO -   Val:   acc1: 89.2000 | acc5: 99.6500 | loss: 0.3497
2025-08-28 05:27:38,804 - INFO -   LR: 0.010000
2025-08-28 05:27:38,821 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-28 05:27:39,004 - INFO - Epoch: [127][0/391] Time 0.183 (0.183) Data 0.158 (0.158) Loss 0.1388 (0.1388) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:27:40,954 - INFO - Epoch: [127][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2393 (0.1791) Acc@1 89.062 (93.820) Acc@5 100.000 (99.868)
2025-08-28 05:27:41,001 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:41,001 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:42,831 - INFO - Epoch: [127][200/391] Time 0.026 (0.020) Data 0.012 (0.003) Loss 0.2617 (0.1790) Acc@1 91.406 (93.793) Acc@5 100.000 (99.856)
2025-08-28 05:27:43,961 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:43,961 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:44,646 - INFO - Epoch: [127][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2540 (0.1826) Acc@1 90.625 (93.672) Acc@5 100.000 (99.844)
2025-08-28 05:27:46,454 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2690 (0.2690) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:27:47,314 - INFO - Epoch 127:
2025-08-28 05:27:47,314 - INFO -   Train: acc1: 93.5840 | acc5: 99.8480 | loss: 0.1860 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:47,314 - INFO -   Val:   acc1: 89.0600 | acc5: 99.5400 | loss: 0.3359
2025-08-28 05:27:47,314 - INFO -   LR: 0.010000
2025-08-28 05:27:47,333 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-28 05:27:47,539 - INFO - Epoch: [128][0/391] Time 0.205 (0.205) Data 0.164 (0.164) Loss 0.2638 (0.2638) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:27:48,173 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:48,173 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:49,451 - INFO - Epoch: [128][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.1361 (0.1808) Acc@1 96.875 (93.657) Acc@5 100.000 (99.907)
2025-08-28 05:27:51,188 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:51,188 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:51,349 - INFO - Epoch: [128][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1649 (0.1807) Acc@1 94.531 (93.676) Acc@5 100.000 (99.895)
2025-08-28 05:27:53,217 - INFO - Epoch: [128][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1299 (0.1840) Acc@1 96.875 (93.612) Acc@5 100.000 (99.909)
2025-08-28 05:27:54,181 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:54,182 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:55,019 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2854 (0.2854) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:27:55,886 - INFO - Epoch 128:
2025-08-28 05:27:55,887 - INFO -   Train: acc1: 93.4940 | acc5: 99.9060 | loss: 0.1875 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:27:55,887 - INFO -   Val:   acc1: 88.7200 | acc5: 99.7200 | loss: 0.3620
2025-08-28 05:27:55,887 - INFO -   LR: 0.010000
2025-08-28 05:27:55,904 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-28 05:27:56,092 - INFO - Epoch: [129][0/391] Time 0.188 (0.188) Data 0.151 (0.151) Loss 0.1409 (0.1409) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:27:57,954 - INFO - Epoch: [129][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1707 (0.1776) Acc@1 94.531 (94.098) Acc@5 100.000 (99.876)
2025-08-28 05:27:58,348 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:27:58,348 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:27:59,764 - INFO - Epoch: [129][200/391] Time 0.024 (0.019) Data 0.012 (0.002) Loss 0.2031 (0.1835) Acc@1 91.406 (93.703) Acc@5 100.000 (99.883)
2025-08-28 05:28:01,224 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:01,224 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:01,590 - INFO - Epoch: [129][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1773 (0.1833) Acc@1 92.188 (93.662) Acc@5 100.000 (99.878)
2025-08-28 05:28:03,401 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2582 (0.2582) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:28:04,280 - INFO - Epoch 129:
2025-08-28 05:28:04,281 - INFO -   Train: acc1: 93.4260 | acc5: 99.8780 | loss: 0.1888 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:04,281 - INFO -   Val:   acc1: 88.9500 | acc5: 99.6800 | loss: 0.3500
2025-08-28 05:28:04,281 - INFO -   LR: 0.010000
2025-08-28 05:28:04,296 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-28 05:28:04,493 - INFO - Epoch: [130][0/391] Time 0.196 (0.196) Data 0.154 (0.154) Loss 0.1900 (0.1900) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:28:05,395 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:05,395 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:06,350 - INFO - Epoch: [130][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1867 (0.1743) Acc@1 93.750 (94.013) Acc@5 100.000 (99.899)
2025-08-28 05:28:08,343 - INFO - Epoch: [130][200/391] Time 0.021 (0.020) Data 0.007 (0.004) Loss 0.1850 (0.1784) Acc@1 94.531 (93.851) Acc@5 100.000 (99.899)
2025-08-28 05:28:08,550 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:08,550 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:10,252 - INFO - Epoch: [130][300/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2452 (0.1835) Acc@1 92.188 (93.659) Acc@5 100.000 (99.891)
2025-08-28 05:28:11,497 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:11,497 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:12,023 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3482 (0.3482) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:28:12,881 - INFO - Epoch 130:
2025-08-28 05:28:12,882 - INFO -   Train: acc1: 93.5260 | acc5: 99.8960 | loss: 0.1857 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:12,882 - INFO -   Val:   acc1: 89.0200 | acc5: 99.7100 | loss: 0.3501
2025-08-28 05:28:12,882 - INFO -   LR: 0.010000
2025-08-28 05:28:12,935 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-28 05:28:13,114 - INFO - Epoch: [131][0/391] Time 0.179 (0.179) Data 0.149 (0.149) Loss 0.1404 (0.1404) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-28 05:28:15,010 - INFO - Epoch: [131][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.1681 (0.1843) Acc@1 95.312 (93.502) Acc@5 99.219 (99.861)
2025-08-28 05:28:15,703 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:15,703 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:16,917 - INFO - Epoch: [131][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.1515 (0.1840) Acc@1 93.750 (93.536) Acc@5 100.000 (99.899)
2025-08-28 05:28:18,717 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:18,717 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:18,755 - INFO - Epoch: [131][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1881 (0.1845) Acc@1 94.531 (93.483) Acc@5 100.000 (99.891)
2025-08-28 05:28:20,549 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2668 (0.2668) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:28:21,398 - INFO - Epoch 131:
2025-08-28 05:28:21,398 - INFO -   Train: acc1: 93.4760 | acc5: 99.8840 | loss: 0.1861 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:21,398 - INFO -   Val:   acc1: 88.7800 | acc5: 99.5900 | loss: 0.3555
2025-08-28 05:28:21,398 - INFO -   LR: 0.010000
2025-08-28 05:28:21,414 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-28 05:28:21,597 - INFO - Epoch: [132][0/391] Time 0.182 (0.182) Data 0.166 (0.166) Loss 0.1821 (0.1821) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 05:28:22,859 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:22,859 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:23,451 - INFO - Epoch: [132][100/391] Time 0.031 (0.020) Data 0.000 (0.005) Loss 0.1407 (0.1799) Acc@1 96.094 (93.603) Acc@5 100.000 (99.907)
2025-08-28 05:28:25,319 - INFO - Epoch: [132][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1918 (0.1778) Acc@1 95.312 (93.847) Acc@5 100.000 (99.918)
2025-08-28 05:28:25,855 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:25,855 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:27,175 - INFO - Epoch: [132][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1778 (0.1816) Acc@1 93.750 (93.768) Acc@5 99.219 (99.894)
2025-08-28 05:28:28,756 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:28,756 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:28,952 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2851 (0.2851) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:28:29,832 - INFO - Epoch 132:
2025-08-28 05:28:29,833 - INFO -   Train: acc1: 93.5440 | acc5: 99.8900 | loss: 0.1863 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:29,833 - INFO -   Val:   acc1: 89.2400 | acc5: 99.6500 | loss: 0.3388
2025-08-28 05:28:29,833 - INFO -   LR: 0.010000
2025-08-28 05:28:29,849 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-28 05:28:30,044 - INFO - Epoch: [133][0/391] Time 0.195 (0.195) Data 0.177 (0.177) Loss 0.1636 (0.1636) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:28:31,882 - INFO - Epoch: [133][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1932 (0.1844) Acc@1 94.531 (93.479) Acc@5 100.000 (99.923)
2025-08-28 05:28:32,980 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:32,980 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:33,777 - INFO - Epoch: [133][200/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.1858 (0.1833) Acc@1 91.406 (93.548) Acc@5 100.000 (99.907)
2025-08-28 05:28:35,577 - INFO - Epoch: [133][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1737 (0.1848) Acc@1 92.188 (93.542) Acc@5 100.000 (99.883)
2025-08-28 05:28:35,896 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:35,896 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:37,361 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.3459 (0.3459) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:28:38,238 - INFO - Epoch 133:
2025-08-28 05:28:38,238 - INFO -   Train: acc1: 93.3760 | acc5: 99.8800 | loss: 0.1887 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:38,238 - INFO -   Val:   acc1: 89.2500 | acc5: 99.7300 | loss: 0.3341
2025-08-28 05:28:38,238 - INFO -   LR: 0.010000
2025-08-28 05:28:38,256 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-28 05:28:38,454 - INFO - Epoch: [134][0/391] Time 0.197 (0.197) Data 0.172 (0.172) Loss 0.1710 (0.1710) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:28:40,051 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:40,051 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:40,272 - INFO - Epoch: [134][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1340 (0.1786) Acc@1 96.094 (94.005) Acc@5 100.000 (99.868)
2025-08-28 05:28:42,098 - INFO - Epoch: [134][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1882 (0.1792) Acc@1 92.969 (93.968) Acc@5 100.000 (99.895)
2025-08-28 05:28:42,963 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:42,963 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:44,012 - INFO - Epoch: [134][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2798 (0.1846) Acc@1 89.062 (93.641) Acc@5 99.219 (99.891)
2025-08-28 05:28:45,817 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2482 (0.2482) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:28:46,667 - INFO - Epoch 134:
2025-08-28 05:28:46,667 - INFO -   Train: acc1: 93.5720 | acc5: 99.8900 | loss: 0.1862 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:46,668 - INFO -   Val:   acc1: 88.6900 | acc5: 99.6400 | loss: 0.3534
2025-08-28 05:28:46,668 - INFO -   LR: 0.010000
2025-08-28 05:28:46,687 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-28 05:28:46,890 - INFO - Epoch: [135][0/391] Time 0.202 (0.202) Data 0.174 (0.174) Loss 0.1955 (0.1955) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:28:47,161 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:47,161 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:48,753 - INFO - Epoch: [135][100/391] Time 0.027 (0.020) Data 0.000 (0.004) Loss 0.2301 (0.1760) Acc@1 91.406 (94.059) Acc@5 100.000 (99.907)
2025-08-28 05:28:50,071 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:50,071 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:50,581 - INFO - Epoch: [135][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.2126 (0.1773) Acc@1 92.969 (94.007) Acc@5 100.000 (99.907)
2025-08-28 05:28:52,456 - INFO - Epoch: [135][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2174 (0.1836) Acc@1 92.188 (93.750) Acc@5 100.000 (99.904)
2025-08-28 05:28:53,081 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:53,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:54,235 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3336 (0.3336) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:28:55,068 - INFO - Epoch 135:
2025-08-28 05:28:55,068 - INFO -   Train: acc1: 93.6280 | acc5: 99.9060 | loss: 0.1856 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:28:55,068 - INFO -   Val:   acc1: 88.2000 | acc5: 99.7000 | loss: 0.3756
2025-08-28 05:28:55,069 - INFO -   LR: 0.010000
2025-08-28 05:28:55,086 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-28 05:28:55,265 - INFO - Epoch: [136][0/391] Time 0.178 (0.178) Data 0.158 (0.158) Loss 0.1416 (0.1416) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:28:57,094 - INFO - Epoch: [136][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.1599 (0.1897) Acc@1 92.188 (93.255) Acc@5 100.000 (99.876)
2025-08-28 05:28:57,152 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:28:57,160 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:28:58,937 - INFO - Epoch: [136][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2219 (0.1894) Acc@1 92.188 (93.369) Acc@5 100.000 (99.891)
2025-08-28 05:29:00,157 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:00,157 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:00,788 - INFO - Epoch: [136][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.3064 (0.1898) Acc@1 89.062 (93.389) Acc@5 99.219 (99.894)
2025-08-28 05:29:02,589 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2345 (0.2345) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:29:03,447 - INFO - Epoch 136:
2025-08-28 05:29:03,447 - INFO -   Train: acc1: 93.3680 | acc5: 99.8880 | loss: 0.1905 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:03,447 - INFO -   Val:   acc1: 88.1900 | acc5: 99.6200 | loss: 0.3713
2025-08-28 05:29:03,447 - INFO -   LR: 0.010000
2025-08-28 05:29:03,465 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-28 05:29:03,654 - INFO - Epoch: [137][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.1538 (0.1538) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:29:04,213 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:04,213 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:05,523 - INFO - Epoch: [137][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.0995 (0.1699) Acc@1 97.656 (94.191) Acc@5 100.000 (99.915)
2025-08-28 05:29:07,134 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:07,134 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:07,293 - INFO - Epoch: [137][200/391] Time 0.026 (0.019) Data 0.005 (0.003) Loss 0.1618 (0.1796) Acc@1 94.531 (93.836) Acc@5 100.000 (99.895)
2025-08-28 05:29:09,110 - INFO - Epoch: [137][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2892 (0.1838) Acc@1 91.406 (93.589) Acc@5 99.219 (99.891)
2025-08-28 05:29:10,100 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:10,100 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:10,900 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2870 (0.2870) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:29:11,762 - INFO - Epoch 137:
2025-08-28 05:29:11,762 - INFO -   Train: acc1: 93.4440 | acc5: 99.8860 | loss: 0.1877 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:11,763 - INFO -   Val:   acc1: 88.8500 | acc5: 99.6100 | loss: 0.3488
2025-08-28 05:29:11,763 - INFO -   LR: 0.010000
2025-08-28 05:29:11,780 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-28 05:29:11,968 - INFO - Epoch: [138][0/391] Time 0.179 (0.179) Data 0.158 (0.158) Loss 0.1383 (0.1383) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:29:13,795 - INFO - Epoch: [138][100/391] Time 0.031 (0.020) Data 0.000 (0.003) Loss 0.1411 (0.1751) Acc@1 93.750 (93.943) Acc@5 99.219 (99.923)
2025-08-28 05:29:14,187 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:14,187 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:15,719 - INFO - Epoch: [138][200/391] Time 0.036 (0.020) Data 0.012 (0.002) Loss 0.1362 (0.1788) Acc@1 92.969 (93.793) Acc@5 100.000 (99.911)
2025-08-28 05:29:17,211 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:17,212 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:17,550 - INFO - Epoch: [138][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.1612 (0.1855) Acc@1 95.312 (93.610) Acc@5 100.000 (99.899)
2025-08-28 05:29:19,388 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3352 (0.3352) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:29:20,258 - INFO - Epoch 138:
2025-08-28 05:29:20,258 - INFO -   Train: acc1: 93.4900 | acc5: 99.9020 | loss: 0.1864 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:20,258 - INFO -   Val:   acc1: 87.5800 | acc5: 99.5400 | loss: 0.4104
2025-08-28 05:29:20,258 - INFO -   LR: 0.010000
2025-08-28 05:29:20,273 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-28 05:29:20,478 - INFO - Epoch: [139][0/391] Time 0.204 (0.204) Data 0.185 (0.185) Loss 0.2732 (0.2732) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:29:21,363 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:21,363 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:22,336 - INFO - Epoch: [139][100/391] Time 0.019 (0.020) Data 0.001 (0.004) Loss 0.1408 (0.1792) Acc@1 93.750 (94.013) Acc@5 100.000 (99.915)
2025-08-28 05:29:24,164 - INFO - Epoch: [139][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1635 (0.1850) Acc@1 94.531 (93.676) Acc@5 100.000 (99.907)
2025-08-28 05:29:24,397 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:24,397 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:26,107 - INFO - Epoch: [139][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2519 (0.1877) Acc@1 90.625 (93.592) Acc@5 100.000 (99.896)
2025-08-28 05:29:27,445 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:27,445 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:27,932 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3034 (0.3034) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:29:28,785 - INFO - Epoch 139:
2025-08-28 05:29:28,786 - INFO -   Train: acc1: 93.4900 | acc5: 99.8860 | loss: 0.1908 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:28,786 - INFO -   Val:   acc1: 88.8400 | acc5: 99.6800 | loss: 0.3572
2025-08-28 05:29:28,786 - INFO -   LR: 0.010000
2025-08-28 05:29:28,801 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-28 05:29:29,007 - INFO - Epoch: [140][0/391] Time 0.206 (0.206) Data 0.162 (0.162) Loss 0.1685 (0.1685) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:29:30,824 - INFO - Epoch: [140][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.2254 (0.1743) Acc@1 90.625 (93.967) Acc@5 99.219 (99.899)
2025-08-28 05:29:31,561 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:31,561 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:32,653 - INFO - Epoch: [140][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2973 (0.1869) Acc@1 89.844 (93.493) Acc@5 100.000 (99.907)
2025-08-28 05:29:34,475 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:34,475 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:34,487 - INFO - Epoch: [140][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1767 (0.1870) Acc@1 92.188 (93.506) Acc@5 100.000 (99.907)
2025-08-28 05:29:36,262 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3817 (0.3817) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:29:37,112 - INFO - Epoch 140:
2025-08-28 05:29:37,112 - INFO -   Train: acc1: 93.4520 | acc5: 99.8960 | loss: 0.1881 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:37,112 - INFO -   Val:   acc1: 88.0200 | acc5: 99.6900 | loss: 0.3829
2025-08-28 05:29:37,112 - INFO -   LR: 0.010000
2025-08-28 05:29:37,163 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-28 05:29:37,355 - INFO - Epoch: [141][0/391] Time 0.190 (0.190) Data 0.173 (0.173) Loss 0.2340 (0.2340) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:29:38,618 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:38,618 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:39,241 - INFO - Epoch: [141][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.1406 (0.1828) Acc@1 94.531 (93.789) Acc@5 100.000 (99.899)
2025-08-28 05:29:41,077 - INFO - Epoch: [141][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.1448 (0.1831) Acc@1 93.750 (93.703) Acc@5 100.000 (99.895)
2025-08-28 05:29:41,558 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:41,558 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:42,877 - INFO - Epoch: [141][300/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.1606 (0.1867) Acc@1 92.969 (93.553) Acc@5 100.000 (99.888)
2025-08-28 05:29:44,637 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:44,637 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:44,830 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3745 (0.3745) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:29:45,700 - INFO - Epoch 141:
2025-08-28 05:29:45,701 - INFO -   Train: acc1: 93.4640 | acc5: 99.8920 | loss: 0.1892 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:45,701 - INFO -   Val:   acc1: 88.8000 | acc5: 99.7100 | loss: 0.3447
2025-08-28 05:29:45,701 - INFO -   LR: 0.010000
2025-08-28 05:29:45,717 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-28 05:29:45,899 - INFO - Epoch: [142][0/391] Time 0.181 (0.181) Data 0.159 (0.159) Loss 0.1498 (0.1498) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:29:47,733 - INFO - Epoch: [142][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.1183 (0.1849) Acc@1 96.875 (93.634) Acc@5 100.000 (99.923)
2025-08-28 05:29:48,895 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:48,896 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:49,627 - INFO - Epoch: [142][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1530 (0.1889) Acc@1 96.094 (93.431) Acc@5 100.000 (99.903)
2025-08-28 05:29:51,488 - INFO - Epoch: [142][300/391] Time 0.023 (0.019) Data 0.007 (0.003) Loss 0.2432 (0.1893) Acc@1 92.188 (93.514) Acc@5 100.000 (99.899)
2025-08-28 05:29:51,851 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:51,852 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:53,294 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3057 (0.3057) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 05:29:54,148 - INFO - Epoch 142:
2025-08-28 05:29:54,148 - INFO -   Train: acc1: 93.4760 | acc5: 99.8820 | loss: 0.1908 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:29:54,148 - INFO -   Val:   acc1: 89.0600 | acc5: 99.7200 | loss: 0.3349
2025-08-28 05:29:54,148 - INFO -   LR: 0.010000
2025-08-28 05:29:54,164 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-28 05:29:54,360 - INFO - Epoch: [143][0/391] Time 0.195 (0.195) Data 0.170 (0.170) Loss 0.1901 (0.1901) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:29:56,052 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:56,052 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:29:56,305 - INFO - Epoch: [143][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.1570 (0.1697) Acc@1 95.312 (94.214) Acc@5 100.000 (99.915)
2025-08-28 05:29:58,140 - INFO - Epoch: [143][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1014 (0.1782) Acc@1 96.875 (93.952) Acc@5 100.000 (99.880)
2025-08-28 05:29:59,009 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:29:59,301 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:00,259 - INFO - Epoch: [143][300/391] Time 0.045 (0.020) Data 0.030 (0.003) Loss 0.2238 (0.1855) Acc@1 93.750 (93.675) Acc@5 99.219 (99.865)
2025-08-28 05:30:02,034 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.3547 (0.3547) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:30:02,867 - INFO - Epoch 143:
2025-08-28 05:30:02,867 - INFO -   Train: acc1: 93.5960 | acc5: 99.8580 | loss: 0.1871 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:02,867 - INFO -   Val:   acc1: 88.3800 | acc5: 99.5500 | loss: 0.3778
2025-08-28 05:30:02,867 - INFO -   LR: 0.010000
2025-08-28 05:30:02,885 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-28 05:30:03,063 - INFO - Epoch: [144][0/391] Time 0.177 (0.177) Data 0.141 (0.141) Loss 0.2336 (0.2336) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:30:03,387 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:03,387 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:04,942 - INFO - Epoch: [144][100/391] Time 0.022 (0.020) Data 0.009 (0.003) Loss 0.1666 (0.1852) Acc@1 95.312 (93.479) Acc@5 100.000 (99.838)
2025-08-28 05:30:06,350 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:06,350 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:06,780 - INFO - Epoch: [144][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.2404 (0.1929) Acc@1 90.625 (93.252) Acc@5 100.000 (99.860)
2025-08-28 05:30:08,577 - INFO - Epoch: [144][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1803 (0.1937) Acc@1 92.969 (93.226) Acc@5 100.000 (99.875)
2025-08-28 05:30:09,209 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:09,209 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:10,396 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.3055 (0.3055) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:30:11,222 - INFO - Epoch 144:
2025-08-28 05:30:11,222 - INFO -   Train: acc1: 93.1780 | acc5: 99.8760 | loss: 0.1956 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:11,222 - INFO -   Val:   acc1: 88.7700 | acc5: 99.7100 | loss: 0.3393
2025-08-28 05:30:11,222 - INFO -   LR: 0.010000
2025-08-28 05:30:11,239 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-28 05:30:11,446 - INFO - Epoch: [145][0/391] Time 0.206 (0.206) Data 0.175 (0.175) Loss 0.1619 (0.1619) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:30:13,262 - INFO - Epoch: [145][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.1845 (0.1770) Acc@1 91.406 (93.905) Acc@5 100.000 (99.892)
2025-08-28 05:30:13,355 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:13,355 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:15,073 - INFO - Epoch: [145][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.1539 (0.1830) Acc@1 96.094 (93.622) Acc@5 100.000 (99.907)
2025-08-28 05:30:16,266 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:16,266 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:16,918 - INFO - Epoch: [145][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2868 (0.1880) Acc@1 89.844 (93.431) Acc@5 100.000 (99.901)
2025-08-28 05:30:18,771 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2794 (0.2794) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:30:19,666 - INFO - Epoch 145:
2025-08-28 05:30:19,666 - INFO -   Train: acc1: 93.2680 | acc5: 99.8960 | loss: 0.1919 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:19,666 - INFO -   Val:   acc1: 89.1500 | acc5: 99.5900 | loss: 0.3410
2025-08-28 05:30:19,666 - INFO -   LR: 0.010000
2025-08-28 05:30:19,682 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-28 05:30:19,889 - INFO - Epoch: [146][0/391] Time 0.207 (0.207) Data 0.169 (0.169) Loss 0.2740 (0.2740) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:30:20,528 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:20,529 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:21,849 - INFO - Epoch: [146][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.1657 (0.1847) Acc@1 90.625 (93.394) Acc@5 100.000 (99.915)
2025-08-28 05:30:23,561 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:23,562 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:23,670 - INFO - Epoch: [146][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1872 (0.1866) Acc@1 93.750 (93.385) Acc@5 100.000 (99.914)
2025-08-28 05:30:25,492 - INFO - Epoch: [146][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1247 (0.1869) Acc@1 95.312 (93.387) Acc@5 100.000 (99.912)
2025-08-28 05:30:26,469 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:26,469 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:27,254 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.3059 (0.3059) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:30:28,103 - INFO - Epoch 146:
2025-08-28 05:30:28,103 - INFO -   Train: acc1: 93.3080 | acc5: 99.9220 | loss: 0.1883 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:28,103 - INFO -   Val:   acc1: 88.4600 | acc5: 99.6500 | loss: 0.3522
2025-08-28 05:30:28,103 - INFO -   LR: 0.010000
2025-08-28 05:30:28,118 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-28 05:30:28,311 - INFO - Epoch: [147][0/391] Time 0.192 (0.192) Data 0.171 (0.171) Loss 0.1941 (0.1941) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 05:30:30,147 - INFO - Epoch: [147][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.2073 (0.1826) Acc@1 92.969 (93.704) Acc@5 100.000 (99.861)
2025-08-28 05:30:30,609 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:30,609 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:31,993 - INFO - Epoch: [147][200/391] Time 0.017 (0.019) Data 0.006 (0.003) Loss 0.2825 (0.1883) Acc@1 87.500 (93.455) Acc@5 100.000 (99.872)
2025-08-28 05:30:33,534 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:33,534 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:33,831 - INFO - Epoch: [147][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2128 (0.1902) Acc@1 92.969 (93.454) Acc@5 100.000 (99.878)
2025-08-28 05:30:35,614 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2743 (0.2743) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:30:36,486 - INFO - Epoch 147:
2025-08-28 05:30:36,486 - INFO -   Train: acc1: 93.4240 | acc5: 99.8780 | loss: 0.1905 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:36,486 - INFO -   Val:   acc1: 88.1900 | acc5: 99.5800 | loss: 0.3721
2025-08-28 05:30:36,486 - INFO -   LR: 0.010000
2025-08-28 05:30:36,506 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-28 05:30:36,685 - INFO - Epoch: [148][0/391] Time 0.178 (0.178) Data 0.146 (0.146) Loss 0.2670 (0.2670) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:30:37,686 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:37,686 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:38,559 - INFO - Epoch: [148][100/391] Time 0.031 (0.020) Data 0.000 (0.003) Loss 0.1882 (0.1834) Acc@1 92.969 (93.502) Acc@5 100.000 (99.946)
2025-08-28 05:30:40,454 - INFO - Epoch: [148][200/391] Time 0.024 (0.020) Data 0.010 (0.003) Loss 0.2232 (0.1860) Acc@1 92.188 (93.427) Acc@5 100.000 (99.903)
2025-08-28 05:30:40,689 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:40,689 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:42,291 - INFO - Epoch: [148][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1931 (0.1907) Acc@1 94.531 (93.311) Acc@5 100.000 (99.896)
2025-08-28 05:30:43,563 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:43,563 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:44,078 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3180 (0.3180) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:30:44,927 - INFO - Epoch 148:
2025-08-28 05:30:44,927 - INFO -   Train: acc1: 93.2700 | acc5: 99.8900 | loss: 0.1920 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:44,927 - INFO -   Val:   acc1: 88.9300 | acc5: 99.7000 | loss: 0.3419
2025-08-28 05:30:44,927 - INFO -   LR: 0.010000
2025-08-28 05:30:44,946 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-28 05:30:45,124 - INFO - Epoch: [149][0/391] Time 0.177 (0.177) Data 0.159 (0.159) Loss 0.2590 (0.2590) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:30:46,937 - INFO - Epoch: [149][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2910 (0.1835) Acc@1 90.625 (93.425) Acc@5 100.000 (99.946)
2025-08-28 05:30:47,667 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:47,668 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:48,758 - INFO - Epoch: [149][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1974 (0.1895) Acc@1 92.188 (93.287) Acc@5 99.219 (99.903)
2025-08-28 05:30:50,577 - INFO - Epoch: [149][300/391] Time 0.042 (0.019) Data 0.021 (0.003) Loss 0.1976 (0.1895) Acc@1 94.531 (93.275) Acc@5 99.219 (99.904)
2025-08-28 05:30:50,586 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:50,586 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:52,394 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.3661 (0.3661) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:30:53,258 - INFO - Epoch 149:
2025-08-28 05:30:53,258 - INFO -   Train: acc1: 93.2020 | acc5: 99.9080 | loss: 0.1909 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:30:53,258 - INFO -   Val:   acc1: 88.8900 | acc5: 99.6600 | loss: 0.3454
2025-08-28 05:30:53,258 - INFO -   LR: 0.001000
2025-08-28 05:30:53,277 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-28 05:30:53,461 - INFO - Epoch: [150][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.2028 (0.2028) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 05:30:54,747 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:54,747 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:55,302 - INFO - Epoch: [150][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.1715 (0.1634) Acc@1 94.531 (94.245) Acc@5 100.000 (99.899)
2025-08-28 05:30:57,111 - INFO - Epoch: [150][200/391] Time 0.019 (0.019) Data 0.002 (0.003) Loss 0.1130 (0.1544) Acc@1 95.312 (94.667) Acc@5 100.000 (99.907)
2025-08-28 05:30:57,661 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:30:57,661 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:30:58,928 - INFO - Epoch: [150][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1641 (0.1514) Acc@1 92.188 (94.819) Acc@5 100.000 (99.914)
2025-08-28 05:31:00,499 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:00,500 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:00,692 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2931 (0.2931) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:31:01,554 - INFO - Epoch 150:
2025-08-28 05:31:01,555 - INFO -   Train: acc1: 94.9060 | acc5: 99.9220 | loss: 0.1484 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:01,555 - INFO -   Val:   acc1: 90.6900 | acc5: 99.7400 | loss: 0.2839
2025-08-28 05:31:01,555 - INFO -   LR: 0.001000
2025-08-28 05:31:01,607 - INFO - Checkpoint saved: epoch=150, metric=90.6900
2025-08-28 05:31:01,638 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-28 05:31:01,829 - INFO - Epoch: [151][0/391] Time 0.190 (0.190) Data 0.168 (0.168) Loss 0.1268 (0.1268) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:31:03,754 - INFO - Epoch: [151][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.1372 (0.1277) Acc@1 95.312 (95.692) Acc@5 100.000 (99.969)
2025-08-28 05:31:04,802 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:04,802 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:05,642 - INFO - Epoch: [151][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1993 (0.1318) Acc@1 92.969 (95.658) Acc@5 99.219 (99.942)
2025-08-28 05:31:07,427 - INFO - Epoch: [151][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0775 (0.1301) Acc@1 97.656 (95.764) Acc@5 100.000 (99.933)
2025-08-28 05:31:07,763 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:07,763 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:09,234 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2898 (0.2898) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:31:10,077 - INFO - Epoch 151:
2025-08-28 05:31:10,077 - INFO -   Train: acc1: 95.7400 | acc5: 99.9380 | loss: 0.1304 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:10,077 - INFO -   Val:   acc1: 90.8900 | acc5: 99.7700 | loss: 0.2819
2025-08-28 05:31:10,077 - INFO -   LR: 0.001000
2025-08-28 05:31:10,128 - INFO - Checkpoint saved: epoch=151, metric=90.8900
2025-08-28 05:31:10,160 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-28 05:31:10,359 - INFO - Epoch: [152][0/391] Time 0.197 (0.197) Data 0.176 (0.176) Loss 0.1928 (0.1928) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:31:11,943 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:11,943 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:12,196 - INFO - Epoch: [152][100/391] Time 0.025 (0.020) Data 0.013 (0.005) Loss 0.1280 (0.1316) Acc@1 96.875 (95.676) Acc@5 100.000 (99.923)
2025-08-28 05:31:14,045 - INFO - Epoch: [152][200/391] Time 0.027 (0.019) Data 0.000 (0.004) Loss 0.1380 (0.1278) Acc@1 96.875 (95.911) Acc@5 100.000 (99.949)
2025-08-28 05:31:14,948 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:14,948 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:15,896 - INFO - Epoch: [152][300/391] Time 0.019 (0.019) Data 0.007 (0.004) Loss 0.0815 (0.1271) Acc@1 97.656 (95.894) Acc@5 100.000 (99.956)
2025-08-28 05:31:17,757 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2815 (0.2815) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:31:18,608 - INFO - Epoch 152:
2025-08-28 05:31:18,608 - INFO -   Train: acc1: 95.8500 | acc5: 99.9520 | loss: 0.1279 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:18,608 - INFO -   Val:   acc1: 91.0500 | acc5: 99.8000 | loss: 0.2792
2025-08-28 05:31:18,608 - INFO -   LR: 0.001000
2025-08-28 05:31:18,662 - INFO - Checkpoint saved: epoch=152, metric=91.0500
2025-08-28 05:31:18,694 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-28 05:31:18,882 - INFO - Epoch: [153][0/391] Time 0.187 (0.187) Data 0.159 (0.159) Loss 0.1221 (0.1221) Acc@1 96.875 (96.875) Acc@5 99.219 (99.219)
2025-08-28 05:31:19,211 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:19,211 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:20,775 - INFO - Epoch: [153][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.1256 (0.1201) Acc@1 96.094 (95.962) Acc@5 100.000 (99.954)
2025-08-28 05:31:22,191 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:22,191 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:22,648 - INFO - Epoch: [153][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.0814 (0.1225) Acc@1 99.219 (95.903) Acc@5 100.000 (99.949)
2025-08-28 05:31:24,546 - INFO - Epoch: [153][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0498 (0.1226) Acc@1 99.219 (95.917) Acc@5 100.000 (99.956)
2025-08-28 05:31:25,165 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:25,166 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:26,296 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2839 (0.2839) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:31:27,141 - INFO - Epoch 153:
2025-08-28 05:31:27,141 - INFO -   Train: acc1: 95.9280 | acc5: 99.9520 | loss: 0.1225 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:27,141 - INFO -   Val:   acc1: 91.0300 | acc5: 99.7500 | loss: 0.2770
2025-08-28 05:31:27,141 - INFO -   LR: 0.001000
2025-08-28 05:31:27,158 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-28 05:31:27,362 - INFO - Epoch: [154][0/391] Time 0.200 (0.200) Data 0.162 (0.162) Loss 0.1710 (0.1710) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:31:29,212 - INFO - Epoch: [154][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.1524 (0.1170) Acc@1 92.969 (96.117) Acc@5 100.000 (99.969)
2025-08-28 05:31:29,329 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:29,329 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:31,075 - INFO - Epoch: [154][200/391] Time 0.029 (0.019) Data 0.014 (0.004) Loss 0.1399 (0.1202) Acc@1 96.094 (95.981) Acc@5 100.000 (99.965)
2025-08-28 05:31:32,317 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:32,317 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:32,924 - INFO - Epoch: [154][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1358 (0.1176) Acc@1 96.094 (96.122) Acc@5 100.000 (99.969)
2025-08-28 05:31:34,700 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2861 (0.2861) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:31:35,532 - INFO - Epoch 154:
2025-08-28 05:31:35,532 - INFO -   Train: acc1: 96.1160 | acc5: 99.9520 | loss: 0.1184 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:35,532 - INFO -   Val:   acc1: 91.0800 | acc5: 99.7800 | loss: 0.2772
2025-08-28 05:31:35,532 - INFO -   LR: 0.001000
2025-08-28 05:31:35,585 - INFO - Checkpoint saved: epoch=154, metric=91.0800
2025-08-28 05:31:35,616 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-28 05:31:35,801 - INFO - Epoch: [155][0/391] Time 0.184 (0.184) Data 0.168 (0.168) Loss 0.0974 (0.0974) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:31:36,407 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:36,407 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:37,637 - INFO - Epoch: [155][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.0975 (0.1160) Acc@1 96.875 (96.218) Acc@5 100.000 (99.961)
2025-08-28 05:31:39,394 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:39,394 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:39,508 - INFO - Epoch: [155][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.1643 (0.1145) Acc@1 96.094 (96.346) Acc@5 99.219 (99.961)
2025-08-28 05:31:41,372 - INFO - Epoch: [155][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1401 (0.1143) Acc@1 96.094 (96.330) Acc@5 100.000 (99.953)
2025-08-28 05:31:42,347 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:42,347 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:43,139 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.2845 (0.2845) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:31:44,014 - INFO - Epoch 155:
2025-08-28 05:31:44,015 - INFO -   Train: acc1: 96.2140 | acc5: 99.9520 | loss: 0.1160 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:44,015 - INFO -   Val:   acc1: 91.0900 | acc5: 99.8000 | loss: 0.2760
2025-08-28 05:31:44,015 - INFO -   LR: 0.001000
2025-08-28 05:31:44,068 - INFO - Checkpoint saved: epoch=155, metric=91.0900
2025-08-28 05:31:44,101 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-28 05:31:44,291 - INFO - Epoch: [156][0/391] Time 0.189 (0.189) Data 0.170 (0.170) Loss 0.1150 (0.1150) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:31:46,095 - INFO - Epoch: [156][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.0924 (0.1178) Acc@1 97.656 (96.016) Acc@5 100.000 (99.977)
2025-08-28 05:31:46,522 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:46,522 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:47,920 - INFO - Epoch: [156][200/391] Time 0.021 (0.019) Data 0.007 (0.003) Loss 0.1151 (0.1128) Acc@1 94.531 (96.304) Acc@5 100.000 (99.977)
2025-08-28 05:31:49,438 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:49,439 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:49,746 - INFO - Epoch: [156][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.0967 (0.1141) Acc@1 96.875 (96.216) Acc@5 100.000 (99.977)
2025-08-28 05:31:51,551 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2731 (0.2731) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:31:52,399 - INFO - Epoch 156:
2025-08-28 05:31:52,399 - INFO -   Train: acc1: 96.2540 | acc5: 99.9660 | loss: 0.1141 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:31:52,399 - INFO -   Val:   acc1: 91.0900 | acc5: 99.7600 | loss: 0.2770
2025-08-28 05:31:52,399 - INFO -   LR: 0.001000
2025-08-28 05:31:52,419 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-28 05:31:52,602 - INFO - Epoch: [157][0/391] Time 0.183 (0.183) Data 0.138 (0.138) Loss 0.1721 (0.1721) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:31:53,588 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:53,588 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:54,477 - INFO - Epoch: [157][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.0918 (0.1116) Acc@1 96.875 (96.450) Acc@5 100.000 (99.938)
2025-08-28 05:31:56,343 - INFO - Epoch: [157][200/391] Time 0.035 (0.020) Data 0.004 (0.003) Loss 0.0687 (0.1153) Acc@1 97.656 (96.315) Acc@5 100.000 (99.946)
2025-08-28 05:31:56,587 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:56,587 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:31:58,248 - INFO - Epoch: [157][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.1710 (0.1149) Acc@1 92.188 (96.260) Acc@5 100.000 (99.951)
2025-08-28 05:31:59,611 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:31:59,611 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:00,061 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2819 (0.2819) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:32:00,922 - INFO - Epoch 157:
2025-08-28 05:32:00,922 - INFO -   Train: acc1: 96.2980 | acc5: 99.9520 | loss: 0.1140 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:00,922 - INFO -   Val:   acc1: 91.0800 | acc5: 99.7800 | loss: 0.2791
2025-08-28 05:32:00,922 - INFO -   LR: 0.001000
2025-08-28 05:32:00,939 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-28 05:32:01,142 - INFO - Epoch: [158][0/391] Time 0.201 (0.201) Data 0.172 (0.172) Loss 0.1207 (0.1207) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:32:02,982 - INFO - Epoch: [158][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.1208 (0.1149) Acc@1 96.875 (96.334) Acc@5 100.000 (99.961)
2025-08-28 05:32:03,725 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:03,725 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:04,788 - INFO - Epoch: [158][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1238 (0.1160) Acc@1 94.531 (96.249) Acc@5 100.000 (99.965)
2025-08-28 05:32:06,676 - INFO - Epoch: [158][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.0780 (0.1114) Acc@1 96.875 (96.426) Acc@5 100.000 (99.958)
2025-08-28 05:32:06,700 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:06,700 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:08,559 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2541 (0.2541) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:32:09,422 - INFO - Epoch 158:
2025-08-28 05:32:09,422 - INFO -   Train: acc1: 96.4140 | acc5: 99.9620 | loss: 0.1115 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:09,422 - INFO -   Val:   acc1: 91.0100 | acc5: 99.7600 | loss: 0.2829
2025-08-28 05:32:09,422 - INFO -   LR: 0.001000
2025-08-28 05:32:09,438 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-28 05:32:09,625 - INFO - Epoch: [159][0/391] Time 0.186 (0.186) Data 0.167 (0.167) Loss 0.1231 (0.1231) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-28 05:32:10,914 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:10,914 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:11,477 - INFO - Epoch: [159][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.1508 (0.1106) Acc@1 95.312 (96.496) Acc@5 99.219 (99.930)
2025-08-28 05:32:13,247 - INFO - Epoch: [159][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0871 (0.1109) Acc@1 96.094 (96.545) Acc@5 100.000 (99.953)
2025-08-28 05:32:13,860 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:13,860 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:15,227 - INFO - Epoch: [159][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1912 (0.1120) Acc@1 94.531 (96.509) Acc@5 100.000 (99.961)
2025-08-28 05:32:17,072 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2700 (0.2700) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:32:17,881 - INFO - Epoch 159:
2025-08-28 05:32:17,881 - INFO -   Train: acc1: 96.4720 | acc5: 99.9620 | loss: 0.1121 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:17,881 - INFO -   Val:   acc1: 91.0600 | acc5: 99.7600 | loss: 0.2779
2025-08-28 05:32:17,882 - INFO -   LR: 0.001000
2025-08-28 05:32:18,012 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-28 05:32:18,178 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:18,179 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:18,199 - INFO - Epoch: [160][0/391] Time 0.186 (0.186) Data 0.151 (0.151) Loss 0.0679 (0.0679) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:32:20,020 - INFO - Epoch: [160][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.0764 (0.1042) Acc@1 97.656 (96.658) Acc@5 100.000 (99.946)
2025-08-28 05:32:21,128 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:21,128 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:21,872 - INFO - Epoch: [160][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1098 (0.1087) Acc@1 95.312 (96.525) Acc@5 100.000 (99.957)
2025-08-28 05:32:23,756 - INFO - Epoch: [160][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.1070 (0.1096) Acc@1 98.438 (96.488) Acc@5 99.219 (99.956)
2025-08-28 05:32:24,151 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:24,151 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:25,570 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2644 (0.2644) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:32:26,433 - INFO - Epoch 160:
2025-08-28 05:32:26,433 - INFO -   Train: acc1: 96.4580 | acc5: 99.9520 | loss: 0.1102 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:26,433 - INFO -   Val:   acc1: 91.0500 | acc5: 99.8000 | loss: 0.2785
2025-08-28 05:32:26,433 - INFO -   LR: 0.001000
2025-08-28 05:32:26,487 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-28 05:32:26,670 - INFO - Epoch: [161][0/391] Time 0.182 (0.182) Data 0.157 (0.157) Loss 0.1693 (0.1693) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:32:28,298 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:28,299 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:28,517 - INFO - Epoch: [161][100/391] Time 0.019 (0.020) Data 0.000 (0.005) Loss 0.0861 (0.1077) Acc@1 98.438 (96.519) Acc@5 100.000 (99.977)
2025-08-28 05:32:30,354 - INFO - Epoch: [161][200/391] Time 0.034 (0.019) Data 0.022 (0.004) Loss 0.0682 (0.1091) Acc@1 97.656 (96.541) Acc@5 100.000 (99.949)
2025-08-28 05:32:31,238 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:31,238 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:32,173 - INFO - Epoch: [161][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.0909 (0.1096) Acc@1 97.656 (96.530) Acc@5 100.000 (99.958)
2025-08-28 05:32:34,000 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2553 (0.2553) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:32:34,875 - INFO - Epoch 161:
2025-08-28 05:32:34,876 - INFO -   Train: acc1: 96.6080 | acc5: 99.9580 | loss: 0.1083 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:34,876 - INFO -   Val:   acc1: 90.9700 | acc5: 99.7800 | loss: 0.2815
2025-08-28 05:32:34,876 - INFO -   LR: 0.001000
2025-08-28 05:32:34,895 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-28 05:32:35,076 - INFO - Epoch: [162][0/391] Time 0.181 (0.181) Data 0.164 (0.164) Loss 0.0936 (0.0936) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:32:35,434 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:35,435 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:37,001 - INFO - Epoch: [162][100/391] Time 0.029 (0.021) Data 0.000 (0.006) Loss 0.1201 (0.1027) Acc@1 96.094 (96.813) Acc@5 100.000 (99.992)
2025-08-28 05:32:38,470 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:38,470 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:38,868 - INFO - Epoch: [162][200/391] Time 0.025 (0.020) Data 0.013 (0.005) Loss 0.1254 (0.1034) Acc@1 93.750 (96.661) Acc@5 100.000 (99.981)
2025-08-28 05:32:40,853 - INFO - Epoch: [162][300/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.1195 (0.1070) Acc@1 96.094 (96.551) Acc@5 100.000 (99.961)
2025-08-28 05:32:41,616 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:41,617 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:42,818 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2511 (0.2511) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:32:43,687 - INFO - Epoch 162:
2025-08-28 05:32:43,687 - INFO -   Train: acc1: 96.5440 | acc5: 99.9620 | loss: 0.1073 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:43,687 - INFO -   Val:   acc1: 90.9100 | acc5: 99.7800 | loss: 0.2848
2025-08-28 05:32:43,687 - INFO -   LR: 0.001000
2025-08-28 05:32:43,706 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-28 05:32:43,869 - INFO - Epoch: [163][0/391] Time 0.162 (0.162) Data 0.142 (0.142) Loss 0.0980 (0.0980) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:32:45,705 - INFO - Epoch: [163][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1207 (0.0996) Acc@1 96.094 (96.798) Acc@5 100.000 (99.946)
2025-08-28 05:32:45,857 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:45,857 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:47,620 - INFO - Epoch: [163][200/391] Time 0.029 (0.019) Data 0.005 (0.002) Loss 0.1373 (0.1037) Acc@1 95.312 (96.650) Acc@5 100.000 (99.957)
2025-08-28 05:32:48,816 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:48,817 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:49,399 - INFO - Epoch: [163][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.0730 (0.1058) Acc@1 98.438 (96.499) Acc@5 100.000 (99.953)
2025-08-28 05:32:51,313 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2455 (0.2455) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:32:52,182 - INFO - Epoch 163:
2025-08-28 05:32:52,182 - INFO -   Train: acc1: 96.5180 | acc5: 99.9600 | loss: 0.1056 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:32:52,182 - INFO -   Val:   acc1: 90.9300 | acc5: 99.7600 | loss: 0.2802
2025-08-28 05:32:52,182 - INFO -   LR: 0.001000
2025-08-28 05:32:52,203 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-28 05:32:52,384 - INFO - Epoch: [164][0/391] Time 0.180 (0.180) Data 0.159 (0.159) Loss 0.1325 (0.1325) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:32:53,073 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:53,073 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:54,270 - INFO - Epoch: [164][100/391] Time 0.018 (0.020) Data 0.000 (0.005) Loss 0.1687 (0.1054) Acc@1 93.750 (96.597) Acc@5 100.000 (99.961)
2025-08-28 05:32:56,003 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:56,003 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:56,072 - INFO - Epoch: [164][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1039 (0.1060) Acc@1 97.656 (96.611) Acc@5 100.000 (99.973)
2025-08-28 05:32:57,852 - INFO - Epoch: [164][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1269 (0.1041) Acc@1 96.875 (96.652) Acc@5 100.000 (99.969)
2025-08-28 05:32:58,913 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:32:58,913 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:32:59,685 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2480 (0.2480) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:33:00,576 - INFO - Epoch 164:
2025-08-28 05:33:00,576 - INFO -   Train: acc1: 96.6180 | acc5: 99.9640 | loss: 0.1048 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:00,576 - INFO -   Val:   acc1: 90.9900 | acc5: 99.7400 | loss: 0.2795
2025-08-28 05:33:00,576 - INFO -   LR: 0.001000
2025-08-28 05:33:00,593 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-28 05:33:00,781 - INFO - Epoch: [165][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.1235 (0.1235) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:33:02,631 - INFO - Epoch: [165][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.0527 (0.1089) Acc@1 98.438 (96.426) Acc@5 100.000 (99.938)
2025-08-28 05:33:03,049 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:03,049 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:04,458 - INFO - Epoch: [165][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.0963 (0.1034) Acc@1 97.656 (96.685) Acc@5 100.000 (99.949)
2025-08-28 05:33:06,034 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:06,035 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:06,291 - INFO - Epoch: [165][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0951 (0.1041) Acc@1 97.656 (96.660) Acc@5 100.000 (99.956)
2025-08-28 05:33:08,117 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2522 (0.2522) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:33:08,956 - INFO - Epoch 165:
2025-08-28 05:33:08,957 - INFO -   Train: acc1: 96.6440 | acc5: 99.9520 | loss: 0.1049 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:08,957 - INFO -   Val:   acc1: 90.8800 | acc5: 99.7500 | loss: 0.2844
2025-08-28 05:33:08,957 - INFO -   LR: 0.001000
2025-08-28 05:33:08,976 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-28 05:33:09,151 - INFO - Epoch: [166][0/391] Time 0.174 (0.174) Data 0.157 (0.157) Loss 0.1231 (0.1231) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:33:10,171 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:10,171 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:11,044 - INFO - Epoch: [166][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0915 (0.1015) Acc@1 97.656 (97.030) Acc@5 100.000 (99.938)
2025-08-28 05:33:12,901 - INFO - Epoch: [166][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1151 (0.1022) Acc@1 96.875 (96.848) Acc@5 100.000 (99.942)
2025-08-28 05:33:13,145 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:13,145 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:14,799 - INFO - Epoch: [166][300/391] Time 0.025 (0.019) Data 0.013 (0.002) Loss 0.0743 (0.1011) Acc@1 97.656 (96.787) Acc@5 100.000 (99.956)
2025-08-28 05:33:16,145 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:16,145 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:16,590 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2435 (0.2435) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:33:17,409 - INFO - Epoch 166:
2025-08-28 05:33:17,409 - INFO -   Train: acc1: 96.7980 | acc5: 99.9500 | loss: 0.1012 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:17,409 - INFO -   Val:   acc1: 90.8000 | acc5: 99.8200 | loss: 0.2868
2025-08-28 05:33:17,409 - INFO -   LR: 0.001000
2025-08-28 05:33:17,427 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-28 05:33:17,609 - INFO - Epoch: [167][0/391] Time 0.182 (0.182) Data 0.155 (0.155) Loss 0.0887 (0.0887) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:33:19,438 - INFO - Epoch: [167][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.0929 (0.1028) Acc@1 96.875 (96.504) Acc@5 100.000 (99.977)
2025-08-28 05:33:20,243 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:20,244 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:21,294 - INFO - Epoch: [167][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0972 (0.1014) Acc@1 96.875 (96.646) Acc@5 100.000 (99.969)
2025-08-28 05:33:23,131 - INFO - Epoch: [167][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.0741 (0.1012) Acc@1 97.656 (96.740) Acc@5 100.000 (99.961)
2025-08-28 05:33:23,197 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:23,197 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:24,959 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2699 (0.2699) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:33:25,827 - INFO - Epoch 167:
2025-08-28 05:33:25,827 - INFO -   Train: acc1: 96.7640 | acc5: 99.9580 | loss: 0.1012 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:25,827 - INFO -   Val:   acc1: 90.8300 | acc5: 99.7500 | loss: 0.2861
2025-08-28 05:33:25,827 - INFO -   LR: 0.001000
2025-08-28 05:33:25,846 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-28 05:33:26,017 - INFO - Epoch: [168][0/391] Time 0.170 (0.170) Data 0.145 (0.145) Loss 0.1671 (0.1671) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:33:27,359 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:27,360 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:27,922 - INFO - Epoch: [168][100/391] Time 0.037 (0.021) Data 0.023 (0.006) Loss 0.1026 (0.0980) Acc@1 95.312 (96.844) Acc@5 99.219 (99.977)
2025-08-28 05:33:29,737 - INFO - Epoch: [168][200/391] Time 0.020 (0.019) Data 0.000 (0.005) Loss 0.1074 (0.1018) Acc@1 96.875 (96.712) Acc@5 99.219 (99.957)
2025-08-28 05:33:30,284 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:30,285 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:31,532 - INFO - Epoch: [168][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.0914 (0.1020) Acc@1 97.656 (96.673) Acc@5 100.000 (99.956)
2025-08-28 05:33:33,228 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.2707 (0.2707) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:33:34,091 - INFO - Epoch 168:
2025-08-28 05:33:34,091 - INFO -   Train: acc1: 96.6460 | acc5: 99.9520 | loss: 0.1026 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:34,091 - INFO -   Val:   acc1: 90.7700 | acc5: 99.7700 | loss: 0.2896
2025-08-28 05:33:34,092 - INFO -   LR: 0.001000
2025-08-28 05:33:34,108 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-28 05:33:34,303 - INFO - Epoch: [169][0/391] Time 0.194 (0.194) Data 0.164 (0.164) Loss 0.1000 (0.1000) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:33:34,313 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:34,313 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:36,094 - INFO - Epoch: [169][100/391] Time 0.026 (0.020) Data 0.000 (0.004) Loss 0.1023 (0.1008) Acc@1 96.094 (96.782) Acc@5 100.000 (99.969)
2025-08-28 05:33:37,262 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:37,262 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:37,957 - INFO - Epoch: [169][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0765 (0.1016) Acc@1 98.438 (96.762) Acc@5 100.000 (99.961)
2025-08-28 05:33:39,794 - INFO - Epoch: [169][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1440 (0.1025) Acc@1 93.750 (96.683) Acc@5 100.000 (99.956)
2025-08-28 05:33:40,176 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:40,176 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:41,578 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2531 (0.2531) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:33:42,461 - INFO - Epoch 169:
2025-08-28 05:33:42,461 - INFO -   Train: acc1: 96.7140 | acc5: 99.9580 | loss: 0.1019 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:42,461 - INFO -   Val:   acc1: 91.0300 | acc5: 99.7700 | loss: 0.2884
2025-08-28 05:33:42,461 - INFO -   LR: 0.001000
2025-08-28 05:33:42,480 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-28 05:33:42,657 - INFO - Epoch: [170][0/391] Time 0.176 (0.176) Data 0.148 (0.148) Loss 0.1540 (0.1540) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:33:44,349 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:44,350 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:44,532 - INFO - Epoch: [170][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1276 (0.1040) Acc@1 94.531 (96.473) Acc@5 100.000 (99.954)
2025-08-28 05:33:46,359 - INFO - Epoch: [170][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.0714 (0.1000) Acc@1 99.219 (96.727) Acc@5 100.000 (99.965)
2025-08-28 05:33:47,239 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:47,239 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:48,260 - INFO - Epoch: [170][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0766 (0.0999) Acc@1 97.656 (96.693) Acc@5 100.000 (99.956)
2025-08-28 05:33:49,996 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2819 (0.2819) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:33:50,868 - INFO - Epoch 170:
2025-08-28 05:33:50,868 - INFO -   Train: acc1: 96.6840 | acc5: 99.9580 | loss: 0.1003 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:50,869 - INFO -   Val:   acc1: 90.7600 | acc5: 99.6800 | loss: 0.2900
2025-08-28 05:33:50,869 - INFO -   LR: 0.001000
2025-08-28 05:33:50,923 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-28 05:33:51,100 - INFO - Epoch: [171][0/391] Time 0.177 (0.177) Data 0.152 (0.152) Loss 0.1178 (0.1178) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:33:51,469 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:51,469 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:53,018 - INFO - Epoch: [171][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.0959 (0.0971) Acc@1 97.656 (96.759) Acc@5 100.000 (99.977)
2025-08-28 05:33:54,475 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:54,476 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:54,865 - INFO - Epoch: [171][200/391] Time 0.025 (0.020) Data 0.015 (0.003) Loss 0.1204 (0.0981) Acc@1 96.875 (96.906) Acc@5 100.000 (99.949)
2025-08-28 05:33:56,768 - INFO - Epoch: [171][300/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.0864 (0.0986) Acc@1 96.875 (96.849) Acc@5 100.000 (99.953)
2025-08-28 05:33:57,438 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:33:57,438 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:33:58,539 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2762 (0.2762) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:33:59,382 - INFO - Epoch 171:
2025-08-28 05:33:59,382 - INFO -   Train: acc1: 96.8420 | acc5: 99.9580 | loss: 0.0987 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:33:59,382 - INFO -   Val:   acc1: 90.7500 | acc5: 99.7300 | loss: 0.2917
2025-08-28 05:33:59,382 - INFO -   LR: 0.001000
2025-08-28 05:33:59,401 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-28 05:33:59,595 - INFO - Epoch: [172][0/391] Time 0.194 (0.194) Data 0.166 (0.166) Loss 0.1346 (0.1346) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:34:01,436 - INFO - Epoch: [172][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.1266 (0.1003) Acc@1 96.094 (96.728) Acc@5 100.000 (99.930)
2025-08-28 05:34:01,578 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:01,578 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:03,356 - INFO - Epoch: [172][200/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.0491 (0.0983) Acc@1 99.219 (96.887) Acc@5 100.000 (99.938)
2025-08-28 05:34:04,573 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:04,573 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:05,173 - INFO - Epoch: [172][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.0451 (0.0999) Acc@1 100.000 (96.756) Acc@5 100.000 (99.948)
2025-08-28 05:34:06,921 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2770 (0.2770) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:34:07,837 - INFO - Epoch 172:
2025-08-28 05:34:07,838 - INFO -   Train: acc1: 96.7580 | acc5: 99.9580 | loss: 0.0991 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:07,838 - INFO -   Val:   acc1: 90.6400 | acc5: 99.7600 | loss: 0.2927
2025-08-28 05:34:07,838 - INFO -   LR: 0.001000
2025-08-28 05:34:07,856 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-28 05:34:08,035 - INFO - Epoch: [173][0/391] Time 0.179 (0.179) Data 0.158 (0.158) Loss 0.0740 (0.0740) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:34:08,737 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:08,737 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:09,863 - INFO - Epoch: [173][100/391] Time 0.011 (0.020) Data 0.001 (0.004) Loss 0.1173 (0.0916) Acc@1 96.094 (97.123) Acc@5 100.000 (99.954)
2025-08-28 05:34:11,768 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:11,768 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:11,831 - INFO - Epoch: [173][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.0667 (0.0968) Acc@1 99.219 (96.875) Acc@5 100.000 (99.946)
2025-08-28 05:34:13,650 - INFO - Epoch: [173][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1027 (0.0985) Acc@1 96.875 (96.810) Acc@5 100.000 (99.953)
2025-08-28 05:34:14,689 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:14,689 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:15,473 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2613 (0.2613) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:34:16,302 - INFO - Epoch 173:
2025-08-28 05:34:16,302 - INFO -   Train: acc1: 96.7340 | acc5: 99.9540 | loss: 0.0991 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:16,303 - INFO -   Val:   acc1: 90.8400 | acc5: 99.7200 | loss: 0.2916
2025-08-28 05:34:16,303 - INFO -   LR: 0.001000
2025-08-28 05:34:16,321 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-28 05:34:16,518 - INFO - Epoch: [174][0/391] Time 0.189 (0.189) Data 0.156 (0.156) Loss 0.1094 (0.1094) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:34:18,387 - INFO - Epoch: [174][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1196 (0.1011) Acc@1 97.656 (96.728) Acc@5 100.000 (99.946)
2025-08-28 05:34:18,828 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:18,828 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:20,216 - INFO - Epoch: [174][200/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.0563 (0.0975) Acc@1 99.219 (96.875) Acc@5 100.000 (99.953)
2025-08-28 05:34:21,776 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:21,776 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:22,013 - INFO - Epoch: [174][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0833 (0.0995) Acc@1 96.094 (96.763) Acc@5 100.000 (99.958)
2025-08-28 05:34:23,789 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2626 (0.2626) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:34:24,627 - INFO - Epoch 174:
2025-08-28 05:34:24,628 - INFO -   Train: acc1: 96.7780 | acc5: 99.9620 | loss: 0.0989 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:24,628 - INFO -   Val:   acc1: 90.7500 | acc5: 99.7100 | loss: 0.2913
2025-08-28 05:34:24,628 - INFO -   LR: 0.001000
2025-08-28 05:34:24,645 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-28 05:34:24,820 - INFO - Epoch: [175][0/391] Time 0.173 (0.173) Data 0.150 (0.150) Loss 0.1136 (0.1136) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:34:25,880 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:25,881 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:26,755 - INFO - Epoch: [175][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.1003 (0.0942) Acc@1 96.875 (97.076) Acc@5 100.000 (99.977)
2025-08-28 05:34:28,606 - INFO - Epoch: [175][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.0555 (0.0934) Acc@1 98.438 (96.995) Acc@5 100.000 (99.969)
2025-08-28 05:34:28,893 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:28,893 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:30,532 - INFO - Epoch: [175][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1475 (0.0954) Acc@1 95.312 (96.935) Acc@5 100.000 (99.974)
2025-08-28 05:34:31,910 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:31,910 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:32,340 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2638 (0.2638) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:34:33,177 - INFO - Epoch 175:
2025-08-28 05:34:33,178 - INFO -   Train: acc1: 96.9500 | acc5: 99.9700 | loss: 0.0957 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:33,178 - INFO -   Val:   acc1: 91.0400 | acc5: 99.7800 | loss: 0.2873
2025-08-28 05:34:33,178 - INFO -   LR: 0.001000
2025-08-28 05:34:33,197 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-28 05:34:33,397 - INFO - Epoch: [176][0/391] Time 0.199 (0.199) Data 0.165 (0.165) Loss 0.0974 (0.0974) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:34:35,207 - INFO - Epoch: [176][100/391] Time 0.011 (0.020) Data 0.000 (0.006) Loss 0.1408 (0.0970) Acc@1 94.531 (96.836) Acc@5 100.000 (99.969)
2025-08-28 05:34:36,026 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:36,026 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:37,003 - INFO - Epoch: [176][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.0958 (0.0948) Acc@1 97.656 (96.933) Acc@5 100.000 (99.969)
2025-08-28 05:34:38,893 - INFO - Epoch: [176][300/391] Time 0.025 (0.019) Data 0.000 (0.004) Loss 0.1324 (0.0958) Acc@1 93.750 (96.917) Acc@5 100.000 (99.969)
2025-08-28 05:34:38,947 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:38,947 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:40,650 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2599 (0.2599) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:34:41,551 - INFO - Epoch 176:
2025-08-28 05:34:41,552 - INFO -   Train: acc1: 96.8880 | acc5: 99.9660 | loss: 0.0967 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:41,552 - INFO -   Val:   acc1: 90.9400 | acc5: 99.7000 | loss: 0.2899
2025-08-28 05:34:41,552 - INFO -   LR: 0.001000
2025-08-28 05:34:41,570 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-28 05:34:41,764 - INFO - Epoch: [177][0/391] Time 0.193 (0.193) Data 0.167 (0.167) Loss 0.0738 (0.0738) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:34:43,189 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:43,189 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:43,715 - INFO - Epoch: [177][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.0689 (0.0910) Acc@1 96.875 (97.084) Acc@5 100.000 (99.946)
2025-08-28 05:34:45,507 - INFO - Epoch: [177][200/391] Time 0.049 (0.020) Data 0.034 (0.003) Loss 0.0365 (0.0917) Acc@1 100.000 (97.093) Acc@5 100.000 (99.961)
2025-08-28 05:34:46,108 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:46,108 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:47,315 - INFO - Epoch: [177][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1913 (0.0943) Acc@1 93.750 (96.997) Acc@5 99.219 (99.964)
2025-08-28 05:34:49,111 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2523 (0.2523) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:34:50,175 - INFO - Epoch 177:
2025-08-28 05:34:50,176 - INFO -   Train: acc1: 97.0320 | acc5: 99.9620 | loss: 0.0935 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:50,176 - INFO -   Val:   acc1: 91.0000 | acc5: 99.7500 | loss: 0.2905
2025-08-28 05:34:50,176 - INFO -   LR: 0.001000
2025-08-28 05:34:50,196 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-28 05:34:50,395 - INFO - Epoch: [178][0/391] Time 0.199 (0.199) Data 0.173 (0.173) Loss 0.0635 (0.0635) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:34:50,421 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:50,422 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:52,215 - INFO - Epoch: [178][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.0832 (0.0945) Acc@1 96.875 (96.976) Acc@5 100.000 (99.969)
2025-08-28 05:34:53,340 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:53,340 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:54,056 - INFO - Epoch: [178][200/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.1048 (0.0952) Acc@1 96.875 (96.995) Acc@5 99.219 (99.973)
2025-08-28 05:34:55,900 - INFO - Epoch: [178][300/391] Time 0.035 (0.019) Data 0.021 (0.003) Loss 0.0719 (0.0943) Acc@1 97.656 (97.044) Acc@5 100.000 (99.979)
2025-08-28 05:34:56,248 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:34:56,248 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:34:57,698 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2617 (0.2617) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:34:58,526 - INFO - Epoch 178:
2025-08-28 05:34:58,527 - INFO -   Train: acc1: 97.0920 | acc5: 99.9760 | loss: 0.0936 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:34:58,527 - INFO -   Val:   acc1: 90.9900 | acc5: 99.7600 | loss: 0.2904
2025-08-28 05:34:58,527 - INFO -   LR: 0.001000
2025-08-28 05:34:58,547 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-28 05:34:58,723 - INFO - Epoch: [179][0/391] Time 0.176 (0.176) Data 0.147 (0.147) Loss 0.0831 (0.0831) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:35:00,432 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:00,432 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:00,572 - INFO - Epoch: [179][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.0810 (0.0951) Acc@1 97.656 (96.860) Acc@5 100.000 (99.954)
2025-08-28 05:35:02,438 - INFO - Epoch: [179][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1236 (0.0933) Acc@1 96.094 (96.922) Acc@5 100.000 (99.961)
2025-08-28 05:35:03,461 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:03,461 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:04,435 - INFO - Epoch: [179][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.0519 (0.0936) Acc@1 98.438 (96.955) Acc@5 100.000 (99.966)
2025-08-28 05:35:06,192 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2677 (0.2677) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:35:07,047 - INFO - Epoch 179:
2025-08-28 05:35:07,047 - INFO -   Train: acc1: 96.9840 | acc5: 99.9660 | loss: 0.0935 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:07,047 - INFO -   Val:   acc1: 90.8000 | acc5: 99.7700 | loss: 0.2931
2025-08-28 05:35:07,048 - INFO -   LR: 0.001000
2025-08-28 05:35:07,065 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-28 05:35:07,251 - INFO - Epoch: [180][0/391] Time 0.185 (0.185) Data 0.163 (0.163) Loss 0.1529 (0.1529) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-28 05:35:07,638 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:07,638 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:09,121 - INFO - Epoch: [180][100/391] Time 0.031 (0.020) Data 0.000 (0.004) Loss 0.0937 (0.0930) Acc@1 96.875 (97.076) Acc@5 100.000 (99.954)
2025-08-28 05:35:10,591 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:10,591 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:10,949 - INFO - Epoch: [180][200/391] Time 0.023 (0.019) Data 0.012 (0.004) Loss 0.0842 (0.0933) Acc@1 96.094 (97.046) Acc@5 100.000 (99.949)
2025-08-28 05:35:12,933 - INFO - Epoch: [180][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1045 (0.0937) Acc@1 96.875 (97.039) Acc@5 100.000 (99.964)
2025-08-28 05:35:13,694 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:13,694 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:14,757 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2544 (0.2544) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:35:15,604 - INFO - Epoch 180:
2025-08-28 05:35:15,604 - INFO -   Train: acc1: 96.9400 | acc5: 99.9680 | loss: 0.0945 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:15,604 - INFO -   Val:   acc1: 90.7800 | acc5: 99.7400 | loss: 0.2923
2025-08-28 05:35:15,604 - INFO -   LR: 0.001000
2025-08-28 05:35:15,656 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-28 05:35:15,855 - INFO - Epoch: [181][0/391] Time 0.198 (0.198) Data 0.179 (0.179) Loss 0.0662 (0.0662) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-28 05:35:17,704 - INFO - Epoch: [181][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.0923 (0.0917) Acc@1 97.656 (97.092) Acc@5 100.000 (99.977)
2025-08-28 05:35:17,879 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:17,880 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:19,518 - INFO - Epoch: [181][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1005 (0.0917) Acc@1 97.656 (97.100) Acc@5 100.000 (99.981)
2025-08-28 05:35:20,771 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:20,771 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:21,302 - INFO - Epoch: [181][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1223 (0.0926) Acc@1 97.656 (97.049) Acc@5 100.000 (99.974)
2025-08-28 05:35:23,114 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2684 (0.2684) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:35:23,993 - INFO - Epoch 181:
2025-08-28 05:35:23,993 - INFO -   Train: acc1: 97.0380 | acc5: 99.9800 | loss: 0.0922 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:23,993 - INFO -   Val:   acc1: 90.9600 | acc5: 99.7500 | loss: 0.2915
2025-08-28 05:35:23,993 - INFO -   LR: 0.001000
2025-08-28 05:35:24,010 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-28 05:35:24,199 - INFO - Epoch: [182][0/391] Time 0.188 (0.188) Data 0.168 (0.168) Loss 0.0766 (0.0766) Acc@1 98.438 (98.438) Acc@5 99.219 (99.219)
2025-08-28 05:35:24,860 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:24,860 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:26,039 - INFO - Epoch: [182][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0688 (0.0848) Acc@1 96.875 (97.262) Acc@5 100.000 (99.992)
2025-08-28 05:35:27,788 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:27,788 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:27,845 - INFO - Epoch: [182][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0575 (0.0874) Acc@1 99.219 (97.186) Acc@5 100.000 (99.992)
2025-08-28 05:35:29,708 - INFO - Epoch: [182][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.0642 (0.0906) Acc@1 98.438 (97.064) Acc@5 100.000 (99.984)
2025-08-28 05:35:30,826 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:30,826 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:31,556 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2482 (0.2482) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:35:32,383 - INFO - Epoch 182:
2025-08-28 05:35:32,383 - INFO -   Train: acc1: 97.0620 | acc5: 99.9820 | loss: 0.0913 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:32,383 - INFO -   Val:   acc1: 90.7400 | acc5: 99.7900 | loss: 0.2968
2025-08-28 05:35:32,383 - INFO -   LR: 0.001000
2025-08-28 05:35:32,400 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-28 05:35:32,590 - INFO - Epoch: [183][0/391] Time 0.189 (0.189) Data 0.154 (0.154) Loss 0.0845 (0.0845) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:35:34,413 - INFO - Epoch: [183][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1042 (0.0945) Acc@1 96.875 (97.022) Acc@5 100.000 (99.961)
2025-08-28 05:35:34,925 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:34,925 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:36,220 - INFO - Epoch: [183][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.0582 (0.0920) Acc@1 98.438 (97.054) Acc@5 100.000 (99.977)
2025-08-28 05:35:37,836 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:37,836 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:38,049 - INFO - Epoch: [183][300/391] Time 0.014 (0.019) Data 0.001 (0.003) Loss 0.0903 (0.0926) Acc@1 95.312 (97.000) Acc@5 100.000 (99.971)
2025-08-28 05:35:39,856 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2616 (0.2616) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:35:40,691 - INFO - Epoch 183:
2025-08-28 05:35:40,692 - INFO -   Train: acc1: 96.9460 | acc5: 99.9760 | loss: 0.0926 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:40,692 - INFO -   Val:   acc1: 90.7800 | acc5: 99.7500 | loss: 0.2948
2025-08-28 05:35:40,692 - INFO -   LR: 0.001000
2025-08-28 05:35:40,713 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-28 05:35:40,894 - INFO - Epoch: [184][0/391] Time 0.180 (0.180) Data 0.162 (0.162) Loss 0.1211 (0.1211) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:35:41,942 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:41,942 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:42,748 - INFO - Epoch: [184][100/391] Time 0.041 (0.020) Data 0.017 (0.004) Loss 0.1267 (0.0884) Acc@1 96.875 (97.092) Acc@5 100.000 (99.961)
2025-08-28 05:35:44,573 - INFO - Epoch: [184][200/391] Time 0.044 (0.019) Data 0.023 (0.004) Loss 0.0951 (0.0912) Acc@1 96.875 (97.023) Acc@5 100.000 (99.961)
2025-08-28 05:35:44,882 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:44,882 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:46,508 - INFO - Epoch: [184][300/391] Time 0.024 (0.019) Data 0.009 (0.004) Loss 0.1468 (0.0912) Acc@1 96.094 (96.989) Acc@5 100.000 (99.964)
2025-08-28 05:35:47,911 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:47,911 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:48,315 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2510 (0.2510) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:35:49,157 - INFO - Epoch 184:
2025-08-28 05:35:49,157 - INFO -   Train: acc1: 96.9620 | acc5: 99.9640 | loss: 0.0924 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:49,157 - INFO -   Val:   acc1: 90.8100 | acc5: 99.7600 | loss: 0.2978
2025-08-28 05:35:49,157 - INFO -   LR: 0.001000
2025-08-28 05:35:49,177 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-28 05:35:49,373 - INFO - Epoch: [185][0/391] Time 0.194 (0.194) Data 0.168 (0.168) Loss 0.1333 (0.1333) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:35:51,370 - INFO - Epoch: [185][100/391] Time 0.015 (0.022) Data 0.000 (0.005) Loss 0.1082 (0.0883) Acc@1 97.656 (97.161) Acc@5 100.000 (99.977)
2025-08-28 05:35:52,136 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:52,136 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:53,186 - INFO - Epoch: [185][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.0611 (0.0896) Acc@1 99.219 (97.186) Acc@5 100.000 (99.965)
2025-08-28 05:35:55,044 - INFO - Epoch: [185][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1167 (0.0900) Acc@1 95.312 (97.127) Acc@5 100.000 (99.964)
2025-08-28 05:35:55,127 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:55,127 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:56,833 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2639 (0.2639) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:35:57,689 - INFO - Epoch 185:
2025-08-28 05:35:57,689 - INFO -   Train: acc1: 97.0800 | acc5: 99.9680 | loss: 0.0909 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:35:57,690 - INFO -   Val:   acc1: 90.8600 | acc5: 99.7600 | loss: 0.2981
2025-08-28 05:35:57,690 - INFO -   LR: 0.001000
2025-08-28 05:35:57,709 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-28 05:35:57,908 - INFO - Epoch: [186][0/391] Time 0.198 (0.198) Data 0.181 (0.181) Loss 0.0710 (0.0710) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:35:59,254 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:35:59,254 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:35:59,777 - INFO - Epoch: [186][100/391] Time 0.051 (0.020) Data 0.026 (0.005) Loss 0.1067 (0.0911) Acc@1 96.875 (96.999) Acc@5 100.000 (99.977)
2025-08-28 05:36:01,672 - INFO - Epoch: [186][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.0753 (0.0915) Acc@1 96.875 (97.050) Acc@5 100.000 (99.973)
2025-08-28 05:36:02,352 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:02,352 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:03,546 - INFO - Epoch: [186][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0663 (0.0927) Acc@1 98.438 (97.000) Acc@5 100.000 (99.971)
2025-08-28 05:36:05,425 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2579 (0.2579) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:36:06,280 - INFO - Epoch 186:
2025-08-28 05:36:06,280 - INFO -   Train: acc1: 97.0020 | acc5: 99.9720 | loss: 0.0934 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:06,280 - INFO -   Val:   acc1: 90.9100 | acc5: 99.7400 | loss: 0.2977
2025-08-28 05:36:06,280 - INFO -   LR: 0.001000
2025-08-28 05:36:06,303 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-28 05:36:06,469 - INFO - Epoch: [187][0/391] Time 0.164 (0.164) Data 0.140 (0.140) Loss 0.0806 (0.0806) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:36:06,537 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:06,538 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:08,429 - INFO - Epoch: [187][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.0985 (0.0887) Acc@1 97.656 (97.169) Acc@5 100.000 (99.977)
2025-08-28 05:36:09,538 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:09,538 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:10,224 - INFO - Epoch: [187][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1349 (0.0899) Acc@1 93.750 (97.163) Acc@5 100.000 (99.973)
2025-08-28 05:36:12,042 - INFO - Epoch: [187][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0423 (0.0907) Acc@1 99.219 (97.145) Acc@5 100.000 (99.977)
2025-08-28 05:36:12,467 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:12,467 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:13,860 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2842 (0.2842) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:36:14,718 - INFO - Epoch 187:
2025-08-28 05:36:14,719 - INFO -   Train: acc1: 97.1100 | acc5: 99.9680 | loss: 0.0914 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:14,719 - INFO -   Val:   acc1: 90.7500 | acc5: 99.7600 | loss: 0.2977
2025-08-28 05:36:14,719 - INFO -   LR: 0.001000
2025-08-28 05:36:14,738 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-28 05:36:14,916 - INFO - Epoch: [188][0/391] Time 0.178 (0.178) Data 0.153 (0.153) Loss 0.0513 (0.0513) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-28 05:36:16,598 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:16,598 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:16,774 - INFO - Epoch: [188][100/391] Time 0.032 (0.020) Data 0.000 (0.004) Loss 0.0940 (0.0862) Acc@1 96.094 (97.347) Acc@5 100.000 (99.977)
2025-08-28 05:36:18,670 - INFO - Epoch: [188][200/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.1304 (0.0863) Acc@1 96.094 (97.244) Acc@5 100.000 (99.988)
2025-08-28 05:36:19,633 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:19,633 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:20,543 - INFO - Epoch: [188][300/391] Time 0.021 (0.019) Data 0.001 (0.003) Loss 0.0706 (0.0868) Acc@1 98.438 (97.212) Acc@5 100.000 (99.987)
2025-08-28 05:36:22,253 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2733 (0.2733) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:36:23,125 - INFO - Epoch 188:
2025-08-28 05:36:23,126 - INFO -   Train: acc1: 97.2000 | acc5: 99.9800 | loss: 0.0868 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:23,126 - INFO -   Val:   acc1: 90.7000 | acc5: 99.7400 | loss: 0.2983
2025-08-28 05:36:23,126 - INFO -   LR: 0.001000
2025-08-28 05:36:23,144 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-28 05:36:23,305 - INFO - Epoch: [189][0/391] Time 0.160 (0.160) Data 0.144 (0.144) Loss 0.0932 (0.0932) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:36:23,684 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:23,684 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:25,090 - INFO - Epoch: [189][100/391] Time 0.015 (0.019) Data 0.001 (0.004) Loss 0.1256 (0.0923) Acc@1 94.531 (96.805) Acc@5 100.000 (99.977)
2025-08-28 05:36:26,617 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:26,617 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:26,928 - INFO - Epoch: [189][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0992 (0.0899) Acc@1 96.875 (96.964) Acc@5 100.000 (99.977)
2025-08-28 05:36:28,804 - INFO - Epoch: [189][300/391] Time 0.029 (0.019) Data 0.019 (0.004) Loss 0.1305 (0.0897) Acc@1 96.875 (97.015) Acc@5 100.000 (99.974)
2025-08-28 05:36:29,558 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:29,558 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:30,619 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2665 (0.2665) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:36:31,474 - INFO - Epoch 189:
2025-08-28 05:36:31,474 - INFO -   Train: acc1: 97.0620 | acc5: 99.9780 | loss: 0.0899 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:31,474 - INFO -   Val:   acc1: 90.8600 | acc5: 99.8100 | loss: 0.2984
2025-08-28 05:36:31,474 - INFO -   LR: 0.001000
2025-08-28 05:36:31,493 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-28 05:36:31,668 - INFO - Epoch: [190][0/391] Time 0.174 (0.174) Data 0.157 (0.157) Loss 0.1008 (0.1008) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:36:33,517 - INFO - Epoch: [190][100/391] Time 0.021 (0.020) Data 0.000 (0.006) Loss 0.1945 (0.0924) Acc@1 96.094 (97.092) Acc@5 100.000 (99.946)
2025-08-28 05:36:33,704 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:33,704 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:35,270 - INFO - Epoch: [190][200/391] Time 0.027 (0.019) Data 0.011 (0.003) Loss 0.0907 (0.0915) Acc@1 96.875 (96.984) Acc@5 100.000 (99.961)
2025-08-28 05:36:36,519 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:36,519 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:37,072 - INFO - Epoch: [190][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.0801 (0.0902) Acc@1 97.656 (97.031) Acc@5 100.000 (99.961)
2025-08-28 05:36:38,818 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2544 (0.2544) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:36:39,678 - INFO - Epoch 190:
2025-08-28 05:36:39,678 - INFO -   Train: acc1: 97.0940 | acc5: 99.9660 | loss: 0.0897 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:39,678 - INFO -   Val:   acc1: 90.8100 | acc5: 99.7700 | loss: 0.3022
2025-08-28 05:36:39,678 - INFO -   LR: 0.001000
2025-08-28 05:36:39,731 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-28 05:36:39,901 - INFO - Epoch: [191][0/391] Time 0.168 (0.168) Data 0.149 (0.149) Loss 0.0893 (0.0893) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:36:40,657 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:40,657 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:41,820 - INFO - Epoch: [191][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.0584 (0.0883) Acc@1 99.219 (97.068) Acc@5 100.000 (99.969)
2025-08-28 05:36:43,635 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:43,636 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:43,677 - INFO - Epoch: [191][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.0617 (0.0876) Acc@1 96.875 (97.155) Acc@5 100.000 (99.969)
2025-08-28 05:36:45,465 - INFO - Epoch: [191][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1037 (0.0874) Acc@1 98.438 (97.231) Acc@5 100.000 (99.971)
2025-08-28 05:36:46,509 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:46,509 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:47,192 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2384 (0.2384) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:36:48,038 - INFO - Epoch 191:
2025-08-28 05:36:48,039 - INFO -   Train: acc1: 97.1960 | acc5: 99.9720 | loss: 0.0889 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:48,039 - INFO -   Val:   acc1: 90.8500 | acc5: 99.7200 | loss: 0.3036
2025-08-28 05:36:48,039 - INFO -   LR: 0.001000
2025-08-28 05:36:48,061 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-28 05:36:48,224 - INFO - Epoch: [192][0/391] Time 0.163 (0.163) Data 0.141 (0.141) Loss 0.0479 (0.0479) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:36:50,162 - INFO - Epoch: [192][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1047 (0.0873) Acc@1 96.094 (97.285) Acc@5 100.000 (99.954)
2025-08-28 05:36:50,627 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:50,627 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:52,046 - INFO - Epoch: [192][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1204 (0.0880) Acc@1 94.531 (97.159) Acc@5 100.000 (99.977)
2025-08-28 05:36:53,667 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:53,667 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:53,935 - INFO - Epoch: [192][300/391] Time 0.032 (0.020) Data 0.017 (0.003) Loss 0.0645 (0.0881) Acc@1 98.438 (97.181) Acc@5 100.000 (99.979)
2025-08-28 05:36:55,691 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2558 (0.2558) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:36:56,611 - INFO - Epoch 192:
2025-08-28 05:36:56,611 - INFO -   Train: acc1: 97.1200 | acc5: 99.9720 | loss: 0.0890 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:36:56,611 - INFO -   Val:   acc1: 90.7200 | acc5: 99.7900 | loss: 0.2994
2025-08-28 05:36:56,611 - INFO -   LR: 0.001000
2025-08-28 05:36:56,633 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-28 05:36:56,818 - INFO - Epoch: [193][0/391] Time 0.184 (0.184) Data 0.168 (0.168) Loss 0.1474 (0.1474) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:36:57,860 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:36:57,860 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:36:58,648 - INFO - Epoch: [193][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1125 (0.0874) Acc@1 96.875 (97.254) Acc@5 100.000 (99.992)
2025-08-28 05:37:00,491 - INFO - Epoch: [193][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.0696 (0.0885) Acc@1 98.438 (97.167) Acc@5 100.000 (99.992)
2025-08-28 05:37:00,828 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:00,828 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:02,331 - INFO - Epoch: [193][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.0958 (0.0876) Acc@1 95.312 (97.228) Acc@5 100.000 (99.982)
2025-08-28 05:37:03,726 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:03,726 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:04,113 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.2753 (0.2753) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:37:04,951 - INFO - Epoch 193:
2025-08-28 05:37:04,951 - INFO -   Train: acc1: 97.2300 | acc5: 99.9760 | loss: 0.0887 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:37:04,951 - INFO -   Val:   acc1: 90.9500 | acc5: 99.7400 | loss: 0.2962
2025-08-28 05:37:04,951 - INFO -   LR: 0.001000
2025-08-28 05:37:06,304 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-28 05:37:06,506 - INFO - Epoch: [194][0/391] Time 0.200 (0.200) Data 0.174 (0.174) Loss 0.0952 (0.0952) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:37:08,342 - INFO - Epoch: [194][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.0465 (0.0891) Acc@1 99.219 (97.153) Acc@5 100.000 (99.961)
2025-08-28 05:37:09,203 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:09,203 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:10,197 - INFO - Epoch: [194][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.0544 (0.0878) Acc@1 99.219 (97.198) Acc@5 100.000 (99.969)
2025-08-28 05:37:12,041 - INFO - Epoch: [194][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.0633 (0.0888) Acc@1 97.656 (97.155) Acc@5 100.000 (99.966)
2025-08-28 05:37:12,145 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:12,145 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:13,816 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2556 (0.2556) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:37:14,667 - INFO - Epoch 194:
2025-08-28 05:37:14,668 - INFO -   Train: acc1: 97.1060 | acc5: 99.9660 | loss: 0.0890 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:37:14,668 - INFO -   Val:   acc1: 90.7600 | acc5: 99.7600 | loss: 0.3028
2025-08-28 05:37:14,668 - INFO -   LR: 0.001000
2025-08-28 05:37:24,684 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-28 05:37:24,862 - INFO - Epoch: [195][0/391] Time 0.177 (0.177) Data 0.146 (0.146) Loss 0.1049 (0.1049) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-28 05:37:26,224 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:26,224 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:26,747 - INFO - Epoch: [195][100/391] Time 0.018 (0.020) Data 0.000 (0.005) Loss 0.0509 (0.0852) Acc@1 98.438 (97.215) Acc@5 100.000 (99.977)
2025-08-28 05:37:28,626 - INFO - Epoch: [195][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1046 (0.0850) Acc@1 96.875 (97.318) Acc@5 100.000 (99.981)
2025-08-28 05:37:29,208 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:29,208 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:30,506 - INFO - Epoch: [195][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.0786 (0.0872) Acc@1 97.656 (97.238) Acc@5 100.000 (99.979)
2025-08-28 05:37:32,305 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2980 (0.2980) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:37:33,155 - INFO - Epoch 195:
2025-08-28 05:37:33,155 - INFO -   Train: acc1: 97.1980 | acc5: 99.9800 | loss: 0.0878 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:37:33,155 - INFO -   Val:   acc1: 90.7300 | acc5: 99.7700 | loss: 0.3039
2025-08-28 05:37:33,155 - INFO -   LR: 0.001000
2025-08-28 05:37:33,176 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-28 05:37:33,361 - INFO - Epoch: [196][0/391] Time 0.184 (0.184) Data 0.159 (0.159) Loss 0.1359 (0.1359) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:37:33,427 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:33,428 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:35,235 - INFO - Epoch: [196][100/391] Time 0.031 (0.020) Data 0.000 (0.003) Loss 0.0446 (0.0904) Acc@1 98.438 (96.976) Acc@5 100.000 (99.992)
2025-08-28 05:37:36,355 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:36,355 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:37,038 - INFO - Epoch: [196][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0872 (0.0907) Acc@1 96.875 (97.030) Acc@5 100.000 (99.988)
2025-08-28 05:37:38,927 - INFO - Epoch: [196][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1036 (0.0904) Acc@1 96.094 (97.018) Acc@5 100.000 (99.982)
2025-08-28 05:37:39,361 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:39,361 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:40,857 - INFO - Test: [0/79] Time 0.230 (0.230) Loss 0.2894 (0.2894) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:37:41,791 - INFO - Epoch 196:
2025-08-28 05:37:41,791 - INFO -   Train: acc1: 97.0400 | acc5: 99.9760 | loss: 0.0902 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:37:41,791 - INFO -   Val:   acc1: 90.4700 | acc5: 99.7100 | loss: 0.3052
2025-08-28 05:37:41,791 - INFO -   LR: 0.001000
2025-08-28 05:37:41,810 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-28 05:37:42,007 - INFO - Epoch: [197][0/391] Time 0.196 (0.196) Data 0.174 (0.174) Loss 0.0627 (0.0627) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:37:43,701 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:43,701 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:43,831 - INFO - Epoch: [197][100/391] Time 0.029 (0.020) Data 0.000 (0.004) Loss 0.0839 (0.0883) Acc@1 97.656 (97.254) Acc@5 100.000 (99.985)
2025-08-28 05:37:45,666 - INFO - Epoch: [197][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1261 (0.0878) Acc@1 94.531 (97.143) Acc@5 99.219 (99.977)
2025-08-28 05:37:46,651 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:46,651 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:47,498 - INFO - Epoch: [197][300/391] Time 0.022 (0.019) Data 0.005 (0.003) Loss 0.1210 (0.0873) Acc@1 96.094 (97.137) Acc@5 100.000 (99.971)
2025-08-28 05:37:49,273 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2327 (0.2327) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:37:50,126 - INFO - Epoch 197:
2025-08-28 05:37:50,126 - INFO -   Train: acc1: 97.1960 | acc5: 99.9740 | loss: 0.0866 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:37:50,126 - INFO -   Val:   acc1: 90.7600 | acc5: 99.7800 | loss: 0.3011
2025-08-28 05:37:50,126 - INFO -   LR: 0.001000
2025-08-28 05:37:50,148 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-28 05:37:50,309 - INFO - Epoch: [198][0/391] Time 0.160 (0.160) Data 0.142 (0.142) Loss 0.0782 (0.0782) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:37:50,710 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:50,711 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:52,169 - INFO - Epoch: [198][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.0818 (0.0846) Acc@1 96.875 (97.370) Acc@5 100.000 (99.977)
2025-08-28 05:37:53,653 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:53,654 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:54,017 - INFO - Epoch: [198][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1041 (0.0881) Acc@1 96.875 (97.233) Acc@5 100.000 (99.977)
2025-08-28 05:37:55,851 - INFO - Epoch: [198][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.0834 (0.0868) Acc@1 95.312 (97.225) Acc@5 100.000 (99.977)
2025-08-28 05:37:56,582 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:37:56,582 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:37:57,637 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2776 (0.2776) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:37:58,473 - INFO - Epoch 198:
2025-08-28 05:37:58,474 - INFO -   Train: acc1: 97.2560 | acc5: 99.9760 | loss: 0.0867 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:37:58,474 - INFO -   Val:   acc1: 90.8600 | acc5: 99.7300 | loss: 0.3025
2025-08-28 05:37:58,474 - INFO -   LR: 0.001000
2025-08-28 05:37:58,492 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-28 05:37:58,704 - INFO - Epoch: [199][0/391] Time 0.211 (0.211) Data 0.187 (0.187) Loss 0.0501 (0.0501) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:38:00,609 - INFO - Epoch: [199][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.1115 (0.0818) Acc@1 94.531 (97.478) Acc@5 100.000 (99.961)
2025-08-28 05:38:00,799 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:38:00,799 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:38:02,482 - INFO - Epoch: [199][200/391] Time 0.029 (0.020) Data 0.010 (0.003) Loss 0.0629 (0.0838) Acc@1 98.438 (97.353) Acc@5 100.000 (99.965)
2025-08-28 05:38:03,788 - INFO - Pruning info: sparsity=0.700
2025-08-28 05:38:03,788 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:38:04,378 - INFO - Epoch: [199][300/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.0954 (0.0846) Acc@1 96.875 (97.319) Acc@5 100.000 (99.969)
2025-08-28 05:38:06,148 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2880 (0.2880) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:38:07,004 - INFO - Epoch 199:
2025-08-28 05:38:07,004 - INFO -   Train: acc1: 97.2760 | acc5: 99.9740 | loss: 0.0861 | sparsity: 0.7000 | reactivation_rate: 0.0000
2025-08-28 05:38:07,004 - INFO -   Val:   acc1: 90.7600 | acc5: 99.6900 | loss: 0.3038
2025-08-28 05:38:07,004 - INFO -   LR: 0.001000
2025-08-28 05:38:07,024 - INFO - training time: 00h 28m 23.39s
2025-08-28 05:38:07,024 - INFO - 
Training completed!
2025-08-28 05:38:07,024 - INFO - Best accuracy: 91.0900
2025-08-28 05:38:07,024 - INFO - Total training time: 0.47 hours
2025-08-28 05:38:07,024 - INFO - total_experiment time: 00h 28m 24.74s
2025-08-28 05:38:07,025 - INFO - Experiment completed successfully
2025-08-28 05:38:07,025 - INFO - Total time: 0.47 hours
