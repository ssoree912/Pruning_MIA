2025-08-28 06:35:32,147 - INFO - Starting experiment: dpf_sparsity0.95
2025-08-28 06:35:32,148 - INFO - Save directory: ./runs/dpf/sparsity0.95/seed42
2025-08-28 06:35:32,148 - INFO - Hyperparameters:
2025-08-28 06:35:32,148 - INFO -   name: dpf_sparsity0.95
2025-08-28 06:35:32,148 - INFO -   description: 
2025-08-28 06:35:32,148 - INFO -   save_dir: ./runs
2025-08-28 06:35:32,148 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 06:35:32,148 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 06:35:32,148 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 06:35:32,148 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.95, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 06:35:32,148 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 06:35:32,148 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 06:35:32,184 - INFO - System Information:
2025-08-28 06:35:32,184 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 06:35:32,184 - INFO -   python_version: 3.9.18
2025-08-28 06:35:32,184 - INFO -   pytorch_version: 2.1.0
2025-08-28 06:35:32,184 - INFO -   cuda_available: True
2025-08-28 06:35:32,184 - INFO -   cpu_count: 4
2025-08-28 06:35:32,184 - INFO -   memory_total_gb: 11.0
2025-08-28 06:35:32,184 - INFO -   timestamp: 1756330532.184009
2025-08-28 06:35:32,184 - INFO -   cuda_version: 11.8
2025-08-28 06:35:32,184 - INFO -   gpu_count: 1
2025-08-28 06:35:32,184 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 06:35:32,191 - INFO - Starting experiment: dpf_sparsity0.95
2025-08-28 06:35:32,191 - INFO - Model: resnet-20
2025-08-28 06:35:32,191 - INFO - Dataset: cifar10
2025-08-28 06:35:32,191 - INFO - Pruning: dpf (95.00%)
2025-08-28 06:35:32,326 - INFO - Model Information:
2025-08-28 06:35:32,326 - INFO -   Type: pruned
2025-08-28 06:35:32,326 - INFO -   Total parameters: 544,948
2025-08-28 06:35:32,326 - INFO -   Trainable parameters: 274,692
2025-08-28 06:35:32,326 - INFO -   Sparsity: 95.00%
2025-08-28 06:35:33,494 - INFO - Starting training...
2025-08-28 06:35:33,495 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 06:35:34,167 - INFO - Pruning info: sparsity=0.000
2025-08-28 06:35:34,167 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:34,700 - INFO - Epoch: [0][0/391] Time 1.205 (1.205) Data 0.526 (0.526) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 06:35:36,602 - INFO - Epoch: [0][100/391] Time 0.017 (0.031) Data 0.000 (0.007) Loss 1.6910 (1.9312) Acc@1 40.625 (25.789) Acc@5 88.281 (81.149)
2025-08-28 06:35:37,796 - INFO - Pruning info: sparsity=0.000
2025-08-28 06:35:37,796 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:38,582 - INFO - Epoch: [0][200/391] Time 0.024 (0.025) Data 0.001 (0.004) Loss 1.5404 (1.7991) Acc@1 42.188 (31.390) Acc@5 91.406 (84.985)
2025-08-28 06:35:40,454 - INFO - Epoch: [0][300/391] Time 0.020 (0.023) Data 0.000 (0.003) Loss 1.4850 (1.7067) Acc@1 50.000 (35.610) Acc@5 90.625 (87.144)
2025-08-28 06:35:40,806 - INFO - Pruning info: sparsity=0.000
2025-08-28 06:35:40,806 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:42,531 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 1.5366 (1.5366) Acc@1 45.312 (45.312) Acc@5 91.406 (91.406)
2025-08-28 06:35:43,447 - INFO - Epoch 0:
2025-08-28 06:35:43,447 - INFO -   Train: acc1: 38.7040 | acc5: 88.4980 | loss: 1.6344 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 06:35:43,447 - INFO -   Val:   acc1: 46.5200 | acc5: 92.5600 | loss: 1.5724
2025-08-28 06:35:43,448 - INFO -   LR: 0.100000
2025-08-28 06:35:43,495 - INFO - Checkpoint saved: epoch=0, metric=46.5200
2025-08-28 06:35:43,527 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 06:35:43,720 - INFO - Epoch: [1][0/391] Time 0.192 (0.192) Data 0.167 (0.167) Loss 1.4818 (1.4818) Acc@1 42.969 (42.969) Acc@5 93.750 (93.750)
2025-08-28 06:35:45,435 - INFO - Pruning info: sparsity=0.037
2025-08-28 06:35:45,435 - INFO -   Reactivation rate: 0.0091
2025-08-28 06:35:45,676 - INFO - Epoch: [1][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 1.2504 (1.2450) Acc@1 54.688 (55.360) Acc@5 94.531 (94.678)
2025-08-28 06:35:47,660 - INFO - Epoch: [1][200/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 1.0291 (1.1965) Acc@1 62.500 (57.090) Acc@5 96.094 (95.130)
2025-08-28 06:35:48,591 - INFO - Pruning info: sparsity=0.037
2025-08-28 06:35:48,592 - INFO -   Reactivation rate: 0.0063
2025-08-28 06:35:49,621 - INFO - Epoch: [1][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.9526 (1.1526) Acc@1 61.719 (58.609) Acc@5 98.438 (95.466)
2025-08-28 06:35:51,465 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 1.2180 (1.2180) Acc@1 52.344 (52.344) Acc@5 96.875 (96.875)
2025-08-28 06:35:52,340 - INFO - Epoch 1:
2025-08-28 06:35:52,340 - INFO -   Train: acc1: 59.9020 | acc5: 95.7340 | loss: 1.1192 | sparsity: 0.0375 | reactivation_rate: 0.0072
2025-08-28 06:35:52,340 - INFO -   Val:   acc1: 54.8300 | acc5: 95.4900 | loss: 1.3311
2025-08-28 06:35:52,340 - INFO -   LR: 0.100000
2025-08-28 06:35:52,384 - INFO - Checkpoint saved: epoch=1, metric=54.8300
2025-08-28 06:35:52,416 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 06:35:52,593 - INFO - Epoch: [2][0/391] Time 0.176 (0.176) Data 0.157 (0.157) Loss 0.9347 (0.9347) Acc@1 67.969 (67.969) Acc@5 96.875 (96.875)
2025-08-28 06:35:52,945 - INFO - Pruning info: sparsity=0.074
2025-08-28 06:35:52,945 - INFO -   Reactivation rate: 0.0140
2025-08-28 06:35:54,553 - INFO - Epoch: [2][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.9033 (0.9660) Acc@1 67.188 (65.563) Acc@5 98.438 (96.898)
2025-08-28 06:35:56,073 - INFO - Pruning info: sparsity=0.074
2025-08-28 06:35:56,074 - INFO -   Reactivation rate: 0.0080
2025-08-28 06:35:56,552 - INFO - Epoch: [2][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.8585 (0.9336) Acc@1 71.094 (66.702) Acc@5 98.438 (97.295)
2025-08-28 06:35:58,637 - INFO - Epoch: [2][300/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.8732 (0.9175) Acc@1 66.406 (67.569) Acc@5 99.219 (97.350)
2025-08-28 06:35:59,343 - INFO - Pruning info: sparsity=0.074
2025-08-28 06:35:59,343 - INFO -   Reactivation rate: 0.0060
2025-08-28 06:36:00,468 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 1.0979 (1.0979) Acc@1 64.062 (64.062) Acc@5 96.094 (96.094)
2025-08-28 06:36:01,350 - INFO - Epoch 2:
2025-08-28 06:36:01,350 - INFO -   Train: acc1: 68.3360 | acc5: 97.4700 | loss: 0.8972 | sparsity: 0.0740 | reactivation_rate: 0.0078
2025-08-28 06:36:01,350 - INFO -   Val:   acc1: 59.1900 | acc5: 93.3100 | loss: 1.3344
2025-08-28 06:36:01,350 - INFO -   LR: 0.100000
2025-08-28 06:36:01,397 - INFO - Checkpoint saved: epoch=2, metric=59.1900
2025-08-28 06:36:01,429 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 06:36:01,612 - INFO - Epoch: [3][0/391] Time 0.182 (0.182) Data 0.153 (0.153) Loss 0.8623 (0.8623) Acc@1 68.750 (68.750) Acc@5 95.312 (95.312)
2025-08-28 06:36:03,536 - INFO - Epoch: [3][100/391] Time 0.021 (0.021) Data 0.005 (0.003) Loss 0.7888 (0.7779) Acc@1 70.312 (73.004) Acc@5 97.656 (97.981)
2025-08-28 06:36:03,663 - INFO - Pruning info: sparsity=0.110
2025-08-28 06:36:03,663 - INFO -   Reactivation rate: 0.0092
2025-08-28 06:36:05,474 - INFO - Epoch: [3][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.8242 (0.7745) Acc@1 71.094 (73.072) Acc@5 96.875 (98.127)
2025-08-28 06:36:06,717 - INFO - Pruning info: sparsity=0.110
2025-08-28 06:36:06,718 - INFO -   Reactivation rate: 0.0068
2025-08-28 06:36:07,354 - INFO - Epoch: [3][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.7494 (0.7674) Acc@1 75.781 (73.297) Acc@5 96.094 (98.149)
2025-08-28 06:36:09,137 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.8843 (0.8843) Acc@1 73.438 (73.438) Acc@5 97.656 (97.656)
2025-08-28 06:36:09,990 - INFO - Epoch 3:
2025-08-28 06:36:09,991 - INFO -   Train: acc1: 73.3440 | acc5: 98.1780 | loss: 0.7675 | sparsity: 0.1095 | reactivation_rate: 0.0078
2025-08-28 06:36:09,991 - INFO -   Val:   acc1: 68.2200 | acc5: 96.7200 | loss: 0.9482
2025-08-28 06:36:09,991 - INFO -   LR: 0.100000
2025-08-28 06:36:10,054 - INFO - Checkpoint saved: epoch=3, metric=68.2200
2025-08-28 06:36:10,086 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 06:36:10,258 - INFO - Epoch: [4][0/391] Time 0.171 (0.171) Data 0.146 (0.146) Loss 0.7300 (0.7300) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 06:36:10,931 - INFO - Pruning info: sparsity=0.144
2025-08-28 06:36:10,931 - INFO -   Reactivation rate: 0.0118
2025-08-28 06:36:12,225 - INFO - Epoch: [4][100/391] Time 0.031 (0.021) Data 0.004 (0.003) Loss 0.7266 (0.7196) Acc@1 77.344 (75.271) Acc@5 95.312 (98.283)
2025-08-28 06:36:14,141 - INFO - Pruning info: sparsity=0.144
2025-08-28 06:36:14,141 - INFO -   Reactivation rate: 0.0071
2025-08-28 06:36:14,244 - INFO - Epoch: [4][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.7248 (0.6986) Acc@1 72.656 (75.894) Acc@5 99.219 (98.344)
2025-08-28 06:36:16,265 - INFO - Epoch: [4][300/391] Time 0.029 (0.021) Data 0.013 (0.002) Loss 0.7058 (0.6941) Acc@1 73.438 (75.989) Acc@5 99.219 (98.404)
2025-08-28 06:36:17,383 - INFO - Pruning info: sparsity=0.144
2025-08-28 06:36:17,383 - INFO -   Reactivation rate: 0.0056
2025-08-28 06:36:18,243 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 1.3605 (1.3605) Acc@1 60.938 (60.938) Acc@5 97.656 (97.656)
2025-08-28 06:36:19,092 - INFO - Epoch 4:
2025-08-28 06:36:19,092 - INFO -   Train: acc1: 76.1500 | acc5: 98.4500 | loss: 0.6897 | sparsity: 0.1440 | reactivation_rate: 0.0075
2025-08-28 06:36:19,092 - INFO -   Val:   acc1: 60.5500 | acc5: 95.8200 | loss: 1.4822
2025-08-28 06:36:19,092 - INFO -   LR: 0.100000
2025-08-28 06:36:19,101 - INFO - 
Epoch: 5, lr = 0.1
2025-08-28 06:36:19,280 - INFO - Epoch: [5][0/391] Time 0.177 (0.177) Data 0.149 (0.149) Loss 0.7036 (0.7036) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-28 06:36:21,292 - INFO - Epoch: [5][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 0.6030 (0.6683) Acc@1 76.562 (76.949) Acc@5 100.000 (98.670)
2025-08-28 06:36:21,774 - INFO - Pruning info: sparsity=0.178
2025-08-28 06:36:21,774 - INFO -   Reactivation rate: 0.0088
2025-08-28 06:36:23,155 - INFO - Epoch: [5][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.6562 (0.6569) Acc@1 78.906 (77.355) Acc@5 98.438 (98.651)
2025-08-28 06:36:24,746 - INFO - Pruning info: sparsity=0.178
2025-08-28 06:36:24,746 - INFO -   Reactivation rate: 0.0059
2025-08-28 06:36:25,043 - INFO - Epoch: [5][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.6952 (0.6510) Acc@1 72.656 (77.479) Acc@5 97.656 (98.630)
2025-08-28 06:36:26,888 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.8671 (0.8671) Acc@1 67.188 (67.188) Acc@5 97.656 (97.656)
2025-08-28 06:36:27,756 - INFO - Epoch 5:
2025-08-28 06:36:27,757 - INFO -   Train: acc1: 77.3820 | acc5: 98.6860 | loss: 0.6525 | sparsity: 0.1776 | reactivation_rate: 0.0074
2025-08-28 06:36:27,757 - INFO -   Val:   acc1: 70.7600 | acc5: 95.9900 | loss: 0.9418
2025-08-28 06:36:27,757 - INFO -   LR: 0.100000
2025-08-28 06:36:27,802 - INFO - Checkpoint saved: epoch=5, metric=70.7600
2025-08-28 06:36:27,834 - INFO - 
Epoch: 6, lr = 0.1
2025-08-28 06:36:28,032 - INFO - Epoch: [6][0/391] Time 0.197 (0.197) Data 0.160 (0.160) Loss 0.5011 (0.5011) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:36:29,100 - INFO - Pruning info: sparsity=0.210
2025-08-28 06:36:29,100 - INFO -   Reactivation rate: 0.0107
2025-08-28 06:36:30,056 - INFO - Epoch: [6][100/391] Time 0.022 (0.022) Data 0.000 (0.003) Loss 0.6046 (0.6123) Acc@1 79.688 (78.837) Acc@5 98.438 (98.793)
2025-08-28 06:36:32,020 - INFO - Epoch: [6][200/391] Time 0.016 (0.021) Data 0.005 (0.002) Loss 0.6033 (0.6188) Acc@1 78.125 (78.626) Acc@5 98.438 (98.764)
2025-08-28 06:36:32,291 - INFO - Pruning info: sparsity=0.210
2025-08-28 06:36:32,291 - INFO -   Reactivation rate: 0.0068
2025-08-28 06:36:34,000 - INFO - Epoch: [6][300/391] Time 0.018 (0.020) Data 0.004 (0.002) Loss 0.6756 (0.6231) Acc@1 75.781 (78.587) Acc@5 98.438 (98.749)
2025-08-28 06:36:35,456 - INFO - Pruning info: sparsity=0.210
2025-08-28 06:36:35,456 - INFO -   Reactivation rate: 0.0050
2025-08-28 06:36:35,890 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 1.1034 (1.1034) Acc@1 67.969 (67.969) Acc@5 96.094 (96.094)
2025-08-28 06:36:36,744 - INFO - Epoch 6:
2025-08-28 06:36:36,744 - INFO -   Train: acc1: 78.6660 | acc5: 98.7700 | loss: 0.6205 | sparsity: 0.2102 | reactivation_rate: 0.0070
2025-08-28 06:36:36,744 - INFO -   Val:   acc1: 62.5400 | acc5: 93.8600 | loss: 1.2885
2025-08-28 06:36:36,744 - INFO -   LR: 0.100000
2025-08-28 06:36:36,753 - INFO - 
Epoch: 7, lr = 0.1
2025-08-28 06:36:36,922 - INFO - Epoch: [7][0/391] Time 0.168 (0.168) Data 0.148 (0.148) Loss 0.6055 (0.6055) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:36:38,932 - INFO - Epoch: [7][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 0.6690 (0.5921) Acc@1 78.125 (79.626) Acc@5 99.219 (98.824)
2025-08-28 06:36:39,791 - INFO - Pruning info: sparsity=0.242
2025-08-28 06:36:39,791 - INFO -   Reactivation rate: 0.0081
2025-08-28 06:36:40,896 - INFO - Epoch: [7][200/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.6243 (0.5946) Acc@1 78.125 (79.489) Acc@5 97.656 (98.768)
2025-08-28 06:36:42,822 - INFO - Epoch: [7][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4656 (0.5963) Acc@1 85.156 (79.389) Acc@5 100.000 (98.770)
2025-08-28 06:36:42,863 - INFO - Pruning info: sparsity=0.242
2025-08-28 06:36:42,863 - INFO -   Reactivation rate: 0.0054
2025-08-28 06:36:44,617 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.9712 (0.9712) Acc@1 71.094 (71.094) Acc@5 96.094 (96.094)
2025-08-28 06:36:45,473 - INFO - Epoch 7:
2025-08-28 06:36:45,473 - INFO -   Train: acc1: 79.4180 | acc5: 98.8040 | loss: 0.5955 | sparsity: 0.2419 | reactivation_rate: 0.0070
2025-08-28 06:36:45,473 - INFO -   Val:   acc1: 67.2200 | acc5: 95.7200 | loss: 1.1048
2025-08-28 06:36:45,473 - INFO -   LR: 0.100000
2025-08-28 06:36:45,483 - INFO - 
Epoch: 8, lr = 0.1
2025-08-28 06:36:45,672 - INFO - Epoch: [8][0/391] Time 0.188 (0.188) Data 0.161 (0.161) Loss 0.5302 (0.5302) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 06:36:47,124 - INFO - Pruning info: sparsity=0.273
2025-08-28 06:36:47,124 - INFO -   Reactivation rate: 0.0092
2025-08-28 06:36:47,668 - INFO - Epoch: [8][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.5109 (0.5917) Acc@1 82.031 (79.448) Acc@5 99.219 (98.817)
2025-08-28 06:36:49,641 - INFO - Epoch: [8][200/391] Time 0.026 (0.021) Data 0.000 (0.002) Loss 0.5031 (0.5815) Acc@1 83.594 (79.761) Acc@5 98.438 (98.741)
2025-08-28 06:36:50,304 - INFO - Pruning info: sparsity=0.273
2025-08-28 06:36:50,304 - INFO -   Reactivation rate: 0.0059
2025-08-28 06:36:51,635 - INFO - Epoch: [8][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.5920 (0.5847) Acc@1 81.250 (79.799) Acc@5 100.000 (98.788)
2025-08-28 06:36:53,570 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6595 (0.6595) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 06:36:54,455 - INFO - Epoch 8:
2025-08-28 06:36:54,455 - INFO -   Train: acc1: 79.9960 | acc5: 98.8320 | loss: 0.5820 | sparsity: 0.2727 | reactivation_rate: 0.0067
2025-08-28 06:36:54,455 - INFO -   Val:   acc1: 73.7200 | acc5: 98.2400 | loss: 0.7713
2025-08-28 06:36:54,455 - INFO -   LR: 0.100000
2025-08-28 06:36:54,503 - INFO - Checkpoint saved: epoch=8, metric=73.7200
2025-08-28 06:36:54,535 - INFO - 
Epoch: 9, lr = 0.1
2025-08-28 06:36:54,715 - INFO - Epoch: [9][0/391] Time 0.179 (0.179) Data 0.146 (0.146) Loss 0.5358 (0.5358) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-28 06:36:54,727 - INFO - Pruning info: sparsity=0.303
2025-08-28 06:36:54,727 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:36:56,723 - INFO - Epoch: [9][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.4968 (0.5562) Acc@1 85.938 (81.002) Acc@5 99.219 (99.041)
2025-08-28 06:36:57,867 - INFO - Pruning info: sparsity=0.303
2025-08-28 06:36:57,867 - INFO -   Reactivation rate: 0.0067
2025-08-28 06:36:58,634 - INFO - Epoch: [9][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4939 (0.5551) Acc@1 84.375 (81.001) Acc@5 100.000 (99.024)
2025-08-28 06:37:00,531 - INFO - Epoch: [9][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.6325 (0.5617) Acc@1 78.125 (80.599) Acc@5 95.312 (99.016)
2025-08-28 06:37:00,896 - INFO - Pruning info: sparsity=0.303
2025-08-28 06:37:00,896 - INFO -   Reactivation rate: 0.0051
2025-08-28 06:37:02,437 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.6284 (0.6284) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 06:37:03,265 - INFO - Epoch 9:
2025-08-28 06:37:03,265 - INFO -   Train: acc1: 80.5380 | acc5: 98.9800 | loss: 0.5643 | sparsity: 0.3026 | reactivation_rate: 0.0064
2025-08-28 06:37:03,266 - INFO -   Val:   acc1: 76.1200 | acc5: 98.2500 | loss: 0.7218
2025-08-28 06:37:03,266 - INFO -   LR: 0.100000
2025-08-28 06:37:03,308 - INFO - Checkpoint saved: epoch=9, metric=76.1200
2025-08-28 06:37:03,341 - INFO - 
Epoch: 10, lr = 0.1
2025-08-28 06:37:03,523 - INFO - Epoch: [10][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.4606 (0.4606) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:37:05,299 - INFO - Pruning info: sparsity=0.332
2025-08-28 06:37:05,299 - INFO -   Reactivation rate: 0.0083
2025-08-28 06:37:05,513 - INFO - Epoch: [10][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3264 (0.5269) Acc@1 90.625 (81.552) Acc@5 100.000 (99.010)
2025-08-28 06:37:07,509 - INFO - Epoch: [10][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.4791 (0.5342) Acc@1 87.500 (81.332) Acc@5 99.219 (99.083)
2025-08-28 06:37:08,413 - INFO - Pruning info: sparsity=0.332
2025-08-28 06:37:08,413 - INFO -   Reactivation rate: 0.0054
2025-08-28 06:37:09,438 - INFO - Epoch: [10][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.6818 (0.5423) Acc@1 78.906 (81.250) Acc@5 99.219 (99.079)
2025-08-28 06:37:11,279 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.6843 (0.6843) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 06:37:12,146 - INFO - Epoch 10:
2025-08-28 06:37:12,146 - INFO -   Train: acc1: 81.2240 | acc5: 99.0640 | loss: 0.5433 | sparsity: 0.3316 | reactivation_rate: 0.0062
2025-08-28 06:37:12,146 - INFO -   Val:   acc1: 76.1200 | acc5: 98.6700 | loss: 0.7029
2025-08-28 06:37:12,146 - INFO -   LR: 0.100000
2025-08-28 06:37:12,192 - INFO - 
Epoch: 11, lr = 0.1
2025-08-28 06:37:12,366 - INFO - Epoch: [11][0/391] Time 0.173 (0.173) Data 0.142 (0.142) Loss 0.5569 (0.5569) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:37:12,744 - INFO - Pruning info: sparsity=0.360
2025-08-28 06:37:12,744 - INFO -   Reactivation rate: 0.0107
2025-08-28 06:37:14,379 - INFO - Epoch: [11][100/391] Time 0.028 (0.022) Data 0.000 (0.003) Loss 0.5725 (0.5316) Acc@1 84.375 (81.675) Acc@5 99.219 (99.095)
2025-08-28 06:37:15,940 - INFO - Pruning info: sparsity=0.360
2025-08-28 06:37:15,940 - INFO -   Reactivation rate: 0.0058
2025-08-28 06:37:16,378 - INFO - Epoch: [11][200/391] Time 0.027 (0.021) Data 0.011 (0.002) Loss 0.6006 (0.5317) Acc@1 77.344 (81.611) Acc@5 100.000 (99.048)
2025-08-28 06:37:18,295 - INFO - Epoch: [11][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.6708 (0.5332) Acc@1 78.906 (81.686) Acc@5 96.875 (99.071)
2025-08-28 06:37:19,001 - INFO - Pruning info: sparsity=0.360
2025-08-28 06:37:19,001 - INFO -   Reactivation rate: 0.0042
2025-08-28 06:37:20,120 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.7413 (0.7413) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 06:37:20,963 - INFO - Epoch 11:
2025-08-28 06:37:20,963 - INFO -   Train: acc1: 81.4820 | acc5: 99.0280 | loss: 0.5366 | sparsity: 0.3597 | reactivation_rate: 0.0059
2025-08-28 06:37:20,963 - INFO -   Val:   acc1: 72.8500 | acc5: 98.2400 | loss: 0.8227
2025-08-28 06:37:20,963 - INFO -   LR: 0.100000
2025-08-28 06:37:20,974 - INFO - 
Epoch: 12, lr = 0.1
2025-08-28 06:37:21,177 - INFO - Epoch: [12][0/391] Time 0.202 (0.202) Data 0.172 (0.172) Loss 0.5390 (0.5390) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:37:23,165 - INFO - Epoch: [12][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.5479 (0.5223) Acc@1 83.594 (81.938) Acc@5 100.000 (99.211)
2025-08-28 06:37:23,291 - INFO - Pruning info: sparsity=0.387
2025-08-28 06:37:23,292 - INFO -   Reactivation rate: 0.0070
2025-08-28 06:37:25,045 - INFO - Epoch: [12][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.6323 (0.5169) Acc@1 75.000 (82.276) Acc@5 100.000 (99.098)
2025-08-28 06:37:26,268 - INFO - Pruning info: sparsity=0.387
2025-08-28 06:37:26,269 - INFO -   Reactivation rate: 0.0048
2025-08-28 06:37:26,903 - INFO - Epoch: [12][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.6448 (0.5240) Acc@1 80.469 (82.094) Acc@5 98.438 (99.081)
2025-08-28 06:37:28,757 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.9911 (0.9911) Acc@1 74.219 (74.219) Acc@5 96.875 (96.875)
2025-08-28 06:37:29,574 - INFO - Epoch 12:
2025-08-28 06:37:29,574 - INFO -   Train: acc1: 82.0160 | acc5: 99.0680 | loss: 0.5261 | sparsity: 0.3869 | reactivation_rate: 0.0057
2025-08-28 06:37:29,574 - INFO -   Val:   acc1: 71.5900 | acc5: 96.8000 | loss: 0.9853
2025-08-28 06:37:29,574 - INFO -   LR: 0.100000
2025-08-28 06:37:29,583 - INFO - 
Epoch: 13, lr = 0.1
2025-08-28 06:37:29,754 - INFO - Epoch: [13][0/391] Time 0.170 (0.170) Data 0.139 (0.139) Loss 0.5741 (0.5741) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:37:30,500 - INFO - Pruning info: sparsity=0.413
2025-08-28 06:37:30,500 - INFO -   Reactivation rate: 0.0083
2025-08-28 06:37:31,734 - INFO - Epoch: [13][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.4175 (0.5017) Acc@1 85.156 (82.890) Acc@5 99.219 (99.203)
2025-08-28 06:37:33,603 - INFO - Pruning info: sparsity=0.413
2025-08-28 06:37:33,603 - INFO -   Reactivation rate: 0.0051
2025-08-28 06:37:33,668 - INFO - Epoch: [13][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3835 (0.5148) Acc@1 86.719 (82.451) Acc@5 98.438 (99.110)
2025-08-28 06:37:35,564 - INFO - Epoch: [13][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5878 (0.5164) Acc@1 75.000 (82.309) Acc@5 99.219 (99.146)
2025-08-28 06:37:36,670 - INFO - Pruning info: sparsity=0.413
2025-08-28 06:37:36,670 - INFO -   Reactivation rate: 0.0040
2025-08-28 06:37:37,431 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6023 (0.6023) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:37:38,276 - INFO - Epoch 13:
2025-08-28 06:37:38,276 - INFO -   Train: acc1: 82.1760 | acc5: 99.1240 | loss: 0.5205 | sparsity: 0.4133 | reactivation_rate: 0.0054
2025-08-28 06:37:38,276 - INFO -   Val:   acc1: 78.1100 | acc5: 98.8500 | loss: 0.6693
2025-08-28 06:37:38,276 - INFO -   LR: 0.100000
2025-08-28 06:37:38,324 - INFO - Checkpoint saved: epoch=13, metric=78.1100
2025-08-28 06:37:38,357 - INFO - 
Epoch: 14, lr = 0.1
2025-08-28 06:37:38,542 - INFO - Epoch: [14][0/391] Time 0.184 (0.184) Data 0.164 (0.164) Loss 0.5087 (0.5087) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:37:40,581 - INFO - Epoch: [14][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.5532 (0.5031) Acc@1 84.375 (82.890) Acc@5 98.438 (99.242)
2025-08-28 06:37:41,086 - INFO - Pruning info: sparsity=0.439
2025-08-28 06:37:41,087 - INFO -   Reactivation rate: 0.0062
2025-08-28 06:37:42,559 - INFO - Epoch: [14][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.5372 (0.5022) Acc@1 81.250 (83.022) Acc@5 99.219 (99.238)
2025-08-28 06:37:44,291 - INFO - Pruning info: sparsity=0.439
2025-08-28 06:37:44,291 - INFO -   Reactivation rate: 0.0043
2025-08-28 06:37:44,516 - INFO - Epoch: [14][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4173 (0.5059) Acc@1 83.594 (82.698) Acc@5 100.000 (99.229)
2025-08-28 06:37:46,308 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.9888 (0.9888) Acc@1 68.750 (68.750) Acc@5 97.656 (97.656)
2025-08-28 06:37:47,191 - INFO - Epoch 14:
2025-08-28 06:37:47,191 - INFO -   Train: acc1: 82.5480 | acc5: 99.1780 | loss: 0.5106 | sparsity: 0.4389 | reactivation_rate: 0.0052
2025-08-28 06:37:47,191 - INFO -   Val:   acc1: 71.4100 | acc5: 97.0100 | loss: 0.9039
2025-08-28 06:37:47,191 - INFO -   LR: 0.100000
2025-08-28 06:37:47,201 - INFO - 
Epoch: 15, lr = 0.1
2025-08-28 06:37:47,380 - INFO - Epoch: [15][0/391] Time 0.178 (0.178) Data 0.147 (0.147) Loss 0.4384 (0.4384) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 06:37:48,448 - INFO - Pruning info: sparsity=0.464
2025-08-28 06:37:48,448 - INFO -   Reactivation rate: 0.0069
2025-08-28 06:37:49,295 - INFO - Epoch: [15][100/391] Time 0.017 (0.021) Data 0.001 (0.003) Loss 0.4387 (0.4900) Acc@1 85.156 (83.192) Acc@5 100.000 (99.126)
2025-08-28 06:37:51,253 - INFO - Epoch: [15][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5549 (0.5036) Acc@1 81.250 (82.704) Acc@5 98.438 (99.017)
2025-08-28 06:37:51,541 - INFO - Pruning info: sparsity=0.464
2025-08-28 06:37:51,541 - INFO -   Reactivation rate: 0.0045
2025-08-28 06:37:53,184 - INFO - Epoch: [15][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.5480 (0.5039) Acc@1 85.156 (82.706) Acc@5 99.219 (99.099)
2025-08-28 06:37:54,570 - INFO - Pruning info: sparsity=0.464
2025-08-28 06:37:54,570 - INFO -   Reactivation rate: 0.0036
2025-08-28 06:37:54,965 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.8912 (0.8912) Acc@1 71.875 (71.875) Acc@5 100.000 (100.000)
2025-08-28 06:37:55,820 - INFO - Epoch 15:
2025-08-28 06:37:55,820 - INFO -   Train: acc1: 82.7940 | acc5: 99.0800 | loss: 0.5030 | sparsity: 0.4636 | reactivation_rate: 0.0049
2025-08-28 06:37:55,820 - INFO -   Val:   acc1: 73.2500 | acc5: 98.9000 | loss: 0.8324
2025-08-28 06:37:55,820 - INFO -   LR: 0.100000
2025-08-28 06:37:55,830 - INFO - 
Epoch: 16, lr = 0.1
2025-08-28 06:37:56,038 - INFO - Epoch: [16][0/391] Time 0.207 (0.207) Data 0.162 (0.162) Loss 0.5723 (0.5723) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:37:58,010 - INFO - Epoch: [16][100/391] Time 0.014 (0.022) Data 0.000 (0.003) Loss 0.4635 (0.4956) Acc@1 82.812 (82.944) Acc@5 99.219 (99.180)
2025-08-28 06:37:58,841 - INFO - Pruning info: sparsity=0.488
2025-08-28 06:37:58,842 - INFO -   Reactivation rate: 0.0052
2025-08-28 06:37:59,890 - INFO - Epoch: [16][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4924 (0.4913) Acc@1 81.250 (82.964) Acc@5 99.219 (99.188)
2025-08-28 06:38:01,856 - INFO - Epoch: [16][300/391] Time 0.015 (0.020) Data 0.000 (0.001) Loss 0.5657 (0.4920) Acc@1 80.469 (83.051) Acc@5 100.000 (99.198)
2025-08-28 06:38:01,925 - INFO - Pruning info: sparsity=0.488
2025-08-28 06:38:01,926 - INFO -   Reactivation rate: 0.0038
2025-08-28 06:38:03,700 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4685 (0.4685) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:38:04,555 - INFO - Epoch 16:
2025-08-28 06:38:04,555 - INFO -   Train: acc1: 83.1880 | acc5: 99.2080 | loss: 0.4897 | sparsity: 0.4875 | reactivation_rate: 0.0047
2025-08-28 06:38:04,555 - INFO -   Val:   acc1: 78.5200 | acc5: 99.0200 | loss: 0.6320
2025-08-28 06:38:04,555 - INFO -   LR: 0.100000
2025-08-28 06:38:04,598 - INFO - Checkpoint saved: epoch=16, metric=78.5200
2025-08-28 06:38:04,631 - INFO - 
Epoch: 17, lr = 0.1
2025-08-28 06:38:04,824 - INFO - Epoch: [17][0/391] Time 0.193 (0.193) Data 0.162 (0.162) Loss 0.5059 (0.5059) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 06:38:06,211 - INFO - Pruning info: sparsity=0.511
2025-08-28 06:38:06,211 - INFO -   Reactivation rate: 0.0063
2025-08-28 06:38:06,701 - INFO - Epoch: [17][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4741 (0.4844) Acc@1 83.594 (83.478) Acc@5 98.438 (99.180)
2025-08-28 06:38:08,678 - INFO - Epoch: [17][200/391] Time 0.014 (0.020) Data 0.001 (0.002) Loss 0.4583 (0.4874) Acc@1 82.031 (83.197) Acc@5 99.219 (99.176)
2025-08-28 06:38:09,311 - INFO - Pruning info: sparsity=0.511
2025-08-28 06:38:09,312 - INFO -   Reactivation rate: 0.0043
2025-08-28 06:38:10,616 - INFO - Epoch: [17][300/391] Time 0.023 (0.020) Data 0.007 (0.002) Loss 0.4992 (0.4937) Acc@1 81.250 (83.085) Acc@5 99.219 (99.180)
2025-08-28 06:38:12,419 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6274 (0.6274) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:38:13,265 - INFO - Epoch 17:
2025-08-28 06:38:13,265 - INFO -   Train: acc1: 83.0840 | acc5: 99.1600 | loss: 0.4946 | sparsity: 0.5106 | reactivation_rate: 0.0046
2025-08-28 06:38:13,265 - INFO -   Val:   acc1: 76.9500 | acc5: 98.9800 | loss: 0.7022
2025-08-28 06:38:13,265 - INFO -   LR: 0.100000
2025-08-28 06:38:13,274 - INFO - 
Epoch: 18, lr = 0.1
2025-08-28 06:38:13,470 - INFO - Epoch: [18][0/391] Time 0.195 (0.195) Data 0.177 (0.177) Loss 0.5123 (0.5123) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 06:38:13,487 - INFO - Pruning info: sparsity=0.533
2025-08-28 06:38:13,487 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:38:15,393 - INFO - Epoch: [18][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.4085 (0.4794) Acc@1 88.281 (83.532) Acc@5 100.000 (99.273)
2025-08-28 06:38:16,475 - INFO - Pruning info: sparsity=0.533
2025-08-28 06:38:16,475 - INFO -   Reactivation rate: 0.0046
2025-08-28 06:38:17,246 - INFO - Epoch: [18][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4712 (0.4838) Acc@1 82.812 (83.380) Acc@5 99.219 (99.258)
2025-08-28 06:38:19,232 - INFO - Epoch: [18][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5967 (0.4810) Acc@1 79.688 (83.435) Acc@5 97.656 (99.245)
2025-08-28 06:38:19,648 - INFO - Pruning info: sparsity=0.533
2025-08-28 06:38:19,648 - INFO -   Reactivation rate: 0.0032
2025-08-28 06:38:21,116 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5584 (0.5584) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:38:21,946 - INFO - Epoch 18:
2025-08-28 06:38:21,947 - INFO -   Train: acc1: 83.3480 | acc5: 99.2160 | loss: 0.4836 | sparsity: 0.5330 | reactivation_rate: 0.0042
2025-08-28 06:38:21,947 - INFO -   Val:   acc1: 79.7300 | acc5: 99.1200 | loss: 0.6036
2025-08-28 06:38:21,947 - INFO -   LR: 0.100000
2025-08-28 06:38:21,991 - INFO - Checkpoint saved: epoch=18, metric=79.7300
2025-08-28 06:38:22,023 - INFO - 
Epoch: 19, lr = 0.1
2025-08-28 06:38:22,231 - INFO - Epoch: [19][0/391] Time 0.206 (0.206) Data 0.178 (0.178) Loss 0.3172 (0.3172) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:38:24,031 - INFO - Pruning info: sparsity=0.555
2025-08-28 06:38:24,031 - INFO -   Reactivation rate: 0.0052
2025-08-28 06:38:24,223 - INFO - Epoch: [19][100/391] Time 0.022 (0.022) Data 0.000 (0.003) Loss 0.4367 (0.4754) Acc@1 82.812 (83.516) Acc@5 100.000 (99.242)
2025-08-28 06:38:26,145 - INFO - Epoch: [19][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3374 (0.4793) Acc@1 87.500 (83.469) Acc@5 100.000 (99.242)
2025-08-28 06:38:27,151 - INFO - Pruning info: sparsity=0.555
2025-08-28 06:38:27,151 - INFO -   Reactivation rate: 0.0035
2025-08-28 06:38:28,090 - INFO - Epoch: [19][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3131 (0.4832) Acc@1 90.625 (83.373) Acc@5 100.000 (99.232)
2025-08-28 06:38:29,945 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5034 (0.5034) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:38:30,823 - INFO - Epoch 19:
2025-08-28 06:38:30,823 - INFO -   Train: acc1: 83.4320 | acc5: 99.2380 | loss: 0.4811 | sparsity: 0.5545 | reactivation_rate: 0.0041
2025-08-28 06:38:30,823 - INFO -   Val:   acc1: 79.2300 | acc5: 98.0900 | loss: 0.6353
2025-08-28 06:38:30,823 - INFO -   LR: 0.100000
2025-08-28 06:38:30,833 - INFO - 
Epoch: 20, lr = 0.1
2025-08-28 06:38:31,014 - INFO - Epoch: [20][0/391] Time 0.181 (0.181) Data 0.149 (0.149) Loss 0.3738 (0.3738) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:38:31,427 - INFO - Pruning info: sparsity=0.575
2025-08-28 06:38:31,427 - INFO -   Reactivation rate: 0.0067
2025-08-28 06:38:32,999 - INFO - Epoch: [20][100/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.4308 (0.4736) Acc@1 88.281 (83.400) Acc@5 98.438 (99.304)
2025-08-28 06:38:34,470 - INFO - Pruning info: sparsity=0.575
2025-08-28 06:38:34,470 - INFO -   Reactivation rate: 0.0038
2025-08-28 06:38:34,893 - INFO - Epoch: [20][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.5012 (0.4800) Acc@1 78.906 (83.403) Acc@5 100.000 (99.285)
2025-08-28 06:38:36,823 - INFO - Epoch: [20][300/391] Time 0.025 (0.020) Data 0.012 (0.002) Loss 0.4269 (0.4764) Acc@1 85.156 (83.607) Acc@5 99.219 (99.258)
2025-08-28 06:38:37,577 - INFO - Pruning info: sparsity=0.575
2025-08-28 06:38:37,577 - INFO -   Reactivation rate: 0.0030
2025-08-28 06:38:38,627 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6423 (0.6423) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-28 06:38:39,492 - INFO - Epoch 20:
2025-08-28 06:38:39,493 - INFO -   Train: acc1: 83.4420 | acc5: 99.2420 | loss: 0.4795 | sparsity: 0.5753 | reactivation_rate: 0.0038
2025-08-28 06:38:39,493 - INFO -   Val:   acc1: 78.6700 | acc5: 98.7800 | loss: 0.6310
2025-08-28 06:38:39,493 - INFO -   LR: 0.100000
2025-08-28 06:38:39,537 - INFO - 
Epoch: 21, lr = 0.1
2025-08-28 06:38:39,725 - INFO - Epoch: [21][0/391] Time 0.187 (0.187) Data 0.164 (0.164) Loss 0.3554 (0.3554) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:38:41,649 - INFO - Epoch: [21][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4572 (0.4576) Acc@1 84.375 (84.367) Acc@5 99.219 (99.350)
2025-08-28 06:38:41,787 - INFO - Pruning info: sparsity=0.595
2025-08-28 06:38:41,787 - INFO -   Reactivation rate: 0.0045
2025-08-28 06:38:43,664 - INFO - Epoch: [21][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.5246 (0.4674) Acc@1 82.031 (83.881) Acc@5 100.000 (99.308)
2025-08-28 06:38:44,950 - INFO - Pruning info: sparsity=0.595
2025-08-28 06:38:44,950 - INFO -   Reactivation rate: 0.0032
2025-08-28 06:38:45,541 - INFO - Epoch: [21][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4149 (0.4696) Acc@1 83.594 (83.809) Acc@5 100.000 (99.278)
2025-08-28 06:38:47,418 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.6479 (0.6479) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-28 06:38:48,257 - INFO - Epoch 21:
2025-08-28 06:38:48,257 - INFO -   Train: acc1: 83.6400 | acc5: 99.2460 | loss: 0.4740 | sparsity: 0.5954 | reactivation_rate: 0.0036
2025-08-28 06:38:48,257 - INFO -   Val:   acc1: 77.0700 | acc5: 97.9700 | loss: 0.6977
2025-08-28 06:38:48,257 - INFO -   LR: 0.100000
2025-08-28 06:38:48,268 - INFO - 
Epoch: 22, lr = 0.1
2025-08-28 06:38:48,446 - INFO - Epoch: [22][0/391] Time 0.177 (0.177) Data 0.146 (0.146) Loss 0.3874 (0.3874) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:38:49,168 - INFO - Pruning info: sparsity=0.615
2025-08-28 06:38:49,168 - INFO -   Reactivation rate: 0.0048
2025-08-28 06:38:50,420 - INFO - Epoch: [22][100/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.4829 (0.4494) Acc@1 78.125 (84.514) Acc@5 99.219 (99.312)
2025-08-28 06:38:52,329 - INFO - Pruning info: sparsity=0.615
2025-08-28 06:38:52,329 - INFO -   Reactivation rate: 0.0031
2025-08-28 06:38:52,385 - INFO - Epoch: [22][200/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.5012 (0.4569) Acc@1 83.594 (84.418) Acc@5 99.219 (99.273)
2025-08-28 06:38:54,240 - INFO - Epoch: [22][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3788 (0.4577) Acc@1 88.281 (84.359) Acc@5 99.219 (99.263)
2025-08-28 06:38:55,348 - INFO - Pruning info: sparsity=0.615
2025-08-28 06:38:55,349 - INFO -   Reactivation rate: 0.0026
2025-08-28 06:38:56,130 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.7949 (0.7949) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 06:38:57,007 - INFO - Epoch 22:
2025-08-28 06:38:57,007 - INFO -   Train: acc1: 84.2520 | acc5: 99.2700 | loss: 0.4599 | sparsity: 0.6148 | reactivation_rate: 0.0033
2025-08-28 06:38:57,007 - INFO -   Val:   acc1: 77.5000 | acc5: 98.9000 | loss: 0.7405
2025-08-28 06:38:57,007 - INFO -   LR: 0.100000
2025-08-28 06:38:57,019 - INFO - 
Epoch: 23, lr = 0.1
2025-08-28 06:38:57,222 - INFO - Epoch: [23][0/391] Time 0.203 (0.203) Data 0.184 (0.184) Loss 0.4684 (0.4684) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 06:38:59,189 - INFO - Epoch: [23][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.4359 (0.4455) Acc@1 86.719 (84.855) Acc@5 98.438 (99.118)
2025-08-28 06:38:59,669 - INFO - Pruning info: sparsity=0.633
2025-08-28 06:38:59,669 - INFO -   Reactivation rate: 0.0039
2025-08-28 06:39:01,116 - INFO - Epoch: [23][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.4940 (0.4630) Acc@1 83.594 (84.235) Acc@5 98.438 (99.149)
2025-08-28 06:39:02,848 - INFO - Pruning info: sparsity=0.633
2025-08-28 06:39:02,848 - INFO -   Reactivation rate: 0.0026
2025-08-28 06:39:03,102 - INFO - Epoch: [23][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3934 (0.4613) Acc@1 87.500 (84.269) Acc@5 99.219 (99.190)
2025-08-28 06:39:04,904 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5314 (0.5314) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:39:05,775 - INFO - Epoch 23:
2025-08-28 06:39:05,775 - INFO -   Train: acc1: 84.1660 | acc5: 99.2060 | loss: 0.4624 | sparsity: 0.6334 | reactivation_rate: 0.0032
2025-08-28 06:39:05,775 - INFO -   Val:   acc1: 78.0000 | acc5: 98.4900 | loss: 0.6873
2025-08-28 06:39:05,775 - INFO -   LR: 0.100000
2025-08-28 06:39:05,784 - INFO - 
Epoch: 24, lr = 0.1
2025-08-28 06:39:05,961 - INFO - Epoch: [24][0/391] Time 0.177 (0.177) Data 0.153 (0.153) Loss 0.3997 (0.3997) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 06:39:07,040 - INFO - Pruning info: sparsity=0.651
2025-08-28 06:39:07,040 - INFO -   Reactivation rate: 0.0038
2025-08-28 06:39:07,918 - INFO - Epoch: [24][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.4563 (0.4568) Acc@1 81.250 (84.228) Acc@5 99.219 (99.373)
2025-08-28 06:39:09,786 - INFO - Epoch: [24][200/391] Time 0.051 (0.020) Data 0.020 (0.003) Loss 0.5765 (0.4624) Acc@1 82.031 (84.188) Acc@5 97.656 (99.285)
2025-08-28 06:39:10,065 - INFO - Pruning info: sparsity=0.651
2025-08-28 06:39:10,065 - INFO -   Reactivation rate: 0.0028
2025-08-28 06:39:11,695 - INFO - Epoch: [24][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5036 (0.4610) Acc@1 78.125 (84.149) Acc@5 99.219 (99.297)
2025-08-28 06:39:13,204 - INFO - Pruning info: sparsity=0.651
2025-08-28 06:39:13,204 - INFO -   Reactivation rate: 0.0024
2025-08-28 06:39:13,596 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7622 (0.7622) Acc@1 71.875 (71.875) Acc@5 97.656 (97.656)
2025-08-28 06:39:14,448 - INFO - Epoch 24:
2025-08-28 06:39:14,449 - INFO -   Train: acc1: 84.1240 | acc5: 99.2840 | loss: 0.4606 | sparsity: 0.6513 | reactivation_rate: 0.0029
2025-08-28 06:39:14,449 - INFO -   Val:   acc1: 76.3000 | acc5: 98.0500 | loss: 0.7771
2025-08-28 06:39:14,449 - INFO -   LR: 0.100000
2025-08-28 06:39:14,459 - INFO - 
Epoch: 25, lr = 0.1
2025-08-28 06:39:14,656 - INFO - Epoch: [25][0/391] Time 0.196 (0.196) Data 0.173 (0.173) Loss 0.4807 (0.4807) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 06:39:16,718 - INFO - Epoch: [25][100/391] Time 0.014 (0.022) Data 0.000 (0.003) Loss 0.5543 (0.4322) Acc@1 83.594 (84.831) Acc@5 98.438 (99.428)
2025-08-28 06:39:17,554 - INFO - Pruning info: sparsity=0.669
2025-08-28 06:39:17,554 - INFO -   Reactivation rate: 0.0032
2025-08-28 06:39:18,687 - INFO - Epoch: [25][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.6149 (0.4450) Acc@1 77.344 (84.402) Acc@5 98.438 (99.394)
2025-08-28 06:39:20,667 - INFO - Epoch: [25][300/391] Time 0.027 (0.021) Data 0.012 (0.002) Loss 0.5018 (0.4451) Acc@1 85.938 (84.546) Acc@5 98.438 (99.364)
2025-08-28 06:39:20,758 - INFO - Pruning info: sparsity=0.669
2025-08-28 06:39:20,758 - INFO -   Reactivation rate: 0.0021
2025-08-28 06:39:22,480 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6552 (0.6552) Acc@1 72.656 (72.656) Acc@5 99.219 (99.219)
2025-08-28 06:39:23,342 - INFO - Epoch 25:
2025-08-28 06:39:23,342 - INFO -   Train: acc1: 84.5740 | acc5: 99.3600 | loss: 0.4470 | sparsity: 0.6685 | reactivation_rate: 0.0028
2025-08-28 06:39:23,342 - INFO -   Val:   acc1: 75.6700 | acc5: 98.3000 | loss: 0.7195
2025-08-28 06:39:23,342 - INFO -   LR: 0.100000
2025-08-28 06:39:23,351 - INFO - 
Epoch: 26, lr = 0.1
2025-08-28 06:39:23,557 - INFO - Epoch: [26][0/391] Time 0.205 (0.205) Data 0.177 (0.177) Loss 0.3579 (0.3579) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 06:39:24,984 - INFO - Pruning info: sparsity=0.685
2025-08-28 06:39:24,984 - INFO -   Reactivation rate: 0.0035
2025-08-28 06:39:25,516 - INFO - Epoch: [26][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4914 (0.4440) Acc@1 84.375 (84.630) Acc@5 99.219 (99.373)
2025-08-28 06:39:27,397 - INFO - Epoch: [26][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.5134 (0.4492) Acc@1 82.812 (84.507) Acc@5 99.219 (99.343)
2025-08-28 06:39:28,001 - INFO - Pruning info: sparsity=0.685
2025-08-28 06:39:28,002 - INFO -   Reactivation rate: 0.0025
2025-08-28 06:39:29,308 - INFO - Epoch: [26][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.7085 (0.4553) Acc@1 71.094 (84.258) Acc@5 99.219 (99.354)
2025-08-28 06:39:31,174 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.4939 (0.4939) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:39:32,002 - INFO - Epoch 26:
2025-08-28 06:39:32,002 - INFO -   Train: acc1: 84.4760 | acc5: 99.3460 | loss: 0.4483 | sparsity: 0.6851 | reactivation_rate: 0.0027
2025-08-28 06:39:32,002 - INFO -   Val:   acc1: 79.5300 | acc5: 98.8800 | loss: 0.6283
2025-08-28 06:39:32,002 - INFO -   LR: 0.100000
2025-08-28 06:39:32,015 - INFO - 
Epoch: 27, lr = 0.1
2025-08-28 06:39:32,163 - INFO - Epoch: [27][0/391] Time 0.146 (0.146) Data 0.130 (0.130) Loss 0.4383 (0.4383) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:39:32,248 - INFO - Pruning info: sparsity=0.701
2025-08-28 06:39:32,248 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:39:34,106 - INFO - Epoch: [27][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.6440 (0.4239) Acc@1 76.562 (85.334) Acc@5 99.219 (99.343)
2025-08-28 06:39:35,256 - INFO - Pruning info: sparsity=0.701
2025-08-28 06:39:35,257 - INFO -   Reactivation rate: 0.0028
2025-08-28 06:39:35,992 - INFO - Epoch: [27][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4180 (0.4325) Acc@1 88.281 (85.257) Acc@5 99.219 (99.401)
2025-08-28 06:39:37,970 - INFO - Epoch: [27][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4642 (0.4379) Acc@1 84.375 (84.912) Acc@5 98.438 (99.395)
2025-08-28 06:39:38,418 - INFO - Pruning info: sparsity=0.701
2025-08-28 06:39:38,419 - INFO -   Reactivation rate: 0.0021
2025-08-28 06:39:39,798 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6535 (0.6535) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-28 06:39:40,676 - INFO - Epoch 27:
2025-08-28 06:39:40,676 - INFO -   Train: acc1: 84.7340 | acc5: 99.3540 | loss: 0.4442 | sparsity: 0.7010 | reactivation_rate: 0.0025
2025-08-28 06:39:40,676 - INFO -   Val:   acc1: 76.8300 | acc5: 98.8000 | loss: 0.6846
2025-08-28 06:39:40,676 - INFO -   LR: 0.100000
2025-08-28 06:39:40,686 - INFO - 
Epoch: 28, lr = 0.1
2025-08-28 06:39:40,875 - INFO - Epoch: [28][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.3664 (0.3664) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-28 06:39:42,638 - INFO - Pruning info: sparsity=0.716
2025-08-28 06:39:42,638 - INFO -   Reactivation rate: 0.0029
2025-08-28 06:39:42,788 - INFO - Epoch: [28][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4353 (0.4408) Acc@1 84.375 (84.870) Acc@5 100.000 (99.397)
2025-08-28 06:39:44,603 - INFO - Epoch: [28][200/391] Time 0.027 (0.019) Data 0.000 (0.002) Loss 0.4732 (0.4408) Acc@1 85.156 (84.760) Acc@5 100.000 (99.390)
2025-08-28 06:39:45,566 - INFO - Pruning info: sparsity=0.716
2025-08-28 06:39:45,566 - INFO -   Reactivation rate: 0.0024
2025-08-28 06:39:46,480 - INFO - Epoch: [28][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.3772 (0.4426) Acc@1 86.719 (84.658) Acc@5 100.000 (99.374)
2025-08-28 06:39:48,282 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.4189 (0.4189) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 06:39:49,142 - INFO - Epoch 28:
2025-08-28 06:39:49,142 - INFO -   Train: acc1: 84.5400 | acc5: 99.3980 | loss: 0.4446 | sparsity: 0.7162 | reactivation_rate: 0.0024
2025-08-28 06:39:49,143 - INFO -   Val:   acc1: 82.9100 | acc5: 99.2200 | loss: 0.5059
2025-08-28 06:39:49,143 - INFO -   LR: 0.100000
2025-08-28 06:39:49,189 - INFO - Checkpoint saved: epoch=28, metric=82.9100
2025-08-28 06:39:49,222 - INFO - 
Epoch: 29, lr = 0.1
2025-08-28 06:39:49,416 - INFO - Epoch: [29][0/391] Time 0.192 (0.192) Data 0.157 (0.157) Loss 0.5337 (0.5337) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:39:49,753 - INFO - Pruning info: sparsity=0.731
2025-08-28 06:39:49,753 - INFO -   Reactivation rate: 0.0032
2025-08-28 06:39:51,274 - INFO - Epoch: [29][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3823 (0.4236) Acc@1 87.500 (85.489) Acc@5 99.219 (99.350)
2025-08-28 06:39:52,794 - INFO - Pruning info: sparsity=0.731
2025-08-28 06:39:52,794 - INFO -   Reactivation rate: 0.0022
2025-08-28 06:39:53,135 - INFO - Epoch: [29][200/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.5041 (0.4305) Acc@1 83.594 (85.246) Acc@5 100.000 (99.382)
2025-08-28 06:39:55,063 - INFO - Epoch: [29][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.5156 (0.4360) Acc@1 82.031 (84.949) Acc@5 99.219 (99.398)
2025-08-28 06:39:55,875 - INFO - Pruning info: sparsity=0.731
2025-08-28 06:39:55,875 - INFO -   Reactivation rate: 0.0019
2025-08-28 06:39:56,896 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6558 (0.6558) Acc@1 78.125 (78.125) Acc@5 96.094 (96.094)
2025-08-28 06:39:57,727 - INFO - Epoch 29:
2025-08-28 06:39:57,727 - INFO -   Train: acc1: 84.9520 | acc5: 99.3780 | loss: 0.4365 | sparsity: 0.7308 | reactivation_rate: 0.0021
2025-08-28 06:39:57,727 - INFO -   Val:   acc1: 74.4800 | acc5: 98.2600 | loss: 0.8010
2025-08-28 06:39:57,727 - INFO -   LR: 0.100000
2025-08-28 06:39:57,738 - INFO - 
Epoch: 30, lr = 0.1
2025-08-28 06:39:57,915 - INFO - Epoch: [30][0/391] Time 0.176 (0.176) Data 0.152 (0.152) Loss 0.3870 (0.3870) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 06:39:59,940 - INFO - Epoch: [30][100/391] Time 0.016 (0.022) Data 0.000 (0.004) Loss 0.3953 (0.4376) Acc@1 86.719 (84.816) Acc@5 100.000 (99.381)
2025-08-28 06:40:00,131 - INFO - Pruning info: sparsity=0.745
2025-08-28 06:40:00,131 - INFO -   Reactivation rate: 0.0023
2025-08-28 06:40:01,885 - INFO - Epoch: [30][200/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.4424 (0.4383) Acc@1 83.594 (84.888) Acc@5 99.219 (99.335)
2025-08-28 06:40:03,172 - INFO - Pruning info: sparsity=0.745
2025-08-28 06:40:03,172 - INFO -   Reactivation rate: 0.0017
2025-08-28 06:40:03,764 - INFO - Epoch: [30][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4871 (0.4391) Acc@1 81.250 (84.772) Acc@5 98.438 (99.354)
2025-08-28 06:40:05,683 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5555 (0.5555) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:40:06,554 - INFO - Epoch 30:
2025-08-28 06:40:06,554 - INFO -   Train: acc1: 84.7900 | acc5: 99.3660 | loss: 0.4406 | sparsity: 0.7448 | reactivation_rate: 0.0020
2025-08-28 06:40:06,554 - INFO -   Val:   acc1: 80.0500 | acc5: 98.8200 | loss: 0.5793
2025-08-28 06:40:06,554 - INFO -   LR: 0.100000
2025-08-28 06:40:06,606 - INFO - 
Epoch: 31, lr = 0.1
2025-08-28 06:40:06,798 - INFO - Epoch: [31][0/391] Time 0.191 (0.191) Data 0.162 (0.162) Loss 0.5401 (0.5401) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:40:07,644 - INFO - Pruning info: sparsity=0.758
2025-08-28 06:40:07,644 - INFO -   Reactivation rate: 0.0024
2025-08-28 06:40:08,863 - INFO - Epoch: [31][100/391] Time 0.022 (0.022) Data 0.000 (0.003) Loss 0.3562 (0.4271) Acc@1 86.719 (85.326) Acc@5 99.219 (99.420)
2025-08-28 06:40:10,700 - INFO - Pruning info: sparsity=0.758
2025-08-28 06:40:10,700 - INFO -   Reactivation rate: 0.0019
2025-08-28 06:40:10,752 - INFO - Epoch: [31][200/391] Time 0.033 (0.021) Data 0.000 (0.002) Loss 0.3939 (0.4295) Acc@1 85.156 (85.125) Acc@5 100.000 (99.366)
2025-08-28 06:40:12,696 - INFO - Epoch: [31][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3640 (0.4308) Acc@1 87.500 (85.138) Acc@5 99.219 (99.354)
2025-08-28 06:40:13,853 - INFO - Pruning info: sparsity=0.758
2025-08-28 06:40:13,853 - INFO -   Reactivation rate: 0.0015
2025-08-28 06:40:14,572 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4344 (0.4344) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:40:15,454 - INFO - Epoch 31:
2025-08-28 06:40:15,454 - INFO -   Train: acc1: 85.0000 | acc5: 99.3400 | loss: 0.4357 | sparsity: 0.7582 | reactivation_rate: 0.0019
2025-08-28 06:40:15,454 - INFO -   Val:   acc1: 80.2800 | acc5: 98.9000 | loss: 0.5994
2025-08-28 06:40:15,454 - INFO -   LR: 0.100000
2025-08-28 06:40:15,464 - INFO - 
Epoch: 32, lr = 0.1
2025-08-28 06:40:15,627 - INFO - Epoch: [32][0/391] Time 0.162 (0.162) Data 0.135 (0.135) Loss 0.5266 (0.5266) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 06:40:17,596 - INFO - Epoch: [32][100/391] Time 0.011 (0.021) Data 0.000 (0.005) Loss 0.3396 (0.4122) Acc@1 86.719 (85.821) Acc@5 100.000 (99.428)
2025-08-28 06:40:18,068 - INFO - Pruning info: sparsity=0.771
2025-08-28 06:40:18,068 - INFO -   Reactivation rate: 0.0020
2025-08-28 06:40:19,471 - INFO - Epoch: [32][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.4128 (0.4173) Acc@1 83.594 (85.669) Acc@5 99.219 (99.429)
2025-08-28 06:40:21,135 - INFO - Pruning info: sparsity=0.771
2025-08-28 06:40:21,135 - INFO -   Reactivation rate: 0.0016
2025-08-28 06:40:21,378 - INFO - Epoch: [32][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4132 (0.4253) Acc@1 89.062 (85.421) Acc@5 100.000 (99.374)
2025-08-28 06:40:23,269 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5970 (0.5970) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:40:24,139 - INFO - Epoch 32:
2025-08-28 06:40:24,140 - INFO -   Train: acc1: 85.2320 | acc5: 99.3740 | loss: 0.4282 | sparsity: 0.7710 | reactivation_rate: 0.0017
2025-08-28 06:40:24,140 - INFO -   Val:   acc1: 77.8900 | acc5: 97.9700 | loss: 0.7035
2025-08-28 06:40:24,140 - INFO -   LR: 0.100000
2025-08-28 06:40:24,151 - INFO - 
Epoch: 33, lr = 0.1
2025-08-28 06:40:24,339 - INFO - Epoch: [33][0/391] Time 0.186 (0.186) Data 0.169 (0.169) Loss 0.3214 (0.3214) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:40:25,542 - INFO - Pruning info: sparsity=0.783
2025-08-28 06:40:25,542 - INFO -   Reactivation rate: 0.0019
2025-08-28 06:40:26,443 - INFO - Epoch: [33][100/391] Time 0.022 (0.023) Data 0.000 (0.003) Loss 0.4008 (0.4290) Acc@1 89.062 (85.079) Acc@5 100.000 (99.420)
2025-08-28 06:40:28,352 - INFO - Epoch: [33][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.4739 (0.4219) Acc@1 82.031 (85.292) Acc@5 99.219 (99.456)
2025-08-28 06:40:28,667 - INFO - Pruning info: sparsity=0.783
2025-08-28 06:40:28,667 - INFO -   Reactivation rate: 0.0016
2025-08-28 06:40:30,281 - INFO - Epoch: [33][300/391] Time 0.019 (0.020) Data 0.002 (0.002) Loss 0.4509 (0.4226) Acc@1 84.375 (85.307) Acc@5 99.219 (99.432)
2025-08-28 06:40:31,740 - INFO - Pruning info: sparsity=0.783
2025-08-28 06:40:31,740 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:40:32,121 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5368 (0.5368) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:40:32,976 - INFO - Epoch 33:
2025-08-28 06:40:32,976 - INFO -   Train: acc1: 85.1220 | acc5: 99.4100 | loss: 0.4291 | sparsity: 0.7832 | reactivation_rate: 0.0016
2025-08-28 06:40:32,976 - INFO -   Val:   acc1: 80.4100 | acc5: 99.0400 | loss: 0.5950
2025-08-28 06:40:32,976 - INFO -   LR: 0.100000
2025-08-28 06:40:32,985 - INFO - 
Epoch: 34, lr = 0.1
2025-08-28 06:40:33,156 - INFO - Epoch: [34][0/391] Time 0.170 (0.170) Data 0.149 (0.149) Loss 0.5153 (0.5153) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:40:35,150 - INFO - Epoch: [34][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3969 (0.4136) Acc@1 85.156 (86.007) Acc@5 100.000 (99.428)
2025-08-28 06:40:36,028 - INFO - Pruning info: sparsity=0.795
2025-08-28 06:40:36,029 - INFO -   Reactivation rate: 0.0018
2025-08-28 06:40:37,025 - INFO - Epoch: [34][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3498 (0.4168) Acc@1 89.844 (85.728) Acc@5 99.219 (99.429)
2025-08-28 06:40:39,008 - INFO - Epoch: [34][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5572 (0.4219) Acc@1 81.250 (85.585) Acc@5 97.656 (99.395)
2025-08-28 06:40:39,116 - INFO - Pruning info: sparsity=0.795
2025-08-28 06:40:39,117 - INFO -   Reactivation rate: 0.0014
2025-08-28 06:40:40,905 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.7736 (0.7736) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 06:40:41,744 - INFO - Epoch 34:
2025-08-28 06:40:41,744 - INFO -   Train: acc1: 85.2520 | acc5: 99.3940 | loss: 0.4296 | sparsity: 0.7948 | reactivation_rate: 0.0015
2025-08-28 06:40:41,744 - INFO -   Val:   acc1: 75.8700 | acc5: 98.7900 | loss: 0.7780
2025-08-28 06:40:41,744 - INFO -   LR: 0.100000
2025-08-28 06:40:41,756 - INFO - 
Epoch: 35, lr = 0.1
2025-08-28 06:40:41,948 - INFO - Epoch: [35][0/391] Time 0.192 (0.192) Data 0.166 (0.166) Loss 0.3155 (0.3155) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-28 06:40:43,522 - INFO - Pruning info: sparsity=0.806
2025-08-28 06:40:43,522 - INFO -   Reactivation rate: 0.0016
2025-08-28 06:40:44,038 - INFO - Epoch: [35][100/391] Time 0.022 (0.023) Data 0.000 (0.003) Loss 0.5254 (0.4220) Acc@1 82.031 (85.149) Acc@5 98.438 (99.335)
2025-08-28 06:40:46,093 - INFO - Epoch: [35][200/391] Time 0.014 (0.022) Data 0.000 (0.002) Loss 0.4057 (0.4174) Acc@1 85.938 (85.432) Acc@5 100.000 (99.386)
2025-08-28 06:40:46,793 - INFO - Pruning info: sparsity=0.806
2025-08-28 06:40:46,793 - INFO -   Reactivation rate: 0.0015
2025-08-28 06:40:48,093 - INFO - Epoch: [35][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.3165 (0.4242) Acc@1 89.062 (85.320) Acc@5 100.000 (99.351)
2025-08-28 06:40:49,950 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5714 (0.5714) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:40:50,808 - INFO - Epoch 35:
2025-08-28 06:40:50,809 - INFO -   Train: acc1: 85.2640 | acc5: 99.3680 | loss: 0.4257 | sparsity: 0.8059 | reactivation_rate: 0.0013
2025-08-28 06:40:50,809 - INFO -   Val:   acc1: 80.0300 | acc5: 98.6100 | loss: 0.6150
2025-08-28 06:40:50,809 - INFO -   LR: 0.100000
2025-08-28 06:40:50,819 - INFO - 
Epoch: 36, lr = 0.1
2025-08-28 06:40:50,999 - INFO - Epoch: [36][0/391] Time 0.180 (0.180) Data 0.157 (0.157) Loss 0.3596 (0.3596) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:40:51,072 - INFO - Pruning info: sparsity=0.816
2025-08-28 06:40:51,073 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:40:52,913 - INFO - Epoch: [36][100/391] Time 0.030 (0.021) Data 0.000 (0.003) Loss 0.3659 (0.4244) Acc@1 85.938 (85.528) Acc@5 100.000 (99.435)
2025-08-28 06:40:54,100 - INFO - Pruning info: sparsity=0.816
2025-08-28 06:40:54,100 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:40:54,836 - INFO - Epoch: [36][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3189 (0.4245) Acc@1 89.844 (85.409) Acc@5 100.000 (99.401)
2025-08-28 06:40:56,678 - INFO - Epoch: [36][300/391] Time 0.030 (0.019) Data 0.000 (0.002) Loss 0.4436 (0.4275) Acc@1 84.375 (85.224) Acc@5 100.000 (99.411)
2025-08-28 06:40:57,143 - INFO - Pruning info: sparsity=0.816
2025-08-28 06:40:57,144 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:40:58,541 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.4857 (0.4857) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:40:59,369 - INFO - Epoch 36:
2025-08-28 06:40:59,370 - INFO -   Train: acc1: 85.2200 | acc5: 99.4180 | loss: 0.4284 | sparsity: 0.8164 | reactivation_rate: 0.0013
2025-08-28 06:40:59,370 - INFO -   Val:   acc1: 81.5000 | acc5: 99.1500 | loss: 0.5350
2025-08-28 06:40:59,370 - INFO -   LR: 0.100000
2025-08-28 06:40:59,382 - INFO - 
Epoch: 37, lr = 0.1
2025-08-28 06:40:59,547 - INFO - Epoch: [37][0/391] Time 0.163 (0.163) Data 0.142 (0.142) Loss 0.3648 (0.3648) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:41:01,458 - INFO - Pruning info: sparsity=0.826
2025-08-28 06:41:01,458 - INFO -   Reactivation rate: 0.0014
2025-08-28 06:41:01,601 - INFO - Epoch: [37][100/391] Time 0.018 (0.022) Data 0.003 (0.002) Loss 0.4314 (0.4304) Acc@1 85.156 (85.172) Acc@5 100.000 (99.389)
2025-08-28 06:41:03,463 - INFO - Epoch: [37][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4363 (0.4373) Acc@1 85.156 (84.939) Acc@5 99.219 (99.363)
2025-08-28 06:41:04,488 - INFO - Pruning info: sparsity=0.826
2025-08-28 06:41:04,489 - INFO -   Reactivation rate: 0.0011
2025-08-28 06:41:05,416 - INFO - Epoch: [37][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5764 (0.4308) Acc@1 82.031 (85.185) Acc@5 99.219 (99.382)
2025-08-28 06:41:07,302 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.4437 (0.4437) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:41:08,150 - INFO - Epoch 37:
2025-08-28 06:41:08,150 - INFO -   Train: acc1: 85.0900 | acc5: 99.3800 | loss: 0.4336 | sparsity: 0.8264 | reactivation_rate: 0.0012
2025-08-28 06:41:08,150 - INFO -   Val:   acc1: 84.2200 | acc5: 99.2900 | loss: 0.4758
2025-08-28 06:41:08,150 - INFO -   LR: 0.100000
2025-08-28 06:41:08,195 - INFO - Checkpoint saved: epoch=37, metric=84.2200
2025-08-28 06:41:08,226 - INFO - 
Epoch: 38, lr = 0.1
2025-08-28 06:41:08,421 - INFO - Epoch: [38][0/391] Time 0.195 (0.195) Data 0.168 (0.168) Loss 0.3417 (0.3417) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:41:08,778 - INFO - Pruning info: sparsity=0.836
2025-08-28 06:41:08,779 - INFO -   Reactivation rate: 0.0015
2025-08-28 06:41:10,392 - INFO - Epoch: [38][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.4621 (0.4195) Acc@1 83.594 (85.535) Acc@5 99.219 (99.381)
2025-08-28 06:41:11,996 - INFO - Pruning info: sparsity=0.836
2025-08-28 06:41:11,996 - INFO -   Reactivation rate: 0.0011
2025-08-28 06:41:12,360 - INFO - Epoch: [38][200/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.3945 (0.4171) Acc@1 84.375 (85.739) Acc@5 100.000 (99.468)
2025-08-28 06:41:14,284 - INFO - Epoch: [38][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4894 (0.4199) Acc@1 82.812 (85.618) Acc@5 100.000 (99.481)
2025-08-28 06:41:15,099 - INFO - Pruning info: sparsity=0.836
2025-08-28 06:41:15,100 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:41:16,228 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.5081 (0.5081) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 06:41:17,071 - INFO - Epoch 38:
2025-08-28 06:41:17,072 - INFO -   Train: acc1: 85.5760 | acc5: 99.4480 | loss: 0.4212 | sparsity: 0.8359 | reactivation_rate: 0.0011
2025-08-28 06:41:17,072 - INFO -   Val:   acc1: 81.6200 | acc5: 98.8300 | loss: 0.5591
2025-08-28 06:41:17,072 - INFO -   LR: 0.100000
2025-08-28 06:41:17,082 - INFO - 
Epoch: 39, lr = 0.1
2025-08-28 06:41:17,279 - INFO - Epoch: [39][0/391] Time 0.196 (0.196) Data 0.173 (0.173) Loss 0.3479 (0.3479) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:41:19,166 - INFO - Epoch: [39][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4407 (0.4095) Acc@1 83.594 (85.883) Acc@5 98.438 (99.466)
2025-08-28 06:41:19,377 - INFO - Pruning info: sparsity=0.845
2025-08-28 06:41:19,377 - INFO -   Reactivation rate: 0.0012
2025-08-28 06:41:21,089 - INFO - Epoch: [39][200/391] Time 0.019 (0.020) Data 0.002 (0.002) Loss 0.5171 (0.4115) Acc@1 82.812 (85.774) Acc@5 99.219 (99.491)
2025-08-28 06:41:22,466 - INFO - Pruning info: sparsity=0.845
2025-08-28 06:41:22,466 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:41:23,040 - INFO - Epoch: [39][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4644 (0.4152) Acc@1 86.719 (85.706) Acc@5 98.438 (99.504)
2025-08-28 06:41:24,860 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.4499 (0.4499) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:41:25,739 - INFO - Epoch 39:
2025-08-28 06:41:25,740 - INFO -   Train: acc1: 85.5040 | acc5: 99.4600 | loss: 0.4212 | sparsity: 0.8449 | reactivation_rate: 0.0010
2025-08-28 06:41:25,740 - INFO -   Val:   acc1: 82.1100 | acc5: 99.3900 | loss: 0.5241
2025-08-28 06:41:25,740 - INFO -   LR: 0.100000
2025-08-28 06:41:25,751 - INFO - 
Epoch: 40, lr = 0.1
2025-08-28 06:41:25,944 - INFO - Epoch: [40][0/391] Time 0.193 (0.193) Data 0.167 (0.167) Loss 0.4071 (0.4071) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:41:26,761 - INFO - Pruning info: sparsity=0.853
2025-08-28 06:41:26,761 - INFO -   Reactivation rate: 0.0011
2025-08-28 06:41:27,910 - INFO - Epoch: [40][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.3403 (0.4254) Acc@1 84.375 (84.978) Acc@5 100.000 (99.420)
2025-08-28 06:41:29,802 - INFO - Pruning info: sparsity=0.853
2025-08-28 06:41:29,803 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:41:29,828 - INFO - Epoch: [40][200/391] Time 0.044 (0.020) Data 0.013 (0.002) Loss 0.4559 (0.4182) Acc@1 85.156 (85.432) Acc@5 99.219 (99.421)
2025-08-28 06:41:31,722 - INFO - Epoch: [40][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4179 (0.4228) Acc@1 84.375 (85.312) Acc@5 100.000 (99.421)
2025-08-28 06:41:32,902 - INFO - Pruning info: sparsity=0.853
2025-08-28 06:41:32,902 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:41:33,587 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.6132 (0.6132) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 06:41:34,498 - INFO - Epoch 40:
2025-08-28 06:41:34,499 - INFO -   Train: acc1: 85.3140 | acc5: 99.4100 | loss: 0.4241 | sparsity: 0.8535 | reactivation_rate: 0.0009
2025-08-28 06:41:34,499 - INFO -   Val:   acc1: 80.4300 | acc5: 98.8300 | loss: 0.5924
2025-08-28 06:41:34,499 - INFO -   LR: 0.100000
2025-08-28 06:41:34,543 - INFO - 
Epoch: 41, lr = 0.1
2025-08-28 06:41:34,722 - INFO - Epoch: [41][0/391] Time 0.178 (0.178) Data 0.151 (0.151) Loss 0.2985 (0.2985) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:41:36,631 - INFO - Epoch: [41][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4877 (0.4075) Acc@1 86.719 (85.930) Acc@5 99.219 (99.412)
2025-08-28 06:41:37,118 - INFO - Pruning info: sparsity=0.861
2025-08-28 06:41:37,119 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:41:38,533 - INFO - Epoch: [41][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4489 (0.4213) Acc@1 83.594 (85.502) Acc@5 99.219 (99.409)
2025-08-28 06:41:40,277 - INFO - Pruning info: sparsity=0.861
2025-08-28 06:41:40,277 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:41:40,502 - INFO - Epoch: [41][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3482 (0.4230) Acc@1 91.406 (85.525) Acc@5 100.000 (99.374)
2025-08-28 06:41:42,398 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.4199 (0.4199) Acc@1 87.500 (87.500) Acc@5 97.656 (97.656)
2025-08-28 06:41:43,264 - INFO - Epoch 41:
2025-08-28 06:41:43,264 - INFO -   Train: acc1: 85.2740 | acc5: 99.3720 | loss: 0.4296 | sparsity: 0.8615 | reactivation_rate: 0.0009
2025-08-28 06:41:43,264 - INFO -   Val:   acc1: 81.1800 | acc5: 98.9100 | loss: 0.5624
2025-08-28 06:41:43,265 - INFO -   LR: 0.100000
2025-08-28 06:41:43,278 - INFO - 
Epoch: 42, lr = 0.1
2025-08-28 06:41:43,452 - INFO - Epoch: [42][0/391] Time 0.173 (0.173) Data 0.152 (0.152) Loss 0.4391 (0.4391) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:41:44,564 - INFO - Pruning info: sparsity=0.869
2025-08-28 06:41:44,565 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:41:45,370 - INFO - Epoch: [42][100/391] Time 0.026 (0.021) Data 0.005 (0.003) Loss 0.5613 (0.4125) Acc@1 78.906 (85.760) Acc@5 99.219 (99.474)
2025-08-28 06:41:47,369 - INFO - Epoch: [42][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.6006 (0.4193) Acc@1 81.250 (85.510) Acc@5 99.219 (99.444)
2025-08-28 06:41:47,679 - INFO - Pruning info: sparsity=0.869
2025-08-28 06:41:47,679 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:41:49,277 - INFO - Epoch: [42][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3051 (0.4277) Acc@1 90.625 (85.174) Acc@5 100.000 (99.445)
2025-08-28 06:41:50,746 - INFO - Pruning info: sparsity=0.869
2025-08-28 06:41:50,746 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:41:51,126 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5777 (0.5777) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:41:51,966 - INFO - Epoch 42:
2025-08-28 06:41:51,966 - INFO -   Train: acc1: 85.2220 | acc5: 99.4220 | loss: 0.4294 | sparsity: 0.8691 | reactivation_rate: 0.0008
2025-08-28 06:41:51,966 - INFO -   Val:   acc1: 81.2700 | acc5: 98.7500 | loss: 0.5616
2025-08-28 06:41:51,966 - INFO -   LR: 0.100000
2025-08-28 06:41:51,979 - INFO - 
Epoch: 43, lr = 0.1
2025-08-28 06:41:52,177 - INFO - Epoch: [43][0/391] Time 0.197 (0.197) Data 0.167 (0.167) Loss 0.3084 (0.3084) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:41:54,201 - INFO - Epoch: [43][100/391] Time 0.020 (0.022) Data 0.000 (0.004) Loss 0.4645 (0.4313) Acc@1 82.031 (84.947) Acc@5 99.219 (99.451)
2025-08-28 06:41:55,062 - INFO - Pruning info: sparsity=0.876
2025-08-28 06:41:55,062 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:41:56,077 - INFO - Epoch: [43][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2650 (0.4229) Acc@1 92.969 (85.285) Acc@5 98.438 (99.471)
2025-08-28 06:41:57,992 - INFO - Epoch: [43][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3480 (0.4268) Acc@1 87.500 (85.135) Acc@5 100.000 (99.481)
2025-08-28 06:41:58,090 - INFO - Pruning info: sparsity=0.876
2025-08-28 06:41:58,090 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:41:59,807 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.6598 (0.6598) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-28 06:42:00,644 - INFO - Epoch 43:
2025-08-28 06:42:00,644 - INFO -   Train: acc1: 85.2260 | acc5: 99.4560 | loss: 0.4277 | sparsity: 0.8762 | reactivation_rate: 0.0007
2025-08-28 06:42:00,644 - INFO -   Val:   acc1: 81.9300 | acc5: 98.9500 | loss: 0.5443
2025-08-28 06:42:00,644 - INFO -   LR: 0.100000
2025-08-28 06:42:00,658 - INFO - 
Epoch: 44, lr = 0.1
2025-08-28 06:42:00,846 - INFO - Epoch: [44][0/391] Time 0.187 (0.187) Data 0.156 (0.156) Loss 0.4039 (0.4039) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:42:02,304 - INFO - Pruning info: sparsity=0.883
2025-08-28 06:42:02,304 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:42:02,793 - INFO - Epoch: [44][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3664 (0.4308) Acc@1 87.500 (84.816) Acc@5 100.000 (99.420)
2025-08-28 06:42:04,707 - INFO - Epoch: [44][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4867 (0.4331) Acc@1 85.156 (84.907) Acc@5 99.219 (99.378)
2025-08-28 06:42:05,431 - INFO - Pruning info: sparsity=0.883
2025-08-28 06:42:05,431 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:42:06,742 - INFO - Epoch: [44][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3315 (0.4298) Acc@1 86.719 (85.133) Acc@5 100.000 (99.387)
2025-08-28 06:42:08,638 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 1.5394 (1.5394) Acc@1 65.625 (65.625) Acc@5 98.438 (98.438)
2025-08-28 06:42:09,506 - INFO - Epoch 44:
2025-08-28 06:42:09,507 - INFO -   Train: acc1: 85.1620 | acc5: 99.4100 | loss: 0.4274 | sparsity: 0.8829 | reactivation_rate: 0.0007
2025-08-28 06:42:09,507 - INFO -   Val:   acc1: 67.1400 | acc5: 97.9600 | loss: 1.3925
2025-08-28 06:42:09,507 - INFO -   LR: 0.100000
2025-08-28 06:42:09,676 - INFO - 
Epoch: 45, lr = 0.1
2025-08-28 06:42:09,862 - INFO - Epoch: [45][0/391] Time 0.185 (0.185) Data 0.148 (0.148) Loss 0.3605 (0.3605) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:42:09,949 - INFO - Pruning info: sparsity=0.889
2025-08-28 06:42:09,949 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:42:11,923 - INFO - Epoch: [45][100/391] Time 0.028 (0.022) Data 0.000 (0.003) Loss 0.6936 (0.4242) Acc@1 76.562 (85.365) Acc@5 98.438 (99.335)
2025-08-28 06:42:13,246 - INFO - Pruning info: sparsity=0.889
2025-08-28 06:42:13,246 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:42:13,902 - INFO - Epoch: [45][200/391] Time 0.013 (0.021) Data 0.000 (0.002) Loss 0.3681 (0.4289) Acc@1 89.844 (85.133) Acc@5 98.438 (99.296)
2025-08-28 06:42:15,907 - INFO - Epoch: [45][300/391] Time 0.027 (0.021) Data 0.013 (0.002) Loss 0.4037 (0.4282) Acc@1 85.938 (85.213) Acc@5 99.219 (99.333)
2025-08-28 06:42:16,387 - INFO - Pruning info: sparsity=0.889
2025-08-28 06:42:16,387 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:42:17,772 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.4169 (0.4169) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 06:42:18,601 - INFO - Epoch 45:
2025-08-28 06:42:18,602 - INFO -   Train: acc1: 85.2320 | acc5: 99.3360 | loss: 0.4288 | sparsity: 0.8892 | reactivation_rate: 0.0006
2025-08-28 06:42:18,602 - INFO -   Val:   acc1: 80.4400 | acc5: 98.9700 | loss: 0.5837
2025-08-28 06:42:18,602 - INFO -   LR: 0.100000
2025-08-28 06:42:18,611 - INFO - 
Epoch: 46, lr = 0.1
2025-08-28 06:42:18,796 - INFO - Epoch: [46][0/391] Time 0.184 (0.184) Data 0.159 (0.159) Loss 0.3600 (0.3600) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:42:20,624 - INFO - Pruning info: sparsity=0.895
2025-08-28 06:42:20,624 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:42:20,763 - INFO - Epoch: [46][100/391] Time 0.018 (0.021) Data 0.001 (0.003) Loss 0.4683 (0.4088) Acc@1 80.469 (86.208) Acc@5 100.000 (99.389)
2025-08-28 06:42:22,679 - INFO - Epoch: [46][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.3822 (0.4250) Acc@1 88.281 (85.549) Acc@5 100.000 (99.355)
2025-08-28 06:42:23,661 - INFO - Pruning info: sparsity=0.895
2025-08-28 06:42:23,661 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:42:24,603 - INFO - Epoch: [46][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4534 (0.4221) Acc@1 85.938 (85.605) Acc@5 100.000 (99.362)
2025-08-28 06:42:26,529 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.6425 (0.6425) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:42:27,361 - INFO - Epoch 46:
2025-08-28 06:42:27,361 - INFO -   Train: acc1: 85.2720 | acc5: 99.4000 | loss: 0.4280 | sparsity: 0.8951 | reactivation_rate: 0.0006
2025-08-28 06:42:27,361 - INFO -   Val:   acc1: 79.4300 | acc5: 98.8800 | loss: 0.6283
2025-08-28 06:42:27,361 - INFO -   LR: 0.100000
2025-08-28 06:42:27,374 - INFO - 
Epoch: 47, lr = 0.1
2025-08-28 06:42:27,555 - INFO - Epoch: [47][0/391] Time 0.181 (0.181) Data 0.160 (0.160) Loss 0.4542 (0.4542) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:42:27,987 - INFO - Pruning info: sparsity=0.901
2025-08-28 06:42:27,987 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:42:29,536 - INFO - Epoch: [47][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4738 (0.4266) Acc@1 87.500 (85.450) Acc@5 100.000 (99.528)
2025-08-28 06:42:31,096 - INFO - Pruning info: sparsity=0.901
2025-08-28 06:42:31,096 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:42:31,451 - INFO - Epoch: [47][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4309 (0.4318) Acc@1 87.500 (85.168) Acc@5 100.000 (99.483)
2025-08-28 06:42:33,396 - INFO - Epoch: [47][300/391] Time 0.022 (0.020) Data 0.000 (0.001) Loss 0.4481 (0.4355) Acc@1 82.812 (84.993) Acc@5 99.219 (99.447)
2025-08-28 06:42:34,228 - INFO - Pruning info: sparsity=0.901
2025-08-28 06:42:34,228 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:42:35,279 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.4864 (0.4864) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:42:36,120 - INFO - Epoch 47:
2025-08-28 06:42:36,120 - INFO -   Train: acc1: 84.9620 | acc5: 99.4300 | loss: 0.4376 | sparsity: 0.9006 | reactivation_rate: 0.0005
2025-08-28 06:42:36,120 - INFO -   Val:   acc1: 78.5200 | acc5: 99.1800 | loss: 0.6194
2025-08-28 06:42:36,120 - INFO -   LR: 0.100000
2025-08-28 06:42:36,132 - INFO - 
Epoch: 48, lr = 0.1
2025-08-28 06:42:36,350 - INFO - Epoch: [48][0/391] Time 0.217 (0.217) Data 0.176 (0.176) Loss 0.4484 (0.4484) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:42:38,253 - INFO - Epoch: [48][100/391] Time 0.030 (0.021) Data 0.019 (0.003) Loss 0.4319 (0.4218) Acc@1 86.719 (85.558) Acc@5 98.438 (99.459)
2025-08-28 06:42:38,489 - INFO - Pruning info: sparsity=0.906
2025-08-28 06:42:38,489 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:42:40,250 - INFO - Epoch: [48][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3808 (0.4223) Acc@1 85.938 (85.448) Acc@5 99.219 (99.417)
2025-08-28 06:42:41,632 - INFO - Pruning info: sparsity=0.906
2025-08-28 06:42:41,633 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:42:42,201 - INFO - Epoch: [48][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4770 (0.4294) Acc@1 84.375 (85.268) Acc@5 100.000 (99.439)
2025-08-28 06:42:44,052 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5261 (0.5261) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:42:44,977 - INFO - Epoch 48:
2025-08-28 06:42:44,978 - INFO -   Train: acc1: 85.0420 | acc5: 99.4100 | loss: 0.4352 | sparsity: 0.9057 | reactivation_rate: 0.0005
2025-08-28 06:42:44,978 - INFO -   Val:   acc1: 79.7600 | acc5: 98.7700 | loss: 0.6227
2025-08-28 06:42:44,978 - INFO -   LR: 0.100000
2025-08-28 06:42:44,990 - INFO - 
Epoch: 49, lr = 0.1
2025-08-28 06:42:45,189 - INFO - Epoch: [49][0/391] Time 0.198 (0.198) Data 0.177 (0.177) Loss 0.5010 (0.5010) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:42:46,052 - INFO - Pruning info: sparsity=0.910
2025-08-28 06:42:46,052 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:42:47,233 - INFO - Epoch: [49][100/391] Time 0.024 (0.022) Data 0.000 (0.003) Loss 0.4529 (0.4318) Acc@1 82.812 (84.870) Acc@5 99.219 (99.412)
2025-08-28 06:42:49,121 - INFO - Epoch: [49][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.3295 (0.4291) Acc@1 87.500 (85.016) Acc@5 99.219 (99.421)
2025-08-28 06:42:49,132 - INFO - Pruning info: sparsity=0.910
2025-08-28 06:42:49,132 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:42:51,090 - INFO - Epoch: [49][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4067 (0.4391) Acc@1 83.594 (84.855) Acc@5 100.000 (99.393)
2025-08-28 06:42:52,266 - INFO - Pruning info: sparsity=0.910
2025-08-28 06:42:52,266 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:42:52,954 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.7746 (0.7746) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-28 06:42:53,793 - INFO - Epoch 49:
2025-08-28 06:42:53,793 - INFO -   Train: acc1: 84.8600 | acc5: 99.3580 | loss: 0.4394 | sparsity: 0.9104 | reactivation_rate: 0.0004
2025-08-28 06:42:53,793 - INFO -   Val:   acc1: 78.2100 | acc5: 98.6900 | loss: 0.6867
2025-08-28 06:42:53,793 - INFO -   LR: 0.100000
2025-08-28 06:42:53,807 - INFO - 
Epoch: 50, lr = 0.1
2025-08-28 06:42:53,977 - INFO - Epoch: [50][0/391] Time 0.168 (0.168) Data 0.143 (0.143) Loss 0.3483 (0.3483) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:42:55,898 - INFO - Epoch: [50][100/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.6345 (0.4394) Acc@1 77.344 (84.715) Acc@5 97.656 (99.350)
2025-08-28 06:42:56,481 - INFO - Pruning info: sparsity=0.915
2025-08-28 06:42:56,481 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:42:57,809 - INFO - Epoch: [50][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3141 (0.4398) Acc@1 87.500 (84.705) Acc@5 100.000 (99.409)
2025-08-28 06:42:59,579 - INFO - Pruning info: sparsity=0.915
2025-08-28 06:42:59,580 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:42:59,793 - INFO - Epoch: [50][300/391] Time 0.019 (0.020) Data 0.002 (0.001) Loss 0.4125 (0.4377) Acc@1 86.719 (84.681) Acc@5 98.438 (99.403)
2025-08-28 06:43:01,625 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5037 (0.5037) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:43:02,520 - INFO - Epoch 50:
2025-08-28 06:43:02,520 - INFO -   Train: acc1: 84.8560 | acc5: 99.3800 | loss: 0.4363 | sparsity: 0.9148 | reactivation_rate: 0.0004
2025-08-28 06:43:02,520 - INFO -   Val:   acc1: 81.2600 | acc5: 99.1900 | loss: 0.5714
2025-08-28 06:43:02,520 - INFO -   LR: 0.100000
2025-08-28 06:43:02,571 - INFO - 
Epoch: 51, lr = 0.1
2025-08-28 06:43:02,748 - INFO - Epoch: [51][0/391] Time 0.176 (0.176) Data 0.150 (0.150) Loss 0.4562 (0.4562) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:43:03,895 - INFO - Pruning info: sparsity=0.919
2025-08-28 06:43:03,895 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:43:04,696 - INFO - Epoch: [51][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.3910 (0.4415) Acc@1 82.812 (84.623) Acc@5 100.000 (99.350)
2025-08-28 06:43:06,690 - INFO - Epoch: [51][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4763 (0.4388) Acc@1 83.594 (84.771) Acc@5 98.438 (99.328)
2025-08-28 06:43:07,044 - INFO - Pruning info: sparsity=0.919
2025-08-28 06:43:07,044 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:08,683 - INFO - Epoch: [51][300/391] Time 0.033 (0.020) Data 0.020 (0.002) Loss 0.4256 (0.4393) Acc@1 88.281 (84.785) Acc@5 99.219 (99.346)
2025-08-28 06:43:10,219 - INFO - Pruning info: sparsity=0.919
2025-08-28 06:43:10,219 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:43:10,593 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.7548 (0.7548) Acc@1 74.219 (74.219) Acc@5 96.094 (96.094)
2025-08-28 06:43:11,465 - INFO - Epoch 51:
2025-08-28 06:43:11,465 - INFO -   Train: acc1: 84.6900 | acc5: 99.3280 | loss: 0.4438 | sparsity: 0.9189 | reactivation_rate: 0.0004
2025-08-28 06:43:11,465 - INFO -   Val:   acc1: 78.3800 | acc5: 98.4100 | loss: 0.6722
2025-08-28 06:43:11,465 - INFO -   LR: 0.100000
2025-08-28 06:43:11,477 - INFO - 
Epoch: 52, lr = 0.1
2025-08-28 06:43:11,668 - INFO - Epoch: [52][0/391] Time 0.190 (0.190) Data 0.165 (0.165) Loss 0.4484 (0.4484) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:43:13,548 - INFO - Epoch: [52][100/391] Time 0.025 (0.020) Data 0.000 (0.004) Loss 0.3632 (0.4257) Acc@1 85.156 (85.388) Acc@5 100.000 (99.389)
2025-08-28 06:43:14,483 - INFO - Pruning info: sparsity=0.923
2025-08-28 06:43:14,483 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:43:15,453 - INFO - Epoch: [52][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4380 (0.4445) Acc@1 85.156 (84.643) Acc@5 100.000 (99.293)
2025-08-28 06:43:17,278 - INFO - Epoch: [52][300/391] Time 0.029 (0.019) Data 0.002 (0.002) Loss 0.3846 (0.4435) Acc@1 84.375 (84.676) Acc@5 100.000 (99.341)
2025-08-28 06:43:17,423 - INFO - Pruning info: sparsity=0.923
2025-08-28 06:43:17,423 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:43:19,188 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.7177 (0.7177) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 06:43:20,052 - INFO - Epoch 52:
2025-08-28 06:43:20,052 - INFO -   Train: acc1: 84.6300 | acc5: 99.3780 | loss: 0.4453 | sparsity: 0.9226 | reactivation_rate: 0.0004
2025-08-28 06:43:20,052 - INFO -   Val:   acc1: 75.4000 | acc5: 98.4700 | loss: 0.7972
2025-08-28 06:43:20,052 - INFO -   LR: 0.100000
2025-08-28 06:43:20,063 - INFO - 
Epoch: 53, lr = 0.1
2025-08-28 06:43:20,264 - INFO - Epoch: [53][0/391] Time 0.200 (0.200) Data 0.175 (0.175) Loss 0.3825 (0.3825) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:43:21,835 - INFO - Pruning info: sparsity=0.926
2025-08-28 06:43:21,835 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:43:22,293 - INFO - Epoch: [53][100/391] Time 0.011 (0.022) Data 0.000 (0.002) Loss 0.4402 (0.4442) Acc@1 84.375 (84.506) Acc@5 99.219 (99.466)
2025-08-28 06:43:24,158 - INFO - Epoch: [53][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4764 (0.4512) Acc@1 84.375 (84.235) Acc@5 100.000 (99.421)
2025-08-28 06:43:24,873 - INFO - Pruning info: sparsity=0.926
2025-08-28 06:43:24,874 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:43:26,121 - INFO - Epoch: [53][300/391] Time 0.016 (0.020) Data 0.000 (0.001) Loss 0.3620 (0.4493) Acc@1 86.719 (84.378) Acc@5 99.219 (99.393)
2025-08-28 06:43:27,975 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6191 (0.6191) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:43:28,876 - INFO - Epoch 53:
2025-08-28 06:43:28,876 - INFO -   Train: acc1: 84.2500 | acc5: 99.3800 | loss: 0.4521 | sparsity: 0.9260 | reactivation_rate: 0.0003
2025-08-28 06:43:28,876 - INFO -   Val:   acc1: 77.9000 | acc5: 98.9800 | loss: 0.6763
2025-08-28 06:43:28,876 - INFO -   LR: 0.100000
2025-08-28 06:43:28,889 - INFO - 
Epoch: 54, lr = 0.1
2025-08-28 06:43:29,082 - INFO - Epoch: [54][0/391] Time 0.192 (0.192) Data 0.169 (0.169) Loss 0.3743 (0.3743) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:43:29,195 - INFO - Pruning info: sparsity=0.929
2025-08-28 06:43:29,195 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:43:30,972 - INFO - Epoch: [54][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3940 (0.4449) Acc@1 88.281 (84.715) Acc@5 99.219 (99.327)
2025-08-28 06:43:32,234 - INFO - Pruning info: sparsity=0.929
2025-08-28 06:43:32,234 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:32,905 - INFO - Epoch: [54][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.5643 (0.4467) Acc@1 79.688 (84.713) Acc@5 98.438 (99.347)
2025-08-28 06:43:34,892 - INFO - Epoch: [54][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3941 (0.4412) Acc@1 85.938 (84.881) Acc@5 99.219 (99.419)
2025-08-28 06:43:35,356 - INFO - Pruning info: sparsity=0.929
2025-08-28 06:43:35,357 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:36,732 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6771 (0.6771) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-28 06:43:37,567 - INFO - Epoch 54:
2025-08-28 06:43:37,567 - INFO -   Train: acc1: 84.7580 | acc5: 99.3820 | loss: 0.4437 | sparsity: 0.9291 | reactivation_rate: 0.0003
2025-08-28 06:43:37,567 - INFO -   Val:   acc1: 78.0900 | acc5: 99.2100 | loss: 0.6661
2025-08-28 06:43:37,567 - INFO -   LR: 0.100000
2025-08-28 06:43:37,579 - INFO - 
Epoch: 55, lr = 0.1
2025-08-28 06:43:37,749 - INFO - Epoch: [55][0/391] Time 0.169 (0.169) Data 0.144 (0.144) Loss 0.4070 (0.4070) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:43:39,695 - INFO - Pruning info: sparsity=0.932
2025-08-28 06:43:39,695 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:39,777 - INFO - Epoch: [55][100/391] Time 0.012 (0.022) Data 0.000 (0.002) Loss 0.6141 (0.4439) Acc@1 78.125 (84.630) Acc@5 99.219 (99.373)
2025-08-28 06:43:41,708 - INFO - Epoch: [55][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.5818 (0.4495) Acc@1 80.469 (84.511) Acc@5 99.219 (99.417)
2025-08-28 06:43:42,816 - INFO - Pruning info: sparsity=0.932
2025-08-28 06:43:42,816 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:43:43,700 - INFO - Epoch: [55][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3382 (0.4490) Acc@1 88.281 (84.541) Acc@5 99.219 (99.416)
2025-08-28 06:43:45,538 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.5787 (0.5787) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:43:46,442 - INFO - Epoch 55:
2025-08-28 06:43:46,443 - INFO -   Train: acc1: 84.3840 | acc5: 99.3900 | loss: 0.4510 | sparsity: 0.9320 | reactivation_rate: 0.0003
2025-08-28 06:43:46,443 - INFO -   Val:   acc1: 76.0900 | acc5: 98.7600 | loss: 0.7209
2025-08-28 06:43:46,443 - INFO -   LR: 0.100000
2025-08-28 06:43:46,456 - INFO - 
Epoch: 56, lr = 0.1
2025-08-28 06:43:46,631 - INFO - Epoch: [56][0/391] Time 0.174 (0.174) Data 0.155 (0.155) Loss 0.3919 (0.3919) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 06:43:47,064 - INFO - Pruning info: sparsity=0.935
2025-08-28 06:43:47,064 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:43:48,526 - INFO - Epoch: [56][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.5249 (0.4441) Acc@1 78.125 (84.731) Acc@5 99.219 (99.420)
2025-08-28 06:43:50,102 - INFO - Pruning info: sparsity=0.935
2025-08-28 06:43:50,103 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:50,427 - INFO - Epoch: [56][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.3746 (0.4532) Acc@1 87.500 (84.406) Acc@5 98.438 (99.382)
2025-08-28 06:43:52,319 - INFO - Epoch: [56][300/391] Time 0.033 (0.019) Data 0.019 (0.002) Loss 0.4738 (0.4522) Acc@1 85.156 (84.476) Acc@5 99.219 (99.372)
2025-08-28 06:43:53,149 - INFO - Pruning info: sparsity=0.935
2025-08-28 06:43:53,150 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:54,220 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4592 (0.4592) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:43:55,056 - INFO - Epoch 56:
2025-08-28 06:43:55,056 - INFO -   Train: acc1: 84.3160 | acc5: 99.3340 | loss: 0.4549 | sparsity: 0.9346 | reactivation_rate: 0.0003
2025-08-28 06:43:55,056 - INFO -   Val:   acc1: 82.9500 | acc5: 99.0600 | loss: 0.5278
2025-08-28 06:43:55,056 - INFO -   LR: 0.100000
2025-08-28 06:43:55,069 - INFO - 
Epoch: 57, lr = 0.1
2025-08-28 06:43:55,258 - INFO - Epoch: [57][0/391] Time 0.188 (0.188) Data 0.155 (0.155) Loss 0.3696 (0.3696) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:43:57,228 - INFO - Epoch: [57][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4586 (0.4560) Acc@1 85.156 (83.996) Acc@5 99.219 (99.381)
2025-08-28 06:43:57,461 - INFO - Pruning info: sparsity=0.937
2025-08-28 06:43:57,461 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:43:59,127 - INFO - Epoch: [57][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4675 (0.4623) Acc@1 82.031 (83.745) Acc@5 100.000 (99.363)
2025-08-28 06:44:00,566 - INFO - Pruning info: sparsity=0.937
2025-08-28 06:44:00,566 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:44:01,139 - INFO - Epoch: [57][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4118 (0.4578) Acc@1 85.156 (83.983) Acc@5 100.000 (99.367)
2025-08-28 06:44:02,987 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.4808 (0.4808) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:44:03,855 - INFO - Epoch 57:
2025-08-28 06:44:03,855 - INFO -   Train: acc1: 84.0840 | acc5: 99.3580 | loss: 0.4569 | sparsity: 0.9369 | reactivation_rate: 0.0002
2025-08-28 06:44:03,855 - INFO -   Val:   acc1: 79.9500 | acc5: 98.9200 | loss: 0.6063
2025-08-28 06:44:03,855 - INFO -   LR: 0.100000
2025-08-28 06:44:03,869 - INFO - 
Epoch: 58, lr = 0.1
2025-08-28 06:44:04,046 - INFO - Epoch: [58][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.5358 (0.5358) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:44:04,851 - INFO - Pruning info: sparsity=0.939
2025-08-28 06:44:04,852 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:44:05,966 - INFO - Epoch: [58][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3718 (0.4653) Acc@1 90.625 (83.710) Acc@5 98.438 (99.343)
2025-08-28 06:44:07,878 - INFO - Epoch: [58][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4126 (0.4657) Acc@1 85.156 (83.854) Acc@5 100.000 (99.359)
2025-08-28 06:44:07,908 - INFO - Pruning info: sparsity=0.939
2025-08-28 06:44:07,908 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:09,809 - INFO - Epoch: [58][300/391] Time 0.011 (0.020) Data 0.000 (0.001) Loss 0.4275 (0.4627) Acc@1 82.812 (83.887) Acc@5 100.000 (99.343)
2025-08-28 06:44:11,078 - INFO - Pruning info: sparsity=0.939
2025-08-28 06:44:11,078 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:11,758 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6187 (0.6187) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:44:12,640 - INFO - Epoch 58:
2025-08-28 06:44:12,641 - INFO -   Train: acc1: 83.9740 | acc5: 99.3700 | loss: 0.4612 | sparsity: 0.9389 | reactivation_rate: 0.0002
2025-08-28 06:44:12,641 - INFO -   Val:   acc1: 77.0000 | acc5: 98.5700 | loss: 0.7113
2025-08-28 06:44:12,641 - INFO -   LR: 0.100000
2025-08-28 06:44:12,655 - INFO - 
Epoch: 59, lr = 0.1
2025-08-28 06:44:12,854 - INFO - Epoch: [59][0/391] Time 0.198 (0.198) Data 0.176 (0.176) Loss 0.4744 (0.4744) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 06:44:14,761 - INFO - Epoch: [59][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4321 (0.4353) Acc@1 85.156 (84.777) Acc@5 98.438 (99.404)
2025-08-28 06:44:15,355 - INFO - Pruning info: sparsity=0.941
2025-08-28 06:44:15,356 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:16,684 - INFO - Epoch: [59][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.5872 (0.4536) Acc@1 77.344 (84.126) Acc@5 98.438 (99.386)
2025-08-28 06:44:18,466 - INFO - Pruning info: sparsity=0.941
2025-08-28 06:44:18,467 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:18,662 - INFO - Epoch: [59][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.6167 (0.4635) Acc@1 76.562 (83.791) Acc@5 100.000 (99.354)
2025-08-28 06:44:20,529 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5192 (0.5192) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:44:21,381 - INFO - Epoch 59:
2025-08-28 06:44:21,381 - INFO -   Train: acc1: 83.9360 | acc5: 99.3660 | loss: 0.4622 | sparsity: 0.9408 | reactivation_rate: 0.0002
2025-08-28 06:44:21,381 - INFO -   Val:   acc1: 81.0300 | acc5: 99.0100 | loss: 0.5756
2025-08-28 06:44:21,381 - INFO -   LR: 0.100000
2025-08-28 06:44:21,392 - INFO - 
Epoch: 60, lr = 0.1
2025-08-28 06:44:21,579 - INFO - Epoch: [60][0/391] Time 0.186 (0.186) Data 0.165 (0.165) Loss 0.4643 (0.4643) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:44:22,739 - INFO - Pruning info: sparsity=0.942
2025-08-28 06:44:22,739 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:23,486 - INFO - Epoch: [60][100/391] Time 0.023 (0.021) Data 0.000 (0.003) Loss 0.4821 (0.4578) Acc@1 85.156 (83.826) Acc@5 99.219 (99.428)
2025-08-28 06:44:25,383 - INFO - Epoch: [60][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3485 (0.4642) Acc@1 85.938 (83.582) Acc@5 100.000 (99.366)
2025-08-28 06:44:25,773 - INFO - Pruning info: sparsity=0.942
2025-08-28 06:44:25,773 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:27,323 - INFO - Epoch: [60][300/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.5034 (0.4624) Acc@1 79.688 (83.830) Acc@5 99.219 (99.328)
2025-08-28 06:44:28,934 - INFO - Pruning info: sparsity=0.942
2025-08-28 06:44:28,934 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:29,250 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5967 (0.5967) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:44:30,135 - INFO - Epoch 60:
2025-08-28 06:44:30,135 - INFO -   Train: acc1: 83.8240 | acc5: 99.3560 | loss: 0.4640 | sparsity: 0.9424 | reactivation_rate: 0.0002
2025-08-28 06:44:30,135 - INFO -   Val:   acc1: 77.1200 | acc5: 98.4900 | loss: 0.7046
2025-08-28 06:44:30,135 - INFO -   LR: 0.100000
2025-08-28 06:44:30,182 - INFO - 
Epoch: 61, lr = 0.1
2025-08-28 06:44:30,388 - INFO - Epoch: [61][0/391] Time 0.205 (0.205) Data 0.181 (0.181) Loss 0.5073 (0.5073) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:44:32,324 - INFO - Epoch: [61][100/391] Time 0.030 (0.021) Data 0.007 (0.003) Loss 0.4099 (0.4398) Acc@1 84.375 (85.102) Acc@5 100.000 (99.412)
2025-08-28 06:44:33,260 - INFO - Pruning info: sparsity=0.944
2025-08-28 06:44:33,260 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:34,231 - INFO - Epoch: [61][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4948 (0.4637) Acc@1 86.719 (84.052) Acc@5 99.219 (99.339)
2025-08-28 06:44:36,222 - INFO - Epoch: [61][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.6022 (0.4672) Acc@1 77.344 (83.848) Acc@5 99.219 (99.307)
2025-08-28 06:44:36,382 - INFO - Pruning info: sparsity=0.944
2025-08-28 06:44:36,382 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:38,130 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5919 (0.5919) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:44:38,953 - INFO - Epoch 61:
2025-08-28 06:44:38,953 - INFO -   Train: acc1: 83.6700 | acc5: 99.3120 | loss: 0.4724 | sparsity: 0.9438 | reactivation_rate: 0.0002
2025-08-28 06:44:38,953 - INFO -   Val:   acc1: 79.3900 | acc5: 98.5500 | loss: 0.6319
2025-08-28 06:44:38,953 - INFO -   LR: 0.100000
2025-08-28 06:44:38,968 - INFO - 
Epoch: 62, lr = 0.1
2025-08-28 06:44:39,145 - INFO - Epoch: [62][0/391] Time 0.177 (0.177) Data 0.145 (0.145) Loss 0.4238 (0.4238) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:44:40,625 - INFO - Pruning info: sparsity=0.945
2025-08-28 06:44:40,625 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:41,062 - INFO - Epoch: [62][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.3576 (0.4498) Acc@1 87.500 (84.197) Acc@5 99.219 (99.451)
2025-08-28 06:44:42,970 - INFO - Epoch: [62][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4215 (0.4543) Acc@1 87.500 (84.029) Acc@5 99.219 (99.433)
2025-08-28 06:44:43,695 - INFO - Pruning info: sparsity=0.945
2025-08-28 06:44:43,695 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:44,907 - INFO - Epoch: [62][300/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.4363 (0.4600) Acc@1 85.938 (83.910) Acc@5 100.000 (99.354)
2025-08-28 06:44:46,850 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5845 (0.5845) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 06:44:47,702 - INFO - Epoch 62:
2025-08-28 06:44:47,702 - INFO -   Train: acc1: 83.8520 | acc5: 99.3580 | loss: 0.4642 | sparsity: 0.9451 | reactivation_rate: 0.0002
2025-08-28 06:44:47,702 - INFO -   Val:   acc1: 79.0000 | acc5: 98.9700 | loss: 0.6482
2025-08-28 06:44:47,702 - INFO -   LR: 0.100000
2025-08-28 06:44:47,715 - INFO - 
Epoch: 63, lr = 0.1
2025-08-28 06:44:47,904 - INFO - Epoch: [63][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.3877 (0.3877) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:44:48,042 - INFO - Pruning info: sparsity=0.946
2025-08-28 06:44:48,042 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:44:49,876 - INFO - Epoch: [63][100/391] Time 0.031 (0.021) Data 0.000 (0.003) Loss 0.4719 (0.4443) Acc@1 81.250 (84.839) Acc@5 97.656 (99.366)
2025-08-28 06:44:51,166 - INFO - Pruning info: sparsity=0.946
2025-08-28 06:44:51,166 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:51,816 - INFO - Epoch: [63][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5413 (0.4508) Acc@1 82.031 (84.476) Acc@5 100.000 (99.363)
2025-08-28 06:44:53,779 - INFO - Epoch: [63][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4175 (0.4596) Acc@1 86.719 (84.095) Acc@5 100.000 (99.362)
2025-08-28 06:44:54,315 - INFO - Pruning info: sparsity=0.946
2025-08-28 06:44:54,316 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:44:55,710 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.5835 (0.5835) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:44:56,576 - INFO - Epoch 63:
2025-08-28 06:44:56,576 - INFO -   Train: acc1: 83.9400 | acc5: 99.3600 | loss: 0.4642 | sparsity: 0.9461 | reactivation_rate: 0.0001
2025-08-28 06:44:56,577 - INFO -   Val:   acc1: 77.9200 | acc5: 98.5900 | loss: 0.6719
2025-08-28 06:44:56,577 - INFO -   LR: 0.100000
2025-08-28 06:44:56,591 - INFO - 
Epoch: 64, lr = 0.1
2025-08-28 06:44:56,793 - INFO - Epoch: [64][0/391] Time 0.201 (0.201) Data 0.167 (0.167) Loss 0.4432 (0.4432) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:44:58,605 - INFO - Pruning info: sparsity=0.947
2025-08-28 06:44:58,605 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:44:58,714 - INFO - Epoch: [64][100/391] Time 0.027 (0.021) Data 0.000 (0.004) Loss 0.3816 (0.4627) Acc@1 86.719 (84.004) Acc@5 100.000 (99.358)
2025-08-28 06:45:00,623 - INFO - Epoch: [64][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5100 (0.4718) Acc@1 82.031 (83.660) Acc@5 99.219 (99.312)
2025-08-28 06:45:01,741 - INFO - Pruning info: sparsity=0.947
2025-08-28 06:45:01,741 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:02,569 - INFO - Epoch: [64][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.6260 (0.4700) Acc@1 78.125 (83.807) Acc@5 98.438 (99.294)
2025-08-28 06:45:04,448 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.8948 (0.8948) Acc@1 74.219 (74.219) Acc@5 98.438 (98.438)
2025-08-28 06:45:05,300 - INFO - Epoch 64:
2025-08-28 06:45:05,301 - INFO -   Train: acc1: 83.7500 | acc5: 99.2500 | loss: 0.4701 | sparsity: 0.9470 | reactivation_rate: 0.0001
2025-08-28 06:45:05,301 - INFO -   Val:   acc1: 72.8600 | acc5: 98.2400 | loss: 0.9146
2025-08-28 06:45:05,301 - INFO -   LR: 0.100000
2025-08-28 06:45:05,317 - INFO - 
Epoch: 65, lr = 0.1
2025-08-28 06:45:05,491 - INFO - Epoch: [65][0/391] Time 0.173 (0.173) Data 0.139 (0.139) Loss 0.3515 (0.3515) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:45:05,943 - INFO - Pruning info: sparsity=0.948
2025-08-28 06:45:05,944 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:45:07,583 - INFO - Epoch: [65][100/391] Time 0.024 (0.022) Data 0.000 (0.003) Loss 0.3508 (0.4732) Acc@1 90.625 (83.601) Acc@5 98.438 (99.312)
2025-08-28 06:45:09,230 - INFO - Pruning info: sparsity=0.948
2025-08-28 06:45:09,230 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:45:09,482 - INFO - Epoch: [65][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.4461 (0.4722) Acc@1 84.375 (83.815) Acc@5 99.219 (99.258)
2025-08-28 06:45:11,442 - INFO - Epoch: [65][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4496 (0.4753) Acc@1 85.938 (83.615) Acc@5 98.438 (99.255)
2025-08-28 06:45:12,320 - INFO - Pruning info: sparsity=0.948
2025-08-28 06:45:12,320 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:13,334 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.6530 (0.6530) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 06:45:14,191 - INFO - Epoch 65:
2025-08-28 06:45:14,191 - INFO -   Train: acc1: 83.6080 | acc5: 99.2600 | loss: 0.4769 | sparsity: 0.9477 | reactivation_rate: 0.0001
2025-08-28 06:45:14,191 - INFO -   Val:   acc1: 74.0200 | acc5: 98.4900 | loss: 0.8076
2025-08-28 06:45:14,191 - INFO -   LR: 0.100000
2025-08-28 06:45:14,205 - INFO - 
Epoch: 66, lr = 0.1
2025-08-28 06:45:14,401 - INFO - Epoch: [66][0/391] Time 0.196 (0.196) Data 0.163 (0.163) Loss 0.4195 (0.4195) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:45:16,348 - INFO - Epoch: [66][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.3981 (0.4543) Acc@1 90.625 (84.367) Acc@5 100.000 (99.350)
2025-08-28 06:45:16,581 - INFO - Pruning info: sparsity=0.948
2025-08-28 06:45:16,581 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:18,274 - INFO - Epoch: [66][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.5973 (0.4626) Acc@1 79.688 (84.122) Acc@5 99.219 (99.304)
2025-08-28 06:45:19,728 - INFO - Pruning info: sparsity=0.948
2025-08-28 06:45:19,729 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:20,275 - INFO - Epoch: [66][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.5241 (0.4722) Acc@1 82.031 (83.744) Acc@5 97.656 (99.271)
2025-08-28 06:45:22,177 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.5731 (0.5731) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:45:23,005 - INFO - Epoch 66:
2025-08-28 06:45:23,005 - INFO -   Train: acc1: 83.8120 | acc5: 99.2840 | loss: 0.4709 | sparsity: 0.9484 | reactivation_rate: 0.0001
2025-08-28 06:45:23,005 - INFO -   Val:   acc1: 78.3800 | acc5: 98.3300 | loss: 0.6522
2025-08-28 06:45:23,005 - INFO -   LR: 0.100000
2025-08-28 06:45:23,019 - INFO - 
Epoch: 67, lr = 0.1
2025-08-28 06:45:23,203 - INFO - Epoch: [67][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.4119 (0.4119) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:45:24,061 - INFO - Pruning info: sparsity=0.949
2025-08-28 06:45:24,061 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:25,225 - INFO - Epoch: [67][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.5134 (0.4601) Acc@1 82.031 (83.857) Acc@5 98.438 (99.366)
2025-08-28 06:45:27,107 - INFO - Epoch: [67][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3870 (0.4759) Acc@1 83.594 (83.578) Acc@5 100.000 (99.293)
2025-08-28 06:45:27,174 - INFO - Pruning info: sparsity=0.949
2025-08-28 06:45:27,174 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:29,099 - INFO - Epoch: [67][300/391] Time 0.025 (0.020) Data 0.007 (0.002) Loss 0.3239 (0.4683) Acc@1 91.406 (83.812) Acc@5 99.219 (99.320)
2025-08-28 06:45:30,299 - INFO - Pruning info: sparsity=0.949
2025-08-28 06:45:30,300 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:30,920 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6374 (0.6374) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:45:31,835 - INFO - Epoch 67:
2025-08-28 06:45:31,835 - INFO -   Train: acc1: 83.8260 | acc5: 99.2860 | loss: 0.4693 | sparsity: 0.9488 | reactivation_rate: 0.0001
2025-08-28 06:45:31,835 - INFO -   Val:   acc1: 78.2500 | acc5: 98.9400 | loss: 0.6756
2025-08-28 06:45:31,835 - INFO -   LR: 0.100000
2025-08-28 06:45:31,848 - INFO - 
Epoch: 68, lr = 0.1
2025-08-28 06:45:32,022 - INFO - Epoch: [68][0/391] Time 0.174 (0.174) Data 0.144 (0.144) Loss 0.4672 (0.4672) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:45:34,038 - INFO - Epoch: [68][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.5625 (0.4679) Acc@1 80.469 (83.911) Acc@5 98.438 (99.319)
2025-08-28 06:45:34,618 - INFO - Pruning info: sparsity=0.949
2025-08-28 06:45:34,618 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:35,855 - INFO - Epoch: [68][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.5542 (0.4773) Acc@1 83.594 (83.625) Acc@5 100.000 (99.254)
2025-08-28 06:45:37,568 - INFO - Pruning info: sparsity=0.949
2025-08-28 06:45:37,568 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:37,726 - INFO - Epoch: [68][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5148 (0.4783) Acc@1 83.594 (83.524) Acc@5 98.438 (99.247)
2025-08-28 06:45:39,529 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.9493 (0.9493) Acc@1 70.312 (70.312) Acc@5 98.438 (98.438)
2025-08-28 06:45:40,396 - INFO - Epoch 68:
2025-08-28 06:45:40,396 - INFO -   Train: acc1: 83.5600 | acc5: 99.2680 | loss: 0.4756 | sparsity: 0.9492 | reactivation_rate: 0.0001
2025-08-28 06:45:40,396 - INFO -   Val:   acc1: 73.1100 | acc5: 98.2700 | loss: 0.9490
2025-08-28 06:45:40,396 - INFO -   LR: 0.100000
2025-08-28 06:45:40,409 - INFO - 
Epoch: 69, lr = 0.1
2025-08-28 06:45:40,604 - INFO - Epoch: [69][0/391] Time 0.194 (0.194) Data 0.172 (0.172) Loss 0.5470 (0.5470) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:45:41,856 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:45:41,857 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:42,687 - INFO - Epoch: [69][100/391] Time 0.012 (0.023) Data 0.000 (0.003) Loss 0.4653 (0.4669) Acc@1 85.156 (83.834) Acc@5 98.438 (99.281)
2025-08-28 06:45:44,608 - INFO - Epoch: [69][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.3794 (0.4650) Acc@1 85.156 (83.862) Acc@5 100.000 (99.308)
2025-08-28 06:45:44,985 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:45:44,985 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:46,547 - INFO - Epoch: [69][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4379 (0.4712) Acc@1 84.375 (83.788) Acc@5 100.000 (99.317)
2025-08-28 06:45:48,159 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:45:48,159 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:45:48,478 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.9208 (0.9208) Acc@1 71.094 (71.094) Acc@5 99.219 (99.219)
2025-08-28 06:45:49,338 - INFO - Epoch 69:
2025-08-28 06:45:49,338 - INFO -   Train: acc1: 83.6900 | acc5: 99.3200 | loss: 0.4745 | sparsity: 0.9495 | reactivation_rate: 0.0001
2025-08-28 06:45:49,338 - INFO -   Val:   acc1: 73.6500 | acc5: 98.5400 | loss: 0.9122
2025-08-28 06:45:49,339 - INFO -   LR: 0.100000
2025-08-28 06:45:49,349 - INFO - 
Epoch: 70, lr = 0.1
2025-08-28 06:45:49,530 - INFO - Epoch: [70][0/391] Time 0.180 (0.180) Data 0.152 (0.152) Loss 0.6612 (0.6612) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:45:51,470 - INFO - Epoch: [70][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.4054 (0.4668) Acc@1 82.812 (83.849) Acc@5 100.000 (99.304)
2025-08-28 06:45:52,460 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:45:52,461 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:53,405 - INFO - Epoch: [70][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4635 (0.4710) Acc@1 82.812 (83.897) Acc@5 100.000 (99.265)
2025-08-28 06:45:55,284 - INFO - Epoch: [70][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2676 (0.4716) Acc@1 90.625 (83.840) Acc@5 100.000 (99.263)
2025-08-28 06:45:55,412 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:45:55,413 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:45:57,203 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5573 (0.5573) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:45:58,063 - INFO - Epoch 70:
2025-08-28 06:45:58,063 - INFO -   Train: acc1: 83.9000 | acc5: 99.2720 | loss: 0.4700 | sparsity: 0.9497 | reactivation_rate: 0.0001
2025-08-28 06:45:58,063 - INFO -   Val:   acc1: 80.8200 | acc5: 98.8500 | loss: 0.5795
2025-08-28 06:45:58,063 - INFO -   LR: 0.100000
2025-08-28 06:45:58,112 - INFO - 
Epoch: 71, lr = 0.1
2025-08-28 06:45:58,313 - INFO - Epoch: [71][0/391] Time 0.200 (0.200) Data 0.163 (0.163) Loss 0.3793 (0.3793) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:45:59,895 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:45:59,895 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:46:00,300 - INFO - Epoch: [71][100/391] Time 0.015 (0.022) Data 0.000 (0.003) Loss 0.4118 (0.4666) Acc@1 84.375 (83.803) Acc@5 100.000 (99.350)
2025-08-28 06:46:02,198 - INFO - Epoch: [71][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3756 (0.4664) Acc@1 89.844 (83.963) Acc@5 100.000 (99.324)
2025-08-28 06:46:02,948 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:02,948 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:46:04,169 - INFO - Epoch: [71][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4038 (0.4702) Acc@1 85.938 (83.936) Acc@5 99.219 (99.312)
2025-08-28 06:46:06,002 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5635 (0.5635) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 06:46:06,870 - INFO - Epoch 71:
2025-08-28 06:46:06,870 - INFO -   Train: acc1: 83.8880 | acc5: 99.2820 | loss: 0.4704 | sparsity: 0.9499 | reactivation_rate: 0.0001
2025-08-28 06:46:06,870 - INFO -   Val:   acc1: 78.3200 | acc5: 98.9400 | loss: 0.6452
2025-08-28 06:46:06,870 - INFO -   LR: 0.100000
2025-08-28 06:46:06,884 - INFO - 
Epoch: 72, lr = 0.1
2025-08-28 06:46:07,067 - INFO - Epoch: [72][0/391] Time 0.182 (0.182) Data 0.154 (0.154) Loss 0.4580 (0.4580) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:46:07,201 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:07,201 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:08,972 - INFO - Epoch: [72][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.2504 (0.4597) Acc@1 92.969 (84.004) Acc@5 100.000 (99.281)
2025-08-28 06:46:10,214 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:10,214 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:46:10,849 - INFO - Epoch: [72][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.5361 (0.4740) Acc@1 80.469 (83.349) Acc@5 100.000 (99.289)
2025-08-28 06:46:12,644 - INFO - Epoch: [72][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.5347 (0.4759) Acc@1 84.375 (83.464) Acc@5 98.438 (99.302)
2025-08-28 06:46:13,199 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:13,199 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:14,549 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.7028 (0.7028) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 06:46:15,391 - INFO - Epoch 72:
2025-08-28 06:46:15,391 - INFO -   Train: acc1: 83.5060 | acc5: 99.3180 | loss: 0.4735 | sparsity: 0.9499 | reactivation_rate: 0.0001
2025-08-28 06:46:15,391 - INFO -   Val:   acc1: 75.4100 | acc5: 98.6500 | loss: 0.8272
2025-08-28 06:46:15,391 - INFO -   LR: 0.100000
2025-08-28 06:46:15,404 - INFO - 
Epoch: 73, lr = 0.1
2025-08-28 06:46:15,589 - INFO - Epoch: [73][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.4935 (0.4935) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 06:46:17,456 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:17,456 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:17,538 - INFO - Epoch: [73][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3167 (0.4532) Acc@1 91.406 (84.445) Acc@5 100.000 (99.381)
2025-08-28 06:46:19,391 - INFO - Epoch: [73][200/391] Time 0.023 (0.020) Data 0.009 (0.002) Loss 0.4406 (0.4643) Acc@1 85.938 (83.947) Acc@5 100.000 (99.324)
2025-08-28 06:46:20,556 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:20,556 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:21,412 - INFO - Epoch: [73][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5058 (0.4659) Acc@1 82.812 (83.895) Acc@5 99.219 (99.330)
2025-08-28 06:46:23,244 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7622 (0.7622) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-28 06:46:24,120 - INFO - Epoch 73:
2025-08-28 06:46:24,121 - INFO -   Train: acc1: 83.7860 | acc5: 99.2720 | loss: 0.4694 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:46:24,121 - INFO -   Val:   acc1: 75.3700 | acc5: 97.9300 | loss: 0.7995
2025-08-28 06:46:24,121 - INFO -   LR: 0.100000
2025-08-28 06:46:24,134 - INFO - 
Epoch: 74, lr = 0.1
2025-08-28 06:46:24,307 - INFO - Epoch: [74][0/391] Time 0.172 (0.172) Data 0.143 (0.143) Loss 0.5431 (0.5431) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:46:24,812 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:24,812 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:26,207 - INFO - Epoch: [74][100/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.3715 (0.4851) Acc@1 85.156 (83.284) Acc@5 100.000 (99.196)
2025-08-28 06:46:27,861 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:27,861 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:28,145 - INFO - Epoch: [74][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.5274 (0.4778) Acc@1 84.375 (83.582) Acc@5 100.000 (99.300)
2025-08-28 06:46:30,158 - INFO - Epoch: [74][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3570 (0.4721) Acc@1 89.062 (83.739) Acc@5 99.219 (99.315)
2025-08-28 06:46:31,076 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:31,076 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:32,149 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.8482 (0.8482) Acc@1 73.438 (73.438) Acc@5 97.656 (97.656)
2025-08-28 06:46:33,013 - INFO - Epoch 74:
2025-08-28 06:46:33,013 - INFO -   Train: acc1: 83.6120 | acc5: 99.3000 | loss: 0.4749 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:46:33,013 - INFO -   Val:   acc1: 74.5300 | acc5: 98.1700 | loss: 0.7729
2025-08-28 06:46:33,013 - INFO -   LR: 0.100000
2025-08-28 06:46:33,027 - INFO - 
Epoch: 75, lr = 0.1
2025-08-28 06:46:33,211 - INFO - Epoch: [75][0/391] Time 0.182 (0.182) Data 0.161 (0.161) Loss 0.4209 (0.4209) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 06:46:35,276 - INFO - Epoch: [75][100/391] Time 0.020 (0.022) Data 0.000 (0.004) Loss 0.5968 (0.4691) Acc@1 82.031 (83.710) Acc@5 99.219 (99.343)
2025-08-28 06:46:35,565 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:35,565 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:37,148 - INFO - Epoch: [75][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3026 (0.4650) Acc@1 92.969 (83.792) Acc@5 98.438 (99.296)
2025-08-28 06:46:38,710 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:38,710 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:39,169 - INFO - Epoch: [75][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5735 (0.4679) Acc@1 82.812 (83.783) Acc@5 100.000 (99.325)
2025-08-28 06:46:41,059 - INFO - Test: [0/79] Time 0.110 (0.110) Loss 0.8958 (0.8958) Acc@1 71.094 (71.094) Acc@5 96.094 (96.094)
2025-08-28 06:46:41,919 - INFO - Epoch 75:
2025-08-28 06:46:41,920 - INFO -   Train: acc1: 83.8060 | acc5: 99.3060 | loss: 0.4683 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:46:41,920 - INFO -   Val:   acc1: 68.4600 | acc5: 98.5300 | loss: 1.1229
2025-08-28 06:46:41,920 - INFO -   LR: 0.100000
2025-08-28 06:46:41,935 - INFO - 
Epoch: 76, lr = 0.1
2025-08-28 06:46:42,102 - INFO - Epoch: [76][0/391] Time 0.166 (0.166) Data 0.143 (0.143) Loss 0.5313 (0.5313) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:46:42,946 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:42,947 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:44,080 - INFO - Epoch: [76][100/391] Time 0.027 (0.021) Data 0.013 (0.003) Loss 0.3856 (0.4785) Acc@1 86.719 (83.447) Acc@5 100.000 (99.273)
2025-08-28 06:46:45,936 - INFO - Epoch: [76][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4652 (0.4752) Acc@1 85.938 (83.703) Acc@5 98.438 (99.203)
2025-08-28 06:46:45,980 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:45,980 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:47,830 - INFO - Epoch: [76][300/391] Time 0.035 (0.020) Data 0.000 (0.002) Loss 0.4864 (0.4736) Acc@1 85.156 (83.781) Acc@5 100.000 (99.229)
2025-08-28 06:46:49,127 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:49,127 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:49,768 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6531 (0.6531) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-28 06:46:50,678 - INFO - Epoch 76:
2025-08-28 06:46:50,678 - INFO -   Train: acc1: 83.8600 | acc5: 99.2460 | loss: 0.4715 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:46:50,678 - INFO -   Val:   acc1: 78.4100 | acc5: 98.3000 | loss: 0.6715
2025-08-28 06:46:50,678 - INFO -   LR: 0.100000
2025-08-28 06:46:50,692 - INFO - 
Epoch: 77, lr = 0.1
2025-08-28 06:46:50,881 - INFO - Epoch: [77][0/391] Time 0.187 (0.187) Data 0.161 (0.161) Loss 0.4085 (0.4085) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:46:52,939 - INFO - Epoch: [77][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.5107 (0.4635) Acc@1 82.031 (84.073) Acc@5 100.000 (99.257)
2025-08-28 06:46:53,572 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:53,572 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:54,842 - INFO - Epoch: [77][200/391] Time 0.011 (0.021) Data 0.000 (0.002) Loss 0.4189 (0.4701) Acc@1 88.281 (83.792) Acc@5 100.000 (99.277)
2025-08-28 06:46:56,704 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:46:56,704 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:46:56,830 - INFO - Epoch: [77][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4018 (0.4708) Acc@1 85.156 (83.835) Acc@5 100.000 (99.281)
2025-08-28 06:46:58,732 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6085 (0.6085) Acc@1 78.906 (78.906) Acc@5 96.875 (96.875)
2025-08-28 06:46:59,596 - INFO - Epoch 77:
2025-08-28 06:46:59,596 - INFO -   Train: acc1: 83.7400 | acc5: 99.2760 | loss: 0.4729 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:46:59,596 - INFO -   Val:   acc1: 76.6200 | acc5: 97.6800 | loss: 0.7777
2025-08-28 06:46:59,596 - INFO -   LR: 0.100000
2025-08-28 06:46:59,610 - INFO - 
Epoch: 78, lr = 0.1
2025-08-28 06:46:59,803 - INFO - Epoch: [78][0/391] Time 0.192 (0.192) Data 0.166 (0.166) Loss 0.5408 (0.5408) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:47:00,959 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:00,959 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:01,766 - INFO - Epoch: [78][100/391] Time 0.018 (0.021) Data 0.000 (0.006) Loss 0.4617 (0.4695) Acc@1 81.250 (83.385) Acc@5 100.000 (99.265)
2025-08-28 06:47:03,706 - INFO - Epoch: [78][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.5161 (0.4731) Acc@1 85.156 (83.442) Acc@5 98.438 (99.293)
2025-08-28 06:47:04,088 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:04,088 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:05,639 - INFO - Epoch: [78][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5293 (0.4759) Acc@1 78.906 (83.381) Acc@5 99.219 (99.299)
2025-08-28 06:47:07,217 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:07,217 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:07,488 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.6136 (0.6136) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:47:08,349 - INFO - Epoch 78:
2025-08-28 06:47:08,349 - INFO -   Train: acc1: 83.4900 | acc5: 99.2660 | loss: 0.4753 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:47:08,349 - INFO -   Val:   acc1: 75.7900 | acc5: 98.9300 | loss: 0.7387
2025-08-28 06:47:08,349 - INFO -   LR: 0.100000
2025-08-28 06:47:08,363 - INFO - 
Epoch: 79, lr = 0.1
2025-08-28 06:47:08,551 - INFO - Epoch: [79][0/391] Time 0.187 (0.187) Data 0.159 (0.159) Loss 0.5080 (0.5080) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 06:47:10,623 - INFO - Epoch: [79][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.4998 (0.4774) Acc@1 81.250 (83.679) Acc@5 99.219 (99.265)
2025-08-28 06:47:11,612 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:11,612 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:12,603 - INFO - Epoch: [79][200/391] Time 0.027 (0.021) Data 0.000 (0.002) Loss 0.4002 (0.4734) Acc@1 89.062 (83.749) Acc@5 100.000 (99.320)
2025-08-28 06:47:14,576 - INFO - Epoch: [79][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.6480 (0.4757) Acc@1 77.344 (83.653) Acc@5 97.656 (99.320)
2025-08-28 06:47:14,777 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:14,778 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:16,482 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4886 (0.4886) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 06:47:17,352 - INFO - Epoch 79:
2025-08-28 06:47:17,352 - INFO -   Train: acc1: 83.3860 | acc5: 99.3180 | loss: 0.4780 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:47:17,352 - INFO -   Val:   acc1: 78.4400 | acc5: 99.0700 | loss: 0.6338
2025-08-28 06:47:17,352 - INFO -   LR: 0.100000
2025-08-28 06:47:17,367 - INFO - 
Epoch: 80, lr = 0.1
2025-08-28 06:47:17,554 - INFO - Epoch: [80][0/391] Time 0.186 (0.186) Data 0.159 (0.159) Loss 0.4219 (0.4219) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:47:19,078 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:19,078 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:19,492 - INFO - Epoch: [80][100/391] Time 0.034 (0.021) Data 0.019 (0.005) Loss 0.5310 (0.4672) Acc@1 78.906 (83.702) Acc@5 100.000 (99.296)
2025-08-28 06:47:21,332 - INFO - Epoch: [80][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4209 (0.4724) Acc@1 86.719 (83.539) Acc@5 99.219 (99.262)
2025-08-28 06:47:22,110 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:22,111 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:23,277 - INFO - Epoch: [80][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.5198 (0.4727) Acc@1 80.469 (83.630) Acc@5 99.219 (99.286)
2025-08-28 06:47:25,161 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5742 (0.5742) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 06:47:26,045 - INFO - Epoch 80:
2025-08-28 06:47:26,045 - INFO -   Train: acc1: 83.6100 | acc5: 99.2680 | loss: 0.4757 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:47:26,045 - INFO -   Val:   acc1: 76.5000 | acc5: 98.8000 | loss: 0.7190
2025-08-28 06:47:26,045 - INFO -   LR: 0.100000
2025-08-28 06:47:26,094 - INFO - 
Epoch: 81, lr = 0.1
2025-08-28 06:47:26,265 - INFO - Epoch: [81][0/391] Time 0.170 (0.170) Data 0.151 (0.151) Loss 0.5287 (0.5287) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 06:47:26,474 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:26,474 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:28,321 - INFO - Epoch: [81][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.4836 (0.4662) Acc@1 79.688 (83.942) Acc@5 100.000 (99.203)
2025-08-28 06:47:29,629 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:29,630 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:30,250 - INFO - Epoch: [81][200/391] Time 0.013 (0.021) Data 0.000 (0.002) Loss 0.4598 (0.4707) Acc@1 83.594 (83.881) Acc@5 100.000 (99.238)
2025-08-28 06:47:32,246 - INFO - Epoch: [81][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4584 (0.4706) Acc@1 82.812 (83.786) Acc@5 98.438 (99.258)
2025-08-28 06:47:32,811 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:32,811 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:34,087 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.8916 (0.8916) Acc@1 68.750 (68.750) Acc@5 97.656 (97.656)
2025-08-28 06:47:34,949 - INFO - Epoch 81:
2025-08-28 06:47:34,950 - INFO -   Train: acc1: 83.7280 | acc5: 99.2760 | loss: 0.4719 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:47:34,950 - INFO -   Val:   acc1: 74.7100 | acc5: 98.0700 | loss: 0.8087
2025-08-28 06:47:34,950 - INFO -   LR: 0.100000
2025-08-28 06:47:34,964 - INFO - 
Epoch: 82, lr = 0.1
2025-08-28 06:47:35,151 - INFO - Epoch: [82][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.5571 (0.5571) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-28 06:47:37,012 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:37,012 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:37,063 - INFO - Epoch: [82][100/391] Time 0.022 (0.021) Data 0.001 (0.003) Loss 0.4880 (0.4775) Acc@1 78.906 (83.718) Acc@5 99.219 (99.242)
2025-08-28 06:47:39,005 - INFO - Epoch: [82][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4740 (0.4821) Acc@1 81.250 (83.469) Acc@5 100.000 (99.234)
2025-08-28 06:47:40,070 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:40,070 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:40,929 - INFO - Epoch: [82][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4151 (0.4806) Acc@1 84.375 (83.493) Acc@5 100.000 (99.245)
2025-08-28 06:47:42,850 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.6455 (0.6455) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 06:47:43,661 - INFO - Epoch 82:
2025-08-28 06:47:43,661 - INFO -   Train: acc1: 83.6400 | acc5: 99.2840 | loss: 0.4759 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:47:43,661 - INFO -   Val:   acc1: 77.3100 | acc5: 98.8300 | loss: 0.6555
2025-08-28 06:47:43,661 - INFO -   LR: 0.100000
2025-08-28 06:47:43,677 - INFO - 
Epoch: 83, lr = 0.1
2025-08-28 06:47:43,861 - INFO - Epoch: [83][0/391] Time 0.183 (0.183) Data 0.159 (0.159) Loss 0.5182 (0.5182) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:47:44,403 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:44,403 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:45,771 - INFO - Epoch: [83][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.4506 (0.4660) Acc@1 83.594 (83.926) Acc@5 100.000 (99.327)
2025-08-28 06:47:47,409 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:47,410 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:47,675 - INFO - Epoch: [83][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4243 (0.4652) Acc@1 85.156 (84.060) Acc@5 100.000 (99.335)
2025-08-28 06:47:49,576 - INFO - Epoch: [83][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5398 (0.4719) Acc@1 83.594 (83.846) Acc@5 97.656 (99.278)
2025-08-28 06:47:50,518 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:50,519 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:51,406 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.7079 (0.7079) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 06:47:52,212 - INFO - Epoch 83:
2025-08-28 06:47:52,212 - INFO -   Train: acc1: 83.7160 | acc5: 99.2700 | loss: 0.4751 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:47:52,212 - INFO -   Val:   acc1: 72.6000 | acc5: 98.7000 | loss: 0.8533
2025-08-28 06:47:52,212 - INFO -   LR: 0.100000
2025-08-28 06:47:55,894 - INFO - 
Epoch: 84, lr = 0.1
2025-08-28 06:47:56,089 - INFO - Epoch: [84][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.3870 (0.3870) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 06:47:58,035 - INFO - Epoch: [84][100/391] Time 0.032 (0.021) Data 0.000 (0.003) Loss 0.5034 (0.4793) Acc@1 83.594 (83.346) Acc@5 99.219 (99.312)
2025-08-28 06:47:58,316 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:47:58,316 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:47:59,984 - INFO - Epoch: [84][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5684 (0.4772) Acc@1 81.250 (83.388) Acc@5 99.219 (99.331)
2025-08-28 06:48:01,521 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:01,521 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:02,046 - INFO - Epoch: [84][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3973 (0.4779) Acc@1 85.938 (83.384) Acc@5 100.000 (99.323)
2025-08-28 06:48:03,992 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.6373 (0.6373) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 06:48:04,833 - INFO - Epoch 84:
2025-08-28 06:48:04,833 - INFO -   Train: acc1: 83.2740 | acc5: 99.3040 | loss: 0.4814 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:04,833 - INFO -   Val:   acc1: 75.1700 | acc5: 98.4500 | loss: 0.7500
2025-08-28 06:48:04,833 - INFO -   LR: 0.100000
2025-08-28 06:48:04,846 - INFO - 
Epoch: 85, lr = 0.1
2025-08-28 06:48:05,022 - INFO - Epoch: [85][0/391] Time 0.175 (0.175) Data 0.155 (0.155) Loss 0.6173 (0.6173) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-28 06:48:05,956 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:05,956 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:07,059 - INFO - Epoch: [85][100/391] Time 0.012 (0.022) Data 0.000 (0.005) Loss 0.4392 (0.4692) Acc@1 82.031 (83.926) Acc@5 99.219 (99.273)
2025-08-28 06:48:08,939 - INFO - Epoch: [85][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3721 (0.4688) Acc@1 88.281 (83.889) Acc@5 99.219 (99.339)
2025-08-28 06:48:09,021 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:09,021 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:10,784 - INFO - Epoch: [85][300/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.5441 (0.4671) Acc@1 78.125 (83.908) Acc@5 100.000 (99.315)
2025-08-28 06:48:12,044 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:12,044 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:12,679 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.5081 (0.5081) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:48:13,501 - INFO - Epoch 85:
2025-08-28 06:48:13,501 - INFO -   Train: acc1: 83.7660 | acc5: 99.2920 | loss: 0.4727 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:13,501 - INFO -   Val:   acc1: 79.2000 | acc5: 99.2200 | loss: 0.6186
2025-08-28 06:48:13,501 - INFO -   LR: 0.100000
2025-08-28 06:48:13,517 - INFO - 
Epoch: 86, lr = 0.1
2025-08-28 06:48:13,697 - INFO - Epoch: [86][0/391] Time 0.179 (0.179) Data 0.157 (0.157) Loss 0.2856 (0.2856) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:48:15,672 - INFO - Epoch: [86][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4656 (0.4626) Acc@1 82.812 (84.298) Acc@5 99.219 (99.343)
2025-08-28 06:48:16,332 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:16,332 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:17,649 - INFO - Epoch: [86][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.4895 (0.4682) Acc@1 80.469 (84.037) Acc@5 99.219 (99.355)
2025-08-28 06:48:19,419 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:19,419 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:19,556 - INFO - Epoch: [86][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4214 (0.4696) Acc@1 86.719 (83.934) Acc@5 100.000 (99.364)
2025-08-28 06:48:21,409 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5251 (0.5251) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:48:22,251 - INFO - Epoch 86:
2025-08-28 06:48:22,252 - INFO -   Train: acc1: 83.9460 | acc5: 99.3320 | loss: 0.4698 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:22,252 - INFO -   Val:   acc1: 78.6600 | acc5: 98.7500 | loss: 0.6505
2025-08-28 06:48:22,252 - INFO -   LR: 0.100000
2025-08-28 06:48:22,268 - INFO - 
Epoch: 87, lr = 0.1
2025-08-28 06:48:22,459 - INFO - Epoch: [87][0/391] Time 0.190 (0.190) Data 0.158 (0.158) Loss 0.4830 (0.4830) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:48:23,691 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:23,691 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:24,417 - INFO - Epoch: [87][100/391] Time 0.019 (0.021) Data 0.005 (0.003) Loss 0.4004 (0.4726) Acc@1 85.156 (83.787) Acc@5 99.219 (99.234)
2025-08-28 06:48:26,331 - INFO - Epoch: [87][200/391] Time 0.021 (0.020) Data 0.005 (0.002) Loss 0.3302 (0.4723) Acc@1 88.281 (83.792) Acc@5 100.000 (99.312)
2025-08-28 06:48:26,717 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:26,717 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:28,158 - INFO - Epoch: [87][300/391] Time 0.016 (0.020) Data 0.005 (0.002) Loss 0.5608 (0.4704) Acc@1 80.469 (83.895) Acc@5 98.438 (99.325)
2025-08-28 06:48:29,775 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:29,775 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:30,055 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6099 (0.6099) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:48:30,900 - INFO - Epoch 87:
2025-08-28 06:48:30,900 - INFO -   Train: acc1: 83.7840 | acc5: 99.3060 | loss: 0.4718 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:30,900 - INFO -   Val:   acc1: 78.6400 | acc5: 99.0900 | loss: 0.6159
2025-08-28 06:48:30,900 - INFO -   LR: 0.100000
2025-08-28 06:48:31,864 - INFO - 
Epoch: 88, lr = 0.1
2025-08-28 06:48:32,059 - INFO - Epoch: [88][0/391] Time 0.194 (0.194) Data 0.164 (0.164) Loss 0.4969 (0.4969) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:48:34,100 - INFO - Epoch: [88][100/391] Time 0.019 (0.022) Data 0.000 (0.004) Loss 0.5299 (0.4728) Acc@1 80.469 (83.725) Acc@5 100.000 (99.242)
2025-08-28 06:48:35,199 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:35,199 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:36,185 - INFO - Epoch: [88][200/391] Time 0.025 (0.021) Data 0.001 (0.003) Loss 0.5188 (0.4716) Acc@1 82.812 (83.609) Acc@5 98.438 (99.273)
2025-08-28 06:48:38,192 - INFO - Epoch: [88][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.6534 (0.4713) Acc@1 81.250 (83.744) Acc@5 100.000 (99.258)
2025-08-28 06:48:38,425 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:38,425 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:40,155 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.9531 (0.9531) Acc@1 65.625 (65.625) Acc@5 99.219 (99.219)
2025-08-28 06:48:40,999 - INFO - Epoch 88:
2025-08-28 06:48:40,999 - INFO -   Train: acc1: 83.7700 | acc5: 99.2460 | loss: 0.4732 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:40,999 - INFO -   Val:   acc1: 67.7000 | acc5: 96.8100 | loss: 1.0148
2025-08-28 06:48:40,999 - INFO -   LR: 0.100000
2025-08-28 06:48:41,014 - INFO - 
Epoch: 89, lr = 0.1
2025-08-28 06:48:41,180 - INFO - Epoch: [89][0/391] Time 0.165 (0.165) Data 0.144 (0.144) Loss 0.4639 (0.4639) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 06:48:43,002 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:43,002 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:43,388 - INFO - Epoch: [89][100/391] Time 0.021 (0.023) Data 0.000 (0.005) Loss 0.5419 (0.4602) Acc@1 82.812 (84.274) Acc@5 99.219 (99.296)
2025-08-28 06:48:45,343 - INFO - Epoch: [89][200/391] Time 0.011 (0.022) Data 0.000 (0.003) Loss 0.4985 (0.4701) Acc@1 80.469 (83.843) Acc@5 99.219 (99.320)
2025-08-28 06:48:46,075 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:46,075 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:47,244 - INFO - Epoch: [89][300/391] Time 0.027 (0.021) Data 0.000 (0.003) Loss 0.7113 (0.4715) Acc@1 76.562 (83.796) Acc@5 98.438 (99.325)
2025-08-28 06:48:49,042 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7248 (0.7248) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-28 06:48:49,913 - INFO - Epoch 89:
2025-08-28 06:48:49,914 - INFO -   Train: acc1: 83.7580 | acc5: 99.3240 | loss: 0.4728 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:49,914 - INFO -   Val:   acc1: 74.5700 | acc5: 98.2500 | loss: 0.7952
2025-08-28 06:48:49,914 - INFO -   LR: 0.100000
2025-08-28 06:48:49,928 - INFO - 
Epoch: 90, lr = 0.1
2025-08-28 06:48:50,114 - INFO - Epoch: [90][0/391] Time 0.185 (0.185) Data 0.161 (0.161) Loss 0.4952 (0.4952) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:48:50,289 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:50,289 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:52,229 - INFO - Epoch: [90][100/391] Time 0.011 (0.023) Data 0.000 (0.004) Loss 0.5628 (0.4668) Acc@1 80.469 (83.501) Acc@5 99.219 (99.296)
2025-08-28 06:48:53,574 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:53,574 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:54,154 - INFO - Epoch: [90][200/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.3874 (0.4685) Acc@1 88.281 (83.648) Acc@5 99.219 (99.331)
2025-08-28 06:48:56,078 - INFO - Epoch: [90][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5817 (0.4676) Acc@1 82.812 (83.871) Acc@5 98.438 (99.325)
2025-08-28 06:48:56,645 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:48:56,645 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:48:57,919 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.6708 (0.6708) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 06:48:59,040 - INFO - Epoch 90:
2025-08-28 06:48:59,040 - INFO -   Train: acc1: 83.7860 | acc5: 99.3200 | loss: 0.4710 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:48:59,040 - INFO -   Val:   acc1: 74.8400 | acc5: 97.9300 | loss: 0.7683
2025-08-28 06:48:59,040 - INFO -   LR: 0.100000
2025-08-28 06:48:59,088 - INFO - 
Epoch: 91, lr = 0.1
2025-08-28 06:48:59,272 - INFO - Epoch: [91][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.4557 (0.4557) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:49:01,174 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:01,174 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:01,202 - INFO - Epoch: [91][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.4890 (0.4430) Acc@1 82.031 (84.537) Acc@5 99.219 (99.459)
2025-08-28 06:49:03,150 - INFO - Epoch: [91][200/391] Time 0.021 (0.020) Data 0.001 (0.002) Loss 0.5450 (0.4634) Acc@1 85.156 (84.107) Acc@5 99.219 (99.324)
2025-08-28 06:49:04,225 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:04,225 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:05,069 - INFO - Epoch: [91][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4639 (0.4658) Acc@1 84.375 (83.999) Acc@5 99.219 (99.286)
2025-08-28 06:49:06,964 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.6984 (0.6984) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:49:07,823 - INFO - Epoch 91:
2025-08-28 06:49:07,823 - INFO -   Train: acc1: 83.7400 | acc5: 99.2700 | loss: 0.4724 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:07,823 - INFO -   Val:   acc1: 75.6600 | acc5: 98.6700 | loss: 0.7864
2025-08-28 06:49:07,823 - INFO -   LR: 0.100000
2025-08-28 06:49:07,838 - INFO - 
Epoch: 92, lr = 0.1
2025-08-28 06:49:08,035 - INFO - Epoch: [92][0/391] Time 0.196 (0.196) Data 0.171 (0.171) Loss 0.4364 (0.4364) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:49:08,599 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:08,599 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:10,037 - INFO - Epoch: [92][100/391] Time 0.013 (0.022) Data 0.000 (0.003) Loss 0.5073 (0.4649) Acc@1 83.594 (84.004) Acc@5 98.438 (99.242)
2025-08-28 06:49:11,673 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:11,674 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:11,914 - INFO - Epoch: [92][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3542 (0.4654) Acc@1 88.281 (83.920) Acc@5 100.000 (99.258)
2025-08-28 06:49:13,838 - INFO - Epoch: [92][300/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.3807 (0.4699) Acc@1 85.938 (83.786) Acc@5 99.219 (99.250)
2025-08-28 06:49:14,747 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:14,748 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:15,684 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.9502 (0.9502) Acc@1 72.656 (72.656) Acc@5 97.656 (97.656)
2025-08-28 06:49:16,521 - INFO - Epoch 92:
2025-08-28 06:49:16,521 - INFO -   Train: acc1: 83.7880 | acc5: 99.2680 | loss: 0.4705 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:16,521 - INFO -   Val:   acc1: 71.5600 | acc5: 97.7000 | loss: 0.9496
2025-08-28 06:49:16,521 - INFO -   LR: 0.100000
2025-08-28 06:49:16,534 - INFO - 
Epoch: 93, lr = 0.1
2025-08-28 06:49:16,720 - INFO - Epoch: [93][0/391] Time 0.186 (0.186) Data 0.157 (0.157) Loss 0.4769 (0.4769) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:49:18,588 - INFO - Epoch: [93][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3735 (0.4811) Acc@1 89.062 (83.400) Acc@5 100.000 (99.265)
2025-08-28 06:49:18,902 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:18,902 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:20,468 - INFO - Epoch: [93][200/391] Time 0.031 (0.020) Data 0.020 (0.003) Loss 0.3330 (0.4675) Acc@1 89.062 (83.979) Acc@5 100.000 (99.277)
2025-08-28 06:49:21,980 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:21,980 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:22,445 - INFO - Epoch: [93][300/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.4771 (0.4690) Acc@1 82.031 (83.848) Acc@5 99.219 (99.307)
2025-08-28 06:49:24,237 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6742 (0.6742) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:49:25,064 - INFO - Epoch 93:
2025-08-28 06:49:25,064 - INFO -   Train: acc1: 83.7000 | acc5: 99.2640 | loss: 0.4716 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:25,064 - INFO -   Val:   acc1: 77.2600 | acc5: 97.5000 | loss: 0.7499
2025-08-28 06:49:25,064 - INFO -   LR: 0.100000
2025-08-28 06:49:25,078 - INFO - 
Epoch: 94, lr = 0.1
2025-08-28 06:49:25,256 - INFO - Epoch: [94][0/391] Time 0.177 (0.177) Data 0.150 (0.150) Loss 0.4759 (0.4759) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-28 06:49:26,138 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:26,138 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:27,103 - INFO - Epoch: [94][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.3776 (0.4672) Acc@1 91.406 (83.988) Acc@5 98.438 (99.219)
2025-08-28 06:49:29,001 - INFO - Epoch: [94][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.5273 (0.4751) Acc@1 82.031 (83.625) Acc@5 99.219 (99.223)
2025-08-28 06:49:29,100 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:29,100 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:30,919 - INFO - Epoch: [94][300/391] Time 0.022 (0.019) Data 0.004 (0.003) Loss 0.4631 (0.4736) Acc@1 85.156 (83.703) Acc@5 99.219 (99.234)
2025-08-28 06:49:32,198 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:32,198 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:32,814 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4844 (0.4844) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:49:33,652 - INFO - Epoch 94:
2025-08-28 06:49:33,652 - INFO -   Train: acc1: 83.4500 | acc5: 99.2560 | loss: 0.4794 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:33,652 - INFO -   Val:   acc1: 80.7100 | acc5: 99.0100 | loss: 0.5579
2025-08-28 06:49:33,652 - INFO -   LR: 0.100000
2025-08-28 06:49:33,667 - INFO - 
Epoch: 95, lr = 0.1
2025-08-28 06:49:33,849 - INFO - Epoch: [95][0/391] Time 0.181 (0.181) Data 0.164 (0.164) Loss 0.4354 (0.4354) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:49:35,739 - INFO - Epoch: [95][100/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4545 (0.4626) Acc@1 86.719 (84.352) Acc@5 100.000 (99.250)
2025-08-28 06:49:36,376 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:36,376 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:37,632 - INFO - Epoch: [95][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.5586 (0.4656) Acc@1 77.344 (84.049) Acc@5 98.438 (99.316)
2025-08-28 06:49:39,419 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:39,420 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:39,532 - INFO - Epoch: [95][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.3901 (0.4701) Acc@1 87.500 (83.910) Acc@5 100.000 (99.302)
2025-08-28 06:49:41,504 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5220 (0.5220) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 06:49:42,346 - INFO - Epoch 95:
2025-08-28 06:49:42,347 - INFO -   Train: acc1: 83.9880 | acc5: 99.3280 | loss: 0.4663 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:42,347 - INFO -   Val:   acc1: 79.8300 | acc5: 98.8500 | loss: 0.5948
2025-08-28 06:49:42,347 - INFO -   LR: 0.100000
2025-08-28 06:49:42,362 - INFO - 
Epoch: 96, lr = 0.1
2025-08-28 06:49:42,561 - INFO - Epoch: [96][0/391] Time 0.198 (0.198) Data 0.154 (0.154) Loss 0.5193 (0.5193) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-28 06:49:43,782 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:43,782 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:44,482 - INFO - Epoch: [96][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4410 (0.4736) Acc@1 82.812 (83.516) Acc@5 97.656 (99.281)
2025-08-28 06:49:46,439 - INFO - Epoch: [96][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.6089 (0.4779) Acc@1 78.906 (83.372) Acc@5 96.094 (99.223)
2025-08-28 06:49:46,896 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:46,896 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:48,359 - INFO - Epoch: [96][300/391] Time 0.032 (0.020) Data 0.018 (0.002) Loss 0.3846 (0.4806) Acc@1 87.500 (83.287) Acc@5 99.219 (99.229)
2025-08-28 06:49:49,997 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:49,998 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:50,251 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.4744 (0.4744) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:49:51,113 - INFO - Epoch 96:
2025-08-28 06:49:51,113 - INFO -   Train: acc1: 83.5020 | acc5: 99.2540 | loss: 0.4755 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:51,113 - INFO -   Val:   acc1: 81.8600 | acc5: 99.3400 | loss: 0.5291
2025-08-28 06:49:51,113 - INFO -   LR: 0.100000
2025-08-28 06:49:51,128 - INFO - 
Epoch: 97, lr = 0.1
2025-08-28 06:49:51,328 - INFO - Epoch: [97][0/391] Time 0.198 (0.198) Data 0.167 (0.167) Loss 0.3835 (0.3835) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:49:53,214 - INFO - Epoch: [97][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.3896 (0.4611) Acc@1 86.719 (84.135) Acc@5 100.000 (99.412)
2025-08-28 06:49:54,238 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:54,238 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:55,148 - INFO - Epoch: [97][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4764 (0.4693) Acc@1 85.938 (83.866) Acc@5 97.656 (99.374)
2025-08-28 06:49:57,036 - INFO - Epoch: [97][300/391] Time 0.021 (0.020) Data 0.001 (0.002) Loss 0.4549 (0.4722) Acc@1 84.375 (83.656) Acc@5 100.000 (99.336)
2025-08-28 06:49:57,273 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:49:57,273 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:49:58,938 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5876 (0.5876) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-28 06:49:59,768 - INFO - Epoch 97:
2025-08-28 06:49:59,768 - INFO -   Train: acc1: 83.4620 | acc5: 99.2920 | loss: 0.4792 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:49:59,769 - INFO -   Val:   acc1: 79.3800 | acc5: 98.7000 | loss: 0.6388
2025-08-28 06:49:59,769 - INFO -   LR: 0.100000
2025-08-28 06:49:59,783 - INFO - 
Epoch: 98, lr = 0.1
2025-08-28 06:49:59,969 - INFO - Epoch: [98][0/391] Time 0.185 (0.185) Data 0.160 (0.160) Loss 0.5389 (0.5389) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:50:01,470 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:01,470 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:01,824 - INFO - Epoch: [98][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.3798 (0.4655) Acc@1 85.938 (84.228) Acc@5 100.000 (99.335)
2025-08-28 06:50:03,709 - INFO - Epoch: [98][200/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.5210 (0.4723) Acc@1 79.688 (83.734) Acc@5 99.219 (99.262)
2025-08-28 06:50:04,485 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:04,485 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:05,622 - INFO - Epoch: [98][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.3885 (0.4712) Acc@1 88.281 (83.833) Acc@5 97.656 (99.302)
2025-08-28 06:50:07,500 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5843 (0.5843) Acc@1 80.469 (80.469) Acc@5 96.875 (96.875)
2025-08-28 06:50:08,347 - INFO - Epoch 98:
2025-08-28 06:50:08,347 - INFO -   Train: acc1: 83.7200 | acc5: 99.2800 | loss: 0.4750 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:50:08,347 - INFO -   Val:   acc1: 78.7900 | acc5: 98.3400 | loss: 0.6438
2025-08-28 06:50:08,347 - INFO -   LR: 0.100000
2025-08-28 06:50:08,362 - INFO - 
Epoch: 99, lr = 0.1
2025-08-28 06:50:08,567 - INFO - Epoch: [99][0/391] Time 0.205 (0.205) Data 0.180 (0.180) Loss 0.4752 (0.4752) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:50:08,792 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:08,793 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:10,505 - INFO - Epoch: [99][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.4494 (0.4733) Acc@1 85.938 (83.346) Acc@5 98.438 (99.234)
2025-08-28 06:50:11,906 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:11,906 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:12,455 - INFO - Epoch: [99][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4258 (0.4836) Acc@1 87.500 (83.015) Acc@5 100.000 (99.242)
2025-08-28 06:50:14,413 - INFO - Epoch: [99][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.4442 (0.4796) Acc@1 86.719 (83.313) Acc@5 97.656 (99.260)
2025-08-28 06:50:15,000 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:15,000 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:16,269 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6233 (0.6233) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 06:50:17,108 - INFO - Epoch 99:
2025-08-28 06:50:17,108 - INFO -   Train: acc1: 83.5060 | acc5: 99.2640 | loss: 0.4745 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:50:17,109 - INFO -   Val:   acc1: 77.5200 | acc5: 98.9000 | loss: 0.6909
2025-08-28 06:50:17,109 - INFO -   LR: 0.010000
2025-08-28 06:50:17,125 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-28 06:50:17,324 - INFO - Epoch: [100][0/391] Time 0.198 (0.198) Data 0.165 (0.165) Loss 0.3878 (0.3878) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:50:19,225 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:19,225 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:19,248 - INFO - Epoch: [100][100/391] Time 0.034 (0.021) Data 0.000 (0.003) Loss 0.2990 (0.3949) Acc@1 90.625 (86.402) Acc@5 100.000 (99.435)
2025-08-28 06:50:21,199 - INFO - Epoch: [100][200/391] Time 0.020 (0.020) Data 0.002 (0.003) Loss 0.3993 (0.3826) Acc@1 85.938 (86.913) Acc@5 100.000 (99.487)
2025-08-28 06:50:22,306 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:22,307 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:23,034 - INFO - Epoch: [100][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2396 (0.3732) Acc@1 91.406 (87.176) Acc@5 100.000 (99.502)
2025-08-28 06:50:24,930 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.3033 (0.3033) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:50:25,796 - INFO - Epoch 100:
2025-08-28 06:50:25,796 - INFO -   Train: acc1: 87.4640 | acc5: 99.4900 | loss: 0.3669 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:50:25,796 - INFO -   Val:   acc1: 87.1200 | acc5: 99.5600 | loss: 0.3736
2025-08-28 06:50:25,796 - INFO -   LR: 0.010000
2025-08-28 06:50:25,847 - INFO - Checkpoint saved: epoch=100, metric=87.1200
2025-08-28 06:50:25,880 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-28 06:50:26,069 - INFO - Epoch: [101][0/391] Time 0.188 (0.188) Data 0.162 (0.162) Loss 0.4011 (0.4011) Acc@1 89.062 (89.062) Acc@5 97.656 (97.656)
2025-08-28 06:50:26,649 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:26,649 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:28,060 - INFO - Epoch: [101][100/391] Time 0.026 (0.022) Data 0.003 (0.003) Loss 0.2210 (0.3321) Acc@1 93.750 (89.062) Acc@5 100.000 (99.520)
2025-08-28 06:50:29,792 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:29,792 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:30,021 - INFO - Epoch: [101][200/391] Time 0.031 (0.021) Data 0.000 (0.002) Loss 0.2514 (0.3275) Acc@1 90.625 (88.973) Acc@5 100.000 (99.619)
2025-08-28 06:50:31,982 - INFO - Epoch: [101][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3389 (0.3285) Acc@1 85.156 (88.803) Acc@5 100.000 (99.637)
2025-08-28 06:50:32,973 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:32,973 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:33,897 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2921 (0.2921) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:50:34,788 - INFO - Epoch 101:
2025-08-28 06:50:34,788 - INFO -   Train: acc1: 88.6640 | acc5: 99.6280 | loss: 0.3319 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:50:34,788 - INFO -   Val:   acc1: 87.0700 | acc5: 99.5700 | loss: 0.3745
2025-08-28 06:50:34,788 - INFO -   LR: 0.010000
2025-08-28 06:50:34,802 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-28 06:50:34,986 - INFO - Epoch: [102][0/391] Time 0.183 (0.183) Data 0.167 (0.167) Loss 0.3411 (0.3411) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:50:36,889 - INFO - Epoch: [102][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.3036 (0.3317) Acc@1 89.062 (88.877) Acc@5 100.000 (99.629)
2025-08-28 06:50:37,257 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:37,257 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:38,790 - INFO - Epoch: [102][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2853 (0.3289) Acc@1 89.844 (88.833) Acc@5 100.000 (99.654)
2025-08-28 06:50:40,318 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:40,318 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:40,753 - INFO - Epoch: [102][300/391] Time 0.019 (0.020) Data 0.005 (0.002) Loss 0.3650 (0.3258) Acc@1 88.281 (88.894) Acc@5 100.000 (99.642)
2025-08-28 06:50:42,688 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2605 (0.2605) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:50:43,574 - INFO - Epoch 102:
2025-08-28 06:50:43,575 - INFO -   Train: acc1: 88.9660 | acc5: 99.6700 | loss: 0.3230 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:50:43,575 - INFO -   Val:   acc1: 87.4000 | acc5: 99.6700 | loss: 0.3631
2025-08-28 06:50:43,575 - INFO -   LR: 0.010000
2025-08-28 06:50:43,627 - INFO - Checkpoint saved: epoch=102, metric=87.4000
2025-08-28 06:50:43,663 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-28 06:50:43,857 - INFO - Epoch: [103][0/391] Time 0.193 (0.193) Data 0.156 (0.156) Loss 0.4095 (0.4095) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:50:44,841 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:44,841 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:45,971 - INFO - Epoch: [103][100/391] Time 0.016 (0.023) Data 0.000 (0.004) Loss 0.3373 (0.3153) Acc@1 86.719 (89.194) Acc@5 99.219 (99.636)
2025-08-28 06:50:47,882 - INFO - Epoch: [103][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.3425 (0.3142) Acc@1 91.406 (89.307) Acc@5 100.000 (99.666)
2025-08-28 06:50:48,020 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:48,020 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:49,791 - INFO - Epoch: [103][300/391] Time 0.031 (0.020) Data 0.012 (0.002) Loss 0.4566 (0.3144) Acc@1 86.719 (89.309) Acc@5 97.656 (99.665)
2025-08-28 06:50:51,087 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:51,087 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:51,736 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.3092 (0.3092) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:50:52,593 - INFO - Epoch 103:
2025-08-28 06:50:52,593 - INFO -   Train: acc1: 89.2480 | acc5: 99.6780 | loss: 0.3158 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:50:52,593 - INFO -   Val:   acc1: 87.6600 | acc5: 99.5700 | loss: 0.3651
2025-08-28 06:50:52,593 - INFO -   LR: 0.010000
2025-08-28 06:50:52,641 - INFO - Checkpoint saved: epoch=103, metric=87.6600
2025-08-28 06:50:52,673 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-28 06:50:52,850 - INFO - Epoch: [104][0/391] Time 0.176 (0.176) Data 0.146 (0.146) Loss 0.3803 (0.3803) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:50:54,684 - INFO - Epoch: [104][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2729 (0.3065) Acc@1 91.406 (89.735) Acc@5 100.000 (99.737)
2025-08-28 06:50:55,408 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:55,408 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:56,661 - INFO - Epoch: [104][200/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.3159 (0.3124) Acc@1 89.844 (89.455) Acc@5 99.219 (99.708)
2025-08-28 06:50:58,441 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:50:58,441 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:50:58,530 - INFO - Epoch: [104][300/391] Time 0.031 (0.019) Data 0.000 (0.002) Loss 0.2349 (0.3126) Acc@1 91.406 (89.397) Acc@5 100.000 (99.686)
2025-08-28 06:51:00,367 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2826 (0.2826) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:51:01,224 - INFO - Epoch 104:
2025-08-28 06:51:01,224 - INFO -   Train: acc1: 89.3220 | acc5: 99.6780 | loss: 0.3141 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:01,225 - INFO -   Val:   acc1: 87.9300 | acc5: 99.6600 | loss: 0.3580
2025-08-28 06:51:01,225 - INFO -   LR: 0.010000
2025-08-28 06:51:01,276 - INFO - Checkpoint saved: epoch=104, metric=87.9300
2025-08-28 06:51:01,309 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-28 06:51:01,490 - INFO - Epoch: [105][0/391] Time 0.180 (0.180) Data 0.158 (0.158) Loss 0.3046 (0.3046) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:51:02,864 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:02,864 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:03,597 - INFO - Epoch: [105][100/391] Time 0.027 (0.023) Data 0.013 (0.003) Loss 0.3216 (0.2973) Acc@1 87.500 (89.983) Acc@5 100.000 (99.722)
2025-08-28 06:51:05,625 - INFO - Epoch: [105][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.2689 (0.3045) Acc@1 90.625 (89.661) Acc@5 99.219 (99.712)
2025-08-28 06:51:06,096 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:06,096 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:07,518 - INFO - Epoch: [105][300/391] Time 0.018 (0.021) Data 0.001 (0.002) Loss 0.3895 (0.3073) Acc@1 85.938 (89.423) Acc@5 98.438 (99.704)
2025-08-28 06:51:09,202 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:09,202 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:09,433 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2571 (0.2571) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:51:10,292 - INFO - Epoch 105:
2025-08-28 06:51:10,292 - INFO -   Train: acc1: 89.4800 | acc5: 99.6960 | loss: 0.3063 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:10,292 - INFO -   Val:   acc1: 87.4600 | acc5: 99.5300 | loss: 0.3784
2025-08-28 06:51:10,292 - INFO -   LR: 0.010000
2025-08-28 06:51:10,309 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-28 06:51:10,510 - INFO - Epoch: [106][0/391] Time 0.199 (0.199) Data 0.173 (0.173) Loss 0.2169 (0.2169) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:51:12,373 - INFO - Epoch: [106][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1690 (0.3010) Acc@1 96.094 (89.705) Acc@5 100.000 (99.667)
2025-08-28 06:51:13,405 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:13,405 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:14,315 - INFO - Epoch: [106][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3228 (0.3010) Acc@1 89.062 (89.704) Acc@5 100.000 (99.677)
2025-08-28 06:51:16,207 - INFO - Epoch: [106][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.5661 (0.3041) Acc@1 80.469 (89.618) Acc@5 100.000 (99.676)
2025-08-28 06:51:16,457 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:16,457 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:18,128 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2911 (0.2911) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:51:19,016 - INFO - Epoch 106:
2025-08-28 06:51:19,016 - INFO -   Train: acc1: 89.5280 | acc5: 99.6780 | loss: 0.3078 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:19,016 - INFO -   Val:   acc1: 87.6600 | acc5: 99.5800 | loss: 0.3652
2025-08-28 06:51:19,016 - INFO -   LR: 0.010000
2025-08-28 06:51:19,032 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-28 06:51:19,236 - INFO - Epoch: [107][0/391] Time 0.203 (0.203) Data 0.176 (0.176) Loss 0.2206 (0.2206) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:51:20,882 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:20,882 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:21,262 - INFO - Epoch: [107][100/391] Time 0.020 (0.022) Data 0.003 (0.003) Loss 0.2272 (0.2957) Acc@1 92.188 (90.053) Acc@5 100.000 (99.722)
2025-08-28 06:51:23,170 - INFO - Epoch: [107][200/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.3648 (0.3013) Acc@1 88.281 (89.817) Acc@5 99.219 (99.697)
2025-08-28 06:51:24,001 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:24,001 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:25,169 - INFO - Epoch: [107][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3049 (0.3019) Acc@1 89.062 (89.776) Acc@5 99.219 (99.696)
2025-08-28 06:51:27,096 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2814 (0.2814) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:51:28,002 - INFO - Epoch 107:
2025-08-28 06:51:28,002 - INFO -   Train: acc1: 89.6320 | acc5: 99.6800 | loss: 0.3051 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:28,002 - INFO -   Val:   acc1: 88.0700 | acc5: 99.6200 | loss: 0.3609
2025-08-28 06:51:28,002 - INFO -   LR: 0.010000
2025-08-28 06:51:28,050 - INFO - Checkpoint saved: epoch=107, metric=88.0700
2025-08-28 06:51:28,081 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-28 06:51:28,244 - INFO - Epoch: [108][0/391] Time 0.162 (0.162) Data 0.146 (0.146) Loss 0.1945 (0.1945) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:51:28,500 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:28,500 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:30,187 - INFO - Epoch: [108][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3193 (0.2968) Acc@1 86.719 (89.913) Acc@5 100.000 (99.667)
2025-08-28 06:51:31,502 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:31,502 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:32,057 - INFO - Epoch: [108][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2725 (0.3026) Acc@1 89.844 (89.626) Acc@5 100.000 (99.701)
2025-08-28 06:51:33,984 - INFO - Epoch: [108][300/391] Time 0.038 (0.020) Data 0.016 (0.002) Loss 0.2228 (0.3013) Acc@1 93.750 (89.691) Acc@5 100.000 (99.704)
2025-08-28 06:51:34,534 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:34,535 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:35,782 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2630 (0.2630) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:51:36,646 - INFO - Epoch 108:
2025-08-28 06:51:36,646 - INFO -   Train: acc1: 89.7020 | acc5: 99.6780 | loss: 0.3020 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:36,646 - INFO -   Val:   acc1: 87.9800 | acc5: 99.5600 | loss: 0.3586
2025-08-28 06:51:36,646 - INFO -   LR: 0.010000
2025-08-28 06:51:36,660 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-28 06:51:36,827 - INFO - Epoch: [109][0/391] Time 0.166 (0.166) Data 0.144 (0.144) Loss 0.2287 (0.2287) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:51:38,860 - INFO - Epoch: [109][100/391] Time 0.011 (0.022) Data 0.000 (0.004) Loss 0.3288 (0.3036) Acc@1 92.188 (89.581) Acc@5 100.000 (99.752)
2025-08-28 06:51:38,870 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:38,870 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:40,781 - INFO - Epoch: [109][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.3240 (0.3009) Acc@1 89.844 (89.731) Acc@5 99.219 (99.701)
2025-08-28 06:51:41,942 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:41,942 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:42,666 - INFO - Epoch: [109][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3442 (0.3001) Acc@1 84.375 (89.722) Acc@5 100.000 (99.707)
2025-08-28 06:51:44,556 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2782 (0.2782) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:51:45,389 - INFO - Epoch 109:
2025-08-28 06:51:45,390 - INFO -   Train: acc1: 89.5780 | acc5: 99.7020 | loss: 0.3036 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:45,390 - INFO -   Val:   acc1: 87.8600 | acc5: 99.6000 | loss: 0.3607
2025-08-28 06:51:45,390 - INFO -   LR: 0.010000
2025-08-28 06:51:45,404 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-28 06:51:45,612 - INFO - Epoch: [110][0/391] Time 0.207 (0.207) Data 0.180 (0.180) Loss 0.2512 (0.2512) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:51:46,190 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:46,190 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:47,497 - INFO - Epoch: [110][100/391] Time 0.035 (0.021) Data 0.021 (0.004) Loss 0.3072 (0.3051) Acc@1 88.281 (89.689) Acc@5 100.000 (99.636)
2025-08-28 06:51:49,271 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:49,271 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:49,497 - INFO - Epoch: [110][200/391] Time 0.037 (0.020) Data 0.013 (0.003) Loss 0.2610 (0.3024) Acc@1 91.406 (89.653) Acc@5 100.000 (99.697)
2025-08-28 06:51:51,409 - INFO - Epoch: [110][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3147 (0.3029) Acc@1 87.500 (89.644) Acc@5 99.219 (99.678)
2025-08-28 06:51:52,376 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:52,376 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:53,286 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2632 (0.2632) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:51:54,142 - INFO - Epoch 110:
2025-08-28 06:51:54,142 - INFO -   Train: acc1: 89.6400 | acc5: 99.6880 | loss: 0.3022 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:51:54,142 - INFO -   Val:   acc1: 87.6300 | acc5: 99.6200 | loss: 0.3622
2025-08-28 06:51:54,142 - INFO -   LR: 0.010000
2025-08-28 06:51:54,194 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-28 06:51:54,388 - INFO - Epoch: [111][0/391] Time 0.193 (0.193) Data 0.168 (0.168) Loss 0.2544 (0.2544) Acc@1 93.750 (93.750) Acc@5 98.438 (98.438)
2025-08-28 06:51:56,405 - INFO - Epoch: [111][100/391] Time 0.026 (0.022) Data 0.013 (0.003) Loss 0.2900 (0.2876) Acc@1 90.625 (90.285) Acc@5 98.438 (99.706)
2025-08-28 06:51:56,773 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:56,773 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:51:58,346 - INFO - Epoch: [111][200/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.2684 (0.2966) Acc@1 89.062 (89.984) Acc@5 100.000 (99.716)
2025-08-28 06:51:59,864 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:51:59,864 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:00,304 - INFO - Epoch: [111][300/391] Time 0.027 (0.020) Data 0.001 (0.002) Loss 0.3085 (0.2997) Acc@1 89.844 (89.826) Acc@5 99.219 (99.673)
2025-08-28 06:52:02,222 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2399 (0.2399) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:52:03,062 - INFO - Epoch 111:
2025-08-28 06:52:03,062 - INFO -   Train: acc1: 89.7980 | acc5: 99.6720 | loss: 0.3001 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:03,062 - INFO -   Val:   acc1: 87.2200 | acc5: 99.6100 | loss: 0.3743
2025-08-28 06:52:03,062 - INFO -   LR: 0.010000
2025-08-28 06:52:03,079 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-28 06:52:03,270 - INFO - Epoch: [112][0/391] Time 0.189 (0.189) Data 0.163 (0.163) Loss 0.2907 (0.2907) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:52:04,184 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:04,184 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:05,170 - INFO - Epoch: [112][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.3752 (0.3018) Acc@1 88.281 (89.457) Acc@5 100.000 (99.706)
2025-08-28 06:52:07,005 - INFO - Epoch: [112][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.3334 (0.2974) Acc@1 87.500 (89.642) Acc@5 99.219 (99.689)
2025-08-28 06:52:07,166 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:07,167 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:08,948 - INFO - Epoch: [112][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.1963 (0.2968) Acc@1 95.312 (89.758) Acc@5 100.000 (99.704)
2025-08-28 06:52:10,275 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:10,276 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:10,815 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2626 (0.2626) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:52:11,664 - INFO - Epoch 112:
2025-08-28 06:52:11,664 - INFO -   Train: acc1: 89.6440 | acc5: 99.6680 | loss: 0.3017 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:11,664 - INFO -   Val:   acc1: 87.5800 | acc5: 99.6400 | loss: 0.3773
2025-08-28 06:52:11,664 - INFO -   LR: 0.010000
2025-08-28 06:52:11,680 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-28 06:52:11,839 - INFO - Epoch: [113][0/391] Time 0.159 (0.159) Data 0.138 (0.138) Loss 0.2784 (0.2784) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:52:13,829 - INFO - Epoch: [113][100/391] Time 0.025 (0.021) Data 0.001 (0.003) Loss 0.2540 (0.2903) Acc@1 90.625 (90.261) Acc@5 99.219 (99.698)
2025-08-28 06:52:14,545 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:14,546 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:15,742 - INFO - Epoch: [113][200/391] Time 0.020 (0.020) Data 0.002 (0.002) Loss 0.3311 (0.2924) Acc@1 88.281 (90.159) Acc@5 100.000 (99.697)
2025-08-28 06:52:17,630 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:17,631 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:17,694 - INFO - Epoch: [113][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3881 (0.2947) Acc@1 83.594 (89.916) Acc@5 99.219 (99.725)
2025-08-28 06:52:19,637 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2921 (0.2921) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:52:20,498 - INFO - Epoch 113:
2025-08-28 06:52:20,499 - INFO -   Train: acc1: 89.7100 | acc5: 99.7120 | loss: 0.2997 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:20,499 - INFO -   Val:   acc1: 87.1400 | acc5: 99.5600 | loss: 0.3935
2025-08-28 06:52:20,499 - INFO -   LR: 0.010000
2025-08-28 06:52:20,515 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-28 06:52:20,724 - INFO - Epoch: [114][0/391] Time 0.209 (0.209) Data 0.169 (0.169) Loss 0.2059 (0.2059) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 06:52:21,965 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:21,965 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:22,669 - INFO - Epoch: [114][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.3258 (0.2922) Acc@1 89.062 (89.952) Acc@5 99.219 (99.745)
2025-08-28 06:52:24,666 - INFO - Epoch: [114][200/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.3904 (0.2986) Acc@1 84.375 (89.762) Acc@5 99.219 (99.720)
2025-08-28 06:52:25,117 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:25,117 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:26,553 - INFO - Epoch: [114][300/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.1850 (0.3015) Acc@1 95.312 (89.623) Acc@5 100.000 (99.704)
2025-08-28 06:52:28,210 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:28,210 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:28,454 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3280 (0.3280) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:52:29,301 - INFO - Epoch 114:
2025-08-28 06:52:29,301 - INFO -   Train: acc1: 89.5960 | acc5: 99.7220 | loss: 0.3025 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:29,301 - INFO -   Val:   acc1: 87.0700 | acc5: 99.6100 | loss: 0.3820
2025-08-28 06:52:29,301 - INFO -   LR: 0.010000
2025-08-28 06:52:29,314 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-28 06:52:29,502 - INFO - Epoch: [115][0/391] Time 0.187 (0.187) Data 0.148 (0.148) Loss 0.3370 (0.3370) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:52:31,413 - INFO - Epoch: [115][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.3733 (0.2950) Acc@1 84.375 (89.921) Acc@5 100.000 (99.791)
2025-08-28 06:52:32,517 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:32,517 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:33,342 - INFO - Epoch: [115][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2884 (0.2959) Acc@1 89.844 (89.785) Acc@5 100.000 (99.790)
2025-08-28 06:52:35,216 - INFO - Epoch: [115][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3654 (0.2981) Acc@1 85.156 (89.771) Acc@5 99.219 (99.748)
2025-08-28 06:52:35,524 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:35,524 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:37,107 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2324 (0.2324) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:52:37,975 - INFO - Epoch 115:
2025-08-28 06:52:37,975 - INFO -   Train: acc1: 89.7400 | acc5: 99.7320 | loss: 0.2991 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:37,975 - INFO -   Val:   acc1: 88.2300 | acc5: 99.6500 | loss: 0.3578
2025-08-28 06:52:37,975 - INFO -   LR: 0.010000
2025-08-28 06:52:38,028 - INFO - Checkpoint saved: epoch=115, metric=88.2300
2025-08-28 06:52:38,061 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-28 06:52:38,257 - INFO - Epoch: [116][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.5014 (0.5014) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:52:39,945 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:39,945 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:40,260 - INFO - Epoch: [116][100/391] Time 0.027 (0.022) Data 0.000 (0.003) Loss 0.3192 (0.2915) Acc@1 89.062 (90.153) Acc@5 99.219 (99.737)
2025-08-28 06:52:42,202 - INFO - Epoch: [116][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.2924 (0.2989) Acc@1 90.625 (89.715) Acc@5 99.219 (99.732)
2025-08-28 06:52:43,049 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:43,049 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:44,110 - INFO - Epoch: [116][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3046 (0.2992) Acc@1 88.281 (89.774) Acc@5 100.000 (99.714)
2025-08-28 06:52:45,954 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2619 (0.2619) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:52:46,817 - INFO - Epoch 116:
2025-08-28 06:52:46,818 - INFO -   Train: acc1: 89.5960 | acc5: 99.6960 | loss: 0.3019 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:46,818 - INFO -   Val:   acc1: 87.9600 | acc5: 99.6200 | loss: 0.3602
2025-08-28 06:52:46,818 - INFO -   LR: 0.010000
2025-08-28 06:52:46,833 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-28 06:52:47,023 - INFO - Epoch: [117][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.3302 (0.3302) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 06:52:47,275 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:47,275 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:48,987 - INFO - Epoch: [117][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.2240 (0.2955) Acc@1 92.188 (89.890) Acc@5 99.219 (99.683)
2025-08-28 06:52:50,377 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:50,377 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:50,931 - INFO - Epoch: [117][200/391] Time 0.020 (0.020) Data 0.001 (0.002) Loss 0.2665 (0.2977) Acc@1 91.406 (89.723) Acc@5 99.219 (99.712)
2025-08-28 06:52:52,807 - INFO - Epoch: [117][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4229 (0.3008) Acc@1 85.156 (89.595) Acc@5 100.000 (99.699)
2025-08-28 06:52:53,482 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:53,482 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:54,713 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2778 (0.2778) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:52:55,569 - INFO - Epoch 117:
2025-08-28 06:52:55,569 - INFO -   Train: acc1: 89.5600 | acc5: 99.6920 | loss: 0.3016 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:52:55,570 - INFO -   Val:   acc1: 87.5000 | acc5: 99.5700 | loss: 0.3724
2025-08-28 06:52:55,570 - INFO -   LR: 0.010000
2025-08-28 06:52:55,586 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-28 06:52:55,774 - INFO - Epoch: [118][0/391] Time 0.186 (0.186) Data 0.166 (0.166) Loss 0.2918 (0.2918) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:52:57,736 - INFO - Epoch: [118][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.3406 (0.3007) Acc@1 86.719 (89.457) Acc@5 100.000 (99.644)
2025-08-28 06:52:57,766 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:52:57,766 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:52:59,744 - INFO - Epoch: [118][200/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.2508 (0.3009) Acc@1 89.844 (89.498) Acc@5 100.000 (99.697)
2025-08-28 06:53:00,892 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:00,892 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:01,664 - INFO - Epoch: [118][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3376 (0.3004) Acc@1 86.719 (89.504) Acc@5 100.000 (99.727)
2025-08-28 06:53:03,491 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2721 (0.2721) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:53:04,330 - INFO - Epoch 118:
2025-08-28 06:53:04,331 - INFO -   Train: acc1: 89.5120 | acc5: 99.7060 | loss: 0.3019 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:04,331 - INFO -   Val:   acc1: 87.5300 | acc5: 99.5600 | loss: 0.3646
2025-08-28 06:53:04,331 - INFO -   LR: 0.010000
2025-08-28 06:53:04,348 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-28 06:53:04,496 - INFO - Epoch: [119][0/391] Time 0.147 (0.147) Data 0.131 (0.131) Loss 0.3276 (0.3276) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:53:05,129 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:05,129 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:06,497 - INFO - Epoch: [119][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.1629 (0.2955) Acc@1 95.312 (89.844) Acc@5 100.000 (99.698)
2025-08-28 06:53:08,194 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:08,194 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:08,371 - INFO - Epoch: [119][200/391] Time 0.025 (0.020) Data 0.001 (0.002) Loss 0.3378 (0.2999) Acc@1 86.719 (89.809) Acc@5 100.000 (99.701)
2025-08-28 06:53:10,273 - INFO - Epoch: [119][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3668 (0.2986) Acc@1 89.062 (89.828) Acc@5 99.219 (99.709)
2025-08-28 06:53:11,261 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:11,262 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:12,154 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2974 (0.2974) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:53:12,993 - INFO - Epoch 119:
2025-08-28 06:53:12,993 - INFO -   Train: acc1: 89.6560 | acc5: 99.7100 | loss: 0.3005 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:12,993 - INFO -   Val:   acc1: 87.6600 | acc5: 99.6500 | loss: 0.3695
2025-08-28 06:53:12,993 - INFO -   LR: 0.010000
2025-08-28 06:53:13,009 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-28 06:53:13,197 - INFO - Epoch: [120][0/391] Time 0.184 (0.184) Data 0.156 (0.156) Loss 0.2231 (0.2231) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-28 06:53:15,192 - INFO - Epoch: [120][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.3345 (0.3011) Acc@1 91.406 (89.503) Acc@5 97.656 (99.683)
2025-08-28 06:53:15,551 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:15,551 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:17,136 - INFO - Epoch: [120][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2194 (0.3001) Acc@1 92.188 (89.599) Acc@5 100.000 (99.693)
2025-08-28 06:53:18,659 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:18,660 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:19,031 - INFO - Epoch: [120][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2494 (0.3001) Acc@1 93.750 (89.584) Acc@5 100.000 (99.696)
2025-08-28 06:53:20,918 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3231 (0.3231) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:53:21,753 - INFO - Epoch 120:
2025-08-28 06:53:21,754 - INFO -   Train: acc1: 89.4920 | acc5: 99.7100 | loss: 0.3034 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:21,754 - INFO -   Val:   acc1: 87.3600 | acc5: 99.6300 | loss: 0.3835
2025-08-28 06:53:21,754 - INFO -   LR: 0.010000
2025-08-28 06:53:21,804 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-28 06:53:21,979 - INFO - Epoch: [121][0/391] Time 0.174 (0.174) Data 0.146 (0.146) Loss 0.3244 (0.3244) Acc@1 90.625 (90.625) Acc@5 97.656 (97.656)
2025-08-28 06:53:22,869 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:22,879 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:23,864 - INFO - Epoch: [121][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.2357 (0.2950) Acc@1 92.188 (90.169) Acc@5 98.438 (99.714)
2025-08-28 06:53:25,755 - INFO - Epoch: [121][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3298 (0.2999) Acc@1 88.281 (89.739) Acc@5 99.219 (99.708)
2025-08-28 06:53:25,918 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:25,918 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:27,691 - INFO - Epoch: [121][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4768 (0.3042) Acc@1 86.719 (89.621) Acc@5 99.219 (99.699)
2025-08-28 06:53:29,047 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:29,047 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:29,599 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2707 (0.2707) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:53:30,452 - INFO - Epoch 121:
2025-08-28 06:53:30,452 - INFO -   Train: acc1: 89.6680 | acc5: 99.6980 | loss: 0.3043 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:30,452 - INFO -   Val:   acc1: 87.2800 | acc5: 99.6000 | loss: 0.3723
2025-08-28 06:53:30,453 - INFO -   LR: 0.010000
2025-08-28 06:53:30,469 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-28 06:53:30,662 - INFO - Epoch: [122][0/391] Time 0.192 (0.192) Data 0.172 (0.172) Loss 0.1862 (0.1862) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:53:32,578 - INFO - Epoch: [122][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4032 (0.2901) Acc@1 84.375 (90.068) Acc@5 100.000 (99.667)
2025-08-28 06:53:33,276 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:33,276 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:34,508 - INFO - Epoch: [122][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2716 (0.3004) Acc@1 92.188 (89.614) Acc@5 100.000 (99.712)
2025-08-28 06:53:36,335 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:36,336 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:36,384 - INFO - Epoch: [122][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3293 (0.3012) Acc@1 90.625 (89.662) Acc@5 100.000 (99.676)
2025-08-28 06:53:38,274 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2573 (0.2573) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:53:39,149 - INFO - Epoch 122:
2025-08-28 06:53:39,149 - INFO -   Train: acc1: 89.5180 | acc5: 99.6660 | loss: 0.3051 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:39,149 - INFO -   Val:   acc1: 87.4800 | acc5: 99.6200 | loss: 0.3707
2025-08-28 06:53:39,149 - INFO -   LR: 0.010000
2025-08-28 06:53:39,164 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-28 06:53:39,363 - INFO - Epoch: [123][0/391] Time 0.198 (0.198) Data 0.176 (0.176) Loss 0.2685 (0.2685) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:53:40,555 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:40,555 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:41,202 - INFO - Epoch: [123][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2806 (0.3105) Acc@1 90.625 (89.333) Acc@5 100.000 (99.636)
2025-08-28 06:53:43,055 - INFO - Epoch: [123][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.3477 (0.3015) Acc@1 89.844 (89.700) Acc@5 99.219 (99.646)
2025-08-28 06:53:43,568 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:43,568 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:44,904 - INFO - Epoch: [123][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.3155 (0.3046) Acc@1 88.281 (89.558) Acc@5 99.219 (99.652)
2025-08-28 06:53:46,559 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:46,559 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:46,787 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2542 (0.2542) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:53:47,661 - INFO - Epoch 123:
2025-08-28 06:53:47,661 - INFO -   Train: acc1: 89.4000 | acc5: 99.6600 | loss: 0.3074 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:47,661 - INFO -   Val:   acc1: 87.1700 | acc5: 99.5500 | loss: 0.3782
2025-08-28 06:53:47,661 - INFO -   LR: 0.010000
2025-08-28 06:53:47,676 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-28 06:53:47,841 - INFO - Epoch: [124][0/391] Time 0.165 (0.165) Data 0.144 (0.144) Loss 0.3429 (0.3429) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:53:49,808 - INFO - Epoch: [124][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3882 (0.2940) Acc@1 89.062 (89.906) Acc@5 100.000 (99.783)
2025-08-28 06:53:50,826 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:50,827 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:51,664 - INFO - Epoch: [124][200/391] Time 0.030 (0.020) Data 0.019 (0.002) Loss 0.3390 (0.3030) Acc@1 91.406 (89.646) Acc@5 99.219 (99.743)
2025-08-28 06:53:53,553 - INFO - Epoch: [124][300/391] Time 0.044 (0.020) Data 0.012 (0.002) Loss 0.2764 (0.3052) Acc@1 90.625 (89.504) Acc@5 99.219 (99.730)
2025-08-28 06:53:53,843 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:53,843 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:55,397 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2977 (0.2977) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:53:56,266 - INFO - Epoch 124:
2025-08-28 06:53:56,266 - INFO -   Train: acc1: 89.4500 | acc5: 99.7140 | loss: 0.3071 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:53:56,266 - INFO -   Val:   acc1: 87.2500 | acc5: 99.6400 | loss: 0.3761
2025-08-28 06:53:56,266 - INFO -   LR: 0.010000
2025-08-28 06:53:56,286 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-28 06:53:56,486 - INFO - Epoch: [125][0/391] Time 0.200 (0.200) Data 0.170 (0.170) Loss 0.3010 (0.3010) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:53:58,092 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:53:58,092 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:53:58,410 - INFO - Epoch: [125][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.2441 (0.2957) Acc@1 94.531 (89.998) Acc@5 100.000 (99.698)
2025-08-28 06:54:00,348 - INFO - Epoch: [125][200/391] Time 0.030 (0.020) Data 0.003 (0.002) Loss 0.2005 (0.3003) Acc@1 92.969 (89.735) Acc@5 100.000 (99.689)
2025-08-28 06:54:01,185 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:01,185 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:02,262 - INFO - Epoch: [125][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2033 (0.3026) Acc@1 93.750 (89.639) Acc@5 100.000 (99.694)
2025-08-28 06:54:04,084 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2725 (0.2725) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:54:04,933 - INFO - Epoch 125:
2025-08-28 06:54:04,933 - INFO -   Train: acc1: 89.5280 | acc5: 99.7060 | loss: 0.3041 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:04,933 - INFO -   Val:   acc1: 87.3400 | acc5: 99.6000 | loss: 0.3741
2025-08-28 06:54:04,933 - INFO -   LR: 0.010000
2025-08-28 06:54:04,949 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-28 06:54:05,135 - INFO - Epoch: [126][0/391] Time 0.185 (0.185) Data 0.167 (0.167) Loss 0.3425 (0.3425) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 06:54:05,374 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:05,374 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:07,058 - INFO - Epoch: [126][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.3675 (0.3041) Acc@1 85.938 (89.248) Acc@5 99.219 (99.729)
2025-08-28 06:54:08,414 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:08,414 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:08,921 - INFO - Epoch: [126][200/391] Time 0.025 (0.020) Data 0.012 (0.002) Loss 0.3216 (0.3084) Acc@1 85.938 (89.296) Acc@5 100.000 (99.689)
2025-08-28 06:54:10,874 - INFO - Epoch: [126][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3211 (0.3051) Acc@1 88.281 (89.423) Acc@5 100.000 (99.714)
2025-08-28 06:54:11,515 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:11,515 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:12,761 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3235 (0.3235) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:54:13,619 - INFO - Epoch 126:
2025-08-28 06:54:13,619 - INFO -   Train: acc1: 89.4220 | acc5: 99.7040 | loss: 0.3065 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:13,619 - INFO -   Val:   acc1: 87.2200 | acc5: 99.6100 | loss: 0.3839
2025-08-28 06:54:13,619 - INFO -   LR: 0.010000
2025-08-28 06:54:13,636 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-28 06:54:13,839 - INFO - Epoch: [127][0/391] Time 0.202 (0.202) Data 0.179 (0.179) Loss 0.2283 (0.2283) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:54:15,826 - INFO - Epoch: [127][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.4089 (0.3086) Acc@1 88.281 (89.449) Acc@5 99.219 (99.667)
2025-08-28 06:54:15,874 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:15,874 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:17,795 - INFO - Epoch: [127][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.4114 (0.3057) Acc@1 88.281 (89.498) Acc@5 100.000 (99.689)
2025-08-28 06:54:18,996 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:18,996 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:19,738 - INFO - Epoch: [127][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3389 (0.3062) Acc@1 88.281 (89.491) Acc@5 99.219 (99.668)
2025-08-28 06:54:21,607 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3014 (0.3014) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:54:22,491 - INFO - Epoch 127:
2025-08-28 06:54:22,491 - INFO -   Train: acc1: 89.4480 | acc5: 99.6660 | loss: 0.3075 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:22,491 - INFO -   Val:   acc1: 86.4700 | acc5: 99.5100 | loss: 0.3930
2025-08-28 06:54:22,491 - INFO -   LR: 0.010000
2025-08-28 06:54:22,507 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-28 06:54:22,697 - INFO - Epoch: [128][0/391] Time 0.189 (0.189) Data 0.161 (0.161) Loss 0.3516 (0.3516) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:54:23,315 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:23,316 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:24,629 - INFO - Epoch: [128][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.2529 (0.3028) Acc@1 92.188 (89.380) Acc@5 99.219 (99.729)
2025-08-28 06:54:26,394 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:26,394 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:26,556 - INFO - Epoch: [128][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2815 (0.3038) Acc@1 88.281 (89.436) Acc@5 100.000 (99.666)
2025-08-28 06:54:28,368 - INFO - Epoch: [128][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2128 (0.3087) Acc@1 91.406 (89.364) Acc@5 100.000 (99.668)
2025-08-28 06:54:29,328 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:29,328 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:30,180 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.2978 (0.2978) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:54:31,028 - INFO - Epoch 128:
2025-08-28 06:54:31,028 - INFO -   Train: acc1: 89.3780 | acc5: 99.6460 | loss: 0.3091 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:31,028 - INFO -   Val:   acc1: 87.5000 | acc5: 99.5600 | loss: 0.3765
2025-08-28 06:54:31,028 - INFO -   LR: 0.010000
2025-08-28 06:54:31,047 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-28 06:54:31,230 - INFO - Epoch: [129][0/391] Time 0.182 (0.182) Data 0.162 (0.162) Loss 0.2599 (0.2599) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:54:33,241 - INFO - Epoch: [129][100/391] Time 0.024 (0.022) Data 0.005 (0.003) Loss 0.3230 (0.3098) Acc@1 88.281 (89.434) Acc@5 100.000 (99.644)
2025-08-28 06:54:33,652 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:33,652 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:35,218 - INFO - Epoch: [129][200/391] Time 0.030 (0.021) Data 0.012 (0.002) Loss 0.3229 (0.3083) Acc@1 87.500 (89.432) Acc@5 100.000 (99.666)
2025-08-28 06:54:36,719 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:36,719 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:37,142 - INFO - Epoch: [129][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.2947 (0.3086) Acc@1 88.281 (89.348) Acc@5 99.219 (99.644)
2025-08-28 06:54:39,038 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.3282 (0.3282) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:54:39,926 - INFO - Epoch 129:
2025-08-28 06:54:39,926 - INFO -   Train: acc1: 89.2400 | acc5: 99.6580 | loss: 0.3118 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:39,926 - INFO -   Val:   acc1: 86.5400 | acc5: 99.6800 | loss: 0.4010
2025-08-28 06:54:39,926 - INFO -   LR: 0.010000
2025-08-28 06:54:39,943 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-28 06:54:40,129 - INFO - Epoch: [130][0/391] Time 0.185 (0.185) Data 0.155 (0.155) Loss 0.3308 (0.3308) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:54:41,107 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:41,107 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:42,105 - INFO - Epoch: [130][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2976 (0.3009) Acc@1 89.844 (89.851) Acc@5 99.219 (99.706)
2025-08-28 06:54:44,045 - INFO - Epoch: [130][200/391] Time 0.022 (0.020) Data 0.009 (0.003) Loss 0.2830 (0.3079) Acc@1 89.844 (89.486) Acc@5 99.219 (99.708)
2025-08-28 06:54:44,225 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:44,226 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:45,928 - INFO - Epoch: [130][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4292 (0.3111) Acc@1 88.281 (89.273) Acc@5 100.000 (99.694)
2025-08-28 06:54:47,321 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:47,322 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:47,838 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3053 (0.3053) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:54:48,676 - INFO - Epoch 130:
2025-08-28 06:54:48,676 - INFO -   Train: acc1: 89.2800 | acc5: 99.6920 | loss: 0.3117 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:48,676 - INFO -   Val:   acc1: 87.7500 | acc5: 99.5800 | loss: 0.3733
2025-08-28 06:54:48,676 - INFO -   LR: 0.010000
2025-08-28 06:54:48,730 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-28 06:54:48,914 - INFO - Epoch: [131][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.2212 (0.2212) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:54:50,829 - INFO - Epoch: [131][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.3103 (0.3059) Acc@1 88.281 (89.333) Acc@5 99.219 (99.683)
2025-08-28 06:54:51,565 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:51,565 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:52,727 - INFO - Epoch: [131][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3030 (0.3107) Acc@1 89.062 (89.276) Acc@5 99.219 (99.674)
2025-08-28 06:54:54,604 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:54,605 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:54,648 - INFO - Epoch: [131][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4561 (0.3104) Acc@1 85.938 (89.304) Acc@5 100.000 (99.678)
2025-08-28 06:54:56,520 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2474 (0.2474) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:54:57,391 - INFO - Epoch 131:
2025-08-28 06:54:57,391 - INFO -   Train: acc1: 89.3260 | acc5: 99.6800 | loss: 0.3100 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:54:57,391 - INFO -   Val:   acc1: 87.2300 | acc5: 99.6000 | loss: 0.3836
2025-08-28 06:54:57,391 - INFO -   LR: 0.010000
2025-08-28 06:54:57,409 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-28 06:54:57,601 - INFO - Epoch: [132][0/391] Time 0.192 (0.192) Data 0.163 (0.163) Loss 0.3596 (0.3596) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 06:54:58,972 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:54:58,972 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:54:59,632 - INFO - Epoch: [132][100/391] Time 0.051 (0.022) Data 0.012 (0.003) Loss 0.3031 (0.3107) Acc@1 87.500 (88.970) Acc@5 100.000 (99.644)
2025-08-28 06:55:01,515 - INFO - Epoch: [132][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3155 (0.3056) Acc@1 87.500 (89.272) Acc@5 100.000 (99.685)
2025-08-28 06:55:02,017 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:02,018 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:03,414 - INFO - Epoch: [132][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3514 (0.3062) Acc@1 86.719 (89.465) Acc@5 99.219 (99.668)
2025-08-28 06:55:05,084 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:05,084 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:05,308 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3209 (0.3209) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:55:06,162 - INFO - Epoch 132:
2025-08-28 06:55:06,163 - INFO -   Train: acc1: 89.2420 | acc5: 99.6500 | loss: 0.3115 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:06,163 - INFO -   Val:   acc1: 87.2000 | acc5: 99.6800 | loss: 0.3802
2025-08-28 06:55:06,163 - INFO -   LR: 0.010000
2025-08-28 06:55:06,180 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-28 06:55:06,339 - INFO - Epoch: [133][0/391] Time 0.158 (0.158) Data 0.127 (0.127) Loss 0.2244 (0.2244) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:55:08,257 - INFO - Epoch: [133][100/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.3422 (0.3119) Acc@1 89.062 (89.086) Acc@5 100.000 (99.745)
2025-08-28 06:55:09,285 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:09,285 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:10,123 - INFO - Epoch: [133][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3071 (0.3145) Acc@1 87.500 (89.043) Acc@5 100.000 (99.705)
2025-08-28 06:55:12,061 - INFO - Epoch: [133][300/391] Time 0.021 (0.020) Data 0.000 (0.001) Loss 0.3030 (0.3126) Acc@1 89.062 (89.226) Acc@5 100.000 (99.689)
2025-08-28 06:55:12,362 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:12,363 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:13,931 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.3410 (0.3410) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:55:14,806 - INFO - Epoch 133:
2025-08-28 06:55:14,806 - INFO -   Train: acc1: 89.1180 | acc5: 99.6780 | loss: 0.3146 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:14,806 - INFO -   Val:   acc1: 86.4000 | acc5: 99.5300 | loss: 0.4107
2025-08-28 06:55:14,806 - INFO -   LR: 0.010000
2025-08-28 06:55:14,824 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-28 06:55:15,009 - INFO - Epoch: [134][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.2882 (0.2882) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:55:16,679 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:16,679 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:16,971 - INFO - Epoch: [134][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2762 (0.3057) Acc@1 92.188 (89.240) Acc@5 100.000 (99.660)
2025-08-28 06:55:18,820 - INFO - Epoch: [134][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2640 (0.3053) Acc@1 92.188 (89.405) Acc@5 99.219 (99.681)
2025-08-28 06:55:19,653 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:19,653 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:20,720 - INFO - Epoch: [134][300/391] Time 0.025 (0.020) Data 0.009 (0.002) Loss 0.3767 (0.3098) Acc@1 87.500 (89.244) Acc@5 100.000 (99.676)
2025-08-28 06:55:22,587 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3240 (0.3240) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:55:23,470 - INFO - Epoch 134:
2025-08-28 06:55:23,471 - INFO -   Train: acc1: 89.2320 | acc5: 99.6560 | loss: 0.3106 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:23,471 - INFO -   Val:   acc1: 87.0000 | acc5: 99.6500 | loss: 0.3834
2025-08-28 06:55:23,471 - INFO -   LR: 0.010000
2025-08-28 06:55:23,490 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-28 06:55:23,674 - INFO - Epoch: [135][0/391] Time 0.184 (0.184) Data 0.161 (0.161) Loss 0.4646 (0.4646) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:55:24,011 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:24,011 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:25,750 - INFO - Epoch: [135][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.2933 (0.3093) Acc@1 87.500 (89.341) Acc@5 100.000 (99.683)
2025-08-28 06:55:27,232 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:27,232 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:27,756 - INFO - Epoch: [135][200/391] Time 0.020 (0.021) Data 0.002 (0.002) Loss 0.2404 (0.3089) Acc@1 89.844 (89.249) Acc@5 100.000 (99.720)
2025-08-28 06:55:29,762 - INFO - Epoch: [135][300/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.4182 (0.3100) Acc@1 82.812 (89.213) Acc@5 100.000 (99.668)
2025-08-28 06:55:30,424 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:30,424 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:31,613 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2497 (0.2497) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:55:32,482 - INFO - Epoch 135:
2025-08-28 06:55:32,482 - INFO -   Train: acc1: 89.1820 | acc5: 99.6600 | loss: 0.3108 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:32,482 - INFO -   Val:   acc1: 87.1000 | acc5: 99.5300 | loss: 0.3809
2025-08-28 06:55:32,482 - INFO -   LR: 0.010000
2025-08-28 06:55:32,498 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-28 06:55:32,689 - INFO - Epoch: [136][0/391] Time 0.189 (0.189) Data 0.164 (0.164) Loss 0.3518 (0.3518) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:55:34,706 - INFO - Epoch: [136][100/391] Time 0.027 (0.022) Data 0.000 (0.003) Loss 0.2186 (0.3188) Acc@1 92.969 (89.202) Acc@5 100.000 (99.598)
2025-08-28 06:55:34,763 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:34,764 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:36,628 - INFO - Epoch: [136][200/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.3555 (0.3139) Acc@1 87.500 (89.311) Acc@5 98.438 (99.639)
2025-08-28 06:55:37,901 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:37,901 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:38,645 - INFO - Epoch: [136][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3700 (0.3149) Acc@1 88.281 (89.249) Acc@5 100.000 (99.660)
2025-08-28 06:55:40,460 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2752 (0.2752) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:55:41,322 - INFO - Epoch 136:
2025-08-28 06:55:41,322 - INFO -   Train: acc1: 89.2480 | acc5: 99.6660 | loss: 0.3149 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:41,322 - INFO -   Val:   acc1: 87.0000 | acc5: 99.6000 | loss: 0.3820
2025-08-28 06:55:41,322 - INFO -   LR: 0.010000
2025-08-28 06:55:41,342 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-28 06:55:41,508 - INFO - Epoch: [137][0/391] Time 0.166 (0.166) Data 0.139 (0.139) Loss 0.2849 (0.2849) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 06:55:42,151 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:42,151 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:43,469 - INFO - Epoch: [137][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.2752 (0.3013) Acc@1 89.062 (89.751) Acc@5 100.000 (99.737)
2025-08-28 06:55:45,253 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:45,253 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:45,406 - INFO - Epoch: [137][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.3489 (0.3125) Acc@1 88.281 (89.253) Acc@5 100.000 (99.697)
2025-08-28 06:55:47,421 - INFO - Epoch: [137][300/391] Time 0.019 (0.020) Data 0.000 (0.001) Loss 0.3737 (0.3125) Acc@1 86.719 (89.231) Acc@5 98.438 (99.665)
2025-08-28 06:55:48,391 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:48,391 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:49,272 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3361 (0.3361) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:55:50,108 - INFO - Epoch 137:
2025-08-28 06:55:50,109 - INFO -   Train: acc1: 89.1980 | acc5: 99.6500 | loss: 0.3147 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:50,109 - INFO -   Val:   acc1: 86.6300 | acc5: 99.4800 | loss: 0.3999
2025-08-28 06:55:50,109 - INFO -   LR: 0.010000
2025-08-28 06:55:50,125 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-28 06:55:50,307 - INFO - Epoch: [138][0/391] Time 0.180 (0.180) Data 0.149 (0.149) Loss 0.3096 (0.3096) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:55:52,162 - INFO - Epoch: [138][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2941 (0.3040) Acc@1 89.844 (89.302) Acc@5 98.438 (99.714)
2025-08-28 06:55:52,592 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:52,592 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:54,110 - INFO - Epoch: [138][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2654 (0.3061) Acc@1 89.844 (89.288) Acc@5 100.000 (99.681)
2025-08-28 06:55:55,776 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:55:55,776 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:55:56,148 - INFO - Epoch: [138][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2895 (0.3107) Acc@1 90.625 (89.146) Acc@5 100.000 (99.678)
2025-08-28 06:55:57,976 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2473 (0.2473) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:55:58,877 - INFO - Epoch 138:
2025-08-28 06:55:58,877 - INFO -   Train: acc1: 89.0980 | acc5: 99.6600 | loss: 0.3127 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:55:58,877 - INFO -   Val:   acc1: 86.8700 | acc5: 99.6000 | loss: 0.3868
2025-08-28 06:55:58,877 - INFO -   LR: 0.010000
2025-08-28 06:55:58,893 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-28 06:55:59,088 - INFO - Epoch: [139][0/391] Time 0.194 (0.194) Data 0.172 (0.172) Loss 0.4565 (0.4565) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:56:00,081 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:00,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:01,015 - INFO - Epoch: [139][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3257 (0.3095) Acc@1 88.281 (89.318) Acc@5 100.000 (99.636)
2025-08-28 06:56:02,951 - INFO - Epoch: [139][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4067 (0.3131) Acc@1 86.719 (89.230) Acc@5 99.219 (99.654)
2025-08-28 06:56:03,166 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:03,167 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:04,855 - INFO - Epoch: [139][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3758 (0.3155) Acc@1 86.719 (89.122) Acc@5 100.000 (99.655)
2025-08-28 06:56:06,213 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:06,213 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:06,711 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2615 (0.2615) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:56:07,569 - INFO - Epoch 139:
2025-08-28 06:56:07,569 - INFO -   Train: acc1: 89.0120 | acc5: 99.6520 | loss: 0.3188 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:56:07,569 - INFO -   Val:   acc1: 87.0000 | acc5: 99.6000 | loss: 0.3795
2025-08-28 06:56:07,569 - INFO -   LR: 0.010000
2025-08-28 06:56:07,585 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-28 06:56:07,767 - INFO - Epoch: [140][0/391] Time 0.181 (0.181) Data 0.156 (0.156) Loss 0.2935 (0.2935) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:56:09,662 - INFO - Epoch: [140][100/391] Time 0.026 (0.021) Data 0.005 (0.003) Loss 0.2530 (0.3123) Acc@1 92.969 (89.086) Acc@5 99.219 (99.644)
2025-08-28 06:56:10,424 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:10,424 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:11,591 - INFO - Epoch: [140][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3539 (0.3233) Acc@1 90.625 (88.790) Acc@5 100.000 (99.646)
2025-08-28 06:56:13,523 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:13,523 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:13,550 - INFO - Epoch: [140][300/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.2330 (0.3199) Acc@1 90.625 (88.966) Acc@5 100.000 (99.634)
2025-08-28 06:56:15,401 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3035 (0.3035) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:56:16,235 - INFO - Epoch 140:
2025-08-28 06:56:16,235 - INFO -   Train: acc1: 89.0260 | acc5: 99.6320 | loss: 0.3190 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:56:16,235 - INFO -   Val:   acc1: 86.7400 | acc5: 99.4900 | loss: 0.4011
2025-08-28 06:56:16,236 - INFO -   LR: 0.010000
2025-08-28 06:56:16,286 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-28 06:56:16,491 - INFO - Epoch: [141][0/391] Time 0.203 (0.203) Data 0.180 (0.180) Loss 0.3777 (0.3777) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:56:17,837 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:17,837 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:18,449 - INFO - Epoch: [141][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.2490 (0.3098) Acc@1 91.406 (89.209) Acc@5 100.000 (99.559)
2025-08-28 06:56:20,326 - INFO - Epoch: [141][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2678 (0.3080) Acc@1 91.406 (89.455) Acc@5 100.000 (99.627)
2025-08-28 06:56:20,911 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:20,911 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:22,287 - INFO - Epoch: [141][300/391] Time 0.021 (0.020) Data 0.001 (0.002) Loss 0.2241 (0.3157) Acc@1 90.625 (89.190) Acc@5 100.000 (99.639)
2025-08-28 06:56:24,047 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:24,047 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:24,257 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3640 (0.3640) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:56:25,165 - INFO - Epoch 141:
2025-08-28 06:56:25,165 - INFO -   Train: acc1: 89.0820 | acc5: 99.6480 | loss: 0.3171 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:56:25,165 - INFO -   Val:   acc1: 86.1700 | acc5: 99.5700 | loss: 0.4121
2025-08-28 06:56:25,165 - INFO -   LR: 0.010000
2025-08-28 06:56:25,183 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-28 06:56:25,369 - INFO - Epoch: [142][0/391] Time 0.186 (0.186) Data 0.154 (0.154) Loss 0.2957 (0.2957) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:56:27,426 - INFO - Epoch: [142][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.3338 (0.3168) Acc@1 88.281 (89.209) Acc@5 100.000 (99.636)
2025-08-28 06:56:28,520 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:28,520 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:29,359 - INFO - Epoch: [142][200/391] Time 0.034 (0.021) Data 0.000 (0.002) Loss 0.3364 (0.3148) Acc@1 89.062 (89.121) Acc@5 99.219 (99.693)
2025-08-28 06:56:31,328 - INFO - Epoch: [142][300/391] Time 0.020 (0.020) Data 0.001 (0.002) Loss 0.4304 (0.3143) Acc@1 86.719 (89.125) Acc@5 100.000 (99.676)
2025-08-28 06:56:31,666 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:31,666 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:33,201 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.2520 (0.2520) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:56:34,106 - INFO - Epoch 142:
2025-08-28 06:56:34,107 - INFO -   Train: acc1: 89.1040 | acc5: 99.6700 | loss: 0.3152 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:56:34,107 - INFO -   Val:   acc1: 86.9200 | acc5: 99.6300 | loss: 0.3840
2025-08-28 06:56:34,107 - INFO -   LR: 0.010000
2025-08-28 06:56:34,123 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-28 06:56:34,320 - INFO - Epoch: [143][0/391] Time 0.196 (0.196) Data 0.166 (0.166) Loss 0.3639 (0.3639) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:56:36,074 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:36,074 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:36,347 - INFO - Epoch: [143][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.2468 (0.3079) Acc@1 90.625 (89.449) Acc@5 100.000 (99.644)
2025-08-28 06:56:38,270 - INFO - Epoch: [143][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.2336 (0.3129) Acc@1 91.406 (89.408) Acc@5 100.000 (99.662)
2025-08-28 06:56:39,125 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:39,125 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:40,172 - INFO - Epoch: [143][300/391] Time 0.033 (0.020) Data 0.000 (0.002) Loss 0.2889 (0.3146) Acc@1 92.188 (89.234) Acc@5 99.219 (99.650)
2025-08-28 06:56:42,004 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3202 (0.3202) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:56:42,857 - INFO - Epoch 143:
2025-08-28 06:56:42,857 - INFO -   Train: acc1: 89.1200 | acc5: 99.6500 | loss: 0.3169 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:56:42,857 - INFO -   Val:   acc1: 86.6200 | acc5: 99.5000 | loss: 0.4068
2025-08-28 06:56:42,858 - INFO -   LR: 0.010000
2025-08-28 06:56:42,875 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-28 06:56:43,073 - INFO - Epoch: [144][0/391] Time 0.197 (0.197) Data 0.166 (0.166) Loss 0.3980 (0.3980) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:56:43,391 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:43,391 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:45,035 - INFO - Epoch: [144][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.3175 (0.3203) Acc@1 87.500 (88.784) Acc@5 100.000 (99.644)
2025-08-28 06:56:46,426 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:46,427 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:46,945 - INFO - Epoch: [144][200/391] Time 0.029 (0.020) Data 0.010 (0.002) Loss 0.3313 (0.3224) Acc@1 89.844 (88.748) Acc@5 99.219 (99.681)
2025-08-28 06:56:48,931 - INFO - Epoch: [144][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3230 (0.3185) Acc@1 91.406 (88.948) Acc@5 100.000 (99.673)
2025-08-28 06:56:49,564 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:49,564 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:50,803 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2931 (0.2931) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:56:51,675 - INFO - Epoch 144:
2025-08-28 06:56:51,675 - INFO -   Train: acc1: 89.0160 | acc5: 99.6620 | loss: 0.3176 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:56:51,675 - INFO -   Val:   acc1: 87.5700 | acc5: 99.5700 | loss: 0.3762
2025-08-28 06:56:51,675 - INFO -   LR: 0.010000
2025-08-28 06:56:51,693 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-28 06:56:51,881 - INFO - Epoch: [145][0/391] Time 0.187 (0.187) Data 0.159 (0.159) Loss 0.3355 (0.3355) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:56:53,796 - INFO - Epoch: [145][100/391] Time 0.034 (0.021) Data 0.011 (0.003) Loss 0.3840 (0.3044) Acc@1 87.500 (89.635) Acc@5 98.438 (99.644)
2025-08-28 06:56:53,879 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:53,879 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:55,748 - INFO - Epoch: [145][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2173 (0.3078) Acc@1 92.188 (89.408) Acc@5 100.000 (99.650)
2025-08-28 06:56:56,925 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:56:56,925 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:56:57,628 - INFO - Epoch: [145][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2645 (0.3118) Acc@1 89.844 (89.192) Acc@5 100.000 (99.644)
2025-08-28 06:56:59,529 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3398 (0.3398) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:57:00,361 - INFO - Epoch 145:
2025-08-28 06:57:00,361 - INFO -   Train: acc1: 89.0680 | acc5: 99.6560 | loss: 0.3167 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:00,361 - INFO -   Val:   acc1: 85.6100 | acc5: 99.4400 | loss: 0.4406
2025-08-28 06:57:00,361 - INFO -   LR: 0.010000
2025-08-28 06:57:00,378 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-28 06:57:00,566 - INFO - Epoch: [146][0/391] Time 0.188 (0.188) Data 0.165 (0.165) Loss 0.3816 (0.3816) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 06:57:01,185 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:01,185 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:02,446 - INFO - Epoch: [146][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2964 (0.3040) Acc@1 89.844 (89.712) Acc@5 100.000 (99.698)
2025-08-28 06:57:04,224 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:04,224 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:04,351 - INFO - Epoch: [146][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2882 (0.3126) Acc@1 89.844 (89.249) Acc@5 100.000 (99.642)
2025-08-28 06:57:06,351 - INFO - Epoch: [146][300/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.2637 (0.3122) Acc@1 90.625 (89.200) Acc@5 100.000 (99.670)
2025-08-28 06:57:07,393 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:07,394 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:08,211 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3124 (0.3124) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:57:09,052 - INFO - Epoch 146:
2025-08-28 06:57:09,052 - INFO -   Train: acc1: 89.0840 | acc5: 99.6700 | loss: 0.3152 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:09,052 - INFO -   Val:   acc1: 86.9400 | acc5: 99.5500 | loss: 0.3910
2025-08-28 06:57:09,052 - INFO -   LR: 0.010000
2025-08-28 06:57:09,071 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-28 06:57:09,247 - INFO - Epoch: [147][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.3474 (0.3474) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:57:11,182 - INFO - Epoch: [147][100/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.2131 (0.3185) Acc@1 94.531 (89.302) Acc@5 100.000 (99.613)
2025-08-28 06:57:11,592 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:11,592 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:13,138 - INFO - Epoch: [147][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3549 (0.3186) Acc@1 89.062 (89.059) Acc@5 100.000 (99.639)
2025-08-28 06:57:14,734 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:14,735 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:15,064 - INFO - Epoch: [147][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3579 (0.3196) Acc@1 90.625 (88.977) Acc@5 99.219 (99.644)
2025-08-28 06:57:16,892 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.4162 (0.4162) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 06:57:17,738 - INFO - Epoch 147:
2025-08-28 06:57:17,738 - INFO -   Train: acc1: 88.9980 | acc5: 99.6500 | loss: 0.3201 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:17,738 - INFO -   Val:   acc1: 85.4600 | acc5: 99.3700 | loss: 0.4389
2025-08-28 06:57:17,738 - INFO -   LR: 0.010000
2025-08-28 06:57:17,756 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-28 06:57:17,960 - INFO - Epoch: [148][0/391] Time 0.202 (0.202) Data 0.177 (0.177) Loss 0.4074 (0.4074) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:57:19,019 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:19,019 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:19,950 - INFO - Epoch: [148][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.3478 (0.3138) Acc@1 87.500 (89.062) Acc@5 100.000 (99.706)
2025-08-28 06:57:21,887 - INFO - Epoch: [148][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.3077 (0.3143) Acc@1 91.406 (89.132) Acc@5 100.000 (99.654)
2025-08-28 06:57:22,121 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:22,121 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:23,790 - INFO - Epoch: [148][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3461 (0.3174) Acc@1 88.281 (89.044) Acc@5 100.000 (99.665)
2025-08-28 06:57:25,197 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:25,197 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:25,693 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2410 (0.2410) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:57:26,553 - INFO - Epoch 148:
2025-08-28 06:57:26,553 - INFO -   Train: acc1: 88.9960 | acc5: 99.6640 | loss: 0.3188 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:26,553 - INFO -   Val:   acc1: 86.8000 | acc5: 99.6200 | loss: 0.3862
2025-08-28 06:57:26,553 - INFO -   LR: 0.010000
2025-08-28 06:57:26,573 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-28 06:57:26,764 - INFO - Epoch: [149][0/391] Time 0.190 (0.190) Data 0.170 (0.170) Loss 0.3546 (0.3546) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:57:28,670 - INFO - Epoch: [149][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3820 (0.3107) Acc@1 88.281 (89.488) Acc@5 100.000 (99.644)
2025-08-28 06:57:29,444 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:29,444 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:30,577 - INFO - Epoch: [149][200/391] Time 0.019 (0.020) Data 0.001 (0.002) Loss 0.3778 (0.3242) Acc@1 86.719 (88.767) Acc@5 100.000 (99.623)
2025-08-28 06:57:32,490 - INFO - Epoch: [149][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2969 (0.3229) Acc@1 92.969 (88.811) Acc@5 98.438 (99.657)
2025-08-28 06:57:32,499 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:32,499 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:34,335 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3225 (0.3225) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:57:35,165 - INFO - Epoch 149:
2025-08-28 06:57:35,165 - INFO -   Train: acc1: 88.9840 | acc5: 99.6620 | loss: 0.3191 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:35,165 - INFO -   Val:   acc1: 87.2000 | acc5: 99.6100 | loss: 0.3905
2025-08-28 06:57:35,165 - INFO -   LR: 0.001000
2025-08-28 06:57:35,184 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-28 06:57:35,375 - INFO - Epoch: [150][0/391] Time 0.190 (0.190) Data 0.172 (0.172) Loss 0.2976 (0.2976) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:57:36,740 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:36,740 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:37,338 - INFO - Epoch: [150][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2287 (0.2921) Acc@1 93.750 (89.851) Acc@5 100.000 (99.729)
2025-08-28 06:57:39,284 - INFO - Epoch: [150][200/391] Time 0.031 (0.020) Data 0.012 (0.002) Loss 0.3170 (0.2888) Acc@1 90.625 (90.104) Acc@5 100.000 (99.728)
2025-08-28 06:57:39,847 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:39,847 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:41,242 - INFO - Epoch: [150][300/391] Time 0.019 (0.020) Data 0.000 (0.001) Loss 0.2623 (0.2911) Acc@1 89.062 (90.020) Acc@5 100.000 (99.699)
2025-08-28 06:57:42,936 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:42,937 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:43,146 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2447 (0.2447) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:57:43,989 - INFO - Epoch 150:
2025-08-28 06:57:43,989 - INFO -   Train: acc1: 90.1700 | acc5: 99.6960 | loss: 0.2887 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:43,989 - INFO -   Val:   acc1: 88.4400 | acc5: 99.6800 | loss: 0.3430
2025-08-28 06:57:43,989 - INFO -   LR: 0.001000
2025-08-28 06:57:44,043 - INFO - Checkpoint saved: epoch=150, metric=88.4400
2025-08-28 06:57:44,076 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-28 06:57:44,240 - INFO - Epoch: [151][0/391] Time 0.163 (0.163) Data 0.141 (0.141) Loss 0.2883 (0.2883) Acc@1 92.188 (92.188) Acc@5 98.438 (98.438)
2025-08-28 06:57:46,254 - INFO - Epoch: [151][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.2517 (0.2744) Acc@1 92.188 (90.640) Acc@5 100.000 (99.745)
2025-08-28 06:57:47,338 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:47,338 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:48,154 - INFO - Epoch: [151][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3888 (0.2800) Acc@1 86.719 (90.454) Acc@5 99.219 (99.740)
2025-08-28 06:57:50,048 - INFO - Epoch: [151][300/391] Time 0.027 (0.020) Data 0.013 (0.002) Loss 0.2913 (0.2784) Acc@1 89.844 (90.521) Acc@5 99.219 (99.735)
2025-08-28 06:57:50,340 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:50,340 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:51,880 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2332 (0.2332) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:57:52,742 - INFO - Epoch 151:
2025-08-28 06:57:52,742 - INFO -   Train: acc1: 90.4740 | acc5: 99.7320 | loss: 0.2788 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:57:52,742 - INFO -   Val:   acc1: 88.6400 | acc5: 99.6600 | loss: 0.3381
2025-08-28 06:57:52,742 - INFO -   LR: 0.001000
2025-08-28 06:57:52,796 - INFO - Checkpoint saved: epoch=151, metric=88.6400
2025-08-28 06:57:52,828 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-28 06:57:53,012 - INFO - Epoch: [152][0/391] Time 0.183 (0.183) Data 0.155 (0.155) Loss 0.3696 (0.3696) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:57:54,825 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:54,825 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:55,058 - INFO - Epoch: [152][100/391] Time 0.012 (0.022) Data 0.000 (0.004) Loss 0.2808 (0.2821) Acc@1 89.062 (90.416) Acc@5 100.000 (99.644)
2025-08-28 06:57:56,963 - INFO - Epoch: [152][200/391] Time 0.026 (0.021) Data 0.000 (0.003) Loss 0.3052 (0.2818) Acc@1 88.281 (90.473) Acc@5 100.000 (99.705)
2025-08-28 06:57:57,872 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:57:57,873 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:57:58,919 - INFO - Epoch: [152][300/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.2080 (0.2793) Acc@1 92.969 (90.454) Acc@5 100.000 (99.714)
2025-08-28 06:58:00,771 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2214 (0.2214) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:58:01,635 - INFO - Epoch 152:
2025-08-28 06:58:01,635 - INFO -   Train: acc1: 90.5060 | acc5: 99.7280 | loss: 0.2779 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:01,635 - INFO -   Val:   acc1: 88.5600 | acc5: 99.6800 | loss: 0.3352
2025-08-28 06:58:01,635 - INFO -   LR: 0.001000
2025-08-28 06:58:01,652 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-28 06:58:01,835 - INFO - Epoch: [153][0/391] Time 0.183 (0.183) Data 0.162 (0.162) Loss 0.3834 (0.3834) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:58:02,127 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:02,127 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:03,762 - INFO - Epoch: [153][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.1909 (0.2754) Acc@1 92.969 (90.478) Acc@5 100.000 (99.760)
2025-08-28 06:58:05,237 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:05,237 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:05,687 - INFO - Epoch: [153][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2778 (0.2753) Acc@1 87.500 (90.567) Acc@5 100.000 (99.740)
2025-08-28 06:58:07,579 - INFO - Epoch: [153][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.1705 (0.2750) Acc@1 95.312 (90.552) Acc@5 100.000 (99.725)
2025-08-28 06:58:08,328 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:08,328 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:09,561 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2286 (0.2286) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:58:10,399 - INFO - Epoch 153:
2025-08-28 06:58:10,399 - INFO -   Train: acc1: 90.6060 | acc5: 99.7360 | loss: 0.2740 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:10,399 - INFO -   Val:   acc1: 88.8000 | acc5: 99.6600 | loss: 0.3360
2025-08-28 06:58:10,399 - INFO -   LR: 0.001000
2025-08-28 06:58:10,457 - INFO - Checkpoint saved: epoch=153, metric=88.8000
2025-08-28 06:58:10,492 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-28 06:58:10,689 - INFO - Epoch: [154][0/391] Time 0.196 (0.196) Data 0.163 (0.163) Loss 0.2308 (0.2308) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:58:12,716 - INFO - Epoch: [154][100/391] Time 0.012 (0.022) Data 0.000 (0.003) Loss 0.3148 (0.2710) Acc@1 91.406 (90.733) Acc@5 98.438 (99.714)
2025-08-28 06:58:12,794 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:12,794 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:14,584 - INFO - Epoch: [154][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2787 (0.2736) Acc@1 92.969 (90.520) Acc@5 100.000 (99.736)
2025-08-28 06:58:15,844 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:15,844 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:16,521 - INFO - Epoch: [154][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3216 (0.2732) Acc@1 87.500 (90.586) Acc@5 100.000 (99.727)
2025-08-28 06:58:18,412 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2202 (0.2202) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:58:19,313 - INFO - Epoch 154:
2025-08-28 06:58:19,314 - INFO -   Train: acc1: 90.6700 | acc5: 99.7420 | loss: 0.2711 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:19,314 - INFO -   Val:   acc1: 88.5900 | acc5: 99.7000 | loss: 0.3354
2025-08-28 06:58:19,314 - INFO -   LR: 0.001000
2025-08-28 06:58:19,331 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-28 06:58:19,501 - INFO - Epoch: [155][0/391] Time 0.168 (0.168) Data 0.142 (0.142) Loss 0.2523 (0.2523) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:58:20,184 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:20,184 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:21,459 - INFO - Epoch: [155][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.2218 (0.2749) Acc@1 90.625 (90.625) Acc@5 100.000 (99.791)
2025-08-28 06:58:23,290 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:23,290 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:23,415 - INFO - Epoch: [155][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4284 (0.2696) Acc@1 85.938 (90.769) Acc@5 98.438 (99.759)
2025-08-28 06:58:25,359 - INFO - Epoch: [155][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2978 (0.2696) Acc@1 90.625 (90.768) Acc@5 99.219 (99.748)
2025-08-28 06:58:26,416 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:26,416 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:27,164 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2404 (0.2404) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:58:28,033 - INFO - Epoch 155:
2025-08-28 06:58:28,034 - INFO -   Train: acc1: 90.7060 | acc5: 99.7380 | loss: 0.2705 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:28,034 - INFO -   Val:   acc1: 88.8400 | acc5: 99.6900 | loss: 0.3350
2025-08-28 06:58:28,034 - INFO -   LR: 0.001000
2025-08-28 06:58:28,085 - INFO - Checkpoint saved: epoch=155, metric=88.8400
2025-08-28 06:58:28,117 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-28 06:58:28,298 - INFO - Epoch: [156][0/391] Time 0.180 (0.180) Data 0.157 (0.157) Loss 0.2817 (0.2817) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:58:30,226 - INFO - Epoch: [156][100/391] Time 0.020 (0.021) Data 0.001 (0.003) Loss 0.2775 (0.2736) Acc@1 92.969 (90.865) Acc@5 99.219 (99.729)
2025-08-28 06:58:30,670 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:30,670 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:32,126 - INFO - Epoch: [156][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3085 (0.2679) Acc@1 87.500 (90.917) Acc@5 100.000 (99.728)
2025-08-28 06:58:33,750 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:33,751 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:34,077 - INFO - Epoch: [156][300/391] Time 0.030 (0.020) Data 0.000 (0.002) Loss 0.2429 (0.2689) Acc@1 93.750 (90.898) Acc@5 100.000 (99.746)
2025-08-28 06:58:35,975 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2408 (0.2408) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:58:36,814 - INFO - Epoch 156:
2025-08-28 06:58:36,814 - INFO -   Train: acc1: 90.9540 | acc5: 99.7280 | loss: 0.2674 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:36,814 - INFO -   Val:   acc1: 88.7700 | acc5: 99.6700 | loss: 0.3351
2025-08-28 06:58:36,814 - INFO -   LR: 0.001000
2025-08-28 06:58:36,831 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-28 06:58:37,020 - INFO - Epoch: [157][0/391] Time 0.188 (0.188) Data 0.163 (0.163) Loss 0.3381 (0.3381) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:58:38,013 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:38,013 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:38,913 - INFO - Epoch: [157][100/391] Time 0.023 (0.021) Data 0.001 (0.004) Loss 0.2774 (0.2668) Acc@1 89.844 (90.973) Acc@5 99.219 (99.737)
2025-08-28 06:58:40,784 - INFO - Epoch: [157][200/391] Time 0.018 (0.020) Data 0.002 (0.002) Loss 0.2495 (0.2724) Acc@1 92.969 (90.714) Acc@5 100.000 (99.747)
2025-08-28 06:58:41,005 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:41,005 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:42,659 - INFO - Epoch: [157][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3636 (0.2727) Acc@1 88.281 (90.724) Acc@5 100.000 (99.746)
2025-08-28 06:58:44,081 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:44,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:44,557 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2359 (0.2359) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:58:45,466 - INFO - Epoch 157:
2025-08-28 06:58:45,467 - INFO -   Train: acc1: 90.7440 | acc5: 99.7500 | loss: 0.2699 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:45,467 - INFO -   Val:   acc1: 88.7200 | acc5: 99.7000 | loss: 0.3346
2025-08-28 06:58:45,467 - INFO -   LR: 0.001000
2025-08-28 06:58:45,484 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-28 06:58:45,686 - INFO - Epoch: [158][0/391] Time 0.201 (0.201) Data 0.177 (0.177) Loss 0.2587 (0.2587) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:58:47,684 - INFO - Epoch: [158][100/391] Time 0.011 (0.022) Data 0.000 (0.003) Loss 0.2791 (0.2780) Acc@1 88.281 (90.316) Acc@5 100.000 (99.745)
2025-08-28 06:58:48,457 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:48,457 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:49,577 - INFO - Epoch: [158][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2382 (0.2740) Acc@1 91.406 (90.532) Acc@5 100.000 (99.743)
2025-08-28 06:58:51,569 - INFO - Epoch: [158][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2190 (0.2664) Acc@1 90.625 (90.755) Acc@5 100.000 (99.772)
2025-08-28 06:58:51,593 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:51,593 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:53,466 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2464 (0.2464) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:58:54,332 - INFO - Epoch 158:
2025-08-28 06:58:54,332 - INFO -   Train: acc1: 90.7640 | acc5: 99.7540 | loss: 0.2676 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:58:54,332 - INFO -   Val:   acc1: 88.5200 | acc5: 99.7000 | loss: 0.3372
2025-08-28 06:58:54,332 - INFO -   LR: 0.001000
2025-08-28 06:58:54,351 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-28 06:58:54,543 - INFO - Epoch: [159][0/391] Time 0.191 (0.191) Data 0.166 (0.166) Loss 0.3415 (0.3415) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:58:55,890 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:55,890 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:58:56,458 - INFO - Epoch: [159][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.2644 (0.2688) Acc@1 89.844 (91.004) Acc@5 100.000 (99.722)
2025-08-28 06:58:58,325 - INFO - Epoch: [159][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2125 (0.2665) Acc@1 92.188 (91.115) Acc@5 99.219 (99.732)
2025-08-28 06:58:58,909 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:58:58,909 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:00,241 - INFO - Epoch: [159][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3508 (0.2683) Acc@1 86.719 (90.939) Acc@5 99.219 (99.751)
2025-08-28 06:59:02,163 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2306 (0.2306) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:59:03,031 - INFO - Epoch 159:
2025-08-28 06:59:03,031 - INFO -   Train: acc1: 90.8640 | acc5: 99.7600 | loss: 0.2688 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:03,031 - INFO -   Val:   acc1: 88.7500 | acc5: 99.7100 | loss: 0.3350
2025-08-28 06:59:03,031 - INFO -   LR: 0.001000
2025-08-28 06:59:03,052 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-28 06:59:03,228 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:03,229 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:03,258 - INFO - Epoch: [160][0/391] Time 0.206 (0.206) Data 0.169 (0.169) Loss 0.2452 (0.2452) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:59:05,277 - INFO - Epoch: [160][100/391] Time 0.013 (0.022) Data 0.000 (0.003) Loss 0.1959 (0.2589) Acc@1 94.531 (91.081) Acc@5 100.000 (99.776)
2025-08-28 06:59:06,423 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:06,423 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:07,277 - INFO - Epoch: [160][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.2977 (0.2674) Acc@1 89.062 (90.823) Acc@5 99.219 (99.759)
2025-08-28 06:59:09,261 - INFO - Epoch: [160][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.2145 (0.2693) Acc@1 92.188 (90.760) Acc@5 100.000 (99.764)
2025-08-28 06:59:09,637 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:09,637 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:11,151 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2509 (0.2509) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:59:12,007 - INFO - Epoch 160:
2025-08-28 06:59:12,007 - INFO -   Train: acc1: 90.8300 | acc5: 99.7560 | loss: 0.2675 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:12,007 - INFO -   Val:   acc1: 88.7200 | acc5: 99.6300 | loss: 0.3355
2025-08-28 06:59:12,007 - INFO -   LR: 0.001000
2025-08-28 06:59:12,059 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-28 06:59:12,228 - INFO - Epoch: [161][0/391] Time 0.167 (0.167) Data 0.146 (0.146) Loss 0.3441 (0.3441) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:59:13,937 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:13,937 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:14,163 - INFO - Epoch: [161][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.2630 (0.2631) Acc@1 92.188 (91.050) Acc@5 100.000 (99.752)
2025-08-28 06:59:16,025 - INFO - Epoch: [161][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1500 (0.2632) Acc@1 94.531 (91.088) Acc@5 100.000 (99.767)
2025-08-28 06:59:16,985 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:16,985 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:18,001 - INFO - Epoch: [161][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2502 (0.2645) Acc@1 90.625 (90.996) Acc@5 99.219 (99.725)
2025-08-28 06:59:19,919 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2482 (0.2482) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:59:20,781 - INFO - Epoch 161:
2025-08-28 06:59:20,781 - INFO -   Train: acc1: 91.0360 | acc5: 99.7180 | loss: 0.2652 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:20,781 - INFO -   Val:   acc1: 88.6000 | acc5: 99.7000 | loss: 0.3342
2025-08-28 06:59:20,781 - INFO -   LR: 0.001000
2025-08-28 06:59:20,801 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-28 06:59:20,976 - INFO - Epoch: [162][0/391] Time 0.175 (0.175) Data 0.150 (0.150) Loss 0.2486 (0.2486) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:59:21,336 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:21,336 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:22,958 - INFO - Epoch: [162][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3371 (0.2623) Acc@1 88.281 (91.004) Acc@5 99.219 (99.783)
2025-08-28 06:59:24,369 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:24,369 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:24,853 - INFO - Epoch: [162][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2488 (0.2607) Acc@1 92.188 (91.095) Acc@5 100.000 (99.763)
2025-08-28 06:59:26,811 - INFO - Epoch: [162][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2332 (0.2655) Acc@1 94.531 (90.892) Acc@5 100.000 (99.738)
2025-08-28 06:59:27,505 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:27,505 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:28,630 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2459 (0.2459) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:59:29,505 - INFO - Epoch 162:
2025-08-28 06:59:29,505 - INFO -   Train: acc1: 90.8820 | acc5: 99.7420 | loss: 0.2660 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:29,505 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6600 | loss: 0.3360
2025-08-28 06:59:29,505 - INFO -   LR: 0.001000
2025-08-28 06:59:29,523 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-28 06:59:29,714 - INFO - Epoch: [163][0/391] Time 0.190 (0.190) Data 0.171 (0.171) Loss 0.3106 (0.3106) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:59:31,634 - INFO - Epoch: [163][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2798 (0.2561) Acc@1 91.406 (91.391) Acc@5 100.000 (99.783)
2025-08-28 06:59:31,755 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:31,756 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:33,459 - INFO - Epoch: [163][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2060 (0.2588) Acc@1 93.750 (91.266) Acc@5 100.000 (99.778)
2025-08-28 06:59:34,693 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:34,694 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:35,328 - INFO - Epoch: [163][300/391] Time 0.018 (0.019) Data 0.000 (0.001) Loss 0.2539 (0.2647) Acc@1 92.188 (90.986) Acc@5 99.219 (99.759)
2025-08-28 06:59:37,139 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2473 (0.2473) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:59:37,972 - INFO - Epoch 163:
2025-08-28 06:59:37,972 - INFO -   Train: acc1: 90.9720 | acc5: 99.7540 | loss: 0.2649 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:37,972 - INFO -   Val:   acc1: 88.5000 | acc5: 99.6900 | loss: 0.3327
2025-08-28 06:59:37,972 - INFO -   LR: 0.001000
2025-08-28 06:59:37,989 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-28 06:59:38,189 - INFO - Epoch: [164][0/391] Time 0.199 (0.199) Data 0.176 (0.176) Loss 0.3167 (0.3167) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:59:38,882 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:38,882 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:40,252 - INFO - Epoch: [164][100/391] Time 0.030 (0.022) Data 0.000 (0.003) Loss 0.2996 (0.2649) Acc@1 90.625 (90.880) Acc@5 98.438 (99.698)
2025-08-28 06:59:41,995 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:41,995 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:42,060 - INFO - Epoch: [164][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3090 (0.2669) Acc@1 87.500 (90.812) Acc@5 99.219 (99.743)
2025-08-28 06:59:44,108 - INFO - Epoch: [164][300/391] Time 0.018 (0.020) Data 0.001 (0.002) Loss 0.3027 (0.2628) Acc@1 89.062 (90.994) Acc@5 99.219 (99.756)
2025-08-28 06:59:45,160 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:45,160 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:45,960 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2467 (0.2467) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:59:46,823 - INFO - Epoch 164:
2025-08-28 06:59:46,823 - INFO -   Train: acc1: 91.0120 | acc5: 99.7360 | loss: 0.2646 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:46,823 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6900 | loss: 0.3369
2025-08-28 06:59:46,823 - INFO -   LR: 0.001000
2025-08-28 06:59:46,842 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-28 06:59:47,022 - INFO - Epoch: [165][0/391] Time 0.180 (0.180) Data 0.149 (0.149) Loss 0.3184 (0.3184) Acc@1 89.062 (89.062) Acc@5 98.438 (98.438)
2025-08-28 06:59:48,957 - INFO - Epoch: [165][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2330 (0.2679) Acc@1 92.969 (90.579) Acc@5 100.000 (99.714)
2025-08-28 06:59:49,424 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:49,424 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:50,885 - INFO - Epoch: [165][200/391] Time 0.023 (0.020) Data 0.008 (0.002) Loss 0.2912 (0.2630) Acc@1 88.281 (90.691) Acc@5 100.000 (99.763)
2025-08-28 06:59:52,458 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:52,459 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:52,761 - INFO - Epoch: [165][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1834 (0.2628) Acc@1 92.969 (90.856) Acc@5 100.000 (99.761)
2025-08-28 06:59:54,635 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2435 (0.2435) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:59:55,543 - INFO - Epoch 165:
2025-08-28 06:59:55,543 - INFO -   Train: acc1: 90.7500 | acc5: 99.7520 | loss: 0.2657 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 06:59:55,543 - INFO -   Val:   acc1: 88.4100 | acc5: 99.6900 | loss: 0.3344
2025-08-28 06:59:55,543 - INFO -   LR: 0.001000
2025-08-28 06:59:55,562 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-28 06:59:55,729 - INFO - Epoch: [166][0/391] Time 0.166 (0.166) Data 0.145 (0.145) Loss 0.2544 (0.2544) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:59:56,883 - INFO - Pruning info: sparsity=0.950
2025-08-28 06:59:56,883 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:59:57,807 - INFO - Epoch: [166][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.2222 (0.2588) Acc@1 94.531 (90.973) Acc@5 99.219 (99.698)
2025-08-28 06:59:59,753 - INFO - Epoch: [166][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.3506 (0.2631) Acc@1 85.938 (91.076) Acc@5 100.000 (99.689)
2025-08-28 07:00:00,011 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:00,011 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:01,752 - INFO - Epoch: [166][300/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.1990 (0.2612) Acc@1 95.312 (91.196) Acc@5 100.000 (99.720)
2025-08-28 07:00:03,186 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:03,186 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:03,610 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2364 (0.2364) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:00:04,469 - INFO - Epoch 166:
2025-08-28 07:00:04,469 - INFO -   Train: acc1: 91.1360 | acc5: 99.7360 | loss: 0.2612 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:04,469 - INFO -   Val:   acc1: 88.6800 | acc5: 99.6700 | loss: 0.3359
2025-08-28 07:00:04,469 - INFO -   LR: 0.001000
2025-08-28 07:00:04,489 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-28 07:00:04,670 - INFO - Epoch: [167][0/391] Time 0.180 (0.180) Data 0.151 (0.151) Loss 0.2438 (0.2438) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 07:00:06,614 - INFO - Epoch: [167][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.2780 (0.2632) Acc@1 89.844 (91.174) Acc@5 100.000 (99.776)
2025-08-28 07:00:07,440 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:07,440 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:08,523 - INFO - Epoch: [167][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2423 (0.2622) Acc@1 92.969 (91.169) Acc@5 100.000 (99.763)
2025-08-28 07:00:10,281 - INFO - Epoch: [167][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.2664 (0.2632) Acc@1 91.406 (91.123) Acc@5 100.000 (99.759)
2025-08-28 07:00:10,334 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:10,335 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:12,156 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2349 (0.2349) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:00:13,000 - INFO - Epoch 167:
2025-08-28 07:00:13,001 - INFO -   Train: acc1: 91.0520 | acc5: 99.7480 | loss: 0.2642 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:13,001 - INFO -   Val:   acc1: 88.6200 | acc5: 99.7100 | loss: 0.3354
2025-08-28 07:00:13,001 - INFO -   LR: 0.001000
2025-08-28 07:00:13,021 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-28 07:00:13,216 - INFO - Epoch: [168][0/391] Time 0.194 (0.194) Data 0.169 (0.169) Loss 0.3034 (0.3034) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 07:00:14,571 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:14,572 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:15,122 - INFO - Epoch: [168][100/391] Time 0.019 (0.021) Data 0.004 (0.003) Loss 0.2457 (0.2612) Acc@1 92.969 (91.112) Acc@5 100.000 (99.760)
2025-08-28 07:00:17,086 - INFO - Epoch: [168][200/391] Time 0.027 (0.020) Data 0.002 (0.002) Loss 0.3067 (0.2626) Acc@1 89.062 (91.111) Acc@5 100.000 (99.755)
2025-08-28 07:00:17,643 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:17,643 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:18,975 - INFO - Epoch: [168][300/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.2215 (0.2635) Acc@1 92.188 (91.051) Acc@5 100.000 (99.774)
2025-08-28 07:00:20,955 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2544 (0.2544) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:00:21,821 - INFO - Epoch 168:
2025-08-28 07:00:21,821 - INFO -   Train: acc1: 91.0320 | acc5: 99.7800 | loss: 0.2634 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:21,821 - INFO -   Val:   acc1: 88.7000 | acc5: 99.6600 | loss: 0.3357
2025-08-28 07:00:21,821 - INFO -   LR: 0.001000
2025-08-28 07:00:21,840 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-28 07:00:22,044 - INFO - Epoch: [169][0/391] Time 0.203 (0.203) Data 0.182 (0.182) Loss 0.2802 (0.2802) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:00:22,049 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:22,049 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:23,973 - INFO - Epoch: [169][100/391] Time 0.025 (0.021) Data 0.003 (0.004) Loss 0.2726 (0.2613) Acc@1 90.625 (91.313) Acc@5 100.000 (99.706)
2025-08-28 07:00:25,105 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:25,105 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:25,842 - INFO - Epoch: [169][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2816 (0.2623) Acc@1 91.406 (91.150) Acc@5 100.000 (99.759)
2025-08-28 07:00:27,837 - INFO - Epoch: [169][300/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.3509 (0.2622) Acc@1 86.719 (91.061) Acc@5 100.000 (99.774)
2025-08-28 07:00:28,214 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:28,214 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:29,666 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2448 (0.2448) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:00:30,564 - INFO - Epoch 169:
2025-08-28 07:00:30,565 - INFO -   Train: acc1: 91.0340 | acc5: 99.7680 | loss: 0.2621 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:30,565 - INFO -   Val:   acc1: 88.6800 | acc5: 99.6400 | loss: 0.3353
2025-08-28 07:00:30,565 - INFO -   LR: 0.001000
2025-08-28 07:00:30,585 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-28 07:00:30,770 - INFO - Epoch: [170][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.2957 (0.2957) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:00:32,514 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:32,514 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:32,701 - INFO - Epoch: [170][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2793 (0.2641) Acc@1 92.188 (90.857) Acc@5 100.000 (99.768)
2025-08-28 07:00:34,662 - INFO - Epoch: [170][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2292 (0.2614) Acc@1 92.188 (91.041) Acc@5 99.219 (99.778)
2025-08-28 07:00:35,608 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:35,608 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:36,555 - INFO - Epoch: [170][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2513 (0.2625) Acc@1 92.969 (91.051) Acc@5 99.219 (99.766)
2025-08-28 07:00:38,410 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2498 (0.2498) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:00:39,254 - INFO - Epoch 170:
2025-08-28 07:00:39,254 - INFO -   Train: acc1: 90.9720 | acc5: 99.7620 | loss: 0.2632 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:39,254 - INFO -   Val:   acc1: 88.7500 | acc5: 99.7000 | loss: 0.3342
2025-08-28 07:00:39,254 - INFO -   LR: 0.001000
2025-08-28 07:00:39,402 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-28 07:00:39,575 - INFO - Epoch: [171][0/391] Time 0.172 (0.172) Data 0.150 (0.150) Loss 0.2130 (0.2130) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:00:39,970 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:39,970 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:41,450 - INFO - Epoch: [171][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3173 (0.2601) Acc@1 88.281 (90.950) Acc@5 100.000 (99.791)
2025-08-28 07:00:42,943 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:42,943 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:43,393 - INFO - Epoch: [171][200/391] Time 0.030 (0.020) Data 0.016 (0.003) Loss 0.3855 (0.2619) Acc@1 84.375 (90.963) Acc@5 100.000 (99.759)
2025-08-28 07:00:45,329 - INFO - Epoch: [171][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2637 (0.2602) Acc@1 92.188 (91.071) Acc@5 100.000 (99.753)
2025-08-28 07:00:46,043 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:46,043 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:47,144 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2477 (0.2477) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:00:47,965 - INFO - Epoch 171:
2025-08-28 07:00:47,965 - INFO -   Train: acc1: 90.9840 | acc5: 99.7520 | loss: 0.2620 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:47,965 - INFO -   Val:   acc1: 88.7100 | acc5: 99.6600 | loss: 0.3346
2025-08-28 07:00:47,965 - INFO -   LR: 0.001000
2025-08-28 07:00:47,986 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-28 07:00:48,187 - INFO - Epoch: [172][0/391] Time 0.200 (0.200) Data 0.175 (0.175) Loss 0.2769 (0.2769) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:00:50,113 - INFO - Epoch: [172][100/391] Time 0.024 (0.021) Data 0.000 (0.002) Loss 0.2916 (0.2543) Acc@1 87.500 (90.919) Acc@5 100.000 (99.768)
2025-08-28 07:00:50,267 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:50,267 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:52,063 - INFO - Epoch: [172][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1994 (0.2530) Acc@1 93.750 (91.138) Acc@5 100.000 (99.775)
2025-08-28 07:00:53,403 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:53,403 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:54,065 - INFO - Epoch: [172][300/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.2268 (0.2585) Acc@1 90.625 (90.981) Acc@5 100.000 (99.772)
2025-08-28 07:00:55,924 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2268 (0.2268) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:00:56,749 - INFO - Epoch 172:
2025-08-28 07:00:56,749 - INFO -   Train: acc1: 90.9920 | acc5: 99.7760 | loss: 0.2594 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:00:56,749 - INFO -   Val:   acc1: 88.7500 | acc5: 99.6900 | loss: 0.3357
2025-08-28 07:00:56,749 - INFO -   LR: 0.001000
2025-08-28 07:00:56,770 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-28 07:00:56,952 - INFO - Epoch: [173][0/391] Time 0.181 (0.181) Data 0.157 (0.157) Loss 0.3448 (0.3448) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-28 07:00:57,731 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:00:57,731 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:00:58,996 - INFO - Epoch: [173][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.2864 (0.2636) Acc@1 91.406 (91.205) Acc@5 99.219 (99.683)
2025-08-28 07:01:00,750 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:00,750 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:00,830 - INFO - Epoch: [173][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2267 (0.2619) Acc@1 90.625 (91.185) Acc@5 100.000 (99.728)
2025-08-28 07:01:02,865 - INFO - Epoch: [173][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2980 (0.2640) Acc@1 91.406 (91.123) Acc@5 100.000 (99.751)
2025-08-28 07:01:03,982 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:03,982 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:04,759 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2402 (0.2402) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:01:05,631 - INFO - Epoch 173:
2025-08-28 07:01:05,632 - INFO -   Train: acc1: 91.0660 | acc5: 99.7320 | loss: 0.2647 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:05,632 - INFO -   Val:   acc1: 88.7000 | acc5: 99.7200 | loss: 0.3355
2025-08-28 07:01:05,632 - INFO -   LR: 0.001000
2025-08-28 07:01:05,651 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-28 07:01:05,863 - INFO - Epoch: [174][0/391] Time 0.211 (0.211) Data 0.189 (0.189) Loss 0.1977 (0.1977) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 07:01:07,870 - INFO - Epoch: [174][100/391] Time 0.017 (0.022) Data 0.005 (0.003) Loss 0.2841 (0.2612) Acc@1 86.719 (91.019) Acc@5 100.000 (99.698)
2025-08-28 07:01:08,376 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:08,376 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:09,728 - INFO - Epoch: [174][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2385 (0.2641) Acc@1 89.844 (90.936) Acc@5 100.000 (99.732)
2025-08-28 07:01:11,345 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:11,346 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:11,631 - INFO - Epoch: [174][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1598 (0.2625) Acc@1 95.312 (91.035) Acc@5 100.000 (99.717)
2025-08-28 07:01:13,468 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2198 (0.2198) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:01:14,317 - INFO - Epoch 174:
2025-08-28 07:01:14,318 - INFO -   Train: acc1: 91.0060 | acc5: 99.7220 | loss: 0.2628 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:14,318 - INFO -   Val:   acc1: 88.5500 | acc5: 99.7100 | loss: 0.3339
2025-08-28 07:01:14,318 - INFO -   LR: 0.001000
2025-08-28 07:01:14,337 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-28 07:01:14,541 - INFO - Epoch: [175][0/391] Time 0.203 (0.203) Data 0.178 (0.178) Loss 0.3505 (0.3505) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 07:01:15,552 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:15,552 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:16,416 - INFO - Epoch: [175][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.2029 (0.2548) Acc@1 92.188 (91.476) Acc@5 100.000 (99.714)
2025-08-28 07:01:18,335 - INFO - Epoch: [175][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2723 (0.2583) Acc@1 92.188 (91.270) Acc@5 100.000 (99.759)
2025-08-28 07:01:18,624 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:18,625 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:20,306 - INFO - Epoch: [175][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2636 (0.2593) Acc@1 91.406 (91.173) Acc@5 99.219 (99.769)
2025-08-28 07:01:21,706 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:21,706 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:22,110 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2298 (0.2298) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:01:22,951 - INFO - Epoch 175:
2025-08-28 07:01:22,951 - INFO -   Train: acc1: 91.1460 | acc5: 99.7500 | loss: 0.2611 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:22,952 - INFO -   Val:   acc1: 88.8200 | acc5: 99.6900 | loss: 0.3346
2025-08-28 07:01:22,952 - INFO -   LR: 0.001000
2025-08-28 07:01:22,972 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-28 07:01:23,182 - INFO - Epoch: [176][0/391] Time 0.209 (0.209) Data 0.178 (0.178) Loss 0.2826 (0.2826) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:01:25,080 - INFO - Epoch: [176][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.2813 (0.2620) Acc@1 92.969 (91.043) Acc@5 100.000 (99.745)
2025-08-28 07:01:25,861 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:25,861 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:26,882 - INFO - Epoch: [176][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2410 (0.2601) Acc@1 92.969 (91.115) Acc@5 100.000 (99.775)
2025-08-28 07:01:28,858 - INFO - Epoch: [176][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3193 (0.2628) Acc@1 87.500 (90.960) Acc@5 99.219 (99.772)
2025-08-28 07:01:28,939 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:28,939 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:30,771 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2344 (0.2344) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:01:31,635 - INFO - Epoch 176:
2025-08-28 07:01:31,635 - INFO -   Train: acc1: 90.9300 | acc5: 99.7620 | loss: 0.2628 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:31,635 - INFO -   Val:   acc1: 88.5900 | acc5: 99.6800 | loss: 0.3349
2025-08-28 07:01:31,635 - INFO -   LR: 0.001000
2025-08-28 07:01:31,656 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-28 07:01:31,829 - INFO - Epoch: [177][0/391] Time 0.172 (0.172) Data 0.146 (0.146) Loss 0.2070 (0.2070) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 07:01:33,215 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:33,216 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:33,690 - INFO - Epoch: [177][100/391] Time 0.031 (0.020) Data 0.020 (0.002) Loss 0.2021 (0.2557) Acc@1 95.312 (91.662) Acc@5 100.000 (99.722)
2025-08-28 07:01:35,634 - INFO - Epoch: [177][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2127 (0.2589) Acc@1 93.750 (91.231) Acc@5 100.000 (99.701)
2025-08-28 07:01:36,295 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:36,296 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:37,508 - INFO - Epoch: [177][300/391] Time 0.013 (0.019) Data 0.000 (0.001) Loss 0.3667 (0.2643) Acc@1 85.938 (90.926) Acc@5 100.000 (99.720)
2025-08-28 07:01:39,317 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2240 (0.2240) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:01:40,159 - INFO - Epoch 177:
2025-08-28 07:01:40,159 - INFO -   Train: acc1: 91.0400 | acc5: 99.7320 | loss: 0.2620 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:40,159 - INFO -   Val:   acc1: 88.6600 | acc5: 99.6700 | loss: 0.3359
2025-08-28 07:01:40,159 - INFO -   LR: 0.001000
2025-08-28 07:01:40,177 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-28 07:01:40,379 - INFO - Epoch: [178][0/391] Time 0.201 (0.201) Data 0.177 (0.177) Loss 0.1424 (0.1424) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 07:01:40,409 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:40,409 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:42,410 - INFO - Epoch: [178][100/391] Time 0.039 (0.022) Data 0.013 (0.003) Loss 0.1670 (0.2648) Acc@1 95.312 (91.151) Acc@5 100.000 (99.752)
2025-08-28 07:01:43,552 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:43,553 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:44,332 - INFO - Epoch: [178][200/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.3041 (0.2675) Acc@1 91.406 (90.885) Acc@5 99.219 (99.751)
2025-08-28 07:01:46,281 - INFO - Epoch: [178][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3014 (0.2631) Acc@1 89.844 (91.040) Acc@5 99.219 (99.759)
2025-08-28 07:01:46,700 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:46,700 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:48,175 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2482 (0.2482) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:01:49,029 - INFO - Epoch 178:
2025-08-28 07:01:49,029 - INFO -   Train: acc1: 91.0460 | acc5: 99.7560 | loss: 0.2612 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:49,029 - INFO -   Val:   acc1: 88.6800 | acc5: 99.6800 | loss: 0.3397
2025-08-28 07:01:49,029 - INFO -   LR: 0.001000
2025-08-28 07:01:49,047 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-28 07:01:49,245 - INFO - Epoch: [179][0/391] Time 0.197 (0.197) Data 0.176 (0.176) Loss 0.2278 (0.2278) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:01:50,955 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:50,955 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:51,129 - INFO - Epoch: [179][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.2838 (0.2577) Acc@1 88.281 (91.004) Acc@5 100.000 (99.698)
2025-08-28 07:01:53,066 - INFO - Epoch: [179][200/391] Time 0.020 (0.020) Data 0.001 (0.003) Loss 0.3344 (0.2572) Acc@1 86.719 (91.231) Acc@5 99.219 (99.724)
2025-08-28 07:01:53,983 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:53,983 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:54,920 - INFO - Epoch: [179][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.2283 (0.2602) Acc@1 93.750 (91.160) Acc@5 100.000 (99.727)
2025-08-28 07:01:56,765 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2536 (0.2536) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:01:57,595 - INFO - Epoch 179:
2025-08-28 07:01:57,595 - INFO -   Train: acc1: 91.1180 | acc5: 99.7260 | loss: 0.2607 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:01:57,596 - INFO -   Val:   acc1: 88.7900 | acc5: 99.7000 | loss: 0.3373
2025-08-28 07:01:57,596 - INFO -   LR: 0.001000
2025-08-28 07:01:57,615 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-28 07:01:57,781 - INFO - Epoch: [180][0/391] Time 0.166 (0.166) Data 0.139 (0.139) Loss 0.3681 (0.3681) Acc@1 89.062 (89.062) Acc@5 97.656 (97.656)
2025-08-28 07:01:58,220 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:01:58,220 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:01:59,768 - INFO - Epoch: [180][100/391] Time 0.029 (0.021) Data 0.000 (0.002) Loss 0.1941 (0.2597) Acc@1 95.312 (91.136) Acc@5 100.000 (99.706)
2025-08-28 07:02:01,260 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:01,260 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:01,649 - INFO - Epoch: [180][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2697 (0.2609) Acc@1 89.844 (91.025) Acc@5 100.000 (99.763)
2025-08-28 07:02:03,559 - INFO - Epoch: [180][300/391] Time 0.025 (0.020) Data 0.004 (0.002) Loss 0.2590 (0.2616) Acc@1 89.062 (90.996) Acc@5 100.000 (99.756)
2025-08-28 07:02:04,357 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:04,357 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:05,462 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2284 (0.2284) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:02:06,349 - INFO - Epoch 180:
2025-08-28 07:02:06,349 - INFO -   Train: acc1: 90.9900 | acc5: 99.7640 | loss: 0.2617 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:06,350 - INFO -   Val:   acc1: 88.6800 | acc5: 99.6900 | loss: 0.3360
2025-08-28 07:02:06,350 - INFO -   LR: 0.001000
2025-08-28 07:02:06,405 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-28 07:02:06,576 - INFO - Epoch: [181][0/391] Time 0.170 (0.170) Data 0.144 (0.144) Loss 0.3160 (0.3160) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:02:08,466 - INFO - Epoch: [181][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2408 (0.2654) Acc@1 91.406 (91.004) Acc@5 100.000 (99.776)
2025-08-28 07:02:08,647 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:08,647 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:10,390 - INFO - Epoch: [181][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2544 (0.2604) Acc@1 91.406 (91.111) Acc@5 99.219 (99.767)
2025-08-28 07:02:11,719 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:11,719 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:12,350 - INFO - Epoch: [181][300/391] Time 0.019 (0.020) Data 0.002 (0.002) Loss 0.2783 (0.2597) Acc@1 90.625 (91.126) Acc@5 99.219 (99.746)
2025-08-28 07:02:14,234 - INFO - Test: [0/79] Time 0.106 (0.106) Loss 0.2323 (0.2323) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:02:15,102 - INFO - Epoch 181:
2025-08-28 07:02:15,102 - INFO -   Train: acc1: 91.0760 | acc5: 99.7620 | loss: 0.2603 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:15,102 - INFO -   Val:   acc1: 88.8400 | acc5: 99.6900 | loss: 0.3382
2025-08-28 07:02:15,102 - INFO -   LR: 0.001000
2025-08-28 07:02:15,120 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-28 07:02:15,311 - INFO - Epoch: [182][0/391] Time 0.190 (0.190) Data 0.168 (0.168) Loss 0.2422 (0.2422) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 07:02:16,098 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:16,098 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:17,338 - INFO - Epoch: [182][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.1590 (0.2604) Acc@1 92.969 (90.989) Acc@5 100.000 (99.752)
2025-08-28 07:02:19,231 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:19,231 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:19,291 - INFO - Epoch: [182][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.1891 (0.2541) Acc@1 92.188 (91.224) Acc@5 99.219 (99.763)
2025-08-28 07:02:21,220 - INFO - Epoch: [182][300/391] Time 0.028 (0.020) Data 0.013 (0.002) Loss 0.2351 (0.2578) Acc@1 90.625 (91.084) Acc@5 99.219 (99.743)
2025-08-28 07:02:22,363 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:22,363 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:23,130 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2324 (0.2324) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:02:23,991 - INFO - Epoch 182:
2025-08-28 07:02:23,991 - INFO -   Train: acc1: 91.0480 | acc5: 99.7440 | loss: 0.2586 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:23,991 - INFO -   Val:   acc1: 88.7500 | acc5: 99.6600 | loss: 0.3368
2025-08-28 07:02:23,991 - INFO -   LR: 0.001000
2025-08-28 07:02:24,013 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-28 07:02:24,190 - INFO - Epoch: [183][0/391] Time 0.175 (0.175) Data 0.147 (0.147) Loss 0.1981 (0.1981) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 07:02:26,085 - INFO - Epoch: [183][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.2942 (0.2646) Acc@1 88.281 (90.826) Acc@5 100.000 (99.776)
2025-08-28 07:02:26,536 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:26,536 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:27,989 - INFO - Epoch: [183][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2557 (0.2612) Acc@1 90.625 (90.920) Acc@5 98.438 (99.755)
2025-08-28 07:02:29,630 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:29,630 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:29,891 - INFO - Epoch: [183][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2334 (0.2638) Acc@1 91.406 (90.887) Acc@5 100.000 (99.733)
2025-08-28 07:02:31,752 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2366 (0.2366) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:02:32,591 - INFO - Epoch 183:
2025-08-28 07:02:32,592 - INFO -   Train: acc1: 90.9840 | acc5: 99.7480 | loss: 0.2633 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:32,592 - INFO -   Val:   acc1: 88.8200 | acc5: 99.7400 | loss: 0.3325
2025-08-28 07:02:32,592 - INFO -   LR: 0.001000
2025-08-28 07:02:32,612 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-28 07:02:32,775 - INFO - Epoch: [184][0/391] Time 0.163 (0.163) Data 0.145 (0.145) Loss 0.3319 (0.3319) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 07:02:33,962 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:33,963 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:34,843 - INFO - Epoch: [184][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.3195 (0.2588) Acc@1 89.062 (91.221) Acc@5 100.000 (99.799)
2025-08-28 07:02:36,842 - INFO - Epoch: [184][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.2070 (0.2597) Acc@1 94.531 (91.165) Acc@5 100.000 (99.767)
2025-08-28 07:02:37,146 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:37,146 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:38,777 - INFO - Epoch: [184][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2718 (0.2578) Acc@1 90.625 (91.289) Acc@5 100.000 (99.772)
2025-08-28 07:02:40,183 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:40,183 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:40,610 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2473 (0.2473) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:02:41,447 - INFO - Epoch 184:
2025-08-28 07:02:41,447 - INFO -   Train: acc1: 91.2080 | acc5: 99.7680 | loss: 0.2592 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:41,448 - INFO -   Val:   acc1: 88.8500 | acc5: 99.7300 | loss: 0.3346
2025-08-28 07:02:41,448 - INFO -   LR: 0.001000
2025-08-28 07:02:41,502 - INFO - Checkpoint saved: epoch=184, metric=88.8500
2025-08-28 07:02:41,535 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-28 07:02:41,721 - INFO - Epoch: [185][0/391] Time 0.184 (0.184) Data 0.158 (0.158) Loss 0.4078 (0.4078) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 07:02:43,549 - INFO - Epoch: [185][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2265 (0.2557) Acc@1 92.188 (91.360) Acc@5 100.000 (99.814)
2025-08-28 07:02:44,418 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:44,418 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:45,455 - INFO - Epoch: [185][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2391 (0.2564) Acc@1 91.406 (91.185) Acc@5 100.000 (99.794)
2025-08-28 07:02:47,406 - INFO - Epoch: [185][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.3353 (0.2592) Acc@1 89.062 (91.121) Acc@5 99.219 (99.756)
2025-08-28 07:02:47,476 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:47,476 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:49,288 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2402 (0.2402) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:02:50,125 - INFO - Epoch 185:
2025-08-28 07:02:50,125 - INFO -   Train: acc1: 91.0840 | acc5: 99.7500 | loss: 0.2606 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:50,125 - INFO -   Val:   acc1: 88.6300 | acc5: 99.6700 | loss: 0.3339
2025-08-28 07:02:50,125 - INFO -   LR: 0.001000
2025-08-28 07:02:50,272 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-28 07:02:50,449 - INFO - Epoch: [186][0/391] Time 0.176 (0.176) Data 0.153 (0.153) Loss 0.2471 (0.2471) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 07:02:51,847 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:51,847 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:52,373 - INFO - Epoch: [186][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.2144 (0.2540) Acc@1 92.188 (91.221) Acc@5 100.000 (99.760)
2025-08-28 07:02:54,293 - INFO - Epoch: [186][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2826 (0.2559) Acc@1 92.188 (91.309) Acc@5 99.219 (99.743)
2025-08-28 07:02:54,909 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:54,909 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:02:56,227 - INFO - Epoch: [186][300/391] Time 0.018 (0.020) Data 0.000 (0.001) Loss 0.2152 (0.2566) Acc@1 92.969 (91.199) Acc@5 100.000 (99.740)
2025-08-28 07:02:58,186 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2337 (0.2337) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:02:59,017 - INFO - Epoch 186:
2025-08-28 07:02:59,017 - INFO -   Train: acc1: 91.0280 | acc5: 99.7500 | loss: 0.2596 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:02:59,017 - INFO -   Val:   acc1: 88.8100 | acc5: 99.6900 | loss: 0.3348
2025-08-28 07:02:59,017 - INFO -   LR: 0.001000
2025-08-28 07:02:59,037 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-28 07:02:59,254 - INFO - Epoch: [187][0/391] Time 0.216 (0.216) Data 0.174 (0.174) Loss 0.2360 (0.2360) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:02:59,302 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:02:59,302 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:01,178 - INFO - Epoch: [187][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.2915 (0.2540) Acc@1 89.062 (91.259) Acc@5 100.000 (99.760)
2025-08-28 07:03:02,314 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:02,314 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:02,977 - INFO - Epoch: [187][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.2979 (0.2605) Acc@1 88.281 (91.056) Acc@5 100.000 (99.778)
2025-08-28 07:03:04,904 - INFO - Epoch: [187][300/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.2245 (0.2610) Acc@1 92.188 (91.020) Acc@5 100.000 (99.795)
2025-08-28 07:03:05,322 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:05,322 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:06,764 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2446 (0.2446) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:03:07,602 - INFO - Epoch 187:
2025-08-28 07:03:07,603 - INFO -   Train: acc1: 90.9580 | acc5: 99.7940 | loss: 0.2622 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:03:07,603 - INFO -   Val:   acc1: 88.6900 | acc5: 99.7100 | loss: 0.3324
2025-08-28 07:03:07,603 - INFO -   LR: 0.001000
2025-08-28 07:03:07,622 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-28 07:03:07,800 - INFO - Epoch: [188][0/391] Time 0.178 (0.178) Data 0.148 (0.148) Loss 0.1683 (0.1683) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 07:03:09,618 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:09,618 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:09,790 - INFO - Epoch: [188][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2409 (0.2651) Acc@1 92.188 (90.764) Acc@5 100.000 (99.822)
2025-08-28 07:03:11,728 - INFO - Epoch: [188][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2965 (0.2627) Acc@1 91.406 (90.913) Acc@5 100.000 (99.810)
2025-08-28 07:03:12,690 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:12,690 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:13,684 - INFO - Epoch: [188][300/391] Time 0.038 (0.020) Data 0.000 (0.002) Loss 0.2198 (0.2609) Acc@1 91.406 (90.981) Acc@5 100.000 (99.795)
2025-08-28 07:03:15,491 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2400 (0.2400) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:03:16,336 - INFO - Epoch 188:
2025-08-28 07:03:16,337 - INFO -   Train: acc1: 90.9720 | acc5: 99.7920 | loss: 0.2608 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:03:16,337 - INFO -   Val:   acc1: 88.8000 | acc5: 99.6600 | loss: 0.3317
2025-08-28 07:03:16,337 - INFO -   LR: 0.001000
2025-08-28 07:03:16,373 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-28 07:03:16,565 - INFO - Epoch: [189][0/391] Time 0.190 (0.190) Data 0.168 (0.168) Loss 0.1957 (0.1957) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:03:16,968 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:16,968 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:18,459 - INFO - Epoch: [189][100/391] Time 0.025 (0.021) Data 0.000 (0.004) Loss 0.2366 (0.2586) Acc@1 88.281 (91.236) Acc@5 100.000 (99.714)
2025-08-28 07:03:20,025 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:20,025 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:20,367 - INFO - Epoch: [189][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.2168 (0.2619) Acc@1 94.531 (91.076) Acc@5 100.000 (99.740)
2025-08-28 07:03:22,313 - INFO - Epoch: [189][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1970 (0.2586) Acc@1 94.531 (91.251) Acc@5 100.000 (99.764)
2025-08-28 07:03:23,081 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:23,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:24,219 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2360 (0.2360) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:03:25,040 - INFO - Epoch 189:
2025-08-28 07:03:25,040 - INFO -   Train: acc1: 91.2240 | acc5: 99.7720 | loss: 0.2586 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:03:25,040 - INFO -   Val:   acc1: 88.6200 | acc5: 99.7000 | loss: 0.3342
2025-08-28 07:03:25,040 - INFO -   LR: 0.001000
2025-08-28 07:03:25,062 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-28 07:03:25,245 - INFO - Epoch: [190][0/391] Time 0.182 (0.182) Data 0.160 (0.160) Loss 0.2605 (0.2605) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:03:27,274 - INFO - Epoch: [190][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.3707 (0.2655) Acc@1 89.062 (90.942) Acc@5 99.219 (99.752)
2025-08-28 07:03:27,451 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:27,451 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:29,280 - INFO - Epoch: [190][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.2405 (0.2626) Acc@1 92.188 (91.018) Acc@5 100.000 (99.743)
2025-08-28 07:03:30,654 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:30,655 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:31,286 - INFO - Epoch: [190][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.3210 (0.2597) Acc@1 89.844 (91.170) Acc@5 99.219 (99.746)
2025-08-28 07:03:33,181 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2505 (0.2505) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:03:34,062 - INFO - Epoch 190:
2025-08-28 07:03:34,062 - INFO -   Train: acc1: 91.1620 | acc5: 99.7520 | loss: 0.2603 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:03:34,062 - INFO -   Val:   acc1: 88.9000 | acc5: 99.6800 | loss: 0.3346
2025-08-28 07:03:34,062 - INFO -   LR: 0.001000
2025-08-28 07:03:34,115 - INFO - Checkpoint saved: epoch=190, metric=88.9000
2025-08-28 07:03:34,147 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-28 07:03:34,329 - INFO - Epoch: [191][0/391] Time 0.180 (0.180) Data 0.164 (0.164) Loss 0.2605 (0.2605) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:03:35,080 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:35,080 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:36,282 - INFO - Epoch: [191][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.2267 (0.2577) Acc@1 92.188 (91.306) Acc@5 100.000 (99.729)
2025-08-28 07:03:38,246 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:38,246 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:38,278 - INFO - Epoch: [191][200/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.2435 (0.2578) Acc@1 91.406 (91.173) Acc@5 100.000 (99.732)
2025-08-28 07:03:40,217 - INFO - Epoch: [191][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2441 (0.2553) Acc@1 91.406 (91.238) Acc@5 100.000 (99.753)
2025-08-28 07:03:41,348 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:41,349 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:42,061 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2308 (0.2308) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 07:03:42,904 - INFO - Epoch 191:
2025-08-28 07:03:42,904 - INFO -   Train: acc1: 91.0900 | acc5: 99.7420 | loss: 0.2584 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:03:42,904 - INFO -   Val:   acc1: 88.8200 | acc5: 99.6800 | loss: 0.3348
2025-08-28 07:03:42,904 - INFO -   LR: 0.001000
2025-08-28 07:03:42,925 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-28 07:03:43,126 - INFO - Epoch: [192][0/391] Time 0.200 (0.200) Data 0.153 (0.153) Loss 0.2690 (0.2690) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:03:45,122 - INFO - Epoch: [192][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.2275 (0.2614) Acc@1 91.406 (91.252) Acc@5 100.000 (99.776)
2025-08-28 07:03:45,676 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:45,676 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:47,091 - INFO - Epoch: [192][200/391] Time 0.024 (0.021) Data 0.003 (0.002) Loss 0.2948 (0.2579) Acc@1 90.625 (91.270) Acc@5 99.219 (99.778)
2025-08-28 07:03:48,801 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:48,801 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:49,045 - INFO - Epoch: [192][300/391] Time 0.024 (0.020) Data 0.003 (0.002) Loss 0.1935 (0.2571) Acc@1 92.188 (91.230) Acc@5 100.000 (99.785)
2025-08-28 07:03:50,885 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2323 (0.2323) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:03:51,717 - INFO - Epoch 192:
2025-08-28 07:03:51,717 - INFO -   Train: acc1: 91.1880 | acc5: 99.7700 | loss: 0.2585 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:03:51,717 - INFO -   Val:   acc1: 88.7700 | acc5: 99.7200 | loss: 0.3336
2025-08-28 07:03:51,717 - INFO -   LR: 0.001000
2025-08-28 07:03:51,739 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-28 07:03:51,931 - INFO - Epoch: [193][0/391] Time 0.190 (0.190) Data 0.164 (0.164) Loss 0.3398 (0.3398) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 07:03:53,012 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:53,012 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:53,833 - INFO - Epoch: [193][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.2058 (0.2526) Acc@1 92.969 (91.437) Acc@5 100.000 (99.799)
2025-08-28 07:03:55,732 - INFO - Epoch: [193][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2924 (0.2561) Acc@1 92.969 (91.239) Acc@5 100.000 (99.782)
2025-08-28 07:03:56,033 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:56,033 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:57,686 - INFO - Epoch: [193][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2919 (0.2569) Acc@1 89.844 (91.227) Acc@5 99.219 (99.772)
2025-08-28 07:03:59,198 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:03:59,199 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:03:59,577 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2265 (0.2265) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:04:00,426 - INFO - Epoch 193:
2025-08-28 07:04:00,427 - INFO -   Train: acc1: 91.2820 | acc5: 99.7720 | loss: 0.2572 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:00,427 - INFO -   Val:   acc1: 88.6200 | acc5: 99.7200 | loss: 0.3353
2025-08-28 07:04:00,427 - INFO -   LR: 0.001000
2025-08-28 07:04:00,447 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-28 07:04:00,655 - INFO - Epoch: [194][0/391] Time 0.207 (0.207) Data 0.165 (0.165) Loss 0.1705 (0.1705) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 07:04:02,658 - INFO - Epoch: [194][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.1812 (0.2613) Acc@1 95.312 (91.012) Acc@5 100.000 (99.745)
2025-08-28 07:04:03,494 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:03,495 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:04,507 - INFO - Epoch: [194][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2355 (0.2577) Acc@1 92.188 (91.056) Acc@5 100.000 (99.755)
2025-08-28 07:04:06,414 - INFO - Epoch: [194][300/391] Time 0.012 (0.020) Data 0.000 (0.001) Loss 0.2352 (0.2581) Acc@1 92.969 (90.996) Acc@5 99.219 (99.740)
2025-08-28 07:04:06,508 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:06,508 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:08,334 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2411 (0.2411) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 07:04:09,194 - INFO - Epoch 194:
2025-08-28 07:04:09,194 - INFO -   Train: acc1: 90.9880 | acc5: 99.7540 | loss: 0.2593 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:09,194 - INFO -   Val:   acc1: 88.6500 | acc5: 99.7200 | loss: 0.3381
2025-08-28 07:04:09,194 - INFO -   LR: 0.001000
2025-08-28 07:04:09,216 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-28 07:04:09,397 - INFO - Epoch: [195][0/391] Time 0.180 (0.180) Data 0.162 (0.162) Loss 0.2568 (0.2568) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 07:04:10,786 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:10,786 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:11,306 - INFO - Epoch: [195][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.2190 (0.2574) Acc@1 92.969 (91.105) Acc@5 100.000 (99.799)
2025-08-28 07:04:13,309 - INFO - Epoch: [195][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2864 (0.2576) Acc@1 89.062 (91.084) Acc@5 100.000 (99.778)
2025-08-28 07:04:13,988 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:13,988 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:15,335 - INFO - Epoch: [195][300/391] Time 0.024 (0.020) Data 0.012 (0.002) Loss 0.2326 (0.2576) Acc@1 91.406 (91.043) Acc@5 100.000 (99.766)
2025-08-28 07:04:17,325 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2432 (0.2432) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:04:18,154 - INFO - Epoch 195:
2025-08-28 07:04:18,154 - INFO -   Train: acc1: 91.0700 | acc5: 99.7660 | loss: 0.2575 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:18,154 - INFO -   Val:   acc1: 88.7600 | acc5: 99.7000 | loss: 0.3366
2025-08-28 07:04:18,154 - INFO -   LR: 0.001000
2025-08-28 07:04:18,172 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-28 07:04:18,361 - INFO - Epoch: [196][0/391] Time 0.188 (0.188) Data 0.153 (0.153) Loss 0.2553 (0.2553) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 07:04:18,429 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:18,429 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:20,411 - INFO - Epoch: [196][100/391] Time 0.031 (0.022) Data 0.000 (0.004) Loss 0.2136 (0.2586) Acc@1 92.969 (90.896) Acc@5 98.438 (99.698)
2025-08-28 07:04:21,688 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:21,688 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:22,441 - INFO - Epoch: [196][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.2331 (0.2592) Acc@1 90.625 (90.893) Acc@5 100.000 (99.740)
2025-08-28 07:04:24,463 - INFO - Epoch: [196][300/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.1906 (0.2589) Acc@1 92.969 (90.872) Acc@5 100.000 (99.764)
2025-08-28 07:04:24,920 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:24,920 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:26,323 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2503 (0.2503) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 07:04:27,177 - INFO - Epoch 196:
2025-08-28 07:04:27,177 - INFO -   Train: acc1: 90.8460 | acc5: 99.7580 | loss: 0.2604 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:27,177 - INFO -   Val:   acc1: 88.5400 | acc5: 99.6500 | loss: 0.3396
2025-08-28 07:04:27,177 - INFO -   LR: 0.001000
2025-08-28 07:04:27,198 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-28 07:04:27,379 - INFO - Epoch: [197][0/391] Time 0.180 (0.180) Data 0.153 (0.153) Loss 0.1996 (0.1996) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 07:04:29,098 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:29,098 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:29,271 - INFO - Epoch: [197][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.3946 (0.2641) Acc@1 86.719 (91.151) Acc@5 99.219 (99.776)
2025-08-28 07:04:31,148 - INFO - Epoch: [197][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.2957 (0.2589) Acc@1 92.188 (91.088) Acc@5 99.219 (99.794)
2025-08-28 07:04:32,142 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:32,142 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:33,037 - INFO - Epoch: [197][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2449 (0.2578) Acc@1 89.844 (91.103) Acc@5 100.000 (99.772)
2025-08-28 07:04:34,940 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2386 (0.2386) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:04:35,864 - INFO - Epoch 197:
2025-08-28 07:04:35,864 - INFO -   Train: acc1: 91.1400 | acc5: 99.7660 | loss: 0.2565 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:35,864 - INFO -   Val:   acc1: 88.6800 | acc5: 99.6400 | loss: 0.3370
2025-08-28 07:04:35,864 - INFO -   LR: 0.001000
2025-08-28 07:04:35,883 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-28 07:04:36,087 - INFO - Epoch: [198][0/391] Time 0.204 (0.204) Data 0.176 (0.176) Loss 0.2531 (0.2531) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 07:04:36,518 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:36,518 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:38,053 - INFO - Epoch: [198][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.2084 (0.2581) Acc@1 92.969 (91.159) Acc@5 100.000 (99.822)
2025-08-28 07:04:39,630 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:39,630 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:39,998 - INFO - Epoch: [198][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3272 (0.2647) Acc@1 89.062 (90.940) Acc@5 100.000 (99.786)
2025-08-28 07:04:41,890 - INFO - Epoch: [198][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2419 (0.2610) Acc@1 89.844 (91.079) Acc@5 100.000 (99.764)
2025-08-28 07:04:42,699 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:42,699 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:43,758 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2421 (0.2421) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 07:04:44,618 - INFO - Epoch 198:
2025-08-28 07:04:44,618 - INFO -   Train: acc1: 91.1900 | acc5: 99.7580 | loss: 0.2584 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:44,618 - INFO -   Val:   acc1: 88.5300 | acc5: 99.6400 | loss: 0.3367
2025-08-28 07:04:44,618 - INFO -   LR: 0.001000
2025-08-28 07:04:44,640 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-28 07:04:44,794 - INFO - Epoch: [199][0/391] Time 0.152 (0.152) Data 0.132 (0.132) Loss 0.2414 (0.2414) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 07:04:46,643 - INFO - Epoch: [199][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2649 (0.2537) Acc@1 92.188 (91.321) Acc@5 99.219 (99.814)
2025-08-28 07:04:46,853 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:46,854 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:48,602 - INFO - Epoch: [199][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2514 (0.2537) Acc@1 92.969 (91.309) Acc@5 100.000 (99.813)
2025-08-28 07:04:50,019 - INFO - Pruning info: sparsity=0.950
2025-08-28 07:04:50,020 - INFO -   Reactivation rate: 0.0000
2025-08-28 07:04:50,601 - INFO - Epoch: [199][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2621 (0.2550) Acc@1 90.625 (91.240) Acc@5 97.656 (99.761)
2025-08-28 07:04:52,454 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2422 (0.2422) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 07:04:53,325 - INFO - Epoch 199:
2025-08-28 07:04:53,325 - INFO -   Train: acc1: 91.1860 | acc5: 99.7560 | loss: 0.2565 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-28 07:04:53,325 - INFO -   Val:   acc1: 88.5200 | acc5: 99.6900 | loss: 0.3369
2025-08-28 07:04:53,325 - INFO -   LR: 0.001000
2025-08-28 07:04:53,346 - INFO - training time: 00h 29m 19.85s
2025-08-28 07:04:53,346 - INFO - 
Training completed!
2025-08-28 07:04:53,346 - INFO - Best accuracy: 88.9000
2025-08-28 07:04:53,347 - INFO - Total training time: 0.49 hours
2025-08-28 07:04:53,347 - INFO - total_experiment time: 00h 29m 21.24s
2025-08-28 07:04:53,348 - INFO - Experiment completed successfully
2025-08-28 07:04:53,348 - INFO - Total time: 0.49 hours
