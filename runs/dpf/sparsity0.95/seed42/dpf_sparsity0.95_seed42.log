2025-08-27 16:57:44,516 - INFO - Starting experiment: dpf_sparsity0.95_seed42
2025-08-27 16:57:44,516 - INFO - Save directory: ./runs/dpf/sparsity0.95/seed42
2025-08-27 16:57:44,516 - INFO - Hyperparameters:
2025-08-27 16:57:44,516 - INFO -   name: dpf_sparsity0.95_seed42
2025-08-27 16:57:44,516 - INFO -   description: DPF pruning 95% (seed=42)
2025-08-27 16:57:44,516 - INFO -   save_dir: ./runs
2025-08-27 16:57:44,516 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 16:57:44,516 - INFO -   model: {'arch': 'resnet', 'layers': 18, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 16:57:44,516 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 16:57:44,516 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.95, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 16:57:44,516 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 16:57:44,516 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 16:57:44,552 - INFO - System Information:
2025-08-27 16:57:44,552 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 16:57:44,552 - INFO -   python_version: 3.9.18
2025-08-27 16:57:44,552 - INFO -   pytorch_version: 2.1.0
2025-08-27 16:57:44,552 - INFO -   cuda_available: True
2025-08-27 16:57:44,552 - INFO -   cpu_count: 4
2025-08-27 16:57:44,552 - INFO -   memory_total_gb: 11.0
2025-08-27 16:57:44,552 - INFO -   timestamp: 1756281464.5520756
2025-08-27 16:57:44,552 - INFO -   cuda_version: 11.8
2025-08-27 16:57:44,552 - INFO -   gpu_count: 1
2025-08-27 16:57:44,552 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 16:57:44,558 - INFO - Starting experiment: dpf_sparsity0.95_seed42
2025-08-27 16:57:44,558 - INFO - Model: resnet-18
2025-08-27 16:57:44,558 - INFO - Dataset: cifar10
2025-08-27 16:57:44,558 - INFO - Pruning: dpf (95.00%)
2025-08-27 18:18:50,208 - INFO - Starting experiment: dpf_sparsity0.95_seed42
2025-08-27 18:18:50,208 - INFO - Save directory: ./runs/dpf/sparsity0.95/seed42
2025-08-27 18:18:50,208 - INFO - Hyperparameters:
2025-08-27 18:18:50,208 - INFO -   name: dpf_sparsity0.95_seed42
2025-08-27 18:18:50,208 - INFO -   description: DPF pruning 95% (seed=42)
2025-08-27 18:18:50,208 - INFO -   save_dir: ./runs
2025-08-27 18:18:50,209 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 18:18:50,209 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 18:18:50,209 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 18:18:50,209 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.95, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 18:18:50,209 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 18:18:50,209 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 18:18:50,257 - INFO - System Information:
2025-08-27 18:18:50,257 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 18:18:50,257 - INFO -   python_version: 3.9.18
2025-08-27 18:18:50,257 - INFO -   pytorch_version: 2.1.0
2025-08-27 18:18:50,257 - INFO -   cuda_available: True
2025-08-27 18:18:50,257 - INFO -   cpu_count: 4
2025-08-27 18:18:50,257 - INFO -   memory_total_gb: 11.0
2025-08-27 18:18:50,257 - INFO -   timestamp: 1756286330.2568514
2025-08-27 18:18:50,257 - INFO -   cuda_version: 11.8
2025-08-27 18:18:50,257 - INFO -   gpu_count: 1
2025-08-27 18:18:50,257 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 18:18:50,263 - INFO - Starting experiment: dpf_sparsity0.95_seed42
2025-08-27 18:18:50,263 - INFO - Model: resnet-20
2025-08-27 18:18:50,263 - INFO - Dataset: cifar10
2025-08-27 18:18:50,263 - INFO - Pruning: dpf (95.00%)
2025-08-27 18:18:50,449 - INFO - Model Information:
2025-08-27 18:18:50,449 - INFO -   Type: pruned
2025-08-27 18:18:50,449 - INFO -   Total parameters: 544,948
2025-08-27 18:18:50,449 - INFO -   Trainable parameters: 274,692
2025-08-27 18:18:50,449 - INFO -   Sparsity: 95.00%
2025-08-27 18:18:51,425 - INFO - Starting training...
2025-08-27 18:18:51,426 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 18:18:52,084 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:18:52,085 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:18:52,588 - INFO - Epoch: [0][0/391] Time 1.162 (1.162) Data 0.512 (0.512) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 18:18:54,512 - INFO - Epoch: [0][100/391] Time 0.020 (0.031) Data 0.000 (0.007) Loss 1.7310 (1.9380) Acc@1 38.281 (26.369) Acc@5 88.281 (81.080)
2025-08-27 18:18:55,602 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:18:55,603 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:18:56,386 - INFO - Epoch: [0][200/391] Time 0.025 (0.025) Data 0.009 (0.004) Loss 1.5681 (1.8020) Acc@1 40.625 (31.608) Acc@5 90.625 (85.156)
2025-08-27 18:18:58,256 - INFO - Epoch: [0][300/391] Time 0.012 (0.023) Data 0.000 (0.003) Loss 1.4460 (1.7118) Acc@1 45.312 (35.582) Acc@5 91.406 (87.264)
2025-08-27 18:18:58,589 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:18:58,590 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:19:00,307 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 1.4572 (1.4572) Acc@1 46.094 (46.094) Acc@5 93.750 (93.750)
2025-08-27 18:19:01,232 - INFO - Epoch 0:
2025-08-27 18:19:01,232 - INFO -   Train: acc1: 38.6340 | acc5: 88.6060 | loss: 1.6414 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 18:19:01,232 - INFO -   Val:   acc1: 45.7700 | acc5: 92.7000 | loss: 1.5645
2025-08-27 18:19:01,232 - INFO -   LR: 0.100000
2025-08-27 18:19:01,280 - INFO - Checkpoint saved: epoch=0, metric=45.7700
2025-08-27 18:19:01,312 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 18:19:01,498 - INFO - Epoch: [1][0/391] Time 0.185 (0.185) Data 0.152 (0.152) Loss 1.4662 (1.4662) Acc@1 49.219 (49.219) Acc@5 90.625 (90.625)
2025-08-27 18:19:03,286 - INFO - Pruning info: sparsity=0.037
2025-08-27 18:19:03,286 - INFO -   Reactivation rate: 0.0094
2025-08-27 18:19:03,511 - INFO - Epoch: [1][100/391] Time 0.029 (0.022) Data 0.013 (0.003) Loss 1.1095 (1.2530) Acc@1 63.281 (54.912) Acc@5 96.094 (94.369)
2025-08-27 18:19:05,416 - INFO - Epoch: [1][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 1.0357 (1.2053) Acc@1 62.500 (56.503) Acc@5 98.438 (95.083)
2025-08-27 18:19:06,391 - INFO - Pruning info: sparsity=0.037
2025-08-27 18:19:06,391 - INFO -   Reactivation rate: 0.0064
2025-08-27 18:19:07,360 - INFO - Epoch: [1][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 1.0456 (1.1637) Acc@1 60.156 (58.028) Acc@5 97.656 (95.429)
2025-08-27 18:19:09,202 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 1.1527 (1.1527) Acc@1 60.938 (60.938) Acc@5 96.875 (96.875)
2025-08-27 18:19:10,034 - INFO - Epoch 1:
2025-08-27 18:19:10,035 - INFO -   Train: acc1: 59.3500 | acc5: 95.7480 | loss: 1.1310 | sparsity: 0.0375 | reactivation_rate: 0.0072
2025-08-27 18:19:10,035 - INFO -   Val:   acc1: 58.6000 | acc5: 96.0400 | loss: 1.1890
2025-08-27 18:19:10,035 - INFO -   LR: 0.100000
2025-08-27 18:19:10,077 - INFO - Checkpoint saved: epoch=1, metric=58.6000
2025-08-27 18:19:10,109 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 18:19:10,284 - INFO - Epoch: [2][0/391] Time 0.174 (0.174) Data 0.144 (0.144) Loss 0.9528 (0.9528) Acc@1 66.406 (66.406) Acc@5 97.656 (97.656)
2025-08-27 18:19:10,628 - INFO - Pruning info: sparsity=0.074
2025-08-27 18:19:10,628 - INFO -   Reactivation rate: 0.0144
2025-08-27 18:19:12,235 - INFO - Epoch: [2][100/391] Time 0.020 (0.021) Data 0.001 (0.003) Loss 0.8631 (0.9735) Acc@1 69.531 (65.795) Acc@5 96.875 (97.115)
2025-08-27 18:19:13,742 - INFO - Pruning info: sparsity=0.074
2025-08-27 18:19:13,743 - INFO -   Reactivation rate: 0.0078
2025-08-27 18:19:14,173 - INFO - Epoch: [2][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.8718 (0.9370) Acc@1 70.312 (66.915) Acc@5 97.656 (97.365)
2025-08-27 18:19:16,158 - INFO - Epoch: [2][300/391] Time 0.020 (0.020) Data 0.000 (0.001) Loss 0.8285 (0.9205) Acc@1 72.656 (67.507) Acc@5 99.219 (97.420)
2025-08-27 18:19:16,921 - INFO - Pruning info: sparsity=0.074
2025-08-27 18:19:16,921 - INFO -   Reactivation rate: 0.0060
2025-08-27 18:19:18,061 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.8595 (0.8595) Acc@1 67.188 (67.188) Acc@5 99.219 (99.219)
2025-08-27 18:19:18,922 - INFO - Epoch 2:
2025-08-27 18:19:18,922 - INFO -   Train: acc1: 68.1800 | acc5: 97.5320 | loss: 0.9038 | sparsity: 0.0740 | reactivation_rate: 0.0077
2025-08-27 18:19:18,922 - INFO -   Val:   acc1: 67.8900 | acc5: 96.6100 | loss: 0.9520
2025-08-27 18:19:18,922 - INFO -   LR: 0.100000
2025-08-27 18:19:18,967 - INFO - Checkpoint saved: epoch=2, metric=67.8900
2025-08-27 18:19:19,000 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 18:19:19,183 - INFO - Epoch: [3][0/391] Time 0.182 (0.182) Data 0.153 (0.153) Loss 0.7914 (0.7914) Acc@1 71.875 (71.875) Acc@5 96.875 (96.875)
2025-08-27 18:19:21,167 - INFO - Epoch: [3][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.8899 (0.7938) Acc@1 66.406 (72.795) Acc@5 96.875 (98.089)
2025-08-27 18:19:21,280 - INFO - Pruning info: sparsity=0.110
2025-08-27 18:19:21,280 - INFO -   Reactivation rate: 0.0095
2025-08-27 18:19:23,094 - INFO - Epoch: [3][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.7055 (0.7803) Acc@1 75.000 (73.216) Acc@5 99.219 (98.169)
2025-08-27 18:19:24,306 - INFO - Pruning info: sparsity=0.110
2025-08-27 18:19:24,306 - INFO -   Reactivation rate: 0.0064
2025-08-27 18:19:24,916 - INFO - Epoch: [3][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.7769 (0.7757) Acc@1 71.094 (73.274) Acc@5 98.438 (98.149)
2025-08-27 18:19:26,855 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.8857 (0.8857) Acc@1 66.406 (66.406) Acc@5 98.438 (98.438)
2025-08-27 18:19:27,695 - INFO - Epoch 3:
2025-08-27 18:19:27,695 - INFO -   Train: acc1: 73.2780 | acc5: 98.1600 | loss: 0.7747 | sparsity: 0.1095 | reactivation_rate: 0.0077
2025-08-27 18:19:27,695 - INFO -   Val:   acc1: 68.1100 | acc5: 97.0400 | loss: 0.9349
2025-08-27 18:19:27,695 - INFO -   LR: 0.100000
2025-08-27 18:19:27,739 - INFO - Checkpoint saved: epoch=3, metric=68.1100
2025-08-27 18:19:27,771 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 18:19:27,940 - INFO - Epoch: [4][0/391] Time 0.168 (0.168) Data 0.136 (0.136) Loss 0.6836 (0.6836) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 18:19:28,644 - INFO - Pruning info: sparsity=0.144
2025-08-27 18:19:28,644 - INFO -   Reactivation rate: 0.0118
2025-08-27 18:19:29,938 - INFO - Epoch: [4][100/391] Time 0.026 (0.021) Data 0.000 (0.003) Loss 0.7196 (0.7268) Acc@1 78.125 (74.559) Acc@5 96.875 (98.399)
2025-08-27 18:19:31,768 - INFO - Pruning info: sparsity=0.144
2025-08-27 18:19:31,768 - INFO -   Reactivation rate: 0.0069
2025-08-27 18:19:31,854 - INFO - Epoch: [4][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.7031 (0.7095) Acc@1 77.344 (75.439) Acc@5 96.094 (98.379)
2025-08-27 18:19:33,754 - INFO - Epoch: [4][300/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.6770 (0.7058) Acc@1 75.000 (75.589) Acc@5 99.219 (98.432)
2025-08-27 18:19:34,851 - INFO - Pruning info: sparsity=0.144
2025-08-27 18:19:34,852 - INFO -   Reactivation rate: 0.0057
2025-08-27 18:19:35,652 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 1.3056 (1.3056) Acc@1 57.812 (57.812) Acc@5 95.312 (95.312)
2025-08-27 18:19:36,497 - INFO - Epoch 4:
2025-08-27 18:19:36,497 - INFO -   Train: acc1: 75.7680 | acc5: 98.4680 | loss: 0.7023 | sparsity: 0.1440 | reactivation_rate: 0.0075
2025-08-27 18:19:36,497 - INFO -   Val:   acc1: 62.5100 | acc5: 96.2200 | loss: 1.1922
2025-08-27 18:19:36,497 - INFO -   LR: 0.100000
2025-08-27 18:19:36,506 - INFO - training time: 00h 00m 45.08s
2025-08-27 18:19:36,506 - INFO - 
Training completed!
2025-08-27 18:19:36,506 - INFO - Best accuracy: 68.1100
2025-08-27 18:19:36,506 - INFO - Total training time: 0.01 hours
2025-08-27 18:19:36,506 - INFO - total_experiment time: 00h 00m 46.30s
2025-08-27 18:19:36,507 - INFO - Experiment completed successfully
2025-08-27 18:19:36,507 - INFO - Total time: 0.01 hours
2025-08-27 23:12:14,677 - INFO - Starting experiment: dpf_sparsity0.95_seed42
2025-08-27 23:12:14,677 - INFO - Save directory: ./runs/dpf/sparsity0.95/seed42
2025-08-27 23:12:14,677 - INFO - Hyperparameters:
2025-08-27 23:12:14,677 - INFO -   name: dpf_sparsity0.95_seed42
2025-08-27 23:12:14,678 - INFO -   description: DPF pruning 95% (seed=42)
2025-08-27 23:12:14,678 - INFO -   save_dir: ./runs
2025-08-27 23:12:14,678 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 23:12:14,678 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 23:12:14,678 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 23:12:14,678 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.95, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 23:12:14,678 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 23:12:14,678 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 23:12:14,764 - INFO - System Information:
2025-08-27 23:12:14,764 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 23:12:14,764 - INFO -   python_version: 3.9.18
2025-08-27 23:12:14,764 - INFO -   pytorch_version: 2.1.0
2025-08-27 23:12:14,764 - INFO -   cuda_available: True
2025-08-27 23:12:14,764 - INFO -   cpu_count: 4
2025-08-27 23:12:14,764 - INFO -   memory_total_gb: 11.0
2025-08-27 23:12:14,764 - INFO -   timestamp: 1756303934.7639856
2025-08-27 23:12:14,764 - INFO -   cuda_version: 11.8
2025-08-27 23:12:14,764 - INFO -   gpu_count: 1
2025-08-27 23:12:14,764 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 23:12:14,770 - INFO - Starting experiment: dpf_sparsity0.95_seed42
2025-08-27 23:12:14,770 - INFO - Model: resnet-20
2025-08-27 23:12:14,771 - INFO - Dataset: cifar10
2025-08-27 23:12:14,771 - INFO - Pruning: dpf (95.00%)
2025-08-27 23:12:14,927 - INFO - Model Information:
2025-08-27 23:12:14,927 - INFO -   Type: pruned
2025-08-27 23:12:14,927 - INFO -   Total parameters: 544,948
2025-08-27 23:12:14,927 - INFO -   Trainable parameters: 274,692
2025-08-27 23:12:14,927 - INFO -   Sparsity: 95.00%
2025-08-27 23:12:15,936 - INFO - Starting training...
2025-08-27 23:12:15,937 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 23:12:16,659 - INFO - Pruning info: sparsity=0.000
2025-08-27 23:12:16,659 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:12:17,167 - INFO - Epoch: [0][0/391] Time 1.230 (1.230) Data 0.575 (0.575) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 23:12:19,033 - INFO - Epoch: [0][100/391] Time 0.018 (0.031) Data 0.002 (0.007) Loss 1.7092 (1.9202) Acc@1 33.594 (26.454) Acc@5 85.938 (81.219)
2025-08-27 23:12:20,102 - INFO - Pruning info: sparsity=0.000
2025-08-27 23:12:20,102 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:12:20,975 - INFO - Epoch: [0][200/391] Time 0.021 (0.025) Data 0.000 (0.004) Loss 1.4758 (1.7776) Acc@1 44.531 (32.066) Acc@5 91.406 (85.269)
2025-08-27 23:12:22,845 - INFO - Epoch: [0][300/391] Time 0.026 (0.023) Data 0.010 (0.003) Loss 1.3887 (1.6679) Acc@1 53.125 (36.965) Acc@5 92.969 (87.671)
2025-08-27 23:12:23,164 - INFO - Pruning info: sparsity=0.000
2025-08-27 23:12:23,164 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:12:24,800 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 1.4578 (1.4578) Acc@1 51.562 (51.562) Acc@5 92.969 (92.969)
2025-08-27 23:12:25,690 - INFO - Epoch 0:
2025-08-27 23:12:25,690 - INFO -   Train: acc1: 40.3000 | acc5: 89.1060 | loss: 1.5902 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 23:12:25,690 - INFO -   Val:   acc1: 49.3600 | acc5: 93.8400 | loss: 1.4149
2025-08-27 23:12:25,690 - INFO -   LR: 0.100000
2025-08-27 23:12:25,746 - INFO - Checkpoint saved: epoch=0, metric=49.3600
2025-08-27 23:12:25,778 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 23:12:25,944 - INFO - Epoch: [1][0/391] Time 0.165 (0.165) Data 0.141 (0.141) Loss 1.3270 (1.3270) Acc@1 52.344 (52.344) Acc@5 93.750 (93.750)
2025-08-27 23:12:27,681 - INFO - Pruning info: sparsity=0.037
2025-08-27 23:12:27,682 - INFO -   Reactivation rate: 0.0090
2025-08-27 23:12:27,878 - INFO - Epoch: [1][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 1.1163 (1.1986) Acc@1 60.156 (56.815) Acc@5 96.094 (94.887)
2025-08-27 23:12:29,749 - INFO - Epoch: [1][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.9660 (1.1545) Acc@1 68.750 (58.753) Acc@5 98.438 (95.188)
2025-08-27 23:12:30,705 - INFO - Pruning info: sparsity=0.037
2025-08-27 23:12:30,705 - INFO -   Reactivation rate: 0.0062
2025-08-27 23:12:31,702 - INFO - Epoch: [1][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.9100 (1.1122) Acc@1 67.969 (60.180) Acc@5 96.875 (95.655)
2025-08-27 23:12:33,588 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.9770 (0.9770) Acc@1 64.844 (64.844) Acc@5 99.219 (99.219)
2025-08-27 23:12:34,442 - INFO - Epoch 1:
2025-08-27 23:12:34,442 - INFO -   Train: acc1: 61.3480 | acc5: 95.9720 | loss: 1.0816 | sparsity: 0.0375 | reactivation_rate: 0.0072
2025-08-27 23:12:34,442 - INFO -   Val:   acc1: 59.8800 | acc5: 96.8900 | loss: 1.0855
2025-08-27 23:12:34,442 - INFO -   LR: 0.100000
2025-08-27 23:12:34,488 - INFO - Checkpoint saved: epoch=1, metric=59.8800
2025-08-27 23:12:34,519 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 23:12:34,696 - INFO - Epoch: [2][0/391] Time 0.177 (0.177) Data 0.159 (0.159) Loss 0.8758 (0.8758) Acc@1 70.312 (70.312) Acc@5 98.438 (98.438)
2025-08-27 23:12:35,051 - INFO - Pruning info: sparsity=0.074
2025-08-27 23:12:35,052 - INFO -   Reactivation rate: 0.0136
2025-08-27 23:12:36,668 - INFO - Epoch: [2][100/391] Time 0.018 (0.021) Data 0.001 (0.002) Loss 0.8963 (0.9335) Acc@1 69.531 (67.071) Acc@5 95.312 (97.161)
2025-08-27 23:12:38,115 - INFO - Pruning info: sparsity=0.074
2025-08-27 23:12:38,115 - INFO -   Reactivation rate: 0.0078
2025-08-27 23:12:38,539 - INFO - Epoch: [2][200/391] Time 0.021 (0.020) Data 0.002 (0.002) Loss 0.7971 (0.9047) Acc@1 75.000 (67.977) Acc@5 97.656 (97.446)
2025-08-27 23:12:40,487 - INFO - Epoch: [2][300/391] Time 0.025 (0.020) Data 0.013 (0.002) Loss 0.8225 (0.8927) Acc@1 70.312 (68.550) Acc@5 100.000 (97.472)
2025-08-27 23:12:41,141 - INFO - Pruning info: sparsity=0.074
2025-08-27 23:12:41,142 - INFO -   Reactivation rate: 0.0060
2025-08-27 23:12:42,302 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.7512 (0.7512) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 23:12:43,163 - INFO - Epoch 2:
2025-08-27 23:12:43,163 - INFO -   Train: acc1: 69.1140 | acc5: 97.5440 | loss: 0.8754 | sparsity: 0.0740 | reactivation_rate: 0.0076
2025-08-27 23:12:43,163 - INFO -   Val:   acc1: 70.4000 | acc5: 97.5900 | loss: 0.8485
2025-08-27 23:12:43,163 - INFO -   LR: 0.100000
2025-08-27 23:12:43,209 - INFO - Checkpoint saved: epoch=2, metric=70.4000
2025-08-27 23:12:43,241 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 23:12:43,411 - INFO - Epoch: [3][0/391] Time 0.169 (0.169) Data 0.146 (0.146) Loss 0.8372 (0.8372) Acc@1 70.312 (70.312) Acc@5 99.219 (99.219)
2025-08-27 23:12:45,338 - INFO - Epoch: [3][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.7868 (0.7705) Acc@1 70.312 (73.144) Acc@5 96.875 (98.089)
2025-08-27 23:12:45,450 - INFO - Pruning info: sparsity=0.110
2025-08-27 23:12:45,450 - INFO -   Reactivation rate: 0.0093
2025-08-27 23:12:47,354 - INFO - Epoch: [3][200/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.7113 (0.7634) Acc@1 72.656 (73.438) Acc@5 97.656 (98.119)
2025-08-27 23:12:48,690 - INFO - Pruning info: sparsity=0.110
2025-08-27 23:12:48,690 - INFO -   Reactivation rate: 0.0064
2025-08-27 23:12:49,314 - INFO - Epoch: [3][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.7674 (0.7564) Acc@1 76.562 (73.575) Acc@5 97.656 (98.157)
2025-08-27 23:12:51,097 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.8425 (0.8425) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-27 23:12:51,943 - INFO - Epoch 3:
2025-08-27 23:12:51,944 - INFO -   Train: acc1: 73.6360 | acc5: 98.1500 | loss: 0.7563 | sparsity: 0.1095 | reactivation_rate: 0.0077
2025-08-27 23:12:51,944 - INFO -   Val:   acc1: 70.7800 | acc5: 97.3900 | loss: 0.9181
2025-08-27 23:12:51,944 - INFO -   LR: 0.100000
2025-08-27 23:12:51,989 - INFO - Checkpoint saved: epoch=3, metric=70.7800
2025-08-27 23:12:52,337 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 23:12:52,519 - INFO - Epoch: [4][0/391] Time 0.181 (0.181) Data 0.159 (0.159) Loss 0.7322 (0.7322) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-27 23:12:53,192 - INFO - Pruning info: sparsity=0.144
2025-08-27 23:12:53,192 - INFO -   Reactivation rate: 0.0120
2025-08-27 23:12:54,376 - INFO - Epoch: [4][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.7504 (0.7148) Acc@1 78.125 (75.333) Acc@5 95.312 (98.267)
2025-08-27 23:12:56,099 - INFO - Pruning info: sparsity=0.144
2025-08-27 23:12:56,099 - INFO -   Reactivation rate: 0.0073
2025-08-27 23:12:56,193 - INFO - Epoch: [4][200/391] Time 0.026 (0.019) Data 0.000 (0.002) Loss 0.6632 (0.7001) Acc@1 75.781 (75.824) Acc@5 97.656 (98.344)
2025-08-27 23:12:58,100 - INFO - Epoch: [4][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.6899 (0.6976) Acc@1 77.344 (76.010) Acc@5 98.438 (98.373)
2025-08-27 23:12:59,188 - INFO - Pruning info: sparsity=0.144
2025-08-27 23:12:59,188 - INFO -   Reactivation rate: 0.0055
2025-08-27 23:12:59,988 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 1.8328 (1.8328) Acc@1 53.125 (53.125) Acc@5 96.875 (96.875)
2025-08-27 23:13:00,822 - INFO - Epoch 4:
2025-08-27 23:13:00,822 - INFO -   Train: acc1: 76.1060 | acc5: 98.4280 | loss: 0.6937 | sparsity: 0.1440 | reactivation_rate: 0.0075
2025-08-27 23:13:00,822 - INFO -   Val:   acc1: 53.1600 | acc5: 93.4200 | loss: 1.8392
2025-08-27 23:13:00,822 - INFO -   LR: 0.100000
2025-08-27 23:13:00,830 - INFO - 
Epoch: 5, lr = 0.1
2025-08-27 23:13:01,004 - INFO - Epoch: [5][0/391] Time 0.172 (0.172) Data 0.154 (0.154) Loss 0.7278 (0.7278) Acc@1 70.312 (70.312) Acc@5 100.000 (100.000)
2025-08-27 23:13:02,797 - INFO - Epoch: [5][100/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.6416 (0.6825) Acc@1 77.344 (76.756) Acc@5 100.000 (98.492)
2025-08-27 23:13:03,281 - INFO - Pruning info: sparsity=0.178
2025-08-27 23:13:03,281 - INFO -   Reactivation rate: 0.0085
2025-08-27 23:13:04,752 - INFO - Epoch: [5][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.6592 (0.6655) Acc@1 81.250 (77.313) Acc@5 99.219 (98.519)
2025-08-27 23:13:06,312 - INFO - Pruning info: sparsity=0.178
2025-08-27 23:13:06,312 - INFO -   Reactivation rate: 0.0063
2025-08-27 23:13:06,649 - INFO - Epoch: [5][300/391] Time 0.035 (0.019) Data 0.016 (0.003) Loss 0.6562 (0.6599) Acc@1 74.219 (77.450) Acc@5 100.000 (98.554)
2025-08-27 23:13:08,421 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.8800 (0.8800) Acc@1 67.969 (67.969) Acc@5 98.438 (98.438)
2025-08-27 23:13:09,252 - INFO - Epoch 5:
2025-08-27 23:13:09,252 - INFO -   Train: acc1: 77.5260 | acc5: 98.5460 | loss: 0.6569 | sparsity: 0.1776 | reactivation_rate: 0.0074
2025-08-27 23:13:09,252 - INFO -   Val:   acc1: 68.9000 | acc5: 97.6600 | loss: 0.9203
2025-08-27 23:13:09,252 - INFO -   LR: 0.100000
2025-08-27 23:13:09,261 - INFO - 
Epoch: 6, lr = 0.1
2025-08-27 23:13:09,432 - INFO - Epoch: [6][0/391] Time 0.170 (0.170) Data 0.152 (0.152) Loss 0.5106 (0.5106) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:13:10,407 - INFO - Pruning info: sparsity=0.210
2025-08-27 23:13:10,407 - INFO -   Reactivation rate: 0.0106
2025-08-27 23:13:11,301 - INFO - Epoch: [6][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.5750 (0.6002) Acc@1 80.469 (79.247) Acc@5 98.438 (98.793)
2025-08-27 23:13:13,184 - INFO - Epoch: [6][200/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.6484 (0.6139) Acc@1 77.344 (78.914) Acc@5 99.219 (98.702)
2025-08-27 23:13:13,431 - INFO - Pruning info: sparsity=0.210
2025-08-27 23:13:13,431 - INFO -   Reactivation rate: 0.0067
2025-08-27 23:13:14,993 - INFO - Epoch: [6][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.6921 (0.6240) Acc@1 72.656 (78.766) Acc@5 100.000 (98.643)
2025-08-27 23:13:16,361 - INFO - Pruning info: sparsity=0.210
2025-08-27 23:13:16,361 - INFO -   Reactivation rate: 0.0051
2025-08-27 23:13:16,827 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.8345 (0.8345) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-27 23:13:17,661 - INFO - Epoch 6:
2025-08-27 23:13:17,661 - INFO -   Train: acc1: 78.7280 | acc5: 98.6680 | loss: 0.6235 | sparsity: 0.2102 | reactivation_rate: 0.0070
2025-08-27 23:13:17,661 - INFO -   Val:   acc1: 72.1600 | acc5: 98.3300 | loss: 0.8689
2025-08-27 23:13:17,661 - INFO -   LR: 0.100000
2025-08-27 23:13:17,705 - INFO - Checkpoint saved: epoch=6, metric=72.1600
2025-08-27 23:13:17,738 - INFO - 
Epoch: 7, lr = 0.1
2025-08-27 23:13:17,917 - INFO - Epoch: [7][0/391] Time 0.177 (0.177) Data 0.156 (0.156) Loss 0.6526 (0.6526) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 23:13:19,934 - INFO - Epoch: [7][100/391] Time 0.028 (0.022) Data 0.016 (0.003) Loss 0.6778 (0.6098) Acc@1 75.781 (79.030) Acc@5 98.438 (98.755)
2025-08-27 23:13:20,754 - INFO - Pruning info: sparsity=0.242
2025-08-27 23:13:20,754 - INFO -   Reactivation rate: 0.0079
2025-08-27 23:13:21,858 - INFO - Epoch: [7][200/391] Time 0.027 (0.020) Data 0.008 (0.002) Loss 0.4977 (0.6052) Acc@1 85.156 (79.186) Acc@5 100.000 (98.756)
2025-08-27 23:13:23,769 - INFO - Epoch: [7][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4727 (0.6025) Acc@1 83.594 (79.205) Acc@5 100.000 (98.811)
2025-08-27 23:13:23,817 - INFO - Pruning info: sparsity=0.242
2025-08-27 23:13:23,818 - INFO -   Reactivation rate: 0.0055
2025-08-27 23:13:25,556 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.7936 (0.7936) Acc@1 71.875 (71.875) Acc@5 96.875 (96.875)
2025-08-27 23:13:26,391 - INFO - Epoch 7:
2025-08-27 23:13:26,391 - INFO -   Train: acc1: 79.2220 | acc5: 98.8360 | loss: 0.6015 | sparsity: 0.2419 | reactivation_rate: 0.0070
2025-08-27 23:13:26,391 - INFO -   Val:   acc1: 70.5500 | acc5: 95.0700 | loss: 1.0560
2025-08-27 23:13:26,391 - INFO -   LR: 0.100000
2025-08-27 23:13:26,400 - INFO - 
Epoch: 8, lr = 0.1
2025-08-27 23:13:26,578 - INFO - Epoch: [8][0/391] Time 0.177 (0.177) Data 0.155 (0.155) Loss 0.4993 (0.4993) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-27 23:13:27,944 - INFO - Pruning info: sparsity=0.273
2025-08-27 23:13:27,945 - INFO -   Reactivation rate: 0.0095
2025-08-27 23:13:28,513 - INFO - Epoch: [8][100/391] Time 0.033 (0.021) Data 0.005 (0.003) Loss 0.5831 (0.5721) Acc@1 78.906 (80.476) Acc@5 100.000 (98.801)
2025-08-27 23:13:30,363 - INFO - Epoch: [8][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.5192 (0.5706) Acc@1 82.812 (80.527) Acc@5 98.438 (98.865)
2025-08-27 23:13:30,986 - INFO - Pruning info: sparsity=0.273
2025-08-27 23:13:30,986 - INFO -   Reactivation rate: 0.0062
2025-08-27 23:13:32,447 - INFO - Epoch: [8][300/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.7416 (0.5810) Acc@1 74.219 (80.178) Acc@5 99.219 (98.887)
2025-08-27 23:13:34,292 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.7343 (0.7343) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 23:13:35,127 - INFO - Epoch 8:
2025-08-27 23:13:35,127 - INFO -   Train: acc1: 80.2200 | acc5: 98.9100 | loss: 0.5782 | sparsity: 0.2727 | reactivation_rate: 0.0068
2025-08-27 23:13:35,127 - INFO -   Val:   acc1: 74.9100 | acc5: 98.5400 | loss: 0.7228
2025-08-27 23:13:35,127 - INFO -   LR: 0.100000
2025-08-27 23:13:35,171 - INFO - Checkpoint saved: epoch=8, metric=74.9100
2025-08-27 23:13:35,204 - INFO - 
Epoch: 9, lr = 0.1
2025-08-27 23:13:35,394 - INFO - Epoch: [9][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.5225 (0.5225) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 23:13:35,403 - INFO - Pruning info: sparsity=0.303
2025-08-27 23:13:35,404 - INFO -   Reactivation rate: 0.0008
2025-08-27 23:13:37,405 - INFO - Epoch: [9][100/391] Time 0.012 (0.022) Data 0.000 (0.003) Loss 0.4910 (0.5538) Acc@1 86.719 (80.941) Acc@5 96.875 (98.994)
2025-08-27 23:13:38,582 - INFO - Pruning info: sparsity=0.303
2025-08-27 23:13:38,582 - INFO -   Reactivation rate: 0.0063
2025-08-27 23:13:39,265 - INFO - Epoch: [9][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.5469 (0.5573) Acc@1 82.812 (80.951) Acc@5 98.438 (98.943)
2025-08-27 23:13:41,195 - INFO - Epoch: [9][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.7116 (0.5616) Acc@1 76.562 (80.785) Acc@5 96.094 (98.925)
2025-08-27 23:13:41,574 - INFO - Pruning info: sparsity=0.303
2025-08-27 23:13:41,574 - INFO -   Reactivation rate: 0.0049
2025-08-27 23:13:43,007 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.9510 (0.9510) Acc@1 67.969 (67.969) Acc@5 99.219 (99.219)
2025-08-27 23:13:43,878 - INFO - Epoch 9:
2025-08-27 23:13:43,878 - INFO -   Train: acc1: 80.6860 | acc5: 98.9380 | loss: 0.5610 | sparsity: 0.3026 | reactivation_rate: 0.0064
2025-08-27 23:13:43,878 - INFO -   Val:   acc1: 70.0700 | acc5: 97.4100 | loss: 0.9812
2025-08-27 23:13:43,878 - INFO -   LR: 0.100000
2025-08-27 23:13:43,888 - INFO - 
Epoch: 10, lr = 0.1
2025-08-27 23:13:44,071 - INFO - Epoch: [10][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.5058 (0.5058) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 23:13:45,731 - INFO - Pruning info: sparsity=0.332
2025-08-27 23:13:45,731 - INFO -   Reactivation rate: 0.0079
2025-08-27 23:13:45,936 - INFO - Epoch: [10][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.3801 (0.5336) Acc@1 85.938 (81.498) Acc@5 100.000 (99.165)
2025-08-27 23:13:47,825 - INFO - Epoch: [10][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4652 (0.5384) Acc@1 86.719 (81.277) Acc@5 97.656 (99.168)
2025-08-27 23:13:48,771 - INFO - Pruning info: sparsity=0.332
2025-08-27 23:13:48,771 - INFO -   Reactivation rate: 0.0054
2025-08-27 23:13:49,756 - INFO - Epoch: [10][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.7901 (0.5428) Acc@1 78.906 (81.245) Acc@5 98.438 (99.055)
2025-08-27 23:13:51,626 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.8732 (0.8732) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 23:13:52,571 - INFO - Epoch 10:
2025-08-27 23:13:52,571 - INFO -   Train: acc1: 81.2060 | acc5: 99.0100 | loss: 0.5431 | sparsity: 0.3316 | reactivation_rate: 0.0062
2025-08-27 23:13:52,571 - INFO -   Val:   acc1: 71.0100 | acc5: 98.4800 | loss: 0.9403
2025-08-27 23:13:52,571 - INFO -   LR: 0.100000
2025-08-27 23:13:52,613 - INFO - 
Epoch: 11, lr = 0.1
2025-08-27 23:13:52,803 - INFO - Epoch: [11][0/391] Time 0.189 (0.189) Data 0.157 (0.157) Loss 0.5642 (0.5642) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 23:13:53,213 - INFO - Pruning info: sparsity=0.360
2025-08-27 23:13:53,213 - INFO -   Reactivation rate: 0.0110
2025-08-27 23:13:54,803 - INFO - Epoch: [11][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.5481 (0.5277) Acc@1 78.906 (81.869) Acc@5 100.000 (99.288)
2025-08-27 23:13:56,228 - INFO - Pruning info: sparsity=0.360
2025-08-27 23:13:56,228 - INFO -   Reactivation rate: 0.0059
2025-08-27 23:13:56,639 - INFO - Epoch: [11][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.6241 (0.5283) Acc@1 77.344 (81.806) Acc@5 98.438 (99.215)
2025-08-27 23:13:58,574 - INFO - Epoch: [11][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.7107 (0.5317) Acc@1 75.781 (81.717) Acc@5 96.875 (99.182)
2025-08-27 23:13:59,313 - INFO - Pruning info: sparsity=0.360
2025-08-27 23:13:59,313 - INFO -   Reactivation rate: 0.0044
2025-08-27 23:14:00,424 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.6233 (0.6233) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 23:14:01,255 - INFO - Epoch 11:
2025-08-27 23:14:01,255 - INFO -   Train: acc1: 81.6480 | acc5: 99.0900 | loss: 0.5332 | sparsity: 0.3597 | reactivation_rate: 0.0059
2025-08-27 23:14:01,255 - INFO -   Val:   acc1: 75.3400 | acc5: 98.4400 | loss: 0.7393
2025-08-27 23:14:01,255 - INFO -   LR: 0.100000
2025-08-27 23:14:01,299 - INFO - Checkpoint saved: epoch=11, metric=75.3400
2025-08-27 23:14:01,332 - INFO - 
Epoch: 12, lr = 0.1
2025-08-27 23:14:01,530 - INFO - Epoch: [12][0/391] Time 0.197 (0.197) Data 0.172 (0.172) Loss 0.5254 (0.5254) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 23:14:03,449 - INFO - Epoch: [12][100/391] Time 0.020 (0.021) Data 0.001 (0.003) Loss 0.4357 (0.5252) Acc@1 85.156 (82.232) Acc@5 100.000 (99.010)
2025-08-27 23:14:03,598 - INFO - Pruning info: sparsity=0.387
2025-08-27 23:14:03,598 - INFO -   Reactivation rate: 0.0073
2025-08-27 23:14:05,435 - INFO - Epoch: [12][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.6774 (0.5170) Acc@1 74.219 (82.198) Acc@5 99.219 (99.028)
2025-08-27 23:14:06,806 - INFO - Pruning info: sparsity=0.387
2025-08-27 23:14:06,806 - INFO -   Reactivation rate: 0.0047
2025-08-27 23:14:07,387 - INFO - Epoch: [12][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5736 (0.5218) Acc@1 79.688 (82.122) Acc@5 100.000 (99.092)
2025-08-27 23:14:09,201 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7411 (0.7411) Acc@1 78.906 (78.906) Acc@5 96.875 (96.875)
2025-08-27 23:14:10,081 - INFO - Epoch 12:
2025-08-27 23:14:10,081 - INFO -   Train: acc1: 82.0220 | acc5: 99.1000 | loss: 0.5222 | sparsity: 0.3869 | reactivation_rate: 0.0057
2025-08-27 23:14:10,081 - INFO -   Val:   acc1: 73.8400 | acc5: 96.6200 | loss: 0.8111
2025-08-27 23:14:10,081 - INFO -   LR: 0.100000
2025-08-27 23:14:10,090 - INFO - 
Epoch: 13, lr = 0.1
2025-08-27 23:14:10,276 - INFO - Epoch: [13][0/391] Time 0.186 (0.186) Data 0.148 (0.148) Loss 0.5536 (0.5536) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 23:14:10,995 - INFO - Pruning info: sparsity=0.413
2025-08-27 23:14:10,995 - INFO -   Reactivation rate: 0.0086
2025-08-27 23:14:12,209 - INFO - Epoch: [13][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.4192 (0.5049) Acc@1 88.281 (82.333) Acc@5 99.219 (99.095)
2025-08-27 23:14:14,009 - INFO - Pruning info: sparsity=0.413
2025-08-27 23:14:14,010 - INFO -   Reactivation rate: 0.0053
2025-08-27 23:14:14,083 - INFO - Epoch: [13][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3539 (0.5176) Acc@1 89.844 (81.985) Acc@5 99.219 (99.063)
2025-08-27 23:14:15,881 - INFO - Epoch: [13][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.5382 (0.5205) Acc@1 76.562 (81.904) Acc@5 100.000 (99.073)
2025-08-27 23:14:16,904 - INFO - Pruning info: sparsity=0.413
2025-08-27 23:14:16,904 - INFO -   Reactivation rate: 0.0038
2025-08-27 23:14:17,697 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5321 (0.5321) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 23:14:18,524 - INFO - Epoch 13:
2025-08-27 23:14:18,525 - INFO -   Train: acc1: 81.8860 | acc5: 99.0760 | loss: 0.5231 | sparsity: 0.4133 | reactivation_rate: 0.0054
2025-08-27 23:14:18,525 - INFO -   Val:   acc1: 77.4300 | acc5: 98.9500 | loss: 0.6527
2025-08-27 23:14:18,525 - INFO -   LR: 0.100000
2025-08-27 23:14:18,571 - INFO - Checkpoint saved: epoch=13, metric=77.4300
2025-08-27 23:14:18,604 - INFO - 
Epoch: 14, lr = 0.1
2025-08-27 23:14:18,801 - INFO - Epoch: [14][0/391] Time 0.196 (0.196) Data 0.173 (0.173) Loss 0.4724 (0.4724) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 23:14:20,733 - INFO - Epoch: [14][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.6599 (0.5071) Acc@1 76.562 (82.751) Acc@5 100.000 (99.196)
2025-08-27 23:14:21,202 - INFO - Pruning info: sparsity=0.439
2025-08-27 23:14:21,202 - INFO -   Reactivation rate: 0.0062
2025-08-27 23:14:22,638 - INFO - Epoch: [14][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.5699 (0.5013) Acc@1 83.594 (82.704) Acc@5 99.219 (99.172)
2025-08-27 23:14:24,334 - INFO - Pruning info: sparsity=0.439
2025-08-27 23:14:24,334 - INFO -   Reactivation rate: 0.0043
2025-08-27 23:14:24,596 - INFO - Epoch: [14][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4639 (0.5077) Acc@1 83.594 (82.389) Acc@5 100.000 (99.175)
2025-08-27 23:14:26,458 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5983 (0.5983) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 23:14:27,310 - INFO - Epoch 14:
2025-08-27 23:14:27,310 - INFO -   Train: acc1: 82.3780 | acc5: 99.1600 | loss: 0.5086 | sparsity: 0.4389 | reactivation_rate: 0.0052
2025-08-27 23:14:27,310 - INFO -   Val:   acc1: 79.4500 | acc5: 98.6700 | loss: 0.6217
2025-08-27 23:14:27,310 - INFO -   LR: 0.100000
2025-08-27 23:14:27,354 - INFO - Checkpoint saved: epoch=14, metric=79.4500
2025-08-27 23:14:27,386 - INFO - 
Epoch: 15, lr = 0.1
2025-08-27 23:14:27,569 - INFO - Epoch: [15][0/391] Time 0.182 (0.182) Data 0.163 (0.163) Loss 0.4920 (0.4920) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 23:14:28,575 - INFO - Pruning info: sparsity=0.464
2025-08-27 23:14:28,575 - INFO -   Reactivation rate: 0.0074
2025-08-27 23:14:29,425 - INFO - Epoch: [15][100/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3910 (0.4898) Acc@1 89.844 (83.021) Acc@5 98.438 (99.234)
2025-08-27 23:14:31,305 - INFO - Epoch: [15][200/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.5861 (0.5064) Acc@1 75.781 (82.653) Acc@5 99.219 (99.149)
2025-08-27 23:14:31,580 - INFO - Pruning info: sparsity=0.464
2025-08-27 23:14:31,580 - INFO -   Reactivation rate: 0.0044
2025-08-27 23:14:33,239 - INFO - Epoch: [15][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.4679 (0.5051) Acc@1 85.938 (82.665) Acc@5 98.438 (99.172)
2025-08-27 23:14:34,662 - INFO - Pruning info: sparsity=0.464
2025-08-27 23:14:34,662 - INFO -   Reactivation rate: 0.0036
2025-08-27 23:14:35,062 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.9660 (0.9660) Acc@1 67.969 (67.969) Acc@5 100.000 (100.000)
2025-08-27 23:14:35,895 - INFO - Epoch 15:
2025-08-27 23:14:35,895 - INFO -   Train: acc1: 82.6660 | acc5: 99.1420 | loss: 0.5063 | sparsity: 0.4636 | reactivation_rate: 0.0050
2025-08-27 23:14:35,896 - INFO -   Val:   acc1: 70.4100 | acc5: 98.3800 | loss: 0.9262
2025-08-27 23:14:35,896 - INFO -   LR: 0.100000
2025-08-27 23:14:35,908 - INFO - 
Epoch: 16, lr = 0.1
2025-08-27 23:14:36,094 - INFO - Epoch: [16][0/391] Time 0.185 (0.185) Data 0.149 (0.149) Loss 0.6397 (0.6397) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 23:14:38,058 - INFO - Epoch: [16][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.4657 (0.4823) Acc@1 85.938 (83.300) Acc@5 100.000 (99.219)
2025-08-27 23:14:38,860 - INFO - Pruning info: sparsity=0.488
2025-08-27 23:14:38,860 - INFO -   Reactivation rate: 0.0050
2025-08-27 23:14:40,017 - INFO - Epoch: [16][200/391] Time 0.019 (0.020) Data 0.008 (0.002) Loss 0.4490 (0.4808) Acc@1 85.938 (83.543) Acc@5 98.438 (99.254)
2025-08-27 23:14:41,917 - INFO - Epoch: [16][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.6242 (0.4885) Acc@1 77.344 (83.171) Acc@5 99.219 (99.229)
2025-08-27 23:14:42,000 - INFO - Pruning info: sparsity=0.488
2025-08-27 23:14:42,001 - INFO -   Reactivation rate: 0.0037
2025-08-27 23:14:43,825 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5954 (0.5954) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 23:14:44,683 - INFO - Epoch 16:
2025-08-27 23:14:44,683 - INFO -   Train: acc1: 83.2600 | acc5: 99.2060 | loss: 0.4879 | sparsity: 0.4875 | reactivation_rate: 0.0047
2025-08-27 23:14:44,683 - INFO -   Val:   acc1: 79.6300 | acc5: 99.0700 | loss: 0.5935
2025-08-27 23:14:44,683 - INFO -   LR: 0.100000
2025-08-27 23:14:44,729 - INFO - Checkpoint saved: epoch=16, metric=79.6300
2025-08-27 23:14:44,761 - INFO - 
Epoch: 17, lr = 0.1
2025-08-27 23:14:44,937 - INFO - Epoch: [17][0/391] Time 0.174 (0.174) Data 0.142 (0.142) Loss 0.4344 (0.4344) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-27 23:14:46,354 - INFO - Pruning info: sparsity=0.511
2025-08-27 23:14:46,354 - INFO -   Reactivation rate: 0.0062
2025-08-27 23:14:46,889 - INFO - Epoch: [17][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.4464 (0.4725) Acc@1 79.688 (83.795) Acc@5 99.219 (99.304)
2025-08-27 23:14:48,739 - INFO - Epoch: [17][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.3911 (0.4817) Acc@1 85.938 (83.438) Acc@5 100.000 (99.207)
2025-08-27 23:14:49,374 - INFO - Pruning info: sparsity=0.511
2025-08-27 23:14:49,375 - INFO -   Reactivation rate: 0.0042
2025-08-27 23:14:50,704 - INFO - Epoch: [17][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4609 (0.4923) Acc@1 81.250 (82.992) Acc@5 99.219 (99.188)
2025-08-27 23:14:52,580 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.9097 (0.9097) Acc@1 72.656 (72.656) Acc@5 99.219 (99.219)
2025-08-27 23:14:53,433 - INFO - Epoch 17:
2025-08-27 23:14:53,433 - INFO -   Train: acc1: 83.0760 | acc5: 99.1880 | loss: 0.4907 | sparsity: 0.5106 | reactivation_rate: 0.0046
2025-08-27 23:14:53,433 - INFO -   Val:   acc1: 70.9300 | acc5: 98.0000 | loss: 0.9610
2025-08-27 23:14:53,433 - INFO -   LR: 0.100000
2025-08-27 23:14:53,444 - INFO - 
Epoch: 18, lr = 0.1
2025-08-27 23:14:53,624 - INFO - Epoch: [18][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.5001 (0.5001) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:14:53,656 - INFO - Pruning info: sparsity=0.533
2025-08-27 23:14:53,656 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:14:55,727 - INFO - Epoch: [18][100/391] Time 0.021 (0.023) Data 0.000 (0.003) Loss 0.4340 (0.4835) Acc@1 84.375 (83.161) Acc@5 99.219 (99.211)
2025-08-27 23:14:56,902 - INFO - Pruning info: sparsity=0.533
2025-08-27 23:14:56,903 - INFO -   Reactivation rate: 0.0045
2025-08-27 23:14:57,606 - INFO - Epoch: [18][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.5504 (0.4810) Acc@1 82.031 (83.477) Acc@5 98.438 (99.203)
2025-08-27 23:14:59,539 - INFO - Epoch: [18][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.6450 (0.4830) Acc@1 78.125 (83.446) Acc@5 99.219 (99.156)
2025-08-27 23:14:59,930 - INFO - Pruning info: sparsity=0.533
2025-08-27 23:14:59,930 - INFO -   Reactivation rate: 0.0034
2025-08-27 23:15:01,343 - INFO - Test: [0/79] Time 0.109 (0.109) Loss 0.7781 (0.7781) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 23:15:02,220 - INFO - Epoch 18:
2025-08-27 23:15:02,221 - INFO -   Train: acc1: 83.4320 | acc5: 99.1720 | loss: 0.4832 | sparsity: 0.5330 | reactivation_rate: 0.0042
2025-08-27 23:15:02,221 - INFO -   Val:   acc1: 71.2200 | acc5: 97.6900 | loss: 0.9258
2025-08-27 23:15:02,221 - INFO -   LR: 0.100000
2025-08-27 23:15:02,231 - INFO - 
Epoch: 19, lr = 0.1
2025-08-27 23:15:02,427 - INFO - Epoch: [19][0/391] Time 0.195 (0.195) Data 0.158 (0.158) Loss 0.3419 (0.3419) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:15:04,149 - INFO - Pruning info: sparsity=0.555
2025-08-27 23:15:04,150 - INFO -   Reactivation rate: 0.0053
2025-08-27 23:15:04,332 - INFO - Epoch: [19][100/391] Time 0.018 (0.021) Data 0.000 (0.005) Loss 0.3783 (0.4647) Acc@1 86.719 (84.213) Acc@5 99.219 (99.234)
2025-08-27 23:15:06,209 - INFO - Epoch: [19][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3680 (0.4748) Acc@1 86.719 (83.633) Acc@5 100.000 (99.250)
2025-08-27 23:15:07,160 - INFO - Pruning info: sparsity=0.555
2025-08-27 23:15:07,160 - INFO -   Reactivation rate: 0.0035
2025-08-27 23:15:08,113 - INFO - Epoch: [19][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3110 (0.4780) Acc@1 88.281 (83.448) Acc@5 100.000 (99.229)
2025-08-27 23:15:10,022 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5127 (0.5127) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:15:10,865 - INFO - Epoch 19:
2025-08-27 23:15:10,865 - INFO -   Train: acc1: 83.6360 | acc5: 99.2540 | loss: 0.4739 | sparsity: 0.5545 | reactivation_rate: 0.0041
2025-08-27 23:15:10,865 - INFO -   Val:   acc1: 79.8200 | acc5: 99.0800 | loss: 0.5944
2025-08-27 23:15:10,865 - INFO -   LR: 0.100000
2025-08-27 23:15:10,910 - INFO - Checkpoint saved: epoch=19, metric=79.8200
2025-08-27 23:15:10,943 - INFO - 
Epoch: 20, lr = 0.1
2025-08-27 23:15:11,135 - INFO - Epoch: [20][0/391] Time 0.191 (0.191) Data 0.166 (0.166) Loss 0.4169 (0.4169) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 23:15:11,518 - INFO - Pruning info: sparsity=0.575
2025-08-27 23:15:11,518 - INFO -   Reactivation rate: 0.0063
2025-08-27 23:15:13,141 - INFO - Epoch: [20][100/391] Time 0.027 (0.022) Data 0.000 (0.003) Loss 0.3415 (0.4619) Acc@1 88.281 (84.004) Acc@5 99.219 (99.281)
2025-08-27 23:15:14,591 - INFO - Pruning info: sparsity=0.575
2025-08-27 23:15:14,591 - INFO -   Reactivation rate: 0.0040
2025-08-27 23:15:14,927 - INFO - Epoch: [20][200/391] Time 0.038 (0.020) Data 0.026 (0.002) Loss 0.4896 (0.4721) Acc@1 82.031 (83.745) Acc@5 99.219 (99.250)
2025-08-27 23:15:16,864 - INFO - Epoch: [20][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.5536 (0.4695) Acc@1 83.594 (83.882) Acc@5 98.438 (99.237)
2025-08-27 23:15:17,566 - INFO - Pruning info: sparsity=0.575
2025-08-27 23:15:17,566 - INFO -   Reactivation rate: 0.0029
2025-08-27 23:15:18,648 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.6013 (0.6013) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 23:15:19,491 - INFO - Epoch 20:
2025-08-27 23:15:19,492 - INFO -   Train: acc1: 83.6060 | acc5: 99.2420 | loss: 0.4753 | sparsity: 0.5753 | reactivation_rate: 0.0037
2025-08-27 23:15:19,492 - INFO -   Val:   acc1: 80.0300 | acc5: 98.6300 | loss: 0.6159
2025-08-27 23:15:19,492 - INFO -   LR: 0.100000
2025-08-27 23:15:19,535 - INFO - Checkpoint saved: epoch=20, metric=80.0300
2025-08-27 23:15:19,567 - INFO - 
Epoch: 21, lr = 0.1
2025-08-27 23:15:19,738 - INFO - Epoch: [21][0/391] Time 0.170 (0.170) Data 0.144 (0.144) Loss 0.4064 (0.4064) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 23:15:21,574 - INFO - Epoch: [21][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4087 (0.4486) Acc@1 84.375 (84.592) Acc@5 100.000 (99.296)
2025-08-27 23:15:21,731 - INFO - Pruning info: sparsity=0.595
2025-08-27 23:15:21,731 - INFO -   Reactivation rate: 0.0044
2025-08-27 23:15:23,481 - INFO - Epoch: [21][200/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.5353 (0.4578) Acc@1 82.031 (84.231) Acc@5 99.219 (99.258)
2025-08-27 23:15:24,746 - INFO - Pruning info: sparsity=0.595
2025-08-27 23:15:24,746 - INFO -   Reactivation rate: 0.0029
2025-08-27 23:15:25,275 - INFO - Epoch: [21][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4699 (0.4643) Acc@1 85.156 (83.970) Acc@5 99.219 (99.250)
2025-08-27 23:15:27,197 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.4257 (0.4257) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 23:15:28,033 - INFO - Epoch 21:
2025-08-27 23:15:28,033 - INFO -   Train: acc1: 83.7780 | acc5: 99.2460 | loss: 0.4683 | sparsity: 0.5954 | reactivation_rate: 0.0035
2025-08-27 23:15:28,033 - INFO -   Val:   acc1: 81.7400 | acc5: 99.0900 | loss: 0.5470
2025-08-27 23:15:28,033 - INFO -   LR: 0.100000
2025-08-27 23:15:28,079 - INFO - Checkpoint saved: epoch=21, metric=81.7400
2025-08-27 23:15:28,110 - INFO - 
Epoch: 22, lr = 0.1
2025-08-27 23:15:28,263 - INFO - Epoch: [22][0/391] Time 0.153 (0.153) Data 0.128 (0.128) Loss 0.3984 (0.3984) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 23:15:28,953 - INFO - Pruning info: sparsity=0.615
2025-08-27 23:15:28,953 - INFO -   Reactivation rate: 0.0046
2025-08-27 23:15:30,137 - INFO - Epoch: [22][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.5624 (0.4508) Acc@1 82.031 (84.599) Acc@5 99.219 (99.281)
2025-08-27 23:15:32,008 - INFO - Pruning info: sparsity=0.615
2025-08-27 23:15:32,008 - INFO -   Reactivation rate: 0.0033
2025-08-27 23:15:32,052 - INFO - Epoch: [22][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.4897 (0.4573) Acc@1 84.375 (84.324) Acc@5 99.219 (99.296)
2025-08-27 23:15:33,998 - INFO - Epoch: [22][300/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4122 (0.4588) Acc@1 82.812 (84.069) Acc@5 99.219 (99.312)
2025-08-27 23:15:35,059 - INFO - Pruning info: sparsity=0.615
2025-08-27 23:15:35,060 - INFO -   Reactivation rate: 0.0026
2025-08-27 23:15:35,774 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6571 (0.6571) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 23:15:36,582 - INFO - Epoch 22:
2025-08-27 23:15:36,582 - INFO -   Train: acc1: 83.9960 | acc5: 99.3100 | loss: 0.4620 | sparsity: 0.6148 | reactivation_rate: 0.0033
2025-08-27 23:15:36,582 - INFO -   Val:   acc1: 75.9400 | acc5: 98.4300 | loss: 0.7619
2025-08-27 23:15:36,582 - INFO -   LR: 0.100000
2025-08-27 23:15:36,591 - INFO - 
Epoch: 23, lr = 0.1
2025-08-27 23:15:36,778 - INFO - Epoch: [23][0/391] Time 0.187 (0.187) Data 0.161 (0.161) Loss 0.4962 (0.4962) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 23:15:38,629 - INFO - Epoch: [23][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4553 (0.4487) Acc@1 85.938 (84.615) Acc@5 98.438 (99.265)
2025-08-27 23:15:39,120 - INFO - Pruning info: sparsity=0.633
2025-08-27 23:15:39,120 - INFO -   Reactivation rate: 0.0038
2025-08-27 23:15:40,456 - INFO - Epoch: [23][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.5522 (0.4655) Acc@1 81.250 (84.037) Acc@5 98.438 (99.269)
2025-08-27 23:15:42,021 - INFO - Pruning info: sparsity=0.633
2025-08-27 23:15:42,021 - INFO -   Reactivation rate: 0.0025
2025-08-27 23:15:42,288 - INFO - Epoch: [23][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4104 (0.4644) Acc@1 89.062 (84.066) Acc@5 100.000 (99.312)
2025-08-27 23:15:44,143 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.7175 (0.7175) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 23:15:44,968 - INFO - Epoch 23:
2025-08-27 23:15:44,968 - INFO -   Train: acc1: 84.1560 | acc5: 99.2740 | loss: 0.4632 | sparsity: 0.6334 | reactivation_rate: 0.0032
2025-08-27 23:15:44,968 - INFO -   Val:   acc1: 74.5800 | acc5: 98.5400 | loss: 0.8704
2025-08-27 23:15:44,968 - INFO -   LR: 0.100000
2025-08-27 23:15:44,979 - INFO - 
Epoch: 24, lr = 0.1
2025-08-27 23:15:45,134 - INFO - Epoch: [24][0/391] Time 0.155 (0.155) Data 0.130 (0.130) Loss 0.4084 (0.4084) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:15:46,162 - INFO - Pruning info: sparsity=0.651
2025-08-27 23:15:46,162 - INFO -   Reactivation rate: 0.0040
2025-08-27 23:15:47,007 - INFO - Epoch: [24][100/391] Time 0.033 (0.020) Data 0.019 (0.004) Loss 0.4211 (0.4674) Acc@1 81.250 (83.594) Acc@5 100.000 (99.343)
2025-08-27 23:15:48,873 - INFO - Epoch: [24][200/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.5450 (0.4662) Acc@1 78.906 (83.710) Acc@5 99.219 (99.324)
2025-08-27 23:15:49,116 - INFO - Pruning info: sparsity=0.651
2025-08-27 23:15:49,116 - INFO -   Reactivation rate: 0.0028
2025-08-27 23:15:50,805 - INFO - Epoch: [24][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4599 (0.4586) Acc@1 82.812 (84.092) Acc@5 100.000 (99.289)
2025-08-27 23:15:52,267 - INFO - Pruning info: sparsity=0.651
2025-08-27 23:15:52,267 - INFO -   Reactivation rate: 0.0023
2025-08-27 23:15:52,624 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.6605 (0.6605) Acc@1 82.031 (82.031) Acc@5 95.312 (95.312)
2025-08-27 23:15:53,516 - INFO - Epoch 24:
2025-08-27 23:15:53,516 - INFO -   Train: acc1: 84.1220 | acc5: 99.2700 | loss: 0.4592 | sparsity: 0.6513 | reactivation_rate: 0.0030
2025-08-27 23:15:53,517 - INFO -   Val:   acc1: 78.3000 | acc5: 97.5500 | loss: 0.6778
2025-08-27 23:15:53,517 - INFO -   LR: 0.100000
2025-08-27 23:15:53,527 - INFO - 
Epoch: 25, lr = 0.1
2025-08-27 23:15:53,698 - INFO - Epoch: [25][0/391] Time 0.169 (0.169) Data 0.147 (0.147) Loss 0.4677 (0.4677) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 23:15:55,673 - INFO - Epoch: [25][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.5646 (0.4262) Acc@1 82.812 (85.365) Acc@5 100.000 (99.397)
2025-08-27 23:15:56,550 - INFO - Pruning info: sparsity=0.669
2025-08-27 23:15:56,551 - INFO -   Reactivation rate: 0.0030
2025-08-27 23:15:57,630 - INFO - Epoch: [25][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.6859 (0.4459) Acc@1 77.344 (84.632) Acc@5 97.656 (99.347)
2025-08-27 23:15:59,593 - INFO - Epoch: [25][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4597 (0.4476) Acc@1 81.250 (84.619) Acc@5 99.219 (99.341)
2025-08-27 23:15:59,675 - INFO - Pruning info: sparsity=0.669
2025-08-27 23:15:59,675 - INFO -   Reactivation rate: 0.0022
2025-08-27 23:16:01,457 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6304 (0.6304) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 23:16:02,295 - INFO - Epoch 25:
2025-08-27 23:16:02,295 - INFO -   Train: acc1: 84.6100 | acc5: 99.3340 | loss: 0.4494 | sparsity: 0.6685 | reactivation_rate: 0.0027
2025-08-27 23:16:02,295 - INFO -   Val:   acc1: 76.5400 | acc5: 98.8300 | loss: 0.7170
2025-08-27 23:16:02,295 - INFO -   LR: 0.100000
2025-08-27 23:16:02,306 - INFO - 
Epoch: 26, lr = 0.1
2025-08-27 23:16:02,500 - INFO - Epoch: [26][0/391] Time 0.193 (0.193) Data 0.171 (0.171) Loss 0.3841 (0.3841) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-27 23:16:03,917 - INFO - Pruning info: sparsity=0.685
2025-08-27 23:16:03,917 - INFO -   Reactivation rate: 0.0034
2025-08-27 23:16:04,373 - INFO - Epoch: [26][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4994 (0.4352) Acc@1 84.375 (85.172) Acc@5 98.438 (99.312)
2025-08-27 23:16:06,253 - INFO - Epoch: [26][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4771 (0.4378) Acc@1 82.031 (84.911) Acc@5 100.000 (99.335)
2025-08-27 23:16:06,916 - INFO - Pruning info: sparsity=0.685
2025-08-27 23:16:06,917 - INFO -   Reactivation rate: 0.0026
2025-08-27 23:16:08,174 - INFO - Epoch: [26][300/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.6785 (0.4480) Acc@1 74.219 (84.567) Acc@5 100.000 (99.336)
2025-08-27 23:16:10,019 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5237 (0.5237) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:16:10,846 - INFO - Epoch 26:
2025-08-27 23:16:10,846 - INFO -   Train: acc1: 84.6700 | acc5: 99.3580 | loss: 0.4445 | sparsity: 0.6851 | reactivation_rate: 0.0027
2025-08-27 23:16:10,846 - INFO -   Val:   acc1: 78.8200 | acc5: 98.7000 | loss: 0.6498
2025-08-27 23:16:10,846 - INFO -   LR: 0.100000
2025-08-27 23:16:10,855 - INFO - 
Epoch: 27, lr = 0.1
2025-08-27 23:16:11,038 - INFO - Epoch: [27][0/391] Time 0.182 (0.182) Data 0.160 (0.160) Loss 0.4337 (0.4337) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 23:16:11,106 - INFO - Pruning info: sparsity=0.701
2025-08-27 23:16:11,106 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:16:12,977 - INFO - Epoch: [27][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.4729 (0.4257) Acc@1 83.594 (85.288) Acc@5 100.000 (99.343)
2025-08-27 23:16:14,060 - INFO - Pruning info: sparsity=0.701
2025-08-27 23:16:14,060 - INFO -   Reactivation rate: 0.0026
2025-08-27 23:16:14,780 - INFO - Epoch: [27][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4911 (0.4339) Acc@1 82.812 (85.044) Acc@5 98.438 (99.425)
2025-08-27 23:16:16,676 - INFO - Epoch: [27][300/391] Time 0.019 (0.019) Data 0.003 (0.002) Loss 0.4964 (0.4385) Acc@1 85.156 (84.912) Acc@5 97.656 (99.419)
2025-08-27 23:16:17,133 - INFO - Pruning info: sparsity=0.701
2025-08-27 23:16:17,133 - INFO -   Reactivation rate: 0.0020
2025-08-27 23:16:18,613 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.7619 (0.7619) Acc@1 71.094 (71.094) Acc@5 100.000 (100.000)
2025-08-27 23:16:19,481 - INFO - Epoch 27:
2025-08-27 23:16:19,482 - INFO -   Train: acc1: 84.7480 | acc5: 99.3800 | loss: 0.4437 | sparsity: 0.7010 | reactivation_rate: 0.0024
2025-08-27 23:16:19,482 - INFO -   Val:   acc1: 75.2400 | acc5: 98.5400 | loss: 0.7102
2025-08-27 23:16:19,482 - INFO -   LR: 0.100000
2025-08-27 23:16:19,490 - INFO - 
Epoch: 28, lr = 0.1
2025-08-27 23:16:19,688 - INFO - Epoch: [28][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.3315 (0.3315) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:16:21,516 - INFO - Pruning info: sparsity=0.716
2025-08-27 23:16:21,516 - INFO -   Reactivation rate: 0.0028
2025-08-27 23:16:21,688 - INFO - Epoch: [28][100/391] Time 0.019 (0.022) Data 0.000 (0.002) Loss 0.4034 (0.4280) Acc@1 86.719 (85.226) Acc@5 100.000 (99.366)
2025-08-27 23:16:23,597 - INFO - Epoch: [28][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4103 (0.4391) Acc@1 87.500 (84.884) Acc@5 99.219 (99.316)
2025-08-27 23:16:24,560 - INFO - Pruning info: sparsity=0.716
2025-08-27 23:16:24,560 - INFO -   Reactivation rate: 0.0021
2025-08-27 23:16:25,519 - INFO - Epoch: [28][300/391] Time 0.030 (0.020) Data 0.000 (0.001) Loss 0.4415 (0.4417) Acc@1 82.031 (84.788) Acc@5 100.000 (99.323)
2025-08-27 23:16:27,321 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5379 (0.5379) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:16:28,163 - INFO - Epoch 28:
2025-08-27 23:16:28,163 - INFO -   Train: acc1: 84.8020 | acc5: 99.3400 | loss: 0.4415 | sparsity: 0.7162 | reactivation_rate: 0.0023
2025-08-27 23:16:28,163 - INFO -   Val:   acc1: 79.4400 | acc5: 98.8700 | loss: 0.6242
2025-08-27 23:16:28,163 - INFO -   LR: 0.100000
2025-08-27 23:16:28,175 - INFO - 
Epoch: 29, lr = 0.1
2025-08-27 23:16:28,367 - INFO - Epoch: [29][0/391] Time 0.191 (0.191) Data 0.163 (0.163) Loss 0.5709 (0.5709) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-27 23:16:28,769 - INFO - Pruning info: sparsity=0.731
2025-08-27 23:16:28,769 - INFO -   Reactivation rate: 0.0030
2025-08-27 23:16:30,295 - INFO - Epoch: [29][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.3498 (0.4239) Acc@1 89.062 (85.342) Acc@5 99.219 (99.443)
2025-08-27 23:16:31,863 - INFO - Pruning info: sparsity=0.731
2025-08-27 23:16:31,864 - INFO -   Reactivation rate: 0.0023
2025-08-27 23:16:32,253 - INFO - Epoch: [29][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4173 (0.4320) Acc@1 85.938 (85.156) Acc@5 100.000 (99.401)
2025-08-27 23:16:34,199 - INFO - Epoch: [29][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4201 (0.4348) Acc@1 83.594 (84.995) Acc@5 99.219 (99.413)
2025-08-27 23:16:34,969 - INFO - Pruning info: sparsity=0.731
2025-08-27 23:16:34,969 - INFO -   Reactivation rate: 0.0018
2025-08-27 23:16:36,069 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5067 (0.5067) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 23:16:36,903 - INFO - Epoch 29:
2025-08-27 23:16:36,904 - INFO -   Train: acc1: 85.0820 | acc5: 99.3800 | loss: 0.4343 | sparsity: 0.7308 | reactivation_rate: 0.0021
2025-08-27 23:16:36,904 - INFO -   Val:   acc1: 81.2400 | acc5: 98.7800 | loss: 0.5614
2025-08-27 23:16:36,904 - INFO -   LR: 0.100000
2025-08-27 23:16:37,387 - INFO - 
Epoch: 30, lr = 0.1
2025-08-27 23:16:37,570 - INFO - Epoch: [30][0/391] Time 0.182 (0.182) Data 0.150 (0.150) Loss 0.3354 (0.3354) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:16:39,386 - INFO - Epoch: [30][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4325 (0.4297) Acc@1 85.156 (85.450) Acc@5 100.000 (99.389)
2025-08-27 23:16:39,603 - INFO - Pruning info: sparsity=0.745
2025-08-27 23:16:39,603 - INFO -   Reactivation rate: 0.0023
2025-08-27 23:16:41,270 - INFO - Epoch: [30][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.3822 (0.4352) Acc@1 85.938 (85.152) Acc@5 98.438 (99.378)
2025-08-27 23:16:42,571 - INFO - Pruning info: sparsity=0.745
2025-08-27 23:16:42,571 - INFO -   Reactivation rate: 0.0018
2025-08-27 23:16:43,092 - INFO - Epoch: [30][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.4631 (0.4346) Acc@1 82.031 (85.161) Acc@5 100.000 (99.372)
2025-08-27 23:16:44,883 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5365 (0.5365) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 23:16:45,753 - INFO - Epoch 30:
2025-08-27 23:16:45,753 - INFO -   Train: acc1: 85.0780 | acc5: 99.4100 | loss: 0.4338 | sparsity: 0.7448 | reactivation_rate: 0.0020
2025-08-27 23:16:45,753 - INFO -   Val:   acc1: 78.6600 | acc5: 98.6900 | loss: 0.6369
2025-08-27 23:16:45,753 - INFO -   LR: 0.100000
2025-08-27 23:16:45,796 - INFO - 
Epoch: 31, lr = 0.1
2025-08-27 23:16:45,978 - INFO - Epoch: [31][0/391] Time 0.180 (0.180) Data 0.160 (0.160) Loss 0.4895 (0.4895) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 23:16:46,659 - INFO - Pruning info: sparsity=0.758
2025-08-27 23:16:46,659 - INFO -   Reactivation rate: 0.0024
2025-08-27 23:16:47,861 - INFO - Epoch: [31][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4307 (0.4246) Acc@1 84.375 (85.257) Acc@5 99.219 (99.319)
2025-08-27 23:16:49,702 - INFO - Pruning info: sparsity=0.758
2025-08-27 23:16:49,702 - INFO -   Reactivation rate: 0.0020
2025-08-27 23:16:49,743 - INFO - Epoch: [31][200/391] Time 0.027 (0.020) Data 0.008 (0.003) Loss 0.4000 (0.4318) Acc@1 86.719 (85.168) Acc@5 100.000 (99.300)
2025-08-27 23:16:51,565 - INFO - Epoch: [31][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4004 (0.4327) Acc@1 86.719 (85.042) Acc@5 99.219 (99.328)
2025-08-27 23:16:52,660 - INFO - Pruning info: sparsity=0.758
2025-08-27 23:16:52,661 - INFO -   Reactivation rate: 0.0014
2025-08-27 23:16:53,352 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5756 (0.5756) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 23:16:54,177 - INFO - Epoch 31:
2025-08-27 23:16:54,177 - INFO -   Train: acc1: 85.0180 | acc5: 99.3420 | loss: 0.4339 | sparsity: 0.7582 | reactivation_rate: 0.0019
2025-08-27 23:16:54,177 - INFO -   Val:   acc1: 79.4000 | acc5: 99.0600 | loss: 0.6048
2025-08-27 23:16:54,177 - INFO -   LR: 0.100000
2025-08-27 23:16:54,188 - INFO - 
Epoch: 32, lr = 0.1
2025-08-27 23:16:54,364 - INFO - Epoch: [32][0/391] Time 0.175 (0.175) Data 0.152 (0.152) Loss 0.4635 (0.4635) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 23:16:56,214 - INFO - Epoch: [32][100/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.4216 (0.4158) Acc@1 85.156 (85.984) Acc@5 99.219 (99.296)
2025-08-27 23:16:56,657 - INFO - Pruning info: sparsity=0.771
2025-08-27 23:16:56,658 - INFO -   Reactivation rate: 0.0021
2025-08-27 23:16:58,057 - INFO - Epoch: [32][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3981 (0.4161) Acc@1 86.719 (85.833) Acc@5 99.219 (99.398)
2025-08-27 23:16:59,722 - INFO - Pruning info: sparsity=0.771
2025-08-27 23:16:59,722 - INFO -   Reactivation rate: 0.0015
2025-08-27 23:16:59,928 - INFO - Epoch: [32][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.3746 (0.4218) Acc@1 88.281 (85.577) Acc@5 100.000 (99.395)
2025-08-27 23:17:01,713 - INFO - Test: [0/79] Time 0.117 (0.117) Loss 0.4608 (0.4608) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 23:17:02,542 - INFO - Epoch 32:
2025-08-27 23:17:02,542 - INFO -   Train: acc1: 85.2800 | acc5: 99.3880 | loss: 0.4284 | sparsity: 0.7710 | reactivation_rate: 0.0017
2025-08-27 23:17:02,542 - INFO -   Val:   acc1: 80.5200 | acc5: 99.2200 | loss: 0.5577
2025-08-27 23:17:02,543 - INFO -   LR: 0.100000
2025-08-27 23:17:02,552 - INFO - 
Epoch: 33, lr = 0.1
2025-08-27 23:17:02,733 - INFO - Epoch: [33][0/391] Time 0.180 (0.180) Data 0.157 (0.157) Loss 0.3515 (0.3515) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:17:03,761 - INFO - Pruning info: sparsity=0.783
2025-08-27 23:17:03,761 - INFO -   Reactivation rate: 0.0020
2025-08-27 23:17:04,535 - INFO - Epoch: [33][100/391] Time 0.023 (0.020) Data 0.012 (0.004) Loss 0.4012 (0.4288) Acc@1 85.156 (85.241) Acc@5 98.438 (99.335)
2025-08-27 23:17:06,397 - INFO - Epoch: [33][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4861 (0.4169) Acc@1 83.594 (85.673) Acc@5 100.000 (99.405)
2025-08-27 23:17:06,679 - INFO - Pruning info: sparsity=0.783
2025-08-27 23:17:06,679 - INFO -   Reactivation rate: 0.0018
2025-08-27 23:17:08,263 - INFO - Epoch: [33][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4446 (0.4211) Acc@1 88.281 (85.652) Acc@5 99.219 (99.413)
2025-08-27 23:17:09,610 - INFO - Pruning info: sparsity=0.783
2025-08-27 23:17:09,610 - INFO -   Reactivation rate: 0.0013
2025-08-27 23:17:09,972 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.4914 (0.4914) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:17:10,789 - INFO - Epoch 33:
2025-08-27 23:17:10,789 - INFO -   Train: acc1: 85.4380 | acc5: 99.3920 | loss: 0.4251 | sparsity: 0.7832 | reactivation_rate: 0.0016
2025-08-27 23:17:10,789 - INFO -   Val:   acc1: 80.8900 | acc5: 99.1700 | loss: 0.5904
2025-08-27 23:17:10,789 - INFO -   LR: 0.100000
2025-08-27 23:17:10,800 - INFO - 
Epoch: 34, lr = 0.1
2025-08-27 23:17:10,971 - INFO - Epoch: [34][0/391] Time 0.169 (0.169) Data 0.152 (0.152) Loss 0.4719 (0.4719) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 23:17:12,792 - INFO - Epoch: [34][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.4794 (0.4145) Acc@1 82.812 (85.705) Acc@5 99.219 (99.420)
2025-08-27 23:17:13,637 - INFO - Pruning info: sparsity=0.795
2025-08-27 23:17:13,637 - INFO -   Reactivation rate: 0.0016
2025-08-27 23:17:14,636 - INFO - Epoch: [34][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3492 (0.4177) Acc@1 87.500 (85.459) Acc@5 100.000 (99.429)
2025-08-27 23:17:16,439 - INFO - Epoch: [34][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4243 (0.4184) Acc@1 85.156 (85.494) Acc@5 98.438 (99.445)
2025-08-27 23:17:16,564 - INFO - Pruning info: sparsity=0.795
2025-08-27 23:17:16,564 - INFO -   Reactivation rate: 0.0013
2025-08-27 23:17:18,318 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5691 (0.5691) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:17:19,187 - INFO - Epoch 34:
2025-08-27 23:17:19,188 - INFO -   Train: acc1: 85.2900 | acc5: 99.4400 | loss: 0.4263 | sparsity: 0.7948 | reactivation_rate: 0.0014
2025-08-27 23:17:19,188 - INFO -   Val:   acc1: 80.6100 | acc5: 99.0700 | loss: 0.5882
2025-08-27 23:17:19,188 - INFO -   LR: 0.100000
2025-08-27 23:17:19,199 - INFO - 
Epoch: 35, lr = 0.1
2025-08-27 23:17:19,357 - INFO - Epoch: [35][0/391] Time 0.157 (0.157) Data 0.131 (0.131) Loss 0.3533 (0.3533) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 23:17:20,888 - INFO - Pruning info: sparsity=0.806
2025-08-27 23:17:20,888 - INFO -   Reactivation rate: 0.0016
2025-08-27 23:17:21,367 - INFO - Epoch: [35][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4636 (0.4182) Acc@1 85.156 (85.775) Acc@5 98.438 (99.366)
2025-08-27 23:17:23,313 - INFO - Epoch: [35][200/391] Time 0.032 (0.020) Data 0.015 (0.003) Loss 0.3459 (0.4156) Acc@1 90.625 (85.840) Acc@5 100.000 (99.328)
2025-08-27 23:17:23,944 - INFO - Pruning info: sparsity=0.806
2025-08-27 23:17:23,944 - INFO -   Reactivation rate: 0.0014
2025-08-27 23:17:25,212 - INFO - Epoch: [35][300/391] Time 0.022 (0.020) Data 0.006 (0.003) Loss 0.3531 (0.4240) Acc@1 85.938 (85.470) Acc@5 100.000 (99.325)
2025-08-27 23:17:27,038 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.4510 (0.4510) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:17:27,906 - INFO - Epoch 35:
2025-08-27 23:17:27,906 - INFO -   Train: acc1: 85.4600 | acc5: 99.3620 | loss: 0.4249 | sparsity: 0.8059 | reactivation_rate: 0.0014
2025-08-27 23:17:27,906 - INFO -   Val:   acc1: 81.8900 | acc5: 98.7900 | loss: 0.5454
2025-08-27 23:17:27,906 - INFO -   LR: 0.100000
2025-08-27 23:17:27,950 - INFO - Checkpoint saved: epoch=35, metric=81.8900
2025-08-27 23:17:27,983 - INFO - 
Epoch: 36, lr = 0.1
2025-08-27 23:17:28,164 - INFO - Epoch: [36][0/391] Time 0.180 (0.180) Data 0.155 (0.155) Loss 0.3714 (0.3714) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:17:28,228 - INFO - Pruning info: sparsity=0.816
2025-08-27 23:17:28,239 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:17:30,090 - INFO - Epoch: [36][100/391] Time 0.029 (0.021) Data 0.000 (0.003) Loss 0.4486 (0.4214) Acc@1 86.719 (85.435) Acc@5 100.000 (99.520)
2025-08-27 23:17:31,313 - INFO - Pruning info: sparsity=0.816
2025-08-27 23:17:31,313 - INFO -   Reactivation rate: 0.0014
2025-08-27 23:17:31,991 - INFO - Epoch: [36][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3473 (0.4211) Acc@1 88.281 (85.456) Acc@5 100.000 (99.436)
2025-08-27 23:17:33,878 - INFO - Epoch: [36][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.5577 (0.4259) Acc@1 78.906 (85.224) Acc@5 100.000 (99.421)
2025-08-27 23:17:34,248 - INFO - Pruning info: sparsity=0.816
2025-08-27 23:17:34,250 - INFO -   Reactivation rate: 0.0012
2025-08-27 23:17:35,604 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.7040 (0.7040) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-27 23:17:36,441 - INFO - Epoch 36:
2025-08-27 23:17:36,441 - INFO -   Train: acc1: 85.3560 | acc5: 99.4100 | loss: 0.4263 | sparsity: 0.8164 | reactivation_rate: 0.0013
2025-08-27 23:17:36,441 - INFO -   Val:   acc1: 77.7800 | acc5: 98.6000 | loss: 0.6884
2025-08-27 23:17:36,441 - INFO -   LR: 0.100000
2025-08-27 23:17:36,451 - INFO - 
Epoch: 37, lr = 0.1
2025-08-27 23:17:36,635 - INFO - Epoch: [37][0/391] Time 0.184 (0.184) Data 0.153 (0.153) Loss 0.4306 (0.4306) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 23:17:38,273 - INFO - Pruning info: sparsity=0.826
2025-08-27 23:17:38,273 - INFO -   Reactivation rate: 0.0013
2025-08-27 23:17:38,434 - INFO - Epoch: [37][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4216 (0.4196) Acc@1 84.375 (85.551) Acc@5 100.000 (99.489)
2025-08-27 23:17:40,342 - INFO - Epoch: [37][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3717 (0.4304) Acc@1 85.938 (85.195) Acc@5 100.000 (99.475)
2025-08-27 23:17:41,373 - INFO - Pruning info: sparsity=0.826
2025-08-27 23:17:41,373 - INFO -   Reactivation rate: 0.0011
2025-08-27 23:17:42,219 - INFO - Epoch: [37][300/391] Time 0.017 (0.019) Data 0.006 (0.002) Loss 0.5476 (0.4245) Acc@1 82.812 (85.390) Acc@5 99.219 (99.452)
2025-08-27 23:17:44,111 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5585 (0.5585) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 23:17:44,937 - INFO - Epoch 37:
2025-08-27 23:17:44,937 - INFO -   Train: acc1: 85.3080 | acc5: 99.4360 | loss: 0.4257 | sparsity: 0.8264 | reactivation_rate: 0.0012
2025-08-27 23:17:44,937 - INFO -   Val:   acc1: 78.3300 | acc5: 99.0500 | loss: 0.6361
2025-08-27 23:17:44,937 - INFO -   LR: 0.100000
2025-08-27 23:17:44,946 - INFO - 
Epoch: 38, lr = 0.1
2025-08-27 23:17:45,117 - INFO - Epoch: [38][0/391] Time 0.170 (0.170) Data 0.148 (0.148) Loss 0.2793 (0.2793) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:17:45,524 - INFO - Pruning info: sparsity=0.836
2025-08-27 23:17:45,524 - INFO -   Reactivation rate: 0.0017
2025-08-27 23:17:46,979 - INFO - Epoch: [38][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.5154 (0.4350) Acc@1 82.812 (84.708) Acc@5 100.000 (99.459)
2025-08-27 23:17:48,523 - INFO - Pruning info: sparsity=0.836
2025-08-27 23:17:48,523 - INFO -   Reactivation rate: 0.0011
2025-08-27 23:17:48,812 - INFO - Epoch: [38][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3311 (0.4320) Acc@1 88.281 (85.129) Acc@5 100.000 (99.436)
2025-08-27 23:17:50,706 - INFO - Epoch: [38][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4416 (0.4317) Acc@1 82.031 (85.081) Acc@5 100.000 (99.413)
2025-08-27 23:17:51,484 - INFO - Pruning info: sparsity=0.836
2025-08-27 23:17:51,485 - INFO -   Reactivation rate: 0.0010
2025-08-27 23:17:52,488 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5732 (0.5732) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 23:17:53,334 - INFO - Epoch 38:
2025-08-27 23:17:53,335 - INFO -   Train: acc1: 85.1640 | acc5: 99.3960 | loss: 0.4305 | sparsity: 0.8359 | reactivation_rate: 0.0011
2025-08-27 23:17:53,335 - INFO -   Val:   acc1: 78.5900 | acc5: 99.1100 | loss: 0.6439
2025-08-27 23:17:53,335 - INFO -   LR: 0.100000
2025-08-27 23:17:53,345 - INFO - 
Epoch: 39, lr = 0.1
2025-08-27 23:17:53,526 - INFO - Epoch: [39][0/391] Time 0.179 (0.179) Data 0.156 (0.156) Loss 0.3293 (0.3293) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:17:55,354 - INFO - Epoch: [39][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4351 (0.4125) Acc@1 86.719 (85.682) Acc@5 99.219 (99.459)
2025-08-27 23:17:55,573 - INFO - Pruning info: sparsity=0.845
2025-08-27 23:17:55,573 - INFO -   Reactivation rate: 0.0010
2025-08-27 23:17:57,257 - INFO - Epoch: [39][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4441 (0.4181) Acc@1 82.812 (85.533) Acc@5 99.219 (99.464)
2025-08-27 23:17:58,613 - INFO - Pruning info: sparsity=0.845
2025-08-27 23:17:58,613 - INFO -   Reactivation rate: 0.0010
2025-08-27 23:17:59,115 - INFO - Epoch: [39][300/391] Time 0.030 (0.019) Data 0.019 (0.003) Loss 0.5005 (0.4222) Acc@1 85.938 (85.470) Acc@5 97.656 (99.447)
2025-08-27 23:18:00,925 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.6913 (0.6913) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 23:18:01,741 - INFO - Epoch 39:
2025-08-27 23:18:01,741 - INFO -   Train: acc1: 85.4440 | acc5: 99.4400 | loss: 0.4235 | sparsity: 0.8449 | reactivation_rate: 0.0010
2025-08-27 23:18:01,741 - INFO -   Val:   acc1: 74.9100 | acc5: 97.9300 | loss: 0.8274
2025-08-27 23:18:01,741 - INFO -   LR: 0.100000
2025-08-27 23:18:01,752 - INFO - 
Epoch: 40, lr = 0.1
2025-08-27 23:18:01,925 - INFO - Epoch: [40][0/391] Time 0.172 (0.172) Data 0.137 (0.137) Loss 0.3504 (0.3504) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:18:02,643 - INFO - Pruning info: sparsity=0.853
2025-08-27 23:18:02,643 - INFO -   Reactivation rate: 0.0012
2025-08-27 23:18:03,727 - INFO - Epoch: [40][100/391] Time 0.030 (0.020) Data 0.013 (0.003) Loss 0.3499 (0.4243) Acc@1 87.500 (84.955) Acc@5 100.000 (99.451)
2025-08-27 23:18:05,617 - INFO - Pruning info: sparsity=0.853
2025-08-27 23:18:05,617 - INFO -   Reactivation rate: 0.0009
2025-08-27 23:18:05,631 - INFO - Epoch: [40][200/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.3967 (0.4147) Acc@1 83.594 (85.584) Acc@5 99.219 (99.471)
2025-08-27 23:18:07,554 - INFO - Epoch: [40][300/391] Time 0.029 (0.019) Data 0.000 (0.002) Loss 0.4381 (0.4179) Acc@1 82.031 (85.507) Acc@5 100.000 (99.494)
2025-08-27 23:18:08,610 - INFO - Pruning info: sparsity=0.853
2025-08-27 23:18:08,610 - INFO -   Reactivation rate: 0.0008
2025-08-27 23:18:09,352 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4955 (0.4955) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 23:18:10,178 - INFO - Epoch 40:
2025-08-27 23:18:10,178 - INFO -   Train: acc1: 85.4880 | acc5: 99.4620 | loss: 0.4208 | sparsity: 0.8535 | reactivation_rate: 0.0009
2025-08-27 23:18:10,178 - INFO -   Val:   acc1: 82.1200 | acc5: 99.3100 | loss: 0.5172
2025-08-27 23:18:10,178 - INFO -   LR: 0.100000
2025-08-27 23:18:10,222 - INFO - Checkpoint saved: epoch=40, metric=82.1200
2025-08-27 23:18:10,255 - INFO - 
Epoch: 41, lr = 0.1
2025-08-27 23:18:10,438 - INFO - Epoch: [41][0/391] Time 0.182 (0.182) Data 0.152 (0.152) Loss 0.3974 (0.3974) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:18:12,307 - INFO - Epoch: [41][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.5051 (0.4109) Acc@1 83.594 (85.651) Acc@5 100.000 (99.443)
2025-08-27 23:18:12,837 - INFO - Pruning info: sparsity=0.861
2025-08-27 23:18:12,837 - INFO -   Reactivation rate: 0.0010
2025-08-27 23:18:14,177 - INFO - Epoch: [41][200/391] Time 0.029 (0.019) Data 0.008 (0.002) Loss 0.3724 (0.4150) Acc@1 85.938 (85.603) Acc@5 99.219 (99.405)
2025-08-27 23:18:15,889 - INFO - Pruning info: sparsity=0.861
2025-08-27 23:18:15,890 - INFO -   Reactivation rate: 0.0008
2025-08-27 23:18:16,117 - INFO - Epoch: [41][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.3885 (0.4159) Acc@1 88.281 (85.678) Acc@5 99.219 (99.382)
2025-08-27 23:18:17,927 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.4226 (0.4226) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 23:18:18,749 - INFO - Epoch 41:
2025-08-27 23:18:18,749 - INFO -   Train: acc1: 85.4320 | acc5: 99.3740 | loss: 0.4217 | sparsity: 0.8615 | reactivation_rate: 0.0009
2025-08-27 23:18:18,750 - INFO -   Val:   acc1: 79.0500 | acc5: 98.8200 | loss: 0.6199
2025-08-27 23:18:18,750 - INFO -   LR: 0.100000
2025-08-27 23:18:18,768 - INFO - 
Epoch: 42, lr = 0.1
2025-08-27 23:18:18,939 - INFO - Epoch: [42][0/391] Time 0.170 (0.170) Data 0.149 (0.149) Loss 0.4578 (0.4578) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 23:18:20,009 - INFO - Pruning info: sparsity=0.869
2025-08-27 23:18:20,009 - INFO -   Reactivation rate: 0.0008
2025-08-27 23:18:20,795 - INFO - Epoch: [42][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.6272 (0.3992) Acc@1 80.469 (86.185) Acc@5 99.219 (99.505)
2025-08-27 23:18:22,709 - INFO - Epoch: [42][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.5067 (0.4096) Acc@1 82.812 (85.984) Acc@5 98.438 (99.471)
2025-08-27 23:18:23,028 - INFO - Pruning info: sparsity=0.869
2025-08-27 23:18:23,029 - INFO -   Reactivation rate: 0.0009
2025-08-27 23:18:24,581 - INFO - Epoch: [42][300/391] Time 0.037 (0.019) Data 0.019 (0.002) Loss 0.2944 (0.4218) Acc@1 89.062 (85.437) Acc@5 100.000 (99.445)
2025-08-27 23:18:26,035 - INFO - Pruning info: sparsity=0.869
2025-08-27 23:18:26,035 - INFO -   Reactivation rate: 0.0007
2025-08-27 23:18:26,402 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6549 (0.6549) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-27 23:18:27,243 - INFO - Epoch 42:
2025-08-27 23:18:27,244 - INFO -   Train: acc1: 85.2320 | acc5: 99.4360 | loss: 0.4274 | sparsity: 0.8691 | reactivation_rate: 0.0008
2025-08-27 23:18:27,244 - INFO -   Val:   acc1: 78.5100 | acc5: 98.5100 | loss: 0.6477
2025-08-27 23:18:27,244 - INFO -   LR: 0.100000
2025-08-27 23:18:27,254 - INFO - 
Epoch: 43, lr = 0.1
2025-08-27 23:18:27,406 - INFO - Epoch: [43][0/391] Time 0.151 (0.151) Data 0.130 (0.130) Loss 0.3558 (0.3558) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:18:29,282 - INFO - Epoch: [43][100/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4519 (0.4309) Acc@1 85.938 (85.311) Acc@5 99.219 (99.489)
2025-08-27 23:18:30,140 - INFO - Pruning info: sparsity=0.876
2025-08-27 23:18:30,141 - INFO -   Reactivation rate: 0.0008
2025-08-27 23:18:31,146 - INFO - Epoch: [43][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.3085 (0.4200) Acc@1 90.625 (85.630) Acc@5 100.000 (99.487)
2025-08-27 23:18:33,043 - INFO - Epoch: [43][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.3019 (0.4201) Acc@1 92.188 (85.597) Acc@5 100.000 (99.509)
2025-08-27 23:18:33,159 - INFO - Pruning info: sparsity=0.876
2025-08-27 23:18:33,159 - INFO -   Reactivation rate: 0.0007
2025-08-27 23:18:34,847 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5553 (0.5553) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 23:18:35,684 - INFO - Epoch 43:
2025-08-27 23:18:35,684 - INFO -   Train: acc1: 85.4500 | acc5: 99.4720 | loss: 0.4225 | sparsity: 0.8762 | reactivation_rate: 0.0007
2025-08-27 23:18:35,684 - INFO -   Val:   acc1: 80.1400 | acc5: 98.8600 | loss: 0.6055
2025-08-27 23:18:35,684 - INFO -   LR: 0.100000
2025-08-27 23:18:35,695 - INFO - 
Epoch: 44, lr = 0.1
2025-08-27 23:18:35,892 - INFO - Epoch: [44][0/391] Time 0.196 (0.196) Data 0.152 (0.152) Loss 0.3831 (0.3831) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 23:18:37,420 - INFO - Pruning info: sparsity=0.883
2025-08-27 23:18:37,420 - INFO -   Reactivation rate: 0.0008
2025-08-27 23:18:37,879 - INFO - Epoch: [44][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.3185 (0.4255) Acc@1 89.844 (85.311) Acc@5 99.219 (99.389)
2025-08-27 23:18:39,738 - INFO - Epoch: [44][200/391] Time 0.020 (0.020) Data 0.001 (0.002) Loss 0.3865 (0.4233) Acc@1 87.500 (85.413) Acc@5 99.219 (99.378)
2025-08-27 23:18:40,417 - INFO - Pruning info: sparsity=0.883
2025-08-27 23:18:40,418 - INFO -   Reactivation rate: 0.0007
2025-08-27 23:18:41,641 - INFO - Epoch: [44][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3261 (0.4218) Acc@1 89.062 (85.522) Acc@5 100.000 (99.403)
2025-08-27 23:18:43,429 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.5496 (0.5496) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:18:44,253 - INFO - Epoch 44:
2025-08-27 23:18:44,253 - INFO -   Train: acc1: 85.5140 | acc5: 99.3940 | loss: 0.4223 | sparsity: 0.8829 | reactivation_rate: 0.0007
2025-08-27 23:18:44,253 - INFO -   Val:   acc1: 81.4000 | acc5: 99.0100 | loss: 0.5710
2025-08-27 23:18:44,253 - INFO -   LR: 0.100000
2025-08-27 23:18:44,267 - INFO - 
Epoch: 45, lr = 0.1
2025-08-27 23:18:44,453 - INFO - Epoch: [45][0/391] Time 0.184 (0.184) Data 0.154 (0.154) Loss 0.3265 (0.3265) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:18:44,539 - INFO - Pruning info: sparsity=0.889
2025-08-27 23:18:44,540 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:18:46,376 - INFO - Epoch: [45][100/391] Time 0.026 (0.021) Data 0.013 (0.003) Loss 0.5472 (0.4227) Acc@1 81.250 (85.272) Acc@5 99.219 (99.435)
2025-08-27 23:18:47,600 - INFO - Pruning info: sparsity=0.889
2025-08-27 23:18:47,600 - INFO -   Reactivation rate: 0.0007
2025-08-27 23:18:48,267 - INFO - Epoch: [45][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3958 (0.4272) Acc@1 85.938 (85.141) Acc@5 100.000 (99.370)
2025-08-27 23:18:50,098 - INFO - Epoch: [45][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4511 (0.4291) Acc@1 82.812 (85.169) Acc@5 99.219 (99.393)
2025-08-27 23:18:50,612 - INFO - Pruning info: sparsity=0.889
2025-08-27 23:18:50,612 - INFO -   Reactivation rate: 0.0006
2025-08-27 23:18:52,002 - INFO - Test: [0/79] Time 0.111 (0.111) Loss 0.5843 (0.5843) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 23:18:52,863 - INFO - Epoch 45:
2025-08-27 23:18:52,864 - INFO -   Train: acc1: 85.1680 | acc5: 99.3920 | loss: 0.4315 | sparsity: 0.8892 | reactivation_rate: 0.0006
2025-08-27 23:18:52,864 - INFO -   Val:   acc1: 79.5700 | acc5: 98.8600 | loss: 0.6277
2025-08-27 23:18:52,864 - INFO -   LR: 0.100000
2025-08-27 23:18:52,875 - INFO - 
Epoch: 46, lr = 0.1
2025-08-27 23:18:53,020 - INFO - Epoch: [46][0/391] Time 0.145 (0.145) Data 0.113 (0.113) Loss 0.3657 (0.3657) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:18:54,809 - INFO - Pruning info: sparsity=0.895
2025-08-27 23:18:54,809 - INFO -   Reactivation rate: 0.0007
2025-08-27 23:18:54,895 - INFO - Epoch: [46][100/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4851 (0.4193) Acc@1 84.375 (85.628) Acc@5 100.000 (99.428)
2025-08-27 23:18:56,769 - INFO - Epoch: [46][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.3445 (0.4250) Acc@1 86.719 (85.296) Acc@5 100.000 (99.390)
2025-08-27 23:18:57,702 - INFO - Pruning info: sparsity=0.895
2025-08-27 23:18:57,702 - INFO -   Reactivation rate: 0.0007
2025-08-27 23:18:58,559 - INFO - Epoch: [46][300/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.3869 (0.4247) Acc@1 85.156 (85.359) Acc@5 100.000 (99.406)
2025-08-27 23:19:00,417 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6872 (0.6872) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-27 23:19:01,238 - INFO - Epoch 46:
2025-08-27 23:19:01,238 - INFO -   Train: acc1: 85.1100 | acc5: 99.3820 | loss: 0.4307 | sparsity: 0.8951 | reactivation_rate: 0.0006
2025-08-27 23:19:01,238 - INFO -   Val:   acc1: 78.7000 | acc5: 98.2400 | loss: 0.7117
2025-08-27 23:19:01,238 - INFO -   LR: 0.100000
2025-08-27 23:19:01,248 - INFO - 
Epoch: 47, lr = 0.1
2025-08-27 23:19:01,439 - INFO - Epoch: [47][0/391] Time 0.191 (0.191) Data 0.170 (0.170) Loss 0.4496 (0.4496) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 23:19:01,828 - INFO - Pruning info: sparsity=0.901
2025-08-27 23:19:01,828 - INFO -   Reactivation rate: 0.0006
2025-08-27 23:19:03,248 - INFO - Epoch: [47][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.3659 (0.4286) Acc@1 88.281 (85.528) Acc@5 98.438 (99.389)
2025-08-27 23:19:04,784 - INFO - Pruning info: sparsity=0.901
2025-08-27 23:19:04,784 - INFO -   Reactivation rate: 0.0006
2025-08-27 23:19:05,128 - INFO - Epoch: [47][200/391] Time 0.026 (0.019) Data 0.015 (0.003) Loss 0.4971 (0.4294) Acc@1 82.031 (85.238) Acc@5 99.219 (99.382)
2025-08-27 23:19:06,973 - INFO - Epoch: [47][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4674 (0.4323) Acc@1 83.594 (85.141) Acc@5 99.219 (99.385)
2025-08-27 23:19:07,741 - INFO - Pruning info: sparsity=0.901
2025-08-27 23:19:07,741 - INFO -   Reactivation rate: 0.0005
2025-08-27 23:19:08,746 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6325 (0.6325) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 23:19:09,553 - INFO - Epoch 47:
2025-08-27 23:19:09,554 - INFO -   Train: acc1: 85.0660 | acc5: 99.3540 | loss: 0.4365 | sparsity: 0.9006 | reactivation_rate: 0.0005
2025-08-27 23:19:09,554 - INFO -   Val:   acc1: 79.3700 | acc5: 98.8600 | loss: 0.6239
2025-08-27 23:19:09,554 - INFO -   LR: 0.100000
2025-08-27 23:19:09,563 - INFO - 
Epoch: 48, lr = 0.1
2025-08-27 23:19:09,752 - INFO - Epoch: [48][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.4473 (0.4473) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-27 23:19:11,591 - INFO - Epoch: [48][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.4079 (0.4145) Acc@1 85.156 (85.620) Acc@5 97.656 (99.482)
2025-08-27 23:19:11,757 - INFO - Pruning info: sparsity=0.906
2025-08-27 23:19:11,757 - INFO -   Reactivation rate: 0.0005
2025-08-27 23:19:13,402 - INFO - Epoch: [48][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3723 (0.4178) Acc@1 87.500 (85.459) Acc@5 98.438 (99.479)
2025-08-27 23:19:14,754 - INFO - Pruning info: sparsity=0.906
2025-08-27 23:19:14,755 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:19:15,228 - INFO - Epoch: [48][300/391] Time 0.018 (0.019) Data 0.006 (0.003) Loss 0.4441 (0.4273) Acc@1 86.719 (85.247) Acc@5 100.000 (99.452)
2025-08-27 23:19:16,994 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.4329 (0.4329) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:19:17,817 - INFO - Epoch 48:
2025-08-27 23:19:17,817 - INFO -   Train: acc1: 85.0640 | acc5: 99.4260 | loss: 0.4328 | sparsity: 0.9057 | reactivation_rate: 0.0005
2025-08-27 23:19:17,817 - INFO -   Val:   acc1: 81.0700 | acc5: 99.2500 | loss: 0.5688
2025-08-27 23:19:17,818 - INFO -   LR: 0.100000
2025-08-27 23:19:17,827 - INFO - 
Epoch: 49, lr = 0.1
2025-08-27 23:19:18,004 - INFO - Epoch: [49][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.4537 (0.4537) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:19:18,722 - INFO - Pruning info: sparsity=0.910
2025-08-27 23:19:18,722 - INFO -   Reactivation rate: 0.0005
2025-08-27 23:19:19,863 - INFO - Epoch: [49][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4641 (0.4162) Acc@1 85.938 (85.558) Acc@5 99.219 (99.489)
2025-08-27 23:19:21,714 - INFO - Epoch: [49][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.2883 (0.4250) Acc@1 92.188 (85.257) Acc@5 100.000 (99.409)
2025-08-27 23:19:21,720 - INFO - Pruning info: sparsity=0.910
2025-08-27 23:19:21,720 - INFO -   Reactivation rate: 0.0005
2025-08-27 23:19:23,517 - INFO - Epoch: [49][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3643 (0.4345) Acc@1 89.062 (84.962) Acc@5 100.000 (99.374)
2025-08-27 23:19:24,607 - INFO - Pruning info: sparsity=0.910
2025-08-27 23:19:24,607 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:19:25,324 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.4125 (0.4125) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 23:19:26,142 - INFO - Epoch 49:
2025-08-27 23:19:26,142 - INFO -   Train: acc1: 85.0200 | acc5: 99.3620 | loss: 0.4336 | sparsity: 0.9104 | reactivation_rate: 0.0005
2025-08-27 23:19:26,142 - INFO -   Val:   acc1: 82.0400 | acc5: 99.0000 | loss: 0.5635
2025-08-27 23:19:26,142 - INFO -   LR: 0.100000
2025-08-27 23:19:26,154 - INFO - 
Epoch: 50, lr = 0.1
2025-08-27 23:19:26,330 - INFO - Epoch: [50][0/391] Time 0.176 (0.176) Data 0.153 (0.153) Loss 0.2720 (0.2720) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:19:28,205 - INFO - Epoch: [50][100/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.6539 (0.4370) Acc@1 77.344 (85.280) Acc@5 100.000 (99.373)
2025-08-27 23:19:28,748 - INFO - Pruning info: sparsity=0.915
2025-08-27 23:19:28,748 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:19:30,233 - INFO - Epoch: [50][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4197 (0.4405) Acc@1 84.375 (84.884) Acc@5 100.000 (99.390)
2025-08-27 23:19:31,933 - INFO - Pruning info: sparsity=0.915
2025-08-27 23:19:31,933 - INFO -   Reactivation rate: 0.0005
2025-08-27 23:19:32,152 - INFO - Epoch: [50][300/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.3757 (0.4380) Acc@1 86.719 (84.930) Acc@5 100.000 (99.385)
2025-08-27 23:19:33,936 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.5406 (0.5406) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:19:34,793 - INFO - Epoch 50:
2025-08-27 23:19:34,793 - INFO -   Train: acc1: 84.9220 | acc5: 99.3640 | loss: 0.4390 | sparsity: 0.9148 | reactivation_rate: 0.0004
2025-08-27 23:19:34,793 - INFO -   Val:   acc1: 80.0900 | acc5: 99.2700 | loss: 0.5896
2025-08-27 23:19:34,793 - INFO -   LR: 0.100000
2025-08-27 23:19:34,837 - INFO - 
Epoch: 51, lr = 0.1
2025-08-27 23:19:35,025 - INFO - Epoch: [51][0/391] Time 0.187 (0.187) Data 0.163 (0.163) Loss 0.4533 (0.4533) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 23:19:36,119 - INFO - Pruning info: sparsity=0.919
2025-08-27 23:19:36,119 - INFO -   Reactivation rate: 0.0005
2025-08-27 23:19:36,902 - INFO - Epoch: [51][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3921 (0.4289) Acc@1 84.375 (85.048) Acc@5 100.000 (99.389)
2025-08-27 23:19:38,789 - INFO - Epoch: [51][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4699 (0.4285) Acc@1 86.719 (84.946) Acc@5 98.438 (99.425)
2025-08-27 23:19:39,145 - INFO - Pruning info: sparsity=0.919
2025-08-27 23:19:39,145 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:19:40,760 - INFO - Epoch: [51][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4118 (0.4356) Acc@1 85.938 (84.868) Acc@5 100.000 (99.374)
2025-08-27 23:19:42,276 - INFO - Pruning info: sparsity=0.919
2025-08-27 23:19:42,276 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:19:42,602 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7531 (0.7531) Acc@1 71.875 (71.875) Acc@5 100.000 (100.000)
2025-08-27 23:19:43,450 - INFO - Epoch 51:
2025-08-27 23:19:43,450 - INFO -   Train: acc1: 84.9700 | acc5: 99.3760 | loss: 0.4372 | sparsity: 0.9189 | reactivation_rate: 0.0004
2025-08-27 23:19:43,450 - INFO -   Val:   acc1: 77.3600 | acc5: 98.9300 | loss: 0.7242
2025-08-27 23:19:43,450 - INFO -   LR: 0.100000
2025-08-27 23:19:43,463 - INFO - 
Epoch: 52, lr = 0.1
2025-08-27 23:19:43,639 - INFO - Epoch: [52][0/391] Time 0.175 (0.175) Data 0.148 (0.148) Loss 0.4810 (0.4810) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-27 23:19:45,487 - INFO - Epoch: [52][100/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.3970 (0.4275) Acc@1 85.156 (85.551) Acc@5 100.000 (99.373)
2025-08-27 23:19:46,341 - INFO - Pruning info: sparsity=0.923
2025-08-27 23:19:46,341 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:19:47,383 - INFO - Epoch: [52][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.4886 (0.4433) Acc@1 83.594 (84.927) Acc@5 99.219 (99.320)
2025-08-27 23:19:49,153 - INFO - Epoch: [52][300/391] Time 0.023 (0.019) Data 0.009 (0.002) Loss 0.3895 (0.4438) Acc@1 87.500 (84.803) Acc@5 98.438 (99.351)
2025-08-27 23:19:49,270 - INFO - Pruning info: sparsity=0.923
2025-08-27 23:19:49,271 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:19:50,987 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.7268 (0.7268) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 23:19:51,796 - INFO - Epoch 52:
2025-08-27 23:19:51,796 - INFO -   Train: acc1: 84.6100 | acc5: 99.3280 | loss: 0.4474 | sparsity: 0.9226 | reactivation_rate: 0.0004
2025-08-27 23:19:51,796 - INFO -   Val:   acc1: 75.8700 | acc5: 98.4400 | loss: 0.7660
2025-08-27 23:19:51,796 - INFO -   LR: 0.100000
2025-08-27 23:19:51,819 - INFO - 
Epoch: 53, lr = 0.1
2025-08-27 23:19:51,976 - INFO - Epoch: [53][0/391] Time 0.156 (0.156) Data 0.130 (0.130) Loss 0.4259 (0.4259) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 23:19:53,360 - INFO - Pruning info: sparsity=0.926
2025-08-27 23:19:53,360 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:19:53,817 - INFO - Epoch: [53][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.4426 (0.4454) Acc@1 83.594 (84.746) Acc@5 99.219 (99.358)
2025-08-27 23:19:55,648 - INFO - Epoch: [53][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4496 (0.4508) Acc@1 83.594 (84.612) Acc@5 100.000 (99.347)
2025-08-27 23:19:56,306 - INFO - Pruning info: sparsity=0.926
2025-08-27 23:19:56,306 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:19:57,556 - INFO - Epoch: [53][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3875 (0.4495) Acc@1 86.719 (84.559) Acc@5 99.219 (99.364)
2025-08-27 23:19:59,359 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4711 (0.4711) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:20:00,186 - INFO - Epoch 53:
2025-08-27 23:20:00,186 - INFO -   Train: acc1: 84.5180 | acc5: 99.3700 | loss: 0.4506 | sparsity: 0.9260 | reactivation_rate: 0.0003
2025-08-27 23:20:00,186 - INFO -   Val:   acc1: 80.3100 | acc5: 98.9400 | loss: 0.5922
2025-08-27 23:20:00,186 - INFO -   LR: 0.100000
2025-08-27 23:20:00,197 - INFO - 
Epoch: 54, lr = 0.1
2025-08-27 23:20:00,357 - INFO - Epoch: [54][0/391] Time 0.159 (0.159) Data 0.134 (0.134) Loss 0.4080 (0.4080) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:20:00,464 - INFO - Pruning info: sparsity=0.929
2025-08-27 23:20:00,464 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:20:02,256 - INFO - Epoch: [54][100/391] Time 0.018 (0.020) Data 0.000 (0.005) Loss 0.3566 (0.4501) Acc@1 89.062 (84.576) Acc@5 99.219 (99.350)
2025-08-27 23:20:03,417 - INFO - Pruning info: sparsity=0.929
2025-08-27 23:20:03,417 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:20:04,111 - INFO - Epoch: [54][200/391] Time 0.034 (0.019) Data 0.021 (0.004) Loss 0.4674 (0.4473) Acc@1 81.250 (84.682) Acc@5 100.000 (99.339)
2025-08-27 23:20:06,040 - INFO - Epoch: [54][300/391] Time 0.017 (0.019) Data 0.003 (0.004) Loss 0.4461 (0.4437) Acc@1 84.375 (84.816) Acc@5 100.000 (99.367)
2025-08-27 23:20:06,483 - INFO - Pruning info: sparsity=0.929
2025-08-27 23:20:06,483 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:07,820 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.4936 (0.4936) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 23:20:08,661 - INFO - Epoch 54:
2025-08-27 23:20:08,661 - INFO -   Train: acc1: 84.7540 | acc5: 99.3680 | loss: 0.4454 | sparsity: 0.9291 | reactivation_rate: 0.0003
2025-08-27 23:20:08,661 - INFO -   Val:   acc1: 78.6900 | acc5: 98.4600 | loss: 0.6569
2025-08-27 23:20:08,661 - INFO -   LR: 0.100000
2025-08-27 23:20:08,851 - INFO - 
Epoch: 55, lr = 0.1
2025-08-27 23:20:08,987 - INFO - Epoch: [55][0/391] Time 0.136 (0.136) Data 0.110 (0.110) Loss 0.3104 (0.3104) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:20:10,743 - INFO - Pruning info: sparsity=0.932
2025-08-27 23:20:10,743 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:20:10,859 - INFO - Epoch: [55][100/391] Time 0.020 (0.020) Data 0.004 (0.002) Loss 0.5594 (0.4540) Acc@1 79.688 (84.344) Acc@5 100.000 (99.265)
2025-08-27 23:20:12,698 - INFO - Epoch: [55][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.4879 (0.4519) Acc@1 81.250 (84.441) Acc@5 100.000 (99.331)
2025-08-27 23:20:13,728 - INFO - Pruning info: sparsity=0.932
2025-08-27 23:20:13,729 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:20:14,524 - INFO - Epoch: [55][300/391] Time 0.040 (0.019) Data 0.029 (0.002) Loss 0.3957 (0.4499) Acc@1 85.938 (84.513) Acc@5 100.000 (99.343)
2025-08-27 23:20:16,366 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.6853 (0.6853) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 23:20:17,225 - INFO - Epoch 55:
2025-08-27 23:20:17,225 - INFO -   Train: acc1: 84.3780 | acc5: 99.3300 | loss: 0.4538 | sparsity: 0.9320 | reactivation_rate: 0.0003
2025-08-27 23:20:17,226 - INFO -   Val:   acc1: 73.0000 | acc5: 99.0800 | loss: 0.8786
2025-08-27 23:20:17,226 - INFO -   LR: 0.100000
2025-08-27 23:20:17,237 - INFO - 
Epoch: 56, lr = 0.1
2025-08-27 23:20:17,398 - INFO - Epoch: [56][0/391] Time 0.160 (0.160) Data 0.138 (0.138) Loss 0.4047 (0.4047) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 23:20:17,874 - INFO - Pruning info: sparsity=0.935
2025-08-27 23:20:17,875 - INFO -   Reactivation rate: 0.0004
2025-08-27 23:20:19,397 - INFO - Epoch: [56][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.4621 (0.4423) Acc@1 84.375 (84.522) Acc@5 100.000 (99.544)
2025-08-27 23:20:20,952 - INFO - Pruning info: sparsity=0.935
2025-08-27 23:20:20,952 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:21,268 - INFO - Epoch: [56][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.4627 (0.4482) Acc@1 84.375 (84.305) Acc@5 99.219 (99.452)
2025-08-27 23:20:23,137 - INFO - Epoch: [56][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4539 (0.4503) Acc@1 83.594 (84.365) Acc@5 100.000 (99.411)
2025-08-27 23:20:23,952 - INFO - Pruning info: sparsity=0.935
2025-08-27 23:20:23,952 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:20:24,934 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.8159 (0.8159) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 23:20:25,770 - INFO - Epoch 56:
2025-08-27 23:20:25,771 - INFO -   Train: acc1: 84.3880 | acc5: 99.3920 | loss: 0.4518 | sparsity: 0.9346 | reactivation_rate: 0.0003
2025-08-27 23:20:25,771 - INFO -   Val:   acc1: 73.7000 | acc5: 97.6800 | loss: 0.9209
2025-08-27 23:20:25,771 - INFO -   LR: 0.100000
2025-08-27 23:20:25,782 - INFO - 
Epoch: 57, lr = 0.1
2025-08-27 23:20:25,956 - INFO - Epoch: [57][0/391] Time 0.174 (0.174) Data 0.142 (0.142) Loss 0.3213 (0.3213) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:20:27,815 - INFO - Epoch: [57][100/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4111 (0.4577) Acc@1 84.375 (84.081) Acc@5 100.000 (99.304)
2025-08-27 23:20:28,051 - INFO - Pruning info: sparsity=0.937
2025-08-27 23:20:28,052 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:20:29,689 - INFO - Epoch: [57][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.5052 (0.4582) Acc@1 80.469 (84.220) Acc@5 98.438 (99.262)
2025-08-27 23:20:31,073 - INFO - Pruning info: sparsity=0.937
2025-08-27 23:20:31,073 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:31,610 - INFO - Epoch: [57][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.3943 (0.4552) Acc@1 86.719 (84.354) Acc@5 100.000 (99.310)
2025-08-27 23:20:33,358 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.7412 (0.7412) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 23:20:34,213 - INFO - Epoch 57:
2025-08-27 23:20:34,213 - INFO -   Train: acc1: 84.3920 | acc5: 99.3040 | loss: 0.4552 | sparsity: 0.9369 | reactivation_rate: 0.0002
2025-08-27 23:20:34,213 - INFO -   Val:   acc1: 74.1200 | acc5: 98.2500 | loss: 0.8748
2025-08-27 23:20:34,213 - INFO -   LR: 0.100000
2025-08-27 23:20:34,223 - INFO - 
Epoch: 58, lr = 0.1
2025-08-27 23:20:34,384 - INFO - Epoch: [58][0/391] Time 0.160 (0.160) Data 0.133 (0.133) Loss 0.5480 (0.5480) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 23:20:35,139 - INFO - Pruning info: sparsity=0.939
2025-08-27 23:20:35,139 - INFO -   Reactivation rate: 0.0003
2025-08-27 23:20:36,225 - INFO - Epoch: [58][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.3790 (0.4672) Acc@1 90.625 (84.352) Acc@5 99.219 (99.281)
2025-08-27 23:20:38,064 - INFO - Epoch: [58][200/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.4665 (0.4657) Acc@1 82.031 (84.204) Acc@5 99.219 (99.258)
2025-08-27 23:20:38,089 - INFO - Pruning info: sparsity=0.939
2025-08-27 23:20:38,090 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:39,872 - INFO - Epoch: [58][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4319 (0.4635) Acc@1 85.938 (84.180) Acc@5 100.000 (99.291)
2025-08-27 23:20:40,977 - INFO - Pruning info: sparsity=0.939
2025-08-27 23:20:40,977 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:41,683 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5979 (0.5979) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 23:20:42,506 - INFO - Epoch 58:
2025-08-27 23:20:42,506 - INFO -   Train: acc1: 84.3420 | acc5: 99.3400 | loss: 0.4590 | sparsity: 0.9389 | reactivation_rate: 0.0002
2025-08-27 23:20:42,506 - INFO -   Val:   acc1: 79.0900 | acc5: 99.1400 | loss: 0.6152
2025-08-27 23:20:42,506 - INFO -   LR: 0.100000
2025-08-27 23:20:42,518 - INFO - 
Epoch: 59, lr = 0.1
2025-08-27 23:20:42,686 - INFO - Epoch: [59][0/391] Time 0.167 (0.167) Data 0.147 (0.147) Loss 0.4717 (0.4717) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 23:20:44,527 - INFO - Epoch: [59][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4411 (0.4490) Acc@1 84.375 (84.483) Acc@5 100.000 (99.528)
2025-08-27 23:20:45,073 - INFO - Pruning info: sparsity=0.941
2025-08-27 23:20:45,073 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:46,332 - INFO - Epoch: [59][200/391] Time 0.026 (0.019) Data 0.001 (0.002) Loss 0.5173 (0.4552) Acc@1 80.469 (84.196) Acc@5 97.656 (99.425)
2025-08-27 23:20:47,968 - INFO - Pruning info: sparsity=0.941
2025-08-27 23:20:47,968 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:48,142 - INFO - Epoch: [59][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.4552 (0.4572) Acc@1 85.156 (84.217) Acc@5 100.000 (99.395)
2025-08-27 23:20:49,947 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.7143 (0.7143) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-27 23:20:50,780 - INFO - Epoch 59:
2025-08-27 23:20:50,780 - INFO -   Train: acc1: 84.1080 | acc5: 99.3740 | loss: 0.4585 | sparsity: 0.9408 | reactivation_rate: 0.0002
2025-08-27 23:20:50,780 - INFO -   Val:   acc1: 76.7400 | acc5: 97.9200 | loss: 0.7676
2025-08-27 23:20:50,781 - INFO -   LR: 0.100000
2025-08-27 23:20:50,791 - INFO - 
Epoch: 60, lr = 0.1
2025-08-27 23:20:50,978 - INFO - Epoch: [60][0/391] Time 0.186 (0.186) Data 0.163 (0.163) Loss 0.5190 (0.5190) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 23:20:52,093 - INFO - Pruning info: sparsity=0.942
2025-08-27 23:20:52,094 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:52,784 - INFO - Epoch: [60][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4612 (0.4657) Acc@1 82.031 (83.880) Acc@5 99.219 (99.265)
2025-08-27 23:20:54,684 - INFO - Epoch: [60][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.3952 (0.4641) Acc@1 89.062 (83.839) Acc@5 100.000 (99.293)
2025-08-27 23:20:55,034 - INFO - Pruning info: sparsity=0.942
2025-08-27 23:20:55,034 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:20:56,552 - INFO - Epoch: [60][300/391] Time 0.059 (0.019) Data 0.043 (0.004) Loss 0.5107 (0.4670) Acc@1 82.031 (83.708) Acc@5 99.219 (99.276)
2025-08-27 23:20:58,110 - INFO - Pruning info: sparsity=0.942
2025-08-27 23:20:58,111 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:20:58,432 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.6962 (0.6962) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 23:20:59,309 - INFO - Epoch 60:
2025-08-27 23:20:59,309 - INFO -   Train: acc1: 83.8800 | acc5: 99.3220 | loss: 0.4626 | sparsity: 0.9424 | reactivation_rate: 0.0002
2025-08-27 23:20:59,309 - INFO -   Val:   acc1: 77.6200 | acc5: 98.6500 | loss: 0.7296
2025-08-27 23:20:59,309 - INFO -   LR: 0.100000
2025-08-27 23:20:59,357 - INFO - 
Epoch: 61, lr = 0.1
2025-08-27 23:20:59,546 - INFO - Epoch: [61][0/391] Time 0.188 (0.188) Data 0.169 (0.169) Loss 0.4859 (0.4859) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:21:01,448 - INFO - Epoch: [61][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4827 (0.4401) Acc@1 84.375 (84.769) Acc@5 99.219 (99.474)
2025-08-27 23:21:02,410 - INFO - Pruning info: sparsity=0.944
2025-08-27 23:21:02,410 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:03,347 - INFO - Epoch: [61][200/391] Time 0.013 (0.020) Data 0.001 (0.003) Loss 0.4800 (0.4547) Acc@1 82.812 (84.099) Acc@5 100.000 (99.433)
2025-08-27 23:21:05,266 - INFO - Epoch: [61][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.6246 (0.4578) Acc@1 80.469 (84.058) Acc@5 99.219 (99.419)
2025-08-27 23:21:05,420 - INFO - Pruning info: sparsity=0.944
2025-08-27 23:21:05,420 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:07,076 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5246 (0.5246) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 23:21:07,926 - INFO - Epoch 61:
2025-08-27 23:21:07,926 - INFO -   Train: acc1: 83.7640 | acc5: 99.3620 | loss: 0.4666 | sparsity: 0.9438 | reactivation_rate: 0.0002
2025-08-27 23:21:07,926 - INFO -   Val:   acc1: 80.3500 | acc5: 98.8900 | loss: 0.5935
2025-08-27 23:21:07,926 - INFO -   LR: 0.100000
2025-08-27 23:21:07,937 - INFO - 
Epoch: 62, lr = 0.1
2025-08-27 23:21:08,125 - INFO - Epoch: [62][0/391] Time 0.187 (0.187) Data 0.161 (0.161) Loss 0.4073 (0.4073) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 23:21:09,683 - INFO - Pruning info: sparsity=0.945
2025-08-27 23:21:09,684 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:10,169 - INFO - Epoch: [62][100/391] Time 0.027 (0.022) Data 0.001 (0.003) Loss 0.4518 (0.4412) Acc@1 84.375 (84.367) Acc@5 100.000 (99.420)
2025-08-27 23:21:12,104 - INFO - Epoch: [62][200/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.3574 (0.4474) Acc@1 85.156 (84.297) Acc@5 99.219 (99.401)
2025-08-27 23:21:12,847 - INFO - Pruning info: sparsity=0.945
2025-08-27 23:21:12,847 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:14,072 - INFO - Epoch: [62][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4000 (0.4576) Acc@1 83.594 (83.983) Acc@5 100.000 (99.354)
2025-08-27 23:21:16,053 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.4566 (0.4566) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 23:21:16,887 - INFO - Epoch 62:
2025-08-27 23:21:16,887 - INFO -   Train: acc1: 83.8500 | acc5: 99.3520 | loss: 0.4620 | sparsity: 0.9451 | reactivation_rate: 0.0002
2025-08-27 23:21:16,887 - INFO -   Val:   acc1: 80.5800 | acc5: 98.5700 | loss: 0.5873
2025-08-27 23:21:16,887 - INFO -   LR: 0.100000
2025-08-27 23:21:16,898 - INFO - 
Epoch: 63, lr = 0.1
2025-08-27 23:21:17,085 - INFO - Epoch: [63][0/391] Time 0.186 (0.186) Data 0.157 (0.157) Loss 0.4460 (0.4460) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 23:21:17,200 - INFO - Pruning info: sparsity=0.946
2025-08-27 23:21:17,200 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:21:19,004 - INFO - Epoch: [63][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4780 (0.4374) Acc@1 78.906 (85.071) Acc@5 99.219 (99.358)
2025-08-27 23:21:20,298 - INFO - Pruning info: sparsity=0.946
2025-08-27 23:21:20,299 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:20,930 - INFO - Epoch: [63][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4745 (0.4473) Acc@1 80.469 (84.464) Acc@5 99.219 (99.386)
2025-08-27 23:21:22,739 - INFO - Epoch: [63][300/391] Time 0.022 (0.019) Data 0.005 (0.002) Loss 0.3535 (0.4518) Acc@1 88.281 (84.375) Acc@5 100.000 (99.387)
2025-08-27 23:21:23,256 - INFO - Pruning info: sparsity=0.946
2025-08-27 23:21:23,256 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:21:24,574 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7154 (0.7154) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 23:21:25,420 - INFO - Epoch 63:
2025-08-27 23:21:25,420 - INFO -   Train: acc1: 84.2700 | acc5: 99.4040 | loss: 0.4563 | sparsity: 0.9461 | reactivation_rate: 0.0001
2025-08-27 23:21:25,420 - INFO -   Val:   acc1: 74.9600 | acc5: 98.5800 | loss: 0.8091
2025-08-27 23:21:25,420 - INFO -   LR: 0.100000
2025-08-27 23:21:25,431 - INFO - 
Epoch: 64, lr = 0.1
2025-08-27 23:21:25,642 - INFO - Epoch: [64][0/391] Time 0.210 (0.210) Data 0.167 (0.167) Loss 0.3947 (0.3947) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 23:21:27,422 - INFO - Pruning info: sparsity=0.947
2025-08-27 23:21:27,432 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:27,533 - INFO - Epoch: [64][100/391] Time 0.032 (0.021) Data 0.015 (0.003) Loss 0.4631 (0.4592) Acc@1 81.250 (84.398) Acc@5 100.000 (99.366)
2025-08-27 23:21:29,409 - INFO - Epoch: [64][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4482 (0.4692) Acc@1 83.594 (83.827) Acc@5 100.000 (99.339)
2025-08-27 23:21:30,492 - INFO - Pruning info: sparsity=0.947
2025-08-27 23:21:30,493 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:21:31,401 - INFO - Epoch: [64][300/391] Time 0.017 (0.020) Data 0.006 (0.002) Loss 0.5773 (0.4670) Acc@1 80.469 (83.895) Acc@5 98.438 (99.369)
2025-08-27 23:21:33,277 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6811 (0.6811) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-27 23:21:34,196 - INFO - Epoch 64:
2025-08-27 23:21:34,196 - INFO -   Train: acc1: 83.7440 | acc5: 99.3540 | loss: 0.4692 | sparsity: 0.9470 | reactivation_rate: 0.0001
2025-08-27 23:21:34,196 - INFO -   Val:   acc1: 75.9500 | acc5: 98.4600 | loss: 0.7493
2025-08-27 23:21:34,196 - INFO -   LR: 0.100000
2025-08-27 23:21:34,208 - INFO - 
Epoch: 65, lr = 0.1
2025-08-27 23:21:34,363 - INFO - Epoch: [65][0/391] Time 0.155 (0.155) Data 0.135 (0.135) Loss 0.3798 (0.3798) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:21:34,873 - INFO - Pruning info: sparsity=0.948
2025-08-27 23:21:34,874 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:36,331 - INFO - Epoch: [65][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.4910 (0.4783) Acc@1 80.469 (83.424) Acc@5 99.219 (99.273)
2025-08-27 23:21:37,904 - INFO - Pruning info: sparsity=0.948
2025-08-27 23:21:37,905 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:21:38,204 - INFO - Epoch: [65][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4766 (0.4660) Acc@1 83.594 (83.905) Acc@5 100.000 (99.335)
2025-08-27 23:21:40,106 - INFO - Epoch: [65][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5000 (0.4662) Acc@1 83.594 (83.871) Acc@5 99.219 (99.312)
2025-08-27 23:21:40,933 - INFO - Pruning info: sparsity=0.948
2025-08-27 23:21:40,933 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:21:41,914 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.4312 (0.4312) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:21:42,760 - INFO - Epoch 65:
2025-08-27 23:21:42,761 - INFO -   Train: acc1: 83.7860 | acc5: 99.3100 | loss: 0.4702 | sparsity: 0.9477 | reactivation_rate: 0.0001
2025-08-27 23:21:42,761 - INFO -   Val:   acc1: 79.9700 | acc5: 99.2600 | loss: 0.5959
2025-08-27 23:21:42,761 - INFO -   LR: 0.100000
2025-08-27 23:21:42,772 - INFO - 
Epoch: 66, lr = 0.1
2025-08-27 23:21:42,960 - INFO - Epoch: [66][0/391] Time 0.187 (0.187) Data 0.164 (0.164) Loss 0.5056 (0.5056) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 23:21:44,872 - INFO - Epoch: [66][100/391] Time 0.013 (0.021) Data 0.002 (0.003) Loss 0.4084 (0.4549) Acc@1 86.719 (84.213) Acc@5 100.000 (99.435)
2025-08-27 23:21:45,125 - INFO - Pruning info: sparsity=0.948
2025-08-27 23:21:45,125 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:46,803 - INFO - Epoch: [66][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.5948 (0.4621) Acc@1 79.688 (83.986) Acc@5 98.438 (99.312)
2025-08-27 23:21:48,182 - INFO - Pruning info: sparsity=0.948
2025-08-27 23:21:48,182 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:21:48,698 - INFO - Epoch: [66][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4494 (0.4747) Acc@1 85.938 (83.578) Acc@5 98.438 (99.265)
2025-08-27 23:21:50,552 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5573 (0.5573) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 23:21:51,413 - INFO - Epoch 66:
2025-08-27 23:21:51,413 - INFO -   Train: acc1: 83.6460 | acc5: 99.3020 | loss: 0.4722 | sparsity: 0.9484 | reactivation_rate: 0.0001
2025-08-27 23:21:51,413 - INFO -   Val:   acc1: 80.4600 | acc5: 99.1200 | loss: 0.5772
2025-08-27 23:21:51,413 - INFO -   LR: 0.100000
2025-08-27 23:21:51,424 - INFO - 
Epoch: 67, lr = 0.1
2025-08-27 23:21:51,573 - INFO - Epoch: [67][0/391] Time 0.148 (0.148) Data 0.122 (0.122) Loss 0.4484 (0.4484) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:21:52,457 - INFO - Pruning info: sparsity=0.949
2025-08-27 23:21:52,457 - INFO -   Reactivation rate: 0.0002
2025-08-27 23:21:53,536 - INFO - Epoch: [67][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.4343 (0.4585) Acc@1 85.156 (83.950) Acc@5 99.219 (99.296)
2025-08-27 23:21:55,411 - INFO - Epoch: [67][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3939 (0.4700) Acc@1 85.938 (83.648) Acc@5 100.000 (99.308)
2025-08-27 23:21:55,466 - INFO - Pruning info: sparsity=0.949
2025-08-27 23:21:55,466 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:21:57,299 - INFO - Epoch: [67][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4593 (0.4647) Acc@1 85.938 (83.796) Acc@5 97.656 (99.377)
2025-08-27 23:21:58,393 - INFO - Pruning info: sparsity=0.949
2025-08-27 23:21:58,394 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:21:59,067 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.4959 (0.4959) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 23:21:59,929 - INFO - Epoch 67:
2025-08-27 23:21:59,930 - INFO -   Train: acc1: 83.7340 | acc5: 99.3360 | loss: 0.4672 | sparsity: 0.9488 | reactivation_rate: 0.0001
2025-08-27 23:21:59,930 - INFO -   Val:   acc1: 81.6200 | acc5: 99.1700 | loss: 0.5507
2025-08-27 23:21:59,930 - INFO -   LR: 0.100000
2025-08-27 23:21:59,944 - INFO - 
Epoch: 68, lr = 0.1
2025-08-27 23:22:00,125 - INFO - Epoch: [68][0/391] Time 0.179 (0.179) Data 0.161 (0.161) Loss 0.4805 (0.4805) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:22:02,001 - INFO - Epoch: [68][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4575 (0.4732) Acc@1 84.375 (83.632) Acc@5 99.219 (99.389)
2025-08-27 23:22:02,581 - INFO - Pruning info: sparsity=0.949
2025-08-27 23:22:02,581 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:03,791 - INFO - Epoch: [68][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.5556 (0.4707) Acc@1 84.375 (83.897) Acc@5 100.000 (99.347)
2025-08-27 23:22:05,492 - INFO - Pruning info: sparsity=0.949
2025-08-27 23:22:05,492 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:05,669 - INFO - Epoch: [68][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.5374 (0.4687) Acc@1 82.031 (83.978) Acc@5 98.438 (99.364)
2025-08-27 23:22:07,442 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6015 (0.6015) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 23:22:08,278 - INFO - Epoch 68:
2025-08-27 23:22:08,279 - INFO -   Train: acc1: 84.0200 | acc5: 99.3540 | loss: 0.4670 | sparsity: 0.9492 | reactivation_rate: 0.0001
2025-08-27 23:22:08,279 - INFO -   Val:   acc1: 78.1400 | acc5: 98.5100 | loss: 0.6639
2025-08-27 23:22:08,279 - INFO -   LR: 0.100000
2025-08-27 23:22:08,291 - INFO - 
Epoch: 69, lr = 0.1
2025-08-27 23:22:08,445 - INFO - Epoch: [69][0/391] Time 0.153 (0.153) Data 0.124 (0.124) Loss 0.5021 (0.5021) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 23:22:09,542 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:09,542 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:10,308 - INFO - Epoch: [69][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4149 (0.4682) Acc@1 85.938 (83.818) Acc@5 100.000 (99.242)
2025-08-27 23:22:12,248 - INFO - Epoch: [69][200/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4782 (0.4628) Acc@1 83.594 (84.111) Acc@5 99.219 (99.230)
2025-08-27 23:22:12,684 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:12,685 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:14,125 - INFO - Epoch: [69][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4537 (0.4677) Acc@1 85.938 (83.856) Acc@5 99.219 (99.268)
2025-08-27 23:22:15,635 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:15,635 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:15,941 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.8071 (0.8071) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 23:22:16,742 - INFO - Epoch 69:
2025-08-27 23:22:16,743 - INFO -   Train: acc1: 83.6960 | acc5: 99.2800 | loss: 0.4720 | sparsity: 0.9495 | reactivation_rate: 0.0001
2025-08-27 23:22:16,743 - INFO -   Val:   acc1: 72.8500 | acc5: 98.6700 | loss: 0.9008
2025-08-27 23:22:16,743 - INFO -   LR: 0.100000
2025-08-27 23:22:16,756 - INFO - 
Epoch: 70, lr = 0.1
2025-08-27 23:22:16,928 - INFO - Epoch: [70][0/391] Time 0.171 (0.171) Data 0.155 (0.155) Loss 0.5327 (0.5327) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 23:22:18,787 - INFO - Epoch: [70][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.4333 (0.4684) Acc@1 85.156 (83.764) Acc@5 100.000 (99.327)
2025-08-27 23:22:19,678 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:19,678 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:20,612 - INFO - Epoch: [70][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4409 (0.4743) Acc@1 85.156 (83.617) Acc@5 100.000 (99.265)
2025-08-27 23:22:22,534 - INFO - Epoch: [70][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2678 (0.4739) Acc@1 89.062 (83.542) Acc@5 99.219 (99.289)
2025-08-27 23:22:22,693 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:22,693 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:24,276 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.5743 (0.5743) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 23:22:25,105 - INFO - Epoch 70:
2025-08-27 23:22:25,105 - INFO -   Train: acc1: 83.7140 | acc5: 99.2940 | loss: 0.4701 | sparsity: 0.9497 | reactivation_rate: 0.0001
2025-08-27 23:22:25,105 - INFO -   Val:   acc1: 77.4400 | acc5: 98.6600 | loss: 0.6751
2025-08-27 23:22:25,106 - INFO -   LR: 0.100000
2025-08-27 23:22:25,166 - INFO - 
Epoch: 71, lr = 0.1
2025-08-27 23:22:25,354 - INFO - Epoch: [71][0/391] Time 0.187 (0.187) Data 0.160 (0.160) Loss 0.2942 (0.2942) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:22:26,807 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:26,807 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:27,213 - INFO - Epoch: [71][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4432 (0.4529) Acc@1 81.250 (84.344) Acc@5 99.219 (99.381)
2025-08-27 23:22:29,079 - INFO - Epoch: [71][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.5245 (0.4600) Acc@1 82.031 (84.037) Acc@5 98.438 (99.370)
2025-08-27 23:22:29,781 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:29,782 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:30,901 - INFO - Epoch: [71][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4464 (0.4635) Acc@1 85.156 (83.983) Acc@5 98.438 (99.333)
2025-08-27 23:22:32,650 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5397 (0.5397) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 23:22:33,492 - INFO - Epoch 71:
2025-08-27 23:22:33,493 - INFO -   Train: acc1: 83.8140 | acc5: 99.3120 | loss: 0.4677 | sparsity: 0.9499 | reactivation_rate: 0.0001
2025-08-27 23:22:33,493 - INFO -   Val:   acc1: 79.5200 | acc5: 98.7700 | loss: 0.6149
2025-08-27 23:22:33,493 - INFO -   LR: 0.100000
2025-08-27 23:22:33,507 - INFO - 
Epoch: 72, lr = 0.1
2025-08-27 23:22:33,670 - INFO - Epoch: [72][0/391] Time 0.163 (0.163) Data 0.135 (0.135) Loss 0.5425 (0.5425) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 23:22:33,826 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:33,826 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:35,563 - INFO - Epoch: [72][100/391] Time 0.036 (0.020) Data 0.021 (0.006) Loss 0.3395 (0.4633) Acc@1 87.500 (83.981) Acc@5 100.000 (99.389)
2025-08-27 23:22:36,802 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:36,802 - INFO -   Reactivation rate: 0.0001
2025-08-27 23:22:37,379 - INFO - Epoch: [72][200/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.5998 (0.4778) Acc@1 78.125 (83.524) Acc@5 99.219 (99.324)
2025-08-27 23:22:39,307 - INFO - Epoch: [72][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5559 (0.4745) Acc@1 78.125 (83.687) Acc@5 99.219 (99.362)
2025-08-27 23:22:39,794 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:39,794 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:41,177 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5708 (0.5708) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 23:22:42,025 - INFO - Epoch 72:
2025-08-27 23:22:42,025 - INFO -   Train: acc1: 83.5980 | acc5: 99.3500 | loss: 0.4745 | sparsity: 0.9499 | reactivation_rate: 0.0000
2025-08-27 23:22:42,025 - INFO -   Val:   acc1: 80.6700 | acc5: 99.0200 | loss: 0.5998
2025-08-27 23:22:42,025 - INFO -   LR: 0.100000
2025-08-27 23:22:42,295 - INFO - 
Epoch: 73, lr = 0.1
2025-08-27 23:22:42,460 - INFO - Epoch: [73][0/391] Time 0.165 (0.165) Data 0.132 (0.132) Loss 0.3675 (0.3675) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-27 23:22:44,186 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:44,186 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:44,245 - INFO - Epoch: [73][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3664 (0.4405) Acc@1 86.719 (84.932) Acc@5 100.000 (99.482)
2025-08-27 23:22:46,162 - INFO - Epoch: [73][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.5500 (0.4539) Acc@1 80.469 (84.344) Acc@5 100.000 (99.370)
2025-08-27 23:22:47,313 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:47,313 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:48,171 - INFO - Epoch: [73][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3635 (0.4573) Acc@1 85.156 (84.144) Acc@5 100.000 (99.380)
2025-08-27 23:22:49,977 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.6970 (0.6970) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-27 23:22:50,835 - INFO - Epoch 73:
2025-08-27 23:22:50,835 - INFO -   Train: acc1: 84.0300 | acc5: 99.3560 | loss: 0.4633 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:22:50,835 - INFO -   Val:   acc1: 75.0800 | acc5: 98.0700 | loss: 0.7636
2025-08-27 23:22:50,835 - INFO -   LR: 0.100000
2025-08-27 23:22:50,848 - INFO - 
Epoch: 74, lr = 0.1
2025-08-27 23:22:51,035 - INFO - Epoch: [74][0/391] Time 0.186 (0.186) Data 0.164 (0.164) Loss 0.4834 (0.4834) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:22:51,512 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:51,512 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:52,945 - INFO - Epoch: [74][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.4595 (0.4751) Acc@1 82.031 (83.632) Acc@5 100.000 (99.304)
2025-08-27 23:22:54,566 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:54,566 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:54,867 - INFO - Epoch: [74][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4907 (0.4721) Acc@1 84.375 (83.668) Acc@5 100.000 (99.324)
2025-08-27 23:22:56,717 - INFO - Epoch: [74][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4431 (0.4721) Acc@1 89.062 (83.653) Acc@5 99.219 (99.359)
2025-08-27 23:22:57,568 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:22:57,568 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:22:58,544 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.7661 (0.7661) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 23:22:59,384 - INFO - Epoch 74:
2025-08-27 23:22:59,384 - INFO -   Train: acc1: 83.6560 | acc5: 99.3540 | loss: 0.4729 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:22:59,384 - INFO -   Val:   acc1: 76.6100 | acc5: 98.3100 | loss: 0.7473
2025-08-27 23:22:59,384 - INFO -   LR: 0.100000
2025-08-27 23:22:59,396 - INFO - 
Epoch: 75, lr = 0.1
2025-08-27 23:22:59,568 - INFO - Epoch: [75][0/391] Time 0.171 (0.171) Data 0.148 (0.148) Loss 0.3331 (0.3331) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:23:01,554 - INFO - Epoch: [75][100/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.6141 (0.4727) Acc@1 78.125 (83.764) Acc@5 97.656 (99.327)
2025-08-27 23:23:01,849 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:01,849 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:03,473 - INFO - Epoch: [75][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3218 (0.4645) Acc@1 91.406 (84.041) Acc@5 100.000 (99.343)
2025-08-27 23:23:04,829 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:04,829 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:05,266 - INFO - Epoch: [75][300/391] Time 0.021 (0.019) Data 0.009 (0.002) Loss 0.5609 (0.4669) Acc@1 80.469 (83.952) Acc@5 96.875 (99.325)
2025-08-27 23:23:07,063 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5973 (0.5973) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 23:23:07,925 - INFO - Epoch 75:
2025-08-27 23:23:07,925 - INFO -   Train: acc1: 83.9320 | acc5: 99.3380 | loss: 0.4682 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:07,925 - INFO -   Val:   acc1: 74.7600 | acc5: 98.6800 | loss: 0.7546
2025-08-27 23:23:07,925 - INFO -   LR: 0.100000
2025-08-27 23:23:07,938 - INFO - 
Epoch: 76, lr = 0.1
2025-08-27 23:23:08,121 - INFO - Epoch: [76][0/391] Time 0.183 (0.183) Data 0.153 (0.153) Loss 0.4433 (0.4433) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:23:08,958 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:08,958 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:10,057 - INFO - Epoch: [76][100/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.4548 (0.4650) Acc@1 87.500 (83.926) Acc@5 100.000 (99.242)
2025-08-27 23:23:12,022 - INFO - Epoch: [76][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4921 (0.4657) Acc@1 85.156 (83.749) Acc@5 98.438 (99.296)
2025-08-27 23:23:12,076 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:12,077 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:13,889 - INFO - Epoch: [76][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4520 (0.4694) Acc@1 85.156 (83.734) Acc@5 99.219 (99.317)
2025-08-27 23:23:15,011 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:15,015 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:15,642 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.6642 (0.6642) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 23:23:16,497 - INFO - Epoch 76:
2025-08-27 23:23:16,497 - INFO -   Train: acc1: 83.8320 | acc5: 99.3180 | loss: 0.4680 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:16,497 - INFO -   Val:   acc1: 78.0200 | acc5: 98.1400 | loss: 0.6938
2025-08-27 23:23:16,497 - INFO -   LR: 0.100000
2025-08-27 23:23:16,512 - INFO - 
Epoch: 77, lr = 0.1
2025-08-27 23:23:16,691 - INFO - Epoch: [77][0/391] Time 0.179 (0.179) Data 0.155 (0.155) Loss 0.4917 (0.4917) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 23:23:18,627 - INFO - Epoch: [77][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4628 (0.4707) Acc@1 83.594 (83.772) Acc@5 100.000 (99.327)
2025-08-27 23:23:19,232 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:19,232 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:20,511 - INFO - Epoch: [77][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4436 (0.4731) Acc@1 84.375 (83.644) Acc@5 99.219 (99.328)
2025-08-27 23:23:22,227 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:22,227 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:22,359 - INFO - Epoch: [77][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.3931 (0.4666) Acc@1 85.156 (83.817) Acc@5 100.000 (99.338)
2025-08-27 23:23:24,217 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5884 (0.5884) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 23:23:25,061 - INFO - Epoch 77:
2025-08-27 23:23:25,061 - INFO -   Train: acc1: 83.6740 | acc5: 99.3140 | loss: 0.4715 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:25,061 - INFO -   Val:   acc1: 78.9800 | acc5: 98.8700 | loss: 0.6512
2025-08-27 23:23:25,061 - INFO -   LR: 0.100000
2025-08-27 23:23:25,074 - INFO - 
Epoch: 78, lr = 0.1
2025-08-27 23:23:25,228 - INFO - Epoch: [78][0/391] Time 0.153 (0.153) Data 0.136 (0.136) Loss 0.5355 (0.5355) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 23:23:26,457 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:26,458 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:27,232 - INFO - Epoch: [78][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.4164 (0.4550) Acc@1 82.031 (84.066) Acc@5 99.219 (99.373)
2025-08-27 23:23:29,104 - INFO - Epoch: [78][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5817 (0.4647) Acc@1 80.469 (83.753) Acc@5 98.438 (99.370)
2025-08-27 23:23:29,544 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:29,545 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:31,086 - INFO - Epoch: [78][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.5473 (0.4693) Acc@1 82.031 (83.700) Acc@5 100.000 (99.341)
2025-08-27 23:23:32,613 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:32,614 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:32,906 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.4905 (0.4905) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 23:23:33,728 - INFO - Epoch 78:
2025-08-27 23:23:33,728 - INFO -   Train: acc1: 83.7260 | acc5: 99.3360 | loss: 0.4694 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:33,728 - INFO -   Val:   acc1: 79.4400 | acc5: 98.8000 | loss: 0.6039
2025-08-27 23:23:33,729 - INFO -   LR: 0.100000
2025-08-27 23:23:33,741 - INFO - 
Epoch: 79, lr = 0.1
2025-08-27 23:23:33,919 - INFO - Epoch: [79][0/391] Time 0.177 (0.177) Data 0.151 (0.151) Loss 0.5275 (0.5275) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 23:23:35,895 - INFO - Epoch: [79][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.5851 (0.4690) Acc@1 78.906 (83.942) Acc@5 96.094 (99.327)
2025-08-27 23:23:36,868 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:36,868 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:37,822 - INFO - Epoch: [79][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.4275 (0.4664) Acc@1 84.375 (83.924) Acc@5 100.000 (99.320)
2025-08-27 23:23:39,747 - INFO - Epoch: [79][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.5407 (0.4672) Acc@1 83.594 (83.965) Acc@5 98.438 (99.351)
2025-08-27 23:23:39,949 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:39,949 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:41,589 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5807 (0.5807) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 23:23:42,452 - INFO - Epoch 79:
2025-08-27 23:23:42,452 - INFO -   Train: acc1: 83.8020 | acc5: 99.3460 | loss: 0.4712 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:42,452 - INFO -   Val:   acc1: 77.8900 | acc5: 98.8100 | loss: 0.6778
2025-08-27 23:23:42,452 - INFO -   LR: 0.100000
2025-08-27 23:23:42,477 - INFO - 
Epoch: 80, lr = 0.1
2025-08-27 23:23:42,674 - INFO - Epoch: [80][0/391] Time 0.196 (0.196) Data 0.155 (0.155) Loss 0.3985 (0.3985) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:23:44,248 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:44,248 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:44,655 - INFO - Epoch: [80][100/391] Time 0.021 (0.022) Data 0.000 (0.002) Loss 0.5535 (0.4652) Acc@1 82.031 (84.135) Acc@5 99.219 (99.250)
2025-08-27 23:23:46,534 - INFO - Epoch: [80][200/391] Time 0.012 (0.020) Data 0.001 (0.002) Loss 0.4414 (0.4695) Acc@1 85.156 (83.979) Acc@5 99.219 (99.262)
2025-08-27 23:23:47,301 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:47,301 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:48,555 - INFO - Epoch: [80][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4626 (0.4710) Acc@1 85.156 (83.905) Acc@5 100.000 (99.299)
2025-08-27 23:23:50,375 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5443 (0.5443) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 23:23:51,220 - INFO - Epoch 80:
2025-08-27 23:23:51,220 - INFO -   Train: acc1: 83.8080 | acc5: 99.3020 | loss: 0.4735 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:51,220 - INFO -   Val:   acc1: 79.7400 | acc5: 98.7400 | loss: 0.6061
2025-08-27 23:23:51,220 - INFO -   LR: 0.100000
2025-08-27 23:23:51,267 - INFO - 
Epoch: 81, lr = 0.1
2025-08-27 23:23:51,456 - INFO - Epoch: [81][0/391] Time 0.188 (0.188) Data 0.165 (0.165) Loss 0.5974 (0.5974) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 23:23:51,612 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:51,612 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:53,317 - INFO - Epoch: [81][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4557 (0.4561) Acc@1 83.594 (84.406) Acc@5 99.219 (99.234)
2025-08-27 23:23:54,686 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:54,686 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:55,309 - INFO - Epoch: [81][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4043 (0.4641) Acc@1 85.156 (84.185) Acc@5 100.000 (99.273)
2025-08-27 23:23:57,212 - INFO - Epoch: [81][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.5710 (0.4666) Acc@1 82.812 (84.053) Acc@5 99.219 (99.286)
2025-08-27 23:23:57,768 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:23:57,768 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:23:59,109 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.8330 (0.8330) Acc@1 75.000 (75.000) Acc@5 96.875 (96.875)
2025-08-27 23:23:59,950 - INFO - Epoch 81:
2025-08-27 23:23:59,950 - INFO -   Train: acc1: 83.8540 | acc5: 99.2800 | loss: 0.4687 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:23:59,950 - INFO -   Val:   acc1: 73.4100 | acc5: 97.3900 | loss: 0.8874
2025-08-27 23:23:59,950 - INFO -   LR: 0.100000
2025-08-27 23:23:59,962 - INFO - 
Epoch: 82, lr = 0.1
2025-08-27 23:24:00,160 - INFO - Epoch: [82][0/391] Time 0.196 (0.196) Data 0.169 (0.169) Loss 0.5959 (0.5959) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 23:24:02,081 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:02,082 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:02,137 - INFO - Epoch: [82][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 0.5035 (0.4687) Acc@1 83.594 (83.880) Acc@5 96.875 (99.304)
2025-08-27 23:24:03,960 - INFO - Epoch: [82][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.3058 (0.4724) Acc@1 91.406 (83.788) Acc@5 100.000 (99.258)
2025-08-27 23:24:05,072 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:05,073 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:05,896 - INFO - Epoch: [82][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4392 (0.4720) Acc@1 87.500 (83.877) Acc@5 100.000 (99.263)
2025-08-27 23:24:07,721 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6132 (0.6132) Acc@1 75.781 (75.781) Acc@5 100.000 (100.000)
2025-08-27 23:24:08,565 - INFO - Epoch 82:
2025-08-27 23:24:08,565 - INFO -   Train: acc1: 83.7460 | acc5: 99.2920 | loss: 0.4724 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:08,565 - INFO -   Val:   acc1: 79.1400 | acc5: 98.9300 | loss: 0.6123
2025-08-27 23:24:08,565 - INFO -   LR: 0.100000
2025-08-27 23:24:08,579 - INFO - 
Epoch: 83, lr = 0.1
2025-08-27 23:24:08,750 - INFO - Epoch: [83][0/391] Time 0.170 (0.170) Data 0.151 (0.151) Loss 0.5078 (0.5078) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 23:24:09,266 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:09,266 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:10,777 - INFO - Epoch: [83][100/391] Time 0.011 (0.022) Data 0.000 (0.004) Loss 0.4657 (0.4566) Acc@1 83.594 (84.460) Acc@5 99.219 (99.397)
2025-08-27 23:24:12,469 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:12,469 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:12,735 - INFO - Epoch: [83][200/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4053 (0.4629) Acc@1 85.938 (84.107) Acc@5 99.219 (99.398)
2025-08-27 23:24:14,612 - INFO - Epoch: [83][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.5824 (0.4683) Acc@1 78.906 (83.851) Acc@5 99.219 (99.369)
2025-08-27 23:24:15,509 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:15,510 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:16,441 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.9293 (0.9293) Acc@1 68.750 (68.750) Acc@5 96.875 (96.875)
2025-08-27 23:24:17,262 - INFO - Epoch 83:
2025-08-27 23:24:17,262 - INFO -   Train: acc1: 83.9320 | acc5: 99.3460 | loss: 0.4686 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:17,262 - INFO -   Val:   acc1: 66.6600 | acc5: 97.6300 | loss: 1.0622
2025-08-27 23:24:17,262 - INFO -   LR: 0.100000
2025-08-27 23:24:17,274 - INFO - 
Epoch: 84, lr = 0.1
2025-08-27 23:24:17,438 - INFO - Epoch: [84][0/391] Time 0.163 (0.163) Data 0.143 (0.143) Loss 0.5240 (0.5240) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 23:24:19,477 - INFO - Epoch: [84][100/391] Time 0.031 (0.022) Data 0.015 (0.006) Loss 0.4993 (0.4773) Acc@1 84.375 (83.501) Acc@5 97.656 (99.304)
2025-08-27 23:24:19,781 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:19,781 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:21,403 - INFO - Epoch: [84][200/391] Time 0.028 (0.021) Data 0.013 (0.005) Loss 0.4936 (0.4687) Acc@1 82.812 (83.866) Acc@5 99.219 (99.308)
2025-08-27 23:24:22,848 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:22,848 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:23,279 - INFO - Epoch: [84][300/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.4618 (0.4698) Acc@1 83.594 (83.871) Acc@5 99.219 (99.289)
2025-08-27 23:24:25,070 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.9520 (0.9520) Acc@1 72.656 (72.656) Acc@5 97.656 (97.656)
2025-08-27 23:24:25,941 - INFO - Epoch 84:
2025-08-27 23:24:25,941 - INFO -   Train: acc1: 83.6400 | acc5: 99.2620 | loss: 0.4746 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:25,941 - INFO -   Val:   acc1: 70.4800 | acc5: 98.3700 | loss: 0.9256
2025-08-27 23:24:25,941 - INFO -   LR: 0.100000
2025-08-27 23:24:25,954 - INFO - 
Epoch: 85, lr = 0.1
2025-08-27 23:24:26,127 - INFO - Epoch: [85][0/391] Time 0.173 (0.173) Data 0.149 (0.149) Loss 0.6734 (0.6734) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 23:24:27,159 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:27,159 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:28,183 - INFO - Epoch: [85][100/391] Time 0.020 (0.022) Data 0.000 (0.006) Loss 0.5253 (0.4636) Acc@1 82.812 (83.710) Acc@5 98.438 (99.312)
2025-08-27 23:24:30,008 - INFO - Epoch: [85][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3684 (0.4674) Acc@1 88.281 (83.784) Acc@5 100.000 (99.320)
2025-08-27 23:24:30,089 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:30,090 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:31,826 - INFO - Epoch: [85][300/391] Time 0.018 (0.019) Data 0.007 (0.003) Loss 0.5062 (0.4629) Acc@1 82.812 (84.082) Acc@5 99.219 (99.320)
2025-08-27 23:24:33,014 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:33,014 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:33,618 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5899 (0.5899) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 23:24:34,478 - INFO - Epoch 85:
2025-08-27 23:24:34,478 - INFO -   Train: acc1: 83.8860 | acc5: 99.3300 | loss: 0.4686 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:34,479 - INFO -   Val:   acc1: 77.9900 | acc5: 98.8900 | loss: 0.6546
2025-08-27 23:24:34,479 - INFO -   LR: 0.100000
2025-08-27 23:24:34,493 - INFO - 
Epoch: 86, lr = 0.1
2025-08-27 23:24:34,792 - INFO - Epoch: [86][0/391] Time 0.298 (0.298) Data 0.276 (0.276) Loss 0.3617 (0.3617) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:24:36,762 - INFO - Epoch: [86][100/391] Time 0.015 (0.022) Data 0.000 (0.003) Loss 0.4135 (0.4636) Acc@1 83.594 (83.702) Acc@5 100.000 (99.273)
2025-08-27 23:24:37,353 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:37,354 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:38,643 - INFO - Epoch: [86][200/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.4708 (0.4712) Acc@1 82.812 (83.462) Acc@5 99.219 (99.285)
2025-08-27 23:24:40,293 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:40,293 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:40,427 - INFO - Epoch: [86][300/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.5657 (0.4705) Acc@1 79.688 (83.508) Acc@5 97.656 (99.278)
2025-08-27 23:24:42,240 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.4791 (0.4791) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 23:24:43,070 - INFO - Epoch 86:
2025-08-27 23:24:43,071 - INFO -   Train: acc1: 83.6480 | acc5: 99.3020 | loss: 0.4677 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:43,071 - INFO -   Val:   acc1: 80.5600 | acc5: 99.3600 | loss: 0.5703
2025-08-27 23:24:43,071 - INFO -   LR: 0.100000
2025-08-27 23:24:43,082 - INFO - 
Epoch: 87, lr = 0.1
2025-08-27 23:24:43,271 - INFO - Epoch: [87][0/391] Time 0.188 (0.188) Data 0.150 (0.150) Loss 0.4675 (0.4675) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 23:24:44,453 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:44,453 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:45,103 - INFO - Epoch: [87][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3494 (0.4650) Acc@1 86.719 (84.042) Acc@5 100.000 (99.257)
2025-08-27 23:24:46,997 - INFO - Epoch: [87][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3880 (0.4730) Acc@1 85.156 (83.605) Acc@5 99.219 (99.289)
2025-08-27 23:24:47,400 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:47,400 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:48,845 - INFO - Epoch: [87][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5987 (0.4712) Acc@1 76.562 (83.775) Acc@5 98.438 (99.276)
2025-08-27 23:24:50,367 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:50,367 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:50,650 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6072 (0.6072) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 23:24:51,486 - INFO - Epoch 87:
2025-08-27 23:24:51,486 - INFO -   Train: acc1: 83.7060 | acc5: 99.2980 | loss: 0.4708 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:51,486 - INFO -   Val:   acc1: 78.2100 | acc5: 98.4100 | loss: 0.6736
2025-08-27 23:24:51,486 - INFO -   LR: 0.100000
2025-08-27 23:24:51,499 - INFO - 
Epoch: 88, lr = 0.1
2025-08-27 23:24:51,674 - INFO - Epoch: [88][0/391] Time 0.174 (0.174) Data 0.140 (0.140) Loss 0.4324 (0.4324) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 23:24:53,470 - INFO - Epoch: [88][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4801 (0.4682) Acc@1 82.812 (84.042) Acc@5 100.000 (99.312)
2025-08-27 23:24:54,477 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:54,478 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:55,347 - INFO - Epoch: [88][200/391] Time 0.031 (0.019) Data 0.000 (0.003) Loss 0.4759 (0.4643) Acc@1 84.375 (84.227) Acc@5 100.000 (99.355)
2025-08-27 23:24:57,188 - INFO - Epoch: [88][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4601 (0.4623) Acc@1 84.375 (84.235) Acc@5 99.219 (99.349)
2025-08-27 23:24:57,411 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:24:57,412 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:24:59,074 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.5887 (0.5887) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:24:59,874 - INFO - Epoch 88:
2025-08-27 23:24:59,874 - INFO -   Train: acc1: 84.1200 | acc5: 99.3420 | loss: 0.4642 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:24:59,874 - INFO -   Val:   acc1: 77.8500 | acc5: 98.4400 | loss: 0.6872
2025-08-27 23:24:59,874 - INFO -   LR: 0.100000
2025-08-27 23:24:59,888 - INFO - 
Epoch: 89, lr = 0.1
2025-08-27 23:25:00,059 - INFO - Epoch: [89][0/391] Time 0.171 (0.171) Data 0.148 (0.148) Loss 0.4187 (0.4187) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 23:25:01,477 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:01,477 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:01,882 - INFO - Epoch: [89][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.5994 (0.4577) Acc@1 81.250 (84.120) Acc@5 98.438 (99.288)
2025-08-27 23:25:03,749 - INFO - Epoch: [89][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4159 (0.4667) Acc@1 84.375 (83.800) Acc@5 100.000 (99.304)
2025-08-27 23:25:04,492 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:04,493 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:05,613 - INFO - Epoch: [89][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.6290 (0.4695) Acc@1 78.906 (83.783) Acc@5 99.219 (99.333)
2025-08-27 23:25:07,519 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6706 (0.6706) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-27 23:25:08,374 - INFO - Epoch 89:
2025-08-27 23:25:08,374 - INFO -   Train: acc1: 83.7780 | acc5: 99.3380 | loss: 0.4699 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:08,374 - INFO -   Val:   acc1: 77.0900 | acc5: 98.3900 | loss: 0.7315
2025-08-27 23:25:08,374 - INFO -   LR: 0.100000
2025-08-27 23:25:08,391 - INFO - 
Epoch: 90, lr = 0.1
2025-08-27 23:25:08,564 - INFO - Epoch: [90][0/391] Time 0.173 (0.173) Data 0.156 (0.156) Loss 0.5130 (0.5130) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 23:25:08,732 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:08,732 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:10,471 - INFO - Epoch: [90][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.6271 (0.4721) Acc@1 82.031 (83.795) Acc@5 98.438 (99.373)
2025-08-27 23:25:11,832 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:11,832 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:12,406 - INFO - Epoch: [90][200/391] Time 0.039 (0.020) Data 0.023 (0.002) Loss 0.5144 (0.4742) Acc@1 84.375 (83.695) Acc@5 98.438 (99.331)
2025-08-27 23:25:14,345 - INFO - Epoch: [90][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.6281 (0.4694) Acc@1 81.250 (83.838) Acc@5 98.438 (99.354)
2025-08-27 23:25:14,936 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:14,936 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:16,235 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5166 (0.5166) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 23:25:17,072 - INFO - Epoch 90:
2025-08-27 23:25:17,072 - INFO -   Train: acc1: 83.7160 | acc5: 99.3380 | loss: 0.4715 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:17,072 - INFO -   Val:   acc1: 77.9100 | acc5: 98.0900 | loss: 0.6883
2025-08-27 23:25:17,072 - INFO -   LR: 0.100000
2025-08-27 23:25:17,121 - INFO - 
Epoch: 91, lr = 0.1
2025-08-27 23:25:17,281 - INFO - Epoch: [91][0/391] Time 0.159 (0.159) Data 0.129 (0.129) Loss 0.5191 (0.5191) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-27 23:25:19,225 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:19,225 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:19,254 - INFO - Epoch: [91][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.4483 (0.4374) Acc@1 85.156 (84.646) Acc@5 97.656 (99.489)
2025-08-27 23:25:21,170 - INFO - Epoch: [91][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4964 (0.4569) Acc@1 85.156 (84.321) Acc@5 98.438 (99.405)
2025-08-27 23:25:22,215 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:22,215 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:22,981 - INFO - Epoch: [91][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.4481 (0.4586) Acc@1 84.375 (84.271) Acc@5 98.438 (99.341)
2025-08-27 23:25:24,722 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6332 (0.6332) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 23:25:25,538 - INFO - Epoch 91:
2025-08-27 23:25:25,539 - INFO -   Train: acc1: 83.9000 | acc5: 99.3500 | loss: 0.4686 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:25,539 - INFO -   Val:   acc1: 78.0800 | acc5: 98.7700 | loss: 0.6912
2025-08-27 23:25:25,539 - INFO -   LR: 0.100000
2025-08-27 23:25:25,551 - INFO - 
Epoch: 92, lr = 0.1
2025-08-27 23:25:25,727 - INFO - Epoch: [92][0/391] Time 0.176 (0.176) Data 0.152 (0.152) Loss 0.4637 (0.4637) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:25:26,171 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:26,171 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:27,552 - INFO - Epoch: [92][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.4647 (0.4625) Acc@1 79.688 (84.205) Acc@5 100.000 (99.257)
2025-08-27 23:25:29,216 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:29,216 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:29,460 - INFO - Epoch: [92][200/391] Time 0.036 (0.019) Data 0.023 (0.004) Loss 0.4016 (0.4636) Acc@1 85.938 (84.091) Acc@5 100.000 (99.331)
2025-08-27 23:25:31,347 - INFO - Epoch: [92][300/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.3546 (0.4678) Acc@1 85.938 (83.835) Acc@5 100.000 (99.333)
2025-08-27 23:25:32,249 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:32,249 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:33,147 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.8589 (0.8589) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-27 23:25:33,962 - INFO - Epoch 92:
2025-08-27 23:25:33,962 - INFO -   Train: acc1: 83.7560 | acc5: 99.2980 | loss: 0.4705 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:33,962 - INFO -   Val:   acc1: 73.6400 | acc5: 98.5800 | loss: 0.8809
2025-08-27 23:25:33,962 - INFO -   LR: 0.100000
2025-08-27 23:25:33,974 - INFO - 
Epoch: 93, lr = 0.1
2025-08-27 23:25:34,164 - INFO - Epoch: [93][0/391] Time 0.189 (0.189) Data 0.163 (0.163) Loss 0.4359 (0.4359) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 23:25:36,006 - INFO - Epoch: [93][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.3694 (0.4767) Acc@1 88.281 (83.571) Acc@5 100.000 (99.358)
2025-08-27 23:25:36,297 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:36,297 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:37,810 - INFO - Epoch: [93][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3689 (0.4668) Acc@1 89.844 (83.714) Acc@5 100.000 (99.339)
2025-08-27 23:25:39,199 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:39,199 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:39,647 - INFO - Epoch: [93][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4470 (0.4666) Acc@1 82.031 (83.726) Acc@5 100.000 (99.364)
2025-08-27 23:25:41,459 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6562 (0.6562) Acc@1 80.469 (80.469) Acc@5 96.875 (96.875)
2025-08-27 23:25:42,292 - INFO - Epoch 93:
2025-08-27 23:25:42,292 - INFO -   Train: acc1: 83.7180 | acc5: 99.3300 | loss: 0.4682 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:42,292 - INFO -   Val:   acc1: 77.4500 | acc5: 98.0900 | loss: 0.7331
2025-08-27 23:25:42,292 - INFO -   LR: 0.100000
2025-08-27 23:25:42,306 - INFO - 
Epoch: 94, lr = 0.1
2025-08-27 23:25:42,483 - INFO - Epoch: [94][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.4815 (0.4815) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 23:25:43,323 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:43,323 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:44,296 - INFO - Epoch: [94][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3990 (0.4573) Acc@1 87.500 (84.205) Acc@5 99.219 (99.358)
2025-08-27 23:25:46,199 - INFO - Epoch: [94][200/391] Time 0.022 (0.019) Data 0.007 (0.003) Loss 0.4555 (0.4608) Acc@1 84.375 (84.153) Acc@5 100.000 (99.366)
2025-08-27 23:25:46,309 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:46,309 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:48,061 - INFO - Epoch: [94][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.5464 (0.4610) Acc@1 81.250 (84.097) Acc@5 100.000 (99.338)
2025-08-27 23:25:49,303 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:49,303 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:49,861 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4127 (0.4127) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:25:50,717 - INFO - Epoch 94:
2025-08-27 23:25:50,717 - INFO -   Train: acc1: 83.9480 | acc5: 99.3300 | loss: 0.4658 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:50,717 - INFO -   Val:   acc1: 80.3500 | acc5: 98.9400 | loss: 0.5925
2025-08-27 23:25:50,717 - INFO -   LR: 0.100000
2025-08-27 23:25:50,730 - INFO - 
Epoch: 95, lr = 0.1
2025-08-27 23:25:50,915 - INFO - Epoch: [95][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.4465 (0.4465) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:25:52,951 - INFO - Epoch: [95][100/391] Time 0.015 (0.022) Data 0.000 (0.003) Loss 0.5119 (0.4595) Acc@1 79.688 (84.421) Acc@5 99.219 (99.265)
2025-08-27 23:25:53,644 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:53,645 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:54,935 - INFO - Epoch: [95][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.5455 (0.4660) Acc@1 80.469 (84.002) Acc@5 100.000 (99.351)
2025-08-27 23:25:56,711 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:25:56,711 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:25:56,824 - INFO - Epoch: [95][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4371 (0.4711) Acc@1 85.156 (83.835) Acc@5 100.000 (99.286)
2025-08-27 23:25:58,726 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5816 (0.5816) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 23:25:59,610 - INFO - Epoch 95:
2025-08-27 23:25:59,610 - INFO -   Train: acc1: 83.8320 | acc5: 99.2900 | loss: 0.4695 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:25:59,610 - INFO -   Val:   acc1: 74.7200 | acc5: 98.6900 | loss: 0.7328
2025-08-27 23:25:59,610 - INFO -   LR: 0.100000
2025-08-27 23:25:59,624 - INFO - 
Epoch: 96, lr = 0.1
2025-08-27 23:25:59,817 - INFO - Epoch: [96][0/391] Time 0.192 (0.192) Data 0.167 (0.167) Loss 0.5519 (0.5519) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 23:26:01,073 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:01,074 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:01,763 - INFO - Epoch: [96][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4537 (0.4589) Acc@1 84.375 (84.135) Acc@5 98.438 (99.404)
2025-08-27 23:26:03,672 - INFO - Epoch: [96][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.5698 (0.4688) Acc@1 78.906 (83.687) Acc@5 100.000 (99.308)
2025-08-27 23:26:04,053 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:04,054 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:05,524 - INFO - Epoch: [96][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3840 (0.4745) Acc@1 87.500 (83.498) Acc@5 99.219 (99.320)
2025-08-27 23:26:07,134 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:07,135 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:07,385 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6346 (0.6346) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 23:26:08,237 - INFO - Epoch 96:
2025-08-27 23:26:08,237 - INFO -   Train: acc1: 83.6120 | acc5: 99.3400 | loss: 0.4718 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:08,237 - INFO -   Val:   acc1: 75.1600 | acc5: 97.4800 | loss: 0.7620
2025-08-27 23:26:08,238 - INFO -   LR: 0.100000
2025-08-27 23:26:08,250 - INFO - 
Epoch: 97, lr = 0.1
2025-08-27 23:26:08,427 - INFO - Epoch: [97][0/391] Time 0.176 (0.176) Data 0.152 (0.152) Loss 0.3972 (0.3972) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:26:10,303 - INFO - Epoch: [97][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4703 (0.4700) Acc@1 82.812 (83.377) Acc@5 100.000 (99.327)
2025-08-27 23:26:11,267 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:11,267 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:12,207 - INFO - Epoch: [97][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.5384 (0.4757) Acc@1 85.156 (83.380) Acc@5 98.438 (99.343)
2025-08-27 23:26:14,116 - INFO - Epoch: [97][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.4367 (0.4766) Acc@1 85.156 (83.358) Acc@5 99.219 (99.263)
2025-08-27 23:26:14,316 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:14,316 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:15,846 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.7178 (0.7178) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 23:26:16,682 - INFO - Epoch 97:
2025-08-27 23:26:16,682 - INFO -   Train: acc1: 83.3540 | acc5: 99.2620 | loss: 0.4776 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:16,682 - INFO -   Val:   acc1: 79.5500 | acc5: 98.9500 | loss: 0.6306
2025-08-27 23:26:16,682 - INFO -   LR: 0.100000
2025-08-27 23:26:16,697 - INFO - 
Epoch: 98, lr = 0.1
2025-08-27 23:26:16,892 - INFO - Epoch: [98][0/391] Time 0.195 (0.195) Data 0.157 (0.157) Loss 0.5375 (0.5375) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 23:26:18,451 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:18,452 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:18,776 - INFO - Epoch: [98][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.3494 (0.4676) Acc@1 85.938 (83.702) Acc@5 100.000 (99.211)
2025-08-27 23:26:20,689 - INFO - Epoch: [98][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4848 (0.4753) Acc@1 86.719 (83.570) Acc@5 98.438 (99.223)
2025-08-27 23:26:21,486 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:21,486 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:22,573 - INFO - Epoch: [98][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3581 (0.4730) Acc@1 86.719 (83.633) Acc@5 100.000 (99.278)
2025-08-27 23:26:24,339 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6545 (0.6545) Acc@1 78.125 (78.125) Acc@5 96.875 (96.875)
2025-08-27 23:26:25,190 - INFO - Epoch 98:
2025-08-27 23:26:25,190 - INFO -   Train: acc1: 83.6400 | acc5: 99.2660 | loss: 0.4743 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:25,190 - INFO -   Val:   acc1: 77.0900 | acc5: 98.1600 | loss: 0.6911
2025-08-27 23:26:25,190 - INFO -   LR: 0.100000
2025-08-27 23:26:25,206 - INFO - 
Epoch: 99, lr = 0.1
2025-08-27 23:26:25,331 - INFO - Epoch: [99][0/391] Time 0.124 (0.124) Data 0.103 (0.103) Loss 0.4367 (0.4367) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 23:26:25,567 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:25,567 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:27,153 - INFO - Epoch: [99][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4286 (0.4760) Acc@1 87.500 (83.594) Acc@5 100.000 (99.273)
2025-08-27 23:26:28,568 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:28,568 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:29,142 - INFO - Epoch: [99][200/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.3892 (0.4772) Acc@1 84.375 (83.434) Acc@5 100.000 (99.324)
2025-08-27 23:26:31,027 - INFO - Epoch: [99][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.5113 (0.4756) Acc@1 84.375 (83.591) Acc@5 97.656 (99.302)
2025-08-27 23:26:31,635 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:31,635 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:32,883 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5702 (0.5702) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 23:26:33,724 - INFO - Epoch 99:
2025-08-27 23:26:33,724 - INFO -   Train: acc1: 83.7900 | acc5: 99.3140 | loss: 0.4717 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:33,724 - INFO -   Val:   acc1: 78.4900 | acc5: 98.6000 | loss: 0.6390
2025-08-27 23:26:33,724 - INFO -   LR: 0.010000
2025-08-27 23:26:33,740 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-27 23:26:33,911 - INFO - Epoch: [100][0/391] Time 0.170 (0.170) Data 0.143 (0.143) Loss 0.3975 (0.3975) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:26:35,788 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:35,788 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:35,804 - INFO - Epoch: [100][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.3248 (0.3988) Acc@1 89.844 (86.332) Acc@5 100.000 (99.505)
2025-08-27 23:26:37,701 - INFO - Epoch: [100][200/391] Time 0.028 (0.020) Data 0.013 (0.003) Loss 0.3573 (0.3843) Acc@1 85.938 (86.921) Acc@5 99.219 (99.541)
2025-08-27 23:26:38,779 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:38,780 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:39,523 - INFO - Epoch: [100][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.2635 (0.3743) Acc@1 91.406 (87.202) Acc@5 100.000 (99.577)
2025-08-27 23:26:41,418 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2729 (0.2729) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:26:42,276 - INFO - Epoch 100:
2025-08-27 23:26:42,276 - INFO -   Train: acc1: 87.5540 | acc5: 99.5800 | loss: 0.3658 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:42,276 - INFO -   Val:   acc1: 86.9100 | acc5: 99.4900 | loss: 0.3733
2025-08-27 23:26:42,276 - INFO -   LR: 0.010000
2025-08-27 23:26:42,333 - INFO - Checkpoint saved: epoch=100, metric=86.9100
2025-08-27 23:26:42,364 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-27 23:26:42,542 - INFO - Epoch: [101][0/391] Time 0.177 (0.177) Data 0.151 (0.151) Loss 0.3670 (0.3670) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-27 23:26:43,127 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:43,127 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:44,561 - INFO - Epoch: [101][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.2478 (0.3335) Acc@1 91.406 (88.676) Acc@5 100.000 (99.590)
2025-08-27 23:26:46,338 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:46,339 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:46,557 - INFO - Epoch: [101][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.3121 (0.3314) Acc@1 89.062 (88.662) Acc@5 100.000 (99.615)
2025-08-27 23:26:48,421 - INFO - Epoch: [101][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3850 (0.3311) Acc@1 89.062 (88.645) Acc@5 99.219 (99.639)
2025-08-27 23:26:49,395 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:49,396 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:50,341 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2846 (0.2846) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:26:51,180 - INFO - Epoch 101:
2025-08-27 23:26:51,180 - INFO -   Train: acc1: 88.6420 | acc5: 99.6400 | loss: 0.3317 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:51,180 - INFO -   Val:   acc1: 87.2600 | acc5: 99.5400 | loss: 0.3699
2025-08-27 23:26:51,180 - INFO -   LR: 0.010000
2025-08-27 23:26:51,229 - INFO - Checkpoint saved: epoch=101, metric=87.2600
2025-08-27 23:26:51,260 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-27 23:26:51,431 - INFO - Epoch: [102][0/391] Time 0.170 (0.170) Data 0.149 (0.149) Loss 0.3568 (0.3568) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:26:53,330 - INFO - Epoch: [102][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.3102 (0.3244) Acc@1 89.844 (88.993) Acc@5 100.000 (99.606)
2025-08-27 23:26:53,641 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:53,641 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:55,198 - INFO - Epoch: [102][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2762 (0.3210) Acc@1 89.062 (89.109) Acc@5 100.000 (99.654)
2025-08-27 23:26:56,643 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:26:56,643 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:26:57,086 - INFO - Epoch: [102][300/391] Time 0.030 (0.019) Data 0.000 (0.002) Loss 0.3184 (0.3201) Acc@1 86.719 (89.057) Acc@5 100.000 (99.629)
2025-08-27 23:26:58,891 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2830 (0.2830) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:26:59,724 - INFO - Epoch 102:
2025-08-27 23:26:59,725 - INFO -   Train: acc1: 89.0400 | acc5: 99.6320 | loss: 0.3200 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:26:59,725 - INFO -   Val:   acc1: 87.4500 | acc5: 99.5300 | loss: 0.3667
2025-08-27 23:26:59,725 - INFO -   LR: 0.010000
2025-08-27 23:26:59,774 - INFO - Checkpoint saved: epoch=102, metric=87.4500
2025-08-27 23:26:59,806 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-27 23:26:59,970 - INFO - Epoch: [103][0/391] Time 0.163 (0.163) Data 0.137 (0.137) Loss 0.4586 (0.4586) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 23:27:00,864 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:00,864 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:01,914 - INFO - Epoch: [103][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3619 (0.3178) Acc@1 86.719 (88.861) Acc@5 99.219 (99.644)
2025-08-27 23:27:03,901 - INFO - Epoch: [103][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4078 (0.3169) Acc@1 85.938 (88.954) Acc@5 100.000 (99.666)
2025-08-27 23:27:04,045 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:04,046 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:05,825 - INFO - Epoch: [103][300/391] Time 0.037 (0.020) Data 0.021 (0.003) Loss 0.4556 (0.3156) Acc@1 85.156 (89.016) Acc@5 98.438 (99.663)
2025-08-27 23:27:07,127 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:07,128 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:07,711 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3177 (0.3177) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:27:08,544 - INFO - Epoch 103:
2025-08-27 23:27:08,544 - INFO -   Train: acc1: 89.0260 | acc5: 99.6800 | loss: 0.3161 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:27:08,544 - INFO -   Val:   acc1: 87.3800 | acc5: 99.5300 | loss: 0.3619
2025-08-27 23:27:08,544 - INFO -   LR: 0.010000
2025-08-27 23:27:08,557 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-27 23:27:08,746 - INFO - Epoch: [104][0/391] Time 0.188 (0.188) Data 0.152 (0.152) Loss 0.3806 (0.3806) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:27:10,656 - INFO - Epoch: [104][100/391] Time 0.024 (0.021) Data 0.011 (0.004) Loss 0.2597 (0.3080) Acc@1 93.750 (89.380) Acc@5 100.000 (99.722)
2025-08-27 23:27:11,344 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:11,344 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:12,554 - INFO - Epoch: [104][200/391] Time 0.029 (0.020) Data 0.012 (0.003) Loss 0.3501 (0.3112) Acc@1 87.500 (89.319) Acc@5 99.219 (99.674)
2025-08-27 23:27:14,356 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:14,356 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:14,459 - INFO - Epoch: [104][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2550 (0.3121) Acc@1 90.625 (89.236) Acc@5 100.000 (99.668)
2025-08-27 23:27:16,269 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3211 (0.3211) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:27:17,116 - INFO - Epoch 104:
2025-08-27 23:27:17,117 - INFO -   Train: acc1: 89.1480 | acc5: 99.6700 | loss: 0.3132 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:27:17,117 - INFO -   Val:   acc1: 87.7700 | acc5: 99.5900 | loss: 0.3579
2025-08-27 23:27:17,117 - INFO -   LR: 0.010000
2025-08-27 23:27:17,164 - INFO - Checkpoint saved: epoch=104, metric=87.7700
2025-08-27 23:27:17,196 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-27 23:27:17,387 - INFO - Epoch: [105][0/391] Time 0.190 (0.190) Data 0.168 (0.168) Loss 0.2508 (0.2508) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:27:18,696 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:18,696 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:19,352 - INFO - Epoch: [105][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3126 (0.3000) Acc@1 86.719 (89.735) Acc@5 100.000 (99.698)
2025-08-27 23:27:21,325 - INFO - Epoch: [105][200/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.2382 (0.3068) Acc@1 93.750 (89.432) Acc@5 99.219 (99.712)
2025-08-27 23:27:21,777 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:21,777 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:23,244 - INFO - Epoch: [105][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.3000 (0.3091) Acc@1 90.625 (89.397) Acc@5 99.219 (99.689)
2025-08-27 23:27:24,993 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:24,993 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:25,239 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3220 (0.3220) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:27:26,086 - INFO - Epoch 105:
2025-08-27 23:27:26,086 - INFO -   Train: acc1: 89.4540 | acc5: 99.7200 | loss: 0.3070 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:27:26,086 - INFO -   Val:   acc1: 87.6300 | acc5: 99.5000 | loss: 0.3726
2025-08-27 23:27:26,087 - INFO -   LR: 0.010000
2025-08-27 23:27:26,101 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-27 23:27:26,282 - INFO - Epoch: [106][0/391] Time 0.180 (0.180) Data 0.153 (0.153) Loss 0.2740 (0.2740) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:27:28,160 - INFO - Epoch: [106][100/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.2204 (0.3042) Acc@1 92.188 (89.573) Acc@5 100.000 (99.683)
2025-08-27 23:27:29,184 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:29,185 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:30,021 - INFO - Epoch: [106][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.3264 (0.2988) Acc@1 87.500 (89.712) Acc@5 100.000 (99.701)
2025-08-27 23:27:31,904 - INFO - Epoch: [106][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.4738 (0.3011) Acc@1 84.375 (89.659) Acc@5 100.000 (99.699)
2025-08-27 23:27:32,141 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:32,141 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:33,769 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2969 (0.2969) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:27:34,616 - INFO - Epoch 106:
2025-08-27 23:27:34,616 - INFO -   Train: acc1: 89.5420 | acc5: 99.6940 | loss: 0.3053 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:27:34,616 - INFO -   Val:   acc1: 87.9600 | acc5: 99.5700 | loss: 0.3583
2025-08-27 23:27:34,616 - INFO -   LR: 0.010000
2025-08-27 23:27:34,665 - INFO - Checkpoint saved: epoch=106, metric=87.9600
2025-08-27 23:27:34,708 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-27 23:27:34,892 - INFO - Epoch: [107][0/391] Time 0.183 (0.183) Data 0.163 (0.163) Loss 0.2131 (0.2131) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:27:36,459 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:36,459 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:36,809 - INFO - Epoch: [107][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.3031 (0.2990) Acc@1 89.062 (89.774) Acc@5 99.219 (99.691)
2025-08-27 23:27:38,705 - INFO - Epoch: [107][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3769 (0.3024) Acc@1 86.719 (89.517) Acc@5 100.000 (99.728)
2025-08-27 23:27:39,562 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:39,562 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:40,687 - INFO - Epoch: [107][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3817 (0.3028) Acc@1 88.281 (89.522) Acc@5 99.219 (99.717)
2025-08-27 23:27:42,557 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2789 (0.2789) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:27:43,404 - INFO - Epoch 107:
2025-08-27 23:27:43,404 - INFO -   Train: acc1: 89.4940 | acc5: 99.7120 | loss: 0.3052 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:27:43,405 - INFO -   Val:   acc1: 87.7400 | acc5: 99.5200 | loss: 0.3712
2025-08-27 23:27:43,405 - INFO -   LR: 0.010000
2025-08-27 23:27:43,419 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-27 23:27:43,597 - INFO - Epoch: [108][0/391] Time 0.177 (0.177) Data 0.157 (0.157) Loss 0.1980 (0.1980) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:27:43,903 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:43,903 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:45,563 - INFO - Epoch: [108][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.3115 (0.2995) Acc@1 88.281 (89.735) Acc@5 99.219 (99.714)
2025-08-27 23:27:46,989 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:46,989 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:47,549 - INFO - Epoch: [108][200/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.3394 (0.3026) Acc@1 85.156 (89.436) Acc@5 100.000 (99.689)
2025-08-27 23:27:49,356 - INFO - Epoch: [108][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2417 (0.3039) Acc@1 94.531 (89.330) Acc@5 100.000 (99.686)
2025-08-27 23:27:49,998 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:49,999 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:51,265 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.3055 (0.3055) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:27:52,117 - INFO - Epoch 108:
2025-08-27 23:27:52,117 - INFO -   Train: acc1: 89.4260 | acc5: 99.6920 | loss: 0.3031 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:27:52,117 - INFO -   Val:   acc1: 87.3700 | acc5: 99.6600 | loss: 0.3723
2025-08-27 23:27:52,117 - INFO -   LR: 0.010000
2025-08-27 23:27:52,131 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-27 23:27:52,310 - INFO - Epoch: [109][0/391] Time 0.178 (0.178) Data 0.148 (0.148) Loss 0.2568 (0.2568) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:27:54,174 - INFO - Epoch: [109][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3229 (0.3080) Acc@1 89.844 (89.333) Acc@5 100.000 (99.776)
2025-08-27 23:27:54,183 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:54,183 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:56,071 - INFO - Epoch: [109][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3146 (0.3010) Acc@1 90.625 (89.572) Acc@5 99.219 (99.755)
2025-08-27 23:27:57,244 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:27:57,244 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:27:57,929 - INFO - Epoch: [109][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.3741 (0.3013) Acc@1 89.062 (89.522) Acc@5 100.000 (99.746)
2025-08-27 23:27:59,802 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2702 (0.2702) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:28:00,655 - INFO - Epoch 109:
2025-08-27 23:28:00,655 - INFO -   Train: acc1: 89.4240 | acc5: 99.7440 | loss: 0.3044 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:00,655 - INFO -   Val:   acc1: 88.0900 | acc5: 99.4900 | loss: 0.3567
2025-08-27 23:28:00,655 - INFO -   LR: 0.010000
2025-08-27 23:28:00,703 - INFO - Checkpoint saved: epoch=109, metric=88.0900
2025-08-27 23:28:00,735 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-27 23:28:00,892 - INFO - Epoch: [110][0/391] Time 0.157 (0.157) Data 0.137 (0.137) Loss 0.2777 (0.2777) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:28:01,445 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:01,445 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:02,740 - INFO - Epoch: [110][100/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.3119 (0.2991) Acc@1 90.625 (89.751) Acc@5 100.000 (99.683)
2025-08-27 23:28:04,352 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:04,352 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:04,536 - INFO - Epoch: [110][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2908 (0.2997) Acc@1 88.281 (89.747) Acc@5 100.000 (99.708)
2025-08-27 23:28:06,405 - INFO - Epoch: [110][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.3248 (0.3009) Acc@1 87.500 (89.740) Acc@5 100.000 (99.694)
2025-08-27 23:28:07,283 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:07,284 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:08,208 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2865 (0.2865) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:28:09,028 - INFO - Epoch 110:
2025-08-27 23:28:09,028 - INFO -   Train: acc1: 89.6600 | acc5: 99.6980 | loss: 0.3017 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:09,028 - INFO -   Val:   acc1: 87.4000 | acc5: 99.4900 | loss: 0.3707
2025-08-27 23:28:09,028 - INFO -   LR: 0.010000
2025-08-27 23:28:09,077 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-27 23:28:09,241 - INFO - Epoch: [111][0/391] Time 0.163 (0.163) Data 0.139 (0.139) Loss 0.2052 (0.2052) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:28:11,073 - INFO - Epoch: [111][100/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3018 (0.2905) Acc@1 87.500 (89.968) Acc@5 100.000 (99.807)
2025-08-27 23:28:11,430 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:11,430 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:12,949 - INFO - Epoch: [111][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.2729 (0.2974) Acc@1 89.844 (89.797) Acc@5 100.000 (99.786)
2025-08-27 23:28:14,366 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:14,366 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:14,761 - INFO - Epoch: [111][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2560 (0.3005) Acc@1 92.188 (89.732) Acc@5 100.000 (99.748)
2025-08-27 23:28:16,572 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3039 (0.3039) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:28:17,388 - INFO - Epoch 111:
2025-08-27 23:28:17,389 - INFO -   Train: acc1: 89.6500 | acc5: 99.7500 | loss: 0.3000 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:17,389 - INFO -   Val:   acc1: 87.5700 | acc5: 99.5200 | loss: 0.3692
2025-08-27 23:28:17,389 - INFO -   LR: 0.010000
2025-08-27 23:28:17,402 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-27 23:28:17,576 - INFO - Epoch: [112][0/391] Time 0.173 (0.173) Data 0.147 (0.147) Loss 0.2631 (0.2631) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:28:18,411 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:18,411 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:19,360 - INFO - Epoch: [112][100/391] Time 0.015 (0.019) Data 0.001 (0.003) Loss 0.3858 (0.2943) Acc@1 86.719 (89.821) Acc@5 100.000 (99.714)
2025-08-27 23:28:21,343 - INFO - Epoch: [112][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.3577 (0.2979) Acc@1 89.844 (89.700) Acc@5 100.000 (99.732)
2025-08-27 23:28:21,477 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:21,477 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:23,171 - INFO - Epoch: [112][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2731 (0.2978) Acc@1 91.406 (89.649) Acc@5 100.000 (99.733)
2025-08-27 23:28:24,381 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:24,382 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:24,935 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2520 (0.2520) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:28:25,752 - INFO - Epoch 112:
2025-08-27 23:28:25,752 - INFO -   Train: acc1: 89.5480 | acc5: 99.7000 | loss: 0.3012 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:25,752 - INFO -   Val:   acc1: 87.8100 | acc5: 99.5600 | loss: 0.3690
2025-08-27 23:28:25,752 - INFO -   LR: 0.010000
2025-08-27 23:28:25,765 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-27 23:28:25,938 - INFO - Epoch: [113][0/391] Time 0.173 (0.173) Data 0.156 (0.156) Loss 0.2462 (0.2462) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:28:27,744 - INFO - Epoch: [113][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.3041 (0.2972) Acc@1 89.844 (89.882) Acc@5 100.000 (99.636)
2025-08-27 23:28:28,419 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:28,419 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:29,627 - INFO - Epoch: [113][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3517 (0.2932) Acc@1 85.156 (89.890) Acc@5 99.219 (99.720)
2025-08-27 23:28:31,429 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:31,429 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:31,496 - INFO - Epoch: [113][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3579 (0.2938) Acc@1 85.938 (89.807) Acc@5 100.000 (99.746)
2025-08-27 23:28:33,355 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3434 (0.3434) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:28:34,177 - INFO - Epoch 113:
2025-08-27 23:28:34,177 - INFO -   Train: acc1: 89.6460 | acc5: 99.7260 | loss: 0.2980 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:34,177 - INFO -   Val:   acc1: 86.9500 | acc5: 99.5900 | loss: 0.3935
2025-08-27 23:28:34,177 - INFO -   LR: 0.010000
2025-08-27 23:28:34,190 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-27 23:28:34,377 - INFO - Epoch: [114][0/391] Time 0.186 (0.186) Data 0.161 (0.161) Loss 0.1687 (0.1687) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-27 23:28:35,572 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:35,572 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:36,229 - INFO - Epoch: [114][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.4122 (0.2991) Acc@1 87.500 (89.496) Acc@5 98.438 (99.667)
2025-08-27 23:28:38,019 - INFO - Epoch: [114][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.3823 (0.2990) Acc@1 83.594 (89.591) Acc@5 99.219 (99.685)
2025-08-27 23:28:38,502 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:38,502 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:39,885 - INFO - Epoch: [114][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1469 (0.2991) Acc@1 96.094 (89.543) Acc@5 100.000 (99.691)
2025-08-27 23:28:41,441 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:41,441 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:41,650 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2960 (0.2960) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:28:42,488 - INFO - Epoch 114:
2025-08-27 23:28:42,488 - INFO -   Train: acc1: 89.4420 | acc5: 99.6900 | loss: 0.3019 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:42,489 - INFO -   Val:   acc1: 87.4000 | acc5: 99.5700 | loss: 0.3701
2025-08-27 23:28:42,489 - INFO -   LR: 0.010000
2025-08-27 23:28:42,502 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-27 23:28:42,692 - INFO - Epoch: [115][0/391] Time 0.190 (0.190) Data 0.171 (0.171) Loss 0.3740 (0.3740) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:28:44,456 - INFO - Epoch: [115][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4337 (0.2908) Acc@1 85.156 (90.091) Acc@5 98.438 (99.745)
2025-08-27 23:28:45,568 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:45,568 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:46,411 - INFO - Epoch: [115][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3113 (0.2904) Acc@1 91.406 (90.023) Acc@5 98.438 (99.697)
2025-08-27 23:28:48,362 - INFO - Epoch: [115][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.3858 (0.2932) Acc@1 84.375 (89.875) Acc@5 99.219 (99.686)
2025-08-27 23:28:48,655 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:48,655 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:50,248 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2633 (0.2633) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:28:51,139 - INFO - Epoch 115:
2025-08-27 23:28:51,139 - INFO -   Train: acc1: 89.7560 | acc5: 99.6880 | loss: 0.2972 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:51,139 - INFO -   Val:   acc1: 87.6500 | acc5: 99.5500 | loss: 0.3634
2025-08-27 23:28:51,139 - INFO -   LR: 0.010000
2025-08-27 23:28:51,154 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-27 23:28:51,340 - INFO - Epoch: [116][0/391] Time 0.185 (0.185) Data 0.159 (0.159) Loss 0.4261 (0.4261) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:28:52,958 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:52,958 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:53,258 - INFO - Epoch: [116][100/391] Time 0.017 (0.021) Data 0.001 (0.003) Loss 0.3641 (0.2978) Acc@1 87.500 (89.573) Acc@5 100.000 (99.830)
2025-08-27 23:28:55,229 - INFO - Epoch: [116][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3173 (0.3011) Acc@1 89.062 (89.416) Acc@5 100.000 (99.743)
2025-08-27 23:28:56,003 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:28:56,003 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:28:57,118 - INFO - Epoch: [116][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2849 (0.2993) Acc@1 89.062 (89.499) Acc@5 100.000 (99.753)
2025-08-27 23:28:58,994 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2650 (0.2650) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:28:59,813 - INFO - Epoch 116:
2025-08-27 23:28:59,813 - INFO -   Train: acc1: 89.4480 | acc5: 99.7320 | loss: 0.3006 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:28:59,813 - INFO -   Val:   acc1: 87.5800 | acc5: 99.5900 | loss: 0.3692
2025-08-27 23:28:59,813 - INFO -   LR: 0.010000
2025-08-27 23:28:59,826 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-27 23:29:00,024 - INFO - Epoch: [117][0/391] Time 0.197 (0.197) Data 0.167 (0.167) Loss 0.3372 (0.3372) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:29:00,253 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:00,253 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:01,901 - INFO - Epoch: [117][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3119 (0.3017) Acc@1 89.844 (89.225) Acc@5 100.000 (99.691)
2025-08-27 23:29:03,336 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:03,337 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:03,912 - INFO - Epoch: [117][200/391] Time 0.026 (0.020) Data 0.013 (0.002) Loss 0.3483 (0.3019) Acc@1 88.281 (89.296) Acc@5 99.219 (99.708)
2025-08-27 23:29:05,814 - INFO - Epoch: [117][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4588 (0.3059) Acc@1 85.156 (89.210) Acc@5 100.000 (99.730)
2025-08-27 23:29:06,373 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:06,373 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:07,588 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.2801 (0.2801) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:29:08,466 - INFO - Epoch 117:
2025-08-27 23:29:08,467 - INFO -   Train: acc1: 89.3020 | acc5: 99.7200 | loss: 0.3049 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:29:08,467 - INFO -   Val:   acc1: 87.7500 | acc5: 99.5800 | loss: 0.3680
2025-08-27 23:29:08,467 - INFO -   LR: 0.010000
2025-08-27 23:29:08,482 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-27 23:29:08,669 - INFO - Epoch: [118][0/391] Time 0.186 (0.186) Data 0.167 (0.167) Loss 0.2716 (0.2716) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:29:10,600 - INFO - Epoch: [118][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3161 (0.2986) Acc@1 89.062 (89.550) Acc@5 100.000 (99.698)
2025-08-27 23:29:10,633 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:10,633 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:12,528 - INFO - Epoch: [118][200/391] Time 0.029 (0.020) Data 0.003 (0.002) Loss 0.1992 (0.3004) Acc@1 92.969 (89.649) Acc@5 100.000 (99.728)
2025-08-27 23:29:13,704 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:13,704 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:14,401 - INFO - Epoch: [118][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3609 (0.3003) Acc@1 88.281 (89.540) Acc@5 100.000 (99.720)
2025-08-27 23:29:16,161 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2678 (0.2678) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:29:16,995 - INFO - Epoch 118:
2025-08-27 23:29:16,995 - INFO -   Train: acc1: 89.4760 | acc5: 99.7100 | loss: 0.3025 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:29:16,995 - INFO -   Val:   acc1: 87.5900 | acc5: 99.4400 | loss: 0.3707
2025-08-27 23:29:16,995 - INFO -   LR: 0.010000
2025-08-27 23:29:17,010 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-27 23:29:17,198 - INFO - Epoch: [119][0/391] Time 0.187 (0.187) Data 0.161 (0.161) Loss 0.2796 (0.2796) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:29:17,751 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:17,751 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:19,086 - INFO - Epoch: [119][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1989 (0.2990) Acc@1 95.312 (89.782) Acc@5 99.219 (99.652)
2025-08-27 23:29:20,849 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:20,849 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:21,027 - INFO - Epoch: [119][200/391] Time 0.026 (0.020) Data 0.013 (0.002) Loss 0.2742 (0.2997) Acc@1 89.062 (89.579) Acc@5 99.219 (99.685)
2025-08-27 23:29:22,958 - INFO - Epoch: [119][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3408 (0.2989) Acc@1 89.844 (89.584) Acc@5 100.000 (99.704)
2025-08-27 23:29:23,939 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:23,939 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:24,802 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3000 (0.3000) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:29:25,665 - INFO - Epoch 119:
2025-08-27 23:29:25,665 - INFO -   Train: acc1: 89.5760 | acc5: 99.6880 | loss: 0.3003 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:29:25,665 - INFO -   Val:   acc1: 87.2500 | acc5: 99.5400 | loss: 0.3836
2025-08-27 23:29:25,665 - INFO -   LR: 0.010000
2025-08-27 23:29:25,679 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-27 23:29:25,836 - INFO - Epoch: [120][0/391] Time 0.156 (0.156) Data 0.131 (0.131) Loss 0.2519 (0.2519) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:29:27,808 - INFO - Epoch: [120][100/391] Time 0.022 (0.021) Data 0.000 (0.004) Loss 0.2977 (0.3002) Acc@1 91.406 (89.588) Acc@5 99.219 (99.722)
2025-08-27 23:29:28,150 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:28,150 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:29,745 - INFO - Epoch: [120][200/391] Time 0.034 (0.020) Data 0.014 (0.003) Loss 0.2572 (0.3056) Acc@1 91.406 (89.269) Acc@5 100.000 (99.705)
2025-08-27 23:29:31,213 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:31,213 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:31,619 - INFO - Epoch: [120][300/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.2884 (0.3026) Acc@1 91.406 (89.408) Acc@5 100.000 (99.712)
2025-08-27 23:29:33,404 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2866 (0.2866) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:29:34,249 - INFO - Epoch 120:
2025-08-27 23:29:34,249 - INFO -   Train: acc1: 89.4420 | acc5: 99.7140 | loss: 0.3020 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:29:34,249 - INFO -   Val:   acc1: 87.6000 | acc5: 99.5000 | loss: 0.3709
2025-08-27 23:29:34,249 - INFO -   LR: 0.010000
2025-08-27 23:29:34,298 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-27 23:29:34,497 - INFO - Epoch: [121][0/391] Time 0.198 (0.198) Data 0.178 (0.178) Loss 0.3415 (0.3415) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:29:35,465 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:35,465 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:36,573 - INFO - Epoch: [121][100/391] Time 0.027 (0.023) Data 0.003 (0.003) Loss 0.2799 (0.2980) Acc@1 88.281 (89.519) Acc@5 98.438 (99.675)
2025-08-27 23:29:38,511 - INFO - Epoch: [121][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.3379 (0.3029) Acc@1 87.500 (89.319) Acc@5 100.000 (99.720)
2025-08-27 23:29:38,672 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:38,672 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:40,484 - INFO - Epoch: [121][300/391] Time 0.026 (0.021) Data 0.004 (0.002) Loss 0.4219 (0.3045) Acc@1 86.719 (89.390) Acc@5 100.000 (99.722)
2025-08-27 23:29:41,830 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:41,830 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:42,388 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.3280 (0.3280) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 23:29:43,267 - INFO - Epoch 121:
2025-08-27 23:29:43,267 - INFO -   Train: acc1: 89.4000 | acc5: 99.7020 | loss: 0.3051 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:29:43,267 - INFO -   Val:   acc1: 87.3100 | acc5: 99.5200 | loss: 0.3786
2025-08-27 23:29:43,267 - INFO -   LR: 0.010000
2025-08-27 23:29:43,281 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-27 23:29:43,436 - INFO - Epoch: [122][0/391] Time 0.154 (0.154) Data 0.138 (0.138) Loss 0.2481 (0.2481) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:29:45,467 - INFO - Epoch: [122][100/391] Time 0.040 (0.022) Data 0.016 (0.003) Loss 0.3866 (0.3062) Acc@1 84.375 (89.279) Acc@5 100.000 (99.667)
2025-08-27 23:29:46,215 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:46,216 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:47,469 - INFO - Epoch: [122][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.3200 (0.3100) Acc@1 88.281 (89.199) Acc@5 99.219 (99.701)
2025-08-27 23:29:49,364 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:49,364 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:49,419 - INFO - Epoch: [122][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3215 (0.3064) Acc@1 89.062 (89.343) Acc@5 100.000 (99.707)
2025-08-27 23:29:51,370 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2722 (0.2722) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:29:52,213 - INFO - Epoch 122:
2025-08-27 23:29:52,213 - INFO -   Train: acc1: 89.2640 | acc5: 99.7020 | loss: 0.3083 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:29:52,213 - INFO -   Val:   acc1: 87.1200 | acc5: 99.6000 | loss: 0.3807
2025-08-27 23:29:52,213 - INFO -   LR: 0.010000
2025-08-27 23:29:52,228 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-27 23:29:52,411 - INFO - Epoch: [123][0/391] Time 0.182 (0.182) Data 0.160 (0.160) Loss 0.2444 (0.2444) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:29:53,776 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:53,776 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:54,388 - INFO - Epoch: [123][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.2288 (0.3108) Acc@1 93.750 (89.070) Acc@5 100.000 (99.691)
2025-08-27 23:29:56,271 - INFO - Epoch: [123][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3208 (0.3042) Acc@1 89.062 (89.420) Acc@5 99.219 (99.712)
2025-08-27 23:29:56,754 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:56,754 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:58,158 - INFO - Epoch: [123][300/391] Time 0.016 (0.020) Data 0.000 (0.001) Loss 0.3290 (0.3042) Acc@1 89.844 (89.486) Acc@5 99.219 (99.722)
2025-08-27 23:29:59,774 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:29:59,775 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:29:59,990 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3195 (0.3195) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:30:00,832 - INFO - Epoch 123:
2025-08-27 23:30:00,832 - INFO -   Train: acc1: 89.4160 | acc5: 99.7020 | loss: 0.3063 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:00,832 - INFO -   Val:   acc1: 86.9300 | acc5: 99.5500 | loss: 0.3844
2025-08-27 23:30:00,832 - INFO -   LR: 0.010000
2025-08-27 23:30:00,848 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-27 23:30:01,019 - INFO - Epoch: [124][0/391] Time 0.171 (0.171) Data 0.140 (0.140) Loss 0.2921 (0.2921) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-27 23:30:02,925 - INFO - Epoch: [124][100/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.4232 (0.2968) Acc@1 84.375 (89.929) Acc@5 99.219 (99.783)
2025-08-27 23:30:03,980 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:03,981 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:04,840 - INFO - Epoch: [124][200/391] Time 0.020 (0.020) Data 0.002 (0.002) Loss 0.3306 (0.3074) Acc@1 87.500 (89.529) Acc@5 99.219 (99.712)
2025-08-27 23:30:06,712 - INFO - Epoch: [124][300/391] Time 0.028 (0.019) Data 0.000 (0.001) Loss 0.2460 (0.3086) Acc@1 90.625 (89.400) Acc@5 99.219 (99.691)
2025-08-27 23:30:06,999 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:06,999 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:08,497 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2805 (0.2805) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:30:09,351 - INFO - Epoch 124:
2025-08-27 23:30:09,351 - INFO -   Train: acc1: 89.2680 | acc5: 99.7020 | loss: 0.3098 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:09,352 - INFO -   Val:   acc1: 87.4200 | acc5: 99.5800 | loss: 0.3704
2025-08-27 23:30:09,352 - INFO -   LR: 0.010000
2025-08-27 23:30:09,367 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-27 23:30:09,535 - INFO - Epoch: [125][0/391] Time 0.167 (0.167) Data 0.144 (0.144) Loss 0.3047 (0.3047) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:30:11,169 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:11,169 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:11,460 - INFO - Epoch: [125][100/391] Time 0.028 (0.021) Data 0.000 (0.002) Loss 0.2262 (0.2940) Acc@1 92.188 (89.844) Acc@5 100.000 (99.760)
2025-08-27 23:30:13,436 - INFO - Epoch: [125][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2428 (0.2981) Acc@1 93.750 (89.704) Acc@5 100.000 (99.712)
2025-08-27 23:30:14,259 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:14,260 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:15,342 - INFO - Epoch: [125][300/391] Time 0.017 (0.020) Data 0.000 (0.001) Loss 0.2500 (0.3009) Acc@1 93.750 (89.722) Acc@5 100.000 (99.702)
2025-08-27 23:30:17,170 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.3129 (0.3129) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:30:18,002 - INFO - Epoch 125:
2025-08-27 23:30:18,002 - INFO -   Train: acc1: 89.6660 | acc5: 99.7060 | loss: 0.3028 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:18,002 - INFO -   Val:   acc1: 87.6200 | acc5: 99.5900 | loss: 0.3735
2025-08-27 23:30:18,003 - INFO -   LR: 0.010000
2025-08-27 23:30:18,020 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-27 23:30:18,206 - INFO - Epoch: [126][0/391] Time 0.185 (0.185) Data 0.161 (0.161) Loss 0.3903 (0.3903) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 23:30:18,474 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:18,474 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:20,148 - INFO - Epoch: [126][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.2663 (0.3005) Acc@1 89.844 (89.751) Acc@5 99.219 (99.714)
2025-08-27 23:30:21,566 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:21,566 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:22,059 - INFO - Epoch: [126][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3014 (0.3035) Acc@1 91.406 (89.611) Acc@5 100.000 (99.697)
2025-08-27 23:30:23,940 - INFO - Epoch: [126][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3115 (0.3030) Acc@1 89.844 (89.610) Acc@5 100.000 (99.704)
2025-08-27 23:30:24,608 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:24,608 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:25,796 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2925 (0.2925) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:30:26,625 - INFO - Epoch 126:
2025-08-27 23:30:26,626 - INFO -   Train: acc1: 89.5780 | acc5: 99.6960 | loss: 0.3045 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:26,626 - INFO -   Val:   acc1: 87.1300 | acc5: 99.5800 | loss: 0.3877
2025-08-27 23:30:26,626 - INFO -   LR: 0.010000
2025-08-27 23:30:26,640 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-27 23:30:26,834 - INFO - Epoch: [127][0/391] Time 0.193 (0.193) Data 0.169 (0.169) Loss 0.2203 (0.2203) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:30:28,773 - INFO - Epoch: [127][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.3560 (0.3012) Acc@1 91.406 (89.751) Acc@5 100.000 (99.667)
2025-08-27 23:30:28,815 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:28,815 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:30,646 - INFO - Epoch: [127][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.3483 (0.3051) Acc@1 86.719 (89.611) Acc@5 100.000 (99.654)
2025-08-27 23:30:31,757 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:31,757 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:32,449 - INFO - Epoch: [127][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3380 (0.3047) Acc@1 89.062 (89.462) Acc@5 100.000 (99.668)
2025-08-27 23:30:34,266 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.3312 (0.3312) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:30:35,073 - INFO - Epoch 127:
2025-08-27 23:30:35,073 - INFO -   Train: acc1: 89.3320 | acc5: 99.6880 | loss: 0.3073 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:35,073 - INFO -   Val:   acc1: 86.2700 | acc5: 99.3700 | loss: 0.4132
2025-08-27 23:30:35,073 - INFO -   LR: 0.010000
2025-08-27 23:30:35,090 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-27 23:30:35,261 - INFO - Epoch: [128][0/391] Time 0.171 (0.171) Data 0.141 (0.141) Loss 0.3228 (0.3228) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:30:35,841 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:35,842 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:37,111 - INFO - Epoch: [128][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.2349 (0.3028) Acc@1 93.750 (89.372) Acc@5 100.000 (99.760)
2025-08-27 23:30:38,806 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:38,806 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:38,992 - INFO - Epoch: [128][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2579 (0.3040) Acc@1 92.969 (89.494) Acc@5 100.000 (99.681)
2025-08-27 23:30:40,823 - INFO - Epoch: [128][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2530 (0.3085) Acc@1 90.625 (89.270) Acc@5 100.000 (99.665)
2025-08-27 23:30:41,751 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:41,751 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:42,583 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2826 (0.2826) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:30:43,419 - INFO - Epoch 128:
2025-08-27 23:30:43,420 - INFO -   Train: acc1: 89.3220 | acc5: 99.6600 | loss: 0.3081 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:43,420 - INFO -   Val:   acc1: 87.5000 | acc5: 99.4900 | loss: 0.3824
2025-08-27 23:30:43,420 - INFO -   LR: 0.010000
2025-08-27 23:30:43,435 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-27 23:30:43,609 - INFO - Epoch: [129][0/391] Time 0.173 (0.173) Data 0.151 (0.151) Loss 0.2564 (0.2564) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:30:45,431 - INFO - Epoch: [129][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.2448 (0.3041) Acc@1 89.062 (89.341) Acc@5 100.000 (99.667)
2025-08-27 23:30:45,840 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:45,840 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:47,273 - INFO - Epoch: [129][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2948 (0.3075) Acc@1 89.844 (89.335) Acc@5 100.000 (99.642)
2025-08-27 23:30:48,806 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:48,806 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:49,111 - INFO - Epoch: [129][300/391] Time 0.022 (0.019) Data 0.011 (0.003) Loss 0.2822 (0.3061) Acc@1 92.188 (89.415) Acc@5 99.219 (99.650)
2025-08-27 23:30:50,979 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2831 (0.2831) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:30:51,817 - INFO - Epoch 129:
2025-08-27 23:30:51,817 - INFO -   Train: acc1: 89.2220 | acc5: 99.6620 | loss: 0.3107 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:30:51,817 - INFO -   Val:   acc1: 87.0800 | acc5: 99.5000 | loss: 0.3899
2025-08-27 23:30:51,817 - INFO -   LR: 0.010000
2025-08-27 23:30:51,832 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-27 23:30:52,019 - INFO - Epoch: [130][0/391] Time 0.187 (0.187) Data 0.156 (0.156) Loss 0.3067 (0.3067) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:30:52,911 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:52,912 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:53,827 - INFO - Epoch: [130][100/391] Time 0.024 (0.020) Data 0.012 (0.005) Loss 0.3134 (0.3059) Acc@1 89.062 (89.542) Acc@5 100.000 (99.783)
2025-08-27 23:30:55,736 - INFO - Epoch: [130][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.2743 (0.3074) Acc@1 89.062 (89.482) Acc@5 100.000 (99.716)
2025-08-27 23:30:55,919 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:55,920 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:57,673 - INFO - Epoch: [130][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4306 (0.3105) Acc@1 84.375 (89.371) Acc@5 100.000 (99.686)
2025-08-27 23:30:59,002 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:30:59,003 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:30:59,562 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2788 (0.2788) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:31:00,402 - INFO - Epoch 130:
2025-08-27 23:31:00,402 - INFO -   Train: acc1: 89.4700 | acc5: 99.6880 | loss: 0.3080 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:00,402 - INFO -   Val:   acc1: 87.0500 | acc5: 99.6400 | loss: 0.3861
2025-08-27 23:31:00,402 - INFO -   LR: 0.010000
2025-08-27 23:31:00,452 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-27 23:31:00,625 - INFO - Epoch: [131][0/391] Time 0.172 (0.172) Data 0.145 (0.145) Loss 0.2147 (0.2147) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:31:02,556 - INFO - Epoch: [131][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.3725 (0.3125) Acc@1 87.500 (89.124) Acc@5 100.000 (99.714)
2025-08-27 23:31:03,281 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:03,282 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:04,448 - INFO - Epoch: [131][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3186 (0.3125) Acc@1 86.719 (89.121) Acc@5 100.000 (99.685)
2025-08-27 23:31:06,338 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:06,338 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:06,376 - INFO - Epoch: [131][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4987 (0.3089) Acc@1 81.250 (89.234) Acc@5 100.000 (99.699)
2025-08-27 23:31:08,220 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2681 (0.2681) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:31:09,073 - INFO - Epoch 131:
2025-08-27 23:31:09,074 - INFO -   Train: acc1: 89.2600 | acc5: 99.6980 | loss: 0.3100 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:09,074 - INFO -   Val:   acc1: 87.2300 | acc5: 99.5000 | loss: 0.3813
2025-08-27 23:31:09,074 - INFO -   LR: 0.010000
2025-08-27 23:31:09,091 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-27 23:31:09,261 - INFO - Epoch: [132][0/391] Time 0.169 (0.169) Data 0.151 (0.151) Loss 0.4003 (0.4003) Acc@1 89.844 (89.844) Acc@5 97.656 (97.656)
2025-08-27 23:31:10,584 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:10,584 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:11,190 - INFO - Epoch: [132][100/391] Time 0.037 (0.021) Data 0.000 (0.003) Loss 0.2894 (0.3078) Acc@1 88.281 (89.093) Acc@5 100.000 (99.629)
2025-08-27 23:31:13,049 - INFO - Epoch: [132][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.2623 (0.3010) Acc@1 91.406 (89.607) Acc@5 100.000 (99.685)
2025-08-27 23:31:13,592 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:13,592 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:15,061 - INFO - Epoch: [132][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3310 (0.3029) Acc@1 86.719 (89.574) Acc@5 99.219 (99.696)
2025-08-27 23:31:16,753 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:16,754 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:16,957 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2939 (0.2939) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:31:17,784 - INFO - Epoch 132:
2025-08-27 23:31:17,784 - INFO -   Train: acc1: 89.2920 | acc5: 99.6700 | loss: 0.3096 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:17,784 - INFO -   Val:   acc1: 87.1400 | acc5: 99.5700 | loss: 0.3854
2025-08-27 23:31:17,784 - INFO -   LR: 0.010000
2025-08-27 23:31:17,802 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-27 23:31:17,967 - INFO - Epoch: [133][0/391] Time 0.164 (0.164) Data 0.131 (0.131) Loss 0.2581 (0.2581) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:31:19,884 - INFO - Epoch: [133][100/391] Time 0.019 (0.021) Data 0.007 (0.003) Loss 0.3579 (0.3099) Acc@1 86.719 (89.202) Acc@5 100.000 (99.814)
2025-08-27 23:31:21,009 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:21,009 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:21,855 - INFO - Epoch: [133][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3182 (0.3080) Acc@1 87.500 (89.171) Acc@5 100.000 (99.732)
2025-08-27 23:31:23,716 - INFO - Epoch: [133][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3657 (0.3094) Acc@1 85.938 (89.218) Acc@5 99.219 (99.694)
2025-08-27 23:31:24,049 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:24,049 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:25,564 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2803 (0.2803) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:31:26,423 - INFO - Epoch 133:
2025-08-27 23:31:26,423 - INFO -   Train: acc1: 89.0860 | acc5: 99.6800 | loss: 0.3117 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:26,424 - INFO -   Val:   acc1: 87.2500 | acc5: 99.5500 | loss: 0.3712
2025-08-27 23:31:26,424 - INFO -   LR: 0.010000
2025-08-27 23:31:26,440 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-27 23:31:26,635 - INFO - Epoch: [134][0/391] Time 0.194 (0.194) Data 0.157 (0.157) Loss 0.2481 (0.2481) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:31:28,333 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:28,333 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:28,608 - INFO - Epoch: [134][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.2589 (0.3070) Acc@1 92.188 (89.349) Acc@5 100.000 (99.729)
2025-08-27 23:31:30,459 - INFO - Epoch: [134][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3052 (0.3000) Acc@1 91.406 (89.673) Acc@5 100.000 (99.743)
2025-08-27 23:31:31,332 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:31,332 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:32,329 - INFO - Epoch: [134][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4093 (0.3083) Acc@1 85.156 (89.348) Acc@5 99.219 (99.733)
2025-08-27 23:31:34,127 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2778 (0.2778) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:31:34,962 - INFO - Epoch 134:
2025-08-27 23:31:34,962 - INFO -   Train: acc1: 89.3440 | acc5: 99.7260 | loss: 0.3090 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:34,962 - INFO -   Val:   acc1: 87.0300 | acc5: 99.5300 | loss: 0.3784
2025-08-27 23:31:34,962 - INFO -   LR: 0.010000
2025-08-27 23:31:34,977 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-27 23:31:35,141 - INFO - Epoch: [135][0/391] Time 0.164 (0.164) Data 0.144 (0.144) Loss 0.3929 (0.3929) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:31:35,427 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:35,428 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:37,049 - INFO - Epoch: [135][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.3734 (0.3107) Acc@1 85.156 (89.233) Acc@5 99.219 (99.698)
2025-08-27 23:31:38,491 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:38,491 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:38,993 - INFO - Epoch: [135][200/391] Time 0.022 (0.020) Data 0.001 (0.002) Loss 0.2918 (0.3132) Acc@1 85.938 (89.136) Acc@5 100.000 (99.712)
2025-08-27 23:31:40,873 - INFO - Epoch: [135][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3459 (0.3117) Acc@1 88.281 (89.236) Acc@5 100.000 (99.714)
2025-08-27 23:31:41,510 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:41,511 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:42,679 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2939 (0.2939) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:31:43,516 - INFO - Epoch 135:
2025-08-27 23:31:43,516 - INFO -   Train: acc1: 89.2520 | acc5: 99.7080 | loss: 0.3109 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:43,516 - INFO -   Val:   acc1: 87.4500 | acc5: 99.5600 | loss: 0.3795
2025-08-27 23:31:43,516 - INFO -   LR: 0.010000
2025-08-27 23:31:43,534 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-27 23:31:43,724 - INFO - Epoch: [136][0/391] Time 0.188 (0.188) Data 0.165 (0.165) Loss 0.2444 (0.2444) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-27 23:31:45,504 - INFO - Epoch: [136][100/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.3030 (0.3246) Acc@1 88.281 (88.591) Acc@5 100.000 (99.660)
2025-08-27 23:31:45,566 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:45,566 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:47,330 - INFO - Epoch: [136][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3079 (0.3193) Acc@1 86.719 (88.779) Acc@5 99.219 (99.654)
2025-08-27 23:31:48,553 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:48,553 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:49,161 - INFO - Epoch: [136][300/391] Time 0.014 (0.019) Data 0.003 (0.002) Loss 0.3644 (0.3163) Acc@1 85.156 (88.961) Acc@5 99.219 (99.673)
2025-08-27 23:31:51,052 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3458 (0.3458) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:31:51,917 - INFO - Epoch 136:
2025-08-27 23:31:51,917 - INFO -   Train: acc1: 89.0500 | acc5: 99.6900 | loss: 0.3155 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:31:51,917 - INFO -   Val:   acc1: 86.0600 | acc5: 99.4700 | loss: 0.4248
2025-08-27 23:31:51,917 - INFO -   LR: 0.010000
2025-08-27 23:31:51,932 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-27 23:31:52,127 - INFO - Epoch: [137][0/391] Time 0.194 (0.194) Data 0.177 (0.177) Loss 0.3049 (0.3049) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:31:52,743 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:52,743 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:53,958 - INFO - Epoch: [137][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.2798 (0.3008) Acc@1 90.625 (89.465) Acc@5 100.000 (99.768)
2025-08-27 23:31:55,824 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:55,825 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:55,959 - INFO - Epoch: [137][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3011 (0.3128) Acc@1 89.844 (89.094) Acc@5 99.219 (99.674)
2025-08-27 23:31:57,822 - INFO - Epoch: [137][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4153 (0.3129) Acc@1 87.500 (89.062) Acc@5 100.000 (99.663)
2025-08-27 23:31:58,828 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:31:58,828 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:31:59,671 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2556 (0.2556) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:32:00,498 - INFO - Epoch 137:
2025-08-27 23:32:00,498 - INFO -   Train: acc1: 89.0600 | acc5: 99.6660 | loss: 0.3137 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:00,498 - INFO -   Val:   acc1: 86.8200 | acc5: 99.6300 | loss: 0.3881
2025-08-27 23:32:00,498 - INFO -   LR: 0.010000
2025-08-27 23:32:00,517 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-27 23:32:00,696 - INFO - Epoch: [138][0/391] Time 0.177 (0.177) Data 0.149 (0.149) Loss 0.3058 (0.3058) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:32:02,589 - INFO - Epoch: [138][100/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3235 (0.3086) Acc@1 88.281 (89.186) Acc@5 99.219 (99.729)
2025-08-27 23:32:02,971 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:02,972 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:04,364 - INFO - Epoch: [138][200/391] Time 0.013 (0.019) Data 0.000 (0.001) Loss 0.2827 (0.3112) Acc@1 89.062 (89.292) Acc@5 100.000 (99.708)
2025-08-27 23:32:06,007 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:06,008 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:06,363 - INFO - Epoch: [138][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2460 (0.3146) Acc@1 91.406 (89.164) Acc@5 100.000 (99.670)
2025-08-27 23:32:08,200 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2613 (0.2613) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:32:09,053 - INFO - Epoch 138:
2025-08-27 23:32:09,053 - INFO -   Train: acc1: 89.1600 | acc5: 99.6720 | loss: 0.3157 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:09,053 - INFO -   Val:   acc1: 86.6400 | acc5: 99.5500 | loss: 0.3996
2025-08-27 23:32:09,053 - INFO -   LR: 0.010000
2025-08-27 23:32:09,071 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-27 23:32:09,252 - INFO - Epoch: [139][0/391] Time 0.180 (0.180) Data 0.147 (0.147) Loss 0.4489 (0.4489) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 23:32:10,223 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:10,224 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:11,146 - INFO - Epoch: [139][100/391] Time 0.019 (0.021) Data 0.008 (0.003) Loss 0.3641 (0.3038) Acc@1 89.844 (89.488) Acc@5 100.000 (99.760)
2025-08-27 23:32:13,036 - INFO - Epoch: [139][200/391] Time 0.019 (0.020) Data 0.005 (0.002) Loss 0.2726 (0.3085) Acc@1 90.625 (89.447) Acc@5 99.219 (99.697)
2025-08-27 23:32:13,246 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:13,247 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:14,917 - INFO - Epoch: [139][300/391] Time 0.043 (0.019) Data 0.031 (0.002) Loss 0.4148 (0.3128) Acc@1 86.719 (89.200) Acc@5 100.000 (99.686)
2025-08-27 23:32:16,291 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:16,291 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:16,793 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3024 (0.3024) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:32:17,613 - INFO - Epoch 139:
2025-08-27 23:32:17,613 - INFO -   Train: acc1: 89.1280 | acc5: 99.6680 | loss: 0.3149 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:17,613 - INFO -   Val:   acc1: 86.1500 | acc5: 99.3700 | loss: 0.4181
2025-08-27 23:32:17,613 - INFO -   LR: 0.010000
2025-08-27 23:32:17,632 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-27 23:32:17,794 - INFO - Epoch: [140][0/391] Time 0.162 (0.162) Data 0.138 (0.138) Loss 0.2749 (0.2749) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:32:19,745 - INFO - Epoch: [140][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.2293 (0.3095) Acc@1 90.625 (89.240) Acc@5 100.000 (99.660)
2025-08-27 23:32:20,505 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:20,506 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:21,649 - INFO - Epoch: [140][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3609 (0.3174) Acc@1 86.719 (88.950) Acc@5 100.000 (99.642)
2025-08-27 23:32:23,539 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:23,539 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:23,564 - INFO - Epoch: [140][300/391] Time 0.030 (0.020) Data 0.000 (0.002) Loss 0.2316 (0.3162) Acc@1 92.969 (89.050) Acc@5 100.000 (99.631)
2025-08-27 23:32:25,419 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3045 (0.3045) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:32:26,236 - INFO - Epoch 140:
2025-08-27 23:32:26,236 - INFO -   Train: acc1: 89.0400 | acc5: 99.6340 | loss: 0.3164 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:26,236 - INFO -   Val:   acc1: 86.8300 | acc5: 99.4400 | loss: 0.3982
2025-08-27 23:32:26,236 - INFO -   LR: 0.010000
2025-08-27 23:32:26,305 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-27 23:32:26,511 - INFO - Epoch: [141][0/391] Time 0.205 (0.205) Data 0.185 (0.185) Loss 0.3990 (0.3990) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 23:32:27,803 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:27,803 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:28,428 - INFO - Epoch: [141][100/391] Time 0.033 (0.021) Data 0.018 (0.005) Loss 0.2734 (0.3037) Acc@1 91.406 (89.550) Acc@5 100.000 (99.598)
2025-08-27 23:32:30,269 - INFO - Epoch: [141][200/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2368 (0.3045) Acc@1 91.406 (89.498) Acc@5 99.219 (99.654)
2025-08-27 23:32:30,809 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:30,809 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:32,110 - INFO - Epoch: [141][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.2110 (0.3142) Acc@1 93.750 (89.052) Acc@5 100.000 (99.637)
2025-08-27 23:32:33,748 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:33,748 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:33,945 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3236 (0.3236) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 23:32:34,794 - INFO - Epoch 141:
2025-08-27 23:32:34,794 - INFO -   Train: acc1: 88.9380 | acc5: 99.6660 | loss: 0.3158 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:34,794 - INFO -   Val:   acc1: 86.1100 | acc5: 99.5300 | loss: 0.4085
2025-08-27 23:32:34,794 - INFO -   LR: 0.010000
2025-08-27 23:32:34,810 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-27 23:32:34,982 - INFO - Epoch: [142][0/391] Time 0.171 (0.171) Data 0.154 (0.154) Loss 0.2589 (0.2589) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:32:36,850 - INFO - Epoch: [142][100/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.3082 (0.3179) Acc@1 92.969 (89.233) Acc@5 100.000 (99.729)
2025-08-27 23:32:37,908 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:37,909 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:38,744 - INFO - Epoch: [142][200/391] Time 0.045 (0.020) Data 0.031 (0.004) Loss 0.2702 (0.3162) Acc@1 92.188 (89.199) Acc@5 100.000 (99.732)
2025-08-27 23:32:40,583 - INFO - Epoch: [142][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.3972 (0.3180) Acc@1 87.500 (89.112) Acc@5 99.219 (99.712)
2025-08-27 23:32:40,919 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:40,919 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:42,441 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.2823 (0.2823) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:32:43,263 - INFO - Epoch 142:
2025-08-27 23:32:43,263 - INFO -   Train: acc1: 89.0720 | acc5: 99.6960 | loss: 0.3189 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:43,263 - INFO -   Val:   acc1: 86.8300 | acc5: 99.5200 | loss: 0.3839
2025-08-27 23:32:43,263 - INFO -   LR: 0.010000
2025-08-27 23:32:43,279 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-27 23:32:43,468 - INFO - Epoch: [143][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.3831 (0.3831) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:32:45,022 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:45,022 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:45,293 - INFO - Epoch: [143][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2890 (0.3081) Acc@1 90.625 (89.333) Acc@5 100.000 (99.683)
2025-08-27 23:32:47,189 - INFO - Epoch: [143][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.2052 (0.3126) Acc@1 92.969 (89.164) Acc@5 100.000 (99.685)
2025-08-27 23:32:48,019 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:48,019 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:49,034 - INFO - Epoch: [143][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3934 (0.3131) Acc@1 86.719 (89.151) Acc@5 100.000 (99.709)
2025-08-27 23:32:50,835 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.3115 (0.3115) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:32:51,665 - INFO - Epoch 143:
2025-08-27 23:32:51,665 - INFO -   Train: acc1: 89.0920 | acc5: 99.7280 | loss: 0.3145 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:51,665 - INFO -   Val:   acc1: 86.7400 | acc5: 99.6000 | loss: 0.4014
2025-08-27 23:32:51,665 - INFO -   LR: 0.010000
2025-08-27 23:32:51,681 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-27 23:32:51,886 - INFO - Epoch: [144][0/391] Time 0.204 (0.204) Data 0.159 (0.159) Loss 0.3925 (0.3925) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 23:32:52,168 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:52,168 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:53,724 - INFO - Epoch: [144][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2754 (0.3099) Acc@1 89.844 (89.519) Acc@5 100.000 (99.629)
2025-08-27 23:32:55,074 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:55,088 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:55,564 - INFO - Epoch: [144][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.3666 (0.3223) Acc@1 89.844 (88.907) Acc@5 98.438 (99.635)
2025-08-27 23:32:57,398 - INFO - Epoch: [144][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2897 (0.3191) Acc@1 88.281 (89.005) Acc@5 100.000 (99.665)
2025-08-27 23:32:58,035 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:32:58,035 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:32:59,125 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3095 (0.3095) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:32:59,925 - INFO - Epoch 144:
2025-08-27 23:32:59,925 - INFO -   Train: acc1: 89.0260 | acc5: 99.6860 | loss: 0.3181 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:32:59,925 - INFO -   Val:   acc1: 86.2300 | acc5: 99.4900 | loss: 0.4138
2025-08-27 23:32:59,925 - INFO -   LR: 0.010000
2025-08-27 23:32:59,942 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-27 23:33:00,107 - INFO - Epoch: [145][0/391] Time 0.164 (0.164) Data 0.135 (0.135) Loss 0.3251 (0.3251) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:33:01,973 - INFO - Epoch: [145][100/391] Time 0.019 (0.020) Data 0.000 (0.005) Loss 0.3598 (0.3046) Acc@1 85.156 (89.387) Acc@5 99.219 (99.722)
2025-08-27 23:33:02,057 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:02,057 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:03,765 - INFO - Epoch: [145][200/391] Time 0.041 (0.019) Data 0.030 (0.004) Loss 0.2610 (0.3103) Acc@1 90.625 (89.121) Acc@5 100.000 (99.685)
2025-08-27 23:33:05,000 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:05,001 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:05,687 - INFO - Epoch: [145][300/391] Time 0.030 (0.019) Data 0.013 (0.004) Loss 0.3546 (0.3163) Acc@1 89.062 (88.891) Acc@5 100.000 (99.657)
2025-08-27 23:33:07,481 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2799 (0.2799) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:33:08,441 - INFO - Epoch 145:
2025-08-27 23:33:08,442 - INFO -   Train: acc1: 88.7400 | acc5: 99.6640 | loss: 0.3195 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:08,442 - INFO -   Val:   acc1: 86.0900 | acc5: 99.4600 | loss: 0.4242
2025-08-27 23:33:08,442 - INFO -   LR: 0.010000
2025-08-27 23:33:08,457 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-27 23:33:08,645 - INFO - Epoch: [146][0/391] Time 0.187 (0.187) Data 0.168 (0.168) Loss 0.4832 (0.4832) Acc@1 84.375 (84.375) Acc@5 96.875 (96.875)
2025-08-27 23:33:09,300 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:09,300 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:10,587 - INFO - Epoch: [146][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2147 (0.3076) Acc@1 90.625 (89.472) Acc@5 100.000 (99.722)
2025-08-27 23:33:12,300 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:12,301 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:12,411 - INFO - Epoch: [146][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2938 (0.3153) Acc@1 93.750 (89.121) Acc@5 99.219 (99.681)
2025-08-27 23:33:14,330 - INFO - Epoch: [146][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.2441 (0.3127) Acc@1 92.969 (89.138) Acc@5 99.219 (99.717)
2025-08-27 23:33:15,284 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:15,284 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:16,102 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2722 (0.2722) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:33:16,943 - INFO - Epoch 146:
2025-08-27 23:33:16,943 - INFO -   Train: acc1: 89.1040 | acc5: 99.7120 | loss: 0.3134 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:16,943 - INFO -   Val:   acc1: 87.0900 | acc5: 99.5500 | loss: 0.3859
2025-08-27 23:33:16,943 - INFO -   LR: 0.010000
2025-08-27 23:33:16,958 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-27 23:33:17,138 - INFO - Epoch: [147][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.2878 (0.2878) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:33:19,064 - INFO - Epoch: [147][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.2814 (0.3202) Acc@1 88.281 (88.916) Acc@5 100.000 (99.698)
2025-08-27 23:33:19,502 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:19,502 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:20,918 - INFO - Epoch: [147][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.3484 (0.3161) Acc@1 87.500 (89.020) Acc@5 99.219 (99.681)
2025-08-27 23:33:22,515 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:22,515 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:22,891 - INFO - Epoch: [147][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3988 (0.3176) Acc@1 89.062 (88.938) Acc@5 99.219 (99.686)
2025-08-27 23:33:24,713 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.3071 (0.3071) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:33:25,534 - INFO - Epoch 147:
2025-08-27 23:33:25,534 - INFO -   Train: acc1: 88.9440 | acc5: 99.6720 | loss: 0.3178 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:25,534 - INFO -   Val:   acc1: 85.8000 | acc5: 99.5000 | loss: 0.4185
2025-08-27 23:33:25,535 - INFO -   LR: 0.010000
2025-08-27 23:33:25,549 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-27 23:33:25,695 - INFO - Epoch: [148][0/391] Time 0.145 (0.145) Data 0.129 (0.129) Loss 0.3547 (0.3547) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:33:26,705 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:26,705 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:27,562 - INFO - Epoch: [148][100/391] Time 0.019 (0.020) Data 0.002 (0.006) Loss 0.3539 (0.3117) Acc@1 89.062 (89.302) Acc@5 99.219 (99.636)
2025-08-27 23:33:29,433 - INFO - Epoch: [148][200/391] Time 0.014 (0.019) Data 0.004 (0.004) Loss 0.3906 (0.3085) Acc@1 85.938 (89.307) Acc@5 100.000 (99.681)
2025-08-27 23:33:29,636 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:29,636 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:31,261 - INFO - Epoch: [148][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2916 (0.3130) Acc@1 88.281 (89.091) Acc@5 100.000 (99.668)
2025-08-27 23:33:32,551 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:32,551 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:33,000 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2940 (0.2940) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:33:33,842 - INFO - Epoch 148:
2025-08-27 23:33:33,842 - INFO -   Train: acc1: 88.9980 | acc5: 99.6740 | loss: 0.3164 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:33,842 - INFO -   Val:   acc1: 86.8300 | acc5: 99.4800 | loss: 0.3988
2025-08-27 23:33:33,842 - INFO -   LR: 0.010000
2025-08-27 23:33:33,859 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-27 23:33:34,049 - INFO - Epoch: [149][0/391] Time 0.189 (0.189) Data 0.162 (0.162) Loss 0.3542 (0.3542) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:33:35,873 - INFO - Epoch: [149][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.3661 (0.3076) Acc@1 88.281 (89.349) Acc@5 100.000 (99.714)
2025-08-27 23:33:36,630 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:36,630 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:37,760 - INFO - Epoch: [149][200/391] Time 0.025 (0.019) Data 0.000 (0.004) Loss 0.3705 (0.3179) Acc@1 86.719 (88.868) Acc@5 100.000 (99.701)
2025-08-27 23:33:39,546 - INFO - Epoch: [149][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2874 (0.3178) Acc@1 90.625 (88.865) Acc@5 99.219 (99.691)
2025-08-27 23:33:39,566 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:39,566 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:41,383 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3511 (0.3511) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:33:42,244 - INFO - Epoch 149:
2025-08-27 23:33:42,244 - INFO -   Train: acc1: 88.8520 | acc5: 99.6860 | loss: 0.3182 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:42,244 - INFO -   Val:   acc1: 86.5100 | acc5: 99.5100 | loss: 0.3928
2025-08-27 23:33:42,244 - INFO -   LR: 0.001000
2025-08-27 23:33:42,260 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-27 23:33:42,435 - INFO - Epoch: [150][0/391] Time 0.175 (0.175) Data 0.157 (0.157) Loss 0.3643 (0.3643) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:33:43,751 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:43,751 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:44,347 - INFO - Epoch: [150][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.2473 (0.2953) Acc@1 91.406 (89.828) Acc@5 100.000 (99.745)
2025-08-27 23:33:46,171 - INFO - Epoch: [150][200/391] Time 0.012 (0.019) Data 0.001 (0.003) Loss 0.2290 (0.2905) Acc@1 91.406 (89.894) Acc@5 100.000 (99.778)
2025-08-27 23:33:46,760 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:46,760 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:48,063 - INFO - Epoch: [150][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3061 (0.2910) Acc@1 89.844 (89.942) Acc@5 100.000 (99.751)
2025-08-27 23:33:49,710 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:49,710 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:49,879 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2778 (0.2778) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:33:50,708 - INFO - Epoch 150:
2025-08-27 23:33:50,708 - INFO -   Train: acc1: 89.9680 | acc5: 99.7380 | loss: 0.2892 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:50,709 - INFO -   Val:   acc1: 88.4100 | acc5: 99.6200 | loss: 0.3476
2025-08-27 23:33:50,709 - INFO -   LR: 0.001000
2025-08-27 23:33:50,794 - INFO - Checkpoint saved: epoch=150, metric=88.4100
2025-08-27 23:33:50,827 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-27 23:33:50,994 - INFO - Epoch: [151][0/391] Time 0.166 (0.166) Data 0.144 (0.144) Loss 0.2488 (0.2488) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:33:52,841 - INFO - Epoch: [151][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2136 (0.2738) Acc@1 92.188 (90.656) Acc@5 100.000 (99.752)
2025-08-27 23:33:53,867 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:53,867 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:54,678 - INFO - Epoch: [151][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.3640 (0.2770) Acc@1 89.844 (90.493) Acc@5 99.219 (99.747)
2025-08-27 23:33:56,496 - INFO - Epoch: [151][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2403 (0.2747) Acc@1 91.406 (90.586) Acc@5 100.000 (99.772)
2025-08-27 23:33:56,840 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:33:56,841 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:33:58,281 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2742 (0.2742) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:33:59,095 - INFO - Epoch 151:
2025-08-27 23:33:59,095 - INFO -   Train: acc1: 90.4260 | acc5: 99.7620 | loss: 0.2771 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:33:59,095 - INFO -   Val:   acc1: 88.4900 | acc5: 99.6700 | loss: 0.3441
2025-08-27 23:33:59,095 - INFO -   LR: 0.001000
2025-08-27 23:33:59,145 - INFO - Checkpoint saved: epoch=151, metric=88.4900
2025-08-27 23:33:59,176 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-27 23:33:59,363 - INFO - Epoch: [152][0/391] Time 0.185 (0.185) Data 0.161 (0.161) Loss 0.3050 (0.3050) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:34:01,110 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:01,110 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:01,363 - INFO - Epoch: [152][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.3015 (0.2810) Acc@1 89.062 (90.285) Acc@5 100.000 (99.714)
2025-08-27 23:34:03,302 - INFO - Epoch: [152][200/391] Time 0.023 (0.021) Data 0.000 (0.002) Loss 0.3456 (0.2784) Acc@1 88.281 (90.473) Acc@5 98.438 (99.771)
2025-08-27 23:34:04,162 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:04,162 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:05,244 - INFO - Epoch: [152][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.2211 (0.2779) Acc@1 92.969 (90.443) Acc@5 100.000 (99.751)
2025-08-27 23:34:07,027 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2648 (0.2648) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:34:07,852 - INFO - Epoch 152:
2025-08-27 23:34:07,852 - INFO -   Train: acc1: 90.3960 | acc5: 99.7660 | loss: 0.2773 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:07,852 - INFO -   Val:   acc1: 88.5300 | acc5: 99.6500 | loss: 0.3445
2025-08-27 23:34:07,852 - INFO -   LR: 0.001000
2025-08-27 23:34:07,903 - INFO - Checkpoint saved: epoch=152, metric=88.5300
2025-08-27 23:34:07,936 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-27 23:34:08,128 - INFO - Epoch: [153][0/391] Time 0.191 (0.191) Data 0.168 (0.168) Loss 0.3702 (0.3702) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 23:34:08,456 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:08,456 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:10,154 - INFO - Epoch: [153][100/391] Time 0.024 (0.022) Data 0.004 (0.003) Loss 0.2521 (0.2706) Acc@1 91.406 (90.903) Acc@5 100.000 (99.783)
2025-08-27 23:34:11,651 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:11,651 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:12,096 - INFO - Epoch: [153][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.2524 (0.2703) Acc@1 89.844 (90.769) Acc@5 100.000 (99.778)
2025-08-27 23:34:14,026 - INFO - Epoch: [153][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1715 (0.2725) Acc@1 95.312 (90.661) Acc@5 100.000 (99.756)
2025-08-27 23:34:14,689 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:14,689 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:15,754 - INFO - Test: [0/79] Time 0.107 (0.107) Loss 0.2748 (0.2748) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:34:16,824 - INFO - Epoch 153:
2025-08-27 23:34:16,824 - INFO -   Train: acc1: 90.6400 | acc5: 99.7480 | loss: 0.2728 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:16,824 - INFO -   Val:   acc1: 88.5300 | acc5: 99.6700 | loss: 0.3431
2025-08-27 23:34:16,824 - INFO -   LR: 0.001000
2025-08-27 23:34:16,841 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-27 23:34:17,032 - INFO - Epoch: [154][0/391] Time 0.190 (0.190) Data 0.153 (0.153) Loss 0.2308 (0.2308) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-27 23:34:18,913 - INFO - Epoch: [154][100/391] Time 0.020 (0.020) Data 0.009 (0.003) Loss 0.3656 (0.2693) Acc@1 89.062 (90.888) Acc@5 98.438 (99.768)
2025-08-27 23:34:19,009 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:19,010 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:20,782 - INFO - Epoch: [154][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2887 (0.2738) Acc@1 92.188 (90.812) Acc@5 100.000 (99.786)
2025-08-27 23:34:22,025 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:22,025 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:22,679 - INFO - Epoch: [154][300/391] Time 0.026 (0.019) Data 0.000 (0.002) Loss 0.3384 (0.2725) Acc@1 88.281 (90.680) Acc@5 99.219 (99.790)
2025-08-27 23:34:24,533 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2728 (0.2728) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:34:25,400 - INFO - Epoch 154:
2025-08-27 23:34:25,400 - INFO -   Train: acc1: 90.6700 | acc5: 99.7800 | loss: 0.2735 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:25,400 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6800 | loss: 0.3441
2025-08-27 23:34:25,400 - INFO -   LR: 0.001000
2025-08-27 23:34:25,452 - INFO - Checkpoint saved: epoch=154, metric=88.6000
2025-08-27 23:34:25,487 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-27 23:34:25,660 - INFO - Epoch: [155][0/391] Time 0.172 (0.172) Data 0.146 (0.146) Loss 0.2616 (0.2616) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-27 23:34:26,325 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:26,325 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:27,632 - INFO - Epoch: [155][100/391] Time 0.011 (0.021) Data 0.000 (0.002) Loss 0.2352 (0.2758) Acc@1 90.625 (90.602) Acc@5 100.000 (99.838)
2025-08-27 23:34:29,277 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:29,277 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:29,368 - INFO - Epoch: [155][200/391] Time 0.027 (0.019) Data 0.004 (0.002) Loss 0.3214 (0.2689) Acc@1 89.062 (90.823) Acc@5 100.000 (99.821)
2025-08-27 23:34:31,321 - INFO - Epoch: [155][300/391] Time 0.020 (0.019) Data 0.000 (0.001) Loss 0.2899 (0.2691) Acc@1 90.625 (90.830) Acc@5 99.219 (99.772)
2025-08-27 23:34:32,303 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:32,303 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:33,093 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2748 (0.2748) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:34:33,946 - INFO - Epoch 155:
2025-08-27 23:34:33,946 - INFO -   Train: acc1: 90.7100 | acc5: 99.7740 | loss: 0.2722 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:33,946 - INFO -   Val:   acc1: 88.6100 | acc5: 99.7000 | loss: 0.3409
2025-08-27 23:34:33,946 - INFO -   LR: 0.001000
2025-08-27 23:34:33,997 - INFO - Checkpoint saved: epoch=155, metric=88.6100
2025-08-27 23:34:34,028 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-27 23:34:34,204 - INFO - Epoch: [156][0/391] Time 0.175 (0.175) Data 0.136 (0.136) Loss 0.2574 (0.2574) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:34:36,120 - INFO - Epoch: [156][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.2757 (0.2790) Acc@1 92.969 (90.602) Acc@5 100.000 (99.830)
2025-08-27 23:34:36,585 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:36,585 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:38,001 - INFO - Epoch: [156][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2798 (0.2711) Acc@1 86.719 (90.882) Acc@5 100.000 (99.825)
2025-08-27 23:34:39,593 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:39,594 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:39,907 - INFO - Epoch: [156][300/391] Time 0.027 (0.020) Data 0.000 (0.003) Loss 0.2042 (0.2721) Acc@1 94.531 (90.773) Acc@5 100.000 (99.808)
2025-08-27 23:34:41,664 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2787 (0.2787) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:34:42,506 - INFO - Epoch 156:
2025-08-27 23:34:42,507 - INFO -   Train: acc1: 90.8960 | acc5: 99.7920 | loss: 0.2691 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:42,507 - INFO -   Val:   acc1: 88.5200 | acc5: 99.6400 | loss: 0.3441
2025-08-27 23:34:42,507 - INFO -   LR: 0.001000
2025-08-27 23:34:42,525 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-27 23:34:42,718 - INFO - Epoch: [157][0/391] Time 0.192 (0.192) Data 0.168 (0.168) Loss 0.3031 (0.3031) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:34:43,624 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:43,624 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:44,534 - INFO - Epoch: [157][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.2161 (0.2696) Acc@1 92.969 (90.756) Acc@5 100.000 (99.752)
2025-08-27 23:34:46,349 - INFO - Epoch: [157][200/391] Time 0.030 (0.019) Data 0.019 (0.003) Loss 0.2528 (0.2726) Acc@1 89.844 (90.473) Acc@5 100.000 (99.802)
2025-08-27 23:34:46,604 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:46,604 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:48,260 - INFO - Epoch: [157][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2768 (0.2733) Acc@1 90.625 (90.446) Acc@5 100.000 (99.800)
2025-08-27 23:34:49,538 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:49,538 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:50,013 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2755 (0.2755) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:34:50,862 - INFO - Epoch 157:
2025-08-27 23:34:50,862 - INFO -   Train: acc1: 90.6260 | acc5: 99.7780 | loss: 0.2702 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:50,862 - INFO -   Val:   acc1: 88.6500 | acc5: 99.7000 | loss: 0.3387
2025-08-27 23:34:50,862 - INFO -   LR: 0.001000
2025-08-27 23:34:50,912 - INFO - Checkpoint saved: epoch=157, metric=88.6500
2025-08-27 23:34:50,943 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-27 23:34:51,105 - INFO - Epoch: [158][0/391] Time 0.161 (0.161) Data 0.132 (0.132) Loss 0.2407 (0.2407) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:34:52,944 - INFO - Epoch: [158][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.3399 (0.2851) Acc@1 86.719 (90.300) Acc@5 100.000 (99.737)
2025-08-27 23:34:53,705 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:53,705 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:54,789 - INFO - Epoch: [158][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.2575 (0.2776) Acc@1 89.844 (90.508) Acc@5 100.000 (99.751)
2025-08-27 23:34:56,622 - INFO - Epoch: [158][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.1969 (0.2691) Acc@1 89.844 (90.796) Acc@5 100.000 (99.748)
2025-08-27 23:34:56,659 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:34:56,659 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:34:58,490 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2747 (0.2747) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:34:59,317 - INFO - Epoch 158:
2025-08-27 23:34:59,317 - INFO -   Train: acc1: 90.7740 | acc5: 99.7380 | loss: 0.2688 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:34:59,317 - INFO -   Val:   acc1: 88.5600 | acc5: 99.6400 | loss: 0.3407
2025-08-27 23:34:59,317 - INFO -   LR: 0.001000
2025-08-27 23:34:59,333 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-27 23:34:59,505 - INFO - Epoch: [159][0/391] Time 0.171 (0.171) Data 0.137 (0.137) Loss 0.3063 (0.3063) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:35:00,777 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:00,777 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:01,339 - INFO - Epoch: [159][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2930 (0.2667) Acc@1 91.406 (90.873) Acc@5 99.219 (99.745)
2025-08-27 23:35:03,273 - INFO - Epoch: [159][200/391] Time 0.031 (0.020) Data 0.016 (0.004) Loss 0.1931 (0.2653) Acc@1 94.531 (90.893) Acc@5 100.000 (99.778)
2025-08-27 23:35:03,827 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:03,827 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:05,054 - INFO - Epoch: [159][300/391] Time 0.016 (0.019) Data 0.004 (0.003) Loss 0.3850 (0.2662) Acc@1 88.281 (90.929) Acc@5 99.219 (99.782)
2025-08-27 23:35:06,981 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2633 (0.2633) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:35:07,820 - INFO - Epoch 159:
2025-08-27 23:35:07,820 - INFO -   Train: acc1: 90.9480 | acc5: 99.7880 | loss: 0.2668 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:07,820 - INFO -   Val:   acc1: 88.6100 | acc5: 99.7000 | loss: 0.3417
2025-08-27 23:35:07,820 - INFO -   LR: 0.001000
2025-08-27 23:35:07,838 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-27 23:35:08,026 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:08,026 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:08,043 - INFO - Epoch: [160][0/391] Time 0.204 (0.204) Data 0.176 (0.176) Loss 0.2222 (0.2222) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:35:10,070 - INFO - Epoch: [160][100/391] Time 0.011 (0.022) Data 0.000 (0.003) Loss 0.1989 (0.2585) Acc@1 93.750 (91.259) Acc@5 100.000 (99.737)
2025-08-27 23:35:11,156 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:11,157 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:12,006 - INFO - Epoch: [160][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.2910 (0.2684) Acc@1 88.281 (90.850) Acc@5 100.000 (99.778)
2025-08-27 23:35:13,899 - INFO - Epoch: [160][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2520 (0.2700) Acc@1 90.625 (90.812) Acc@5 100.000 (99.782)
2025-08-27 23:35:14,262 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:14,262 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:15,680 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2636 (0.2636) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:35:16,518 - INFO - Epoch 160:
2025-08-27 23:35:16,518 - INFO -   Train: acc1: 90.8580 | acc5: 99.7840 | loss: 0.2685 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:16,518 - INFO -   Val:   acc1: 88.6600 | acc5: 99.7000 | loss: 0.3391
2025-08-27 23:35:16,518 - INFO -   LR: 0.001000
2025-08-27 23:35:16,570 - INFO - Checkpoint saved: epoch=160, metric=88.6600
2025-08-27 23:35:16,603 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-27 23:35:16,792 - INFO - Epoch: [161][0/391] Time 0.188 (0.188) Data 0.157 (0.157) Loss 0.2971 (0.2971) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:35:18,577 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:18,577 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:18,817 - INFO - Epoch: [161][100/391] Time 0.020 (0.022) Data 0.000 (0.002) Loss 0.2887 (0.2645) Acc@1 88.281 (90.842) Acc@5 100.000 (99.807)
2025-08-27 23:35:20,849 - INFO - Epoch: [161][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.1806 (0.2638) Acc@1 90.625 (90.862) Acc@5 100.000 (99.782)
2025-08-27 23:35:21,843 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:21,843 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:22,809 - INFO - Epoch: [161][300/391] Time 0.023 (0.021) Data 0.000 (0.002) Loss 0.2496 (0.2655) Acc@1 91.406 (90.801) Acc@5 100.000 (99.769)
2025-08-27 23:35:24,633 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2690 (0.2690) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:35:25,481 - INFO - Epoch 161:
2025-08-27 23:35:25,482 - INFO -   Train: acc1: 90.7660 | acc5: 99.7600 | loss: 0.2659 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:25,482 - INFO -   Val:   acc1: 88.7700 | acc5: 99.6600 | loss: 0.3403
2025-08-27 23:35:25,482 - INFO -   LR: 0.001000
2025-08-27 23:35:25,537 - INFO - Checkpoint saved: epoch=161, metric=88.7700
2025-08-27 23:35:25,569 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-27 23:35:25,768 - INFO - Epoch: [162][0/391] Time 0.198 (0.198) Data 0.177 (0.177) Loss 0.2301 (0.2301) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:35:26,119 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:26,119 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:27,713 - INFO - Epoch: [162][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.2918 (0.2634) Acc@1 90.625 (91.066) Acc@5 100.000 (99.752)
2025-08-27 23:35:29,176 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:29,176 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:29,602 - INFO - Epoch: [162][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2083 (0.2640) Acc@1 93.750 (90.815) Acc@5 100.000 (99.712)
2025-08-27 23:35:31,466 - INFO - Epoch: [162][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2742 (0.2673) Acc@1 88.281 (90.760) Acc@5 100.000 (99.748)
2025-08-27 23:35:32,179 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:32,180 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:33,284 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2621 (0.2621) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:35:34,136 - INFO - Epoch 162:
2025-08-27 23:35:34,136 - INFO -   Train: acc1: 90.8020 | acc5: 99.7660 | loss: 0.2672 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:34,137 - INFO -   Val:   acc1: 88.5200 | acc5: 99.6900 | loss: 0.3410
2025-08-27 23:35:34,137 - INFO -   LR: 0.001000
2025-08-27 23:35:34,155 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-27 23:35:34,335 - INFO - Epoch: [163][0/391] Time 0.179 (0.179) Data 0.147 (0.147) Loss 0.3032 (0.3032) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:35:36,242 - INFO - Epoch: [163][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2820 (0.2637) Acc@1 92.969 (90.826) Acc@5 99.219 (99.814)
2025-08-27 23:35:36,382 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:36,382 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:38,195 - INFO - Epoch: [163][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1751 (0.2647) Acc@1 95.312 (90.784) Acc@5 100.000 (99.837)
2025-08-27 23:35:39,513 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:39,513 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:40,072 - INFO - Epoch: [163][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2202 (0.2691) Acc@1 92.969 (90.698) Acc@5 100.000 (99.795)
2025-08-27 23:35:41,875 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2528 (0.2528) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:35:42,714 - INFO - Epoch 163:
2025-08-27 23:35:42,714 - INFO -   Train: acc1: 90.7660 | acc5: 99.7820 | loss: 0.2671 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:42,714 - INFO -   Val:   acc1: 88.6000 | acc5: 99.7000 | loss: 0.3410
2025-08-27 23:35:42,714 - INFO -   LR: 0.001000
2025-08-27 23:35:42,733 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-27 23:35:42,923 - INFO - Epoch: [164][0/391] Time 0.189 (0.189) Data 0.170 (0.170) Loss 0.3516 (0.3516) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:35:43,532 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:43,532 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:44,688 - INFO - Epoch: [164][100/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.3755 (0.2695) Acc@1 88.281 (90.517) Acc@5 100.000 (99.830)
2025-08-27 23:35:46,559 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:46,560 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:46,648 - INFO - Epoch: [164][200/391] Time 0.021 (0.019) Data 0.010 (0.005) Loss 0.3043 (0.2684) Acc@1 85.938 (90.718) Acc@5 100.000 (99.778)
2025-08-27 23:35:48,569 - INFO - Epoch: [164][300/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.2558 (0.2649) Acc@1 92.188 (90.807) Acc@5 100.000 (99.785)
2025-08-27 23:35:49,596 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:49,596 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:50,354 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2612 (0.2612) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:35:51,165 - INFO - Epoch 164:
2025-08-27 23:35:51,165 - INFO -   Train: acc1: 90.7820 | acc5: 99.7640 | loss: 0.2651 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:51,165 - INFO -   Val:   acc1: 88.5800 | acc5: 99.6900 | loss: 0.3419
2025-08-27 23:35:51,165 - INFO -   LR: 0.001000
2025-08-27 23:35:51,181 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-27 23:35:51,362 - INFO - Epoch: [165][0/391] Time 0.181 (0.181) Data 0.163 (0.163) Loss 0.3468 (0.3468) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:35:53,163 - INFO - Epoch: [165][100/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2957 (0.2709) Acc@1 90.625 (90.571) Acc@5 100.000 (99.760)
2025-08-27 23:35:53,623 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:53,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:55,039 - INFO - Epoch: [165][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.3165 (0.2638) Acc@1 89.844 (90.897) Acc@5 100.000 (99.790)
2025-08-27 23:35:56,559 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:35:56,560 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:35:56,820 - INFO - Epoch: [165][300/391] Time 0.035 (0.019) Data 0.019 (0.002) Loss 0.2215 (0.2622) Acc@1 92.188 (91.009) Acc@5 100.000 (99.787)
2025-08-27 23:35:58,624 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2644 (0.2644) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:35:59,443 - INFO - Epoch 165:
2025-08-27 23:35:59,443 - INFO -   Train: acc1: 90.9860 | acc5: 99.7800 | loss: 0.2643 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:35:59,443 - INFO -   Val:   acc1: 88.6900 | acc5: 99.6900 | loss: 0.3413
2025-08-27 23:35:59,443 - INFO -   LR: 0.001000
2025-08-27 23:35:59,460 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-27 23:35:59,642 - INFO - Epoch: [166][0/391] Time 0.181 (0.181) Data 0.158 (0.158) Loss 0.2485 (0.2485) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:36:00,624 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:00,624 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:01,451 - INFO - Epoch: [166][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2172 (0.2600) Acc@1 93.750 (90.973) Acc@5 99.219 (99.783)
2025-08-27 23:36:03,296 - INFO - Epoch: [166][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3133 (0.2619) Acc@1 89.062 (90.955) Acc@5 100.000 (99.778)
2025-08-27 23:36:03,544 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:03,545 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:05,134 - INFO - Epoch: [166][300/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.1860 (0.2615) Acc@1 92.969 (90.991) Acc@5 100.000 (99.790)
2025-08-27 23:36:06,463 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:06,463 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:06,930 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2570 (0.2570) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:36:07,748 - INFO - Epoch 166:
2025-08-27 23:36:07,748 - INFO -   Train: acc1: 91.0000 | acc5: 99.7740 | loss: 0.2632 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:07,748 - INFO -   Val:   acc1: 88.7400 | acc5: 99.6400 | loss: 0.3412
2025-08-27 23:36:07,748 - INFO -   LR: 0.001000
2025-08-27 23:36:07,768 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-27 23:36:07,954 - INFO - Epoch: [167][0/391] Time 0.184 (0.184) Data 0.161 (0.161) Loss 0.2777 (0.2777) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:36:09,796 - INFO - Epoch: [167][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2154 (0.2680) Acc@1 95.312 (90.919) Acc@5 99.219 (99.783)
2025-08-27 23:36:10,531 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:10,532 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:11,604 - INFO - Epoch: [167][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2533 (0.2643) Acc@1 88.281 (91.037) Acc@5 100.000 (99.778)
2025-08-27 23:36:13,433 - INFO - Epoch: [167][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.2127 (0.2633) Acc@1 94.531 (90.975) Acc@5 100.000 (99.790)
2025-08-27 23:36:13,487 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:13,487 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:15,238 - INFO - Test: [0/79] Time 0.107 (0.107) Loss 0.2573 (0.2573) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:36:16,071 - INFO - Epoch 167:
2025-08-27 23:36:16,071 - INFO -   Train: acc1: 90.9380 | acc5: 99.7860 | loss: 0.2636 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:16,071 - INFO -   Val:   acc1: 88.7200 | acc5: 99.6900 | loss: 0.3397
2025-08-27 23:36:16,071 - INFO -   LR: 0.001000
2025-08-27 23:36:16,087 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-27 23:36:16,275 - INFO - Epoch: [168][0/391] Time 0.188 (0.188) Data 0.168 (0.168) Loss 0.3127 (0.3127) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:36:17,536 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:17,537 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:18,085 - INFO - Epoch: [168][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2474 (0.2586) Acc@1 92.188 (91.166) Acc@5 100.000 (99.776)
2025-08-27 23:36:19,964 - INFO - Epoch: [168][200/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.2353 (0.2617) Acc@1 90.625 (91.123) Acc@5 100.000 (99.759)
2025-08-27 23:36:20,528 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:20,528 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:21,796 - INFO - Epoch: [168][300/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.2487 (0.2629) Acc@1 91.406 (90.991) Acc@5 100.000 (99.766)
2025-08-27 23:36:23,620 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2644 (0.2644) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:36:24,447 - INFO - Epoch 168:
2025-08-27 23:36:24,447 - INFO -   Train: acc1: 90.9580 | acc5: 99.7640 | loss: 0.2637 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:24,447 - INFO -   Val:   acc1: 88.8100 | acc5: 99.6600 | loss: 0.3408
2025-08-27 23:36:24,447 - INFO -   LR: 0.001000
2025-08-27 23:36:24,498 - INFO - Checkpoint saved: epoch=168, metric=88.8100
2025-08-27 23:36:24,529 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-27 23:36:24,685 - INFO - Epoch: [169][0/391] Time 0.155 (0.155) Data 0.134 (0.134) Loss 0.3325 (0.3325) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:36:24,691 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:24,691 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:26,579 - INFO - Epoch: [169][100/391] Time 0.032 (0.020) Data 0.017 (0.003) Loss 0.2773 (0.2629) Acc@1 91.406 (90.903) Acc@5 98.438 (99.799)
2025-08-27 23:36:27,687 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:27,687 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:28,368 - INFO - Epoch: [169][200/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.2284 (0.2648) Acc@1 91.406 (90.963) Acc@5 100.000 (99.829)
2025-08-27 23:36:30,258 - INFO - Epoch: [169][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3270 (0.2633) Acc@1 87.500 (90.898) Acc@5 100.000 (99.824)
2025-08-27 23:36:30,664 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:30,664 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:32,123 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2531 (0.2531) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:36:32,963 - INFO - Epoch 169:
2025-08-27 23:36:32,963 - INFO -   Train: acc1: 90.8640 | acc5: 99.8080 | loss: 0.2649 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:32,963 - INFO -   Val:   acc1: 88.7900 | acc5: 99.6700 | loss: 0.3404
2025-08-27 23:36:32,963 - INFO -   LR: 0.001000
2025-08-27 23:36:32,980 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-27 23:36:33,134 - INFO - Epoch: [170][0/391] Time 0.153 (0.153) Data 0.133 (0.133) Loss 0.3750 (0.3750) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:36:34,794 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:34,794 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:34,994 - INFO - Epoch: [170][100/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2720 (0.2638) Acc@1 92.969 (90.695) Acc@5 100.000 (99.737)
2025-08-27 23:36:36,837 - INFO - Epoch: [170][200/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.2041 (0.2640) Acc@1 93.750 (90.897) Acc@5 100.000 (99.743)
2025-08-27 23:36:37,809 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:37,809 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:38,759 - INFO - Epoch: [170][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.2062 (0.2649) Acc@1 92.969 (90.830) Acc@5 99.219 (99.756)
2025-08-27 23:36:40,588 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2606 (0.2606) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:36:41,437 - INFO - Epoch 170:
2025-08-27 23:36:41,437 - INFO -   Train: acc1: 90.9160 | acc5: 99.7700 | loss: 0.2641 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:41,437 - INFO -   Val:   acc1: 88.6800 | acc5: 99.6900 | loss: 0.3416
2025-08-27 23:36:41,437 - INFO -   LR: 0.001000
2025-08-27 23:36:41,488 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-27 23:36:41,677 - INFO - Epoch: [171][0/391] Time 0.189 (0.189) Data 0.168 (0.168) Loss 0.2341 (0.2341) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:36:42,057 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:42,057 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:43,752 - INFO - Epoch: [171][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.2883 (0.2591) Acc@1 90.625 (91.236) Acc@5 100.000 (99.822)
2025-08-27 23:36:45,350 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:45,351 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:45,742 - INFO - Epoch: [171][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.4370 (0.2608) Acc@1 81.250 (91.010) Acc@5 98.438 (99.806)
2025-08-27 23:36:47,734 - INFO - Epoch: [171][300/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.2196 (0.2600) Acc@1 92.188 (91.048) Acc@5 99.219 (99.798)
2025-08-27 23:36:48,530 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:48,531 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:49,681 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2820 (0.2820) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:36:50,506 - INFO - Epoch 171:
2025-08-27 23:36:50,506 - INFO -   Train: acc1: 90.9400 | acc5: 99.7880 | loss: 0.2625 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:50,506 - INFO -   Val:   acc1: 88.5100 | acc5: 99.6900 | loss: 0.3446
2025-08-27 23:36:50,506 - INFO -   LR: 0.001000
2025-08-27 23:36:50,524 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-27 23:36:50,703 - INFO - Epoch: [172][0/391] Time 0.179 (0.179) Data 0.157 (0.157) Loss 0.2936 (0.2936) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:36:52,573 - INFO - Epoch: [172][100/391] Time 0.022 (0.020) Data 0.002 (0.004) Loss 0.3128 (0.2562) Acc@1 89.844 (91.244) Acc@5 99.219 (99.830)
2025-08-27 23:36:52,716 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:52,717 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:54,454 - INFO - Epoch: [172][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2144 (0.2577) Acc@1 91.406 (91.185) Acc@5 100.000 (99.813)
2025-08-27 23:36:55,670 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:55,670 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:36:56,330 - INFO - Epoch: [172][300/391] Time 0.029 (0.019) Data 0.000 (0.002) Loss 0.2007 (0.2609) Acc@1 94.531 (91.131) Acc@5 100.000 (99.803)
2025-08-27 23:36:58,168 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2567 (0.2567) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:36:59,017 - INFO - Epoch 172:
2025-08-27 23:36:59,017 - INFO -   Train: acc1: 91.1280 | acc5: 99.7960 | loss: 0.2604 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:36:59,017 - INFO -   Val:   acc1: 88.6500 | acc5: 99.6900 | loss: 0.3419
2025-08-27 23:36:59,017 - INFO -   LR: 0.001000
2025-08-27 23:36:59,038 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-27 23:36:59,229 - INFO - Epoch: [173][0/391] Time 0.190 (0.190) Data 0.165 (0.165) Loss 0.3234 (0.3234) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:36:59,859 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:36:59,859 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:01,097 - INFO - Epoch: [173][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3489 (0.2547) Acc@1 84.375 (91.151) Acc@5 100.000 (99.838)
2025-08-27 23:37:02,869 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:02,870 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:02,944 - INFO - Epoch: [173][200/391] Time 0.017 (0.019) Data 0.001 (0.002) Loss 0.2470 (0.2567) Acc@1 89.062 (91.080) Acc@5 100.000 (99.825)
2025-08-27 23:37:04,814 - INFO - Epoch: [173][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.2087 (0.2600) Acc@1 93.750 (91.038) Acc@5 100.000 (99.803)
2025-08-27 23:37:05,852 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:05,852 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:06,654 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2557 (0.2557) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:37:07,476 - INFO - Epoch 173:
2025-08-27 23:37:07,477 - INFO -   Train: acc1: 90.9920 | acc5: 99.7900 | loss: 0.2621 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:37:07,477 - INFO -   Val:   acc1: 88.7800 | acc5: 99.6900 | loss: 0.3443
2025-08-27 23:37:07,477 - INFO -   LR: 0.001000
2025-08-27 23:37:08,925 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-27 23:37:09,103 - INFO - Epoch: [174][0/391] Time 0.177 (0.177) Data 0.148 (0.148) Loss 0.2620 (0.2620) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 23:37:10,943 - INFO - Epoch: [174][100/391] Time 0.027 (0.020) Data 0.013 (0.003) Loss 0.3062 (0.2657) Acc@1 88.281 (91.004) Acc@5 100.000 (99.760)
2025-08-27 23:37:11,405 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:11,405 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:12,845 - INFO - Epoch: [174][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.2186 (0.2631) Acc@1 92.188 (90.971) Acc@5 100.000 (99.775)
2025-08-27 23:37:14,401 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:14,401 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:14,711 - INFO - Epoch: [174][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1702 (0.2649) Acc@1 95.312 (90.890) Acc@5 100.000 (99.774)
2025-08-27 23:37:16,481 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2633 (0.2633) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:37:17,351 - INFO - Epoch 174:
2025-08-27 23:37:17,351 - INFO -   Train: acc1: 90.8040 | acc5: 99.7700 | loss: 0.2665 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:37:17,351 - INFO -   Val:   acc1: 88.8100 | acc5: 99.7000 | loss: 0.3386
2025-08-27 23:37:17,351 - INFO -   LR: 0.001000
2025-08-27 23:37:17,370 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-27 23:37:17,556 - INFO - Epoch: [175][0/391] Time 0.185 (0.185) Data 0.154 (0.154) Loss 0.3900 (0.3900) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:37:18,574 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:18,575 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:19,419 - INFO - Epoch: [175][100/391] Time 0.028 (0.020) Data 0.016 (0.003) Loss 0.2030 (0.2597) Acc@1 94.531 (90.965) Acc@5 100.000 (99.791)
2025-08-27 23:37:21,276 - INFO - Epoch: [175][200/391] Time 0.011 (0.019) Data 0.001 (0.003) Loss 0.2495 (0.2615) Acc@1 89.062 (90.854) Acc@5 100.000 (99.790)
2025-08-27 23:37:21,557 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:21,557 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:23,132 - INFO - Epoch: [175][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2678 (0.2618) Acc@1 90.625 (90.879) Acc@5 99.219 (99.769)
2025-08-27 23:37:24,496 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:24,498 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:24,913 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2578 (0.2578) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:37:25,743 - INFO - Epoch 175:
2025-08-27 23:37:25,743 - INFO -   Train: acc1: 90.8620 | acc5: 99.7640 | loss: 0.2626 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:37:25,743 - INFO -   Val:   acc1: 88.7400 | acc5: 99.7200 | loss: 0.3395
2025-08-27 23:37:25,743 - INFO -   LR: 0.001000
2025-08-27 23:37:25,759 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-27 23:37:25,958 - INFO - Epoch: [176][0/391] Time 0.198 (0.198) Data 0.155 (0.155) Loss 0.2571 (0.2571) Acc@1 92.188 (92.188) Acc@5 98.438 (98.438)
2025-08-27 23:37:27,787 - INFO - Epoch: [176][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.2236 (0.2599) Acc@1 92.969 (91.190) Acc@5 100.000 (99.822)
2025-08-27 23:37:28,566 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:28,567 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:29,636 - INFO - Epoch: [176][200/391] Time 0.025 (0.019) Data 0.012 (0.004) Loss 0.2282 (0.2586) Acc@1 92.188 (91.173) Acc@5 100.000 (99.798)
2025-08-27 23:37:31,512 - INFO - Epoch: [176][300/391] Time 0.029 (0.019) Data 0.014 (0.004) Loss 0.2928 (0.2618) Acc@1 88.281 (90.908) Acc@5 100.000 (99.813)
2025-08-27 23:37:31,576 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:31,576 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:33,305 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2539 (0.2539) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:37:34,126 - INFO - Epoch 176:
2025-08-27 23:37:34,126 - INFO -   Train: acc1: 90.9100 | acc5: 99.8140 | loss: 0.2620 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:37:34,126 - INFO -   Val:   acc1: 88.7400 | acc5: 99.7200 | loss: 0.3418
2025-08-27 23:37:34,126 - INFO -   LR: 0.001000
2025-08-27 23:37:34,143 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-27 23:37:34,334 - INFO - Epoch: [177][0/391] Time 0.189 (0.189) Data 0.169 (0.169) Loss 0.1713 (0.1713) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:37:35,664 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:35,664 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:36,187 - INFO - Epoch: [177][100/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2142 (0.2599) Acc@1 92.188 (91.027) Acc@5 100.000 (99.768)
2025-08-27 23:37:38,006 - INFO - Epoch: [177][200/391] Time 0.033 (0.019) Data 0.000 (0.002) Loss 0.1753 (0.2590) Acc@1 93.750 (91.142) Acc@5 100.000 (99.771)
2025-08-27 23:37:38,666 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:38,666 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:40,014 - INFO - Epoch: [177][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.3448 (0.2608) Acc@1 85.938 (91.105) Acc@5 98.438 (99.779)
2025-08-27 23:37:41,924 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2520 (0.2520) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:37:42,761 - INFO - Epoch 177:
2025-08-27 23:37:42,761 - INFO -   Train: acc1: 91.0840 | acc5: 99.7860 | loss: 0.2601 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:37:42,761 - INFO -   Val:   acc1: 88.7600 | acc5: 99.6800 | loss: 0.3420
2025-08-27 23:37:42,761 - INFO -   LR: 0.001000
2025-08-27 23:37:42,780 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-27 23:37:42,958 - INFO - Epoch: [178][0/391] Time 0.178 (0.178) Data 0.156 (0.156) Loss 0.1655 (0.1655) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:37:42,987 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:42,988 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:44,819 - INFO - Epoch: [178][100/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2189 (0.2612) Acc@1 94.531 (91.120) Acc@5 100.000 (99.760)
2025-08-27 23:37:45,928 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:45,928 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:46,711 - INFO - Epoch: [178][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2654 (0.2659) Acc@1 94.531 (90.940) Acc@5 99.219 (99.736)
2025-08-27 23:37:48,668 - INFO - Epoch: [178][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2737 (0.2603) Acc@1 92.188 (91.136) Acc@5 99.219 (99.782)
2025-08-27 23:37:49,099 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:49,099 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:50,582 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.2605 (0.2605) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:37:51,422 - INFO - Epoch 178:
2025-08-27 23:37:51,422 - INFO -   Train: acc1: 91.0840 | acc5: 99.7880 | loss: 0.2598 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:37:51,422 - INFO -   Val:   acc1: 88.5800 | acc5: 99.6700 | loss: 0.3448
2025-08-27 23:37:51,422 - INFO -   LR: 0.001000
2025-08-27 23:37:51,439 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-27 23:37:51,629 - INFO - Epoch: [179][0/391] Time 0.189 (0.189) Data 0.172 (0.172) Loss 0.2602 (0.2602) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:37:53,340 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:53,341 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:53,540 - INFO - Epoch: [179][100/391] Time 0.028 (0.021) Data 0.000 (0.003) Loss 0.2805 (0.2658) Acc@1 89.062 (90.610) Acc@5 100.000 (99.776)
2025-08-27 23:37:55,427 - INFO - Epoch: [179][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3267 (0.2598) Acc@1 86.719 (90.928) Acc@5 100.000 (99.790)
2025-08-27 23:37:56,405 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:37:56,405 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:37:57,382 - INFO - Epoch: [179][300/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.1925 (0.2608) Acc@1 93.750 (91.001) Acc@5 100.000 (99.777)
2025-08-27 23:37:59,224 - INFO - Test: [0/79] Time 0.108 (0.108) Loss 0.2552 (0.2552) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:38:00,076 - INFO - Epoch 179:
2025-08-27 23:38:00,076 - INFO -   Train: acc1: 91.0000 | acc5: 99.7840 | loss: 0.2610 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:00,076 - INFO -   Val:   acc1: 88.5200 | acc5: 99.6800 | loss: 0.3423
2025-08-27 23:38:00,076 - INFO -   LR: 0.001000
2025-08-27 23:38:00,097 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-27 23:38:00,277 - INFO - Epoch: [180][0/391] Time 0.179 (0.179) Data 0.135 (0.135) Loss 0.3616 (0.3616) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:38:00,675 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:00,675 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:02,192 - INFO - Epoch: [180][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.2624 (0.2612) Acc@1 89.844 (91.182) Acc@5 100.000 (99.698)
2025-08-27 23:38:03,724 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:03,724 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:04,108 - INFO - Epoch: [180][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2634 (0.2631) Acc@1 89.844 (90.924) Acc@5 100.000 (99.724)
2025-08-27 23:38:05,969 - INFO - Epoch: [180][300/391] Time 0.019 (0.019) Data 0.000 (0.001) Loss 0.3494 (0.2618) Acc@1 88.281 (90.923) Acc@5 100.000 (99.743)
2025-08-27 23:38:06,735 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:06,735 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:07,816 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2535 (0.2535) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:38:08,653 - INFO - Epoch 180:
2025-08-27 23:38:08,654 - INFO -   Train: acc1: 90.9700 | acc5: 99.7680 | loss: 0.2621 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:08,654 - INFO -   Val:   acc1: 88.8000 | acc5: 99.6700 | loss: 0.3390
2025-08-27 23:38:08,654 - INFO -   LR: 0.001000
2025-08-27 23:38:08,707 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-27 23:38:08,885 - INFO - Epoch: [181][0/391] Time 0.177 (0.177) Data 0.160 (0.160) Loss 0.3215 (0.3215) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:38:10,787 - INFO - Epoch: [181][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.2885 (0.2596) Acc@1 92.188 (91.066) Acc@5 100.000 (99.868)
2025-08-27 23:38:10,940 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:10,940 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:12,623 - INFO - Epoch: [181][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2876 (0.2566) Acc@1 90.625 (91.146) Acc@5 99.219 (99.829)
2025-08-27 23:38:13,904 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:13,904 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:14,487 - INFO - Epoch: [181][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2811 (0.2597) Acc@1 90.625 (91.077) Acc@5 98.438 (99.798)
2025-08-27 23:38:16,323 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2553 (0.2553) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:38:17,189 - INFO - Epoch 181:
2025-08-27 23:38:17,190 - INFO -   Train: acc1: 90.9880 | acc5: 99.7960 | loss: 0.2618 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:17,190 - INFO -   Val:   acc1: 88.9600 | acc5: 99.7100 | loss: 0.3425
2025-08-27 23:38:17,190 - INFO -   LR: 0.001000
2025-08-27 23:38:17,244 - INFO - Checkpoint saved: epoch=181, metric=88.9600
2025-08-27 23:38:17,276 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-27 23:38:17,440 - INFO - Epoch: [182][0/391] Time 0.163 (0.163) Data 0.133 (0.133) Loss 0.2513 (0.2513) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:38:18,171 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:18,171 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:19,319 - INFO - Epoch: [182][100/391] Time 0.026 (0.020) Data 0.013 (0.002) Loss 0.1322 (0.2582) Acc@1 97.656 (91.089) Acc@5 100.000 (99.822)
2025-08-27 23:38:21,115 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:21,115 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:21,151 - INFO - Epoch: [182][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2412 (0.2554) Acc@1 91.406 (91.115) Acc@5 100.000 (99.810)
2025-08-27 23:38:23,043 - INFO - Epoch: [182][300/391] Time 0.017 (0.019) Data 0.000 (0.001) Loss 0.1934 (0.2602) Acc@1 92.969 (90.916) Acc@5 100.000 (99.798)
2025-08-27 23:38:24,082 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:24,082 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:24,811 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2508 (0.2508) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:38:25,633 - INFO - Epoch 182:
2025-08-27 23:38:25,633 - INFO -   Train: acc1: 90.9180 | acc5: 99.8120 | loss: 0.2599 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:25,633 - INFO -   Val:   acc1: 88.7300 | acc5: 99.6600 | loss: 0.3410
2025-08-27 23:38:25,633 - INFO -   LR: 0.001000
2025-08-27 23:38:25,652 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-27 23:38:25,839 - INFO - Epoch: [183][0/391] Time 0.186 (0.186) Data 0.153 (0.153) Loss 0.2328 (0.2328) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:38:27,720 - INFO - Epoch: [183][100/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2859 (0.2626) Acc@1 89.844 (91.120) Acc@5 99.219 (99.760)
2025-08-27 23:38:28,223 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:28,223 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:29,608 - INFO - Epoch: [183][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1969 (0.2621) Acc@1 92.188 (90.955) Acc@5 99.219 (99.806)
2025-08-27 23:38:31,145 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:31,145 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:31,430 - INFO - Epoch: [183][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.2399 (0.2601) Acc@1 92.188 (91.014) Acc@5 100.000 (99.803)
2025-08-27 23:38:33,355 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2498 (0.2498) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:38:34,241 - INFO - Epoch 183:
2025-08-27 23:38:34,241 - INFO -   Train: acc1: 91.0180 | acc5: 99.7800 | loss: 0.2604 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:34,242 - INFO -   Val:   acc1: 88.9700 | acc5: 99.7000 | loss: 0.3374
2025-08-27 23:38:34,242 - INFO -   LR: 0.001000
2025-08-27 23:38:34,295 - INFO - Checkpoint saved: epoch=183, metric=88.9700
2025-08-27 23:38:34,329 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-27 23:38:34,515 - INFO - Epoch: [184][0/391] Time 0.185 (0.185) Data 0.158 (0.158) Loss 0.2893 (0.2893) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 23:38:35,643 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:35,643 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:36,444 - INFO - Epoch: [184][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.2839 (0.2639) Acc@1 92.188 (90.579) Acc@5 100.000 (99.830)
2025-08-27 23:38:38,396 - INFO - Epoch: [184][200/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.2151 (0.2628) Acc@1 94.531 (90.792) Acc@5 100.000 (99.798)
2025-08-27 23:38:38,686 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:38,687 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:40,289 - INFO - Epoch: [184][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2995 (0.2611) Acc@1 90.625 (90.900) Acc@5 99.219 (99.795)
2025-08-27 23:38:41,726 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:41,727 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:42,129 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2596 (0.2596) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:38:42,951 - INFO - Epoch 184:
2025-08-27 23:38:42,951 - INFO -   Train: acc1: 90.8380 | acc5: 99.7980 | loss: 0.2621 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:42,951 - INFO -   Val:   acc1: 88.8300 | acc5: 99.7200 | loss: 0.3404
2025-08-27 23:38:42,951 - INFO -   LR: 0.001000
2025-08-27 23:38:42,971 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-27 23:38:43,146 - INFO - Epoch: [185][0/391] Time 0.174 (0.174) Data 0.158 (0.158) Loss 0.3923 (0.3923) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 23:38:45,045 - INFO - Epoch: [185][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.2205 (0.2559) Acc@1 92.188 (91.143) Acc@5 99.219 (99.807)
2025-08-27 23:38:45,910 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:45,910 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:46,948 - INFO - Epoch: [185][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2436 (0.2573) Acc@1 91.406 (91.181) Acc@5 100.000 (99.810)
2025-08-27 23:38:48,771 - INFO - Epoch: [185][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3143 (0.2582) Acc@1 89.844 (91.225) Acc@5 99.219 (99.795)
2025-08-27 23:38:48,844 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:48,844 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:50,548 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2507 (0.2507) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:38:51,410 - INFO - Epoch 185:
2025-08-27 23:38:51,411 - INFO -   Train: acc1: 91.1940 | acc5: 99.8040 | loss: 0.2587 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:51,411 - INFO -   Val:   acc1: 88.5900 | acc5: 99.6900 | loss: 0.3413
2025-08-27 23:38:51,411 - INFO -   LR: 0.001000
2025-08-27 23:38:51,430 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-27 23:38:51,633 - INFO - Epoch: [186][0/391] Time 0.203 (0.203) Data 0.162 (0.162) Loss 0.2429 (0.2429) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:38:53,022 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:53,022 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:53,520 - INFO - Epoch: [186][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.2316 (0.2591) Acc@1 90.625 (91.081) Acc@5 99.219 (99.776)
2025-08-27 23:38:55,410 - INFO - Epoch: [186][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2692 (0.2587) Acc@1 89.844 (91.157) Acc@5 99.219 (99.782)
2025-08-27 23:38:56,034 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:38:56,035 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:38:57,280 - INFO - Epoch: [186][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.1704 (0.2587) Acc@1 96.094 (91.095) Acc@5 99.219 (99.795)
2025-08-27 23:38:59,102 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2432 (0.2432) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:38:59,910 - INFO - Epoch 186:
2025-08-27 23:38:59,910 - INFO -   Train: acc1: 91.0440 | acc5: 99.7900 | loss: 0.2606 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:38:59,910 - INFO -   Val:   acc1: 88.8700 | acc5: 99.6800 | loss: 0.3385
2025-08-27 23:38:59,910 - INFO -   LR: 0.001000
2025-08-27 23:38:59,929 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-27 23:39:00,105 - INFO - Epoch: [187][0/391] Time 0.175 (0.175) Data 0.158 (0.158) Loss 0.2354 (0.2354) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:39:00,186 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:00,186 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:02,143 - INFO - Epoch: [187][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.3443 (0.2555) Acc@1 90.625 (91.375) Acc@5 100.000 (99.791)
2025-08-27 23:39:03,405 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:03,406 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:04,183 - INFO - Epoch: [187][200/391] Time 0.025 (0.021) Data 0.007 (0.002) Loss 0.2897 (0.2589) Acc@1 90.625 (91.266) Acc@5 100.000 (99.813)
2025-08-27 23:39:06,188 - INFO - Epoch: [187][300/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.1898 (0.2583) Acc@1 92.969 (91.201) Acc@5 100.000 (99.824)
2025-08-27 23:39:06,635 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:06,635 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:08,124 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2595 (0.2595) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:39:08,938 - INFO - Epoch 187:
2025-08-27 23:39:08,938 - INFO -   Train: acc1: 91.0880 | acc5: 99.8080 | loss: 0.2602 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:39:08,938 - INFO -   Val:   acc1: 88.9900 | acc5: 99.7000 | loss: 0.3370
2025-08-27 23:39:08,939 - INFO -   LR: 0.001000
2025-08-27 23:39:08,994 - INFO - Checkpoint saved: epoch=187, metric=88.9900
2025-08-27 23:39:09,026 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-27 23:39:09,195 - INFO - Epoch: [188][0/391] Time 0.169 (0.169) Data 0.148 (0.148) Loss 0.2046 (0.2046) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:39:10,953 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:10,953 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:11,111 - INFO - Epoch: [188][100/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.3141 (0.2606) Acc@1 89.062 (91.089) Acc@5 98.438 (99.814)
2025-08-27 23:39:12,965 - INFO - Epoch: [188][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2496 (0.2640) Acc@1 91.406 (90.847) Acc@5 100.000 (99.817)
2025-08-27 23:39:13,965 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:13,966 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:14,955 - INFO - Epoch: [188][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.2581 (0.2611) Acc@1 89.844 (90.952) Acc@5 99.219 (99.818)
2025-08-27 23:39:16,804 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2402 (0.2402) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:39:17,653 - INFO - Epoch 188:
2025-08-27 23:39:17,653 - INFO -   Train: acc1: 90.9320 | acc5: 99.8140 | loss: 0.2615 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:39:17,654 - INFO -   Val:   acc1: 88.7200 | acc5: 99.7000 | loss: 0.3383
2025-08-27 23:39:17,654 - INFO -   LR: 0.001000
2025-08-27 23:39:17,674 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-27 23:39:17,834 - INFO - Epoch: [189][0/391] Time 0.160 (0.160) Data 0.139 (0.139) Loss 0.1968 (0.1968) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:39:18,223 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:18,225 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:19,828 - INFO - Epoch: [189][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3153 (0.2587) Acc@1 87.500 (91.027) Acc@5 100.000 (99.752)
2025-08-27 23:39:21,431 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:21,432 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:21,802 - INFO - Epoch: [189][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2180 (0.2597) Acc@1 92.969 (90.951) Acc@5 99.219 (99.759)
2025-08-27 23:39:23,851 - INFO - Epoch: [189][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.2316 (0.2586) Acc@1 93.750 (91.014) Acc@5 99.219 (99.766)
2025-08-27 23:39:24,627 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:24,627 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:25,708 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2491 (0.2491) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:39:26,559 - INFO - Epoch 189:
2025-08-27 23:39:26,559 - INFO -   Train: acc1: 90.9620 | acc5: 99.7720 | loss: 0.2599 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:39:26,559 - INFO -   Val:   acc1: 88.7600 | acc5: 99.6700 | loss: 0.3382
2025-08-27 23:39:26,559 - INFO -   LR: 0.001000
2025-08-27 23:39:26,579 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-27 23:39:26,764 - INFO - Epoch: [190][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.2661 (0.2661) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:39:28,702 - INFO - Epoch: [190][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3282 (0.2742) Acc@1 92.188 (90.625) Acc@5 99.219 (99.752)
2025-08-27 23:39:28,888 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:28,890 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:30,551 - INFO - Epoch: [190][200/391] Time 0.028 (0.020) Data 0.006 (0.003) Loss 0.2398 (0.2697) Acc@1 89.062 (90.730) Acc@5 100.000 (99.751)
2025-08-27 23:39:31,906 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:31,906 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:32,452 - INFO - Epoch: [190][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2498 (0.2657) Acc@1 90.625 (90.866) Acc@5 100.000 (99.764)
2025-08-27 23:39:34,371 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2361 (0.2361) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:39:35,199 - INFO - Epoch 190:
2025-08-27 23:39:35,199 - INFO -   Train: acc1: 90.9660 | acc5: 99.7700 | loss: 0.2641 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:39:35,199 - INFO -   Val:   acc1: 88.9600 | acc5: 99.6900 | loss: 0.3382
2025-08-27 23:39:35,199 - INFO -   LR: 0.001000
2025-08-27 23:39:35,255 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-27 23:39:35,445 - INFO - Epoch: [191][0/391] Time 0.189 (0.189) Data 0.156 (0.156) Loss 0.2427 (0.2427) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:39:36,240 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:36,240 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:37,464 - INFO - Epoch: [191][100/391] Time 0.024 (0.022) Data 0.013 (0.003) Loss 0.2561 (0.2547) Acc@1 91.406 (91.429) Acc@5 100.000 (99.783)
2025-08-27 23:39:39,356 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:39,356 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:39,386 - INFO - Epoch: [191][200/391] Time 0.017 (0.021) Data 0.001 (0.002) Loss 0.2926 (0.2564) Acc@1 89.062 (91.336) Acc@5 100.000 (99.782)
2025-08-27 23:39:41,312 - INFO - Epoch: [191][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.2850 (0.2537) Acc@1 89.062 (91.373) Acc@5 100.000 (99.772)
2025-08-27 23:39:42,427 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:42,427 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:43,143 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2397 (0.2397) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:39:43,977 - INFO - Epoch 191:
2025-08-27 23:39:43,977 - INFO -   Train: acc1: 91.1620 | acc5: 99.7720 | loss: 0.2585 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:39:43,977 - INFO -   Val:   acc1: 88.6800 | acc5: 99.7000 | loss: 0.3420
2025-08-27 23:39:43,977 - INFO -   LR: 0.001000
2025-08-27 23:39:43,996 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-27 23:39:44,182 - INFO - Epoch: [192][0/391] Time 0.185 (0.185) Data 0.157 (0.157) Loss 0.2406 (0.2406) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:39:46,077 - INFO - Epoch: [192][100/391] Time 0.026 (0.021) Data 0.015 (0.002) Loss 0.1858 (0.2576) Acc@1 94.531 (91.128) Acc@5 100.000 (99.783)
2025-08-27 23:39:46,590 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:46,590 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:47,958 - INFO - Epoch: [192][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3124 (0.2581) Acc@1 89.062 (91.181) Acc@5 100.000 (99.782)
2025-08-27 23:39:49,635 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:49,635 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:49,879 - INFO - Epoch: [192][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2207 (0.2585) Acc@1 91.406 (91.144) Acc@5 100.000 (99.787)
2025-08-27 23:39:51,717 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2230 (0.2230) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:39:52,582 - INFO - Epoch 192:
2025-08-27 23:39:52,583 - INFO -   Train: acc1: 91.0060 | acc5: 99.7800 | loss: 0.2615 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:39:52,583 - INFO -   Val:   acc1: 88.7200 | acc5: 99.6500 | loss: 0.3406
2025-08-27 23:39:52,583 - INFO -   LR: 0.001000
2025-08-27 23:39:52,603 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-27 23:39:52,804 - INFO - Epoch: [193][0/391] Time 0.200 (0.200) Data 0.172 (0.172) Loss 0.3536 (0.3536) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:39:53,993 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:53,993 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:54,873 - INFO - Epoch: [193][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.2338 (0.2562) Acc@1 90.625 (91.050) Acc@5 100.000 (99.814)
2025-08-27 23:39:56,740 - INFO - Epoch: [193][200/391] Time 0.027 (0.021) Data 0.013 (0.002) Loss 0.3224 (0.2589) Acc@1 88.281 (91.064) Acc@5 99.219 (99.778)
2025-08-27 23:39:57,006 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:39:57,006 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:39:58,647 - INFO - Epoch: [193][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2819 (0.2595) Acc@1 89.844 (91.071) Acc@5 100.000 (99.766)
2025-08-27 23:40:00,067 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:00,067 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:00,459 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2436 (0.2436) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:40:01,308 - INFO - Epoch 193:
2025-08-27 23:40:01,308 - INFO -   Train: acc1: 91.0440 | acc5: 99.7700 | loss: 0.2610 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:01,309 - INFO -   Val:   acc1: 88.8400 | acc5: 99.6600 | loss: 0.3368
2025-08-27 23:40:01,309 - INFO -   LR: 0.001000
2025-08-27 23:40:01,326 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-27 23:40:01,516 - INFO - Epoch: [194][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.2173 (0.2173) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:40:03,445 - INFO - Epoch: [194][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1941 (0.2577) Acc@1 92.969 (91.313) Acc@5 100.000 (99.783)
2025-08-27 23:40:04,285 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:04,285 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:05,249 - INFO - Epoch: [194][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2856 (0.2582) Acc@1 91.406 (91.344) Acc@5 100.000 (99.759)
2025-08-27 23:40:07,152 - INFO - Epoch: [194][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2358 (0.2586) Acc@1 90.625 (91.139) Acc@5 100.000 (99.766)
2025-08-27 23:40:07,231 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:07,231 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:09,033 - INFO - Test: [0/79] Time 0.164 (0.164) Loss 0.2385 (0.2385) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:40:09,872 - INFO - Epoch 194:
2025-08-27 23:40:09,872 - INFO -   Train: acc1: 91.1120 | acc5: 99.7920 | loss: 0.2588 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:09,872 - INFO -   Val:   acc1: 88.7600 | acc5: 99.7000 | loss: 0.3430
2025-08-27 23:40:09,873 - INFO -   LR: 0.001000
2025-08-27 23:40:09,892 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-27 23:40:10,066 - INFO - Epoch: [195][0/391] Time 0.173 (0.173) Data 0.145 (0.145) Loss 0.2205 (0.2205) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:40:11,515 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:11,515 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:12,011 - INFO - Epoch: [195][100/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.1846 (0.2580) Acc@1 93.750 (91.236) Acc@5 100.000 (99.760)
2025-08-27 23:40:13,899 - INFO - Epoch: [195][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2807 (0.2587) Acc@1 91.406 (91.216) Acc@5 100.000 (99.786)
2025-08-27 23:40:14,537 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:14,537 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:15,807 - INFO - Epoch: [195][300/391] Time 0.015 (0.020) Data 0.000 (0.001) Loss 0.2439 (0.2597) Acc@1 92.188 (91.100) Acc@5 100.000 (99.774)
2025-08-27 23:40:17,657 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2444 (0.2444) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:40:18,475 - INFO - Epoch 195:
2025-08-27 23:40:18,475 - INFO -   Train: acc1: 91.0120 | acc5: 99.7900 | loss: 0.2604 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:18,475 - INFO -   Val:   acc1: 88.9400 | acc5: 99.7000 | loss: 0.3382
2025-08-27 23:40:18,475 - INFO -   LR: 0.001000
2025-08-27 23:40:18,493 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-27 23:40:18,629 - INFO - Epoch: [196][0/391] Time 0.135 (0.135) Data 0.114 (0.114) Loss 0.2976 (0.2976) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:40:18,744 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:18,744 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:20,630 - INFO - Epoch: [196][100/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.2244 (0.2652) Acc@1 91.406 (90.741) Acc@5 100.000 (99.822)
2025-08-27 23:40:21,822 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:21,822 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:22,518 - INFO - Epoch: [196][200/391] Time 0.036 (0.020) Data 0.012 (0.002) Loss 0.2114 (0.2623) Acc@1 92.188 (90.979) Acc@5 100.000 (99.778)
2025-08-27 23:40:24,444 - INFO - Epoch: [196][300/391] Time 0.025 (0.020) Data 0.010 (0.002) Loss 0.2418 (0.2621) Acc@1 91.406 (90.960) Acc@5 100.000 (99.787)
2025-08-27 23:40:24,845 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:24,845 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:26,287 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2444 (0.2444) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:40:27,151 - INFO - Epoch 196:
2025-08-27 23:40:27,151 - INFO -   Train: acc1: 91.0160 | acc5: 99.7860 | loss: 0.2615 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:27,151 - INFO -   Val:   acc1: 88.7800 | acc5: 99.7000 | loss: 0.3422
2025-08-27 23:40:27,151 - INFO -   LR: 0.001000
2025-08-27 23:40:27,171 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-27 23:40:27,343 - INFO - Epoch: [197][0/391] Time 0.171 (0.171) Data 0.144 (0.144) Loss 0.1953 (0.1953) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:40:29,192 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:29,193 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:29,319 - INFO - Epoch: [197][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.3629 (0.2642) Acc@1 87.500 (90.896) Acc@5 99.219 (99.752)
2025-08-27 23:40:31,147 - INFO - Epoch: [197][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2605 (0.2586) Acc@1 91.406 (91.029) Acc@5 100.000 (99.794)
2025-08-27 23:40:32,108 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:32,108 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:32,957 - INFO - Epoch: [197][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2229 (0.2572) Acc@1 93.750 (91.105) Acc@5 100.000 (99.787)
2025-08-27 23:40:34,851 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2397 (0.2397) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:40:35,670 - INFO - Epoch 197:
2025-08-27 23:40:35,671 - INFO -   Train: acc1: 91.1960 | acc5: 99.7840 | loss: 0.2557 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:35,671 - INFO -   Val:   acc1: 88.8100 | acc5: 99.6700 | loss: 0.3404
2025-08-27 23:40:35,671 - INFO -   LR: 0.001000
2025-08-27 23:40:35,688 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-27 23:40:35,882 - INFO - Epoch: [198][0/391] Time 0.193 (0.193) Data 0.166 (0.166) Loss 0.1978 (0.1978) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:40:36,262 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:36,263 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:37,739 - INFO - Epoch: [198][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2170 (0.2575) Acc@1 92.188 (91.012) Acc@5 100.000 (99.822)
2025-08-27 23:40:39,272 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:39,272 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:39,637 - INFO - Epoch: [198][200/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.3529 (0.2650) Acc@1 85.156 (90.800) Acc@5 100.000 (99.782)
2025-08-27 23:40:41,557 - INFO - Epoch: [198][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.2216 (0.2617) Acc@1 94.531 (90.908) Acc@5 100.000 (99.779)
2025-08-27 23:40:42,258 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:42,258 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:43,283 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.2426 (0.2426) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:40:44,142 - INFO - Epoch 198:
2025-08-27 23:40:44,142 - INFO -   Train: acc1: 91.0040 | acc5: 99.7980 | loss: 0.2599 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:44,142 - INFO -   Val:   acc1: 88.7400 | acc5: 99.7200 | loss: 0.3400
2025-08-27 23:40:44,142 - INFO -   LR: 0.001000
2025-08-27 23:40:44,161 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-27 23:40:44,340 - INFO - Epoch: [199][0/391] Time 0.173 (0.173) Data 0.142 (0.142) Loss 0.2057 (0.2057) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:40:46,148 - INFO - Epoch: [199][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2696 (0.2606) Acc@1 90.625 (90.702) Acc@5 99.219 (99.807)
2025-08-27 23:40:46,330 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:46,330 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:47,951 - INFO - Epoch: [199][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2502 (0.2563) Acc@1 92.188 (91.014) Acc@5 100.000 (99.813)
2025-08-27 23:40:49,344 - INFO - Pruning info: sparsity=0.950
2025-08-27 23:40:49,345 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:40:49,900 - INFO - Epoch: [199][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.3265 (0.2580) Acc@1 89.062 (91.027) Acc@5 98.438 (99.795)
2025-08-27 23:40:51,787 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2420 (0.2420) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:40:52,617 - INFO - Epoch 199:
2025-08-27 23:40:52,617 - INFO -   Train: acc1: 91.0160 | acc5: 99.7920 | loss: 0.2598 | sparsity: 0.9500 | reactivation_rate: 0.0000
2025-08-27 23:40:52,617 - INFO -   Val:   acc1: 88.8400 | acc5: 99.7200 | loss: 0.3394
2025-08-27 23:40:52,617 - INFO -   LR: 0.001000
2025-08-27 23:40:52,636 - INFO - training time: 00h 28m 36.70s
2025-08-27 23:40:52,637 - INFO - 
Training completed!
2025-08-27 23:40:52,637 - INFO - Best accuracy: 88.9900
2025-08-27 23:40:52,637 - INFO - Total training time: 0.48 hours
2025-08-27 23:40:52,637 - INFO - total_experiment time: 00h 28m 37.96s
2025-08-27 23:40:52,638 - INFO - Experiment completed successfully
2025-08-27 23:40:52,638 - INFO - Total time: 0.48 hours
