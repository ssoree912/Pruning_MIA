2025-08-27 16:57:30,797 - INFO - Starting experiment: dpf_sparsity0.5_seed42
2025-08-27 16:57:30,798 - INFO - Save directory: ./runs/dpf/sparsity0.5/seed42
2025-08-27 16:57:30,798 - INFO - Hyperparameters:
2025-08-27 16:57:30,798 - INFO -   name: dpf_sparsity0.5_seed42
2025-08-27 16:57:30,798 - INFO -   description: DPF pruning 50% (seed=42)
2025-08-27 16:57:30,798 - INFO -   save_dir: ./runs
2025-08-27 16:57:30,798 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 16:57:30,798 - INFO -   model: {'arch': 'resnet', 'layers': 18, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 16:57:30,798 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 16:57:30,798 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.5, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 16:57:30,798 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 16:57:30,798 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 16:57:30,832 - INFO - System Information:
2025-08-27 16:57:30,833 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 16:57:30,833 - INFO -   python_version: 3.9.18
2025-08-27 16:57:30,833 - INFO -   pytorch_version: 2.1.0
2025-08-27 16:57:30,833 - INFO -   cuda_available: True
2025-08-27 16:57:30,833 - INFO -   cpu_count: 4
2025-08-27 16:57:30,833 - INFO -   memory_total_gb: 11.0
2025-08-27 16:57:30,833 - INFO -   timestamp: 1756281450.8325288
2025-08-27 16:57:30,833 - INFO -   cuda_version: 11.8
2025-08-27 16:57:30,833 - INFO -   gpu_count: 1
2025-08-27 16:57:30,833 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 16:57:30,839 - INFO - Starting experiment: dpf_sparsity0.5_seed42
2025-08-27 16:57:30,839 - INFO - Model: resnet-18
2025-08-27 16:57:30,839 - INFO - Dataset: cifar10
2025-08-27 16:57:30,839 - INFO - Pruning: dpf (50.00%)
2025-08-27 18:15:25,982 - INFO - Starting experiment: dpf_sparsity0.5_seed42
2025-08-27 18:15:25,982 - INFO - Save directory: ./runs/dpf/sparsity0.5/seed42
2025-08-27 18:15:25,982 - INFO - Hyperparameters:
2025-08-27 18:15:25,983 - INFO -   name: dpf_sparsity0.5_seed42
2025-08-27 18:15:25,983 - INFO -   description: DPF pruning 50% (seed=42)
2025-08-27 18:15:25,983 - INFO -   save_dir: ./runs
2025-08-27 18:15:25,983 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 18:15:25,983 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 18:15:25,983 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 18:15:25,983 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.5, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 18:15:25,983 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 18:15:25,983 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 18:15:26,035 - INFO - System Information:
2025-08-27 18:15:26,036 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 18:15:26,036 - INFO -   python_version: 3.9.18
2025-08-27 18:15:26,036 - INFO -   pytorch_version: 2.1.0
2025-08-27 18:15:26,036 - INFO -   cuda_available: True
2025-08-27 18:15:26,036 - INFO -   cpu_count: 4
2025-08-27 18:15:26,036 - INFO -   memory_total_gb: 11.0
2025-08-27 18:15:26,036 - INFO -   timestamp: 1756286126.0355778
2025-08-27 18:15:26,036 - INFO -   cuda_version: 11.8
2025-08-27 18:15:26,036 - INFO -   gpu_count: 1
2025-08-27 18:15:26,036 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 18:15:26,042 - INFO - Starting experiment: dpf_sparsity0.5_seed42
2025-08-27 18:15:26,042 - INFO - Model: resnet-20
2025-08-27 18:15:26,042 - INFO - Dataset: cifar10
2025-08-27 18:15:26,042 - INFO - Pruning: dpf (50.00%)
2025-08-27 18:15:26,206 - INFO - Model Information:
2025-08-27 18:15:26,206 - INFO -   Type: pruned
2025-08-27 18:15:26,207 - INFO -   Total parameters: 544,948
2025-08-27 18:15:26,207 - INFO -   Trainable parameters: 274,692
2025-08-27 18:15:26,207 - INFO -   Sparsity: 50.00%
2025-08-27 18:15:27,190 - INFO - Starting training...
2025-08-27 18:15:27,190 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 18:15:28,119 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:15:28,120 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:15:28,624 - INFO - Epoch: [0][0/391] Time 1.433 (1.433) Data 0.648 (0.648) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 18:15:30,583 - INFO - Epoch: [0][100/391] Time 0.017 (0.034) Data 0.000 (0.008) Loss 1.7709 (1.9203) Acc@1 32.812 (26.269) Acc@5 88.281 (81.389)
2025-08-27 18:15:31,743 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:15:31,744 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:15:32,464 - INFO - Epoch: [0][200/391] Time 0.021 (0.026) Data 0.000 (0.004) Loss 1.4679 (1.7693) Acc@1 47.656 (32.525) Acc@5 92.188 (85.576)
2025-08-27 18:15:34,443 - INFO - Epoch: [0][300/391] Time 0.022 (0.024) Data 0.000 (0.003) Loss 1.3276 (1.6625) Acc@1 51.562 (37.316) Acc@5 93.750 (87.887)
2025-08-27 18:15:34,806 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:15:34,807 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:15:36,446 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 1.3799 (1.3799) Acc@1 52.344 (52.344) Acc@5 93.750 (93.750)
2025-08-27 18:15:37,362 - INFO - Epoch 0:
2025-08-27 18:15:37,362 - INFO -   Train: acc1: 40.7480 | acc5: 89.2540 | loss: 1.5805 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 18:15:37,362 - INFO -   Val:   acc1: 51.7500 | acc5: 94.4700 | loss: 1.3873
2025-08-27 18:15:37,362 - INFO -   LR: 0.100000
2025-08-27 18:15:37,409 - INFO - Checkpoint saved: epoch=0, metric=51.7500
2025-08-27 18:15:37,440 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 18:15:37,641 - INFO - Epoch: [1][0/391] Time 0.201 (0.201) Data 0.174 (0.174) Loss 1.4228 (1.4228) Acc@1 47.656 (47.656) Acc@5 90.625 (90.625)
2025-08-27 18:15:39,335 - INFO - Pruning info: sparsity=0.020
2025-08-27 18:15:39,335 - INFO -   Reactivation rate: 0.0067
2025-08-27 18:15:39,571 - INFO - Epoch: [1][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 1.1420 (1.1806) Acc@1 57.031 (57.580) Acc@5 95.312 (95.096)
2025-08-27 18:15:41,492 - INFO - Epoch: [1][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.9447 (1.1415) Acc@1 68.750 (59.091) Acc@5 97.656 (95.526)
2025-08-27 18:15:42,487 - INFO - Pruning info: sparsity=0.020
2025-08-27 18:15:42,487 - INFO -   Reactivation rate: 0.0044
2025-08-27 18:15:43,586 - INFO - Epoch: [1][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.9442 (1.1039) Acc@1 64.062 (60.395) Acc@5 97.656 (95.852)
2025-08-27 18:15:45,519 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.9420 (0.9420) Acc@1 63.281 (63.281) Acc@5 100.000 (100.000)
2025-08-27 18:15:46,430 - INFO - Epoch 1:
2025-08-27 18:15:46,431 - INFO -   Train: acc1: 61.5500 | acc5: 96.0940 | loss: 1.0752 | sparsity: 0.0197 | reactivation_rate: 0.0053
2025-08-27 18:15:46,431 - INFO -   Val:   acc1: 61.5500 | acc5: 96.4500 | loss: 1.0722
2025-08-27 18:15:46,431 - INFO -   LR: 0.100000
2025-08-27 18:15:46,472 - INFO - Checkpoint saved: epoch=1, metric=61.5500
2025-08-27 18:15:46,510 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 18:15:46,687 - INFO - Epoch: [2][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.8902 (0.8902) Acc@1 67.969 (67.969) Acc@5 96.875 (96.875)
2025-08-27 18:15:47,061 - INFO - Pruning info: sparsity=0.039
2025-08-27 18:15:47,061 - INFO -   Reactivation rate: 0.0112
2025-08-27 18:15:48,622 - INFO - Epoch: [2][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.8217 (0.9444) Acc@1 72.656 (66.460) Acc@5 97.656 (96.983)
2025-08-27 18:15:50,137 - INFO - Pruning info: sparsity=0.039
2025-08-27 18:15:50,137 - INFO -   Reactivation rate: 0.0056
2025-08-27 18:15:50,594 - INFO - Epoch: [2][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.8124 (0.9054) Acc@1 69.531 (67.771) Acc@5 98.438 (97.442)
2025-08-27 18:15:52,525 - INFO - Epoch: [2][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.8385 (0.8944) Acc@1 68.750 (68.405) Acc@5 100.000 (97.537)
2025-08-27 18:15:53,265 - INFO - Pruning info: sparsity=0.039
2025-08-27 18:15:53,266 - INFO -   Reactivation rate: 0.0044
2025-08-27 18:15:54,392 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.9718 (0.9718) Acc@1 69.531 (69.531) Acc@5 96.875 (96.875)
2025-08-27 18:15:55,271 - INFO - Epoch 2:
2025-08-27 18:15:55,271 - INFO -   Train: acc1: 69.1240 | acc5: 97.6100 | loss: 0.8743 | sparsity: 0.0389 | reactivation_rate: 0.0058
2025-08-27 18:15:55,271 - INFO -   Val:   acc1: 64.6600 | acc5: 96.6600 | loss: 1.0882
2025-08-27 18:15:55,271 - INFO -   LR: 0.100000
2025-08-27 18:15:55,314 - INFO - Checkpoint saved: epoch=2, metric=64.6600
2025-08-27 18:15:55,345 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 18:15:55,527 - INFO - Epoch: [3][0/391] Time 0.181 (0.181) Data 0.152 (0.152) Loss 0.8248 (0.8248) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-27 18:15:57,445 - INFO - Epoch: [3][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.8495 (0.7676) Acc@1 67.969 (73.739) Acc@5 98.438 (98.082)
2025-08-27 18:15:57,583 - INFO - Pruning info: sparsity=0.058
2025-08-27 18:15:57,584 - INFO -   Reactivation rate: 0.0074
2025-08-27 18:15:59,302 - INFO - Epoch: [3][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.7404 (0.7645) Acc@1 74.219 (73.655) Acc@5 97.656 (98.193)
2025-08-27 18:16:00,607 - INFO - Pruning info: sparsity=0.058
2025-08-27 18:16:00,608 - INFO -   Reactivation rate: 0.0050
2025-08-27 18:16:01,273 - INFO - Epoch: [3][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.7272 (0.7596) Acc@1 74.219 (73.788) Acc@5 99.219 (98.212)
2025-08-27 18:16:03,110 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 1.0214 (1.0214) Acc@1 64.062 (64.062) Acc@5 98.438 (98.438)
2025-08-27 18:16:03,995 - INFO - Epoch 3:
2025-08-27 18:16:03,995 - INFO -   Train: acc1: 73.7340 | acc5: 98.2220 | loss: 0.7585 | sparsity: 0.0576 | reactivation_rate: 0.0061
2025-08-27 18:16:03,995 - INFO -   Val:   acc1: 65.0300 | acc5: 95.5600 | loss: 1.1396
2025-08-27 18:16:03,995 - INFO -   LR: 0.100000
2025-08-27 18:16:04,040 - INFO - Checkpoint saved: epoch=3, metric=65.0300
2025-08-27 18:16:04,072 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 18:16:04,269 - INFO - Epoch: [4][0/391] Time 0.196 (0.196) Data 0.171 (0.171) Loss 0.7220 (0.7220) Acc@1 67.188 (67.188) Acc@5 97.656 (97.656)
2025-08-27 18:16:04,957 - INFO - Pruning info: sparsity=0.076
2025-08-27 18:16:04,957 - INFO -   Reactivation rate: 0.0102
2025-08-27 18:16:06,221 - INFO - Epoch: [4][100/391] Time 0.026 (0.021) Data 0.000 (0.003) Loss 0.7217 (0.7202) Acc@1 77.344 (75.054) Acc@5 97.656 (98.515)
2025-08-27 18:16:08,029 - INFO - Pruning info: sparsity=0.076
2025-08-27 18:16:08,030 - INFO -   Reactivation rate: 0.0056
2025-08-27 18:16:08,138 - INFO - Epoch: [4][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.7485 (0.7027) Acc@1 71.094 (75.808) Acc@5 98.438 (98.441)
2025-08-27 18:16:10,089 - INFO - Epoch: [4][300/391] Time 0.032 (0.020) Data 0.000 (0.002) Loss 0.7104 (0.6959) Acc@1 71.094 (76.062) Acc@5 98.438 (98.458)
2025-08-27 18:16:11,268 - INFO - Pruning info: sparsity=0.076
2025-08-27 18:16:11,269 - INFO -   Reactivation rate: 0.0044
2025-08-27 18:16:12,030 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 1.1487 (1.1487) Acc@1 60.156 (60.156) Acc@5 96.094 (96.094)
2025-08-27 18:16:12,918 - INFO - Epoch 4:
2025-08-27 18:16:12,918 - INFO -   Train: acc1: 76.1980 | acc5: 98.4800 | loss: 0.6919 | sparsity: 0.0758 | reactivation_rate: 0.0059
2025-08-27 18:16:12,918 - INFO -   Val:   acc1: 63.2700 | acc5: 96.5500 | loss: 1.1309
2025-08-27 18:16:12,918 - INFO -   LR: 0.100000
2025-08-27 18:16:12,928 - INFO - training time: 00h 00m 45.74s
2025-08-27 18:16:12,928 - INFO - 
Training completed!
2025-08-27 18:16:12,928 - INFO - Best accuracy: 65.0300
2025-08-27 18:16:12,928 - INFO - Total training time: 0.01 hours
2025-08-27 18:16:12,928 - INFO - total_experiment time: 00h 00m 46.95s
2025-08-27 18:16:12,930 - INFO - Experiment completed successfully
2025-08-27 18:16:12,930 - INFO - Total time: 0.01 hours
2025-08-27 21:19:38,045 - INFO - Starting experiment: dpf_sparsity0.5_seed42
2025-08-27 21:19:38,045 - INFO - Save directory: ./runs/dpf/sparsity0.5/seed42
2025-08-27 21:19:38,046 - INFO - Hyperparameters:
2025-08-27 21:19:38,046 - INFO -   name: dpf_sparsity0.5_seed42
2025-08-27 21:19:38,046 - INFO -   description: DPF pruning 50% (seed=42)
2025-08-27 21:19:38,046 - INFO -   save_dir: ./runs
2025-08-27 21:19:38,046 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 21:19:38,046 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 21:19:38,046 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 21:19:38,046 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.5, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 21:19:38,046 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 21:19:38,046 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 21:19:38,111 - INFO - System Information:
2025-08-27 21:19:38,111 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 21:19:38,112 - INFO -   python_version: 3.9.18
2025-08-27 21:19:38,112 - INFO -   pytorch_version: 2.1.0
2025-08-27 21:19:38,112 - INFO -   cuda_available: True
2025-08-27 21:19:38,112 - INFO -   cpu_count: 4
2025-08-27 21:19:38,112 - INFO -   memory_total_gb: 11.0
2025-08-27 21:19:38,112 - INFO -   timestamp: 1756297178.1115742
2025-08-27 21:19:38,112 - INFO -   cuda_version: 11.8
2025-08-27 21:19:38,112 - INFO -   gpu_count: 1
2025-08-27 21:19:38,112 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 21:19:38,118 - INFO - Starting experiment: dpf_sparsity0.5_seed42
2025-08-27 21:19:38,118 - INFO - Model: resnet-20
2025-08-27 21:19:38,118 - INFO - Dataset: cifar10
2025-08-27 21:19:38,118 - INFO - Pruning: dpf (50.00%)
2025-08-27 21:19:38,280 - INFO - Model Information:
2025-08-27 21:19:38,281 - INFO -   Type: pruned
2025-08-27 21:19:38,281 - INFO -   Total parameters: 544,948
2025-08-27 21:19:38,281 - INFO -   Trainable parameters: 274,692
2025-08-27 21:19:38,281 - INFO -   Sparsity: 50.00%
2025-08-27 21:19:39,289 - INFO - Starting training...
2025-08-27 21:19:39,289 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 21:19:39,973 - INFO - Pruning info: sparsity=0.000
2025-08-27 21:19:39,973 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:19:40,500 - INFO - Epoch: [0][0/391] Time 1.210 (1.210) Data 0.538 (0.538) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 21:19:42,337 - INFO - Epoch: [0][100/391] Time 0.014 (0.030) Data 0.000 (0.006) Loss 1.6624 (1.9148) Acc@1 40.625 (26.153) Acc@5 91.406 (81.211)
2025-08-27 21:19:43,496 - INFO - Pruning info: sparsity=0.000
2025-08-27 21:19:43,497 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:19:44,259 - INFO - Epoch: [0][200/391] Time 0.013 (0.025) Data 0.000 (0.004) Loss 1.4511 (1.7803) Acc@1 42.188 (31.880) Acc@5 93.750 (85.250)
2025-08-27 21:19:46,213 - INFO - Epoch: [0][300/391] Time 0.016 (0.023) Data 0.000 (0.003) Loss 1.4839 (1.6826) Acc@1 41.406 (36.358) Acc@5 89.844 (87.443)
2025-08-27 21:19:46,583 - INFO - Pruning info: sparsity=0.000
2025-08-27 21:19:46,584 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:19:48,318 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 1.4382 (1.4382) Acc@1 50.781 (50.781) Acc@5 94.531 (94.531)
2025-08-27 21:19:49,268 - INFO - Epoch 0:
2025-08-27 21:19:49,268 - INFO -   Train: acc1: 39.5940 | acc5: 88.8100 | loss: 1.6090 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 21:19:49,269 - INFO -   Val:   acc1: 49.1700 | acc5: 93.9500 | loss: 1.4592
2025-08-27 21:19:49,269 - INFO -   LR: 0.100000
2025-08-27 21:19:49,331 - INFO - Checkpoint saved: epoch=0, metric=49.1700
2025-08-27 21:19:49,363 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 21:19:49,546 - INFO - Epoch: [1][0/391] Time 0.183 (0.183) Data 0.156 (0.156) Loss 1.3764 (1.3764) Acc@1 50.000 (50.000) Acc@5 92.969 (92.969)
2025-08-27 21:19:51,282 - INFO - Pruning info: sparsity=0.020
2025-08-27 21:19:51,282 - INFO -   Reactivation rate: 0.0068
2025-08-27 21:19:51,513 - INFO - Epoch: [1][100/391] Time 0.013 (0.021) Data 0.000 (0.002) Loss 1.1287 (1.2028) Acc@1 56.250 (55.948) Acc@5 92.969 (94.933)
2025-08-27 21:19:53,383 - INFO - Epoch: [1][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.9541 (1.1636) Acc@1 66.406 (57.673) Acc@5 97.656 (95.336)
2025-08-27 21:19:54,293 - INFO - Pruning info: sparsity=0.020
2025-08-27 21:19:54,293 - INFO -   Reactivation rate: 0.0044
2025-08-27 21:19:55,265 - INFO - Epoch: [1][300/391] Time 0.012 (0.020) Data 0.000 (0.001) Loss 0.9021 (1.1225) Acc@1 68.750 (59.230) Acc@5 96.094 (95.640)
2025-08-27 21:19:57,100 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 1.0828 (1.0828) Acc@1 61.719 (61.719) Acc@5 96.875 (96.875)
2025-08-27 21:19:57,910 - INFO - Epoch 1:
2025-08-27 21:19:57,910 - INFO -   Train: acc1: 60.6120 | acc5: 95.9060 | loss: 1.0914 | sparsity: 0.0197 | reactivation_rate: 0.0052
2025-08-27 21:19:57,910 - INFO -   Val:   acc1: 60.4300 | acc5: 95.7600 | loss: 1.1522
2025-08-27 21:19:57,910 - INFO -   LR: 0.100000
2025-08-27 21:19:57,954 - INFO - Checkpoint saved: epoch=1, metric=60.4300
2025-08-27 21:19:57,986 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 21:19:58,180 - INFO - Epoch: [2][0/391] Time 0.192 (0.192) Data 0.164 (0.164) Loss 0.8819 (0.8819) Acc@1 70.312 (70.312) Acc@5 99.219 (99.219)
2025-08-27 21:19:58,524 - INFO - Pruning info: sparsity=0.039
2025-08-27 21:19:58,524 - INFO -   Reactivation rate: 0.0114
2025-08-27 21:20:00,156 - INFO - Epoch: [2][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.9197 (0.9492) Acc@1 71.875 (66.623) Acc@5 96.875 (97.092)
2025-08-27 21:20:01,638 - INFO - Pruning info: sparsity=0.039
2025-08-27 21:20:01,639 - INFO -   Reactivation rate: 0.0057
2025-08-27 21:20:02,085 - INFO - Epoch: [2][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.8763 (0.9174) Acc@1 67.188 (67.553) Acc@5 98.438 (97.384)
2025-08-27 21:20:04,079 - INFO - Epoch: [2][300/391] Time 0.027 (0.020) Data 0.012 (0.002) Loss 0.9444 (0.8996) Acc@1 62.500 (68.298) Acc@5 99.219 (97.407)
2025-08-27 21:20:04,769 - INFO - Pruning info: sparsity=0.039
2025-08-27 21:20:04,769 - INFO -   Reactivation rate: 0.0042
2025-08-27 21:20:05,875 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 1.1066 (1.1066) Acc@1 64.844 (64.844) Acc@5 98.438 (98.438)
2025-08-27 21:20:06,773 - INFO - Epoch 2:
2025-08-27 21:20:06,773 - INFO -   Train: acc1: 68.9140 | acc5: 97.5020 | loss: 0.8812 | sparsity: 0.0389 | reactivation_rate: 0.0058
2025-08-27 21:20:06,773 - INFO -   Val:   acc1: 59.6800 | acc5: 95.7900 | loss: 1.2965
2025-08-27 21:20:06,773 - INFO -   LR: 0.100000
2025-08-27 21:20:06,783 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 21:20:06,963 - INFO - Epoch: [3][0/391] Time 0.179 (0.179) Data 0.153 (0.153) Loss 0.7931 (0.7931) Acc@1 70.312 (70.312) Acc@5 97.656 (97.656)
2025-08-27 21:20:08,931 - INFO - Epoch: [3][100/391] Time 0.029 (0.021) Data 0.013 (0.003) Loss 0.8298 (0.7801) Acc@1 66.406 (72.649) Acc@5 96.875 (98.035)
2025-08-27 21:20:09,066 - INFO - Pruning info: sparsity=0.058
2025-08-27 21:20:09,067 - INFO -   Reactivation rate: 0.0071
2025-08-27 21:20:10,817 - INFO - Epoch: [3][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.7644 (0.7734) Acc@1 71.875 (72.889) Acc@5 98.438 (98.018)
2025-08-27 21:20:12,085 - INFO - Pruning info: sparsity=0.058
2025-08-27 21:20:12,086 - INFO -   Reactivation rate: 0.0049
2025-08-27 21:20:12,765 - INFO - Epoch: [3][300/391] Time 0.020 (0.020) Data 0.001 (0.001) Loss 0.7664 (0.7655) Acc@1 77.344 (73.217) Acc@5 98.438 (98.020)
2025-08-27 21:20:14,656 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.9002 (0.9002) Acc@1 67.969 (67.969) Acc@5 97.656 (97.656)
2025-08-27 21:20:15,551 - INFO - Epoch 3:
2025-08-27 21:20:15,552 - INFO -   Train: acc1: 73.2540 | acc5: 98.0820 | loss: 0.7638 | sparsity: 0.0576 | reactivation_rate: 0.0060
2025-08-27 21:20:15,552 - INFO -   Val:   acc1: 65.3900 | acc5: 96.0300 | loss: 1.0969
2025-08-27 21:20:15,552 - INFO -   LR: 0.100000
2025-08-27 21:20:15,600 - INFO - Checkpoint saved: epoch=3, metric=65.3900
2025-08-27 21:20:15,637 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 21:20:15,810 - INFO - Epoch: [4][0/391] Time 0.171 (0.171) Data 0.151 (0.151) Loss 0.7152 (0.7152) Acc@1 75.781 (75.781) Acc@5 97.656 (97.656)
2025-08-27 21:20:16,458 - INFO - Pruning info: sparsity=0.076
2025-08-27 21:20:16,458 - INFO -   Reactivation rate: 0.0097
2025-08-27 21:20:17,602 - INFO - Epoch: [4][100/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.6472 (0.7198) Acc@1 82.031 (74.977) Acc@5 97.656 (98.345)
2025-08-27 21:20:19,457 - INFO - Pruning info: sparsity=0.076
2025-08-27 21:20:19,457 - INFO -   Reactivation rate: 0.0054
2025-08-27 21:20:19,541 - INFO - Epoch: [4][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.7266 (0.7096) Acc@1 71.875 (75.521) Acc@5 97.656 (98.344)
2025-08-27 21:20:21,432 - INFO - Epoch: [4][300/391] Time 0.017 (0.019) Data 0.001 (0.002) Loss 0.6877 (0.7040) Acc@1 71.875 (75.724) Acc@5 99.219 (98.365)
2025-08-27 21:20:22,484 - INFO - Pruning info: sparsity=0.076
2025-08-27 21:20:22,484 - INFO -   Reactivation rate: 0.0040
2025-08-27 21:20:23,307 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 1.1462 (1.1462) Acc@1 65.625 (65.625) Acc@5 96.875 (96.875)
2025-08-27 21:20:24,139 - INFO - Epoch 4:
2025-08-27 21:20:24,139 - INFO -   Train: acc1: 75.7740 | acc5: 98.4140 | loss: 0.7013 | sparsity: 0.0758 | reactivation_rate: 0.0058
2025-08-27 21:20:24,139 - INFO -   Val:   acc1: 64.2000 | acc5: 96.6000 | loss: 1.1653
2025-08-27 21:20:24,139 - INFO -   LR: 0.100000
2025-08-27 21:20:24,149 - INFO - 
Epoch: 5, lr = 0.1
2025-08-27 21:20:24,336 - INFO - Epoch: [5][0/391] Time 0.186 (0.186) Data 0.169 (0.169) Loss 0.7501 (0.7501) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 21:20:26,193 - INFO - Epoch: [5][100/391] Time 0.021 (0.020) Data 0.002 (0.002) Loss 0.6221 (0.6905) Acc@1 78.125 (76.168) Acc@5 98.438 (98.662)
2025-08-27 21:20:26,699 - INFO - Pruning info: sparsity=0.093
2025-08-27 21:20:26,700 - INFO -   Reactivation rate: 0.0067
2025-08-27 21:20:28,127 - INFO - Epoch: [5][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.7743 (0.6751) Acc@1 71.094 (76.605) Acc@5 98.438 (98.612)
2025-08-27 21:20:29,752 - INFO - Pruning info: sparsity=0.093
2025-08-27 21:20:29,753 - INFO -   Reactivation rate: 0.0048
2025-08-27 21:20:30,054 - INFO - Epoch: [5][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.7138 (0.6706) Acc@1 73.438 (76.757) Acc@5 97.656 (98.624)
2025-08-27 21:20:31,858 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.9906 (0.9906) Acc@1 73.438 (73.438) Acc@5 97.656 (97.656)
2025-08-27 21:20:32,695 - INFO - Epoch 5:
2025-08-27 21:20:32,696 - INFO -   Train: acc1: 76.8960 | acc5: 98.6640 | loss: 0.6664 | sparsity: 0.0935 | reactivation_rate: 0.0059
2025-08-27 21:20:32,696 - INFO -   Val:   acc1: 67.1800 | acc5: 97.3200 | loss: 1.0886
2025-08-27 21:20:32,696 - INFO -   LR: 0.100000
2025-08-27 21:20:32,741 - INFO - Checkpoint saved: epoch=5, metric=67.1800
2025-08-27 21:20:32,773 - INFO - 
Epoch: 6, lr = 0.1
2025-08-27 21:20:32,946 - INFO - Epoch: [6][0/391] Time 0.173 (0.173) Data 0.150 (0.150) Loss 0.5110 (0.5110) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-27 21:20:34,040 - INFO - Pruning info: sparsity=0.111
2025-08-27 21:20:34,040 - INFO -   Reactivation rate: 0.0091
2025-08-27 21:20:34,862 - INFO - Epoch: [6][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.6549 (0.6180) Acc@1 78.125 (78.581) Acc@5 97.656 (98.762)
2025-08-27 21:20:36,755 - INFO - Epoch: [6][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.6271 (0.6261) Acc@1 78.906 (78.323) Acc@5 98.438 (98.678)
2025-08-27 21:20:37,002 - INFO - Pruning info: sparsity=0.111
2025-08-27 21:20:37,002 - INFO -   Reactivation rate: 0.0052
2025-08-27 21:20:38,562 - INFO - Epoch: [6][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.5977 (0.6319) Acc@1 81.250 (78.156) Acc@5 100.000 (98.702)
2025-08-27 21:20:39,960 - INFO - Pruning info: sparsity=0.111
2025-08-27 21:20:39,960 - INFO -   Reactivation rate: 0.0041
2025-08-27 21:20:40,414 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.7648 (0.7648) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 21:20:41,249 - INFO - Epoch 6:
2025-08-27 21:20:41,249 - INFO -   Train: acc1: 78.2720 | acc5: 98.7080 | loss: 0.6307 | sparsity: 0.1107 | reactivation_rate: 0.0058
2025-08-27 21:20:41,249 - INFO -   Val:   acc1: 69.3900 | acc5: 97.3100 | loss: 0.9684
2025-08-27 21:20:41,249 - INFO -   LR: 0.100000
2025-08-27 21:20:41,294 - INFO - Checkpoint saved: epoch=6, metric=69.3900
2025-08-27 21:20:41,325 - INFO - 
Epoch: 7, lr = 0.1
2025-08-27 21:20:41,481 - INFO - Epoch: [7][0/391] Time 0.155 (0.155) Data 0.128 (0.128) Loss 0.6504 (0.6504) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 21:20:43,375 - INFO - Epoch: [7][100/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.7082 (0.6109) Acc@1 78.125 (78.728) Acc@5 97.656 (98.863)
2025-08-27 21:20:44,153 - INFO - Pruning info: sparsity=0.127
2025-08-27 21:20:44,153 - INFO -   Reactivation rate: 0.0059
2025-08-27 21:20:45,238 - INFO - Epoch: [7][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.6109 (0.6073) Acc@1 80.469 (78.910) Acc@5 99.219 (98.783)
2025-08-27 21:20:47,137 - INFO - Epoch: [7][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.5509 (0.6068) Acc@1 82.812 (79.002) Acc@5 99.219 (98.715)
2025-08-27 21:20:47,180 - INFO - Pruning info: sparsity=0.127
2025-08-27 21:20:47,180 - INFO -   Reactivation rate: 0.0044
2025-08-27 21:20:48,979 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.8889 (0.8889) Acc@1 75.000 (75.000) Acc@5 96.094 (96.094)
2025-08-27 21:20:49,819 - INFO - Epoch 7:
2025-08-27 21:20:49,819 - INFO -   Train: acc1: 78.9040 | acc5: 98.7680 | loss: 0.6070 | sparsity: 0.1273 | reactivation_rate: 0.0057
2025-08-27 21:20:49,819 - INFO -   Val:   acc1: 70.5800 | acc5: 96.8400 | loss: 0.9634
2025-08-27 21:20:49,819 - INFO -   LR: 0.100000
2025-08-27 21:20:49,865 - INFO - Checkpoint saved: epoch=7, metric=70.5800
2025-08-27 21:20:49,897 - INFO - 
Epoch: 8, lr = 0.1
2025-08-27 21:20:50,063 - INFO - Epoch: [8][0/391] Time 0.166 (0.166) Data 0.140 (0.140) Loss 0.5097 (0.5097) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:20:51,448 - INFO - Pruning info: sparsity=0.144
2025-08-27 21:20:51,448 - INFO -   Reactivation rate: 0.0081
2025-08-27 21:20:51,935 - INFO - Epoch: [8][100/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5938 (0.5981) Acc@1 77.344 (79.378) Acc@5 100.000 (98.654)
2025-08-27 21:20:53,835 - INFO - Epoch: [8][200/391] Time 0.023 (0.020) Data 0.002 (0.002) Loss 0.4864 (0.5919) Acc@1 85.156 (79.629) Acc@5 98.438 (98.807)
2025-08-27 21:20:54,432 - INFO - Pruning info: sparsity=0.144
2025-08-27 21:20:54,432 - INFO -   Reactivation rate: 0.0048
2025-08-27 21:20:55,779 - INFO - Epoch: [8][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.7258 (0.6005) Acc@1 76.562 (79.366) Acc@5 100.000 (98.853)
2025-08-27 21:20:57,629 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.7213 (0.7213) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 21:20:58,589 - INFO - Epoch 8:
2025-08-27 21:20:58,589 - INFO -   Train: acc1: 79.5400 | acc5: 98.9260 | loss: 0.5933 | sparsity: 0.1435 | reactivation_rate: 0.0057
2025-08-27 21:20:58,589 - INFO -   Val:   acc1: 75.3000 | acc5: 98.7900 | loss: 0.7310
2025-08-27 21:20:58,589 - INFO -   LR: 0.100000
2025-08-27 21:20:58,635 - INFO - Checkpoint saved: epoch=8, metric=75.3000
2025-08-27 21:20:58,667 - INFO - 
Epoch: 9, lr = 0.1
2025-08-27 21:20:58,835 - INFO - Epoch: [9][0/391] Time 0.167 (0.167) Data 0.143 (0.143) Loss 0.4579 (0.4579) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:20:58,843 - INFO - Pruning info: sparsity=0.159
2025-08-27 21:20:58,845 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:21:00,737 - INFO - Epoch: [9][100/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4735 (0.5562) Acc@1 83.594 (80.941) Acc@5 98.438 (98.963)
2025-08-27 21:21:01,788 - INFO - Pruning info: sparsity=0.159
2025-08-27 21:21:01,789 - INFO -   Reactivation rate: 0.0054
2025-08-27 21:21:02,598 - INFO - Epoch: [9][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5351 (0.5623) Acc@1 82.812 (80.706) Acc@5 99.219 (98.978)
2025-08-27 21:21:04,511 - INFO - Epoch: [9][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.7239 (0.5696) Acc@1 77.344 (80.326) Acc@5 96.094 (98.951)
2025-08-27 21:21:04,927 - INFO - Pruning info: sparsity=0.159
2025-08-27 21:21:04,927 - INFO -   Reactivation rate: 0.0040
2025-08-27 21:21:06,346 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.8345 (0.8345) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-27 21:21:07,153 - INFO - Epoch 9:
2025-08-27 21:21:07,154 - INFO -   Train: acc1: 80.3900 | acc5: 98.9420 | loss: 0.5687 | sparsity: 0.1593 | reactivation_rate: 0.0055
2025-08-27 21:21:07,154 - INFO -   Val:   acc1: 74.3600 | acc5: 98.4500 | loss: 0.7892
2025-08-27 21:21:07,154 - INFO -   LR: 0.100000
2025-08-27 21:21:07,164 - INFO - 
Epoch: 10, lr = 0.1
2025-08-27 21:21:07,339 - INFO - Epoch: [10][0/391] Time 0.174 (0.174) Data 0.147 (0.147) Loss 0.5462 (0.5462) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 21:21:09,086 - INFO - Pruning info: sparsity=0.175
2025-08-27 21:21:09,087 - INFO -   Reactivation rate: 0.0071
2025-08-27 21:21:09,287 - INFO - Epoch: [10][100/391] Time 0.011 (0.021) Data 0.000 (0.002) Loss 0.3743 (0.5378) Acc@1 86.719 (81.157) Acc@5 99.219 (98.987)
2025-08-27 21:21:11,375 - INFO - Epoch: [10][200/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.5068 (0.5441) Acc@1 84.375 (80.885) Acc@5 98.438 (99.032)
2025-08-27 21:21:12,349 - INFO - Pruning info: sparsity=0.175
2025-08-27 21:21:12,350 - INFO -   Reactivation rate: 0.0046
2025-08-27 21:21:13,314 - INFO - Epoch: [10][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.6644 (0.5520) Acc@1 79.688 (80.700) Acc@5 97.656 (98.998)
2025-08-27 21:21:15,177 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.9103 (0.9103) Acc@1 66.406 (66.406) Acc@5 99.219 (99.219)
2025-08-27 21:21:16,026 - INFO - Epoch 10:
2025-08-27 21:21:16,026 - INFO -   Train: acc1: 80.7860 | acc5: 98.9880 | loss: 0.5529 | sparsity: 0.1745 | reactivation_rate: 0.0054
2025-08-27 21:21:16,026 - INFO -   Val:   acc1: 69.2500 | acc5: 97.3300 | loss: 0.9352
2025-08-27 21:21:16,026 - INFO -   LR: 0.100000
2025-08-27 21:21:16,071 - INFO - 
Epoch: 11, lr = 0.1
2025-08-27 21:21:16,245 - INFO - Epoch: [11][0/391] Time 0.173 (0.173) Data 0.154 (0.154) Loss 0.6065 (0.6065) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 21:21:16,607 - INFO - Pruning info: sparsity=0.189
2025-08-27 21:21:16,608 - INFO -   Reactivation rate: 0.0106
2025-08-27 21:21:18,222 - INFO - Epoch: [11][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4985 (0.5417) Acc@1 87.500 (81.575) Acc@5 100.000 (99.103)
2025-08-27 21:21:19,688 - INFO - Pruning info: sparsity=0.189
2025-08-27 21:21:19,688 - INFO -   Reactivation rate: 0.0051
2025-08-27 21:21:20,135 - INFO - Epoch: [11][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5403 (0.5393) Acc@1 81.250 (81.518) Acc@5 99.219 (99.106)
2025-08-27 21:21:22,062 - INFO - Epoch: [11][300/391] Time 0.020 (0.020) Data 0.001 (0.003) Loss 0.7878 (0.5432) Acc@1 75.000 (81.369) Acc@5 96.875 (99.097)
2025-08-27 21:21:22,781 - INFO - Pruning info: sparsity=0.189
2025-08-27 21:21:22,782 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:21:23,844 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.6873 (0.6873) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:21:24,693 - INFO - Epoch 11:
2025-08-27 21:21:24,693 - INFO -   Train: acc1: 81.2960 | acc5: 99.0660 | loss: 0.5459 | sparsity: 0.1893 | reactivation_rate: 0.0053
2025-08-27 21:21:24,693 - INFO -   Val:   acc1: 76.0700 | acc5: 98.8100 | loss: 0.7460
2025-08-27 21:21:24,693 - INFO -   LR: 0.100000
2025-08-27 21:21:24,737 - INFO - Checkpoint saved: epoch=11, metric=76.0700
2025-08-27 21:21:24,768 - INFO - 
Epoch: 12, lr = 0.1
2025-08-27 21:21:24,944 - INFO - Epoch: [12][0/391] Time 0.175 (0.175) Data 0.148 (0.148) Loss 0.5714 (0.5714) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 21:21:26,888 - INFO - Epoch: [12][100/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.5260 (0.5389) Acc@1 78.906 (81.621) Acc@5 100.000 (99.056)
2025-08-27 21:21:27,029 - INFO - Pruning info: sparsity=0.204
2025-08-27 21:21:27,029 - INFO -   Reactivation rate: 0.0062
2025-08-27 21:21:28,729 - INFO - Epoch: [12][200/391] Time 0.023 (0.020) Data 0.012 (0.002) Loss 0.5841 (0.5335) Acc@1 81.250 (81.643) Acc@5 99.219 (99.044)
2025-08-27 21:21:30,043 - INFO - Pruning info: sparsity=0.204
2025-08-27 21:21:30,044 - INFO -   Reactivation rate: 0.0039
2025-08-27 21:21:30,699 - INFO - Epoch: [12][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.5597 (0.5348) Acc@1 78.906 (81.652) Acc@5 99.219 (99.034)
2025-08-27 21:21:32,453 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.7145 (0.7145) Acc@1 81.250 (81.250) Acc@5 96.094 (96.094)
2025-08-27 21:21:33,292 - INFO - Epoch 12:
2025-08-27 21:21:33,292 - INFO -   Train: acc1: 81.5620 | acc5: 99.0020 | loss: 0.5367 | sparsity: 0.2036 | reactivation_rate: 0.0052
2025-08-27 21:21:33,292 - INFO -   Val:   acc1: 74.5000 | acc5: 97.0700 | loss: 0.7881
2025-08-27 21:21:33,292 - INFO -   LR: 0.100000
2025-08-27 21:21:33,302 - INFO - 
Epoch: 13, lr = 0.1
2025-08-27 21:21:33,433 - INFO - Epoch: [13][0/391] Time 0.129 (0.129) Data 0.105 (0.105) Loss 0.5193 (0.5193) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:21:34,128 - INFO - Pruning info: sparsity=0.218
2025-08-27 21:21:34,128 - INFO -   Reactivation rate: 0.0086
2025-08-27 21:21:35,317 - INFO - Epoch: [13][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.5446 (0.5119) Acc@1 80.469 (82.418) Acc@5 97.656 (99.103)
2025-08-27 21:21:37,103 - INFO - Pruning info: sparsity=0.218
2025-08-27 21:21:37,103 - INFO -   Reactivation rate: 0.0045
2025-08-27 21:21:37,167 - INFO - Epoch: [13][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2984 (0.5232) Acc@1 89.062 (82.090) Acc@5 99.219 (99.071)
2025-08-27 21:21:38,975 - INFO - Epoch: [13][300/391] Time 0.021 (0.019) Data 0.010 (0.002) Loss 0.6079 (0.5259) Acc@1 80.469 (81.940) Acc@5 98.438 (99.089)
2025-08-27 21:21:40,005 - INFO - Pruning info: sparsity=0.218
2025-08-27 21:21:40,005 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:21:40,758 - INFO - Test: [0/79] Time 0.115 (0.115) Loss 0.5897 (0.5897) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 21:21:41,615 - INFO - Epoch 13:
2025-08-27 21:21:41,615 - INFO -   Train: acc1: 81.9160 | acc5: 99.0880 | loss: 0.5265 | sparsity: 0.2175 | reactivation_rate: 0.0050
2025-08-27 21:21:41,615 - INFO -   Val:   acc1: 78.2800 | acc5: 98.7200 | loss: 0.6787
2025-08-27 21:21:41,615 - INFO -   LR: 0.100000
2025-08-27 21:21:41,657 - INFO - Checkpoint saved: epoch=13, metric=78.2800
2025-08-27 21:21:41,691 - INFO - 
Epoch: 14, lr = 0.1
2025-08-27 21:21:41,865 - INFO - Epoch: [14][0/391] Time 0.173 (0.173) Data 0.148 (0.148) Loss 0.4969 (0.4969) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:21:43,726 - INFO - Epoch: [14][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.6169 (0.5196) Acc@1 82.812 (82.201) Acc@5 99.219 (99.134)
2025-08-27 21:21:44,172 - INFO - Pruning info: sparsity=0.231
2025-08-27 21:21:44,173 - INFO -   Reactivation rate: 0.0056
2025-08-27 21:21:45,607 - INFO - Epoch: [14][200/391] Time 0.032 (0.019) Data 0.006 (0.003) Loss 0.5578 (0.5176) Acc@1 80.469 (82.315) Acc@5 98.438 (99.098)
2025-08-27 21:21:47,140 - INFO - Pruning info: sparsity=0.231
2025-08-27 21:21:47,140 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:21:47,391 - INFO - Epoch: [14][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3953 (0.5200) Acc@1 85.156 (82.107) Acc@5 100.000 (99.073)
2025-08-27 21:21:49,172 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6502 (0.6502) Acc@1 76.562 (76.562) Acc@5 97.656 (97.656)
2025-08-27 21:21:50,068 - INFO - Epoch 14:
2025-08-27 21:21:50,068 - INFO -   Train: acc1: 82.1180 | acc5: 99.0860 | loss: 0.5199 | sparsity: 0.2310 | reactivation_rate: 0.0048
2025-08-27 21:21:50,068 - INFO -   Val:   acc1: 76.0900 | acc5: 98.1700 | loss: 0.7627
2025-08-27 21:21:50,068 - INFO -   LR: 0.100000
2025-08-27 21:21:50,077 - INFO - 
Epoch: 15, lr = 0.1
2025-08-27 21:21:50,243 - INFO - Epoch: [15][0/391] Time 0.165 (0.165) Data 0.147 (0.147) Loss 0.4381 (0.4381) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:21:51,251 - INFO - Pruning info: sparsity=0.244
2025-08-27 21:21:51,251 - INFO -   Reactivation rate: 0.0074
2025-08-27 21:21:52,066 - INFO - Epoch: [15][100/391] Time 0.018 (0.020) Data 0.002 (0.003) Loss 0.4795 (0.5045) Acc@1 82.031 (82.472) Acc@5 100.000 (99.126)
2025-08-27 21:21:53,908 - INFO - Epoch: [15][200/391] Time 0.019 (0.019) Data 0.008 (0.003) Loss 0.5575 (0.5169) Acc@1 81.250 (82.206) Acc@5 100.000 (99.067)
2025-08-27 21:21:54,195 - INFO - Pruning info: sparsity=0.244
2025-08-27 21:21:54,195 - INFO -   Reactivation rate: 0.0041
2025-08-27 21:21:55,730 - INFO - Epoch: [15][300/391] Time 0.020 (0.019) Data 0.008 (0.003) Loss 0.4794 (0.5128) Acc@1 84.375 (82.330) Acc@5 99.219 (99.123)
2025-08-27 21:21:57,068 - INFO - Pruning info: sparsity=0.244
2025-08-27 21:21:57,068 - INFO -   Reactivation rate: 0.0031
2025-08-27 21:21:57,473 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7446 (0.7446) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-27 21:21:58,312 - INFO - Epoch 15:
2025-08-27 21:21:58,312 - INFO -   Train: acc1: 82.2360 | acc5: 99.0840 | loss: 0.5159 | sparsity: 0.2440 | reactivation_rate: 0.0048
2025-08-27 21:21:58,312 - INFO -   Val:   acc1: 74.4800 | acc5: 97.8100 | loss: 0.8258
2025-08-27 21:21:58,312 - INFO -   LR: 0.100000
2025-08-27 21:21:58,320 - INFO - 
Epoch: 16, lr = 0.1
2025-08-27 21:21:58,508 - INFO - Epoch: [16][0/391] Time 0.186 (0.186) Data 0.149 (0.149) Loss 0.5230 (0.5230) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 21:22:00,480 - INFO - Epoch: [16][100/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.5165 (0.5042) Acc@1 82.031 (82.867) Acc@5 99.219 (99.149)
2025-08-27 21:22:01,345 - INFO - Pruning info: sparsity=0.257
2025-08-27 21:22:01,345 - INFO -   Reactivation rate: 0.0047
2025-08-27 21:22:02,422 - INFO - Epoch: [16][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5447 (0.5062) Acc@1 82.812 (82.781) Acc@5 99.219 (99.149)
2025-08-27 21:22:04,292 - INFO - Epoch: [16][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5633 (0.5069) Acc@1 82.031 (82.732) Acc@5 98.438 (99.102)
2025-08-27 21:22:04,359 - INFO - Pruning info: sparsity=0.257
2025-08-27 21:22:04,359 - INFO -   Reactivation rate: 0.0035
2025-08-27 21:22:06,105 - INFO - Test: [0/79] Time 0.108 (0.108) Loss 0.7612 (0.7612) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 21:22:06,948 - INFO - Epoch 16:
2025-08-27 21:22:06,948 - INFO -   Train: acc1: 82.6300 | acc5: 99.1540 | loss: 0.5064 | sparsity: 0.2566 | reactivation_rate: 0.0046
2025-08-27 21:22:06,949 - INFO -   Val:   acc1: 75.5300 | acc5: 98.3000 | loss: 0.7857
2025-08-27 21:22:06,949 - INFO -   LR: 0.100000
2025-08-27 21:22:06,960 - INFO - 
Epoch: 17, lr = 0.1
2025-08-27 21:22:07,142 - INFO - Epoch: [17][0/391] Time 0.180 (0.180) Data 0.160 (0.160) Loss 0.5284 (0.5284) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-27 21:22:08,485 - INFO - Pruning info: sparsity=0.269
2025-08-27 21:22:08,485 - INFO -   Reactivation rate: 0.0063
2025-08-27 21:22:09,029 - INFO - Epoch: [17][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.4469 (0.4861) Acc@1 84.375 (83.269) Acc@5 99.219 (99.350)
2025-08-27 21:22:10,888 - INFO - Epoch: [17][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4797 (0.4949) Acc@1 82.031 (83.007) Acc@5 99.219 (99.250)
2025-08-27 21:22:11,486 - INFO - Pruning info: sparsity=0.269
2025-08-27 21:22:11,486 - INFO -   Reactivation rate: 0.0038
2025-08-27 21:22:12,819 - INFO - Epoch: [17][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.4071 (0.5054) Acc@1 87.500 (82.646) Acc@5 99.219 (99.198)
2025-08-27 21:22:14,629 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5857 (0.5857) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:22:15,444 - INFO - Epoch 17:
2025-08-27 21:22:15,444 - INFO -   Train: acc1: 82.6380 | acc5: 99.1940 | loss: 0.5069 | sparsity: 0.2688 | reactivation_rate: 0.0045
2025-08-27 21:22:15,444 - INFO -   Val:   acc1: 78.0500 | acc5: 98.6900 | loss: 0.6686
2025-08-27 21:22:15,444 - INFO -   LR: 0.100000
2025-08-27 21:22:15,455 - INFO - 
Epoch: 18, lr = 0.1
2025-08-27 21:22:15,617 - INFO - Epoch: [18][0/391] Time 0.161 (0.161) Data 0.136 (0.136) Loss 0.3822 (0.3822) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:22:15,649 - INFO - Pruning info: sparsity=0.281
2025-08-27 21:22:15,649 - INFO -   Reactivation rate: 0.0018
2025-08-27 21:22:17,472 - INFO - Epoch: [18][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4691 (0.4881) Acc@1 83.594 (83.153) Acc@5 99.219 (99.219)
2025-08-27 21:22:18,655 - INFO - Pruning info: sparsity=0.281
2025-08-27 21:22:18,655 - INFO -   Reactivation rate: 0.0045
2025-08-27 21:22:19,351 - INFO - Epoch: [18][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4111 (0.4919) Acc@1 88.281 (83.092) Acc@5 99.219 (99.199)
2025-08-27 21:22:21,236 - INFO - Epoch: [18][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5857 (0.4966) Acc@1 81.250 (82.968) Acc@5 96.875 (99.177)
2025-08-27 21:22:21,661 - INFO - Pruning info: sparsity=0.281
2025-08-27 21:22:21,661 - INFO -   Reactivation rate: 0.0032
2025-08-27 21:22:23,049 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.6554 (0.6554) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 21:22:23,925 - INFO - Epoch 18:
2025-08-27 21:22:23,925 - INFO -   Train: acc1: 82.8660 | acc5: 99.1800 | loss: 0.5006 | sparsity: 0.2805 | reactivation_rate: 0.0045
2025-08-27 21:22:23,925 - INFO -   Val:   acc1: 75.4200 | acc5: 98.0700 | loss: 0.7486
2025-08-27 21:22:23,925 - INFO -   LR: 0.100000
2025-08-27 21:22:23,936 - INFO - 
Epoch: 19, lr = 0.1
2025-08-27 21:22:24,113 - INFO - Epoch: [19][0/391] Time 0.176 (0.176) Data 0.147 (0.147) Loss 0.3501 (0.3501) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:22:25,823 - INFO - Pruning info: sparsity=0.292
2025-08-27 21:22:25,823 - INFO -   Reactivation rate: 0.0056
2025-08-27 21:22:26,002 - INFO - Epoch: [19][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4505 (0.4823) Acc@1 82.812 (83.470) Acc@5 99.219 (99.265)
2025-08-27 21:22:27,904 - INFO - Epoch: [19][200/391] Time 0.030 (0.020) Data 0.003 (0.002) Loss 0.4055 (0.4905) Acc@1 85.938 (83.100) Acc@5 100.000 (99.188)
2025-08-27 21:22:28,902 - INFO - Pruning info: sparsity=0.292
2025-08-27 21:22:28,902 - INFO -   Reactivation rate: 0.0035
2025-08-27 21:22:29,854 - INFO - Epoch: [19][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3440 (0.4937) Acc@1 87.500 (82.997) Acc@5 100.000 (99.198)
2025-08-27 21:22:31,619 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.4962 (0.4962) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:22:32,456 - INFO - Epoch 19:
2025-08-27 21:22:32,456 - INFO -   Train: acc1: 83.0680 | acc5: 99.1700 | loss: 0.4932 | sparsity: 0.2919 | reactivation_rate: 0.0044
2025-08-27 21:22:32,456 - INFO -   Val:   acc1: 79.6000 | acc5: 98.8600 | loss: 0.6084
2025-08-27 21:22:32,456 - INFO -   LR: 0.100000
2025-08-27 21:22:32,500 - INFO - Checkpoint saved: epoch=19, metric=79.6000
2025-08-27 21:22:32,531 - INFO - 
Epoch: 20, lr = 0.1
2025-08-27 21:22:32,712 - INFO - Epoch: [20][0/391] Time 0.181 (0.181) Data 0.160 (0.160) Loss 0.3739 (0.3739) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 21:22:33,061 - INFO - Pruning info: sparsity=0.303
2025-08-27 21:22:33,061 - INFO -   Reactivation rate: 0.0083
2025-08-27 21:22:34,640 - INFO - Epoch: [20][100/391] Time 0.036 (0.021) Data 0.000 (0.002) Loss 0.3374 (0.4750) Acc@1 91.406 (83.764) Acc@5 98.438 (99.412)
2025-08-27 21:22:36,171 - INFO - Pruning info: sparsity=0.303
2025-08-27 21:22:36,172 - INFO -   Reactivation rate: 0.0042
2025-08-27 21:22:36,576 - INFO - Epoch: [20][200/391] Time 0.029 (0.020) Data 0.003 (0.002) Loss 0.4706 (0.4865) Acc@1 85.156 (83.302) Acc@5 98.438 (99.300)
2025-08-27 21:22:38,512 - INFO - Epoch: [20][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5267 (0.4873) Acc@1 83.594 (83.233) Acc@5 97.656 (99.255)
2025-08-27 21:22:39,191 - INFO - Pruning info: sparsity=0.303
2025-08-27 21:22:39,192 - INFO -   Reactivation rate: 0.0031
2025-08-27 21:22:40,253 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.5771 (0.5771) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:22:41,126 - INFO - Epoch 20:
2025-08-27 21:22:41,126 - INFO -   Train: acc1: 83.1600 | acc5: 99.2660 | loss: 0.4899 | sparsity: 0.3028 | reactivation_rate: 0.0043
2025-08-27 21:22:41,126 - INFO -   Val:   acc1: 80.6200 | acc5: 98.9800 | loss: 0.5819
2025-08-27 21:22:41,126 - INFO -   LR: 0.100000
2025-08-27 21:22:41,172 - INFO - Checkpoint saved: epoch=20, metric=80.6200
2025-08-27 21:22:41,204 - INFO - 
Epoch: 21, lr = 0.1
2025-08-27 21:22:41,404 - INFO - Epoch: [21][0/391] Time 0.199 (0.199) Data 0.173 (0.173) Loss 0.3870 (0.3870) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:22:43,398 - INFO - Epoch: [21][100/391] Time 0.024 (0.022) Data 0.000 (0.003) Loss 0.4631 (0.4573) Acc@1 86.719 (84.398) Acc@5 98.438 (99.335)
2025-08-27 21:22:43,535 - INFO - Pruning info: sparsity=0.313
2025-08-27 21:22:43,535 - INFO -   Reactivation rate: 0.0051
2025-08-27 21:22:45,188 - INFO - Epoch: [21][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4803 (0.4732) Acc@1 81.250 (83.753) Acc@5 99.219 (99.215)
2025-08-27 21:22:46,571 - INFO - Pruning info: sparsity=0.313
2025-08-27 21:22:46,571 - INFO -   Reactivation rate: 0.0032
2025-08-27 21:22:47,129 - INFO - Epoch: [21][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4858 (0.4763) Acc@1 83.594 (83.594) Acc@5 99.219 (99.175)
2025-08-27 21:22:48,966 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.4994 (0.4994) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:22:49,858 - INFO - Epoch 21:
2025-08-27 21:22:49,858 - INFO -   Train: acc1: 83.3880 | acc5: 99.1640 | loss: 0.4819 | sparsity: 0.3134 | reactivation_rate: 0.0042
2025-08-27 21:22:49,858 - INFO -   Val:   acc1: 81.6000 | acc5: 99.0300 | loss: 0.5576
2025-08-27 21:22:49,858 - INFO -   LR: 0.100000
2025-08-27 21:22:49,902 - INFO - Checkpoint saved: epoch=21, metric=81.6000
2025-08-27 21:22:49,934 - INFO - 
Epoch: 22, lr = 0.1
2025-08-27 21:22:50,110 - INFO - Epoch: [22][0/391] Time 0.174 (0.174) Data 0.150 (0.150) Loss 0.4937 (0.4937) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:22:50,881 - INFO - Pruning info: sparsity=0.324
2025-08-27 21:22:50,881 - INFO -   Reactivation rate: 0.0068
2025-08-27 21:22:52,145 - INFO - Epoch: [22][100/391] Time 0.027 (0.022) Data 0.013 (0.003) Loss 0.5026 (0.4687) Acc@1 84.375 (83.965) Acc@5 98.438 (99.172)
2025-08-27 21:22:53,961 - INFO - Pruning info: sparsity=0.324
2025-08-27 21:22:53,961 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:22:54,021 - INFO - Epoch: [22][200/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.5213 (0.4735) Acc@1 79.688 (83.862) Acc@5 98.438 (99.164)
2025-08-27 21:22:55,855 - INFO - Epoch: [22][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3623 (0.4774) Acc@1 86.719 (83.783) Acc@5 100.000 (99.182)
2025-08-27 21:22:56,998 - INFO - Pruning info: sparsity=0.324
2025-08-27 21:22:56,999 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:22:57,732 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.5679 (0.5679) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 21:22:58,547 - INFO - Epoch 22:
2025-08-27 21:22:58,547 - INFO -   Train: acc1: 83.6980 | acc5: 99.1840 | loss: 0.4784 | sparsity: 0.3236 | reactivation_rate: 0.0040
2025-08-27 21:22:58,547 - INFO -   Val:   acc1: 78.9800 | acc5: 98.4800 | loss: 0.6463
2025-08-27 21:22:58,547 - INFO -   LR: 0.100000
2025-08-27 21:22:58,556 - INFO - 
Epoch: 23, lr = 0.1
2025-08-27 21:22:58,719 - INFO - Epoch: [23][0/391] Time 0.161 (0.161) Data 0.137 (0.137) Loss 0.4782 (0.4782) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:23:00,543 - INFO - Epoch: [23][100/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4285 (0.4731) Acc@1 82.031 (83.942) Acc@5 99.219 (99.087)
2025-08-27 21:23:01,032 - INFO - Pruning info: sparsity=0.333
2025-08-27 21:23:01,032 - INFO -   Reactivation rate: 0.0045
2025-08-27 21:23:02,505 - INFO - Epoch: [23][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4868 (0.4868) Acc@1 85.156 (83.337) Acc@5 98.438 (99.129)
2025-08-27 21:23:04,241 - INFO - Pruning info: sparsity=0.333
2025-08-27 21:23:04,241 - INFO -   Reactivation rate: 0.0031
2025-08-27 21:23:04,506 - INFO - Epoch: [23][300/391] Time 0.023 (0.020) Data 0.010 (0.002) Loss 0.5268 (0.4843) Acc@1 78.906 (83.306) Acc@5 100.000 (99.167)
2025-08-27 21:23:06,354 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.6362 (0.6362) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 21:23:07,262 - INFO - Epoch 23:
2025-08-27 21:23:07,263 - INFO -   Train: acc1: 83.4000 | acc5: 99.1720 | loss: 0.4813 | sparsity: 0.3334 | reactivation_rate: 0.0039
2025-08-27 21:23:07,263 - INFO -   Val:   acc1: 79.3700 | acc5: 99.0300 | loss: 0.6330
2025-08-27 21:23:07,263 - INFO -   LR: 0.100000
2025-08-27 21:23:07,272 - INFO - 
Epoch: 24, lr = 0.1
2025-08-27 21:23:07,441 - INFO - Epoch: [24][0/391] Time 0.168 (0.168) Data 0.141 (0.141) Loss 0.4045 (0.4045) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 21:23:08,518 - INFO - Pruning info: sparsity=0.343
2025-08-27 21:23:08,519 - INFO -   Reactivation rate: 0.0057
2025-08-27 21:23:09,395 - INFO - Epoch: [24][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.5275 (0.4783) Acc@1 83.594 (83.656) Acc@5 98.438 (99.288)
2025-08-27 21:23:11,388 - INFO - Epoch: [24][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.6025 (0.4783) Acc@1 81.250 (83.539) Acc@5 99.219 (99.281)
2025-08-27 21:23:11,659 - INFO - Pruning info: sparsity=0.343
2025-08-27 21:23:11,660 - INFO -   Reactivation rate: 0.0035
2025-08-27 21:23:13,222 - INFO - Epoch: [24][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.6003 (0.4800) Acc@1 76.562 (83.477) Acc@5 99.219 (99.263)
2025-08-27 21:23:14,757 - INFO - Pruning info: sparsity=0.343
2025-08-27 21:23:14,757 - INFO -   Reactivation rate: 0.0025
2025-08-27 21:23:15,141 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.5223 (0.5223) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:23:15,994 - INFO - Epoch 24:
2025-08-27 21:23:15,994 - INFO -   Train: acc1: 83.5260 | acc5: 99.2040 | loss: 0.4799 | sparsity: 0.3428 | reactivation_rate: 0.0038
2025-08-27 21:23:15,994 - INFO -   Val:   acc1: 82.0200 | acc5: 99.1300 | loss: 0.5389
2025-08-27 21:23:15,994 - INFO -   LR: 0.100000
2025-08-27 21:23:16,040 - INFO - Checkpoint saved: epoch=24, metric=82.0200
2025-08-27 21:23:16,072 - INFO - 
Epoch: 25, lr = 0.1
2025-08-27 21:23:16,232 - INFO - Epoch: [25][0/391] Time 0.159 (0.159) Data 0.131 (0.131) Loss 0.4630 (0.4630) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:23:18,144 - INFO - Epoch: [25][100/391] Time 0.027 (0.020) Data 0.013 (0.003) Loss 0.5929 (0.4527) Acc@1 81.250 (84.584) Acc@5 98.438 (99.420)
2025-08-27 21:23:18,941 - INFO - Pruning info: sparsity=0.352
2025-08-27 21:23:18,942 - INFO -   Reactivation rate: 0.0038
2025-08-27 21:23:19,928 - INFO - Epoch: [25][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.6349 (0.4661) Acc@1 78.906 (84.111) Acc@5 96.875 (99.363)
2025-08-27 21:23:21,769 - INFO - Epoch: [25][300/391] Time 0.015 (0.019) Data 0.005 (0.003) Loss 0.4754 (0.4676) Acc@1 85.156 (84.027) Acc@5 99.219 (99.356)
2025-08-27 21:23:21,891 - INFO - Pruning info: sparsity=0.352
2025-08-27 21:23:21,891 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:23:23,583 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.7369 (0.7369) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 21:23:24,445 - INFO - Epoch 25:
2025-08-27 21:23:24,445 - INFO -   Train: acc1: 83.9040 | acc5: 99.3400 | loss: 0.4705 | sparsity: 0.3519 | reactivation_rate: 0.0036
2025-08-27 21:23:24,445 - INFO -   Val:   acc1: 75.4500 | acc5: 98.4300 | loss: 0.7622
2025-08-27 21:23:24,445 - INFO -   LR: 0.100000
2025-08-27 21:23:24,455 - INFO - 
Epoch: 26, lr = 0.1
2025-08-27 21:23:24,613 - INFO - Epoch: [26][0/391] Time 0.157 (0.157) Data 0.127 (0.127) Loss 0.3638 (0.3638) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:23:25,991 - INFO - Pruning info: sparsity=0.361
2025-08-27 21:23:25,991 - INFO -   Reactivation rate: 0.0049
2025-08-27 21:23:26,432 - INFO - Epoch: [26][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4645 (0.4568) Acc@1 83.594 (84.274) Acc@5 99.219 (99.343)
2025-08-27 21:23:28,310 - INFO - Epoch: [26][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.5120 (0.4599) Acc@1 81.250 (84.371) Acc@5 99.219 (99.320)
2025-08-27 21:23:28,920 - INFO - Pruning info: sparsity=0.361
2025-08-27 21:23:28,920 - INFO -   Reactivation rate: 0.0031
2025-08-27 21:23:30,219 - INFO - Epoch: [26][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.6917 (0.4679) Acc@1 74.219 (84.006) Acc@5 99.219 (99.325)
2025-08-27 21:23:32,068 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.5067 (0.5067) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 21:23:32,937 - INFO - Epoch 26:
2025-08-27 21:23:32,938 - INFO -   Train: acc1: 84.1480 | acc5: 99.3180 | loss: 0.4635 | sparsity: 0.3606 | reactivation_rate: 0.0035
2025-08-27 21:23:32,938 - INFO -   Val:   acc1: 78.9700 | acc5: 98.8200 | loss: 0.6237
2025-08-27 21:23:32,938 - INFO -   LR: 0.100000
2025-08-27 21:23:32,949 - INFO - 
Epoch: 27, lr = 0.1
2025-08-27 21:23:33,124 - INFO - Epoch: [27][0/391] Time 0.175 (0.175) Data 0.143 (0.143) Loss 0.4005 (0.4005) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:23:33,178 - INFO - Pruning info: sparsity=0.369
2025-08-27 21:23:33,178 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:23:35,011 - INFO - Epoch: [27][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.5146 (0.4392) Acc@1 81.250 (84.994) Acc@5 100.000 (99.281)
2025-08-27 21:23:36,204 - INFO - Pruning info: sparsity=0.369
2025-08-27 21:23:36,204 - INFO -   Reactivation rate: 0.0036
2025-08-27 21:23:36,928 - INFO - Epoch: [27][200/391] Time 0.022 (0.020) Data 0.011 (0.004) Loss 0.3475 (0.4516) Acc@1 85.938 (84.480) Acc@5 100.000 (99.343)
2025-08-27 21:23:38,783 - INFO - Epoch: [27][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4688 (0.4581) Acc@1 85.156 (84.318) Acc@5 99.219 (99.346)
2025-08-27 21:23:39,228 - INFO - Pruning info: sparsity=0.369
2025-08-27 21:23:39,229 - INFO -   Reactivation rate: 0.0025
2025-08-27 21:23:40,608 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.7079 (0.7079) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 21:23:41,454 - INFO - Epoch 27:
2025-08-27 21:23:41,454 - INFO -   Train: acc1: 84.2920 | acc5: 99.3280 | loss: 0.4609 | sparsity: 0.3689 | reactivation_rate: 0.0034
2025-08-27 21:23:41,454 - INFO -   Val:   acc1: 75.6100 | acc5: 98.6600 | loss: 0.7351
2025-08-27 21:23:41,454 - INFO -   LR: 0.100000
2025-08-27 21:23:41,598 - INFO - 
Epoch: 28, lr = 0.1
2025-08-27 21:23:41,774 - INFO - Epoch: [28][0/391] Time 0.176 (0.176) Data 0.145 (0.145) Loss 0.4405 (0.4405) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-27 21:23:43,481 - INFO - Pruning info: sparsity=0.377
2025-08-27 21:23:43,481 - INFO -   Reactivation rate: 0.0045
2025-08-27 21:23:43,631 - INFO - Epoch: [28][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4883 (0.4675) Acc@1 85.156 (84.158) Acc@5 100.000 (99.226)
2025-08-27 21:23:45,474 - INFO - Epoch: [28][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4488 (0.4695) Acc@1 80.469 (83.874) Acc@5 100.000 (99.262)
2025-08-27 21:23:46,399 - INFO - Pruning info: sparsity=0.377
2025-08-27 21:23:46,399 - INFO -   Reactivation rate: 0.0029
2025-08-27 21:23:47,329 - INFO - Epoch: [28][300/391] Time 0.037 (0.019) Data 0.000 (0.003) Loss 0.3488 (0.4672) Acc@1 88.281 (84.012) Acc@5 99.219 (99.240)
2025-08-27 21:23:49,091 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5878 (0.5878) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 21:23:49,955 - INFO - Epoch 28:
2025-08-27 21:23:49,955 - INFO -   Train: acc1: 84.0560 | acc5: 99.2800 | loss: 0.4649 | sparsity: 0.3770 | reactivation_rate: 0.0034
2025-08-27 21:23:49,955 - INFO -   Val:   acc1: 77.7300 | acc5: 98.9200 | loss: 0.6669
2025-08-27 21:23:49,955 - INFO -   LR: 0.100000
2025-08-27 21:23:49,967 - INFO - 
Epoch: 29, lr = 0.1
2025-08-27 21:23:50,146 - INFO - Epoch: [29][0/391] Time 0.179 (0.179) Data 0.146 (0.146) Loss 0.6433 (0.6433) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 21:23:50,531 - INFO - Pruning info: sparsity=0.385
2025-08-27 21:23:50,531 - INFO -   Reactivation rate: 0.0062
2025-08-27 21:23:51,997 - INFO - Epoch: [29][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.4473 (0.4567) Acc@1 85.156 (84.213) Acc@5 99.219 (99.366)
2025-08-27 21:23:53,470 - INFO - Pruning info: sparsity=0.385
2025-08-27 21:23:53,470 - INFO -   Reactivation rate: 0.0032
2025-08-27 21:23:53,841 - INFO - Epoch: [29][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4469 (0.4578) Acc@1 81.250 (84.352) Acc@5 100.000 (99.370)
2025-08-27 21:23:55,688 - INFO - Epoch: [29][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4753 (0.4612) Acc@1 82.812 (84.144) Acc@5 98.438 (99.356)
2025-08-27 21:23:56,459 - INFO - Pruning info: sparsity=0.385
2025-08-27 21:23:56,459 - INFO -   Reactivation rate: 0.0024
2025-08-27 21:23:57,516 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.9355 (0.9355) Acc@1 71.094 (71.094) Acc@5 99.219 (99.219)
2025-08-27 21:23:58,400 - INFO - Epoch 29:
2025-08-27 21:23:58,400 - INFO -   Train: acc1: 84.1080 | acc5: 99.3420 | loss: 0.4632 | sparsity: 0.3846 | reactivation_rate: 0.0033
2025-08-27 21:23:58,400 - INFO -   Val:   acc1: 71.6600 | acc5: 98.2800 | loss: 0.9656
2025-08-27 21:23:58,400 - INFO -   LR: 0.100000
2025-08-27 21:23:58,410 - INFO - 
Epoch: 30, lr = 0.1
2025-08-27 21:23:58,575 - INFO - Epoch: [30][0/391] Time 0.164 (0.164) Data 0.139 (0.139) Loss 0.4232 (0.4232) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:24:00,424 - INFO - Epoch: [30][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4459 (0.4616) Acc@1 83.594 (84.089) Acc@5 100.000 (99.273)
2025-08-27 21:24:00,591 - INFO - Pruning info: sparsity=0.392
2025-08-27 21:24:00,592 - INFO -   Reactivation rate: 0.0039
2025-08-27 21:24:02,290 - INFO - Epoch: [30][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3669 (0.4570) Acc@1 85.938 (84.461) Acc@5 100.000 (99.262)
2025-08-27 21:24:03,565 - INFO - Pruning info: sparsity=0.392
2025-08-27 21:24:03,565 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:24:04,184 - INFO - Epoch: [30][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.5375 (0.4562) Acc@1 84.375 (84.450) Acc@5 99.219 (99.255)
2025-08-27 21:24:05,942 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.5299 (0.5299) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:24:06,763 - INFO - Epoch 30:
2025-08-27 21:24:06,763 - INFO -   Train: acc1: 84.3680 | acc5: 99.2900 | loss: 0.4572 | sparsity: 0.3920 | reactivation_rate: 0.0032
2025-08-27 21:24:06,763 - INFO -   Val:   acc1: 80.7400 | acc5: 99.0600 | loss: 0.5798
2025-08-27 21:24:06,763 - INFO -   LR: 0.100000
2025-08-27 21:24:06,808 - INFO - 
Epoch: 31, lr = 0.1
2025-08-27 21:24:06,979 - INFO - Epoch: [31][0/391] Time 0.170 (0.170) Data 0.146 (0.146) Loss 0.5745 (0.5745) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 21:24:07,670 - INFO - Pruning info: sparsity=0.399
2025-08-27 21:24:07,670 - INFO -   Reactivation rate: 0.0049
2025-08-27 21:24:08,808 - INFO - Epoch: [31][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.3769 (0.4415) Acc@1 85.938 (85.404) Acc@5 100.000 (99.373)
2025-08-27 21:24:10,661 - INFO - Pruning info: sparsity=0.399
2025-08-27 21:24:10,661 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:24:10,696 - INFO - Epoch: [31][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.4313 (0.4454) Acc@1 86.719 (85.024) Acc@5 99.219 (99.335)
2025-08-27 21:24:12,493 - INFO - Epoch: [31][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3970 (0.4519) Acc@1 85.156 (84.736) Acc@5 99.219 (99.284)
2025-08-27 21:24:13,567 - INFO - Pruning info: sparsity=0.399
2025-08-27 21:24:13,567 - INFO -   Reactivation rate: 0.0021
2025-08-27 21:24:14,287 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.5051 (0.5051) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:24:15,120 - INFO - Epoch 31:
2025-08-27 21:24:15,120 - INFO -   Train: acc1: 84.6440 | acc5: 99.2960 | loss: 0.4517 | sparsity: 0.3990 | reactivation_rate: 0.0031
2025-08-27 21:24:15,120 - INFO -   Val:   acc1: 80.3000 | acc5: 98.7300 | loss: 0.6114
2025-08-27 21:24:15,120 - INFO -   LR: 0.100000
2025-08-27 21:24:15,130 - INFO - 
Epoch: 32, lr = 0.1
2025-08-27 21:24:15,308 - INFO - Epoch: [32][0/391] Time 0.177 (0.177) Data 0.146 (0.146) Loss 0.5836 (0.5836) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:24:17,151 - INFO - Epoch: [32][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.3856 (0.4347) Acc@1 85.938 (85.326) Acc@5 100.000 (99.296)
2025-08-27 21:24:17,673 - INFO - Pruning info: sparsity=0.406
2025-08-27 21:24:17,673 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:24:19,068 - INFO - Epoch: [32][200/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4424 (0.4421) Acc@1 86.719 (84.935) Acc@5 100.000 (99.355)
2025-08-27 21:24:20,838 - INFO - Pruning info: sparsity=0.406
2025-08-27 21:24:20,839 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:24:21,076 - INFO - Epoch: [32][300/391] Time 0.028 (0.020) Data 0.013 (0.003) Loss 0.4979 (0.4482) Acc@1 82.031 (84.627) Acc@5 99.219 (99.336)
2025-08-27 21:24:22,971 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.5784 (0.5784) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 21:24:23,814 - INFO - Epoch 32:
2025-08-27 21:24:23,814 - INFO -   Train: acc1: 84.5340 | acc5: 99.3140 | loss: 0.4518 | sparsity: 0.4058 | reactivation_rate: 0.0030
2025-08-27 21:24:23,814 - INFO -   Val:   acc1: 80.0700 | acc5: 98.9600 | loss: 0.6015
2025-08-27 21:24:23,814 - INFO -   LR: 0.100000
2025-08-27 21:24:23,825 - INFO - 
Epoch: 33, lr = 0.1
2025-08-27 21:24:24,001 - INFO - Epoch: [33][0/391] Time 0.175 (0.175) Data 0.152 (0.152) Loss 0.4642 (0.4642) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 21:24:25,094 - INFO - Pruning info: sparsity=0.412
2025-08-27 21:24:25,094 - INFO -   Reactivation rate: 0.0044
2025-08-27 21:24:25,915 - INFO - Epoch: [33][100/391] Time 0.020 (0.021) Data 0.006 (0.003) Loss 0.4982 (0.4682) Acc@1 80.469 (83.872) Acc@5 100.000 (99.312)
2025-08-27 21:24:27,866 - INFO - Epoch: [33][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4954 (0.4445) Acc@1 80.469 (84.713) Acc@5 99.219 (99.347)
2025-08-27 21:24:28,135 - INFO - Pruning info: sparsity=0.412
2025-08-27 21:24:28,135 - INFO -   Reactivation rate: 0.0026
2025-08-27 21:24:29,701 - INFO - Epoch: [33][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3709 (0.4493) Acc@1 89.844 (84.585) Acc@5 98.438 (99.343)
2025-08-27 21:24:31,186 - INFO - Pruning info: sparsity=0.412
2025-08-27 21:24:31,186 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:24:31,561 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5655 (0.5655) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 21:24:32,398 - INFO - Epoch 33:
2025-08-27 21:24:32,398 - INFO -   Train: acc1: 84.5020 | acc5: 99.3020 | loss: 0.4523 | sparsity: 0.4122 | reactivation_rate: 0.0029
2025-08-27 21:24:32,398 - INFO -   Val:   acc1: 78.8000 | acc5: 98.7100 | loss: 0.6520
2025-08-27 21:24:32,398 - INFO -   LR: 0.100000
2025-08-27 21:24:32,409 - INFO - 
Epoch: 34, lr = 0.1
2025-08-27 21:24:32,566 - INFO - Epoch: [34][0/391] Time 0.157 (0.157) Data 0.137 (0.137) Loss 0.4987 (0.4987) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 21:24:34,674 - INFO - Epoch: [34][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.5270 (0.4315) Acc@1 82.812 (85.172) Acc@5 98.438 (99.327)
2025-08-27 21:24:35,567 - INFO - Pruning info: sparsity=0.418
2025-08-27 21:24:35,567 - INFO -   Reactivation rate: 0.0029
2025-08-27 21:24:36,678 - INFO - Epoch: [34][200/391] Time 0.029 (0.021) Data 0.013 (0.002) Loss 0.3302 (0.4394) Acc@1 88.281 (84.880) Acc@5 99.219 (99.335)
2025-08-27 21:24:38,644 - INFO - Epoch: [34][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.6447 (0.4439) Acc@1 77.344 (84.803) Acc@5 99.219 (99.374)
2025-08-27 21:24:38,760 - INFO - Pruning info: sparsity=0.418
2025-08-27 21:24:38,760 - INFO -   Reactivation rate: 0.0022
2025-08-27 21:24:40,518 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.7901 (0.7901) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 21:24:41,356 - INFO - Epoch 34:
2025-08-27 21:24:41,357 - INFO -   Train: acc1: 84.5060 | acc5: 99.3440 | loss: 0.4525 | sparsity: 0.4183 | reactivation_rate: 0.0028
2025-08-27 21:24:41,357 - INFO -   Val:   acc1: 74.2700 | acc5: 98.4400 | loss: 0.8825
2025-08-27 21:24:41,357 - INFO -   LR: 0.100000
2025-08-27 21:24:41,366 - INFO - 
Epoch: 35, lr = 0.1
2025-08-27 21:24:41,557 - INFO - Epoch: [35][0/391] Time 0.190 (0.190) Data 0.163 (0.163) Loss 0.3903 (0.3903) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:24:42,999 - INFO - Pruning info: sparsity=0.424
2025-08-27 21:24:43,000 - INFO -   Reactivation rate: 0.0037
2025-08-27 21:24:43,491 - INFO - Epoch: [35][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.5333 (0.4415) Acc@1 81.250 (85.087) Acc@5 98.438 (99.350)
2025-08-27 21:24:45,436 - INFO - Epoch: [35][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.4560 (0.4343) Acc@1 85.938 (85.285) Acc@5 100.000 (99.312)
2025-08-27 21:24:46,094 - INFO - Pruning info: sparsity=0.424
2025-08-27 21:24:46,095 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:24:47,336 - INFO - Epoch: [35][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3890 (0.4393) Acc@1 85.156 (85.019) Acc@5 99.219 (99.284)
2025-08-27 21:24:49,079 - INFO - Test: [0/79] Time 0.111 (0.111) Loss 0.6517 (0.6517) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 21:24:49,916 - INFO - Epoch 35:
2025-08-27 21:24:49,916 - INFO -   Train: acc1: 84.9580 | acc5: 99.2980 | loss: 0.4422 | sparsity: 0.4241 | reactivation_rate: 0.0027
2025-08-27 21:24:49,916 - INFO -   Val:   acc1: 77.0800 | acc5: 98.0800 | loss: 0.7181
2025-08-27 21:24:49,916 - INFO -   LR: 0.100000
2025-08-27 21:24:49,926 - INFO - 
Epoch: 36, lr = 0.1
2025-08-27 21:24:50,102 - INFO - Epoch: [36][0/391] Time 0.175 (0.175) Data 0.150 (0.150) Loss 0.4189 (0.4189) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:24:50,166 - INFO - Pruning info: sparsity=0.430
2025-08-27 21:24:50,167 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:24:52,003 - INFO - Epoch: [36][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.4072 (0.4401) Acc@1 83.594 (84.986) Acc@5 100.000 (99.327)
2025-08-27 21:24:53,296 - INFO - Pruning info: sparsity=0.430
2025-08-27 21:24:53,296 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:24:53,998 - INFO - Epoch: [36][200/391] Time 0.022 (0.020) Data 0.002 (0.002) Loss 0.3438 (0.4428) Acc@1 89.844 (84.923) Acc@5 100.000 (99.293)
2025-08-27 21:24:55,966 - INFO - Epoch: [36][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.5300 (0.4488) Acc@1 82.812 (84.653) Acc@5 98.438 (99.260)
2025-08-27 21:24:56,431 - INFO - Pruning info: sparsity=0.430
2025-08-27 21:24:56,431 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:24:57,809 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.7489 (0.7489) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-27 21:24:58,642 - INFO - Epoch 36:
2025-08-27 21:24:58,642 - INFO -   Train: acc1: 84.6840 | acc5: 99.2920 | loss: 0.4489 | sparsity: 0.4297 | reactivation_rate: 0.0027
2025-08-27 21:24:58,642 - INFO -   Val:   acc1: 75.0700 | acc5: 98.5800 | loss: 0.7837
2025-08-27 21:24:58,642 - INFO -   LR: 0.100000
2025-08-27 21:24:58,652 - INFO - 
Epoch: 37, lr = 0.1
2025-08-27 21:24:58,820 - INFO - Epoch: [37][0/391] Time 0.166 (0.166) Data 0.139 (0.139) Loss 0.3872 (0.3872) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:25:00,630 - INFO - Pruning info: sparsity=0.435
2025-08-27 21:25:00,630 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:25:00,775 - INFO - Epoch: [37][100/391] Time 0.027 (0.021) Data 0.000 (0.002) Loss 0.4887 (0.4460) Acc@1 85.156 (84.630) Acc@5 99.219 (99.350)
2025-08-27 21:25:02,742 - INFO - Epoch: [37][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4095 (0.4587) Acc@1 85.156 (84.278) Acc@5 100.000 (99.300)
2025-08-27 21:25:03,696 - INFO - Pruning info: sparsity=0.435
2025-08-27 21:25:03,696 - INFO -   Reactivation rate: 0.0021
2025-08-27 21:25:04,603 - INFO - Epoch: [37][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.6013 (0.4530) Acc@1 79.688 (84.487) Acc@5 98.438 (99.336)
2025-08-27 21:25:06,445 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.6175 (0.6175) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 21:25:07,259 - INFO - Epoch 37:
2025-08-27 21:25:07,260 - INFO -   Train: acc1: 84.5080 | acc5: 99.3400 | loss: 0.4526 | sparsity: 0.4350 | reactivation_rate: 0.0026
2025-08-27 21:25:07,260 - INFO -   Val:   acc1: 78.0100 | acc5: 99.0800 | loss: 0.6698
2025-08-27 21:25:07,260 - INFO -   LR: 0.100000
2025-08-27 21:25:07,270 - INFO - 
Epoch: 38, lr = 0.1
2025-08-27 21:25:07,437 - INFO - Epoch: [38][0/391] Time 0.166 (0.166) Data 0.137 (0.137) Loss 0.4071 (0.4071) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:25:07,871 - INFO - Pruning info: sparsity=0.440
2025-08-27 21:25:07,871 - INFO -   Reactivation rate: 0.0047
2025-08-27 21:25:09,342 - INFO - Epoch: [38][100/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.5275 (0.4376) Acc@1 78.906 (85.303) Acc@5 99.219 (99.257)
2025-08-27 21:25:10,892 - INFO - Pruning info: sparsity=0.440
2025-08-27 21:25:10,893 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:25:11,235 - INFO - Epoch: [38][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.3515 (0.4424) Acc@1 89.062 (84.981) Acc@5 100.000 (99.304)
2025-08-27 21:25:13,154 - INFO - Epoch: [38][300/391] Time 0.018 (0.020) Data 0.000 (0.001) Loss 0.5350 (0.4460) Acc@1 78.906 (84.702) Acc@5 100.000 (99.333)
2025-08-27 21:25:13,909 - INFO - Pruning info: sparsity=0.440
2025-08-27 21:25:13,909 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:25:14,948 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.6155 (0.6155) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:25:15,765 - INFO - Epoch 38:
2025-08-27 21:25:15,766 - INFO -   Train: acc1: 84.7380 | acc5: 99.3360 | loss: 0.4454 | sparsity: 0.4400 | reactivation_rate: 0.0025
2025-08-27 21:25:15,766 - INFO -   Val:   acc1: 79.0500 | acc5: 99.1700 | loss: 0.6210
2025-08-27 21:25:15,766 - INFO -   LR: 0.100000
2025-08-27 21:25:15,778 - INFO - 
Epoch: 39, lr = 0.1
2025-08-27 21:25:15,957 - INFO - Epoch: [39][0/391] Time 0.178 (0.178) Data 0.156 (0.156) Loss 0.3466 (0.3466) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:25:17,837 - INFO - Epoch: [39][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4934 (0.4357) Acc@1 83.594 (85.133) Acc@5 99.219 (99.327)
2025-08-27 21:25:18,049 - INFO - Pruning info: sparsity=0.445
2025-08-27 21:25:18,050 - INFO -   Reactivation rate: 0.0030
2025-08-27 21:25:19,788 - INFO - Epoch: [39][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.6088 (0.4412) Acc@1 80.469 (84.779) Acc@5 97.656 (99.335)
2025-08-27 21:25:21,153 - INFO - Pruning info: sparsity=0.445
2025-08-27 21:25:21,154 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:25:21,742 - INFO - Epoch: [39][300/391] Time 0.016 (0.020) Data 0.002 (0.002) Loss 0.4655 (0.4443) Acc@1 82.812 (84.653) Acc@5 99.219 (99.349)
2025-08-27 21:25:23,588 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5143 (0.5143) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 21:25:24,421 - INFO - Epoch 39:
2025-08-27 21:25:24,422 - INFO -   Train: acc1: 84.5580 | acc5: 99.3260 | loss: 0.4486 | sparsity: 0.4447 | reactivation_rate: 0.0025
2025-08-27 21:25:24,422 - INFO -   Val:   acc1: 81.5600 | acc5: 98.9900 | loss: 0.5546
2025-08-27 21:25:24,422 - INFO -   LR: 0.100000
2025-08-27 21:25:24,433 - INFO - 
Epoch: 40, lr = 0.1
2025-08-27 21:25:24,593 - INFO - Epoch: [40][0/391] Time 0.159 (0.159) Data 0.133 (0.133) Loss 0.4100 (0.4100) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 21:25:25,331 - INFO - Pruning info: sparsity=0.449
2025-08-27 21:25:25,331 - INFO -   Reactivation rate: 0.0039
2025-08-27 21:25:26,388 - INFO - Epoch: [40][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3513 (0.4365) Acc@1 88.281 (85.234) Acc@5 99.219 (99.358)
2025-08-27 21:25:28,289 - INFO - Pruning info: sparsity=0.449
2025-08-27 21:25:28,289 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:25:28,305 - INFO - Epoch: [40][200/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.4046 (0.4362) Acc@1 89.062 (85.152) Acc@5 99.219 (99.378)
2025-08-27 21:25:30,112 - INFO - Epoch: [40][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4503 (0.4390) Acc@1 83.594 (85.008) Acc@5 99.219 (99.372)
2025-08-27 21:25:31,158 - INFO - Pruning info: sparsity=0.449
2025-08-27 21:25:31,158 - INFO -   Reactivation rate: 0.0016
2025-08-27 21:25:31,841 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.5235 (0.5235) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:25:32,720 - INFO - Epoch 40:
2025-08-27 21:25:32,720 - INFO -   Train: acc1: 85.0160 | acc5: 99.3660 | loss: 0.4411 | sparsity: 0.4492 | reactivation_rate: 0.0024
2025-08-27 21:25:32,720 - INFO -   Val:   acc1: 80.0900 | acc5: 99.0700 | loss: 0.5977
2025-08-27 21:25:32,720 - INFO -   LR: 0.100000
2025-08-27 21:25:32,762 - INFO - 
Epoch: 41, lr = 0.1
2025-08-27 21:25:32,941 - INFO - Epoch: [41][0/391] Time 0.179 (0.179) Data 0.154 (0.154) Loss 0.3499 (0.3499) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 21:25:34,827 - INFO - Epoch: [41][100/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.4768 (0.4154) Acc@1 85.156 (86.023) Acc@5 100.000 (99.366)
2025-08-27 21:25:35,306 - INFO - Pruning info: sparsity=0.453
2025-08-27 21:25:35,306 - INFO -   Reactivation rate: 0.0026
2025-08-27 21:25:36,666 - INFO - Epoch: [41][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4344 (0.4342) Acc@1 85.156 (85.218) Acc@5 98.438 (99.328)
2025-08-27 21:25:38,274 - INFO - Pruning info: sparsity=0.453
2025-08-27 21:25:38,274 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:25:38,445 - INFO - Epoch: [41][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4324 (0.4359) Acc@1 87.500 (85.151) Acc@5 100.000 (99.364)
2025-08-27 21:25:40,354 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.4699 (0.4699) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:25:41,191 - INFO - Epoch 41:
2025-08-27 21:25:41,191 - INFO -   Train: acc1: 84.9180 | acc5: 99.3540 | loss: 0.4412 | sparsity: 0.4534 | reactivation_rate: 0.0023
2025-08-27 21:25:41,192 - INFO -   Val:   acc1: 80.2700 | acc5: 98.9600 | loss: 0.5730
2025-08-27 21:25:41,192 - INFO -   LR: 0.100000
2025-08-27 21:25:41,204 - INFO - 
Epoch: 42, lr = 0.1
2025-08-27 21:25:41,387 - INFO - Epoch: [42][0/391] Time 0.181 (0.181) Data 0.158 (0.158) Loss 0.4035 (0.4035) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 21:25:42,497 - INFO - Pruning info: sparsity=0.457
2025-08-27 21:25:42,498 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:25:43,255 - INFO - Epoch: [42][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.5637 (0.4337) Acc@1 79.688 (85.102) Acc@5 100.000 (99.350)
2025-08-27 21:25:45,208 - INFO - Epoch: [42][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.5731 (0.4361) Acc@1 78.906 (84.950) Acc@5 97.656 (99.401)
2025-08-27 21:25:45,542 - INFO - Pruning info: sparsity=0.457
2025-08-27 21:25:45,542 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:25:47,097 - INFO - Epoch: [42][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3483 (0.4460) Acc@1 84.375 (84.577) Acc@5 100.000 (99.377)
2025-08-27 21:25:48,541 - INFO - Pruning info: sparsity=0.457
2025-08-27 21:25:48,542 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:25:48,893 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.6236 (0.6236) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 21:25:49,734 - INFO - Epoch 42:
2025-08-27 21:25:49,734 - INFO -   Train: acc1: 84.6800 | acc5: 99.3880 | loss: 0.4448 | sparsity: 0.4574 | reactivation_rate: 0.0022
2025-08-27 21:25:49,734 - INFO -   Val:   acc1: 78.6000 | acc5: 98.2200 | loss: 0.6356
2025-08-27 21:25:49,734 - INFO -   LR: 0.100000
2025-08-27 21:25:49,747 - INFO - 
Epoch: 43, lr = 0.1
2025-08-27 21:25:49,927 - INFO - Epoch: [43][0/391] Time 0.179 (0.179) Data 0.154 (0.154) Loss 0.3656 (0.3656) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:25:51,906 - INFO - Epoch: [43][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4198 (0.4534) Acc@1 85.938 (84.112) Acc@5 100.000 (99.420)
2025-08-27 21:25:52,809 - INFO - Pruning info: sparsity=0.461
2025-08-27 21:25:52,810 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:25:53,830 - INFO - Epoch: [43][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3893 (0.4434) Acc@1 83.594 (84.534) Acc@5 100.000 (99.351)
2025-08-27 21:25:55,747 - INFO - Epoch: [43][300/391] Time 0.020 (0.020) Data 0.009 (0.002) Loss 0.2879 (0.4410) Acc@1 91.406 (84.710) Acc@5 100.000 (99.356)
2025-08-27 21:25:55,867 - INFO - Pruning info: sparsity=0.461
2025-08-27 21:25:55,868 - INFO -   Reactivation rate: 0.0016
2025-08-27 21:25:57,511 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.7045 (0.7045) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 21:25:58,369 - INFO - Epoch 43:
2025-08-27 21:25:58,369 - INFO -   Train: acc1: 84.6720 | acc5: 99.3620 | loss: 0.4415 | sparsity: 0.4612 | reactivation_rate: 0.0022
2025-08-27 21:25:58,369 - INFO -   Val:   acc1: 79.4700 | acc5: 98.8200 | loss: 0.6651
2025-08-27 21:25:58,369 - INFO -   LR: 0.100000
2025-08-27 21:25:58,382 - INFO - 
Epoch: 44, lr = 0.1
2025-08-27 21:25:58,539 - INFO - Epoch: [44][0/391] Time 0.156 (0.156) Data 0.130 (0.130) Loss 0.3803 (0.3803) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 21:25:59,922 - INFO - Pruning info: sparsity=0.465
2025-08-27 21:25:59,922 - INFO -   Reactivation rate: 0.0029
2025-08-27 21:26:00,376 - INFO - Epoch: [44][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4116 (0.4293) Acc@1 89.062 (85.195) Acc@5 100.000 (99.420)
2025-08-27 21:26:02,172 - INFO - Epoch: [44][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4160 (0.4289) Acc@1 87.500 (85.234) Acc@5 99.219 (99.394)
2025-08-27 21:26:02,837 - INFO - Pruning info: sparsity=0.465
2025-08-27 21:26:02,837 - INFO -   Reactivation rate: 0.0018
2025-08-27 21:26:04,025 - INFO - Epoch: [44][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2911 (0.4300) Acc@1 92.188 (85.187) Acc@5 99.219 (99.369)
2025-08-27 21:26:05,871 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.7994 (0.7994) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-27 21:26:06,765 - INFO - Epoch 44:
2025-08-27 21:26:06,765 - INFO -   Train: acc1: 85.1620 | acc5: 99.3980 | loss: 0.4310 | sparsity: 0.4647 | reactivation_rate: 0.0021
2025-08-27 21:26:06,765 - INFO -   Val:   acc1: 75.0300 | acc5: 98.2900 | loss: 0.7586
2025-08-27 21:26:06,765 - INFO -   LR: 0.100000
2025-08-27 21:26:06,777 - INFO - 
Epoch: 45, lr = 0.1
2025-08-27 21:26:06,951 - INFO - Epoch: [45][0/391] Time 0.173 (0.173) Data 0.147 (0.147) Loss 0.3333 (0.3333) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:26:07,036 - INFO - Pruning info: sparsity=0.468
2025-08-27 21:26:07,036 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:26:08,783 - INFO - Epoch: [45][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.6160 (0.4420) Acc@1 78.906 (85.118) Acc@5 99.219 (99.304)
2025-08-27 21:26:09,960 - INFO - Pruning info: sparsity=0.468
2025-08-27 21:26:09,960 - INFO -   Reactivation rate: 0.0021
2025-08-27 21:26:10,669 - INFO - Epoch: [45][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3348 (0.4413) Acc@1 89.062 (84.876) Acc@5 100.000 (99.312)
2025-08-27 21:26:12,549 - INFO - Epoch: [45][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4448 (0.4441) Acc@1 83.594 (84.868) Acc@5 100.000 (99.338)
2025-08-27 21:26:13,006 - INFO - Pruning info: sparsity=0.468
2025-08-27 21:26:13,006 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:26:14,411 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4910 (0.4910) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:26:15,222 - INFO - Epoch 45:
2025-08-27 21:26:15,222 - INFO -   Train: acc1: 84.9140 | acc5: 99.3440 | loss: 0.4435 | sparsity: 0.4680 | reactivation_rate: 0.0020
2025-08-27 21:26:15,222 - INFO -   Val:   acc1: 80.8000 | acc5: 98.7600 | loss: 0.5813
2025-08-27 21:26:15,222 - INFO -   LR: 0.100000
2025-08-27 21:26:15,234 - INFO - 
Epoch: 46, lr = 0.1
2025-08-27 21:26:15,407 - INFO - Epoch: [46][0/391] Time 0.172 (0.172) Data 0.135 (0.135) Loss 0.4433 (0.4433) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:26:17,096 - INFO - Pruning info: sparsity=0.471
2025-08-27 21:26:17,096 - INFO -   Reactivation rate: 0.0025
2025-08-27 21:26:17,211 - INFO - Epoch: [46][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4180 (0.4198) Acc@1 85.938 (85.713) Acc@5 100.000 (99.520)
2025-08-27 21:26:19,143 - INFO - Epoch: [46][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.4155 (0.4286) Acc@1 84.375 (85.323) Acc@5 100.000 (99.405)
2025-08-27 21:26:20,129 - INFO - Pruning info: sparsity=0.471
2025-08-27 21:26:20,130 - INFO -   Reactivation rate: 0.0016
2025-08-27 21:26:21,006 - INFO - Epoch: [46][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.3798 (0.4320) Acc@1 88.281 (85.190) Acc@5 100.000 (99.346)
2025-08-27 21:26:22,916 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.5768 (0.5768) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 21:26:23,748 - INFO - Epoch 46:
2025-08-27 21:26:23,748 - INFO -   Train: acc1: 84.9560 | acc5: 99.3480 | loss: 0.4379 | sparsity: 0.4711 | reactivation_rate: 0.0019
2025-08-27 21:26:23,748 - INFO -   Val:   acc1: 79.7400 | acc5: 99.0700 | loss: 0.6091
2025-08-27 21:26:23,748 - INFO -   LR: 0.100000
2025-08-27 21:26:23,759 - INFO - 
Epoch: 47, lr = 0.1
2025-08-27 21:26:23,937 - INFO - Epoch: [47][0/391] Time 0.177 (0.177) Data 0.152 (0.152) Loss 0.5735 (0.5735) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 21:26:24,405 - INFO - Pruning info: sparsity=0.474
2025-08-27 21:26:24,405 - INFO -   Reactivation rate: 0.0033
2025-08-27 21:26:25,929 - INFO - Epoch: [47][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4260 (0.4247) Acc@1 82.031 (85.566) Acc@5 98.438 (99.412)
2025-08-27 21:26:27,432 - INFO - Pruning info: sparsity=0.474
2025-08-27 21:26:27,433 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:26:27,746 - INFO - Epoch: [47][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4799 (0.4311) Acc@1 84.375 (85.137) Acc@5 100.000 (99.328)
2025-08-27 21:26:29,583 - INFO - Epoch: [47][300/391] Time 0.035 (0.019) Data 0.019 (0.002) Loss 0.4374 (0.4335) Acc@1 80.469 (85.003) Acc@5 99.219 (99.328)
2025-08-27 21:26:30,362 - INFO - Pruning info: sparsity=0.474
2025-08-27 21:26:30,362 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:26:31,371 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.7694 (0.7694) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 21:26:32,273 - INFO - Epoch 47:
2025-08-27 21:26:32,273 - INFO -   Train: acc1: 84.8300 | acc5: 99.3400 | loss: 0.4409 | sparsity: 0.4740 | reactivation_rate: 0.0019
2025-08-27 21:26:32,273 - INFO -   Val:   acc1: 79.2700 | acc5: 98.6700 | loss: 0.6467
2025-08-27 21:26:32,273 - INFO -   LR: 0.100000
2025-08-27 21:26:32,285 - INFO - 
Epoch: 48, lr = 0.1
2025-08-27 21:26:32,457 - INFO - Epoch: [48][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 0.4172 (0.4172) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:26:34,304 - INFO - Epoch: [48][100/391] Time 0.022 (0.020) Data 0.004 (0.002) Loss 0.5298 (0.4142) Acc@1 80.469 (85.852) Acc@5 99.219 (99.412)
2025-08-27 21:26:34,506 - INFO - Pruning info: sparsity=0.477
2025-08-27 21:26:34,507 - INFO -   Reactivation rate: 0.0021
2025-08-27 21:26:36,137 - INFO - Epoch: [48][200/391] Time 0.023 (0.019) Data 0.013 (0.001) Loss 0.3865 (0.4243) Acc@1 88.281 (85.312) Acc@5 98.438 (99.374)
2025-08-27 21:26:37,448 - INFO - Pruning info: sparsity=0.477
2025-08-27 21:26:37,449 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:26:37,976 - INFO - Epoch: [48][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.4305 (0.4300) Acc@1 86.719 (85.174) Acc@5 100.000 (99.374)
2025-08-27 21:26:39,716 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 1.0072 (1.0072) Acc@1 71.094 (71.094) Acc@5 96.875 (96.875)
2025-08-27 21:26:40,552 - INFO - Epoch 48:
2025-08-27 21:26:40,552 - INFO -   Train: acc1: 85.0080 | acc5: 99.3500 | loss: 0.4350 | sparsity: 0.4767 | reactivation_rate: 0.0018
2025-08-27 21:26:40,552 - INFO -   Val:   acc1: 71.0400 | acc5: 97.5400 | loss: 0.9572
2025-08-27 21:26:40,552 - INFO -   LR: 0.100000
2025-08-27 21:26:40,562 - INFO - 
Epoch: 49, lr = 0.1
2025-08-27 21:26:40,738 - INFO - Epoch: [49][0/391] Time 0.175 (0.175) Data 0.154 (0.154) Loss 0.6075 (0.6075) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 21:26:41,491 - INFO - Pruning info: sparsity=0.479
2025-08-27 21:26:41,491 - INFO -   Reactivation rate: 0.0027
2025-08-27 21:26:42,600 - INFO - Epoch: [49][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4144 (0.4272) Acc@1 88.281 (85.311) Acc@5 100.000 (99.404)
2025-08-27 21:26:44,444 - INFO - Epoch: [49][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.3706 (0.4276) Acc@1 87.500 (85.195) Acc@5 100.000 (99.343)
2025-08-27 21:26:44,449 - INFO - Pruning info: sparsity=0.479
2025-08-27 21:26:44,450 - INFO -   Reactivation rate: 0.0016
2025-08-27 21:26:46,263 - INFO - Epoch: [49][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.3831 (0.4349) Acc@1 86.719 (85.037) Acc@5 100.000 (99.310)
2025-08-27 21:26:47,444 - INFO - Pruning info: sparsity=0.479
2025-08-27 21:26:47,444 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:26:48,100 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7321 (0.7321) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 21:26:49,000 - INFO - Epoch 49:
2025-08-27 21:26:49,000 - INFO -   Train: acc1: 85.0240 | acc5: 99.3180 | loss: 0.4351 | sparsity: 0.4792 | reactivation_rate: 0.0017
2025-08-27 21:26:49,000 - INFO -   Val:   acc1: 78.2600 | acc5: 98.6600 | loss: 0.7032
2025-08-27 21:26:49,000 - INFO -   LR: 0.100000
2025-08-27 21:26:49,011 - INFO - 
Epoch: 50, lr = 0.1
2025-08-27 21:26:49,177 - INFO - Epoch: [50][0/391] Time 0.165 (0.165) Data 0.143 (0.143) Loss 0.3795 (0.3795) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 21:26:51,020 - INFO - Epoch: [50][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5366 (0.4256) Acc@1 81.250 (85.705) Acc@5 100.000 (99.358)
2025-08-27 21:26:51,566 - INFO - Pruning info: sparsity=0.481
2025-08-27 21:26:51,566 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:26:52,887 - INFO - Epoch: [50][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.3528 (0.4329) Acc@1 85.938 (85.183) Acc@5 100.000 (99.312)
2025-08-27 21:26:54,497 - INFO - Pruning info: sparsity=0.481
2025-08-27 21:26:54,497 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:26:54,701 - INFO - Epoch: [50][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3505 (0.4325) Acc@1 86.719 (85.229) Acc@5 100.000 (99.338)
2025-08-27 21:26:56,479 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.5486 (0.5486) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 21:26:57,322 - INFO - Epoch 50:
2025-08-27 21:26:57,322 - INFO -   Train: acc1: 85.2080 | acc5: 99.3200 | loss: 0.4339 | sparsity: 0.4815 | reactivation_rate: 0.0017
2025-08-27 21:26:57,322 - INFO -   Val:   acc1: 81.1200 | acc5: 99.2100 | loss: 0.5632
2025-08-27 21:26:57,322 - INFO -   LR: 0.100000
2025-08-27 21:26:57,368 - INFO - 
Epoch: 51, lr = 0.1
2025-08-27 21:26:57,555 - INFO - Epoch: [51][0/391] Time 0.186 (0.186) Data 0.152 (0.152) Loss 0.4915 (0.4915) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:26:58,607 - INFO - Pruning info: sparsity=0.484
2025-08-27 21:26:58,608 - INFO -   Reactivation rate: 0.0023
2025-08-27 21:26:59,409 - INFO - Epoch: [51][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3695 (0.4264) Acc@1 87.500 (85.388) Acc@5 99.219 (99.335)
2025-08-27 21:27:01,340 - INFO - Epoch: [51][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.4811 (0.4222) Acc@1 86.719 (85.529) Acc@5 100.000 (99.394)
2025-08-27 21:27:01,689 - INFO - Pruning info: sparsity=0.484
2025-08-27 21:27:01,689 - INFO -   Reactivation rate: 0.0015
2025-08-27 21:27:03,256 - INFO - Epoch: [51][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3185 (0.4286) Acc@1 91.406 (85.465) Acc@5 100.000 (99.372)
2025-08-27 21:27:04,691 - INFO - Pruning info: sparsity=0.484
2025-08-27 21:27:04,692 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:27:05,073 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.6334 (0.6334) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 21:27:05,911 - INFO - Epoch 51:
2025-08-27 21:27:05,911 - INFO -   Train: acc1: 85.2860 | acc5: 99.3620 | loss: 0.4330 | sparsity: 0.4836 | reactivation_rate: 0.0016
2025-08-27 21:27:05,911 - INFO -   Val:   acc1: 77.4600 | acc5: 98.5300 | loss: 0.7147
2025-08-27 21:27:05,911 - INFO -   LR: 0.100000
2025-08-27 21:27:05,923 - INFO - 
Epoch: 52, lr = 0.1
2025-08-27 21:27:06,107 - INFO - Epoch: [52][0/391] Time 0.183 (0.183) Data 0.149 (0.149) Loss 0.4394 (0.4394) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:27:07,972 - INFO - Epoch: [52][100/391] Time 0.027 (0.020) Data 0.000 (0.003) Loss 0.3226 (0.4065) Acc@1 88.281 (86.425) Acc@5 99.219 (99.420)
2025-08-27 21:27:08,839 - INFO - Pruning info: sparsity=0.486
2025-08-27 21:27:08,839 - INFO -   Reactivation rate: 0.0017
2025-08-27 21:27:09,834 - INFO - Epoch: [52][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.4968 (0.4350) Acc@1 81.250 (85.327) Acc@5 100.000 (99.296)
2025-08-27 21:27:11,747 - INFO - Epoch: [52][300/391] Time 0.022 (0.019) Data 0.001 (0.001) Loss 0.3635 (0.4377) Acc@1 89.062 (85.148) Acc@5 100.000 (99.317)
2025-08-27 21:27:11,903 - INFO - Pruning info: sparsity=0.486
2025-08-27 21:27:11,904 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:27:13,549 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.5484 (0.5484) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:27:14,361 - INFO - Epoch 52:
2025-08-27 21:27:14,361 - INFO -   Train: acc1: 85.1280 | acc5: 99.3240 | loss: 0.4379 | sparsity: 0.4856 | reactivation_rate: 0.0015
2025-08-27 21:27:14,361 - INFO -   Val:   acc1: 80.0800 | acc5: 98.8900 | loss: 0.5936
2025-08-27 21:27:14,361 - INFO -   LR: 0.100000
2025-08-27 21:27:14,373 - INFO - 
Epoch: 53, lr = 0.1
2025-08-27 21:27:14,551 - INFO - Epoch: [53][0/391] Time 0.177 (0.177) Data 0.158 (0.158) Loss 0.4800 (0.4800) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 21:27:16,063 - INFO - Pruning info: sparsity=0.487
2025-08-27 21:27:16,064 - INFO -   Reactivation rate: 0.0020
2025-08-27 21:27:16,478 - INFO - Epoch: [53][100/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.4624 (0.4341) Acc@1 82.031 (85.118) Acc@5 100.000 (99.358)
2025-08-27 21:27:18,272 - INFO - Epoch: [53][200/391] Time 0.028 (0.019) Data 0.014 (0.002) Loss 0.4112 (0.4348) Acc@1 88.281 (84.989) Acc@5 100.000 (99.421)
2025-08-27 21:27:18,927 - INFO - Pruning info: sparsity=0.487
2025-08-27 21:27:18,927 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:27:20,157 - INFO - Epoch: [53][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3447 (0.4332) Acc@1 89.062 (85.130) Acc@5 100.000 (99.411)
2025-08-27 21:27:21,971 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.5445 (0.5445) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:27:22,843 - INFO - Epoch 53:
2025-08-27 21:27:22,843 - INFO -   Train: acc1: 85.0580 | acc5: 99.4180 | loss: 0.4337 | sparsity: 0.4874 | reactivation_rate: 0.0015
2025-08-27 21:27:22,843 - INFO -   Val:   acc1: 80.2300 | acc5: 98.7200 | loss: 0.6156
2025-08-27 21:27:22,843 - INFO -   LR: 0.100000
2025-08-27 21:27:22,856 - INFO - 
Epoch: 54, lr = 0.1
2025-08-27 21:27:23,040 - INFO - Epoch: [54][0/391] Time 0.183 (0.183) Data 0.153 (0.153) Loss 0.3963 (0.3963) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:27:23,143 - INFO - Pruning info: sparsity=0.489
2025-08-27 21:27:23,143 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:27:24,893 - INFO - Epoch: [54][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.4103 (0.4344) Acc@1 86.719 (85.149) Acc@5 98.438 (99.389)
2025-08-27 21:27:26,054 - INFO - Pruning info: sparsity=0.489
2025-08-27 21:27:26,054 - INFO -   Reactivation rate: 0.0014
2025-08-27 21:27:26,743 - INFO - Epoch: [54][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.5490 (0.4315) Acc@1 78.906 (85.292) Acc@5 100.000 (99.382)
2025-08-27 21:27:28,502 - INFO - Epoch: [54][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4172 (0.4277) Acc@1 88.281 (85.437) Acc@5 98.438 (99.377)
2025-08-27 21:27:28,923 - INFO - Pruning info: sparsity=0.489
2025-08-27 21:27:28,923 - INFO -   Reactivation rate: 0.0011
2025-08-27 21:27:30,341 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.4738 (0.4738) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 21:27:31,181 - INFO - Epoch 54:
2025-08-27 21:27:31,181 - INFO -   Train: acc1: 85.2400 | acc5: 99.4000 | loss: 0.4302 | sparsity: 0.4890 | reactivation_rate: 0.0014
2025-08-27 21:27:31,181 - INFO -   Val:   acc1: 81.2800 | acc5: 98.8100 | loss: 0.5749
2025-08-27 21:27:31,181 - INFO -   LR: 0.100000
2025-08-27 21:27:31,192 - INFO - 
Epoch: 55, lr = 0.1
2025-08-27 21:27:31,361 - INFO - Epoch: [55][0/391] Time 0.168 (0.168) Data 0.139 (0.139) Loss 0.2739 (0.2739) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-27 21:27:33,133 - INFO - Pruning info: sparsity=0.491
2025-08-27 21:27:33,133 - INFO -   Reactivation rate: 0.0017
2025-08-27 21:27:33,245 - INFO - Epoch: [55][100/391] Time 0.023 (0.020) Data 0.012 (0.004) Loss 0.4657 (0.4259) Acc@1 87.500 (85.133) Acc@5 100.000 (99.389)
2025-08-27 21:27:35,152 - INFO - Epoch: [55][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4417 (0.4298) Acc@1 84.375 (85.063) Acc@5 99.219 (99.394)
2025-08-27 21:27:36,118 - INFO - Pruning info: sparsity=0.491
2025-08-27 21:27:36,118 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:27:36,950 - INFO - Epoch: [55][300/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.3828 (0.4316) Acc@1 89.062 (85.167) Acc@5 100.000 (99.393)
2025-08-27 21:27:38,793 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6232 (0.6232) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:27:39,619 - INFO - Epoch 55:
2025-08-27 21:27:39,619 - INFO -   Train: acc1: 85.1040 | acc5: 99.3680 | loss: 0.4343 | sparsity: 0.4905 | reactivation_rate: 0.0013
2025-08-27 21:27:39,619 - INFO -   Val:   acc1: 76.0500 | acc5: 99.1000 | loss: 0.7327
2025-08-27 21:27:39,619 - INFO -   LR: 0.100000
2025-08-27 21:27:39,631 - INFO - 
Epoch: 56, lr = 0.1
2025-08-27 21:27:39,819 - INFO - Epoch: [56][0/391] Time 0.187 (0.187) Data 0.165 (0.165) Loss 0.4534 (0.4534) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:27:40,256 - INFO - Pruning info: sparsity=0.492
2025-08-27 21:27:40,256 - INFO -   Reactivation rate: 0.0019
2025-08-27 21:27:41,664 - INFO - Epoch: [56][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.4540 (0.4195) Acc@1 82.812 (85.613) Acc@5 99.219 (99.373)
2025-08-27 21:27:43,242 - INFO - Pruning info: sparsity=0.492
2025-08-27 21:27:43,242 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:27:43,555 - INFO - Epoch: [56][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.3934 (0.4320) Acc@1 85.156 (85.102) Acc@5 99.219 (99.363)
2025-08-27 21:27:45,382 - INFO - Epoch: [56][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4429 (0.4323) Acc@1 84.375 (85.206) Acc@5 100.000 (99.377)
2025-08-27 21:27:46,250 - INFO - Pruning info: sparsity=0.492
2025-08-27 21:27:46,250 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:27:47,283 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.4152 (0.4152) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 21:27:48,085 - INFO - Epoch 56:
2025-08-27 21:27:48,085 - INFO -   Train: acc1: 85.1240 | acc5: 99.3460 | loss: 0.4341 | sparsity: 0.4919 | reactivation_rate: 0.0013
2025-08-27 21:27:48,085 - INFO -   Val:   acc1: 82.1900 | acc5: 98.9000 | loss: 0.5264
2025-08-27 21:27:48,085 - INFO -   LR: 0.100000
2025-08-27 21:27:48,131 - INFO - Checkpoint saved: epoch=56, metric=82.1900
2025-08-27 21:27:48,164 - INFO - 
Epoch: 57, lr = 0.1
2025-08-27 21:27:48,345 - INFO - Epoch: [57][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.3413 (0.3413) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:27:50,251 - INFO - Epoch: [57][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4040 (0.4284) Acc@1 87.500 (85.226) Acc@5 100.000 (99.451)
2025-08-27 21:27:50,468 - INFO - Pruning info: sparsity=0.493
2025-08-27 21:27:50,468 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:27:52,130 - INFO - Epoch: [57][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4547 (0.4300) Acc@1 83.594 (85.141) Acc@5 99.219 (99.444)
2025-08-27 21:27:53,498 - INFO - Pruning info: sparsity=0.493
2025-08-27 21:27:53,498 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:27:54,008 - INFO - Epoch: [57][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.4445 (0.4291) Acc@1 85.938 (85.229) Acc@5 99.219 (99.439)
2025-08-27 21:27:55,883 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.8736 (0.8736) Acc@1 73.438 (73.438) Acc@5 98.438 (98.438)
2025-08-27 21:27:56,697 - INFO - Epoch 57:
2025-08-27 21:27:56,698 - INFO -   Train: acc1: 85.1540 | acc5: 99.4020 | loss: 0.4304 | sparsity: 0.4931 | reactivation_rate: 0.0011
2025-08-27 21:27:56,698 - INFO -   Val:   acc1: 74.3100 | acc5: 98.7200 | loss: 0.9247
2025-08-27 21:27:56,698 - INFO -   LR: 0.100000
2025-08-27 21:27:56,711 - INFO - 
Epoch: 58, lr = 0.1
2025-08-27 21:27:56,887 - INFO - Epoch: [58][0/391] Time 0.174 (0.174) Data 0.148 (0.148) Loss 0.4524 (0.4524) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:27:57,715 - INFO - Pruning info: sparsity=0.494
2025-08-27 21:27:57,715 - INFO -   Reactivation rate: 0.0016
2025-08-27 21:27:58,854 - INFO - Epoch: [58][100/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.3961 (0.4289) Acc@1 86.719 (85.071) Acc@5 99.219 (99.319)
2025-08-27 21:28:00,777 - INFO - Epoch: [58][200/391] Time 0.031 (0.020) Data 0.013 (0.002) Loss 0.4239 (0.4384) Acc@1 85.156 (84.834) Acc@5 99.219 (99.285)
2025-08-27 21:28:00,806 - INFO - Pruning info: sparsity=0.494
2025-08-27 21:28:00,807 - INFO -   Reactivation rate: 0.0011
2025-08-27 21:28:02,741 - INFO - Epoch: [58][300/391] Time 0.026 (0.020) Data 0.013 (0.002) Loss 0.4013 (0.4355) Acc@1 85.938 (84.980) Acc@5 99.219 (99.299)
2025-08-27 21:28:03,921 - INFO - Pruning info: sparsity=0.494
2025-08-27 21:28:03,921 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:28:04,609 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.7933 (0.7933) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-27 21:28:05,452 - INFO - Epoch 58:
2025-08-27 21:28:05,452 - INFO -   Train: acc1: 85.0760 | acc5: 99.3320 | loss: 0.4353 | sparsity: 0.4942 | reactivation_rate: 0.0011
2025-08-27 21:28:05,452 - INFO -   Val:   acc1: 72.3500 | acc5: 98.4500 | loss: 0.8588
2025-08-27 21:28:05,452 - INFO -   LR: 0.100000
2025-08-27 21:28:05,464 - INFO - 
Epoch: 59, lr = 0.1
2025-08-27 21:28:05,645 - INFO - Epoch: [59][0/391] Time 0.179 (0.179) Data 0.160 (0.160) Loss 0.4290 (0.4290) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:28:07,707 - INFO - Epoch: [59][100/391] Time 0.019 (0.022) Data 0.000 (0.005) Loss 0.4344 (0.4111) Acc@1 85.156 (86.030) Acc@5 98.438 (99.451)
2025-08-27 21:28:08,299 - INFO - Pruning info: sparsity=0.495
2025-08-27 21:28:08,299 - INFO -   Reactivation rate: 0.0012
2025-08-27 21:28:09,715 - INFO - Epoch: [59][200/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.6186 (0.4275) Acc@1 78.906 (85.343) Acc@5 96.875 (99.417)
2025-08-27 21:28:11,509 - INFO - Pruning info: sparsity=0.495
2025-08-27 21:28:11,509 - INFO -   Reactivation rate: 0.0009
2025-08-27 21:28:11,703 - INFO - Epoch: [59][300/391] Time 0.027 (0.021) Data 0.013 (0.003) Loss 0.4814 (0.4344) Acc@1 83.594 (85.026) Acc@5 99.219 (99.382)
2025-08-27 21:28:13,622 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5391 (0.5391) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 21:28:14,520 - INFO - Epoch 59:
2025-08-27 21:28:14,520 - INFO -   Train: acc1: 85.0260 | acc5: 99.4000 | loss: 0.4357 | sparsity: 0.4951 | reactivation_rate: 0.0011
2025-08-27 21:28:14,520 - INFO -   Val:   acc1: 79.4400 | acc5: 98.7200 | loss: 0.6169
2025-08-27 21:28:14,520 - INFO -   LR: 0.100000
2025-08-27 21:28:14,533 - INFO - 
Epoch: 60, lr = 0.1
2025-08-27 21:28:14,726 - INFO - Epoch: [60][0/391] Time 0.192 (0.192) Data 0.164 (0.164) Loss 0.3271 (0.3271) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 21:28:16,061 - INFO - Pruning info: sparsity=0.496
2025-08-27 21:28:16,061 - INFO -   Reactivation rate: 0.0013
2025-08-27 21:28:16,861 - INFO - Epoch: [60][100/391] Time 0.019 (0.023) Data 0.000 (0.004) Loss 0.4517 (0.4235) Acc@1 83.594 (85.852) Acc@5 99.219 (99.435)
2025-08-27 21:28:18,785 - INFO - Epoch: [60][200/391] Time 0.024 (0.021) Data 0.001 (0.002) Loss 0.3398 (0.4306) Acc@1 89.844 (85.319) Acc@5 99.219 (99.398)
2025-08-27 21:28:19,147 - INFO - Pruning info: sparsity=0.496
2025-08-27 21:28:19,147 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:28:20,760 - INFO - Epoch: [60][300/391] Time 0.026 (0.021) Data 0.000 (0.002) Loss 0.4643 (0.4307) Acc@1 80.469 (85.211) Acc@5 100.000 (99.367)
2025-08-27 21:28:22,292 - INFO - Pruning info: sparsity=0.496
2025-08-27 21:28:22,292 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:28:22,625 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6067 (0.6067) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:28:23,497 - INFO - Epoch 60:
2025-08-27 21:28:23,497 - INFO -   Train: acc1: 85.1560 | acc5: 99.3980 | loss: 0.4315 | sparsity: 0.4960 | reactivation_rate: 0.0010
2025-08-27 21:28:23,497 - INFO -   Val:   acc1: 79.7400 | acc5: 98.5700 | loss: 0.6350
2025-08-27 21:28:23,497 - INFO -   LR: 0.100000
2025-08-27 21:28:23,660 - INFO - 
Epoch: 61, lr = 0.1
2025-08-27 21:28:23,848 - INFO - Epoch: [61][0/391] Time 0.188 (0.188) Data 0.157 (0.157) Loss 0.5292 (0.5292) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 21:28:25,783 - INFO - Epoch: [61][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.5065 (0.4063) Acc@1 85.156 (85.914) Acc@5 100.000 (99.466)
2025-08-27 21:28:26,665 - INFO - Pruning info: sparsity=0.497
2025-08-27 21:28:26,665 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:28:27,668 - INFO - Epoch: [61][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4047 (0.4248) Acc@1 84.375 (85.331) Acc@5 99.219 (99.378)
2025-08-27 21:28:29,558 - INFO - Epoch: [61][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4637 (0.4311) Acc@1 82.031 (85.094) Acc@5 100.000 (99.380)
2025-08-27 21:28:29,733 - INFO - Pruning info: sparsity=0.497
2025-08-27 21:28:29,734 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:28:31,477 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5671 (0.5671) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 21:28:32,330 - INFO - Epoch 61:
2025-08-27 21:28:32,330 - INFO -   Train: acc1: 84.8740 | acc5: 99.3360 | loss: 0.4390 | sparsity: 0.4967 | reactivation_rate: 0.0009
2025-08-27 21:28:32,330 - INFO -   Val:   acc1: 78.8100 | acc5: 98.5200 | loss: 0.6601
2025-08-27 21:28:32,330 - INFO -   LR: 0.100000
2025-08-27 21:28:32,664 - INFO - 
Epoch: 62, lr = 0.1
2025-08-27 21:28:32,837 - INFO - Epoch: [62][0/391] Time 0.172 (0.172) Data 0.151 (0.151) Loss 0.3968 (0.3968) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:28:34,212 - INFO - Pruning info: sparsity=0.497
2025-08-27 21:28:34,212 - INFO -   Reactivation rate: 0.0010
2025-08-27 21:28:34,686 - INFO - Epoch: [62][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.4151 (0.4097) Acc@1 85.938 (85.783) Acc@5 100.000 (99.466)
2025-08-27 21:28:36,582 - INFO - Epoch: [62][200/391] Time 0.021 (0.019) Data 0.006 (0.002) Loss 0.3880 (0.4138) Acc@1 85.938 (85.607) Acc@5 99.219 (99.471)
2025-08-27 21:28:37,305 - INFO - Pruning info: sparsity=0.497
2025-08-27 21:28:37,305 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:28:38,465 - INFO - Epoch: [62][300/391] Time 0.024 (0.019) Data 0.007 (0.002) Loss 0.4205 (0.4222) Acc@1 85.938 (85.434) Acc@5 99.219 (99.403)
2025-08-27 21:28:40,261 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6029 (0.6029) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 21:28:41,162 - INFO - Epoch 62:
2025-08-27 21:28:41,162 - INFO -   Train: acc1: 85.2360 | acc5: 99.3800 | loss: 0.4308 | sparsity: 0.4974 | reactivation_rate: 0.0009
2025-08-27 21:28:41,162 - INFO -   Val:   acc1: 80.6600 | acc5: 99.1600 | loss: 0.5710
2025-08-27 21:28:41,162 - INFO -   LR: 0.100000
2025-08-27 21:28:41,175 - INFO - 
Epoch: 63, lr = 0.1
2025-08-27 21:28:41,359 - INFO - Epoch: [63][0/391] Time 0.183 (0.183) Data 0.160 (0.160) Loss 0.3775 (0.3775) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:28:41,497 - INFO - Pruning info: sparsity=0.498
2025-08-27 21:28:41,497 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:28:43,331 - INFO - Epoch: [63][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4305 (0.3982) Acc@1 85.156 (86.386) Acc@5 99.219 (99.459)
2025-08-27 21:28:44,677 - INFO - Pruning info: sparsity=0.498
2025-08-27 21:28:44,678 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:28:45,347 - INFO - Epoch: [63][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.4708 (0.4124) Acc@1 84.375 (85.829) Acc@5 100.000 (99.491)
2025-08-27 21:28:47,268 - INFO - Epoch: [63][300/391] Time 0.022 (0.020) Data 0.000 (0.001) Loss 0.3879 (0.4182) Acc@1 84.375 (85.709) Acc@5 99.219 (99.458)
2025-08-27 21:28:47,791 - INFO - Pruning info: sparsity=0.498
2025-08-27 21:28:47,791 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:28:49,214 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.5683 (0.5683) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:28:50,101 - INFO - Epoch 63:
2025-08-27 21:28:50,101 - INFO -   Train: acc1: 85.5520 | acc5: 99.4480 | loss: 0.4253 | sparsity: 0.4980 | reactivation_rate: 0.0008
2025-08-27 21:28:50,101 - INFO -   Val:   acc1: 79.8100 | acc5: 98.6400 | loss: 0.6144
2025-08-27 21:28:50,101 - INFO -   LR: 0.100000
2025-08-27 21:28:50,115 - INFO - 
Epoch: 64, lr = 0.1
2025-08-27 21:28:50,297 - INFO - Epoch: [64][0/391] Time 0.181 (0.181) Data 0.153 (0.153) Loss 0.3416 (0.3416) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 21:28:52,073 - INFO - Pruning info: sparsity=0.498
2025-08-27 21:28:52,073 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:28:52,157 - INFO - Epoch: [64][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.4565 (0.4175) Acc@1 85.156 (85.442) Acc@5 99.219 (99.373)
2025-08-27 21:28:54,080 - INFO - Epoch: [64][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4018 (0.4255) Acc@1 83.594 (85.176) Acc@5 100.000 (99.347)
2025-08-27 21:28:55,159 - INFO - Pruning info: sparsity=0.498
2025-08-27 21:28:55,160 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:28:56,013 - INFO - Epoch: [64][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4952 (0.4277) Acc@1 81.250 (85.198) Acc@5 99.219 (99.359)
2025-08-27 21:28:57,863 - INFO - Test: [0/79] Time 0.111 (0.111) Loss 0.5058 (0.5058) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:28:58,716 - INFO - Epoch 64:
2025-08-27 21:28:58,717 - INFO -   Train: acc1: 85.1520 | acc5: 99.3540 | loss: 0.4292 | sparsity: 0.4984 | reactivation_rate: 0.0007
2025-08-27 21:28:58,717 - INFO -   Val:   acc1: 79.8400 | acc5: 98.5600 | loss: 0.6394
2025-08-27 21:28:58,717 - INFO -   LR: 0.100000
2025-08-27 21:28:58,728 - INFO - 
Epoch: 65, lr = 0.1
2025-08-27 21:28:58,879 - INFO - Epoch: [65][0/391] Time 0.149 (0.149) Data 0.122 (0.122) Loss 0.3586 (0.3586) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:28:59,367 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:28:59,367 - INFO -   Reactivation rate: 0.0008
2025-08-27 21:29:00,823 - INFO - Epoch: [65][100/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.5912 (0.4344) Acc@1 77.344 (85.133) Acc@5 97.656 (99.350)
2025-08-27 21:29:02,430 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:02,430 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:29:02,738 - INFO - Epoch: [65][200/391] Time 0.028 (0.020) Data 0.013 (0.002) Loss 0.5131 (0.4285) Acc@1 83.594 (85.339) Acc@5 100.000 (99.394)
2025-08-27 21:29:04,689 - INFO - Epoch: [65][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4415 (0.4298) Acc@1 83.594 (85.237) Acc@5 98.438 (99.390)
2025-08-27 21:29:05,518 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:05,518 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:29:06,515 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6071 (0.6071) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-27 21:29:07,345 - INFO - Epoch 65:
2025-08-27 21:29:07,345 - INFO -   Train: acc1: 85.1780 | acc5: 99.3840 | loss: 0.4328 | sparsity: 0.4988 | reactivation_rate: 0.0007
2025-08-27 21:29:07,345 - INFO -   Val:   acc1: 78.5000 | acc5: 98.6300 | loss: 0.6468
2025-08-27 21:29:07,345 - INFO -   LR: 0.100000
2025-08-27 21:29:07,358 - INFO - 
Epoch: 66, lr = 0.1
2025-08-27 21:29:07,551 - INFO - Epoch: [66][0/391] Time 0.192 (0.192) Data 0.170 (0.170) Loss 0.4188 (0.4188) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:29:09,412 - INFO - Epoch: [66][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.3298 (0.4138) Acc@1 90.625 (85.589) Acc@5 100.000 (99.443)
2025-08-27 21:29:09,657 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:09,657 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:29:11,264 - INFO - Epoch: [66][200/391] Time 0.026 (0.019) Data 0.000 (0.002) Loss 0.4297 (0.4231) Acc@1 84.375 (85.370) Acc@5 99.219 (99.421)
2025-08-27 21:29:12,593 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:12,593 - INFO -   Reactivation rate: 0.0006
2025-08-27 21:29:13,069 - INFO - Epoch: [66][300/391] Time 0.021 (0.019) Data 0.010 (0.002) Loss 0.5199 (0.4312) Acc@1 84.375 (85.123) Acc@5 99.219 (99.421)
2025-08-27 21:29:14,910 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5499 (0.5499) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:29:15,805 - INFO - Epoch 66:
2025-08-27 21:29:15,805 - INFO -   Train: acc1: 85.0620 | acc5: 99.4260 | loss: 0.4328 | sparsity: 0.4991 | reactivation_rate: 0.0006
2025-08-27 21:29:15,805 - INFO -   Val:   acc1: 82.3300 | acc5: 99.2200 | loss: 0.5288
2025-08-27 21:29:15,805 - INFO -   LR: 0.100000
2025-08-27 21:29:15,851 - INFO - Checkpoint saved: epoch=66, metric=82.3300
2025-08-27 21:29:15,884 - INFO - 
Epoch: 67, lr = 0.1
2025-08-27 21:29:16,062 - INFO - Epoch: [67][0/391] Time 0.177 (0.177) Data 0.148 (0.148) Loss 0.3181 (0.3181) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:29:16,878 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:16,878 - INFO -   Reactivation rate: 0.0007
2025-08-27 21:29:17,992 - INFO - Epoch: [67][100/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.4294 (0.4069) Acc@1 85.156 (85.930) Acc@5 99.219 (99.451)
2025-08-27 21:29:19,847 - INFO - Epoch: [67][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3973 (0.4250) Acc@1 85.938 (85.421) Acc@5 100.000 (99.421)
2025-08-27 21:29:19,896 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:19,896 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:29:21,838 - INFO - Epoch: [67][300/391] Time 0.018 (0.020) Data 0.002 (0.002) Loss 0.3352 (0.4235) Acc@1 87.500 (85.444) Acc@5 100.000 (99.439)
2025-08-27 21:29:22,968 - INFO - Pruning info: sparsity=0.499
2025-08-27 21:29:22,968 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:29:23,631 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5416 (0.5416) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:29:24,442 - INFO - Epoch 67:
2025-08-27 21:29:24,442 - INFO -   Train: acc1: 85.2480 | acc5: 99.4060 | loss: 0.4297 | sparsity: 0.4994 | reactivation_rate: 0.0005
2025-08-27 21:29:24,442 - INFO -   Val:   acc1: 79.5400 | acc5: 98.6900 | loss: 0.6237
2025-08-27 21:29:24,442 - INFO -   LR: 0.100000
2025-08-27 21:29:24,456 - INFO - 
Epoch: 68, lr = 0.1
2025-08-27 21:29:24,647 - INFO - Epoch: [68][0/391] Time 0.189 (0.189) Data 0.158 (0.158) Loss 0.4048 (0.4048) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 21:29:26,593 - INFO - Epoch: [68][100/391] Time 0.028 (0.021) Data 0.000 (0.003) Loss 0.5098 (0.4235) Acc@1 82.812 (85.651) Acc@5 98.438 (99.420)
2025-08-27 21:29:27,203 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:27,203 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:29:28,660 - INFO - Epoch: [68][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.4314 (0.4301) Acc@1 89.062 (85.257) Acc@5 100.000 (99.417)
2025-08-27 21:29:30,414 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:30,415 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:29:30,583 - INFO - Epoch: [68][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4786 (0.4315) Acc@1 83.594 (85.242) Acc@5 99.219 (99.416)
2025-08-27 21:29:32,417 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.7039 (0.7039) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 21:29:33,310 - INFO - Epoch 68:
2025-08-27 21:29:33,310 - INFO -   Train: acc1: 85.2280 | acc5: 99.4060 | loss: 0.4309 | sparsity: 0.4996 | reactivation_rate: 0.0005
2025-08-27 21:29:33,310 - INFO -   Val:   acc1: 76.5600 | acc5: 98.2000 | loss: 0.7637
2025-08-27 21:29:33,310 - INFO -   LR: 0.100000
2025-08-27 21:29:33,323 - INFO - 
Epoch: 69, lr = 0.1
2025-08-27 21:29:33,494 - INFO - Epoch: [69][0/391] Time 0.169 (0.169) Data 0.128 (0.128) Loss 0.5886 (0.5886) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 21:29:34,616 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:34,616 - INFO -   Reactivation rate: 0.0005
2025-08-27 21:29:35,380 - INFO - Epoch: [69][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.3857 (0.4244) Acc@1 89.062 (85.303) Acc@5 99.219 (99.381)
2025-08-27 21:29:37,218 - INFO - Epoch: [69][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4311 (0.4203) Acc@1 87.500 (85.397) Acc@5 99.219 (99.390)
2025-08-27 21:29:37,584 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:37,584 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:29:39,041 - INFO - Epoch: [69][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.5295 (0.4268) Acc@1 85.156 (85.234) Acc@5 100.000 (99.395)
2025-08-27 21:29:40,531 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:40,531 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:29:40,825 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7423 (0.7423) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 21:29:41,678 - INFO - Epoch 69:
2025-08-27 21:29:41,678 - INFO -   Train: acc1: 85.1380 | acc5: 99.4020 | loss: 0.4292 | sparsity: 0.4997 | reactivation_rate: 0.0004
2025-08-27 21:29:41,678 - INFO -   Val:   acc1: 77.9700 | acc5: 98.7100 | loss: 0.7490
2025-08-27 21:29:41,678 - INFO -   LR: 0.100000
2025-08-27 21:29:41,691 - INFO - 
Epoch: 70, lr = 0.1
2025-08-27 21:29:41,863 - INFO - Epoch: [70][0/391] Time 0.172 (0.172) Data 0.151 (0.151) Loss 0.5060 (0.5060) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 21:29:43,714 - INFO - Epoch: [70][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3705 (0.4249) Acc@1 86.719 (85.497) Acc@5 100.000 (99.412)
2025-08-27 21:29:44,610 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:44,610 - INFO -   Reactivation rate: 0.0004
2025-08-27 21:29:45,498 - INFO - Epoch: [70][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4350 (0.4282) Acc@1 85.156 (85.491) Acc@5 99.219 (99.331)
2025-08-27 21:29:47,370 - INFO - Epoch: [70][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.3012 (0.4277) Acc@1 90.625 (85.356) Acc@5 100.000 (99.377)
2025-08-27 21:29:47,569 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:47,569 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:29:49,146 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.7004 (0.7004) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 21:29:49,982 - INFO - Epoch 70:
2025-08-27 21:29:49,982 - INFO -   Train: acc1: 85.3820 | acc5: 99.3860 | loss: 0.4279 | sparsity: 0.4999 | reactivation_rate: 0.0004
2025-08-27 21:29:49,982 - INFO -   Val:   acc1: 76.0600 | acc5: 98.6000 | loss: 0.7455
2025-08-27 21:29:49,982 - INFO -   LR: 0.100000
2025-08-27 21:29:50,029 - INFO - 
Epoch: 71, lr = 0.1
2025-08-27 21:29:50,205 - INFO - Epoch: [71][0/391] Time 0.175 (0.175) Data 0.144 (0.144) Loss 0.3043 (0.3043) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:29:51,645 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:51,645 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:29:52,055 - INFO - Epoch: [71][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.4417 (0.4151) Acc@1 84.375 (85.961) Acc@5 100.000 (99.397)
2025-08-27 21:29:53,973 - INFO - Epoch: [71][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3575 (0.4164) Acc@1 87.500 (85.735) Acc@5 99.219 (99.386)
2025-08-27 21:29:54,665 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:54,665 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:29:55,757 - INFO - Epoch: [71][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.3718 (0.4234) Acc@1 87.500 (85.522) Acc@5 99.219 (99.338)
2025-08-27 21:29:57,551 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.6909 (0.6909) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-27 21:29:58,403 - INFO - Epoch 71:
2025-08-27 21:29:58,403 - INFO -   Train: acc1: 85.3660 | acc5: 99.3240 | loss: 0.4272 | sparsity: 0.4999 | reactivation_rate: 0.0003
2025-08-27 21:29:58,403 - INFO -   Val:   acc1: 77.6400 | acc5: 98.2000 | loss: 0.6873
2025-08-27 21:29:58,403 - INFO -   LR: 0.100000
2025-08-27 21:29:58,416 - INFO - 
Epoch: 72, lr = 0.1
2025-08-27 21:29:58,582 - INFO - Epoch: [72][0/391] Time 0.165 (0.165) Data 0.146 (0.146) Loss 0.4491 (0.4491) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:29:58,687 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:29:58,688 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:30:00,366 - INFO - Epoch: [72][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2435 (0.4105) Acc@1 92.188 (86.185) Acc@5 100.000 (99.443)
2025-08-27 21:30:01,648 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:01,649 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:30:02,194 - INFO - Epoch: [72][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.5440 (0.4317) Acc@1 80.469 (85.226) Acc@5 100.000 (99.370)
2025-08-27 21:30:04,186 - INFO - Epoch: [72][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5202 (0.4348) Acc@1 83.594 (85.156) Acc@5 98.438 (99.338)
2025-08-27 21:30:04,750 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:04,750 - INFO -   Reactivation rate: 0.0003
2025-08-27 21:30:06,079 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.6821 (0.6821) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 21:30:06,914 - INFO - Epoch 72:
2025-08-27 21:30:06,914 - INFO -   Train: acc1: 85.0560 | acc5: 99.3540 | loss: 0.4357 | sparsity: 0.5000 | reactivation_rate: 0.0003
2025-08-27 21:30:06,914 - INFO -   Val:   acc1: 76.6400 | acc5: 98.7700 | loss: 0.7420
2025-08-27 21:30:06,914 - INFO -   LR: 0.100000
2025-08-27 21:30:06,926 - INFO - 
Epoch: 73, lr = 0.1
2025-08-27 21:30:07,065 - INFO - Epoch: [73][0/391] Time 0.138 (0.138) Data 0.118 (0.118) Loss 0.3496 (0.3496) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 21:30:08,914 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:08,914 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:08,966 - INFO - Epoch: [73][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2950 (0.4012) Acc@1 89.062 (85.914) Acc@5 100.000 (99.582)
2025-08-27 21:30:10,996 - INFO - Epoch: [73][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3750 (0.4220) Acc@1 86.719 (85.389) Acc@5 100.000 (99.491)
2025-08-27 21:30:12,094 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:12,095 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:12,956 - INFO - Epoch: [73][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3404 (0.4225) Acc@1 85.938 (85.377) Acc@5 100.000 (99.478)
2025-08-27 21:30:14,838 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5539 (0.5539) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 21:30:15,669 - INFO - Epoch 73:
2025-08-27 21:30:15,669 - INFO -   Train: acc1: 85.2720 | acc5: 99.4240 | loss: 0.4260 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-27 21:30:15,669 - INFO -   Val:   acc1: 79.4700 | acc5: 98.9400 | loss: 0.6122
2025-08-27 21:30:15,669 - INFO -   LR: 0.100000
2025-08-27 21:30:15,684 - INFO - 
Epoch: 74, lr = 0.1
2025-08-27 21:30:15,863 - INFO - Epoch: [74][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.5122 (0.5122) Acc@1 83.594 (83.594) Acc@5 96.875 (96.875)
2025-08-27 21:30:16,338 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:16,338 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:17,761 - INFO - Epoch: [74][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.3690 (0.4260) Acc@1 83.594 (85.396) Acc@5 100.000 (99.366)
2025-08-27 21:30:19,476 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:19,476 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:19,756 - INFO - Epoch: [74][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4427 (0.4266) Acc@1 85.156 (85.471) Acc@5 100.000 (99.405)
2025-08-27 21:30:21,771 - INFO - Epoch: [74][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3724 (0.4258) Acc@1 87.500 (85.522) Acc@5 97.656 (99.429)
2025-08-27 21:30:22,662 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:22,662 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:23,660 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4649 (0.4649) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 21:30:24,491 - INFO - Epoch 74:
2025-08-27 21:30:24,491 - INFO -   Train: acc1: 85.3600 | acc5: 99.4080 | loss: 0.4303 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-27 21:30:24,491 - INFO -   Val:   acc1: 81.8600 | acc5: 99.2500 | loss: 0.5358
2025-08-27 21:30:24,491 - INFO -   LR: 0.100000
2025-08-27 21:30:24,505 - INFO - 
Epoch: 75, lr = 0.1
2025-08-27 21:30:24,702 - INFO - Epoch: [75][0/391] Time 0.196 (0.196) Data 0.150 (0.150) Loss 0.3142 (0.3142) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 21:30:26,622 - INFO - Epoch: [75][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4649 (0.4128) Acc@1 86.719 (85.713) Acc@5 99.219 (99.559)
2025-08-27 21:30:26,877 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:26,877 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:28,621 - INFO - Epoch: [75][200/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.2895 (0.4187) Acc@1 90.625 (85.537) Acc@5 99.219 (99.483)
2025-08-27 21:30:30,046 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:30,046 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:30,560 - INFO - Epoch: [75][300/391] Time 0.015 (0.020) Data 0.003 (0.002) Loss 0.5390 (0.4197) Acc@1 82.812 (85.538) Acc@5 99.219 (99.468)
2025-08-27 21:30:32,421 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.5519 (0.5519) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 21:30:33,279 - INFO - Epoch 75:
2025-08-27 21:30:33,279 - INFO -   Train: acc1: 85.6540 | acc5: 99.4500 | loss: 0.4179 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-27 21:30:33,279 - INFO -   Val:   acc1: 78.3700 | acc5: 98.6700 | loss: 0.6731
2025-08-27 21:30:33,279 - INFO -   LR: 0.100000
2025-08-27 21:30:33,294 - INFO - 
Epoch: 76, lr = 0.1
2025-08-27 21:30:33,474 - INFO - Epoch: [76][0/391] Time 0.179 (0.179) Data 0.149 (0.149) Loss 0.4658 (0.4658) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 21:30:34,400 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:34,400 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:35,561 - INFO - Epoch: [76][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.4583 (0.4246) Acc@1 83.594 (85.512) Acc@5 100.000 (99.373)
2025-08-27 21:30:37,458 - INFO - Epoch: [76][200/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.3735 (0.4338) Acc@1 89.844 (85.343) Acc@5 98.438 (99.339)
2025-08-27 21:30:37,523 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:37,523 - INFO -   Reactivation rate: 0.0002
2025-08-27 21:30:39,493 - INFO - Epoch: [76][300/391] Time 0.027 (0.021) Data 0.000 (0.002) Loss 0.4482 (0.4351) Acc@1 83.594 (85.161) Acc@5 99.219 (99.362)
2025-08-27 21:30:40,748 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:40,749 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:30:41,352 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6242 (0.6242) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 21:30:42,184 - INFO - Epoch 76:
2025-08-27 21:30:42,184 - INFO -   Train: acc1: 85.2560 | acc5: 99.3780 | loss: 0.4331 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-27 21:30:42,184 - INFO -   Val:   acc1: 79.6200 | acc5: 98.7100 | loss: 0.6480
2025-08-27 21:30:42,184 - INFO -   LR: 0.100000
2025-08-27 21:30:42,198 - INFO - 
Epoch: 77, lr = 0.1
2025-08-27 21:30:42,385 - INFO - Epoch: [77][0/391] Time 0.187 (0.187) Data 0.168 (0.168) Loss 0.3067 (0.3067) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 21:30:44,323 - INFO - Epoch: [77][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.4597 (0.4157) Acc@1 85.938 (85.752) Acc@5 98.438 (99.505)
2025-08-27 21:30:44,945 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:44,945 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:30:46,245 - INFO - Epoch: [77][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4642 (0.4284) Acc@1 83.594 (85.265) Acc@5 98.438 (99.440)
2025-08-27 21:30:48,021 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:48,021 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:30:48,156 - INFO - Epoch: [77][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4088 (0.4225) Acc@1 88.281 (85.507) Acc@5 100.000 (99.408)
2025-08-27 21:30:50,012 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5504 (0.5504) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:30:50,871 - INFO - Epoch 77:
2025-08-27 21:30:50,871 - INFO -   Train: acc1: 85.3060 | acc5: 99.3500 | loss: 0.4285 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:30:50,872 - INFO -   Val:   acc1: 79.8900 | acc5: 98.9000 | loss: 0.6095
2025-08-27 21:30:50,872 - INFO -   LR: 0.100000
2025-08-27 21:30:50,887 - INFO - 
Epoch: 78, lr = 0.1
2025-08-27 21:30:51,062 - INFO - Epoch: [78][0/391] Time 0.174 (0.174) Data 0.153 (0.153) Loss 0.4480 (0.4480) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 21:30:52,224 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:52,225 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:30:52,937 - INFO - Epoch: [78][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3734 (0.4138) Acc@1 87.500 (86.208) Acc@5 99.219 (99.459)
2025-08-27 21:30:54,798 - INFO - Epoch: [78][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4748 (0.4292) Acc@1 85.938 (85.463) Acc@5 99.219 (99.378)
2025-08-27 21:30:55,177 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:55,178 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:30:56,635 - INFO - Epoch: [78][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4546 (0.4321) Acc@1 81.250 (85.328) Acc@5 100.000 (99.372)
2025-08-27 21:30:58,158 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:30:58,158 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:30:58,413 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.6081 (0.6081) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 21:30:59,313 - INFO - Epoch 78:
2025-08-27 21:30:59,314 - INFO -   Train: acc1: 85.1920 | acc5: 99.3680 | loss: 0.4351 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:30:59,314 - INFO -   Val:   acc1: 76.6800 | acc5: 98.3800 | loss: 0.7336
2025-08-27 21:30:59,314 - INFO -   LR: 0.100000
2025-08-27 21:30:59,326 - INFO - 
Epoch: 79, lr = 0.1
2025-08-27 21:30:59,524 - INFO - Epoch: [79][0/391] Time 0.197 (0.197) Data 0.159 (0.159) Loss 0.3969 (0.3969) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 21:31:01,506 - INFO - Epoch: [79][100/391] Time 0.022 (0.022) Data 0.000 (0.003) Loss 0.5294 (0.4118) Acc@1 80.469 (85.999) Acc@5 96.875 (99.319)
2025-08-27 21:31:02,403 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:02,403 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:03,318 - INFO - Epoch: [79][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4220 (0.4218) Acc@1 84.375 (85.467) Acc@5 98.438 (99.366)
2025-08-27 21:31:05,181 - INFO - Epoch: [79][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.6131 (0.4278) Acc@1 82.812 (85.299) Acc@5 100.000 (99.395)
2025-08-27 21:31:05,365 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:05,365 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:06,975 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4517 (0.4517) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-27 21:31:07,795 - INFO - Epoch 79:
2025-08-27 21:31:07,795 - INFO -   Train: acc1: 85.1420 | acc5: 99.3760 | loss: 0.4316 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:31:07,795 - INFO -   Val:   acc1: 80.7600 | acc5: 98.6200 | loss: 0.5863
2025-08-27 21:31:07,795 - INFO -   LR: 0.100000
2025-08-27 21:31:07,809 - INFO - 
Epoch: 80, lr = 0.1
2025-08-27 21:31:07,975 - INFO - Epoch: [80][0/391] Time 0.165 (0.165) Data 0.129 (0.129) Loss 0.2940 (0.2940) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 21:31:09,489 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:09,489 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:09,901 - INFO - Epoch: [80][100/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.4738 (0.4105) Acc@1 82.812 (86.030) Acc@5 99.219 (99.428)
2025-08-27 21:31:11,899 - INFO - Epoch: [80][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.3282 (0.4238) Acc@1 90.625 (85.467) Acc@5 100.000 (99.405)
2025-08-27 21:31:12,651 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:12,652 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:13,764 - INFO - Epoch: [80][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4765 (0.4262) Acc@1 82.031 (85.366) Acc@5 98.438 (99.377)
2025-08-27 21:31:15,672 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.4729 (0.4729) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 21:31:16,494 - INFO - Epoch 80:
2025-08-27 21:31:16,494 - INFO -   Train: acc1: 85.1840 | acc5: 99.3480 | loss: 0.4315 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:31:16,494 - INFO -   Val:   acc1: 77.4600 | acc5: 98.9800 | loss: 0.6641
2025-08-27 21:31:16,494 - INFO -   LR: 0.100000
2025-08-27 21:31:16,541 - INFO - 
Epoch: 81, lr = 0.1
2025-08-27 21:31:16,689 - INFO - Epoch: [81][0/391] Time 0.147 (0.147) Data 0.126 (0.126) Loss 0.4341 (0.4341) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:31:16,881 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:16,882 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:18,613 - INFO - Epoch: [81][100/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.4118 (0.4138) Acc@1 85.938 (85.961) Acc@5 99.219 (99.373)
2025-08-27 21:31:19,866 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:19,866 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:20,461 - INFO - Epoch: [81][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4349 (0.4233) Acc@1 82.812 (85.662) Acc@5 100.000 (99.335)
2025-08-27 21:31:22,284 - INFO - Epoch: [81][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.3862 (0.4266) Acc@1 86.719 (85.517) Acc@5 99.219 (99.351)
2025-08-27 21:31:22,767 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:22,767 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:24,022 - INFO - Test: [0/79] Time 0.109 (0.109) Loss 0.6504 (0.6504) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 21:31:24,873 - INFO - Epoch 81:
2025-08-27 21:31:24,873 - INFO -   Train: acc1: 85.4600 | acc5: 99.3580 | loss: 0.4281 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:31:24,873 - INFO -   Val:   acc1: 79.0700 | acc5: 98.8200 | loss: 0.6100
2025-08-27 21:31:24,873 - INFO -   LR: 0.100000
2025-08-27 21:31:24,887 - INFO - 
Epoch: 82, lr = 0.1
2025-08-27 21:31:25,058 - INFO - Epoch: [82][0/391] Time 0.170 (0.170) Data 0.145 (0.145) Loss 0.5977 (0.5977) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 21:31:26,963 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:26,964 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:27,013 - INFO - Epoch: [82][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4371 (0.4256) Acc@1 87.500 (85.365) Acc@5 99.219 (99.397)
2025-08-27 21:31:28,840 - INFO - Epoch: [82][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4065 (0.4306) Acc@1 82.812 (85.164) Acc@5 100.000 (99.339)
2025-08-27 21:31:29,882 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:29,883 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:30,700 - INFO - Epoch: [82][300/391] Time 0.042 (0.019) Data 0.027 (0.003) Loss 0.4252 (0.4291) Acc@1 84.375 (85.273) Acc@5 100.000 (99.315)
2025-08-27 21:31:32,521 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5610 (0.5610) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:31:33,367 - INFO - Epoch 82:
2025-08-27 21:31:33,367 - INFO -   Train: acc1: 85.2580 | acc5: 99.3480 | loss: 0.4285 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:31:33,367 - INFO -   Val:   acc1: 79.6300 | acc5: 98.9500 | loss: 0.6140
2025-08-27 21:31:33,367 - INFO -   LR: 0.100000
2025-08-27 21:31:33,380 - INFO - 
Epoch: 83, lr = 0.1
2025-08-27 21:31:33,536 - INFO - Epoch: [83][0/391] Time 0.154 (0.154) Data 0.131 (0.131) Loss 0.5020 (0.5020) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:31:34,058 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:34,058 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:35,441 - INFO - Epoch: [83][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.4055 (0.4187) Acc@1 85.156 (85.729) Acc@5 100.000 (99.366)
2025-08-27 21:31:37,037 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:37,037 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:37,288 - INFO - Epoch: [83][200/391] Time 0.027 (0.019) Data 0.013 (0.002) Loss 0.3610 (0.4201) Acc@1 85.938 (85.522) Acc@5 99.219 (99.366)
2025-08-27 21:31:39,133 - INFO - Epoch: [83][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.5567 (0.4241) Acc@1 82.031 (85.424) Acc@5 96.875 (99.346)
2025-08-27 21:31:39,997 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:39,997 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:40,927 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5855 (0.5855) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:31:41,779 - INFO - Epoch 83:
2025-08-27 21:31:41,779 - INFO -   Train: acc1: 85.3820 | acc5: 99.3500 | loss: 0.4275 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:31:41,779 - INFO -   Val:   acc1: 79.7600 | acc5: 98.9400 | loss: 0.6097
2025-08-27 21:31:41,779 - INFO -   LR: 0.100000
2025-08-27 21:31:41,791 - INFO - 
Epoch: 84, lr = 0.1
2025-08-27 21:31:41,955 - INFO - Epoch: [84][0/391] Time 0.163 (0.163) Data 0.138 (0.138) Loss 0.4425 (0.4425) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 21:31:43,764 - INFO - Epoch: [84][100/391] Time 0.055 (0.020) Data 0.030 (0.003) Loss 0.4343 (0.4259) Acc@1 85.938 (85.466) Acc@5 99.219 (99.404)
2025-08-27 21:31:44,051 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:44,052 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:45,671 - INFO - Epoch: [84][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4136 (0.4231) Acc@1 87.500 (85.498) Acc@5 100.000 (99.475)
2025-08-27 21:31:47,026 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:47,026 - INFO -   Reactivation rate: 0.0001
2025-08-27 21:31:47,474 - INFO - Epoch: [84][300/391] Time 0.024 (0.019) Data 0.012 (0.002) Loss 0.4555 (0.4212) Acc@1 84.375 (85.590) Acc@5 99.219 (99.463)
2025-08-27 21:31:49,371 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.8926 (0.8926) Acc@1 70.312 (70.312) Acc@5 97.656 (97.656)
2025-08-27 21:31:50,228 - INFO - Epoch 84:
2025-08-27 21:31:50,228 - INFO -   Train: acc1: 85.2140 | acc5: 99.4440 | loss: 0.4302 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-27 21:31:50,228 - INFO -   Val:   acc1: 71.8400 | acc5: 98.6100 | loss: 0.8860
2025-08-27 21:31:50,228 - INFO -   LR: 0.100000
2025-08-27 21:31:50,243 - INFO - 
Epoch: 85, lr = 0.1
2025-08-27 21:31:50,437 - INFO - Epoch: [85][0/391] Time 0.194 (0.194) Data 0.169 (0.169) Loss 0.5203 (0.5203) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 21:31:51,241 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:51,241 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:31:52,236 - INFO - Epoch: [85][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4555 (0.4127) Acc@1 82.812 (86.023) Acc@5 99.219 (99.366)
2025-08-27 21:31:54,116 - INFO - Epoch: [85][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3995 (0.4194) Acc@1 86.719 (85.712) Acc@5 100.000 (99.363)
2025-08-27 21:31:54,202 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:54,202 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:31:55,935 - INFO - Epoch: [85][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.5102 (0.4220) Acc@1 81.250 (85.595) Acc@5 98.438 (99.338)
2025-08-27 21:31:57,133 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:31:57,133 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:31:57,699 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5361 (0.5361) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:31:58,517 - INFO - Epoch 85:
2025-08-27 21:31:58,517 - INFO -   Train: acc1: 85.4980 | acc5: 99.3580 | loss: 0.4268 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:31:58,517 - INFO -   Val:   acc1: 80.3100 | acc5: 98.8400 | loss: 0.6048
2025-08-27 21:31:58,517 - INFO -   LR: 0.100000
2025-08-27 21:31:58,530 - INFO - 
Epoch: 86, lr = 0.1
2025-08-27 21:31:58,734 - INFO - Epoch: [86][0/391] Time 0.203 (0.203) Data 0.176 (0.176) Loss 0.2459 (0.2459) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:32:00,665 - INFO - Epoch: [86][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.4822 (0.4191) Acc@1 84.375 (85.729) Acc@5 98.438 (99.435)
2025-08-27 21:32:01,332 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:01,332 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:02,612 - INFO - Epoch: [86][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4175 (0.4257) Acc@1 85.938 (85.514) Acc@5 99.219 (99.421)
2025-08-27 21:32:04,365 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:04,366 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:04,492 - INFO - Epoch: [86][300/391] Time 0.022 (0.020) Data 0.001 (0.002) Loss 0.4848 (0.4274) Acc@1 85.156 (85.364) Acc@5 98.438 (99.434)
2025-08-27 21:32:06,344 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5855 (0.5855) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 21:32:07,199 - INFO - Epoch 86:
2025-08-27 21:32:07,199 - INFO -   Train: acc1: 85.3600 | acc5: 99.4320 | loss: 0.4277 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:07,199 - INFO -   Val:   acc1: 78.9300 | acc5: 99.0500 | loss: 0.6608
2025-08-27 21:32:07,199 - INFO -   LR: 0.100000
2025-08-27 21:32:07,213 - INFO - 
Epoch: 87, lr = 0.1
2025-08-27 21:32:07,373 - INFO - Epoch: [87][0/391] Time 0.160 (0.160) Data 0.133 (0.133) Loss 0.4466 (0.4466) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 21:32:08,634 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:08,634 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:09,414 - INFO - Epoch: [87][100/391] Time 0.013 (0.022) Data 0.000 (0.003) Loss 0.3431 (0.4282) Acc@1 88.281 (85.179) Acc@5 100.000 (99.420)
2025-08-27 21:32:11,467 - INFO - Epoch: [87][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.3197 (0.4312) Acc@1 88.281 (85.164) Acc@5 99.219 (99.370)
2025-08-27 21:32:11,922 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:11,923 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:13,494 - INFO - Epoch: [87][300/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.6507 (0.4265) Acc@1 78.906 (85.356) Acc@5 100.000 (99.390)
2025-08-27 21:32:15,129 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:15,129 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:15,401 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5379 (0.5379) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:32:16,238 - INFO - Epoch 87:
2025-08-27 21:32:16,238 - INFO -   Train: acc1: 85.2620 | acc5: 99.4220 | loss: 0.4270 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:16,238 - INFO -   Val:   acc1: 78.1700 | acc5: 98.9000 | loss: 0.6346
2025-08-27 21:32:16,238 - INFO -   LR: 0.100000
2025-08-27 21:32:16,251 - INFO - 
Epoch: 88, lr = 0.1
2025-08-27 21:32:16,411 - INFO - Epoch: [88][0/391] Time 0.159 (0.159) Data 0.134 (0.134) Loss 0.4206 (0.4206) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:32:18,422 - INFO - Epoch: [88][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.4326 (0.4308) Acc@1 85.156 (84.723) Acc@5 100.000 (99.373)
2025-08-27 21:32:19,448 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:19,449 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:20,386 - INFO - Epoch: [88][200/391] Time 0.029 (0.021) Data 0.000 (0.002) Loss 0.4407 (0.4216) Acc@1 82.031 (85.250) Acc@5 100.000 (99.417)
2025-08-27 21:32:22,265 - INFO - Epoch: [88][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5548 (0.4243) Acc@1 81.250 (85.294) Acc@5 100.000 (99.364)
2025-08-27 21:32:22,463 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:22,463 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:24,099 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.4586 (0.4586) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:32:24,933 - INFO - Epoch 88:
2025-08-27 21:32:24,933 - INFO -   Train: acc1: 85.2540 | acc5: 99.3540 | loss: 0.4279 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:24,933 - INFO -   Val:   acc1: 82.0400 | acc5: 98.8900 | loss: 0.5537
2025-08-27 21:32:24,933 - INFO -   LR: 0.100000
2025-08-27 21:32:24,948 - INFO - 
Epoch: 89, lr = 0.1
2025-08-27 21:32:25,129 - INFO - Epoch: [89][0/391] Time 0.181 (0.181) Data 0.149 (0.149) Loss 0.3563 (0.3563) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:32:26,721 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:26,721 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:27,099 - INFO - Epoch: [89][100/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.4284 (0.4197) Acc@1 84.375 (85.698) Acc@5 99.219 (99.381)
2025-08-27 21:32:28,975 - INFO - Epoch: [89][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4774 (0.4226) Acc@1 82.812 (85.444) Acc@5 98.438 (99.448)
2025-08-27 21:32:29,708 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:29,709 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:30,908 - INFO - Epoch: [89][300/391] Time 0.026 (0.020) Data 0.012 (0.002) Loss 0.6341 (0.4306) Acc@1 78.906 (85.229) Acc@5 98.438 (99.408)
2025-08-27 21:32:32,787 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.6525 (0.6525) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 21:32:33,676 - INFO - Epoch 89:
2025-08-27 21:32:33,676 - INFO -   Train: acc1: 85.2220 | acc5: 99.4000 | loss: 0.4320 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:33,676 - INFO -   Val:   acc1: 77.6900 | acc5: 98.3000 | loss: 0.7030
2025-08-27 21:32:33,676 - INFO -   LR: 0.100000
2025-08-27 21:32:33,689 - INFO - 
Epoch: 90, lr = 0.1
2025-08-27 21:32:33,854 - INFO - Epoch: [90][0/391] Time 0.165 (0.165) Data 0.145 (0.145) Loss 0.4448 (0.4448) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:32:33,992 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:33,992 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:35,788 - INFO - Epoch: [90][100/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.5452 (0.4133) Acc@1 79.688 (85.791) Acc@5 99.219 (99.203)
2025-08-27 21:32:37,093 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:37,093 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:37,635 - INFO - Epoch: [90][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4537 (0.4235) Acc@1 88.281 (85.553) Acc@5 98.438 (99.258)
2025-08-27 21:32:39,629 - INFO - Epoch: [90][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.5078 (0.4233) Acc@1 84.375 (85.540) Acc@5 98.438 (99.323)
2025-08-27 21:32:40,203 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:40,204 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:41,468 - INFO - Test: [0/79] Time 0.111 (0.111) Loss 0.8893 (0.8893) Acc@1 73.438 (73.438) Acc@5 96.094 (96.094)
2025-08-27 21:32:42,312 - INFO - Epoch 90:
2025-08-27 21:32:42,312 - INFO -   Train: acc1: 85.4260 | acc5: 99.3520 | loss: 0.4246 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:42,312 - INFO -   Val:   acc1: 71.8800 | acc5: 96.0900 | loss: 0.9198
2025-08-27 21:32:42,312 - INFO -   LR: 0.100000
2025-08-27 21:32:42,360 - INFO - 
Epoch: 91, lr = 0.1
2025-08-27 21:32:42,532 - INFO - Epoch: [91][0/391] Time 0.170 (0.170) Data 0.152 (0.152) Loss 0.4643 (0.4643) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:32:44,437 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:44,437 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:44,466 - INFO - Epoch: [91][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.4131 (0.4075) Acc@1 86.719 (85.868) Acc@5 100.000 (99.520)
2025-08-27 21:32:46,403 - INFO - Epoch: [91][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4785 (0.4222) Acc@1 87.500 (85.475) Acc@5 99.219 (99.370)
2025-08-27 21:32:47,559 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:47,560 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:48,364 - INFO - Epoch: [91][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3565 (0.4234) Acc@1 85.938 (85.387) Acc@5 99.219 (99.372)
2025-08-27 21:32:50,173 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5234 (0.5234) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 21:32:51,020 - INFO - Epoch 91:
2025-08-27 21:32:51,020 - INFO -   Train: acc1: 85.2620 | acc5: 99.3520 | loss: 0.4290 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:51,020 - INFO -   Val:   acc1: 78.4600 | acc5: 98.7100 | loss: 0.6605
2025-08-27 21:32:51,020 - INFO -   LR: 0.100000
2025-08-27 21:32:51,035 - INFO - 
Epoch: 92, lr = 0.1
2025-08-27 21:32:51,194 - INFO - Epoch: [92][0/391] Time 0.158 (0.158) Data 0.132 (0.132) Loss 0.4890 (0.4890) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 21:32:51,747 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:51,747 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:53,207 - INFO - Epoch: [92][100/391] Time 0.031 (0.021) Data 0.000 (0.003) Loss 0.4489 (0.4199) Acc@1 85.938 (85.442) Acc@5 100.000 (99.412)
2025-08-27 21:32:54,792 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:54,792 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:55,039 - INFO - Epoch: [92][200/391] Time 0.030 (0.020) Data 0.019 (0.002) Loss 0.3674 (0.4234) Acc@1 87.500 (85.358) Acc@5 100.000 (99.433)
2025-08-27 21:32:56,977 - INFO - Epoch: [92][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3254 (0.4252) Acc@1 89.062 (85.356) Acc@5 100.000 (99.421)
2025-08-27 21:32:57,873 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:32:57,873 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:32:58,796 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7233 (0.7233) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-27 21:32:59,610 - INFO - Epoch 92:
2025-08-27 21:32:59,611 - INFO -   Train: acc1: 85.2500 | acc5: 99.4320 | loss: 0.4281 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:32:59,611 - INFO -   Val:   acc1: 77.7900 | acc5: 98.3500 | loss: 0.6865
2025-08-27 21:32:59,611 - INFO -   LR: 0.100000
2025-08-27 21:32:59,625 - INFO - 
Epoch: 93, lr = 0.1
2025-08-27 21:32:59,799 - INFO - Epoch: [93][0/391] Time 0.173 (0.173) Data 0.154 (0.154) Loss 0.4517 (0.4517) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 21:33:01,710 - INFO - Epoch: [93][100/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.2853 (0.4266) Acc@1 90.625 (85.435) Acc@5 100.000 (99.397)
2025-08-27 21:33:02,035 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:02,035 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:03,652 - INFO - Epoch: [93][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3247 (0.4278) Acc@1 89.062 (85.296) Acc@5 100.000 (99.417)
2025-08-27 21:33:05,177 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:05,177 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:05,628 - INFO - Epoch: [93][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4064 (0.4258) Acc@1 84.375 (85.325) Acc@5 100.000 (99.445)
2025-08-27 21:33:07,428 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.7742 (0.7742) Acc@1 76.562 (76.562) Acc@5 96.875 (96.875)
2025-08-27 21:33:08,304 - INFO - Epoch 93:
2025-08-27 21:33:08,304 - INFO -   Train: acc1: 85.2760 | acc5: 99.4160 | loss: 0.4280 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:08,304 - INFO -   Val:   acc1: 75.3300 | acc5: 98.0900 | loss: 0.8262
2025-08-27 21:33:08,304 - INFO -   LR: 0.100000
2025-08-27 21:33:08,319 - INFO - 
Epoch: 94, lr = 0.1
2025-08-27 21:33:08,492 - INFO - Epoch: [94][0/391] Time 0.173 (0.173) Data 0.152 (0.152) Loss 0.4938 (0.4938) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 21:33:09,305 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:09,305 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:10,377 - INFO - Epoch: [94][100/391] Time 0.021 (0.020) Data 0.001 (0.004) Loss 0.3372 (0.4397) Acc@1 92.188 (85.063) Acc@5 100.000 (99.412)
2025-08-27 21:33:12,239 - INFO - Epoch: [94][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4072 (0.4337) Acc@1 85.156 (85.358) Acc@5 100.000 (99.401)
2025-08-27 21:33:12,341 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:12,341 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:14,110 - INFO - Epoch: [94][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4990 (0.4291) Acc@1 85.938 (85.444) Acc@5 100.000 (99.413)
2025-08-27 21:33:15,323 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:15,323 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:15,927 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4784 (0.4784) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 21:33:16,782 - INFO - Epoch 94:
2025-08-27 21:33:16,782 - INFO -   Train: acc1: 85.2700 | acc5: 99.3960 | loss: 0.4319 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:16,782 - INFO -   Val:   acc1: 81.0300 | acc5: 99.2700 | loss: 0.5508
2025-08-27 21:33:16,782 - INFO -   LR: 0.100000
2025-08-27 21:33:16,797 - INFO - 
Epoch: 95, lr = 0.1
2025-08-27 21:33:16,976 - INFO - Epoch: [95][0/391] Time 0.179 (0.179) Data 0.149 (0.149) Loss 0.4030 (0.4030) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 21:33:18,746 - INFO - Epoch: [95][100/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.4986 (0.4264) Acc@1 84.375 (85.473) Acc@5 99.219 (99.273)
2025-08-27 21:33:19,335 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:19,335 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:20,599 - INFO - Epoch: [95][200/391] Time 0.030 (0.019) Data 0.013 (0.003) Loss 0.5642 (0.4240) Acc@1 82.812 (85.424) Acc@5 98.438 (99.363)
2025-08-27 21:33:22,378 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:22,378 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:22,486 - INFO - Epoch: [95][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3389 (0.4303) Acc@1 87.500 (85.117) Acc@5 100.000 (99.338)
2025-08-27 21:33:24,231 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.5514 (0.5514) Acc@1 81.250 (81.250) Acc@5 96.875 (96.875)
2025-08-27 21:33:25,072 - INFO - Epoch 95:
2025-08-27 21:33:25,073 - INFO -   Train: acc1: 85.0660 | acc5: 99.3520 | loss: 0.4318 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:25,073 - INFO -   Val:   acc1: 76.5500 | acc5: 97.5800 | loss: 0.7130
2025-08-27 21:33:25,073 - INFO -   LR: 0.100000
2025-08-27 21:33:25,088 - INFO - 
Epoch: 96, lr = 0.1
2025-08-27 21:33:25,257 - INFO - Epoch: [96][0/391] Time 0.168 (0.168) Data 0.142 (0.142) Loss 0.5192 (0.5192) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 21:33:26,437 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:26,438 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:27,088 - INFO - Epoch: [96][100/391] Time 0.021 (0.020) Data 0.007 (0.003) Loss 0.3442 (0.4071) Acc@1 87.500 (86.077) Acc@5 99.219 (99.466)
2025-08-27 21:33:28,932 - INFO - Epoch: [96][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.5047 (0.4220) Acc@1 83.594 (85.277) Acc@5 99.219 (99.378)
2025-08-27 21:33:29,357 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:29,357 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:30,738 - INFO - Epoch: [96][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3711 (0.4283) Acc@1 85.938 (85.182) Acc@5 98.438 (99.390)
2025-08-27 21:33:32,437 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:32,437 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:32,668 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5868 (0.5868) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 21:33:33,503 - INFO - Epoch 96:
2025-08-27 21:33:33,503 - INFO -   Train: acc1: 85.1720 | acc5: 99.4120 | loss: 0.4281 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:33,503 - INFO -   Val:   acc1: 77.0700 | acc5: 98.9400 | loss: 0.7074
2025-08-27 21:33:33,503 - INFO -   LR: 0.100000
2025-08-27 21:33:33,519 - INFO - 
Epoch: 97, lr = 0.1
2025-08-27 21:33:33,692 - INFO - Epoch: [97][0/391] Time 0.171 (0.171) Data 0.144 (0.144) Loss 0.4187 (0.4187) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 21:33:35,597 - INFO - Epoch: [97][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.3596 (0.4095) Acc@1 89.062 (85.984) Acc@5 99.219 (99.459)
2025-08-27 21:33:36,584 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:36,584 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:37,475 - INFO - Epoch: [97][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4173 (0.4166) Acc@1 85.938 (85.599) Acc@5 99.219 (99.514)
2025-08-27 21:33:39,403 - INFO - Epoch: [97][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4190 (0.4213) Acc@1 84.375 (85.608) Acc@5 100.000 (99.450)
2025-08-27 21:33:39,578 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:39,578 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:41,204 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.5708 (0.5708) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 21:33:42,086 - INFO - Epoch 97:
2025-08-27 21:33:42,087 - INFO -   Train: acc1: 85.3860 | acc5: 99.4240 | loss: 0.4267 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:42,087 - INFO -   Val:   acc1: 78.1400 | acc5: 98.6300 | loss: 0.6629
2025-08-27 21:33:42,087 - INFO -   LR: 0.100000
2025-08-27 21:33:42,100 - INFO - 
Epoch: 98, lr = 0.1
2025-08-27 21:33:42,256 - INFO - Epoch: [98][0/391] Time 0.155 (0.155) Data 0.131 (0.131) Loss 0.3671 (0.3671) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:33:43,900 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:43,900 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:44,286 - INFO - Epoch: [98][100/391] Time 0.014 (0.022) Data 0.000 (0.003) Loss 0.4157 (0.4172) Acc@1 84.375 (85.752) Acc@5 99.219 (99.312)
2025-08-27 21:33:46,170 - INFO - Epoch: [98][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.5868 (0.4239) Acc@1 82.031 (85.572) Acc@5 96.875 (99.324)
2025-08-27 21:33:46,964 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:46,964 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:47,989 - INFO - Epoch: [98][300/391] Time 0.025 (0.020) Data 0.013 (0.002) Loss 0.3924 (0.4271) Acc@1 85.156 (85.260) Acc@5 100.000 (99.354)
2025-08-27 21:33:49,849 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.5662 (0.5662) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-27 21:33:50,736 - INFO - Epoch 98:
2025-08-27 21:33:50,736 - INFO -   Train: acc1: 85.2540 | acc5: 99.3540 | loss: 0.4279 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:50,736 - INFO -   Val:   acc1: 78.4400 | acc5: 98.0400 | loss: 0.6503
2025-08-27 21:33:50,736 - INFO -   LR: 0.100000
2025-08-27 21:33:50,751 - INFO - 
Epoch: 99, lr = 0.1
2025-08-27 21:33:50,906 - INFO - Epoch: [99][0/391] Time 0.155 (0.155) Data 0.130 (0.130) Loss 0.4288 (0.4288) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 21:33:51,114 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:51,114 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:52,824 - INFO - Epoch: [99][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.3558 (0.4240) Acc@1 88.281 (85.373) Acc@5 99.219 (99.404)
2025-08-27 21:33:54,207 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:54,208 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:54,753 - INFO - Epoch: [99][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.3227 (0.4363) Acc@1 89.844 (85.082) Acc@5 99.219 (99.417)
2025-08-27 21:33:56,559 - INFO - Epoch: [99][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3126 (0.4307) Acc@1 90.625 (85.208) Acc@5 97.656 (99.382)
2025-08-27 21:33:57,141 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:33:57,142 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:33:58,349 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.5792 (0.5792) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 21:33:59,216 - INFO - Epoch 99:
2025-08-27 21:33:59,216 - INFO -   Train: acc1: 85.1740 | acc5: 99.3860 | loss: 0.4310 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:33:59,216 - INFO -   Val:   acc1: 80.0900 | acc5: 98.5900 | loss: 0.6059
2025-08-27 21:33:59,216 - INFO -   LR: 0.010000
2025-08-27 21:33:59,231 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-27 21:33:59,395 - INFO - Epoch: [100][0/391] Time 0.163 (0.163) Data 0.138 (0.138) Loss 0.3792 (0.3792) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 21:34:01,302 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:01,302 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:01,314 - INFO - Epoch: [100][100/391] Time 0.024 (0.021) Data 0.000 (0.004) Loss 0.2531 (0.3292) Acc@1 89.844 (88.645) Acc@5 100.000 (99.667)
2025-08-27 21:34:03,144 - INFO - Epoch: [100][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3462 (0.3111) Acc@1 87.500 (89.529) Acc@5 100.000 (99.708)
2025-08-27 21:34:04,194 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:04,194 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:04,999 - INFO - Epoch: [100][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2377 (0.3010) Acc@1 93.750 (89.807) Acc@5 100.000 (99.717)
2025-08-27 21:34:06,730 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2254 (0.2254) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:34:07,574 - INFO - Epoch 100:
2025-08-27 21:34:07,575 - INFO -   Train: acc1: 90.1680 | acc5: 99.6840 | loss: 0.2910 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:07,575 - INFO -   Val:   acc1: 89.6600 | acc5: 99.6600 | loss: 0.3052
2025-08-27 21:34:07,575 - INFO -   LR: 0.010000
2025-08-27 21:34:07,623 - INFO - Checkpoint saved: epoch=100, metric=89.6600
2025-08-27 21:34:07,654 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-27 21:34:07,832 - INFO - Epoch: [101][0/391] Time 0.176 (0.176) Data 0.149 (0.149) Loss 0.3360 (0.3360) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 21:34:08,363 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:08,363 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:09,661 - INFO - Epoch: [101][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1736 (0.2490) Acc@1 93.750 (91.770) Acc@5 100.000 (99.714)
2025-08-27 21:34:11,361 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:11,361 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:11,603 - INFO - Epoch: [101][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1485 (0.2443) Acc@1 97.656 (91.966) Acc@5 100.000 (99.736)
2025-08-27 21:34:13,422 - INFO - Epoch: [101][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2501 (0.2442) Acc@1 90.625 (91.858) Acc@5 100.000 (99.756)
2025-08-27 21:34:14,330 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:14,330 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:15,245 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2099 (0.2099) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:34:16,074 - INFO - Epoch 101:
2025-08-27 21:34:16,074 - INFO -   Train: acc1: 91.8160 | acc5: 99.7580 | loss: 0.2454 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:16,074 - INFO -   Val:   acc1: 89.7700 | acc5: 99.7300 | loss: 0.2999
2025-08-27 21:34:16,074 - INFO -   LR: 0.010000
2025-08-27 21:34:16,122 - INFO - Checkpoint saved: epoch=101, metric=89.7700
2025-08-27 21:34:16,153 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-27 21:34:16,334 - INFO - Epoch: [102][0/391] Time 0.179 (0.179) Data 0.159 (0.159) Loss 0.1886 (0.1886) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:34:18,185 - INFO - Epoch: [102][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2425 (0.2330) Acc@1 90.625 (92.110) Acc@5 100.000 (99.729)
2025-08-27 21:34:18,510 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:18,511 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:20,125 - INFO - Epoch: [102][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.1830 (0.2309) Acc@1 93.750 (92.102) Acc@5 100.000 (99.782)
2025-08-27 21:34:21,673 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:21,673 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:22,087 - INFO - Epoch: [102][300/391] Time 0.021 (0.020) Data 0.003 (0.002) Loss 0.2568 (0.2307) Acc@1 92.188 (92.213) Acc@5 100.000 (99.787)
2025-08-27 21:34:23,982 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2226 (0.2226) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:34:24,832 - INFO - Epoch 102:
2025-08-27 21:34:24,832 - INFO -   Train: acc1: 92.2800 | acc5: 99.8000 | loss: 0.2292 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:24,832 - INFO -   Val:   acc1: 90.0600 | acc5: 99.7400 | loss: 0.2892
2025-08-27 21:34:24,832 - INFO -   LR: 0.010000
2025-08-27 21:34:24,883 - INFO - Checkpoint saved: epoch=102, metric=90.0600
2025-08-27 21:34:24,914 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-27 21:34:25,109 - INFO - Epoch: [103][0/391] Time 0.194 (0.194) Data 0.165 (0.165) Loss 0.2846 (0.2846) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:34:26,009 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:26,009 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:27,074 - INFO - Epoch: [103][100/391] Time 0.033 (0.021) Data 0.013 (0.003) Loss 0.2547 (0.2107) Acc@1 90.625 (93.054) Acc@5 100.000 (99.830)
2025-08-27 21:34:29,032 - INFO - Epoch: [103][200/391] Time 0.027 (0.020) Data 0.008 (0.002) Loss 0.2116 (0.2129) Acc@1 92.188 (92.930) Acc@5 100.000 (99.833)
2025-08-27 21:34:29,130 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:29,130 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:30,890 - INFO - Epoch: [103][300/391] Time 0.030 (0.020) Data 0.007 (0.002) Loss 0.4349 (0.2137) Acc@1 89.062 (92.881) Acc@5 98.438 (99.829)
2025-08-27 21:34:32,243 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:32,244 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:32,800 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2117 (0.2117) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:34:33,639 - INFO - Epoch 103:
2025-08-27 21:34:33,640 - INFO -   Train: acc1: 92.8160 | acc5: 99.8460 | loss: 0.2146 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:33,640 - INFO -   Val:   acc1: 90.2100 | acc5: 99.7400 | loss: 0.2887
2025-08-27 21:34:33,640 - INFO -   LR: 0.010000
2025-08-27 21:34:33,688 - INFO - Checkpoint saved: epoch=103, metric=90.2100
2025-08-27 21:34:33,720 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-27 21:34:33,902 - INFO - Epoch: [104][0/391] Time 0.181 (0.181) Data 0.159 (0.159) Loss 0.2418 (0.2418) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:34:35,876 - INFO - Epoch: [104][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.1569 (0.2049) Acc@1 96.094 (92.907) Acc@5 100.000 (99.868)
2025-08-27 21:34:36,591 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:36,596 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:37,862 - INFO - Epoch: [104][200/391] Time 0.026 (0.021) Data 0.000 (0.002) Loss 0.2239 (0.2076) Acc@1 92.969 (92.899) Acc@5 100.000 (99.852)
2025-08-27 21:34:39,628 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:39,628 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:39,726 - INFO - Epoch: [104][300/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.1379 (0.2080) Acc@1 94.531 (92.958) Acc@5 100.000 (99.847)
2025-08-27 21:34:41,523 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2111 (0.2111) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:34:42,351 - INFO - Epoch 104:
2025-08-27 21:34:42,351 - INFO -   Train: acc1: 92.7840 | acc5: 99.8460 | loss: 0.2111 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:42,351 - INFO -   Val:   acc1: 90.3800 | acc5: 99.7100 | loss: 0.2884
2025-08-27 21:34:42,351 - INFO -   LR: 0.010000
2025-08-27 21:34:42,401 - INFO - Checkpoint saved: epoch=104, metric=90.3800
2025-08-27 21:34:42,433 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-27 21:34:42,620 - INFO - Epoch: [105][0/391] Time 0.186 (0.186) Data 0.159 (0.159) Loss 0.1689 (0.1689) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:34:43,898 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:43,898 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:44,576 - INFO - Epoch: [105][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2015 (0.1912) Acc@1 94.531 (93.750) Acc@5 100.000 (99.892)
2025-08-27 21:34:46,498 - INFO - Epoch: [105][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1217 (0.1985) Acc@1 92.969 (93.350) Acc@5 100.000 (99.883)
2025-08-27 21:34:46,955 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:46,955 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:48,395 - INFO - Epoch: [105][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2364 (0.2010) Acc@1 91.406 (93.265) Acc@5 98.438 (99.886)
2025-08-27 21:34:50,045 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:50,046 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:50,305 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.1873 (0.1873) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:34:51,173 - INFO - Epoch 105:
2025-08-27 21:34:51,173 - INFO -   Train: acc1: 93.1980 | acc5: 99.8780 | loss: 0.2021 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:51,173 - INFO -   Val:   acc1: 90.1000 | acc5: 99.7500 | loss: 0.2910
2025-08-27 21:34:51,173 - INFO -   LR: 0.010000
2025-08-27 21:34:51,188 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-27 21:34:51,362 - INFO - Epoch: [106][0/391] Time 0.174 (0.174) Data 0.151 (0.151) Loss 0.1214 (0.1214) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:34:53,270 - INFO - Epoch: [106][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1752 (0.1952) Acc@1 91.406 (93.263) Acc@5 100.000 (99.822)
2025-08-27 21:34:54,304 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:54,304 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:55,237 - INFO - Epoch: [106][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2445 (0.1908) Acc@1 89.062 (93.482) Acc@5 100.000 (99.860)
2025-08-27 21:34:57,111 - INFO - Epoch: [106][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3544 (0.1946) Acc@1 88.281 (93.345) Acc@5 100.000 (99.844)
2025-08-27 21:34:57,379 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:34:57,379 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:34:58,924 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.1649 (0.1649) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:34:59,750 - INFO - Epoch 106:
2025-08-27 21:34:59,750 - INFO -   Train: acc1: 93.2460 | acc5: 99.8500 | loss: 0.1974 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:34:59,750 - INFO -   Val:   acc1: 90.2700 | acc5: 99.7700 | loss: 0.2885
2025-08-27 21:34:59,750 - INFO -   LR: 0.010000
2025-08-27 21:34:59,764 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-27 21:34:59,947 - INFO - Epoch: [107][0/391] Time 0.182 (0.182) Data 0.148 (0.148) Loss 0.1067 (0.1067) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:35:01,543 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:01,544 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:01,885 - INFO - Epoch: [107][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1385 (0.1880) Acc@1 93.750 (93.564) Acc@5 100.000 (99.830)
2025-08-27 21:35:03,746 - INFO - Epoch: [107][200/391] Time 0.032 (0.020) Data 0.002 (0.002) Loss 0.2767 (0.1924) Acc@1 89.844 (93.346) Acc@5 100.000 (99.845)
2025-08-27 21:35:04,526 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:04,526 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:05,616 - INFO - Epoch: [107][300/391] Time 0.011 (0.019) Data 0.000 (0.001) Loss 0.2679 (0.1900) Acc@1 90.625 (93.503) Acc@5 100.000 (99.868)
2025-08-27 21:35:07,412 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.1992 (0.1992) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:35:08,254 - INFO - Epoch 107:
2025-08-27 21:35:08,254 - INFO -   Train: acc1: 93.3780 | acc5: 99.8580 | loss: 0.1930 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:08,254 - INFO -   Val:   acc1: 90.3600 | acc5: 99.7300 | loss: 0.2923
2025-08-27 21:35:08,254 - INFO -   LR: 0.010000
2025-08-27 21:35:08,270 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-27 21:35:08,452 - INFO - Epoch: [108][0/391] Time 0.181 (0.181) Data 0.158 (0.158) Loss 0.0895 (0.0895) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:35:08,690 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:08,690 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:10,311 - INFO - Epoch: [108][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2122 (0.1835) Acc@1 92.969 (93.874) Acc@5 100.000 (99.915)
2025-08-27 21:35:11,648 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:11,648 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:12,219 - INFO - Epoch: [108][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1920 (0.1868) Acc@1 95.312 (93.696) Acc@5 100.000 (99.887)
2025-08-27 21:35:14,082 - INFO - Epoch: [108][300/391] Time 0.028 (0.019) Data 0.004 (0.002) Loss 0.1370 (0.1875) Acc@1 96.875 (93.610) Acc@5 100.000 (99.888)
2025-08-27 21:35:14,652 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:14,652 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:15,842 - INFO - Test: [0/79] Time 0.107 (0.107) Loss 0.1809 (0.1809) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:35:16,727 - INFO - Epoch 108:
2025-08-27 21:35:16,727 - INFO -   Train: acc1: 93.5820 | acc5: 99.8760 | loss: 0.1872 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:16,727 - INFO -   Val:   acc1: 90.1900 | acc5: 99.8000 | loss: 0.2856
2025-08-27 21:35:16,727 - INFO -   LR: 0.010000
2025-08-27 21:35:16,742 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-27 21:35:16,921 - INFO - Epoch: [109][0/391] Time 0.178 (0.178) Data 0.161 (0.161) Loss 0.1626 (0.1626) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:35:18,726 - INFO - Epoch: [109][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1935 (0.1788) Acc@1 93.750 (93.719) Acc@5 100.000 (99.838)
2025-08-27 21:35:18,731 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:18,731 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:20,614 - INFO - Epoch: [109][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1875 (0.1788) Acc@1 94.531 (93.738) Acc@5 99.219 (99.837)
2025-08-27 21:35:21,735 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:21,735 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:22,457 - INFO - Epoch: [109][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2409 (0.1802) Acc@1 92.969 (93.758) Acc@5 100.000 (99.860)
2025-08-27 21:35:24,323 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.1429 (0.1429) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:35:25,168 - INFO - Epoch 109:
2025-08-27 21:35:25,169 - INFO -   Train: acc1: 93.6600 | acc5: 99.8560 | loss: 0.1830 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:25,169 - INFO -   Val:   acc1: 90.1900 | acc5: 99.7900 | loss: 0.2961
2025-08-27 21:35:25,169 - INFO -   LR: 0.010000
2025-08-27 21:35:25,183 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-27 21:35:25,345 - INFO - Epoch: [110][0/391] Time 0.161 (0.161) Data 0.133 (0.133) Loss 0.1496 (0.1496) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:35:25,887 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:25,888 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:27,323 - INFO - Epoch: [110][100/391] Time 0.034 (0.021) Data 0.009 (0.003) Loss 0.2114 (0.1759) Acc@1 91.406 (94.168) Acc@5 100.000 (99.915)
2025-08-27 21:35:29,029 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:29,029 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:29,231 - INFO - Epoch: [110][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1564 (0.1763) Acc@1 93.750 (94.065) Acc@5 100.000 (99.922)
2025-08-27 21:35:31,034 - INFO - Epoch: [110][300/391] Time 0.018 (0.019) Data 0.005 (0.002) Loss 0.1941 (0.1784) Acc@1 92.969 (93.939) Acc@5 100.000 (99.894)
2025-08-27 21:35:32,003 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:32,003 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:32,890 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2036 (0.2036) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:35:33,722 - INFO - Epoch 110:
2025-08-27 21:35:33,722 - INFO -   Train: acc1: 93.9320 | acc5: 99.8860 | loss: 0.1791 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:33,722 - INFO -   Val:   acc1: 89.7400 | acc5: 99.7100 | loss: 0.3040
2025-08-27 21:35:33,722 - INFO -   LR: 0.010000
2025-08-27 21:35:33,773 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-27 21:35:33,958 - INFO - Epoch: [111][0/391] Time 0.185 (0.185) Data 0.155 (0.155) Loss 0.1922 (0.1922) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:35:35,936 - INFO - Epoch: [111][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1898 (0.1668) Acc@1 93.750 (94.508) Acc@5 100.000 (99.899)
2025-08-27 21:35:36,260 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:36,260 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:37,867 - INFO - Epoch: [111][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1406 (0.1735) Acc@1 93.750 (94.115) Acc@5 100.000 (99.911)
2025-08-27 21:35:39,434 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:39,434 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:39,851 - INFO - Epoch: [111][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1460 (0.1780) Acc@1 96.094 (93.906) Acc@5 100.000 (99.888)
2025-08-27 21:35:41,696 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.1618 (0.1618) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:35:42,514 - INFO - Epoch 111:
2025-08-27 21:35:42,514 - INFO -   Train: acc1: 93.9400 | acc5: 99.8860 | loss: 0.1774 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:42,514 - INFO -   Val:   acc1: 89.8800 | acc5: 99.8100 | loss: 0.3019
2025-08-27 21:35:42,514 - INFO -   LR: 0.010000
2025-08-27 21:35:42,528 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-27 21:35:42,717 - INFO - Epoch: [112][0/391] Time 0.188 (0.188) Data 0.147 (0.147) Loss 0.1374 (0.1374) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:35:43,663 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:43,664 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:44,689 - INFO - Epoch: [112][100/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.2387 (0.1706) Acc@1 92.188 (94.253) Acc@5 100.000 (99.930)
2025-08-27 21:35:46,541 - INFO - Epoch: [112][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1395 (0.1687) Acc@1 94.531 (94.232) Acc@5 100.000 (99.918)
2025-08-27 21:35:46,683 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:46,683 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:48,449 - INFO - Epoch: [112][300/391] Time 0.019 (0.020) Data 0.000 (0.001) Loss 0.1337 (0.1710) Acc@1 94.531 (94.087) Acc@5 100.000 (99.920)
2025-08-27 21:35:49,724 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:49,724 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:50,314 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.1977 (0.1977) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:35:51,119 - INFO - Epoch 112:
2025-08-27 21:35:51,119 - INFO -   Train: acc1: 93.9480 | acc5: 99.9040 | loss: 0.1752 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:51,120 - INFO -   Val:   acc1: 89.8900 | acc5: 99.7300 | loss: 0.3075
2025-08-27 21:35:51,120 - INFO -   LR: 0.010000
2025-08-27 21:35:51,134 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-27 21:35:51,304 - INFO - Epoch: [113][0/391] Time 0.169 (0.169) Data 0.150 (0.150) Loss 0.1909 (0.1909) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:35:53,226 - INFO - Epoch: [113][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.1519 (0.1671) Acc@1 96.094 (94.299) Acc@5 100.000 (99.868)
2025-08-27 21:35:53,886 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:53,886 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:55,148 - INFO - Epoch: [113][200/391] Time 0.014 (0.020) Data 0.001 (0.002) Loss 0.1334 (0.1666) Acc@1 96.094 (94.279) Acc@5 100.000 (99.876)
2025-08-27 21:35:57,061 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:35:57,062 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:35:57,133 - INFO - Epoch: [113][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1747 (0.1686) Acc@1 93.750 (94.183) Acc@5 100.000 (99.888)
2025-08-27 21:35:58,991 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.1967 (0.1967) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:35:59,879 - INFO - Epoch 113:
2025-08-27 21:35:59,879 - INFO -   Train: acc1: 94.1380 | acc5: 99.8880 | loss: 0.1712 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:35:59,879 - INFO -   Val:   acc1: 90.4400 | acc5: 99.8400 | loss: 0.2969
2025-08-27 21:35:59,879 - INFO -   LR: 0.010000
2025-08-27 21:35:59,930 - INFO - Checkpoint saved: epoch=113, metric=90.4400
2025-08-27 21:35:59,962 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-27 21:36:00,125 - INFO - Epoch: [114][0/391] Time 0.163 (0.163) Data 0.140 (0.140) Loss 0.1148 (0.1148) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:36:01,323 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:01,323 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:01,944 - INFO - Epoch: [114][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2383 (0.1657) Acc@1 94.531 (94.400) Acc@5 98.438 (99.868)
2025-08-27 21:36:03,815 - INFO - Epoch: [114][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2019 (0.1688) Acc@1 95.312 (94.321) Acc@5 100.000 (99.880)
2025-08-27 21:36:04,345 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:04,346 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:05,739 - INFO - Epoch: [114][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1024 (0.1695) Acc@1 97.656 (94.321) Acc@5 100.000 (99.888)
2025-08-27 21:36:07,283 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:07,283 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:07,496 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2030 (0.2030) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:36:08,329 - INFO - Epoch 114:
2025-08-27 21:36:08,329 - INFO -   Train: acc1: 94.1760 | acc5: 99.8960 | loss: 0.1724 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:08,329 - INFO -   Val:   acc1: 90.1400 | acc5: 99.7900 | loss: 0.3029
2025-08-27 21:36:08,329 - INFO -   LR: 0.010000
2025-08-27 21:36:08,344 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-27 21:36:08,514 - INFO - Epoch: [115][0/391] Time 0.169 (0.169) Data 0.145 (0.145) Loss 0.1837 (0.1837) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:36:10,356 - INFO - Epoch: [115][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1642 (0.1569) Acc@1 96.875 (94.748) Acc@5 100.000 (99.923)
2025-08-27 21:36:11,410 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:11,410 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:12,286 - INFO - Epoch: [115][200/391] Time 0.023 (0.020) Data 0.012 (0.002) Loss 0.2099 (0.1592) Acc@1 94.531 (94.586) Acc@5 100.000 (99.934)
2025-08-27 21:36:14,083 - INFO - Epoch: [115][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1675 (0.1645) Acc@1 94.531 (94.376) Acc@5 100.000 (99.912)
2025-08-27 21:36:14,346 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:14,346 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:15,918 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.1677 (0.1677) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:36:16,756 - INFO - Epoch 115:
2025-08-27 21:36:16,756 - INFO -   Train: acc1: 94.2620 | acc5: 99.9060 | loss: 0.1667 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:16,756 - INFO -   Val:   acc1: 90.2100 | acc5: 99.7500 | loss: 0.2962
2025-08-27 21:36:16,756 - INFO -   LR: 0.010000
2025-08-27 21:36:16,771 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-27 21:36:16,948 - INFO - Epoch: [116][0/391] Time 0.176 (0.176) Data 0.147 (0.147) Loss 0.2591 (0.2591) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:36:18,493 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:18,493 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:18,826 - INFO - Epoch: [116][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.1588 (0.1616) Acc@1 92.969 (94.384) Acc@5 100.000 (99.930)
2025-08-27 21:36:20,732 - INFO - Epoch: [116][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1600 (0.1671) Acc@1 95.312 (94.166) Acc@5 100.000 (99.918)
2025-08-27 21:36:21,527 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:21,527 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:22,596 - INFO - Epoch: [116][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1981 (0.1693) Acc@1 92.969 (94.113) Acc@5 100.000 (99.909)
2025-08-27 21:36:24,402 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2734 (0.2734) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 21:36:25,253 - INFO - Epoch 116:
2025-08-27 21:36:25,254 - INFO -   Train: acc1: 94.0580 | acc5: 99.9080 | loss: 0.1705 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:25,254 - INFO -   Val:   acc1: 90.6100 | acc5: 99.7200 | loss: 0.2978
2025-08-27 21:36:25,254 - INFO -   LR: 0.010000
2025-08-27 21:36:25,302 - INFO - Checkpoint saved: epoch=116, metric=90.6100
2025-08-27 21:36:25,332 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-27 21:36:25,505 - INFO - Epoch: [117][0/391] Time 0.171 (0.171) Data 0.146 (0.146) Loss 0.1431 (0.1431) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:36:25,693 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:25,694 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:27,390 - INFO - Epoch: [117][100/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.1669 (0.1554) Acc@1 94.531 (94.856) Acc@5 100.000 (99.899)
2025-08-27 21:36:28,709 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:28,709 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:29,252 - INFO - Epoch: [117][200/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.1807 (0.1577) Acc@1 95.312 (94.729) Acc@5 99.219 (99.883)
2025-08-27 21:36:31,059 - INFO - Epoch: [117][300/391] Time 0.016 (0.019) Data 0.006 (0.003) Loss 0.2349 (0.1614) Acc@1 92.188 (94.500) Acc@5 100.000 (99.886)
2025-08-27 21:36:31,732 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:31,732 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:32,938 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2284 (0.2284) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:36:33,820 - INFO - Epoch 117:
2025-08-27 21:36:33,821 - INFO -   Train: acc1: 94.3120 | acc5: 99.8860 | loss: 0.1650 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:33,821 - INFO -   Val:   acc1: 90.3400 | acc5: 99.7300 | loss: 0.3024
2025-08-27 21:36:33,821 - INFO -   LR: 0.010000
2025-08-27 21:36:33,834 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-27 21:36:34,018 - INFO - Epoch: [118][0/391] Time 0.183 (0.183) Data 0.152 (0.152) Loss 0.1409 (0.1409) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:36:35,847 - INFO - Epoch: [118][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1446 (0.1629) Acc@1 94.531 (94.431) Acc@5 100.000 (99.899)
2025-08-27 21:36:35,871 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:35,872 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:37,832 - INFO - Epoch: [118][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1859 (0.1653) Acc@1 92.188 (94.286) Acc@5 100.000 (99.899)
2025-08-27 21:36:39,013 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:39,014 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:39,736 - INFO - Epoch: [118][300/391] Time 0.029 (0.020) Data 0.013 (0.002) Loss 0.1592 (0.1646) Acc@1 93.750 (94.298) Acc@5 100.000 (99.896)
2025-08-27 21:36:41,599 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.1937 (0.1937) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:36:42,416 - INFO - Epoch 118:
2025-08-27 21:36:42,417 - INFO -   Train: acc1: 94.2500 | acc5: 99.8880 | loss: 0.1669 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:42,417 - INFO -   Val:   acc1: 89.8900 | acc5: 99.6600 | loss: 0.3180
2025-08-27 21:36:42,417 - INFO -   LR: 0.010000
2025-08-27 21:36:42,433 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-27 21:36:42,581 - INFO - Epoch: [119][0/391] Time 0.147 (0.147) Data 0.130 (0.130) Loss 0.1849 (0.1849) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:36:43,195 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:43,195 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:44,556 - INFO - Epoch: [119][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.0752 (0.1675) Acc@1 97.656 (94.067) Acc@5 100.000 (99.915)
2025-08-27 21:36:46,320 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:46,320 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:46,500 - INFO - Epoch: [119][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1466 (0.1670) Acc@1 93.750 (94.104) Acc@5 100.000 (99.918)
2025-08-27 21:36:48,383 - INFO - Epoch: [119][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1634 (0.1680) Acc@1 93.750 (94.150) Acc@5 100.000 (99.904)
2025-08-27 21:36:49,365 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:49,365 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:50,248 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2652 (0.2652) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 21:36:51,107 - INFO - Epoch 119:
2025-08-27 21:36:51,108 - INFO -   Train: acc1: 94.1460 | acc5: 99.8940 | loss: 0.1692 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:51,108 - INFO -   Val:   acc1: 89.2200 | acc5: 99.6400 | loss: 0.3347
2025-08-27 21:36:51,108 - INFO -   LR: 0.010000
2025-08-27 21:36:51,123 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-27 21:36:51,305 - INFO - Epoch: [120][0/391] Time 0.181 (0.181) Data 0.162 (0.162) Loss 0.1610 (0.1610) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:36:53,219 - INFO - Epoch: [120][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.1605 (0.1606) Acc@1 96.094 (94.632) Acc@5 99.219 (99.899)
2025-08-27 21:36:53,598 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:53,598 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:55,194 - INFO - Epoch: [120][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.1342 (0.1620) Acc@1 95.312 (94.384) Acc@5 100.000 (99.934)
2025-08-27 21:36:56,742 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:36:56,742 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:36:57,140 - INFO - Epoch: [120][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0924 (0.1631) Acc@1 96.875 (94.334) Acc@5 100.000 (99.935)
2025-08-27 21:36:58,974 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2190 (0.2190) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:36:59,786 - INFO - Epoch 120:
2025-08-27 21:36:59,787 - INFO -   Train: acc1: 94.3040 | acc5: 99.9280 | loss: 0.1642 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:36:59,787 - INFO -   Val:   acc1: 89.4400 | acc5: 99.7100 | loss: 0.3322
2025-08-27 21:36:59,787 - INFO -   LR: 0.010000
2025-08-27 21:36:59,836 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-27 21:37:00,000 - INFO - Epoch: [121][0/391] Time 0.164 (0.164) Data 0.137 (0.137) Loss 0.1758 (0.1758) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:37:00,976 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:00,976 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:02,003 - INFO - Epoch: [121][100/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.1748 (0.1548) Acc@1 93.750 (94.694) Acc@5 100.000 (99.892)
2025-08-27 21:37:03,841 - INFO - Epoch: [121][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1625 (0.1602) Acc@1 95.312 (94.399) Acc@5 99.219 (99.887)
2025-08-27 21:37:03,996 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:03,996 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:05,783 - INFO - Epoch: [121][300/391] Time 0.021 (0.020) Data 0.000 (0.001) Loss 0.2476 (0.1652) Acc@1 95.312 (94.215) Acc@5 100.000 (99.888)
2025-08-27 21:37:07,133 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:07,136 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:07,691 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2152 (0.2152) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:37:08,527 - INFO - Epoch 121:
2025-08-27 21:37:08,527 - INFO -   Train: acc1: 94.2080 | acc5: 99.9000 | loss: 0.1659 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:08,527 - INFO -   Val:   acc1: 90.2600 | acc5: 99.7200 | loss: 0.3032
2025-08-27 21:37:08,527 - INFO -   LR: 0.010000
2025-08-27 21:37:08,542 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-27 21:37:08,727 - INFO - Epoch: [122][0/391] Time 0.184 (0.184) Data 0.166 (0.166) Loss 0.1158 (0.1158) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:37:10,618 - INFO - Epoch: [122][100/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.1716 (0.1584) Acc@1 92.188 (94.400) Acc@5 100.000 (99.899)
2025-08-27 21:37:11,376 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:11,376 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:12,614 - INFO - Epoch: [122][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2277 (0.1630) Acc@1 92.969 (94.310) Acc@5 100.000 (99.899)
2025-08-27 21:37:14,436 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:14,437 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:14,494 - INFO - Epoch: [122][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1988 (0.1628) Acc@1 94.531 (94.430) Acc@5 100.000 (99.891)
2025-08-27 21:37:16,325 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.2582 (0.2582) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:37:17,158 - INFO - Epoch 122:
2025-08-27 21:37:17,158 - INFO -   Train: acc1: 94.2500 | acc5: 99.8900 | loss: 0.1665 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:17,158 - INFO -   Val:   acc1: 89.9300 | acc5: 99.6800 | loss: 0.3216
2025-08-27 21:37:17,158 - INFO -   LR: 0.010000
2025-08-27 21:37:17,173 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-27 21:37:17,331 - INFO - Epoch: [123][0/391] Time 0.157 (0.157) Data 0.140 (0.140) Loss 0.1361 (0.1361) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:37:18,637 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:18,637 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:19,280 - INFO - Epoch: [123][100/391] Time 0.034 (0.021) Data 0.003 (0.003) Loss 0.1296 (0.1642) Acc@1 96.094 (94.477) Acc@5 100.000 (99.946)
2025-08-27 21:37:21,170 - INFO - Epoch: [123][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1815 (0.1616) Acc@1 92.969 (94.465) Acc@5 100.000 (99.930)
2025-08-27 21:37:21,660 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:21,660 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:23,091 - INFO - Epoch: [123][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2180 (0.1613) Acc@1 90.625 (94.414) Acc@5 100.000 (99.930)
2025-08-27 21:37:24,739 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:24,740 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:24,971 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2211 (0.2211) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-27 21:37:25,804 - INFO - Epoch 123:
2025-08-27 21:37:25,804 - INFO -   Train: acc1: 94.3500 | acc5: 99.9260 | loss: 0.1634 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:25,804 - INFO -   Val:   acc1: 89.3900 | acc5: 99.6600 | loss: 0.3384
2025-08-27 21:37:25,804 - INFO -   LR: 0.010000
2025-08-27 21:37:25,820 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-27 21:37:26,010 - INFO - Epoch: [124][0/391] Time 0.189 (0.189) Data 0.158 (0.158) Loss 0.1220 (0.1220) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:37:27,986 - INFO - Epoch: [124][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.1991 (0.1517) Acc@1 92.969 (94.787) Acc@5 100.000 (99.938)
2025-08-27 21:37:29,065 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:29,065 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:29,914 - INFO - Epoch: [124][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1391 (0.1601) Acc@1 95.312 (94.508) Acc@5 100.000 (99.926)
2025-08-27 21:37:31,789 - INFO - Epoch: [124][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1899 (0.1623) Acc@1 93.750 (94.453) Acc@5 100.000 (99.904)
2025-08-27 21:37:32,069 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:32,069 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:33,617 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.1626 (0.1626) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-27 21:37:34,429 - INFO - Epoch 124:
2025-08-27 21:37:34,429 - INFO -   Train: acc1: 94.2920 | acc5: 99.9100 | loss: 0.1658 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:34,429 - INFO -   Val:   acc1: 89.6400 | acc5: 99.7100 | loss: 0.3174
2025-08-27 21:37:34,430 - INFO -   LR: 0.010000
2025-08-27 21:37:34,445 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-27 21:37:34,637 - INFO - Epoch: [125][0/391] Time 0.192 (0.192) Data 0.171 (0.171) Loss 0.1606 (0.1606) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:37:36,250 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:36,250 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:36,552 - INFO - Epoch: [125][100/391] Time 0.021 (0.021) Data 0.005 (0.003) Loss 0.1821 (0.1579) Acc@1 92.969 (94.562) Acc@5 100.000 (99.938)
2025-08-27 21:37:38,429 - INFO - Epoch: [125][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1643 (0.1598) Acc@1 93.750 (94.539) Acc@5 100.000 (99.926)
2025-08-27 21:37:39,275 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:39,276 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:40,321 - INFO - Epoch: [125][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1296 (0.1608) Acc@1 95.312 (94.510) Acc@5 100.000 (99.909)
2025-08-27 21:37:42,245 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2649 (0.2649) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 21:37:43,088 - INFO - Epoch 125:
2025-08-27 21:37:43,089 - INFO -   Train: acc1: 94.4640 | acc5: 99.9080 | loss: 0.1617 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:43,089 - INFO -   Val:   acc1: 89.9800 | acc5: 99.6900 | loss: 0.3116
2025-08-27 21:37:43,089 - INFO -   LR: 0.010000
2025-08-27 21:37:43,105 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-27 21:37:43,292 - INFO - Epoch: [126][0/391] Time 0.186 (0.186) Data 0.168 (0.168) Loss 0.1672 (0.1672) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:37:43,500 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:43,500 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:45,142 - INFO - Epoch: [126][100/391] Time 0.017 (0.020) Data 0.003 (0.004) Loss 0.1500 (0.1570) Acc@1 96.094 (94.554) Acc@5 100.000 (99.954)
2025-08-27 21:37:46,458 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:46,458 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:46,893 - INFO - Epoch: [126][200/391] Time 0.021 (0.019) Data 0.010 (0.003) Loss 0.1463 (0.1619) Acc@1 95.312 (94.430) Acc@5 100.000 (99.922)
2025-08-27 21:37:48,815 - INFO - Epoch: [126][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.1490 (0.1648) Acc@1 94.531 (94.279) Acc@5 100.000 (99.927)
2025-08-27 21:37:49,381 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:49,381 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:50,557 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.3051 (0.3051) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:37:51,419 - INFO - Epoch 126:
2025-08-27 21:37:51,420 - INFO -   Train: acc1: 94.2600 | acc5: 99.9220 | loss: 0.1650 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:51,420 - INFO -   Val:   acc1: 89.9500 | acc5: 99.8000 | loss: 0.3096
2025-08-27 21:37:51,420 - INFO -   LR: 0.010000
2025-08-27 21:37:51,436 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-27 21:37:51,614 - INFO - Epoch: [127][0/391] Time 0.177 (0.177) Data 0.149 (0.149) Loss 0.1303 (0.1303) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:37:53,523 - INFO - Epoch: [127][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.2136 (0.1590) Acc@1 93.750 (94.423) Acc@5 100.000 (99.938)
2025-08-27 21:37:53,575 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:53,575 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:55,351 - INFO - Epoch: [127][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2048 (0.1585) Acc@1 93.750 (94.492) Acc@5 99.219 (99.926)
2025-08-27 21:37:56,515 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:37:56,515 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:37:57,181 - INFO - Epoch: [127][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1937 (0.1621) Acc@1 91.406 (94.414) Acc@5 100.000 (99.920)
2025-08-27 21:37:58,995 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2621 (0.2621) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 21:37:59,916 - INFO - Epoch 127:
2025-08-27 21:37:59,916 - INFO -   Train: acc1: 94.3160 | acc5: 99.9180 | loss: 0.1645 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:37:59,916 - INFO -   Val:   acc1: 89.3200 | acc5: 99.6500 | loss: 0.3312
2025-08-27 21:37:59,916 - INFO -   LR: 0.010000
2025-08-27 21:37:59,932 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-27 21:38:00,077 - INFO - Epoch: [128][0/391] Time 0.144 (0.144) Data 0.109 (0.109) Loss 0.1723 (0.1723) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:38:00,665 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:00,665 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:01,868 - INFO - Epoch: [128][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1080 (0.1538) Acc@1 96.094 (94.802) Acc@5 100.000 (99.969)
2025-08-27 21:38:03,638 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:03,638 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:03,804 - INFO - Epoch: [128][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.1798 (0.1549) Acc@1 92.969 (94.776) Acc@5 100.000 (99.957)
2025-08-27 21:38:05,706 - INFO - Epoch: [128][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1435 (0.1615) Acc@1 93.750 (94.433) Acc@5 100.000 (99.948)
2025-08-27 21:38:06,711 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:06,712 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:07,503 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3002 (0.3002) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 21:38:08,358 - INFO - Epoch 128:
2025-08-27 21:38:08,358 - INFO -   Train: acc1: 94.3380 | acc5: 99.9380 | loss: 0.1643 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:08,358 - INFO -   Val:   acc1: 89.8600 | acc5: 99.7700 | loss: 0.3168
2025-08-27 21:38:08,358 - INFO -   LR: 0.010000
2025-08-27 21:38:08,373 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-27 21:38:08,565 - INFO - Epoch: [129][0/391] Time 0.192 (0.192) Data 0.171 (0.171) Loss 0.1152 (0.1152) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:38:10,471 - INFO - Epoch: [129][100/391] Time 0.017 (0.021) Data 0.000 (0.005) Loss 0.1549 (0.1575) Acc@1 92.969 (94.562) Acc@5 100.000 (99.938)
2025-08-27 21:38:10,823 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:10,828 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:12,341 - INFO - Epoch: [129][200/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1303 (0.1609) Acc@1 96.094 (94.411) Acc@5 100.000 (99.926)
2025-08-27 21:38:13,842 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:13,842 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:14,185 - INFO - Epoch: [129][300/391] Time 0.021 (0.019) Data 0.001 (0.003) Loss 0.1933 (0.1628) Acc@1 93.750 (94.290) Acc@5 100.000 (99.938)
2025-08-27 21:38:16,042 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2820 (0.2820) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:38:16,881 - INFO - Epoch 129:
2025-08-27 21:38:16,881 - INFO -   Train: acc1: 94.1720 | acc5: 99.9300 | loss: 0.1673 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:16,881 - INFO -   Val:   acc1: 88.7100 | acc5: 99.6700 | loss: 0.3737
2025-08-27 21:38:16,881 - INFO -   LR: 0.010000
2025-08-27 21:38:16,899 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-27 21:38:17,043 - INFO - Epoch: [130][0/391] Time 0.143 (0.143) Data 0.128 (0.128) Loss 0.1736 (0.1736) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:38:17,970 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:17,971 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:18,904 - INFO - Epoch: [130][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.1710 (0.1546) Acc@1 94.531 (94.694) Acc@5 100.000 (99.938)
2025-08-27 21:38:20,707 - INFO - Epoch: [130][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1512 (0.1577) Acc@1 94.531 (94.593) Acc@5 100.000 (99.930)
2025-08-27 21:38:20,897 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:20,897 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:22,573 - INFO - Epoch: [130][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2601 (0.1623) Acc@1 90.625 (94.433) Acc@5 100.000 (99.914)
2025-08-27 21:38:23,853 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:23,854 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:24,348 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2324 (0.2324) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:38:25,202 - INFO - Epoch 130:
2025-08-27 21:38:25,202 - INFO -   Train: acc1: 94.3860 | acc5: 99.9100 | loss: 0.1636 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:25,203 - INFO -   Val:   acc1: 89.7500 | acc5: 99.8600 | loss: 0.3202
2025-08-27 21:38:25,203 - INFO -   LR: 0.010000
2025-08-27 21:38:25,251 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-27 21:38:25,432 - INFO - Epoch: [131][0/391] Time 0.180 (0.180) Data 0.155 (0.155) Loss 0.0839 (0.0839) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:38:27,385 - INFO - Epoch: [131][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1385 (0.1592) Acc@1 95.312 (94.531) Acc@5 100.000 (99.923)
2025-08-27 21:38:28,048 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:28,048 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:29,212 - INFO - Epoch: [131][200/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.1093 (0.1608) Acc@1 97.656 (94.345) Acc@5 100.000 (99.934)
2025-08-27 21:38:30,987 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:30,987 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:31,029 - INFO - Epoch: [131][300/391] Time 0.025 (0.019) Data 0.008 (0.002) Loss 0.1551 (0.1650) Acc@1 94.531 (94.165) Acc@5 100.000 (99.917)
2025-08-27 21:38:32,823 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2705 (0.2705) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:38:33,685 - INFO - Epoch 131:
2025-08-27 21:38:33,686 - INFO -   Train: acc1: 94.1020 | acc5: 99.9120 | loss: 0.1663 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:33,686 - INFO -   Val:   acc1: 88.5900 | acc5: 99.6500 | loss: 0.3538
2025-08-27 21:38:33,686 - INFO -   LR: 0.010000
2025-08-27 21:38:33,701 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-27 21:38:33,865 - INFO - Epoch: [132][0/391] Time 0.162 (0.162) Data 0.141 (0.141) Loss 0.1863 (0.1863) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:38:35,099 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:35,100 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:35,759 - INFO - Epoch: [132][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.1184 (0.1594) Acc@1 96.094 (94.485) Acc@5 100.000 (99.961)
2025-08-27 21:38:37,640 - INFO - Epoch: [132][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.0992 (0.1605) Acc@1 96.094 (94.384) Acc@5 100.000 (99.949)
2025-08-27 21:38:38,109 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:38,110 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:39,549 - INFO - Epoch: [132][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.1437 (0.1604) Acc@1 96.094 (94.422) Acc@5 100.000 (99.943)
2025-08-27 21:38:41,162 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:41,163 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:41,357 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2163 (0.2163) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:38:42,192 - INFO - Epoch 132:
2025-08-27 21:38:42,192 - INFO -   Train: acc1: 94.2340 | acc5: 99.9260 | loss: 0.1651 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:42,192 - INFO -   Val:   acc1: 89.6500 | acc5: 99.8000 | loss: 0.3102
2025-08-27 21:38:42,193 - INFO -   LR: 0.010000
2025-08-27 21:38:42,210 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-27 21:38:42,386 - INFO - Epoch: [133][0/391] Time 0.175 (0.175) Data 0.155 (0.155) Loss 0.1301 (0.1301) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:38:44,313 - INFO - Epoch: [133][100/391] Time 0.018 (0.021) Data 0.000 (0.005) Loss 0.1930 (0.1630) Acc@1 91.406 (94.299) Acc@5 100.000 (99.915)
2025-08-27 21:38:45,346 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:45,347 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:46,152 - INFO - Epoch: [133][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1267 (0.1667) Acc@1 96.875 (94.205) Acc@5 100.000 (99.914)
2025-08-27 21:38:48,019 - INFO - Epoch: [133][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.1653 (0.1672) Acc@1 91.406 (94.134) Acc@5 100.000 (99.912)
2025-08-27 21:38:48,348 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:48,349 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:49,855 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2812 (0.2812) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:38:50,693 - INFO - Epoch 133:
2025-08-27 21:38:50,693 - INFO -   Train: acc1: 94.1180 | acc5: 99.9100 | loss: 0.1695 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:50,693 - INFO -   Val:   acc1: 89.2600 | acc5: 99.7500 | loss: 0.3253
2025-08-27 21:38:50,693 - INFO -   LR: 0.010000
2025-08-27 21:38:50,710 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-27 21:38:50,915 - INFO - Epoch: [134][0/391] Time 0.205 (0.205) Data 0.183 (0.183) Loss 0.0981 (0.0981) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:38:52,666 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:52,667 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:52,949 - INFO - Epoch: [134][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.1227 (0.1639) Acc@1 95.312 (94.222) Acc@5 100.000 (99.923)
2025-08-27 21:38:54,967 - INFO - Epoch: [134][200/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.1884 (0.1648) Acc@1 93.750 (94.115) Acc@5 100.000 (99.946)
2025-08-27 21:38:55,848 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:38:55,849 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:38:56,942 - INFO - Epoch: [134][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.2836 (0.1691) Acc@1 89.844 (94.090) Acc@5 100.000 (99.935)
2025-08-27 21:38:58,807 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2576 (0.2576) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 21:38:59,646 - INFO - Epoch 134:
2025-08-27 21:38:59,646 - INFO -   Train: acc1: 94.0300 | acc5: 99.9260 | loss: 0.1708 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:38:59,646 - INFO -   Val:   acc1: 89.2400 | acc5: 99.7600 | loss: 0.3375
2025-08-27 21:38:59,646 - INFO -   LR: 0.010000
2025-08-27 21:38:59,662 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-27 21:38:59,859 - INFO - Epoch: [135][0/391] Time 0.195 (0.195) Data 0.164 (0.164) Loss 0.1945 (0.1945) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 21:39:00,112 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:00,112 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:01,726 - INFO - Epoch: [135][100/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.1993 (0.1589) Acc@1 91.406 (94.524) Acc@5 100.000 (99.930)
2025-08-27 21:39:03,184 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:03,184 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:03,670 - INFO - Epoch: [135][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2185 (0.1614) Acc@1 92.188 (94.465) Acc@5 100.000 (99.922)
2025-08-27 21:39:05,578 - INFO - Epoch: [135][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2273 (0.1637) Acc@1 89.062 (94.308) Acc@5 100.000 (99.914)
2025-08-27 21:39:06,255 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:06,256 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:07,471 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2780 (0.2780) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 21:39:08,307 - INFO - Epoch 135:
2025-08-27 21:39:08,307 - INFO -   Train: acc1: 94.1980 | acc5: 99.9180 | loss: 0.1664 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:39:08,307 - INFO -   Val:   acc1: 88.9400 | acc5: 99.6500 | loss: 0.3485
2025-08-27 21:39:08,308 - INFO -   LR: 0.010000
2025-08-27 21:39:08,325 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-27 21:39:08,495 - INFO - Epoch: [136][0/391] Time 0.170 (0.170) Data 0.142 (0.142) Loss 0.1341 (0.1341) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:39:10,528 - INFO - Epoch: [136][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 0.1250 (0.1657) Acc@1 95.312 (94.315) Acc@5 100.000 (99.915)
2025-08-27 21:39:10,595 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:10,595 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:12,496 - INFO - Epoch: [136][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.2133 (0.1665) Acc@1 91.406 (94.325) Acc@5 100.000 (99.895)
2025-08-27 21:39:13,736 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:13,736 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:14,492 - INFO - Epoch: [136][300/391] Time 0.020 (0.020) Data 0.000 (0.001) Loss 0.2538 (0.1648) Acc@1 91.406 (94.339) Acc@5 100.000 (99.917)
2025-08-27 21:39:16,385 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2425 (0.2425) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 21:39:17,279 - INFO - Epoch 136:
2025-08-27 21:39:17,279 - INFO -   Train: acc1: 94.2940 | acc5: 99.9200 | loss: 0.1656 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:39:17,279 - INFO -   Val:   acc1: 89.1700 | acc5: 99.8000 | loss: 0.3379
2025-08-27 21:39:17,280 - INFO -   LR: 0.010000
2025-08-27 21:39:17,295 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-27 21:39:17,467 - INFO - Epoch: [137][0/391] Time 0.171 (0.171) Data 0.152 (0.152) Loss 0.1712 (0.1712) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:39:18,054 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:18,055 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:19,283 - INFO - Epoch: [137][100/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1002 (0.1598) Acc@1 96.094 (94.338) Acc@5 100.000 (99.930)
2025-08-27 21:39:21,098 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:21,098 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:21,262 - INFO - Epoch: [137][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1386 (0.1646) Acc@1 94.531 (94.146) Acc@5 100.000 (99.907)
2025-08-27 21:39:23,114 - INFO - Epoch: [137][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.2769 (0.1676) Acc@1 91.406 (94.113) Acc@5 99.219 (99.920)
2025-08-27 21:39:24,114 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:24,114 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:24,967 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2048 (0.2048) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:39:25,780 - INFO - Epoch 137:
2025-08-27 21:39:25,780 - INFO -   Train: acc1: 94.0760 | acc5: 99.9120 | loss: 0.1690 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:39:25,780 - INFO -   Val:   acc1: 89.8900 | acc5: 99.7100 | loss: 0.3167
2025-08-27 21:39:25,780 - INFO -   LR: 0.010000
2025-08-27 21:39:25,797 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-27 21:39:25,939 - INFO - Epoch: [138][0/391] Time 0.140 (0.140) Data 0.124 (0.124) Loss 0.1490 (0.1490) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:39:27,961 - INFO - Epoch: [138][100/391] Time 0.035 (0.021) Data 0.020 (0.003) Loss 0.1731 (0.1598) Acc@1 94.531 (94.230) Acc@5 99.219 (99.946)
2025-08-27 21:39:28,322 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:28,322 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:29,950 - INFO - Epoch: [138][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.1613 (0.1624) Acc@1 92.969 (94.193) Acc@5 100.000 (99.922)
2025-08-27 21:39:31,464 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:31,464 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:31,858 - INFO - Epoch: [138][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1319 (0.1681) Acc@1 95.312 (93.991) Acc@5 100.000 (99.920)
2025-08-27 21:39:33,796 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2317 (0.2317) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:39:34,657 - INFO - Epoch 138:
2025-08-27 21:39:34,657 - INFO -   Train: acc1: 94.0220 | acc5: 99.9320 | loss: 0.1683 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:39:34,657 - INFO -   Val:   acc1: 89.3400 | acc5: 99.6100 | loss: 0.3328
2025-08-27 21:39:34,657 - INFO -   LR: 0.010000
2025-08-27 21:39:34,675 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-27 21:39:34,845 - INFO - Epoch: [139][0/391] Time 0.169 (0.169) Data 0.144 (0.144) Loss 0.2628 (0.2628) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:39:35,836 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:35,836 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:36,796 - INFO - Epoch: [139][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.1704 (0.1491) Acc@1 94.531 (95.011) Acc@5 100.000 (99.954)
2025-08-27 21:39:38,670 - INFO - Epoch: [139][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1766 (0.1614) Acc@1 92.969 (94.481) Acc@5 100.000 (99.949)
2025-08-27 21:39:38,882 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:38,882 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:40,468 - INFO - Epoch: [139][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2195 (0.1647) Acc@1 93.750 (94.407) Acc@5 100.000 (99.943)
2025-08-27 21:39:41,855 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:41,855 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:42,342 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2240 (0.2240) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:39:43,184 - INFO - Epoch 139:
2025-08-27 21:39:43,184 - INFO -   Train: acc1: 94.2780 | acc5: 99.9380 | loss: 0.1670 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:39:43,184 - INFO -   Val:   acc1: 87.6800 | acc5: 99.5900 | loss: 0.3907
2025-08-27 21:39:43,184 - INFO -   LR: 0.010000
2025-08-27 21:39:43,200 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-27 21:39:43,375 - INFO - Epoch: [140][0/391] Time 0.175 (0.175) Data 0.134 (0.134) Loss 0.1283 (0.1283) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:39:45,295 - INFO - Epoch: [140][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.2007 (0.1543) Acc@1 91.406 (94.678) Acc@5 100.000 (99.923)
2025-08-27 21:39:46,081 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:46,081 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:47,273 - INFO - Epoch: [140][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1710 (0.1649) Acc@1 95.312 (94.364) Acc@5 100.000 (99.903)
2025-08-27 21:39:49,220 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:49,220 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:49,237 - INFO - Epoch: [140][300/391] Time 0.029 (0.020) Data 0.003 (0.002) Loss 0.1844 (0.1654) Acc@1 93.750 (94.326) Acc@5 100.000 (99.899)
2025-08-27 21:39:51,038 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2066 (0.2066) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:39:51,842 - INFO - Epoch 140:
2025-08-27 21:39:51,842 - INFO -   Train: acc1: 94.3200 | acc5: 99.9040 | loss: 0.1658 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:39:51,842 - INFO -   Val:   acc1: 89.1300 | acc5: 99.7500 | loss: 0.3335
2025-08-27 21:39:51,842 - INFO -   LR: 0.010000
2025-08-27 21:39:51,895 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-27 21:39:52,076 - INFO - Epoch: [141][0/391] Time 0.180 (0.180) Data 0.154 (0.154) Loss 0.1814 (0.1814) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:39:53,425 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:53,425 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:54,008 - INFO - Epoch: [141][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.1065 (0.1603) Acc@1 96.094 (94.508) Acc@5 100.000 (99.930)
2025-08-27 21:39:55,910 - INFO - Epoch: [141][200/391] Time 0.019 (0.020) Data 0.001 (0.002) Loss 0.1178 (0.1575) Acc@1 97.656 (94.601) Acc@5 100.000 (99.946)
2025-08-27 21:39:56,424 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:56,425 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:57,849 - INFO - Epoch: [141][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1201 (0.1636) Acc@1 95.312 (94.329) Acc@5 100.000 (99.940)
2025-08-27 21:39:59,534 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:39:59,534 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:39:59,727 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.3153 (0.3153) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 21:40:00,548 - INFO - Epoch 141:
2025-08-27 21:40:00,548 - INFO -   Train: acc1: 94.2020 | acc5: 99.9360 | loss: 0.1667 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:00,548 - INFO -   Val:   acc1: 87.5200 | acc5: 99.7200 | loss: 0.4178
2025-08-27 21:40:00,548 - INFO -   LR: 0.010000
2025-08-27 21:40:00,565 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-27 21:40:00,737 - INFO - Epoch: [142][0/391] Time 0.170 (0.170) Data 0.153 (0.153) Loss 0.1960 (0.1960) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:40:02,580 - INFO - Epoch: [142][100/391] Time 0.019 (0.020) Data 0.003 (0.002) Loss 0.1391 (0.1689) Acc@1 95.312 (94.121) Acc@5 100.000 (99.930)
2025-08-27 21:40:03,596 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:03,596 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:04,377 - INFO - Epoch: [142][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.1501 (0.1646) Acc@1 96.094 (94.232) Acc@5 100.000 (99.938)
2025-08-27 21:40:06,266 - INFO - Epoch: [142][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.1774 (0.1642) Acc@1 93.750 (94.277) Acc@5 100.000 (99.935)
2025-08-27 21:40:06,541 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:06,541 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:08,009 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2150 (0.2150) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:40:08,848 - INFO - Epoch 142:
2025-08-27 21:40:08,849 - INFO -   Train: acc1: 94.2000 | acc5: 99.9280 | loss: 0.1666 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:08,849 - INFO -   Val:   acc1: 89.4500 | acc5: 99.6800 | loss: 0.3264
2025-08-27 21:40:08,849 - INFO -   LR: 0.010000
2025-08-27 21:40:08,864 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-27 21:40:09,026 - INFO - Epoch: [143][0/391] Time 0.161 (0.161) Data 0.131 (0.131) Loss 0.1401 (0.1401) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:40:10,625 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:10,625 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:10,870 - INFO - Epoch: [143][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1254 (0.1578) Acc@1 96.094 (94.624) Acc@5 100.000 (99.946)
2025-08-27 21:40:12,715 - INFO - Epoch: [143][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1076 (0.1564) Acc@1 95.312 (94.527) Acc@5 100.000 (99.942)
2025-08-27 21:40:13,563 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:13,563 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:14,541 - INFO - Epoch: [143][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.1590 (0.1624) Acc@1 96.094 (94.313) Acc@5 100.000 (99.943)
2025-08-27 21:40:16,367 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.2741 (0.2741) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 21:40:17,225 - INFO - Epoch 143:
2025-08-27 21:40:17,225 - INFO -   Train: acc1: 94.2220 | acc5: 99.9400 | loss: 0.1655 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:17,225 - INFO -   Val:   acc1: 87.8700 | acc5: 99.6100 | loss: 0.3804
2025-08-27 21:40:17,226 - INFO -   LR: 0.010000
2025-08-27 21:40:17,242 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-27 21:40:17,417 - INFO - Epoch: [144][0/391] Time 0.174 (0.174) Data 0.146 (0.146) Loss 0.1843 (0.1843) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:40:17,682 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:17,682 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:19,262 - INFO - Epoch: [144][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1598 (0.1596) Acc@1 94.531 (94.624) Acc@5 100.000 (99.946)
2025-08-27 21:40:20,686 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:20,687 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:21,148 - INFO - Epoch: [144][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1995 (0.1646) Acc@1 96.094 (94.321) Acc@5 100.000 (99.946)
2025-08-27 21:40:22,982 - INFO - Epoch: [144][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1875 (0.1660) Acc@1 92.969 (94.254) Acc@5 99.219 (99.935)
2025-08-27 21:40:23,598 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:23,598 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:24,711 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.1779 (0.1779) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:40:25,573 - INFO - Epoch 144:
2025-08-27 21:40:25,573 - INFO -   Train: acc1: 94.2320 | acc5: 99.9320 | loss: 0.1666 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:25,573 - INFO -   Val:   acc1: 88.6200 | acc5: 99.7900 | loss: 0.3560
2025-08-27 21:40:25,573 - INFO -   LR: 0.010000
2025-08-27 21:40:25,592 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-27 21:40:25,741 - INFO - Epoch: [145][0/391] Time 0.148 (0.148) Data 0.120 (0.120) Loss 0.1144 (0.1144) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:40:27,577 - INFO - Epoch: [145][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1583 (0.1571) Acc@1 96.094 (94.647) Acc@5 100.000 (99.930)
2025-08-27 21:40:27,669 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:27,669 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:29,438 - INFO - Epoch: [145][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2092 (0.1609) Acc@1 91.406 (94.438) Acc@5 100.000 (99.926)
2025-08-27 21:40:30,629 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:30,629 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:31,321 - INFO - Epoch: [145][300/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.2031 (0.1668) Acc@1 92.969 (94.246) Acc@5 100.000 (99.920)
2025-08-27 21:40:33,132 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2993 (0.2993) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:40:33,970 - INFO - Epoch 145:
2025-08-27 21:40:33,970 - INFO -   Train: acc1: 94.1300 | acc5: 99.9140 | loss: 0.1687 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:33,970 - INFO -   Val:   acc1: 89.1800 | acc5: 99.5900 | loss: 0.3465
2025-08-27 21:40:33,970 - INFO -   LR: 0.010000
2025-08-27 21:40:33,987 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-27 21:40:34,167 - INFO - Epoch: [146][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.1457 (0.1457) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:40:34,755 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:34,756 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:36,013 - INFO - Epoch: [146][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1020 (0.1590) Acc@1 96.875 (94.462) Acc@5 100.000 (99.938)
2025-08-27 21:40:37,715 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:37,715 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:37,832 - INFO - Epoch: [146][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1703 (0.1606) Acc@1 92.969 (94.310) Acc@5 100.000 (99.911)
2025-08-27 21:40:39,681 - INFO - Epoch: [146][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1188 (0.1621) Acc@1 94.531 (94.246) Acc@5 100.000 (99.917)
2025-08-27 21:40:40,693 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:40,693 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:41,485 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.2811 (0.2811) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 21:40:42,352 - INFO - Epoch 146:
2025-08-27 21:40:42,352 - INFO -   Train: acc1: 94.1500 | acc5: 99.9160 | loss: 0.1645 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:42,353 - INFO -   Val:   acc1: 89.2200 | acc5: 99.6400 | loss: 0.3367
2025-08-27 21:40:42,353 - INFO -   LR: 0.010000
2025-08-27 21:40:42,369 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-27 21:40:42,542 - INFO - Epoch: [147][0/391] Time 0.171 (0.171) Data 0.152 (0.152) Loss 0.1409 (0.1409) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:40:44,519 - INFO - Epoch: [147][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1225 (0.1612) Acc@1 96.094 (94.500) Acc@5 100.000 (99.954)
2025-08-27 21:40:44,920 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:44,920 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:46,429 - INFO - Epoch: [147][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2148 (0.1675) Acc@1 92.969 (94.201) Acc@5 100.000 (99.926)
2025-08-27 21:40:47,945 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:47,946 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:48,281 - INFO - Epoch: [147][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2018 (0.1721) Acc@1 93.750 (94.069) Acc@5 100.000 (99.920)
2025-08-27 21:40:50,088 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2469 (0.2469) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 21:40:50,898 - INFO - Epoch 147:
2025-08-27 21:40:50,898 - INFO -   Train: acc1: 94.0540 | acc5: 99.9200 | loss: 0.1716 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:50,898 - INFO -   Val:   acc1: 88.2200 | acc5: 99.5100 | loss: 0.3778
2025-08-27 21:40:50,898 - INFO -   LR: 0.010000
2025-08-27 21:40:50,917 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-27 21:40:51,091 - INFO - Epoch: [148][0/391] Time 0.173 (0.173) Data 0.151 (0.151) Loss 0.1606 (0.1606) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:40:52,048 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:52,049 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:53,006 - INFO - Epoch: [148][100/391] Time 0.028 (0.021) Data 0.000 (0.003) Loss 0.1788 (0.1587) Acc@1 93.750 (94.632) Acc@5 100.000 (99.892)
2025-08-27 21:40:54,982 - INFO - Epoch: [148][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1660 (0.1581) Acc@1 93.750 (94.601) Acc@5 100.000 (99.903)
2025-08-27 21:40:55,216 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:55,216 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:56,922 - INFO - Epoch: [148][300/391] Time 0.027 (0.020) Data 0.001 (0.002) Loss 0.1376 (0.1650) Acc@1 93.750 (94.303) Acc@5 100.000 (99.909)
2025-08-27 21:40:58,297 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:40:58,297 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:40:58,758 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2802 (0.2802) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 21:40:59,595 - INFO - Epoch 148:
2025-08-27 21:40:59,595 - INFO -   Train: acc1: 94.1760 | acc5: 99.9140 | loss: 0.1685 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:40:59,595 - INFO -   Val:   acc1: 89.4600 | acc5: 99.7100 | loss: 0.3368
2025-08-27 21:40:59,595 - INFO -   LR: 0.010000
2025-08-27 21:40:59,611 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-27 21:40:59,794 - INFO - Epoch: [149][0/391] Time 0.182 (0.182) Data 0.159 (0.159) Loss 0.2065 (0.2065) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:41:01,745 - INFO - Epoch: [149][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1889 (0.1518) Acc@1 96.094 (94.787) Acc@5 99.219 (99.946)
2025-08-27 21:41:02,489 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:02,489 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:03,616 - INFO - Epoch: [149][200/391] Time 0.026 (0.020) Data 0.013 (0.002) Loss 0.1901 (0.1637) Acc@1 91.406 (94.279) Acc@5 100.000 (99.934)
2025-08-27 21:41:05,554 - INFO - Epoch: [149][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1730 (0.1653) Acc@1 93.750 (94.194) Acc@5 100.000 (99.940)
2025-08-27 21:41:05,568 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:05,568 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:07,365 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.3561 (0.3561) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 21:41:08,186 - INFO - Epoch 149:
2025-08-27 21:41:08,186 - INFO -   Train: acc1: 94.2780 | acc5: 99.9320 | loss: 0.1639 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:41:08,186 - INFO -   Val:   acc1: 88.3200 | acc5: 99.6200 | loss: 0.3629
2025-08-27 21:41:08,186 - INFO -   LR: 0.001000
2025-08-27 21:41:08,202 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-27 21:41:08,384 - INFO - Epoch: [150][0/391] Time 0.181 (0.181) Data 0.157 (0.157) Loss 0.2244 (0.2244) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:41:09,734 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:09,734 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:10,368 - INFO - Epoch: [150][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1426 (0.1340) Acc@1 95.312 (95.421) Acc@5 100.000 (99.961)
2025-08-27 21:41:12,271 - INFO - Epoch: [150][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1124 (0.1265) Acc@1 97.656 (95.833) Acc@5 100.000 (99.969)
2025-08-27 21:41:12,786 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:12,786 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:14,061 - INFO - Epoch: [150][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.1176 (0.1235) Acc@1 93.750 (95.956) Acc@5 100.000 (99.964)
2025-08-27 21:41:15,780 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:15,780 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:15,948 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.2163 (0.2163) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:41:16,834 - INFO - Epoch 150:
2025-08-27 21:41:16,834 - INFO -   Train: acc1: 96.0980 | acc5: 99.9660 | loss: 0.1203 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:41:16,834 - INFO -   Val:   acc1: 91.1800 | acc5: 99.8700 | loss: 0.2673
2025-08-27 21:41:16,834 - INFO -   LR: 0.001000
2025-08-27 21:41:16,884 - INFO - Checkpoint saved: epoch=150, metric=91.1800
2025-08-27 21:41:16,916 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-27 21:41:17,102 - INFO - Epoch: [151][0/391] Time 0.185 (0.185) Data 0.160 (0.160) Loss 0.0888 (0.0888) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:41:19,063 - INFO - Epoch: [151][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.0895 (0.0982) Acc@1 96.094 (96.751) Acc@5 100.000 (99.977)
2025-08-27 21:41:20,169 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:20,169 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:20,955 - INFO - Epoch: [151][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1091 (0.1001) Acc@1 97.656 (96.712) Acc@5 100.000 (99.969)
2025-08-27 21:41:22,948 - INFO - Epoch: [151][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.0317 (0.0999) Acc@1 100.000 (96.756) Acc@5 100.000 (99.966)
2025-08-27 21:41:23,322 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:23,323 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:24,789 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.1888 (0.1888) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 21:41:25,604 - INFO - Epoch 151:
2025-08-27 21:41:25,604 - INFO -   Train: acc1: 96.7540 | acc5: 99.9720 | loss: 0.1003 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:41:25,604 - INFO -   Val:   acc1: 91.2800 | acc5: 99.9000 | loss: 0.2647
2025-08-27 21:41:25,605 - INFO -   LR: 0.001000
2025-08-27 21:41:25,657 - INFO - Checkpoint saved: epoch=151, metric=91.2800
2025-08-27 21:41:25,689 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-27 21:41:25,874 - INFO - Epoch: [152][0/391] Time 0.184 (0.184) Data 0.157 (0.157) Loss 0.1009 (0.1009) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:41:27,505 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:27,505 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:27,754 - INFO - Epoch: [152][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1180 (0.0991) Acc@1 96.875 (96.674) Acc@5 100.000 (99.954)
2025-08-27 21:41:29,677 - INFO - Epoch: [152][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.0569 (0.0977) Acc@1 100.000 (96.836) Acc@5 100.000 (99.977)
2025-08-27 21:41:30,605 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:30,606 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:31,618 - INFO - Epoch: [152][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.0681 (0.0979) Acc@1 97.656 (96.792) Acc@5 100.000 (99.982)
2025-08-27 21:41:33,540 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.1852 (0.1852) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:41:34,417 - INFO - Epoch 152:
2025-08-27 21:41:34,417 - INFO -   Train: acc1: 96.7920 | acc5: 99.9800 | loss: 0.0979 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:41:34,417 - INFO -   Val:   acc1: 91.3600 | acc5: 99.8500 | loss: 0.2654
2025-08-27 21:41:34,417 - INFO -   LR: 0.001000
2025-08-27 21:41:34,469 - INFO - Checkpoint saved: epoch=152, metric=91.3600
2025-08-27 21:41:34,500 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-27 21:41:34,677 - INFO - Epoch: [153][0/391] Time 0.175 (0.175) Data 0.156 (0.156) Loss 0.1308 (0.1308) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 21:41:35,024 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:35,024 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:36,665 - INFO - Epoch: [153][100/391] Time 0.023 (0.021) Data 0.000 (0.004) Loss 0.0906 (0.0902) Acc@1 96.875 (97.184) Acc@5 100.000 (99.969)
2025-08-27 21:41:38,083 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:38,083 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:38,536 - INFO - Epoch: [153][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0804 (0.0900) Acc@1 99.219 (97.209) Acc@5 100.000 (99.977)
2025-08-27 21:41:40,470 - INFO - Epoch: [153][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.0295 (0.0914) Acc@1 100.000 (97.176) Acc@5 100.000 (99.966)
2025-08-27 21:41:41,149 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:41,149 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:42,282 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.1793 (0.1793) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:41:43,118 - INFO - Epoch 153:
2025-08-27 21:41:43,118 - INFO -   Train: acc1: 97.1780 | acc5: 99.9660 | loss: 0.0916 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:41:43,118 - INFO -   Val:   acc1: 91.2900 | acc5: 99.8700 | loss: 0.2634
2025-08-27 21:41:43,118 - INFO -   LR: 0.001000
2025-08-27 21:41:43,137 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-27 21:41:43,320 - INFO - Epoch: [154][0/391] Time 0.183 (0.183) Data 0.158 (0.158) Loss 0.0642 (0.0642) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:41:45,290 - INFO - Epoch: [154][100/391] Time 0.020 (0.021) Data 0.006 (0.003) Loss 0.0601 (0.0924) Acc@1 98.438 (97.045) Acc@5 100.000 (99.985)
2025-08-27 21:41:45,413 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:45,413 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:47,231 - INFO - Epoch: [154][200/391] Time 0.016 (0.020) Data 0.001 (0.002) Loss 0.1252 (0.0923) Acc@1 94.531 (97.058) Acc@5 100.000 (99.988)
2025-08-27 21:41:48,419 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:48,419 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:49,091 - INFO - Epoch: [154][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.0847 (0.0908) Acc@1 97.656 (97.111) Acc@5 100.000 (99.982)
2025-08-27 21:41:50,880 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.1783 (0.1783) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:41:51,745 - INFO - Epoch 154:
2025-08-27 21:41:51,746 - INFO -   Train: acc1: 97.1560 | acc5: 99.9800 | loss: 0.0902 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:41:51,746 - INFO -   Val:   acc1: 91.3900 | acc5: 99.8700 | loss: 0.2595
2025-08-27 21:41:51,746 - INFO -   LR: 0.001000
2025-08-27 21:41:51,945 - INFO - Checkpoint saved: epoch=154, metric=91.3900
2025-08-27 21:41:51,977 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-27 21:41:52,168 - INFO - Epoch: [155][0/391] Time 0.189 (0.189) Data 0.167 (0.167) Loss 0.0738 (0.0738) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:41:52,824 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:52,824 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:53,970 - INFO - Epoch: [155][100/391] Time 0.013 (0.020) Data 0.002 (0.003) Loss 0.0672 (0.0836) Acc@1 96.875 (97.409) Acc@5 100.000 (99.954)
2025-08-27 21:41:55,714 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:55,714 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:55,824 - INFO - Epoch: [155][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1197 (0.0857) Acc@1 96.094 (97.318) Acc@5 99.219 (99.969)
2025-08-27 21:41:57,700 - INFO - Epoch: [155][300/391] Time 0.036 (0.019) Data 0.000 (0.003) Loss 0.0941 (0.0859) Acc@1 96.875 (97.345) Acc@5 100.000 (99.971)
2025-08-27 21:41:58,717 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:41:58,718 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:41:59,468 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.1885 (0.1885) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:42:00,319 - INFO - Epoch 155:
2025-08-27 21:42:00,319 - INFO -   Train: acc1: 97.2840 | acc5: 99.9680 | loss: 0.0873 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:00,319 - INFO -   Val:   acc1: 91.4400 | acc5: 99.8600 | loss: 0.2631
2025-08-27 21:42:00,319 - INFO -   LR: 0.001000
2025-08-27 21:42:00,370 - INFO - Checkpoint saved: epoch=155, metric=91.4400
2025-08-27 21:42:00,399 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-27 21:42:00,570 - INFO - Epoch: [156][0/391] Time 0.170 (0.170) Data 0.151 (0.151) Loss 0.0629 (0.0629) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:42:02,404 - INFO - Epoch: [156][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.0958 (0.0884) Acc@1 97.656 (97.316) Acc@5 100.000 (99.985)
2025-08-27 21:42:02,848 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:02,848 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:04,255 - INFO - Epoch: [156][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.1138 (0.0849) Acc@1 94.531 (97.427) Acc@5 100.000 (99.992)
2025-08-27 21:42:05,728 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:05,729 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:06,072 - INFO - Epoch: [156][300/391] Time 0.021 (0.019) Data 0.004 (0.002) Loss 0.0584 (0.0844) Acc@1 100.000 (97.397) Acc@5 100.000 (99.992)
2025-08-27 21:42:07,866 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.1665 (0.1665) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:42:08,727 - INFO - Epoch 156:
2025-08-27 21:42:08,728 - INFO -   Train: acc1: 97.4020 | acc5: 99.9860 | loss: 0.0839 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:08,728 - INFO -   Val:   acc1: 91.4100 | acc5: 99.8800 | loss: 0.2631
2025-08-27 21:42:08,728 - INFO -   LR: 0.001000
2025-08-27 21:42:08,745 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-27 21:42:08,894 - INFO - Epoch: [157][0/391] Time 0.148 (0.148) Data 0.124 (0.124) Loss 0.1058 (0.1058) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:42:09,866 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:09,867 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:10,784 - INFO - Epoch: [157][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.0686 (0.0848) Acc@1 98.438 (97.285) Acc@5 100.000 (99.961)
2025-08-27 21:42:12,614 - INFO - Epoch: [157][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.0619 (0.0868) Acc@1 97.656 (97.244) Acc@5 100.000 (99.973)
2025-08-27 21:42:12,859 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:12,859 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:14,489 - INFO - Epoch: [157][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1181 (0.0841) Acc@1 95.312 (97.363) Acc@5 100.000 (99.982)
2025-08-27 21:42:15,825 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:15,826 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:16,265 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.1690 (0.1690) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:42:17,120 - INFO - Epoch 157:
2025-08-27 21:42:17,120 - INFO -   Train: acc1: 97.4180 | acc5: 99.9820 | loss: 0.0834 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:17,120 - INFO -   Val:   acc1: 91.3400 | acc5: 99.8600 | loss: 0.2620
2025-08-27 21:42:17,120 - INFO -   LR: 0.001000
2025-08-27 21:42:17,137 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-27 21:42:17,311 - INFO - Epoch: [158][0/391] Time 0.173 (0.173) Data 0.148 (0.148) Loss 0.0706 (0.0706) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:42:19,164 - INFO - Epoch: [158][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1007 (0.0837) Acc@1 97.656 (97.386) Acc@5 100.000 (99.992)
2025-08-27 21:42:19,994 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:19,994 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:20,994 - INFO - Epoch: [158][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.0544 (0.0820) Acc@1 98.438 (97.446) Acc@5 100.000 (99.992)
2025-08-27 21:42:22,880 - INFO - Epoch: [158][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.0807 (0.0799) Acc@1 98.438 (97.498) Acc@5 100.000 (99.979)
2025-08-27 21:42:22,936 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:22,936 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:24,686 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.1780 (0.1780) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:42:25,522 - INFO - Epoch 158:
2025-08-27 21:42:25,522 - INFO -   Train: acc1: 97.4900 | acc5: 99.9780 | loss: 0.0804 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:25,522 - INFO -   Val:   acc1: 91.4400 | acc5: 99.8600 | loss: 0.2646
2025-08-27 21:42:25,522 - INFO -   LR: 0.001000
2025-08-27 21:42:25,540 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-27 21:42:25,725 - INFO - Epoch: [159][0/391] Time 0.184 (0.184) Data 0.161 (0.161) Loss 0.1048 (0.1048) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-27 21:42:26,982 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:26,982 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:27,525 - INFO - Epoch: [159][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0778 (0.0815) Acc@1 98.438 (97.339) Acc@5 100.000 (99.985)
2025-08-27 21:42:29,453 - INFO - Epoch: [159][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.0496 (0.0805) Acc@1 98.438 (97.404) Acc@5 100.000 (99.981)
2025-08-27 21:42:30,019 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:30,020 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:31,374 - INFO - Epoch: [159][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.0995 (0.0795) Acc@1 95.312 (97.446) Acc@5 100.000 (99.984)
2025-08-27 21:42:33,252 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.1757 (0.1757) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:42:34,087 - INFO - Epoch 159:
2025-08-27 21:42:34,087 - INFO -   Train: acc1: 97.4200 | acc5: 99.9820 | loss: 0.0806 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:34,087 - INFO -   Val:   acc1: 91.3600 | acc5: 99.8400 | loss: 0.2632
2025-08-27 21:42:34,087 - INFO -   LR: 0.001000
2025-08-27 21:42:34,106 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-27 21:42:34,283 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:34,283 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:34,304 - INFO - Epoch: [160][0/391] Time 0.198 (0.198) Data 0.165 (0.165) Loss 0.0637 (0.0637) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:42:36,233 - INFO - Epoch: [160][100/391] Time 0.016 (0.021) Data 0.001 (0.003) Loss 0.0372 (0.0739) Acc@1 100.000 (97.672) Acc@5 100.000 (99.977)
2025-08-27 21:42:37,397 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:37,397 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:38,135 - INFO - Epoch: [160][200/391] Time 0.012 (0.020) Data 0.001 (0.002) Loss 0.0961 (0.0776) Acc@1 97.656 (97.590) Acc@5 100.000 (99.977)
2025-08-27 21:42:40,012 - INFO - Epoch: [160][300/391] Time 0.016 (0.020) Data 0.001 (0.002) Loss 0.0710 (0.0784) Acc@1 98.438 (97.576) Acc@5 100.000 (99.979)
2025-08-27 21:42:40,363 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:40,363 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:41,864 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.1760 (0.1760) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:42:42,698 - INFO - Epoch 160:
2025-08-27 21:42:42,698 - INFO -   Train: acc1: 97.6100 | acc5: 99.9820 | loss: 0.0785 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:42,698 - INFO -   Val:   acc1: 91.5200 | acc5: 99.8800 | loss: 0.2639
2025-08-27 21:42:42,698 - INFO -   LR: 0.001000
2025-08-27 21:42:42,752 - INFO - Checkpoint saved: epoch=160, metric=91.5200
2025-08-27 21:42:42,784 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-27 21:42:42,957 - INFO - Epoch: [161][0/391] Time 0.172 (0.172) Data 0.153 (0.153) Loss 0.0796 (0.0796) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:42:44,603 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:44,604 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:44,829 - INFO - Epoch: [161][100/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1122 (0.0721) Acc@1 95.312 (97.950) Acc@5 100.000 (99.985)
2025-08-27 21:42:46,730 - INFO - Epoch: [161][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0550 (0.0741) Acc@1 98.438 (97.827) Acc@5 100.000 (99.988)
2025-08-27 21:42:47,660 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:47,660 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:48,670 - INFO - Epoch: [161][300/391] Time 0.022 (0.020) Data 0.002 (0.002) Loss 0.0866 (0.0758) Acc@1 96.094 (97.742) Acc@5 100.000 (99.987)
2025-08-27 21:42:50,538 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.1685 (0.1685) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:42:51,397 - INFO - Epoch 161:
2025-08-27 21:42:51,397 - INFO -   Train: acc1: 97.7060 | acc5: 99.9900 | loss: 0.0763 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:42:51,397 - INFO -   Val:   acc1: 91.3300 | acc5: 99.8600 | loss: 0.2651
2025-08-27 21:42:51,397 - INFO -   LR: 0.001000
2025-08-27 21:42:51,414 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-27 21:42:51,600 - INFO - Epoch: [162][0/391] Time 0.185 (0.185) Data 0.148 (0.148) Loss 0.0584 (0.0584) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:42:51,957 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:51,957 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:53,565 - INFO - Epoch: [162][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.0858 (0.0709) Acc@1 98.438 (97.927) Acc@5 100.000 (99.985)
2025-08-27 21:42:54,956 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:54,956 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:55,394 - INFO - Epoch: [162][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.0735 (0.0729) Acc@1 97.656 (97.753) Acc@5 100.000 (99.988)
2025-08-27 21:42:57,323 - INFO - Epoch: [162][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.0573 (0.0759) Acc@1 96.875 (97.630) Acc@5 100.000 (99.977)
2025-08-27 21:42:58,042 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:42:58,042 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:42:59,183 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.1598 (0.1598) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:43:00,017 - INFO - Epoch 162:
2025-08-27 21:43:00,017 - INFO -   Train: acc1: 97.6320 | acc5: 99.9760 | loss: 0.0760 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:00,017 - INFO -   Val:   acc1: 91.4300 | acc5: 99.8300 | loss: 0.2676
2025-08-27 21:43:00,017 - INFO -   LR: 0.001000
2025-08-27 21:43:00,036 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-27 21:43:00,228 - INFO - Epoch: [163][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.0708 (0.0708) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:43:02,108 - INFO - Epoch: [163][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.0670 (0.0707) Acc@1 97.656 (97.865) Acc@5 100.000 (99.992)
2025-08-27 21:43:02,212 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:02,213 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:03,869 - INFO - Epoch: [163][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.0429 (0.0729) Acc@1 99.219 (97.792) Acc@5 100.000 (99.992)
2025-08-27 21:43:05,091 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:05,091 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:05,709 - INFO - Epoch: [163][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.0860 (0.0743) Acc@1 97.656 (97.773) Acc@5 100.000 (99.995)
2025-08-27 21:43:07,502 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.1739 (0.1739) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:43:08,344 - INFO - Epoch 163:
2025-08-27 21:43:08,344 - INFO -   Train: acc1: 97.7940 | acc5: 99.9960 | loss: 0.0742 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:08,344 - INFO -   Val:   acc1: 91.4200 | acc5: 99.8500 | loss: 0.2665
2025-08-27 21:43:08,344 - INFO -   LR: 0.001000
2025-08-27 21:43:08,362 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-27 21:43:08,532 - INFO - Epoch: [164][0/391] Time 0.169 (0.169) Data 0.136 (0.136) Loss 0.1391 (0.1391) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:43:09,202 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:09,202 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:10,412 - INFO - Epoch: [164][100/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.1039 (0.0711) Acc@1 96.875 (97.881) Acc@5 100.000 (99.992)
2025-08-27 21:43:12,172 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:12,172 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:12,270 - INFO - Epoch: [164][200/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.0520 (0.0728) Acc@1 97.656 (97.796) Acc@5 100.000 (99.992)
2025-08-27 21:43:14,077 - INFO - Epoch: [164][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.0340 (0.0719) Acc@1 99.219 (97.804) Acc@5 100.000 (99.992)
2025-08-27 21:43:15,168 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:15,168 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:15,891 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.1789 (0.1789) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:43:16,732 - INFO - Epoch 164:
2025-08-27 21:43:16,732 - INFO -   Train: acc1: 97.7120 | acc5: 99.9880 | loss: 0.0735 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:16,732 - INFO -   Val:   acc1: 91.1900 | acc5: 99.8700 | loss: 0.2650
2025-08-27 21:43:16,732 - INFO -   LR: 0.001000
2025-08-27 21:43:16,750 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-27 21:43:16,909 - INFO - Epoch: [165][0/391] Time 0.159 (0.159) Data 0.139 (0.139) Loss 0.0858 (0.0858) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:43:18,749 - INFO - Epoch: [165][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0575 (0.0715) Acc@1 99.219 (97.850) Acc@5 100.000 (99.992)
2025-08-27 21:43:19,188 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:19,188 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:20,592 - INFO - Epoch: [165][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0363 (0.0713) Acc@1 99.219 (97.827) Acc@5 100.000 (99.996)
2025-08-27 21:43:22,184 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:22,184 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:22,437 - INFO - Epoch: [165][300/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.0743 (0.0725) Acc@1 97.656 (97.794) Acc@5 100.000 (99.995)
2025-08-27 21:43:24,245 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.1763 (0.1763) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:43:25,069 - INFO - Epoch 165:
2025-08-27 21:43:25,070 - INFO -   Train: acc1: 97.7760 | acc5: 99.9940 | loss: 0.0733 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:25,070 - INFO -   Val:   acc1: 91.3200 | acc5: 99.8600 | loss: 0.2679
2025-08-27 21:43:25,070 - INFO -   LR: 0.001000
2025-08-27 21:43:25,088 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-27 21:43:25,250 - INFO - Epoch: [166][0/391] Time 0.161 (0.161) Data 0.142 (0.142) Loss 0.1177 (0.1177) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-27 21:43:26,280 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:26,280 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:27,153 - INFO - Epoch: [166][100/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0284 (0.0701) Acc@1 99.219 (97.904) Acc@5 100.000 (99.977)
2025-08-27 21:43:28,973 - INFO - Epoch: [166][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.0557 (0.0703) Acc@1 98.438 (97.921) Acc@5 100.000 (99.977)
2025-08-27 21:43:29,249 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:29,250 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:30,805 - INFO - Epoch: [166][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.0375 (0.0701) Acc@1 100.000 (97.921) Acc@5 100.000 (99.979)
2025-08-27 21:43:32,205 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:32,205 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:32,621 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.1572 (0.1572) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:43:33,448 - INFO - Epoch 166:
2025-08-27 21:43:33,448 - INFO -   Train: acc1: 97.8780 | acc5: 99.9840 | loss: 0.0711 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:33,448 - INFO -   Val:   acc1: 91.4400 | acc5: 99.8700 | loss: 0.2695
2025-08-27 21:43:33,448 - INFO -   LR: 0.001000
2025-08-27 21:43:33,467 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-27 21:43:33,607 - INFO - Epoch: [167][0/391] Time 0.139 (0.139) Data 0.119 (0.119) Loss 0.0471 (0.0471) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:43:35,513 - INFO - Epoch: [167][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.0856 (0.0696) Acc@1 97.656 (97.904) Acc@5 100.000 (99.985)
2025-08-27 21:43:36,258 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:36,258 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:37,358 - INFO - Epoch: [167][200/391] Time 0.012 (0.019) Data 0.001 (0.003) Loss 0.0456 (0.0692) Acc@1 99.219 (97.843) Acc@5 100.000 (99.984)
2025-08-27 21:43:39,248 - INFO - Epoch: [167][300/391] Time 0.017 (0.019) Data 0.004 (0.002) Loss 0.0765 (0.0702) Acc@1 97.656 (97.848) Acc@5 100.000 (99.979)
2025-08-27 21:43:39,298 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:39,298 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:41,129 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.1786 (0.1786) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:43:41,976 - INFO - Epoch 167:
2025-08-27 21:43:41,976 - INFO -   Train: acc1: 97.8560 | acc5: 99.9780 | loss: 0.0701 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:41,976 - INFO -   Val:   acc1: 91.3400 | acc5: 99.8800 | loss: 0.2655
2025-08-27 21:43:41,976 - INFO -   LR: 0.001000
2025-08-27 21:43:41,993 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-27 21:43:42,156 - INFO - Epoch: [168][0/391] Time 0.162 (0.162) Data 0.144 (0.144) Loss 0.1168 (0.1168) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:43:43,488 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:43,488 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:44,067 - INFO - Epoch: [168][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.0463 (0.0685) Acc@1 99.219 (97.765) Acc@5 100.000 (99.992)
2025-08-27 21:43:46,002 - INFO - Epoch: [168][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.0893 (0.0708) Acc@1 96.875 (97.812) Acc@5 100.000 (99.996)
2025-08-27 21:43:46,628 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:46,628 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:47,934 - INFO - Epoch: [168][300/391] Time 0.027 (0.020) Data 0.001 (0.002) Loss 0.0538 (0.0705) Acc@1 98.438 (97.812) Acc@5 100.000 (99.987)
2025-08-27 21:43:49,800 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.1836 (0.1836) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:43:50,635 - INFO - Epoch 168:
2025-08-27 21:43:50,636 - INFO -   Train: acc1: 97.8240 | acc5: 99.9880 | loss: 0.0705 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:50,636 - INFO -   Val:   acc1: 91.4500 | acc5: 99.8900 | loss: 0.2686
2025-08-27 21:43:50,636 - INFO -   LR: 0.001000
2025-08-27 21:43:50,653 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-27 21:43:50,846 - INFO - Epoch: [169][0/391] Time 0.192 (0.192) Data 0.172 (0.172) Loss 0.0423 (0.0423) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-27 21:43:50,856 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:50,856 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:52,834 - INFO - Epoch: [169][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.0491 (0.0654) Acc@1 99.219 (98.074) Acc@5 100.000 (100.000)
2025-08-27 21:43:54,035 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:54,036 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:54,834 - INFO - Epoch: [169][200/391] Time 0.024 (0.021) Data 0.000 (0.002) Loss 0.0480 (0.0668) Acc@1 99.219 (98.041) Acc@5 100.000 (99.996)
2025-08-27 21:43:56,797 - INFO - Epoch: [169][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0648 (0.0682) Acc@1 98.438 (97.970) Acc@5 100.000 (99.990)
2025-08-27 21:43:57,205 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:43:57,205 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:43:58,672 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.1879 (0.1879) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:43:59,492 - INFO - Epoch 169:
2025-08-27 21:43:59,492 - INFO -   Train: acc1: 97.9500 | acc5: 99.9920 | loss: 0.0684 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:43:59,492 - INFO -   Val:   acc1: 91.4800 | acc5: 99.8600 | loss: 0.2658
2025-08-27 21:43:59,492 - INFO -   LR: 0.001000
2025-08-27 21:43:59,512 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-27 21:43:59,704 - INFO - Epoch: [170][0/391] Time 0.190 (0.190) Data 0.169 (0.169) Loss 0.0569 (0.0569) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:44:01,464 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:01,464 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:01,676 - INFO - Epoch: [170][100/391] Time 0.033 (0.021) Data 0.000 (0.003) Loss 0.0955 (0.0691) Acc@1 96.875 (97.865) Acc@5 100.000 (100.000)
2025-08-27 21:44:03,579 - INFO - Epoch: [170][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0482 (0.0678) Acc@1 98.438 (97.928) Acc@5 100.000 (99.992)
2025-08-27 21:44:04,449 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:04,449 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:05,410 - INFO - Epoch: [170][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0737 (0.0686) Acc@1 97.656 (97.887) Acc@5 100.000 (99.990)
2025-08-27 21:44:07,268 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.1777 (0.1777) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:44:08,091 - INFO - Epoch 170:
2025-08-27 21:44:08,092 - INFO -   Train: acc1: 97.9360 | acc5: 99.9840 | loss: 0.0680 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:08,092 - INFO -   Val:   acc1: 91.5800 | acc5: 99.8800 | loss: 0.2680
2025-08-27 21:44:08,092 - INFO -   LR: 0.001000
2025-08-27 21:44:08,145 - INFO - Checkpoint saved: epoch=170, metric=91.5800
2025-08-27 21:44:08,176 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-27 21:44:08,338 - INFO - Epoch: [171][0/391] Time 0.161 (0.161) Data 0.136 (0.136) Loss 0.0496 (0.0496) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:44:08,652 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:08,653 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:10,287 - INFO - Epoch: [171][100/391] Time 0.030 (0.021) Data 0.007 (0.004) Loss 0.0787 (0.0660) Acc@1 96.875 (97.942) Acc@5 100.000 (100.000)
2025-08-27 21:44:11,849 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:11,849 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:12,276 - INFO - Epoch: [171][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0818 (0.0664) Acc@1 98.438 (97.971) Acc@5 100.000 (100.000)
2025-08-27 21:44:14,191 - INFO - Epoch: [171][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0907 (0.0653) Acc@1 96.094 (97.994) Acc@5 100.000 (100.000)
2025-08-27 21:44:14,946 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:14,946 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:16,052 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.1655 (0.1655) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:44:16,899 - INFO - Epoch 171:
2025-08-27 21:44:16,899 - INFO -   Train: acc1: 97.9400 | acc5: 99.9980 | loss: 0.0665 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:16,899 - INFO -   Val:   acc1: 91.4900 | acc5: 99.8900 | loss: 0.2710
2025-08-27 21:44:16,899 - INFO -   LR: 0.001000
2025-08-27 21:44:16,916 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-27 21:44:17,101 - INFO - Epoch: [172][0/391] Time 0.184 (0.184) Data 0.162 (0.162) Loss 0.0571 (0.0571) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:44:19,015 - INFO - Epoch: [172][100/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.0659 (0.0655) Acc@1 97.656 (98.035) Acc@5 100.000 (99.977)
2025-08-27 21:44:19,141 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:19,141 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:20,832 - INFO - Epoch: [172][200/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.0289 (0.0638) Acc@1 100.000 (98.088) Acc@5 100.000 (99.984)
2025-08-27 21:44:22,109 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:22,109 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:22,747 - INFO - Epoch: [172][300/391] Time 0.032 (0.019) Data 0.000 (0.002) Loss 0.0225 (0.0654) Acc@1 100.000 (98.077) Acc@5 100.000 (99.984)
2025-08-27 21:44:24,575 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.1792 (0.1792) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:44:25,378 - INFO - Epoch 172:
2025-08-27 21:44:25,378 - INFO -   Train: acc1: 98.0940 | acc5: 99.9880 | loss: 0.0646 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:25,378 - INFO -   Val:   acc1: 91.5000 | acc5: 99.8700 | loss: 0.2706
2025-08-27 21:44:25,379 - INFO -   LR: 0.001000
2025-08-27 21:44:25,397 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-27 21:44:25,566 - INFO - Epoch: [173][0/391] Time 0.168 (0.168) Data 0.144 (0.144) Loss 0.0548 (0.0548) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:44:26,273 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:26,273 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:27,407 - INFO - Epoch: [173][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0649 (0.0643) Acc@1 96.875 (98.136) Acc@5 100.000 (99.992)
2025-08-27 21:44:29,291 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:29,291 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:29,339 - INFO - Epoch: [173][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.0514 (0.0650) Acc@1 98.438 (98.119) Acc@5 100.000 (99.984)
2025-08-27 21:44:31,174 - INFO - Epoch: [173][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.0979 (0.0664) Acc@1 96.875 (98.051) Acc@5 100.000 (99.990)
2025-08-27 21:44:32,283 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:32,284 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:33,042 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.1941 (0.1941) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:44:33,857 - INFO - Epoch 173:
2025-08-27 21:44:33,857 - INFO -   Train: acc1: 98.0740 | acc5: 99.9880 | loss: 0.0663 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:33,857 - INFO -   Val:   acc1: 91.3100 | acc5: 99.8500 | loss: 0.2746
2025-08-27 21:44:33,857 - INFO -   LR: 0.001000
2025-08-27 21:44:33,876 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-27 21:44:34,058 - INFO - Epoch: [174][0/391] Time 0.181 (0.181) Data 0.151 (0.151) Loss 0.0452 (0.0452) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:44:35,888 - INFO - Epoch: [174][100/391] Time 0.019 (0.020) Data 0.006 (0.005) Loss 0.0538 (0.0662) Acc@1 98.438 (97.942) Acc@5 100.000 (99.992)
2025-08-27 21:44:36,383 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:36,383 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:37,765 - INFO - Epoch: [174][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.0544 (0.0640) Acc@1 97.656 (98.060) Acc@5 100.000 (99.988)
2025-08-27 21:44:39,343 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:39,344 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:39,646 - INFO - Epoch: [174][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.0532 (0.0647) Acc@1 98.438 (98.046) Acc@5 100.000 (99.987)
2025-08-27 21:44:41,446 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.1789 (0.1789) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:44:42,300 - INFO - Epoch 174:
2025-08-27 21:44:42,300 - INFO -   Train: acc1: 98.0500 | acc5: 99.9880 | loss: 0.0649 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:42,300 - INFO -   Val:   acc1: 91.3100 | acc5: 99.8600 | loss: 0.2717
2025-08-27 21:44:42,300 - INFO -   LR: 0.001000
2025-08-27 21:44:42,319 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-27 21:44:42,513 - INFO - Epoch: [175][0/391] Time 0.193 (0.193) Data 0.169 (0.169) Loss 0.0604 (0.0604) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:44:43,629 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:43,629 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:44,524 - INFO - Epoch: [175][100/391] Time 0.016 (0.022) Data 0.000 (0.004) Loss 0.0539 (0.0633) Acc@1 99.219 (98.144) Acc@5 100.000 (100.000)
2025-08-27 21:44:46,443 - INFO - Epoch: [175][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.0315 (0.0626) Acc@1 99.219 (98.177) Acc@5 100.000 (99.992)
2025-08-27 21:44:46,730 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:46,730 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:48,342 - INFO - Epoch: [175][300/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.0718 (0.0644) Acc@1 98.438 (98.056) Acc@5 100.000 (99.995)
2025-08-27 21:44:49,783 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:49,784 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:50,176 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.1904 (0.1904) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:44:50,991 - INFO - Epoch 175:
2025-08-27 21:44:50,991 - INFO -   Train: acc1: 98.0880 | acc5: 99.9960 | loss: 0.0643 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:50,991 - INFO -   Val:   acc1: 91.3100 | acc5: 99.8300 | loss: 0.2701
2025-08-27 21:44:50,991 - INFO -   LR: 0.001000
2025-08-27 21:44:51,011 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-27 21:44:51,201 - INFO - Epoch: [176][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.0398 (0.0398) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:44:53,117 - INFO - Epoch: [176][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.0801 (0.0600) Acc@1 96.875 (98.128) Acc@5 100.000 (100.000)
2025-08-27 21:44:53,968 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:53,968 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:55,067 - INFO - Epoch: [176][200/391] Time 0.033 (0.020) Data 0.022 (0.002) Loss 0.0445 (0.0619) Acc@1 99.219 (98.092) Acc@5 100.000 (99.992)
2025-08-27 21:44:56,937 - INFO - Epoch: [176][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0491 (0.0641) Acc@1 99.219 (98.001) Acc@5 100.000 (99.992)
2025-08-27 21:44:57,008 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:44:57,008 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:44:58,798 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.1787 (0.1787) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:44:59,641 - INFO - Epoch 176:
2025-08-27 21:44:59,641 - INFO -   Train: acc1: 98.0020 | acc5: 99.9920 | loss: 0.0643 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:44:59,641 - INFO -   Val:   acc1: 91.3300 | acc5: 99.8400 | loss: 0.2737
2025-08-27 21:44:59,641 - INFO -   LR: 0.001000
2025-08-27 21:44:59,661 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-27 21:44:59,840 - INFO - Epoch: [177][0/391] Time 0.179 (0.179) Data 0.147 (0.147) Loss 0.0571 (0.0571) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:45:01,221 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:01,221 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:01,730 - INFO - Epoch: [177][100/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.0628 (0.0624) Acc@1 97.656 (98.051) Acc@5 100.000 (99.992)
2025-08-27 21:45:03,589 - INFO - Epoch: [177][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.0457 (0.0619) Acc@1 99.219 (98.127) Acc@5 100.000 (99.996)
2025-08-27 21:45:04,213 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:04,214 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:05,461 - INFO - Epoch: [177][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1193 (0.0627) Acc@1 96.094 (98.116) Acc@5 100.000 (99.992)
2025-08-27 21:45:07,284 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.1819 (0.1819) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:45:08,147 - INFO - Epoch 177:
2025-08-27 21:45:08,147 - INFO -   Train: acc1: 98.1160 | acc5: 99.9920 | loss: 0.0626 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:08,147 - INFO -   Val:   acc1: 91.5300 | acc5: 99.8700 | loss: 0.2751
2025-08-27 21:45:08,147 - INFO -   LR: 0.001000
2025-08-27 21:45:08,166 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-27 21:45:08,342 - INFO - Epoch: [178][0/391] Time 0.175 (0.175) Data 0.123 (0.123) Loss 0.0492 (0.0492) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:45:08,371 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:08,371 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:10,152 - INFO - Epoch: [178][100/391] Time 0.024 (0.020) Data 0.006 (0.003) Loss 0.0657 (0.0629) Acc@1 98.438 (98.198) Acc@5 100.000 (99.992)
2025-08-27 21:45:11,250 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:11,250 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:11,956 - INFO - Epoch: [178][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.0564 (0.0615) Acc@1 97.656 (98.216) Acc@5 100.000 (99.992)
2025-08-27 21:45:13,850 - INFO - Epoch: [178][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.0699 (0.0617) Acc@1 98.438 (98.196) Acc@5 100.000 (99.990)
2025-08-27 21:45:14,235 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:14,236 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:15,657 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.1960 (0.1960) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:45:16,491 - INFO - Epoch 178:
2025-08-27 21:45:16,491 - INFO -   Train: acc1: 98.1700 | acc5: 99.9900 | loss: 0.0618 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:16,491 - INFO -   Val:   acc1: 91.3300 | acc5: 99.8400 | loss: 0.2784
2025-08-27 21:45:16,491 - INFO -   LR: 0.001000
2025-08-27 21:45:16,509 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-27 21:45:16,681 - INFO - Epoch: [179][0/391] Time 0.170 (0.170) Data 0.151 (0.151) Loss 0.0379 (0.0379) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:45:18,329 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:18,330 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:18,499 - INFO - Epoch: [179][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.0439 (0.0596) Acc@1 100.000 (98.337) Acc@5 100.000 (99.992)
2025-08-27 21:45:20,338 - INFO - Epoch: [179][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.0774 (0.0600) Acc@1 98.438 (98.290) Acc@5 100.000 (99.984)
2025-08-27 21:45:21,279 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:21,279 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:22,114 - INFO - Epoch: [179][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.0263 (0.0607) Acc@1 100.000 (98.261) Acc@5 100.000 (99.982)
2025-08-27 21:45:23,937 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2229 (0.2229) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:45:24,764 - INFO - Epoch 179:
2025-08-27 21:45:24,765 - INFO -   Train: acc1: 98.2400 | acc5: 99.9840 | loss: 0.0611 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:24,765 - INFO -   Val:   acc1: 91.3200 | acc5: 99.8200 | loss: 0.2772
2025-08-27 21:45:24,765 - INFO -   LR: 0.001000
2025-08-27 21:45:24,783 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-27 21:45:24,962 - INFO - Epoch: [180][0/391] Time 0.178 (0.178) Data 0.155 (0.155) Loss 0.1103 (0.1103) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:45:25,303 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:25,303 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:26,849 - INFO - Epoch: [180][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.0505 (0.0637) Acc@1 98.438 (98.144) Acc@5 100.000 (99.985)
2025-08-27 21:45:28,290 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:28,290 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:28,700 - INFO - Epoch: [180][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.0516 (0.0629) Acc@1 99.219 (98.165) Acc@5 100.000 (99.988)
2025-08-27 21:45:30,606 - INFO - Epoch: [180][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.0595 (0.0624) Acc@1 98.438 (98.194) Acc@5 100.000 (99.992)
2025-08-27 21:45:31,398 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:31,399 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:32,465 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.1898 (0.1898) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:45:33,301 - INFO - Epoch 180:
2025-08-27 21:45:33,301 - INFO -   Train: acc1: 98.1720 | acc5: 99.9940 | loss: 0.0618 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:33,301 - INFO -   Val:   acc1: 91.4700 | acc5: 99.8600 | loss: 0.2759
2025-08-27 21:45:33,301 - INFO -   LR: 0.001000
2025-08-27 21:45:33,355 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-27 21:45:33,535 - INFO - Epoch: [181][0/391] Time 0.179 (0.179) Data 0.150 (0.150) Loss 0.0611 (0.0611) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:45:35,453 - INFO - Epoch: [181][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.0426 (0.0582) Acc@1 98.438 (98.291) Acc@5 100.000 (99.977)
2025-08-27 21:45:35,623 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:35,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:37,414 - INFO - Epoch: [181][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.0797 (0.0583) Acc@1 96.875 (98.274) Acc@5 100.000 (99.988)
2025-08-27 21:45:38,667 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:38,667 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:39,274 - INFO - Epoch: [181][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0640 (0.0599) Acc@1 97.656 (98.217) Acc@5 100.000 (99.992)
2025-08-27 21:45:41,118 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.1925 (0.1925) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:45:41,953 - INFO - Epoch 181:
2025-08-27 21:45:41,954 - INFO -   Train: acc1: 98.2340 | acc5: 99.9940 | loss: 0.0595 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:41,954 - INFO -   Val:   acc1: 91.2900 | acc5: 99.8800 | loss: 0.2763
2025-08-27 21:45:41,954 - INFO -   LR: 0.001000
2025-08-27 21:45:41,973 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-27 21:45:42,154 - INFO - Epoch: [182][0/391] Time 0.179 (0.179) Data 0.162 (0.162) Loss 0.0295 (0.0295) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-27 21:45:42,902 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:42,902 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:44,113 - INFO - Epoch: [182][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.0374 (0.0570) Acc@1 99.219 (98.337) Acc@5 100.000 (100.000)
2025-08-27 21:45:45,938 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:45,938 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:45,974 - INFO - Epoch: [182][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.0568 (0.0557) Acc@1 97.656 (98.383) Acc@5 100.000 (100.000)
2025-08-27 21:45:47,913 - INFO - Epoch: [182][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.0496 (0.0590) Acc@1 97.656 (98.230) Acc@5 100.000 (99.995)
2025-08-27 21:45:49,058 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:49,059 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:49,774 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.2162 (0.2162) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:45:50,611 - INFO - Epoch 182:
2025-08-27 21:45:50,611 - INFO -   Train: acc1: 98.2020 | acc5: 99.9940 | loss: 0.0593 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:50,612 - INFO -   Val:   acc1: 91.4400 | acc5: 99.8600 | loss: 0.2790
2025-08-27 21:45:50,612 - INFO -   LR: 0.001000
2025-08-27 21:45:50,630 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-27 21:45:50,803 - INFO - Epoch: [183][0/391] Time 0.172 (0.172) Data 0.141 (0.141) Loss 0.0582 (0.0582) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:45:52,654 - INFO - Epoch: [183][100/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.0913 (0.0594) Acc@1 97.656 (98.329) Acc@5 100.000 (99.992)
2025-08-27 21:45:53,159 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:53,159 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:54,577 - INFO - Epoch: [183][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0572 (0.0581) Acc@1 97.656 (98.352) Acc@5 100.000 (99.996)
2025-08-27 21:45:56,209 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:45:56,209 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:45:56,466 - INFO - Epoch: [183][300/391] Time 0.016 (0.019) Data 0.000 (0.001) Loss 0.0581 (0.0582) Acc@1 99.219 (98.336) Acc@5 100.000 (99.992)
2025-08-27 21:45:58,267 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2168 (0.2168) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:45:59,083 - INFO - Epoch 183:
2025-08-27 21:45:59,084 - INFO -   Train: acc1: 98.2720 | acc5: 99.9920 | loss: 0.0587 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:45:59,084 - INFO -   Val:   acc1: 91.4800 | acc5: 99.8600 | loss: 0.2775
2025-08-27 21:45:59,084 - INFO -   LR: 0.001000
2025-08-27 21:45:59,103 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-27 21:45:59,263 - INFO - Epoch: [184][0/391] Time 0.159 (0.159) Data 0.143 (0.143) Loss 0.0838 (0.0838) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:46:00,406 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:00,406 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:01,282 - INFO - Epoch: [184][100/391] Time 0.026 (0.022) Data 0.013 (0.003) Loss 0.0783 (0.0567) Acc@1 96.094 (98.221) Acc@5 100.000 (100.000)
2025-08-27 21:46:03,244 - INFO - Epoch: [184][200/391] Time 0.029 (0.021) Data 0.000 (0.002) Loss 0.0475 (0.0569) Acc@1 97.656 (98.274) Acc@5 100.000 (99.996)
2025-08-27 21:46:03,548 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:03,548 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:05,263 - INFO - Epoch: [184][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0743 (0.0575) Acc@1 98.438 (98.232) Acc@5 100.000 (99.995)
2025-08-27 21:46:06,787 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:06,787 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:07,207 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2028 (0.2028) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:46:08,045 - INFO - Epoch 184:
2025-08-27 21:46:08,046 - INFO -   Train: acc1: 98.2160 | acc5: 99.9940 | loss: 0.0583 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:08,046 - INFO -   Val:   acc1: 91.5400 | acc5: 99.8500 | loss: 0.2774
2025-08-27 21:46:08,046 - INFO -   LR: 0.001000
2025-08-27 21:46:08,066 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-27 21:46:08,227 - INFO - Epoch: [185][0/391] Time 0.160 (0.160) Data 0.137 (0.137) Loss 0.0734 (0.0734) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 21:46:10,196 - INFO - Epoch: [185][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.0584 (0.0578) Acc@1 99.219 (98.283) Acc@5 100.000 (100.000)
2025-08-27 21:46:11,054 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:11,054 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:12,068 - INFO - Epoch: [185][200/391] Time 0.022 (0.020) Data 0.009 (0.003) Loss 0.0625 (0.0582) Acc@1 99.219 (98.294) Acc@5 100.000 (100.000)
2025-08-27 21:46:13,921 - INFO - Epoch: [185][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0662 (0.0591) Acc@1 97.656 (98.256) Acc@5 100.000 (99.992)
2025-08-27 21:46:14,015 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:14,015 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:15,778 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.2000 (0.2000) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:46:16,616 - INFO - Epoch 185:
2025-08-27 21:46:16,616 - INFO -   Train: acc1: 98.2800 | acc5: 99.9940 | loss: 0.0587 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:16,616 - INFO -   Val:   acc1: 91.2800 | acc5: 99.8700 | loss: 0.2811
2025-08-27 21:46:16,616 - INFO -   LR: 0.001000
2025-08-27 21:46:16,637 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-27 21:46:16,825 - INFO - Epoch: [186][0/391] Time 0.187 (0.187) Data 0.155 (0.155) Loss 0.0440 (0.0440) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:46:18,165 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:18,165 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:18,644 - INFO - Epoch: [186][100/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0771 (0.0580) Acc@1 98.438 (98.337) Acc@5 100.000 (99.985)
2025-08-27 21:46:20,468 - INFO - Epoch: [186][200/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.0593 (0.0573) Acc@1 97.656 (98.352) Acc@5 100.000 (99.988)
2025-08-27 21:46:21,109 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:21,109 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:22,339 - INFO - Epoch: [186][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.0391 (0.0583) Acc@1 99.219 (98.305) Acc@5 100.000 (99.990)
2025-08-27 21:46:24,160 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2009 (0.2009) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:46:25,019 - INFO - Epoch 186:
2025-08-27 21:46:25,019 - INFO -   Train: acc1: 98.2700 | acc5: 99.9920 | loss: 0.0590 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:25,019 - INFO -   Val:   acc1: 91.3700 | acc5: 99.8700 | loss: 0.2797
2025-08-27 21:46:25,019 - INFO -   LR: 0.001000
2025-08-27 21:46:25,037 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-27 21:46:25,204 - INFO - Epoch: [187][0/391] Time 0.167 (0.167) Data 0.146 (0.146) Loss 0.0648 (0.0648) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:46:25,257 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:25,257 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:27,061 - INFO - Epoch: [187][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0561 (0.0569) Acc@1 97.656 (98.383) Acc@5 100.000 (99.985)
2025-08-27 21:46:28,292 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:28,292 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:28,978 - INFO - Epoch: [187][200/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.0487 (0.0570) Acc@1 99.219 (98.344) Acc@5 100.000 (99.992)
2025-08-27 21:46:30,852 - INFO - Epoch: [187][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0646 (0.0583) Acc@1 96.094 (98.258) Acc@5 100.000 (99.995)
2025-08-27 21:46:31,254 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:31,254 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:32,675 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2098 (0.2098) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:46:33,547 - INFO - Epoch 187:
2025-08-27 21:46:33,547 - INFO -   Train: acc1: 98.1980 | acc5: 99.9940 | loss: 0.0594 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:33,547 - INFO -   Val:   acc1: 91.2400 | acc5: 99.8600 | loss: 0.2808
2025-08-27 21:46:33,547 - INFO -   LR: 0.001000
2025-08-27 21:46:33,566 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-27 21:46:33,753 - INFO - Epoch: [188][0/391] Time 0.186 (0.186) Data 0.160 (0.160) Loss 0.0441 (0.0441) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:46:35,420 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:35,420 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:35,596 - INFO - Epoch: [188][100/391] Time 0.026 (0.020) Data 0.011 (0.004) Loss 0.0429 (0.0570) Acc@1 99.219 (98.306) Acc@5 100.000 (100.000)
2025-08-27 21:46:37,473 - INFO - Epoch: [188][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.0730 (0.0560) Acc@1 96.875 (98.313) Acc@5 100.000 (100.000)
2025-08-27 21:46:38,407 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:38,407 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:39,320 - INFO - Epoch: [188][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.0736 (0.0564) Acc@1 97.656 (98.274) Acc@5 100.000 (100.000)
2025-08-27 21:46:41,055 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2358 (0.2358) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:46:41,926 - INFO - Epoch 188:
2025-08-27 21:46:41,927 - INFO -   Train: acc1: 98.2560 | acc5: 99.9980 | loss: 0.0569 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:41,927 - INFO -   Val:   acc1: 91.2200 | acc5: 99.8600 | loss: 0.2843
2025-08-27 21:46:41,927 - INFO -   LR: 0.001000
2025-08-27 21:46:41,946 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-27 21:46:42,145 - INFO - Epoch: [189][0/391] Time 0.198 (0.198) Data 0.166 (0.166) Loss 0.0248 (0.0248) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-27 21:46:42,572 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:42,573 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:44,158 - INFO - Epoch: [189][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.1012 (0.0591) Acc@1 95.312 (98.229) Acc@5 100.000 (99.985)
2025-08-27 21:46:45,696 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:45,697 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:46,052 - INFO - Epoch: [189][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0557 (0.0582) Acc@1 98.438 (98.239) Acc@5 100.000 (99.988)
2025-08-27 21:46:47,962 - INFO - Epoch: [189][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.0773 (0.0565) Acc@1 97.656 (98.287) Acc@5 100.000 (99.990)
2025-08-27 21:46:48,739 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:48,740 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:49,812 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.1944 (0.1944) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:46:50,634 - INFO - Epoch 189:
2025-08-27 21:46:50,634 - INFO -   Train: acc1: 98.2600 | acc5: 99.9920 | loss: 0.0569 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:50,634 - INFO -   Val:   acc1: 91.5000 | acc5: 99.9000 | loss: 0.2787
2025-08-27 21:46:50,634 - INFO -   LR: 0.001000
2025-08-27 21:46:50,656 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-27 21:46:50,844 - INFO - Epoch: [190][0/391] Time 0.187 (0.187) Data 0.152 (0.152) Loss 0.0632 (0.0632) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:46:52,695 - INFO - Epoch: [190][100/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1059 (0.0551) Acc@1 95.312 (98.360) Acc@5 100.000 (100.000)
2025-08-27 21:46:52,867 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:52,867 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:54,622 - INFO - Epoch: [190][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.0371 (0.0567) Acc@1 100.000 (98.255) Acc@5 100.000 (100.000)
2025-08-27 21:46:55,986 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:46:55,986 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:46:56,579 - INFO - Epoch: [190][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0429 (0.0564) Acc@1 99.219 (98.290) Acc@5 100.000 (99.995)
2025-08-27 21:46:58,430 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2167 (0.2167) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:46:59,310 - INFO - Epoch 190:
2025-08-27 21:46:59,310 - INFO -   Train: acc1: 98.3120 | acc5: 99.9940 | loss: 0.0563 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:46:59,310 - INFO -   Val:   acc1: 91.3700 | acc5: 99.8500 | loss: 0.2813
2025-08-27 21:46:59,310 - INFO -   LR: 0.001000
2025-08-27 21:46:59,464 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-27 21:46:59,628 - INFO - Epoch: [191][0/391] Time 0.163 (0.163) Data 0.137 (0.137) Loss 0.0803 (0.0803) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 21:47:00,362 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:00,362 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:01,478 - INFO - Epoch: [191][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0587 (0.0568) Acc@1 97.656 (98.345) Acc@5 100.000 (99.985)
2025-08-27 21:47:03,293 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:03,293 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:03,317 - INFO - Epoch: [191][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.0483 (0.0563) Acc@1 100.000 (98.325) Acc@5 100.000 (99.988)
2025-08-27 21:47:05,185 - INFO - Epoch: [191][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.0539 (0.0551) Acc@1 99.219 (98.401) Acc@5 100.000 (99.992)
2025-08-27 21:47:06,363 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:06,363 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:07,113 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2151 (0.2151) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:47:07,917 - INFO - Epoch 191:
2025-08-27 21:47:07,917 - INFO -   Train: acc1: 98.3420 | acc5: 99.9920 | loss: 0.0565 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:07,917 - INFO -   Val:   acc1: 91.2600 | acc5: 99.8800 | loss: 0.2840
2025-08-27 21:47:07,917 - INFO -   LR: 0.001000
2025-08-27 21:47:07,937 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-27 21:47:08,114 - INFO - Epoch: [192][0/391] Time 0.176 (0.176) Data 0.149 (0.149) Loss 0.0511 (0.0511) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:47:09,931 - INFO - Epoch: [192][100/391] Time 0.026 (0.020) Data 0.010 (0.003) Loss 0.1010 (0.0544) Acc@1 94.531 (98.492) Acc@5 100.000 (100.000)
2025-08-27 21:47:10,467 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:10,468 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:11,806 - INFO - Epoch: [192][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.0682 (0.0534) Acc@1 99.219 (98.539) Acc@5 100.000 (99.996)
2025-08-27 21:47:13,462 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:13,462 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:13,686 - INFO - Epoch: [192][300/391] Time 0.027 (0.019) Data 0.015 (0.003) Loss 0.0914 (0.0545) Acc@1 96.094 (98.463) Acc@5 100.000 (99.995)
2025-08-27 21:47:15,434 - INFO - Test: [0/79] Time 0.106 (0.106) Loss 0.1892 (0.1892) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 21:47:16,287 - INFO - Epoch 192:
2025-08-27 21:47:16,287 - INFO -   Train: acc1: 98.4080 | acc5: 99.9920 | loss: 0.0554 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:16,287 - INFO -   Val:   acc1: 91.3900 | acc5: 99.8400 | loss: 0.2798
2025-08-27 21:47:16,288 - INFO -   LR: 0.001000
2025-08-27 21:47:16,308 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-27 21:47:16,481 - INFO - Epoch: [193][0/391] Time 0.172 (0.172) Data 0.154 (0.154) Loss 0.1067 (0.1067) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 21:47:17,524 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:17,524 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:18,351 - INFO - Epoch: [193][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.0820 (0.0549) Acc@1 98.438 (98.507) Acc@5 100.000 (100.000)
2025-08-27 21:47:20,194 - INFO - Epoch: [193][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0330 (0.0570) Acc@1 99.219 (98.403) Acc@5 100.000 (99.992)
2025-08-27 21:47:20,502 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:20,503 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:22,159 - INFO - Epoch: [193][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0414 (0.0557) Acc@1 99.219 (98.417) Acc@5 100.000 (99.995)
2025-08-27 21:47:23,723 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:23,723 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:24,098 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2040 (0.2040) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:47:24,915 - INFO - Epoch 193:
2025-08-27 21:47:24,915 - INFO -   Train: acc1: 98.4500 | acc5: 99.9920 | loss: 0.0552 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:24,915 - INFO -   Val:   acc1: 91.6600 | acc5: 99.8600 | loss: 0.2800
2025-08-27 21:47:24,915 - INFO -   LR: 0.001000
2025-08-27 21:47:24,967 - INFO - Checkpoint saved: epoch=193, metric=91.6600
2025-08-27 21:47:24,998 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-27 21:47:25,187 - INFO - Epoch: [194][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.0160 (0.0160) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-27 21:47:27,048 - INFO - Epoch: [194][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.0260 (0.0500) Acc@1 100.000 (98.615) Acc@5 100.000 (100.000)
2025-08-27 21:47:27,922 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:27,922 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:28,987 - INFO - Epoch: [194][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0619 (0.0522) Acc@1 97.656 (98.476) Acc@5 100.000 (99.996)
2025-08-27 21:47:30,896 - INFO - Epoch: [194][300/391] Time 0.032 (0.020) Data 0.013 (0.002) Loss 0.0368 (0.0532) Acc@1 99.219 (98.445) Acc@5 100.000 (99.995)
2025-08-27 21:47:30,997 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:30,997 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:32,714 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.1974 (0.1974) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:47:33,557 - INFO - Epoch 194:
2025-08-27 21:47:33,557 - INFO -   Train: acc1: 98.4760 | acc5: 99.9920 | loss: 0.0529 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:33,557 - INFO -   Val:   acc1: 91.4100 | acc5: 99.8800 | loss: 0.2858
2025-08-27 21:47:33,557 - INFO -   LR: 0.001000
2025-08-27 21:47:33,578 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-27 21:47:33,749 - INFO - Epoch: [195][0/391] Time 0.170 (0.170) Data 0.145 (0.145) Loss 0.0563 (0.0563) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:47:35,131 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:35,131 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:35,674 - INFO - Epoch: [195][100/391] Time 0.031 (0.021) Data 0.016 (0.003) Loss 0.0071 (0.0517) Acc@1 100.000 (98.561) Acc@5 100.000 (100.000)
2025-08-27 21:47:37,527 - INFO - Epoch: [195][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0385 (0.0518) Acc@1 100.000 (98.496) Acc@5 100.000 (100.000)
2025-08-27 21:47:38,141 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:38,141 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:39,356 - INFO - Epoch: [195][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.0407 (0.0533) Acc@1 99.219 (98.435) Acc@5 100.000 (100.000)
2025-08-27 21:47:41,167 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.2174 (0.2174) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 21:47:42,010 - INFO - Epoch 195:
2025-08-27 21:47:42,010 - INFO -   Train: acc1: 98.4300 | acc5: 100.0000 | loss: 0.0536 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:42,010 - INFO -   Val:   acc1: 91.3200 | acc5: 99.8300 | loss: 0.2885
2025-08-27 21:47:42,010 - INFO -   LR: 0.001000
2025-08-27 21:47:42,028 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-27 21:47:42,213 - INFO - Epoch: [196][0/391] Time 0.184 (0.184) Data 0.165 (0.165) Loss 0.0473 (0.0473) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:47:42,257 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:42,257 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:44,113 - INFO - Epoch: [196][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.0357 (0.0538) Acc@1 100.000 (98.484) Acc@5 100.000 (100.000)
2025-08-27 21:47:45,214 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:45,214 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:45,850 - INFO - Epoch: [196][200/391] Time 0.039 (0.019) Data 0.028 (0.002) Loss 0.0503 (0.0532) Acc@1 98.438 (98.461) Acc@5 100.000 (99.996)
2025-08-27 21:47:47,783 - INFO - Epoch: [196][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.0644 (0.0540) Acc@1 96.875 (98.432) Acc@5 100.000 (99.997)
2025-08-27 21:47:48,233 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:48,233 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:49,582 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2125 (0.2125) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:47:50,435 - INFO - Epoch 196:
2025-08-27 21:47:50,436 - INFO -   Train: acc1: 98.3780 | acc5: 99.9960 | loss: 0.0550 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:50,436 - INFO -   Val:   acc1: 91.3700 | acc5: 99.8500 | loss: 0.2885
2025-08-27 21:47:50,436 - INFO -   LR: 0.001000
2025-08-27 21:47:50,456 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-27 21:47:50,635 - INFO - Epoch: [197][0/391] Time 0.179 (0.179) Data 0.154 (0.154) Loss 0.0457 (0.0457) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-27 21:47:52,361 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:52,361 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:52,508 - INFO - Epoch: [197][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.0630 (0.0574) Acc@1 98.438 (98.360) Acc@5 100.000 (99.992)
2025-08-27 21:47:54,344 - INFO - Epoch: [197][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0753 (0.0545) Acc@1 97.656 (98.449) Acc@5 100.000 (99.996)
2025-08-27 21:47:55,259 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:55,259 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:47:56,149 - INFO - Epoch: [197][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0458 (0.0534) Acc@1 100.000 (98.448) Acc@5 100.000 (99.997)
2025-08-27 21:47:57,943 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2023 (0.2023) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 21:47:58,773 - INFO - Epoch 197:
2025-08-27 21:47:58,773 - INFO -   Train: acc1: 98.4380 | acc5: 99.9960 | loss: 0.0533 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:47:58,773 - INFO -   Val:   acc1: 91.5400 | acc5: 99.8800 | loss: 0.2835
2025-08-27 21:47:58,773 - INFO -   LR: 0.001000
2025-08-27 21:47:58,794 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-27 21:47:58,980 - INFO - Epoch: [198][0/391] Time 0.185 (0.185) Data 0.160 (0.160) Loss 0.0326 (0.0326) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-27 21:47:59,401 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:47:59,402 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:00,907 - INFO - Epoch: [198][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.0421 (0.0552) Acc@1 98.438 (98.267) Acc@5 100.000 (99.985)
2025-08-27 21:48:02,471 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:48:02,472 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:02,829 - INFO - Epoch: [198][200/391] Time 0.027 (0.020) Data 0.010 (0.002) Loss 0.0379 (0.0560) Acc@1 99.219 (98.243) Acc@5 100.000 (99.988)
2025-08-27 21:48:04,670 - INFO - Epoch: [198][300/391] Time 0.041 (0.020) Data 0.013 (0.002) Loss 0.0562 (0.0548) Acc@1 96.875 (98.328) Acc@5 100.000 (99.987)
2025-08-27 21:48:05,458 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:48:05,458 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:06,443 - INFO - Test: [0/79] Time 0.115 (0.115) Loss 0.2248 (0.2248) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:48:07,286 - INFO - Epoch 198:
2025-08-27 21:48:07,286 - INFO -   Train: acc1: 98.3560 | acc5: 99.9900 | loss: 0.0539 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:48:07,286 - INFO -   Val:   acc1: 91.3800 | acc5: 99.8700 | loss: 0.2884
2025-08-27 21:48:07,286 - INFO -   LR: 0.001000
2025-08-27 21:48:07,306 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-27 21:48:07,458 - INFO - Epoch: [199][0/391] Time 0.151 (0.151) Data 0.134 (0.134) Loss 0.0500 (0.0500) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 21:48:09,458 - INFO - Epoch: [199][100/391] Time 0.027 (0.021) Data 0.000 (0.003) Loss 0.0817 (0.0535) Acc@1 98.438 (98.468) Acc@5 100.000 (100.000)
2025-08-27 21:48:09,657 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:48:09,657 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:11,418 - INFO - Epoch: [199][200/391] Time 0.025 (0.020) Data 0.012 (0.002) Loss 0.0396 (0.0544) Acc@1 99.219 (98.403) Acc@5 100.000 (99.996)
2025-08-27 21:48:12,770 - INFO - Pruning info: sparsity=0.500
2025-08-27 21:48:12,770 - INFO -   Reactivation rate: 0.0000
2025-08-27 21:48:13,354 - INFO - Epoch: [199][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0385 (0.0539) Acc@1 100.000 (98.432) Acc@5 100.000 (99.995)
2025-08-27 21:48:15,219 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2105 (0.2105) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 21:48:16,026 - INFO - Epoch 199:
2025-08-27 21:48:16,026 - INFO -   Train: acc1: 98.4060 | acc5: 99.9940 | loss: 0.0541 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-27 21:48:16,026 - INFO -   Val:   acc1: 91.3900 | acc5: 99.8200 | loss: 0.2853
2025-08-27 21:48:16,026 - INFO -   LR: 0.001000
2025-08-27 21:48:16,048 - INFO - training time: 00h 28m 36.76s
2025-08-27 21:48:16,048 - INFO - 
Training completed!
2025-08-27 21:48:16,048 - INFO - Best accuracy: 91.6600
2025-08-27 21:48:16,048 - INFO - Total training time: 0.48 hours
2025-08-27 21:48:16,048 - INFO - total_experiment time: 00h 28m 38.00s
2025-08-27 21:48:16,049 - INFO - Experiment completed successfully
2025-08-27 21:48:16,050 - INFO - Total time: 0.48 hours
