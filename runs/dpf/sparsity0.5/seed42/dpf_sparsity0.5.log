2025-08-28 01:36:22,647 - INFO - Starting experiment: dpf_sparsity0.5
2025-08-28 01:36:22,647 - INFO - Save directory: ./runs/dpf/sparsity0.5/seed42
2025-08-28 01:36:22,647 - INFO - Hyperparameters:
2025-08-28 01:36:22,647 - INFO -   name: dpf_sparsity0.5
2025-08-28 01:36:22,647 - INFO -   description: 
2025-08-28 01:36:22,647 - INFO -   save_dir: ./runs
2025-08-28 01:36:22,647 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 01:36:22,647 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 01:36:22,647 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 01:36:22,647 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.5, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 01:36:22,647 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 01:36:22,647 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 01:36:22,684 - INFO - System Information:
2025-08-28 01:36:22,685 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 01:36:22,685 - INFO -   python_version: 3.9.18
2025-08-28 01:36:22,685 - INFO -   pytorch_version: 2.1.0
2025-08-28 01:36:22,685 - INFO -   cuda_available: True
2025-08-28 01:36:22,685 - INFO -   cpu_count: 4
2025-08-28 01:36:22,685 - INFO -   memory_total_gb: 11.0
2025-08-28 01:36:22,685 - INFO -   timestamp: 1756312582.6846993
2025-08-28 01:36:22,685 - INFO -   cuda_version: 11.8
2025-08-28 01:36:22,685 - INFO -   gpu_count: 1
2025-08-28 01:36:22,685 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 01:36:22,713 - INFO - Starting experiment: dpf_sparsity0.5
2025-08-28 01:36:22,713 - INFO - Model: resnet-20
2025-08-28 01:36:22,713 - INFO - Dataset: cifar10
2025-08-28 01:36:22,713 - INFO - Pruning: dpf (50.00%)
2025-08-28 01:36:22,840 - INFO - Model Information:
2025-08-28 01:36:22,840 - INFO -   Type: pruned
2025-08-28 01:36:22,840 - INFO -   Total parameters: 544,948
2025-08-28 01:36:22,840 - INFO -   Trainable parameters: 274,692
2025-08-28 01:36:22,840 - INFO -   Sparsity: 50.00%
2025-08-28 01:36:23,884 - INFO - Starting training...
2025-08-28 01:36:23,884 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 01:36:24,556 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:36:24,556 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:36:25,067 - INFO - Epoch: [0][0/391] Time 1.182 (1.182) Data 0.517 (0.517) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 01:36:26,892 - INFO - Epoch: [0][100/391] Time 0.011 (0.030) Data 0.000 (0.007) Loss 1.6624 (1.9148) Acc@1 40.625 (26.153) Acc@5 91.406 (81.211)
2025-08-28 01:36:27,932 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:36:27,932 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:36:28,692 - INFO - Epoch: [0][200/391] Time 0.013 (0.024) Data 0.000 (0.004) Loss 1.4511 (1.7803) Acc@1 42.188 (31.880) Acc@5 93.750 (85.250)
2025-08-28 01:36:30,512 - INFO - Epoch: [0][300/391] Time 0.011 (0.022) Data 0.000 (0.004) Loss 1.4839 (1.6826) Acc@1 41.406 (36.358) Acc@5 89.844 (87.443)
2025-08-28 01:36:30,875 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:36:30,876 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:36:32,483 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 1.4382 (1.4382) Acc@1 50.781 (50.781) Acc@5 94.531 (94.531)
2025-08-28 01:36:33,396 - INFO - Epoch 0:
2025-08-28 01:36:33,396 - INFO -   Train: acc1: 39.5940 | acc5: 88.8100 | loss: 1.6090 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 01:36:33,396 - INFO -   Val:   acc1: 49.1700 | acc5: 93.9500 | loss: 1.4592
2025-08-28 01:36:33,396 - INFO -   LR: 0.100000
2025-08-28 01:36:33,509 - INFO - Checkpoint saved: epoch=0, metric=49.1700
2025-08-28 01:36:33,540 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 01:36:33,731 - INFO - Epoch: [1][0/391] Time 0.190 (0.190) Data 0.159 (0.159) Loss 1.3764 (1.3764) Acc@1 50.000 (50.000) Acc@5 92.969 (92.969)
2025-08-28 01:36:35,408 - INFO - Pruning info: sparsity=0.020
2025-08-28 01:36:35,408 - INFO -   Reactivation rate: 0.0068
2025-08-28 01:36:35,617 - INFO - Epoch: [1][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 1.1477 (1.2014) Acc@1 57.031 (56.095) Acc@5 94.531 (94.980)
2025-08-28 01:36:37,506 - INFO - Epoch: [1][200/391] Time 0.036 (0.020) Data 0.005 (0.004) Loss 0.9373 (1.1626) Acc@1 62.500 (57.778) Acc@5 96.094 (95.386)
2025-08-28 01:36:38,397 - INFO - Pruning info: sparsity=0.020
2025-08-28 01:36:38,397 - INFO -   Reactivation rate: 0.0046
2025-08-28 01:36:39,360 - INFO - Epoch: [1][300/391] Time 0.059 (0.019) Data 0.044 (0.004) Loss 0.9425 (1.1230) Acc@1 63.281 (59.409) Acc@5 96.875 (95.707)
2025-08-28 01:36:41,150 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 1.0367 (1.0367) Acc@1 66.406 (66.406) Acc@5 99.219 (99.219)
2025-08-28 01:36:41,972 - INFO - Epoch 1:
2025-08-28 01:36:41,972 - INFO -   Train: acc1: 60.6800 | acc5: 95.9880 | loss: 1.0919 | sparsity: 0.0197 | reactivation_rate: 0.0052
2025-08-28 01:36:41,972 - INFO -   Val:   acc1: 61.6500 | acc5: 96.7200 | loss: 1.0862
2025-08-28 01:36:41,972 - INFO -   LR: 0.100000
2025-08-28 01:36:42,015 - INFO - Checkpoint saved: epoch=1, metric=61.6500
2025-08-28 01:36:42,047 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 01:36:42,218 - INFO - Epoch: [2][0/391] Time 0.169 (0.169) Data 0.152 (0.152) Loss 0.9386 (0.9386) Acc@1 69.531 (69.531) Acc@5 97.656 (97.656)
2025-08-28 01:36:42,504 - INFO - Pruning info: sparsity=0.039
2025-08-28 01:36:42,504 - INFO -   Reactivation rate: 0.0116
2025-08-28 01:36:44,047 - INFO - Epoch: [2][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.9245 (0.9368) Acc@1 67.969 (67.195) Acc@5 96.875 (97.092)
2025-08-28 01:36:45,483 - INFO - Pruning info: sparsity=0.039
2025-08-28 01:36:45,483 - INFO -   Reactivation rate: 0.0056
2025-08-28 01:36:45,913 - INFO - Epoch: [2][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.8516 (0.9093) Acc@1 68.750 (68.167) Acc@5 100.000 (97.384)
2025-08-28 01:36:47,825 - INFO - Epoch: [2][300/391] Time 0.054 (0.019) Data 0.027 (0.004) Loss 0.8918 (0.8935) Acc@1 66.406 (68.779) Acc@5 100.000 (97.467)
2025-08-28 01:36:48,536 - INFO - Pruning info: sparsity=0.039
2025-08-28 01:36:48,536 - INFO -   Reactivation rate: 0.0043
2025-08-28 01:36:49,665 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.7950 (0.7950) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 01:36:50,517 - INFO - Epoch 2:
2025-08-28 01:36:50,517 - INFO -   Train: acc1: 69.3440 | acc5: 97.5600 | loss: 0.8770 | sparsity: 0.0389 | reactivation_rate: 0.0059
2025-08-28 01:36:50,517 - INFO -   Val:   acc1: 68.3200 | acc5: 97.6900 | loss: 0.8903
2025-08-28 01:36:50,517 - INFO -   LR: 0.100000
2025-08-28 01:36:50,561 - INFO - Checkpoint saved: epoch=2, metric=68.3200
2025-08-28 01:36:50,593 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 01:36:50,772 - INFO - Epoch: [3][0/391] Time 0.178 (0.178) Data 0.157 (0.157) Loss 0.7901 (0.7901) Acc@1 71.094 (71.094) Acc@5 97.656 (97.656)
2025-08-28 01:36:52,594 - INFO - Epoch: [3][100/391] Time 0.010 (0.020) Data 0.000 (0.005) Loss 0.7976 (0.7780) Acc@1 67.969 (72.765) Acc@5 99.219 (98.028)
2025-08-28 01:36:52,692 - INFO - Pruning info: sparsity=0.058
2025-08-28 01:36:52,692 - INFO -   Reactivation rate: 0.0074
2025-08-28 01:36:54,420 - INFO - Epoch: [3][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.7091 (0.7736) Acc@1 75.781 (73.165) Acc@5 97.656 (98.060)
2025-08-28 01:36:55,675 - INFO - Pruning info: sparsity=0.058
2025-08-28 01:36:55,675 - INFO -   Reactivation rate: 0.0048
2025-08-28 01:36:56,261 - INFO - Epoch: [3][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.7455 (0.7657) Acc@1 75.000 (73.508) Acc@5 96.875 (98.097)
2025-08-28 01:36:58,056 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.8201 (0.8201) Acc@1 66.406 (66.406) Acc@5 100.000 (100.000)
2025-08-28 01:36:58,890 - INFO - Epoch 3:
2025-08-28 01:36:58,891 - INFO -   Train: acc1: 73.6380 | acc5: 98.1260 | loss: 0.7644 | sparsity: 0.0576 | reactivation_rate: 0.0060
2025-08-28 01:36:58,891 - INFO -   Val:   acc1: 70.2200 | acc5: 97.9000 | loss: 0.8988
2025-08-28 01:36:58,891 - INFO -   LR: 0.100000
2025-08-28 01:36:58,934 - INFO - Checkpoint saved: epoch=3, metric=70.2200
2025-08-28 01:36:58,965 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 01:36:59,141 - INFO - Epoch: [4][0/391] Time 0.174 (0.174) Data 0.157 (0.157) Loss 0.6815 (0.6815) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 01:36:59,789 - INFO - Pruning info: sparsity=0.076
2025-08-28 01:36:59,789 - INFO -   Reactivation rate: 0.0100
2025-08-28 01:37:01,045 - INFO - Epoch: [4][100/391] Time 0.028 (0.021) Data 0.013 (0.004) Loss 0.5892 (0.7147) Acc@1 82.031 (75.495) Acc@5 98.438 (98.414)
2025-08-28 01:37:02,792 - INFO - Pruning info: sparsity=0.076
2025-08-28 01:37:02,793 - INFO -   Reactivation rate: 0.0055
2025-08-28 01:37:02,947 - INFO - Epoch: [4][200/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.6923 (0.7049) Acc@1 76.562 (75.696) Acc@5 98.438 (98.383)
2025-08-28 01:37:04,784 - INFO - Epoch: [4][300/391] Time 0.024 (0.019) Data 0.008 (0.003) Loss 0.7586 (0.7038) Acc@1 70.312 (75.711) Acc@5 98.438 (98.388)
2025-08-28 01:37:05,823 - INFO - Pruning info: sparsity=0.076
2025-08-28 01:37:05,823 - INFO -   Reactivation rate: 0.0041
2025-08-28 01:37:06,595 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.9962 (0.9962) Acc@1 67.969 (67.969) Acc@5 96.875 (96.875)
2025-08-28 01:37:07,472 - INFO - Epoch 4:
2025-08-28 01:37:07,472 - INFO -   Train: acc1: 75.8740 | acc5: 98.4240 | loss: 0.6991 | sparsity: 0.0758 | reactivation_rate: 0.0058
2025-08-28 01:37:07,472 - INFO -   Val:   acc1: 67.8600 | acc5: 97.5100 | loss: 0.9651
2025-08-28 01:37:07,472 - INFO -   LR: 0.100000
2025-08-28 01:37:07,481 - INFO - training time: 00h 00m 43.60s
2025-08-28 01:37:07,481 - INFO - 
Training completed!
2025-08-28 01:37:07,481 - INFO - Best accuracy: 70.2200
2025-08-28 01:37:07,481 - INFO - Total training time: 0.01 hours
2025-08-28 01:37:07,481 - INFO - total_experiment time: 00h 00m 44.84s
2025-08-28 01:37:07,482 - INFO - Experiment completed successfully
2025-08-28 01:37:07,482 - INFO - Total time: 0.01 hours
2025-08-28 04:40:27,967 - INFO - Starting experiment: dpf_sparsity0.5
2025-08-28 04:40:27,967 - INFO - Save directory: ./runs/dpf/sparsity0.5/seed42
2025-08-28 04:40:27,967 - INFO - Hyperparameters:
2025-08-28 04:40:27,967 - INFO -   name: dpf_sparsity0.5
2025-08-28 04:40:27,967 - INFO -   description: 
2025-08-28 04:40:27,967 - INFO -   save_dir: ./runs
2025-08-28 04:40:27,967 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 04:40:27,967 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 04:40:27,968 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 04:40:27,968 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.5, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 04:40:27,968 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 04:40:27,968 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 04:40:28,038 - INFO - System Information:
2025-08-28 04:40:28,039 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 04:40:28,039 - INFO -   python_version: 3.9.18
2025-08-28 04:40:28,039 - INFO -   pytorch_version: 2.1.0
2025-08-28 04:40:28,039 - INFO -   cuda_available: True
2025-08-28 04:40:28,039 - INFO -   cpu_count: 4
2025-08-28 04:40:28,039 - INFO -   memory_total_gb: 11.0
2025-08-28 04:40:28,039 - INFO -   timestamp: 1756323628.0387409
2025-08-28 04:40:28,039 - INFO -   cuda_version: 11.8
2025-08-28 04:40:28,039 - INFO -   gpu_count: 1
2025-08-28 04:40:28,039 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 04:40:28,046 - INFO - Starting experiment: dpf_sparsity0.5
2025-08-28 04:40:28,046 - INFO - Model: resnet-20
2025-08-28 04:40:28,046 - INFO - Dataset: cifar10
2025-08-28 04:40:28,046 - INFO - Pruning: dpf (50.00%)
2025-08-28 04:40:28,182 - INFO - Model Information:
2025-08-28 04:40:28,182 - INFO -   Type: pruned
2025-08-28 04:40:28,182 - INFO -   Total parameters: 544,948
2025-08-28 04:40:28,182 - INFO -   Trainable parameters: 274,692
2025-08-28 04:40:28,182 - INFO -   Sparsity: 50.00%
2025-08-28 04:40:29,297 - INFO - Starting training...
2025-08-28 04:40:29,297 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 04:40:30,000 - INFO - Pruning info: sparsity=0.000
2025-08-28 04:40:30,000 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:40:30,513 - INFO - Epoch: [0][0/391] Time 1.216 (1.216) Data 0.553 (0.553) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 04:40:32,455 - INFO - Epoch: [0][100/391] Time 0.021 (0.031) Data 0.000 (0.007) Loss 1.7157 (1.9181) Acc@1 32.812 (26.191) Acc@5 85.938 (81.621)
2025-08-28 04:40:33,566 - INFO - Pruning info: sparsity=0.000
2025-08-28 04:40:33,566 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:40:34,355 - INFO - Epoch: [0][200/391] Time 0.013 (0.025) Data 0.001 (0.005) Loss 1.4727 (1.7835) Acc@1 49.219 (31.748) Acc@5 91.406 (85.510)
2025-08-28 04:40:36,192 - INFO - Epoch: [0][300/391] Time 0.011 (0.023) Data 0.000 (0.004) Loss 1.3876 (1.6764) Acc@1 50.781 (36.480) Acc@5 93.750 (87.811)
2025-08-28 04:40:36,542 - INFO - Pruning info: sparsity=0.000
2025-08-28 04:40:36,542 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:40:38,185 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 1.6975 (1.6975) Acc@1 42.969 (42.969) Acc@5 92.188 (92.188)
2025-08-28 04:40:39,092 - INFO - Epoch 0:
2025-08-28 04:40:39,092 - INFO -   Train: acc1: 39.8920 | acc5: 89.2480 | loss: 1.5989 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 04:40:39,092 - INFO -   Val:   acc1: 43.0500 | acc5: 90.9800 | loss: 1.6688
2025-08-28 04:40:39,092 - INFO -   LR: 0.100000
2025-08-28 04:40:39,170 - INFO - Checkpoint saved: epoch=0, metric=43.0500
2025-08-28 04:40:39,201 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 04:40:39,404 - INFO - Epoch: [1][0/391] Time 0.202 (0.202) Data 0.173 (0.173) Loss 1.3115 (1.3115) Acc@1 49.219 (49.219) Acc@5 97.656 (97.656)
2025-08-28 04:40:41,199 - INFO - Pruning info: sparsity=0.020
2025-08-28 04:40:41,199 - INFO -   Reactivation rate: 0.0070
2025-08-28 04:40:41,427 - INFO - Epoch: [1][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 1.0964 (1.2046) Acc@1 60.156 (55.964) Acc@5 95.312 (95.135)
2025-08-28 04:40:43,398 - INFO - Epoch: [1][200/391] Time 0.018 (0.021) Data 0.002 (0.002) Loss 0.9396 (1.1589) Acc@1 65.625 (58.096) Acc@5 98.438 (95.573)
2025-08-28 04:40:44,366 - INFO - Pruning info: sparsity=0.020
2025-08-28 04:40:44,367 - INFO -   Reactivation rate: 0.0046
2025-08-28 04:40:45,372 - INFO - Epoch: [1][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.9662 (1.1211) Acc@1 69.531 (59.596) Acc@5 97.656 (95.884)
2025-08-28 04:40:47,166 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 1.0937 (1.0937) Acc@1 61.719 (61.719) Acc@5 98.438 (98.438)
2025-08-28 04:40:47,996 - INFO - Epoch 1:
2025-08-28 04:40:47,997 - INFO -   Train: acc1: 60.7700 | acc5: 96.1520 | loss: 1.0920 | sparsity: 0.0197 | reactivation_rate: 0.0054
2025-08-28 04:40:47,997 - INFO -   Val:   acc1: 54.4800 | acc5: 96.2500 | loss: 1.2707
2025-08-28 04:40:47,997 - INFO -   LR: 0.100000
2025-08-28 04:40:48,041 - INFO - Checkpoint saved: epoch=1, metric=54.4800
2025-08-28 04:40:48,073 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 04:40:48,273 - INFO - Epoch: [2][0/391] Time 0.199 (0.199) Data 0.173 (0.173) Loss 0.9402 (0.9402) Acc@1 64.062 (64.062) Acc@5 96.875 (96.875)
2025-08-28 04:40:48,620 - INFO - Pruning info: sparsity=0.039
2025-08-28 04:40:48,620 - INFO -   Reactivation rate: 0.0115
2025-08-28 04:40:50,172 - INFO - Epoch: [2][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.8648 (0.9475) Acc@1 70.312 (66.700) Acc@5 96.094 (97.084)
2025-08-28 04:40:51,664 - INFO - Pruning info: sparsity=0.039
2025-08-28 04:40:51,664 - INFO -   Reactivation rate: 0.0058
2025-08-28 04:40:52,087 - INFO - Epoch: [2][200/391] Time 0.033 (0.020) Data 0.001 (0.002) Loss 0.8440 (0.9110) Acc@1 68.750 (67.771) Acc@5 97.656 (97.450)
2025-08-28 04:40:54,038 - INFO - Epoch: [2][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.7827 (0.8940) Acc@1 73.438 (68.428) Acc@5 100.000 (97.449)
2025-08-28 04:40:54,772 - INFO - Pruning info: sparsity=0.039
2025-08-28 04:40:54,772 - INFO -   Reactivation rate: 0.0044
2025-08-28 04:40:55,891 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 1.0068 (1.0068) Acc@1 63.281 (63.281) Acc@5 100.000 (100.000)
2025-08-28 04:40:56,727 - INFO - Epoch 2:
2025-08-28 04:40:56,727 - INFO -   Train: acc1: 69.1200 | acc5: 97.5320 | loss: 0.8780 | sparsity: 0.0389 | reactivation_rate: 0.0059
2025-08-28 04:40:56,727 - INFO -   Val:   acc1: 63.1900 | acc5: 97.2000 | loss: 1.1654
2025-08-28 04:40:56,727 - INFO -   LR: 0.100000
2025-08-28 04:40:56,772 - INFO - Checkpoint saved: epoch=2, metric=63.1900
2025-08-28 04:40:56,805 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 04:40:56,978 - INFO - Epoch: [3][0/391] Time 0.172 (0.172) Data 0.143 (0.143) Loss 0.8096 (0.8096) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-28 04:40:58,936 - INFO - Epoch: [3][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.8263 (0.7708) Acc@1 72.656 (73.345) Acc@5 98.438 (98.082)
2025-08-28 04:40:59,038 - INFO - Pruning info: sparsity=0.058
2025-08-28 04:40:59,039 - INFO -   Reactivation rate: 0.0072
2025-08-28 04:41:00,840 - INFO - Epoch: [3][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.6919 (0.7602) Acc@1 76.562 (73.815) Acc@5 98.438 (98.197)
2025-08-28 04:41:02,095 - INFO - Pruning info: sparsity=0.058
2025-08-28 04:41:02,096 - INFO -   Reactivation rate: 0.0050
2025-08-28 04:41:02,807 - INFO - Epoch: [3][300/391] Time 0.022 (0.020) Data 0.004 (0.002) Loss 0.8225 (0.7562) Acc@1 71.875 (73.949) Acc@5 98.438 (98.165)
2025-08-28 04:41:04,710 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.8616 (0.8616) Acc@1 71.875 (71.875) Acc@5 100.000 (100.000)
2025-08-28 04:41:05,612 - INFO - Epoch 3:
2025-08-28 04:41:05,612 - INFO -   Train: acc1: 73.8880 | acc5: 98.1840 | loss: 0.7556 | sparsity: 0.0576 | reactivation_rate: 0.0061
2025-08-28 04:41:05,612 - INFO -   Val:   acc1: 69.6500 | acc5: 97.7400 | loss: 0.9149
2025-08-28 04:41:05,612 - INFO -   LR: 0.100000
2025-08-28 04:41:05,657 - INFO - Checkpoint saved: epoch=3, metric=69.6500
2025-08-28 04:41:05,691 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 04:41:05,874 - INFO - Epoch: [4][0/391] Time 0.182 (0.182) Data 0.149 (0.149) Loss 0.7395 (0.7395) Acc@1 71.094 (71.094) Acc@5 99.219 (99.219)
2025-08-28 04:41:06,599 - INFO - Pruning info: sparsity=0.076
2025-08-28 04:41:06,599 - INFO -   Reactivation rate: 0.0102
2025-08-28 04:41:07,817 - INFO - Epoch: [4][100/391] Time 0.026 (0.021) Data 0.010 (0.003) Loss 0.7128 (0.7032) Acc@1 78.906 (75.820) Acc@5 97.656 (98.383)
2025-08-28 04:41:09,562 - INFO - Pruning info: sparsity=0.076
2025-08-28 04:41:09,563 - INFO -   Reactivation rate: 0.0055
2025-08-28 04:41:09,648 - INFO - Epoch: [4][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.6907 (0.6972) Acc@1 75.781 (76.178) Acc@5 99.219 (98.391)
2025-08-28 04:41:11,632 - INFO - Epoch: [4][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.7178 (0.6926) Acc@1 72.656 (76.269) Acc@5 98.438 (98.406)
2025-08-28 04:41:12,672 - INFO - Pruning info: sparsity=0.076
2025-08-28 04:41:12,672 - INFO -   Reactivation rate: 0.0043
2025-08-28 04:41:13,458 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 1.5174 (1.5174) Acc@1 58.594 (58.594) Acc@5 92.188 (92.188)
2025-08-28 04:41:14,296 - INFO - Epoch 4:
2025-08-28 04:41:14,296 - INFO -   Train: acc1: 76.3520 | acc5: 98.4500 | loss: 0.6897 | sparsity: 0.0758 | reactivation_rate: 0.0060
2025-08-28 04:41:14,296 - INFO -   Val:   acc1: 59.4100 | acc5: 94.4500 | loss: 1.4917
2025-08-28 04:41:14,296 - INFO -   LR: 0.100000
2025-08-28 04:41:14,305 - INFO - 
Epoch: 5, lr = 0.1
2025-08-28 04:41:14,505 - INFO - Epoch: [5][0/391] Time 0.199 (0.199) Data 0.171 (0.171) Loss 0.7032 (0.7032) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-28 04:41:16,480 - INFO - Epoch: [5][100/391] Time 0.022 (0.022) Data 0.000 (0.005) Loss 0.6040 (0.6710) Acc@1 76.562 (76.965) Acc@5 100.000 (98.670)
2025-08-28 04:41:16,893 - INFO - Pruning info: sparsity=0.093
2025-08-28 04:41:16,893 - INFO -   Reactivation rate: 0.0070
2025-08-28 04:41:18,381 - INFO - Epoch: [5][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.6502 (0.6628) Acc@1 76.562 (77.208) Acc@5 99.219 (98.585)
2025-08-28 04:41:20,038 - INFO - Pruning info: sparsity=0.093
2025-08-28 04:41:20,038 - INFO -   Reactivation rate: 0.0047
2025-08-28 04:41:20,275 - INFO - Epoch: [5][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.7061 (0.6613) Acc@1 74.219 (77.154) Acc@5 97.656 (98.570)
2025-08-28 04:41:22,171 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.6787 (0.6787) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 04:41:23,043 - INFO - Epoch 5:
2025-08-28 04:41:23,043 - INFO -   Train: acc1: 77.2680 | acc5: 98.6180 | loss: 0.6575 | sparsity: 0.0935 | reactivation_rate: 0.0061
2025-08-28 04:41:23,043 - INFO -   Val:   acc1: 71.2000 | acc5: 97.3300 | loss: 0.8452
2025-08-28 04:41:23,043 - INFO -   LR: 0.100000
2025-08-28 04:41:23,086 - INFO - Checkpoint saved: epoch=5, metric=71.2000
2025-08-28 04:41:23,118 - INFO - 
Epoch: 6, lr = 0.1
2025-08-28 04:41:23,311 - INFO - Epoch: [6][0/391] Time 0.192 (0.192) Data 0.164 (0.164) Loss 0.4800 (0.4800) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:41:24,413 - INFO - Pruning info: sparsity=0.111
2025-08-28 04:41:24,413 - INFO -   Reactivation rate: 0.0092
2025-08-28 04:41:25,316 - INFO - Epoch: [6][100/391] Time 0.023 (0.022) Data 0.001 (0.003) Loss 0.5867 (0.6136) Acc@1 78.906 (78.605) Acc@5 98.438 (98.832)
2025-08-28 04:41:27,207 - INFO - Epoch: [6][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.5926 (0.6173) Acc@1 83.594 (78.448) Acc@5 98.438 (98.760)
2025-08-28 04:41:27,443 - INFO - Pruning info: sparsity=0.111
2025-08-28 04:41:27,443 - INFO -   Reactivation rate: 0.0052
2025-08-28 04:41:29,182 - INFO - Epoch: [6][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.6659 (0.6237) Acc@1 75.781 (78.312) Acc@5 98.438 (98.772)
2025-08-28 04:41:30,610 - INFO - Pruning info: sparsity=0.111
2025-08-28 04:41:30,611 - INFO -   Reactivation rate: 0.0041
2025-08-28 04:41:31,054 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.9630 (0.9630) Acc@1 70.312 (70.312) Acc@5 92.969 (92.969)
2025-08-28 04:41:31,907 - INFO - Epoch 6:
2025-08-28 04:41:31,907 - INFO -   Train: acc1: 78.3740 | acc5: 98.7820 | loss: 0.6247 | sparsity: 0.1107 | reactivation_rate: 0.0059
2025-08-28 04:41:31,907 - INFO -   Val:   acc1: 68.8400 | acc5: 95.0900 | loss: 1.0075
2025-08-28 04:41:31,908 - INFO -   LR: 0.100000
2025-08-28 04:41:31,916 - INFO - 
Epoch: 7, lr = 0.1
2025-08-28 04:41:32,105 - INFO - Epoch: [7][0/391] Time 0.188 (0.188) Data 0.163 (0.163) Loss 0.7286 (0.7286) Acc@1 78.125 (78.125) Acc@5 96.875 (96.875)
2025-08-28 04:41:33,968 - INFO - Epoch: [7][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.7074 (0.6046) Acc@1 74.219 (79.370) Acc@5 98.438 (98.824)
2025-08-28 04:41:34,798 - INFO - Pruning info: sparsity=0.127
2025-08-28 04:41:34,799 - INFO -   Reactivation rate: 0.0062
2025-08-28 04:41:35,870 - INFO - Epoch: [7][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.5404 (0.6007) Acc@1 82.812 (79.466) Acc@5 98.438 (98.815)
2025-08-28 04:41:37,853 - INFO - Epoch: [7][300/391] Time 0.022 (0.020) Data 0.003 (0.002) Loss 0.4470 (0.6005) Acc@1 82.031 (79.322) Acc@5 98.438 (98.790)
2025-08-28 04:41:37,893 - INFO - Pruning info: sparsity=0.127
2025-08-28 04:41:37,893 - INFO -   Reactivation rate: 0.0045
2025-08-28 04:41:39,632 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7439 (0.7439) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-28 04:41:40,492 - INFO - Epoch 7:
2025-08-28 04:41:40,492 - INFO -   Train: acc1: 79.1880 | acc5: 98.8280 | loss: 0.6013 | sparsity: 0.1273 | reactivation_rate: 0.0058
2025-08-28 04:41:40,492 - INFO -   Val:   acc1: 70.4000 | acc5: 96.0100 | loss: 0.9724
2025-08-28 04:41:40,492 - INFO -   LR: 0.100000
2025-08-28 04:41:40,501 - INFO - 
Epoch: 8, lr = 0.1
2025-08-28 04:41:40,678 - INFO - Epoch: [8][0/391] Time 0.176 (0.176) Data 0.151 (0.151) Loss 0.5346 (0.5346) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 04:41:42,075 - INFO - Pruning info: sparsity=0.144
2025-08-28 04:41:42,075 - INFO -   Reactivation rate: 0.0080
2025-08-28 04:41:42,621 - INFO - Epoch: [8][100/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.5190 (0.5854) Acc@1 80.469 (79.734) Acc@5 100.000 (98.770)
2025-08-28 04:41:44,568 - INFO - Epoch: [8][200/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.4777 (0.5789) Acc@1 85.156 (80.181) Acc@5 99.219 (98.861)
2025-08-28 04:41:45,134 - INFO - Pruning info: sparsity=0.144
2025-08-28 04:41:45,134 - INFO -   Reactivation rate: 0.0049
2025-08-28 04:41:46,440 - INFO - Epoch: [8][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.6718 (0.5848) Acc@1 78.125 (79.885) Acc@5 99.219 (98.881)
2025-08-28 04:41:48,280 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.9743 (0.9743) Acc@1 63.281 (63.281) Acc@5 98.438 (98.438)
2025-08-28 04:41:49,148 - INFO - Epoch 8:
2025-08-28 04:41:49,148 - INFO -   Train: acc1: 79.9560 | acc5: 98.9200 | loss: 0.5813 | sparsity: 0.1435 | reactivation_rate: 0.0057
2025-08-28 04:41:49,148 - INFO -   Val:   acc1: 65.2000 | acc5: 97.5200 | loss: 1.0891
2025-08-28 04:41:49,148 - INFO -   LR: 0.100000
2025-08-28 04:41:49,158 - INFO - 
Epoch: 9, lr = 0.1
2025-08-28 04:41:49,347 - INFO - Epoch: [9][0/391] Time 0.188 (0.188) Data 0.151 (0.151) Loss 0.5211 (0.5211) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:41:49,361 - INFO - Pruning info: sparsity=0.159
2025-08-28 04:41:49,361 - INFO -   Reactivation rate: 0.0019
2025-08-28 04:41:51,267 - INFO - Epoch: [9][100/391] Time 0.018 (0.021) Data 0.002 (0.003) Loss 0.5023 (0.5577) Acc@1 80.469 (80.941) Acc@5 98.438 (98.971)
2025-08-28 04:41:52,407 - INFO - Pruning info: sparsity=0.159
2025-08-28 04:41:52,407 - INFO -   Reactivation rate: 0.0058
2025-08-28 04:41:53,123 - INFO - Epoch: [9][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.5048 (0.5572) Acc@1 83.594 (80.826) Acc@5 99.219 (99.001)
2025-08-28 04:41:55,045 - INFO - Epoch: [9][300/391] Time 0.026 (0.020) Data 0.003 (0.002) Loss 0.7137 (0.5606) Acc@1 77.344 (80.772) Acc@5 96.094 (98.996)
2025-08-28 04:41:55,389 - INFO - Pruning info: sparsity=0.159
2025-08-28 04:41:55,389 - INFO -   Reactivation rate: 0.0043
2025-08-28 04:41:56,781 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 1.2091 (1.2091) Acc@1 64.062 (64.062) Acc@5 96.875 (96.875)
2025-08-28 04:41:57,628 - INFO - Epoch 9:
2025-08-28 04:41:57,628 - INFO -   Train: acc1: 80.8900 | acc5: 98.9940 | loss: 0.5595 | sparsity: 0.1593 | reactivation_rate: 0.0056
2025-08-28 04:41:57,628 - INFO -   Val:   acc1: 65.2500 | acc5: 96.0000 | loss: 1.2389
2025-08-28 04:41:57,628 - INFO -   LR: 0.100000
2025-08-28 04:41:57,637 - INFO - 
Epoch: 10, lr = 0.1
2025-08-28 04:41:57,826 - INFO - Epoch: [10][0/391] Time 0.188 (0.188) Data 0.157 (0.157) Loss 0.5378 (0.5378) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 04:41:59,478 - INFO - Pruning info: sparsity=0.175
2025-08-28 04:41:59,479 - INFO -   Reactivation rate: 0.0071
2025-08-28 04:41:59,682 - INFO - Epoch: [10][100/391] Time 0.026 (0.020) Data 0.015 (0.003) Loss 0.4061 (0.5365) Acc@1 86.719 (81.165) Acc@5 100.000 (98.956)
2025-08-28 04:42:01,583 - INFO - Epoch: [10][200/391] Time 0.025 (0.020) Data 0.013 (0.002) Loss 0.4834 (0.5383) Acc@1 85.156 (81.258) Acc@5 99.219 (99.024)
2025-08-28 04:42:02,576 - INFO - Pruning info: sparsity=0.175
2025-08-28 04:42:02,576 - INFO -   Reactivation rate: 0.0048
2025-08-28 04:42:03,516 - INFO - Epoch: [10][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.8152 (0.5470) Acc@1 75.781 (81.081) Acc@5 99.219 (98.990)
2025-08-28 04:42:05,316 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.9084 (0.9084) Acc@1 73.438 (73.438) Acc@5 98.438 (98.438)
2025-08-28 04:42:06,181 - INFO - Epoch 10:
2025-08-28 04:42:06,181 - INFO -   Train: acc1: 81.0880 | acc5: 98.9620 | loss: 0.5486 | sparsity: 0.1745 | reactivation_rate: 0.0055
2025-08-28 04:42:06,181 - INFO -   Val:   acc1: 72.0400 | acc5: 98.1200 | loss: 0.8668
2025-08-28 04:42:06,181 - INFO -   LR: 0.100000
2025-08-28 04:42:06,226 - INFO - Checkpoint saved: epoch=10, metric=72.0400
2025-08-28 04:42:06,260 - INFO - 
Epoch: 11, lr = 0.1
2025-08-28 04:42:06,440 - INFO - Epoch: [11][0/391] Time 0.180 (0.180) Data 0.141 (0.141) Loss 0.6546 (0.6546) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 04:42:06,785 - INFO - Pruning info: sparsity=0.189
2025-08-28 04:42:06,785 - INFO -   Reactivation rate: 0.0108
2025-08-28 04:42:08,385 - INFO - Epoch: [11][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.6013 (0.5489) Acc@1 82.031 (80.809) Acc@5 98.438 (99.087)
2025-08-28 04:42:09,849 - INFO - Pruning info: sparsity=0.189
2025-08-28 04:42:09,849 - INFO -   Reactivation rate: 0.0052
2025-08-28 04:42:10,282 - INFO - Epoch: [11][200/391] Time 0.027 (0.020) Data 0.014 (0.002) Loss 0.5990 (0.5445) Acc@1 76.562 (81.168) Acc@5 99.219 (99.075)
2025-08-28 04:42:12,091 - INFO - Epoch: [11][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.6428 (0.5444) Acc@1 78.125 (81.266) Acc@5 97.656 (99.068)
2025-08-28 04:42:12,881 - INFO - Pruning info: sparsity=0.189
2025-08-28 04:42:12,881 - INFO -   Reactivation rate: 0.0035
2025-08-28 04:42:13,951 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.6792 (0.6792) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 04:42:14,823 - INFO - Epoch 11:
2025-08-28 04:42:14,823 - INFO -   Train: acc1: 81.2000 | acc5: 99.0460 | loss: 0.5448 | sparsity: 0.1893 | reactivation_rate: 0.0053
2025-08-28 04:42:14,823 - INFO -   Val:   acc1: 76.2000 | acc5: 98.3200 | loss: 0.7186
2025-08-28 04:42:14,823 - INFO -   LR: 0.100000
2025-08-28 04:42:14,868 - INFO - Checkpoint saved: epoch=11, metric=76.2000
2025-08-28 04:42:14,901 - INFO - 
Epoch: 12, lr = 0.1
2025-08-28 04:42:15,096 - INFO - Epoch: [12][0/391] Time 0.194 (0.194) Data 0.168 (0.168) Loss 0.4743 (0.4743) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 04:42:17,060 - INFO - Epoch: [12][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.5404 (0.5428) Acc@1 80.469 (81.397) Acc@5 100.000 (99.064)
2025-08-28 04:42:17,208 - INFO - Pruning info: sparsity=0.204
2025-08-28 04:42:17,209 - INFO -   Reactivation rate: 0.0063
2025-08-28 04:42:18,903 - INFO - Epoch: [12][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.6972 (0.5268) Acc@1 74.219 (81.954) Acc@5 99.219 (99.021)
2025-08-28 04:42:20,153 - INFO - Pruning info: sparsity=0.204
2025-08-28 04:42:20,153 - INFO -   Reactivation rate: 0.0041
2025-08-28 04:42:20,784 - INFO - Epoch: [12][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4824 (0.5319) Acc@1 83.594 (81.645) Acc@5 99.219 (99.021)
2025-08-28 04:42:22,631 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5454 (0.5454) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 04:42:23,622 - INFO - Epoch 12:
2025-08-28 04:42:23,622 - INFO -   Train: acc1: 81.6700 | acc5: 99.0280 | loss: 0.5326 | sparsity: 0.2036 | reactivation_rate: 0.0052
2025-08-28 04:42:23,622 - INFO -   Val:   acc1: 79.3300 | acc5: 98.7700 | loss: 0.6136
2025-08-28 04:42:23,622 - INFO -   LR: 0.100000
2025-08-28 04:42:26,202 - INFO - Checkpoint saved: epoch=12, metric=79.3300
2025-08-28 04:42:26,233 - INFO - 
Epoch: 13, lr = 0.1
2025-08-28 04:42:26,428 - INFO - Epoch: [13][0/391] Time 0.194 (0.194) Data 0.167 (0.167) Loss 0.5020 (0.5020) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:42:27,131 - INFO - Pruning info: sparsity=0.218
2025-08-28 04:42:27,131 - INFO -   Reactivation rate: 0.0086
2025-08-28 04:42:28,292 - INFO - Epoch: [13][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4307 (0.5064) Acc@1 85.938 (82.449) Acc@5 99.219 (99.141)
2025-08-28 04:42:30,140 - INFO - Pruning info: sparsity=0.218
2025-08-28 04:42:30,141 - INFO -   Reactivation rate: 0.0048
2025-08-28 04:42:30,208 - INFO - Epoch: [13][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3833 (0.5181) Acc@1 86.719 (81.950) Acc@5 100.000 (99.102)
2025-08-28 04:42:32,138 - INFO - Epoch: [13][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.5676 (0.5207) Acc@1 83.594 (81.907) Acc@5 100.000 (99.151)
2025-08-28 04:42:33,204 - INFO - Pruning info: sparsity=0.218
2025-08-28 04:42:33,204 - INFO -   Reactivation rate: 0.0034
2025-08-28 04:42:34,027 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.7532 (0.7532) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 04:42:34,921 - INFO - Epoch 13:
2025-08-28 04:42:34,921 - INFO -   Train: acc1: 81.8820 | acc5: 99.1140 | loss: 0.5243 | sparsity: 0.2175 | reactivation_rate: 0.0049
2025-08-28 04:42:34,921 - INFO -   Val:   acc1: 74.1200 | acc5: 98.5200 | loss: 0.8333
2025-08-28 04:42:34,921 - INFO -   LR: 0.100000
2025-08-28 04:42:34,932 - INFO - 
Epoch: 14, lr = 0.1
2025-08-28 04:42:35,111 - INFO - Epoch: [14][0/391] Time 0.179 (0.179) Data 0.159 (0.159) Loss 0.4415 (0.4415) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:42:37,180 - INFO - Epoch: [14][100/391] Time 0.022 (0.022) Data 0.001 (0.003) Loss 0.5544 (0.5053) Acc@1 79.688 (82.689) Acc@5 99.219 (99.103)
2025-08-28 04:42:37,696 - INFO - Pruning info: sparsity=0.231
2025-08-28 04:42:37,696 - INFO -   Reactivation rate: 0.0059
2025-08-28 04:42:39,142 - INFO - Epoch: [14][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.5393 (0.5128) Acc@1 75.781 (82.404) Acc@5 99.219 (99.063)
2025-08-28 04:42:40,830 - INFO - Pruning info: sparsity=0.231
2025-08-28 04:42:40,830 - INFO -   Reactivation rate: 0.0039
2025-08-28 04:42:41,118 - INFO - Epoch: [14][300/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.3733 (0.5157) Acc@1 87.500 (82.166) Acc@5 100.000 (99.073)
2025-08-28 04:42:42,953 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.6506 (0.6506) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 04:42:43,837 - INFO - Epoch 14:
2025-08-28 04:42:43,837 - INFO -   Train: acc1: 82.2600 | acc5: 99.0740 | loss: 0.5150 | sparsity: 0.2310 | reactivation_rate: 0.0049
2025-08-28 04:42:43,837 - INFO -   Val:   acc1: 76.8100 | acc5: 98.6200 | loss: 0.7032
2025-08-28 04:42:43,837 - INFO -   LR: 0.100000
2025-08-28 04:42:43,848 - INFO - 
Epoch: 15, lr = 0.1
2025-08-28 04:42:44,033 - INFO - Epoch: [15][0/391] Time 0.185 (0.185) Data 0.157 (0.157) Loss 0.5004 (0.5004) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 04:42:45,122 - INFO - Pruning info: sparsity=0.244
2025-08-28 04:42:45,123 - INFO -   Reactivation rate: 0.0073
2025-08-28 04:42:46,019 - INFO - Epoch: [15][100/391] Time 0.019 (0.021) Data 0.002 (0.003) Loss 0.4099 (0.4899) Acc@1 85.938 (83.091) Acc@5 100.000 (99.234)
2025-08-28 04:42:47,980 - INFO - Epoch: [15][200/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.5939 (0.5089) Acc@1 79.688 (82.564) Acc@5 99.219 (99.145)
2025-08-28 04:42:48,274 - INFO - Pruning info: sparsity=0.244
2025-08-28 04:42:48,274 - INFO -   Reactivation rate: 0.0043
2025-08-28 04:42:49,900 - INFO - Epoch: [15][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4805 (0.5108) Acc@1 84.375 (82.457) Acc@5 98.438 (99.164)
2025-08-28 04:42:51,351 - INFO - Pruning info: sparsity=0.244
2025-08-28 04:42:51,351 - INFO -   Reactivation rate: 0.0034
2025-08-28 04:42:51,762 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7404 (0.7404) Acc@1 73.438 (73.438) Acc@5 100.000 (100.000)
2025-08-28 04:42:52,666 - INFO - Epoch 15:
2025-08-28 04:42:52,666 - INFO -   Train: acc1: 82.4600 | acc5: 99.1740 | loss: 0.5127 | sparsity: 0.2440 | reactivation_rate: 0.0048
2025-08-28 04:42:52,666 - INFO -   Val:   acc1: 77.2500 | acc5: 98.6900 | loss: 0.7205
2025-08-28 04:42:52,666 - INFO -   LR: 0.100000
2025-08-28 04:42:52,677 - INFO - 
Epoch: 16, lr = 0.1
2025-08-28 04:42:52,874 - INFO - Epoch: [16][0/391] Time 0.196 (0.196) Data 0.156 (0.156) Loss 0.5540 (0.5540) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 04:42:54,908 - INFO - Epoch: [16][100/391] Time 0.024 (0.022) Data 0.006 (0.003) Loss 0.5090 (0.4963) Acc@1 83.594 (82.967) Acc@5 99.219 (99.203)
2025-08-28 04:42:55,773 - INFO - Pruning info: sparsity=0.257
2025-08-28 04:42:55,773 - INFO -   Reactivation rate: 0.0048
2025-08-28 04:42:56,873 - INFO - Epoch: [16][200/391] Time 0.027 (0.021) Data 0.000 (0.002) Loss 0.5630 (0.4949) Acc@1 82.031 (83.007) Acc@5 100.000 (99.215)
2025-08-28 04:42:58,747 - INFO - Epoch: [16][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.5716 (0.5001) Acc@1 77.344 (82.771) Acc@5 99.219 (99.180)
2025-08-28 04:42:58,812 - INFO - Pruning info: sparsity=0.257
2025-08-28 04:42:58,812 - INFO -   Reactivation rate: 0.0036
2025-08-28 04:43:00,592 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.5372 (0.5372) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 04:43:01,447 - INFO - Epoch 16:
2025-08-28 04:43:01,447 - INFO -   Train: acc1: 82.7900 | acc5: 99.1600 | loss: 0.5004 | sparsity: 0.2566 | reactivation_rate: 0.0046
2025-08-28 04:43:01,447 - INFO -   Val:   acc1: 79.5300 | acc5: 98.8500 | loss: 0.6227
2025-08-28 04:43:01,447 - INFO -   LR: 0.100000
2025-08-28 04:43:01,491 - INFO - Checkpoint saved: epoch=16, metric=79.5300
2025-08-28 04:43:01,524 - INFO - 
Epoch: 17, lr = 0.1
2025-08-28 04:43:01,716 - INFO - Epoch: [17][0/391] Time 0.191 (0.191) Data 0.170 (0.170) Loss 0.4318 (0.4318) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 04:43:03,056 - INFO - Pruning info: sparsity=0.269
2025-08-28 04:43:03,056 - INFO -   Reactivation rate: 0.0066
2025-08-28 04:43:03,582 - INFO - Epoch: [17][100/391] Time 0.018 (0.020) Data 0.004 (0.005) Loss 0.3950 (0.4847) Acc@1 85.156 (83.447) Acc@5 99.219 (99.196)
2025-08-28 04:43:05,475 - INFO - Epoch: [17][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.5371 (0.4962) Acc@1 82.812 (83.038) Acc@5 100.000 (99.172)
2025-08-28 04:43:06,029 - INFO - Pruning info: sparsity=0.269
2025-08-28 04:43:06,029 - INFO -   Reactivation rate: 0.0039
2025-08-28 04:43:07,301 - INFO - Epoch: [17][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4799 (0.5060) Acc@1 82.812 (82.636) Acc@5 100.000 (99.118)
2025-08-28 04:43:09,162 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.7590 (0.7590) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 04:43:10,049 - INFO - Epoch 17:
2025-08-28 04:43:10,049 - INFO -   Train: acc1: 82.7380 | acc5: 99.1220 | loss: 0.5036 | sparsity: 0.2688 | reactivation_rate: 0.0046
2025-08-28 04:43:10,049 - INFO -   Val:   acc1: 72.2100 | acc5: 98.0300 | loss: 0.8771
2025-08-28 04:43:10,049 - INFO -   LR: 0.100000
2025-08-28 04:43:10,058 - INFO - 
Epoch: 18, lr = 0.1
2025-08-28 04:43:10,237 - INFO - Epoch: [18][0/391] Time 0.178 (0.178) Data 0.156 (0.156) Loss 0.4105 (0.4105) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 04:43:10,269 - INFO - Pruning info: sparsity=0.281
2025-08-28 04:43:10,269 - INFO -   Reactivation rate: 0.0018
2025-08-28 04:43:12,228 - INFO - Epoch: [18][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.4437 (0.4815) Acc@1 84.375 (83.447) Acc@5 99.219 (99.196)
2025-08-28 04:43:13,397 - INFO - Pruning info: sparsity=0.281
2025-08-28 04:43:13,397 - INFO -   Reactivation rate: 0.0044
2025-08-28 04:43:14,122 - INFO - Epoch: [18][200/391] Time 0.018 (0.020) Data 0.002 (0.002) Loss 0.4850 (0.4923) Acc@1 83.594 (83.085) Acc@5 99.219 (99.160)
2025-08-28 04:43:15,934 - INFO - Epoch: [18][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.5061 (0.4924) Acc@1 85.156 (83.173) Acc@5 100.000 (99.149)
2025-08-28 04:43:16,375 - INFO - Pruning info: sparsity=0.281
2025-08-28 04:43:16,375 - INFO -   Reactivation rate: 0.0032
2025-08-28 04:43:17,778 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.9292 (0.9292) Acc@1 72.656 (72.656) Acc@5 96.094 (96.094)
2025-08-28 04:43:18,694 - INFO - Epoch 18:
2025-08-28 04:43:18,695 - INFO -   Train: acc1: 83.1780 | acc5: 99.1740 | loss: 0.4921 | sparsity: 0.2805 | reactivation_rate: 0.0044
2025-08-28 04:43:18,695 - INFO -   Val:   acc1: 72.3500 | acc5: 97.5300 | loss: 0.8779
2025-08-28 04:43:18,695 - INFO -   LR: 0.100000
2025-08-28 04:43:18,704 - INFO - 
Epoch: 19, lr = 0.1
2025-08-28 04:43:18,881 - INFO - Epoch: [19][0/391] Time 0.176 (0.176) Data 0.146 (0.146) Loss 0.4276 (0.4276) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 04:43:20,576 - INFO - Pruning info: sparsity=0.292
2025-08-28 04:43:20,577 - INFO -   Reactivation rate: 0.0057
2025-08-28 04:43:20,701 - INFO - Epoch: [19][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4732 (0.4833) Acc@1 82.031 (83.284) Acc@5 100.000 (99.234)
2025-08-28 04:43:22,718 - INFO - Epoch: [19][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4175 (0.4932) Acc@1 85.938 (82.952) Acc@5 100.000 (99.168)
2025-08-28 04:43:23,738 - INFO - Pruning info: sparsity=0.292
2025-08-28 04:43:23,738 - INFO -   Reactivation rate: 0.0037
2025-08-28 04:43:24,745 - INFO - Epoch: [19][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3961 (0.4914) Acc@1 85.156 (83.025) Acc@5 99.219 (99.208)
2025-08-28 04:43:26,581 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.6781 (0.6781) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 04:43:27,451 - INFO - Epoch 19:
2025-08-28 04:43:27,452 - INFO -   Train: acc1: 83.2440 | acc5: 99.2020 | loss: 0.4865 | sparsity: 0.2919 | reactivation_rate: 0.0044
2025-08-28 04:43:27,452 - INFO -   Val:   acc1: 74.4400 | acc5: 98.7100 | loss: 0.7468
2025-08-28 04:43:27,452 - INFO -   LR: 0.100000
2025-08-28 04:43:27,462 - INFO - 
Epoch: 20, lr = 0.1
2025-08-28 04:43:27,639 - INFO - Epoch: [20][0/391] Time 0.177 (0.177) Data 0.138 (0.138) Loss 0.4534 (0.4534) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:43:28,021 - INFO - Pruning info: sparsity=0.303
2025-08-28 04:43:28,021 - INFO -   Reactivation rate: 0.0083
2025-08-28 04:43:29,621 - INFO - Epoch: [20][100/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.4065 (0.4861) Acc@1 85.938 (83.377) Acc@5 99.219 (99.257)
2025-08-28 04:43:31,157 - INFO - Pruning info: sparsity=0.303
2025-08-28 04:43:31,157 - INFO -   Reactivation rate: 0.0041
2025-08-28 04:43:31,562 - INFO - Epoch: [20][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5156 (0.4899) Acc@1 82.812 (83.131) Acc@5 99.219 (99.164)
2025-08-28 04:43:33,496 - INFO - Epoch: [20][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4611 (0.4848) Acc@1 86.719 (83.298) Acc@5 99.219 (99.206)
2025-08-28 04:43:34,301 - INFO - Pruning info: sparsity=0.303
2025-08-28 04:43:34,301 - INFO -   Reactivation rate: 0.0030
2025-08-28 04:43:35,373 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5805 (0.5805) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 04:43:36,205 - INFO - Epoch 20:
2025-08-28 04:43:36,205 - INFO -   Train: acc1: 83.1540 | acc5: 99.1920 | loss: 0.4898 | sparsity: 0.3028 | reactivation_rate: 0.0043
2025-08-28 04:43:36,205 - INFO -   Val:   acc1: 79.5200 | acc5: 98.6900 | loss: 0.5930
2025-08-28 04:43:36,205 - INFO -   LR: 0.100000
2025-08-28 04:43:36,251 - INFO - 
Epoch: 21, lr = 0.1
2025-08-28 04:43:36,427 - INFO - Epoch: [21][0/391] Time 0.175 (0.175) Data 0.133 (0.133) Loss 0.3686 (0.3686) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 04:43:38,359 - INFO - Epoch: [21][100/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.3953 (0.4648) Acc@1 85.938 (84.073) Acc@5 100.000 (99.226)
2025-08-28 04:43:38,522 - INFO - Pruning info: sparsity=0.313
2025-08-28 04:43:38,522 - INFO -   Reactivation rate: 0.0048
2025-08-28 04:43:40,323 - INFO - Epoch: [21][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4780 (0.4744) Acc@1 85.156 (83.675) Acc@5 100.000 (99.180)
2025-08-28 04:43:41,668 - INFO - Pruning info: sparsity=0.313
2025-08-28 04:43:41,668 - INFO -   Reactivation rate: 0.0034
2025-08-28 04:43:42,292 - INFO - Epoch: [21][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5055 (0.4773) Acc@1 82.031 (83.547) Acc@5 99.219 (99.214)
2025-08-28 04:43:44,172 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.8133 (0.8133) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-28 04:43:45,018 - INFO - Epoch 21:
2025-08-28 04:43:45,018 - INFO -   Train: acc1: 83.3040 | acc5: 99.1960 | loss: 0.4833 | sparsity: 0.3134 | reactivation_rate: 0.0042
2025-08-28 04:43:45,018 - INFO -   Val:   acc1: 73.8900 | acc5: 96.8400 | loss: 0.8584
2025-08-28 04:43:45,018 - INFO -   LR: 0.100000
2025-08-28 04:43:45,030 - INFO - 
Epoch: 22, lr = 0.1
2025-08-28 04:43:45,209 - INFO - Epoch: [22][0/391] Time 0.179 (0.179) Data 0.153 (0.153) Loss 0.4868 (0.4868) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 04:43:45,949 - INFO - Pruning info: sparsity=0.324
2025-08-28 04:43:45,949 - INFO -   Reactivation rate: 0.0070
2025-08-28 04:43:47,161 - INFO - Epoch: [22][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4420 (0.4721) Acc@1 83.594 (83.895) Acc@5 99.219 (99.211)
2025-08-28 04:43:49,099 - INFO - Pruning info: sparsity=0.324
2025-08-28 04:43:49,099 - INFO -   Reactivation rate: 0.0039
2025-08-28 04:43:49,156 - INFO - Epoch: [22][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.5031 (0.4773) Acc@1 79.688 (83.337) Acc@5 99.219 (99.149)
2025-08-28 04:43:51,132 - INFO - Epoch: [22][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3919 (0.4761) Acc@1 86.719 (83.454) Acc@5 100.000 (99.195)
2025-08-28 04:43:52,197 - INFO - Pruning info: sparsity=0.324
2025-08-28 04:43:52,197 - INFO -   Reactivation rate: 0.0028
2025-08-28 04:43:52,939 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6308 (0.6308) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 04:43:53,816 - INFO - Epoch 22:
2025-08-28 04:43:53,816 - INFO -   Train: acc1: 83.2900 | acc5: 99.1860 | loss: 0.4823 | sparsity: 0.3236 | reactivation_rate: 0.0041
2025-08-28 04:43:53,816 - INFO -   Val:   acc1: 79.0400 | acc5: 98.3300 | loss: 0.6500
2025-08-28 04:43:53,816 - INFO -   LR: 0.100000
2025-08-28 04:43:53,827 - INFO - 
Epoch: 23, lr = 0.1
2025-08-28 04:43:54,006 - INFO - Epoch: [23][0/391] Time 0.178 (0.178) Data 0.156 (0.156) Loss 0.4240 (0.4240) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-28 04:43:55,931 - INFO - Epoch: [23][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.5531 (0.4656) Acc@1 78.125 (84.220) Acc@5 98.438 (99.172)
2025-08-28 04:43:56,447 - INFO - Pruning info: sparsity=0.333
2025-08-28 04:43:56,448 - INFO -   Reactivation rate: 0.0046
2025-08-28 04:43:57,853 - INFO - Epoch: [23][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.5191 (0.4832) Acc@1 84.375 (83.551) Acc@5 99.219 (99.145)
2025-08-28 04:43:59,424 - INFO - Pruning info: sparsity=0.333
2025-08-28 04:43:59,424 - INFO -   Reactivation rate: 0.0030
2025-08-28 04:43:59,708 - INFO - Epoch: [23][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4729 (0.4779) Acc@1 84.375 (83.739) Acc@5 99.219 (99.182)
2025-08-28 04:44:01,531 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5034 (0.5034) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 04:44:02,358 - INFO - Epoch 23:
2025-08-28 04:44:02,358 - INFO -   Train: acc1: 83.6900 | acc5: 99.1540 | loss: 0.4790 | sparsity: 0.3334 | reactivation_rate: 0.0039
2025-08-28 04:44:02,358 - INFO -   Val:   acc1: 79.7200 | acc5: 98.8600 | loss: 0.6152
2025-08-28 04:44:02,358 - INFO -   LR: 0.100000
2025-08-28 04:44:02,402 - INFO - Checkpoint saved: epoch=23, metric=79.7200
2025-08-28 04:44:02,436 - INFO - 
Epoch: 24, lr = 0.1
2025-08-28 04:44:02,612 - INFO - Epoch: [24][0/391] Time 0.176 (0.176) Data 0.153 (0.153) Loss 0.4687 (0.4687) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 04:44:03,662 - INFO - Pruning info: sparsity=0.343
2025-08-28 04:44:03,663 - INFO -   Reactivation rate: 0.0057
2025-08-28 04:44:04,523 - INFO - Epoch: [24][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4815 (0.4753) Acc@1 82.812 (83.393) Acc@5 99.219 (99.281)
2025-08-28 04:44:06,422 - INFO - Epoch: [24][200/391] Time 0.033 (0.020) Data 0.000 (0.003) Loss 0.4836 (0.4779) Acc@1 85.938 (83.283) Acc@5 99.219 (99.316)
2025-08-28 04:44:06,707 - INFO - Pruning info: sparsity=0.343
2025-08-28 04:44:06,707 - INFO -   Reactivation rate: 0.0033
2025-08-28 04:44:08,305 - INFO - Epoch: [24][300/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.4915 (0.4769) Acc@1 82.031 (83.384) Acc@5 100.000 (99.302)
2025-08-28 04:44:09,822 - INFO - Pruning info: sparsity=0.343
2025-08-28 04:44:09,822 - INFO -   Reactivation rate: 0.0025
2025-08-28 04:44:10,202 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.5752 (0.5752) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 04:44:11,036 - INFO - Epoch 24:
2025-08-28 04:44:11,037 - INFO -   Train: acc1: 83.5380 | acc5: 99.2700 | loss: 0.4746 | sparsity: 0.3428 | reactivation_rate: 0.0038
2025-08-28 04:44:11,037 - INFO -   Val:   acc1: 78.7600 | acc5: 98.8000 | loss: 0.6196
2025-08-28 04:44:11,037 - INFO -   LR: 0.100000
2025-08-28 04:44:11,046 - INFO - 
Epoch: 25, lr = 0.1
2025-08-28 04:44:11,240 - INFO - Epoch: [25][0/391] Time 0.193 (0.193) Data 0.172 (0.172) Loss 0.3853 (0.3853) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:44:13,202 - INFO - Epoch: [25][100/391] Time 0.026 (0.021) Data 0.013 (0.004) Loss 0.5681 (0.4539) Acc@1 77.344 (84.499) Acc@5 98.438 (99.281)
2025-08-28 04:44:14,076 - INFO - Pruning info: sparsity=0.352
2025-08-28 04:44:14,077 - INFO -   Reactivation rate: 0.0041
2025-08-28 04:44:15,091 - INFO - Epoch: [25][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.5632 (0.4688) Acc@1 78.906 (83.975) Acc@5 99.219 (99.296)
2025-08-28 04:44:16,979 - INFO - Epoch: [25][300/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.4696 (0.4678) Acc@1 87.500 (84.001) Acc@5 100.000 (99.302)
2025-08-28 04:44:17,064 - INFO - Pruning info: sparsity=0.352
2025-08-28 04:44:17,064 - INFO -   Reactivation rate: 0.0026
2025-08-28 04:44:18,908 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.6159 (0.6159) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-28 04:44:19,789 - INFO - Epoch 25:
2025-08-28 04:44:19,789 - INFO -   Train: acc1: 83.8780 | acc5: 99.2840 | loss: 0.4697 | sparsity: 0.3519 | reactivation_rate: 0.0036
2025-08-28 04:44:19,789 - INFO -   Val:   acc1: 76.9700 | acc5: 98.1800 | loss: 0.6943
2025-08-28 04:44:19,789 - INFO -   LR: 0.100000
2025-08-28 04:44:19,799 - INFO - 
Epoch: 26, lr = 0.1
2025-08-28 04:44:19,980 - INFO - Epoch: [26][0/391] Time 0.180 (0.180) Data 0.151 (0.151) Loss 0.3668 (0.3668) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:44:21,439 - INFO - Pruning info: sparsity=0.361
2025-08-28 04:44:21,439 - INFO -   Reactivation rate: 0.0052
2025-08-28 04:44:21,973 - INFO - Epoch: [26][100/391] Time 0.015 (0.022) Data 0.000 (0.003) Loss 0.4981 (0.4707) Acc@1 84.375 (84.259) Acc@5 98.438 (99.242)
2025-08-28 04:44:23,879 - INFO - Epoch: [26][200/391] Time 0.038 (0.020) Data 0.026 (0.003) Loss 0.4795 (0.4638) Acc@1 81.250 (84.356) Acc@5 100.000 (99.242)
2025-08-28 04:44:24,610 - INFO - Pruning info: sparsity=0.361
2025-08-28 04:44:24,610 - INFO -   Reactivation rate: 0.0031
2025-08-28 04:44:25,901 - INFO - Epoch: [26][300/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.6862 (0.4734) Acc@1 77.344 (83.918) Acc@5 100.000 (99.263)
2025-08-28 04:44:27,756 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.7392 (0.7392) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 04:44:28,679 - INFO - Epoch 26:
2025-08-28 04:44:28,679 - INFO -   Train: acc1: 84.0720 | acc5: 99.2940 | loss: 0.4665 | sparsity: 0.3606 | reactivation_rate: 0.0036
2025-08-28 04:44:28,679 - INFO -   Val:   acc1: 77.2100 | acc5: 98.6300 | loss: 0.7190
2025-08-28 04:44:28,679 - INFO -   LR: 0.100000
2025-08-28 04:44:28,689 - INFO - 
Epoch: 27, lr = 0.1
2025-08-28 04:44:28,872 - INFO - Epoch: [27][0/391] Time 0.182 (0.182) Data 0.150 (0.150) Loss 0.4274 (0.4274) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 04:44:28,907 - INFO - Pruning info: sparsity=0.369
2025-08-28 04:44:28,907 - INFO -   Reactivation rate: 0.0016
2025-08-28 04:44:30,813 - INFO - Epoch: [27][100/391] Time 0.027 (0.021) Data 0.011 (0.005) Loss 0.5446 (0.4409) Acc@1 82.031 (84.769) Acc@5 98.438 (99.327)
2025-08-28 04:44:32,047 - INFO - Pruning info: sparsity=0.369
2025-08-28 04:44:32,047 - INFO -   Reactivation rate: 0.0034
2025-08-28 04:44:32,826 - INFO - Epoch: [27][200/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4421 (0.4540) Acc@1 84.375 (84.258) Acc@5 99.219 (99.335)
2025-08-28 04:44:34,744 - INFO - Epoch: [27][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.5143 (0.4596) Acc@1 81.250 (84.097) Acc@5 98.438 (99.330)
2025-08-28 04:44:35,152 - INFO - Pruning info: sparsity=0.369
2025-08-28 04:44:35,152 - INFO -   Reactivation rate: 0.0025
2025-08-28 04:44:36,522 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5561 (0.5561) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 04:44:37,353 - INFO - Epoch 27:
2025-08-28 04:44:37,353 - INFO -   Train: acc1: 84.0180 | acc5: 99.3020 | loss: 0.4638 | sparsity: 0.3689 | reactivation_rate: 0.0035
2025-08-28 04:44:37,353 - INFO -   Val:   acc1: 78.5600 | acc5: 98.9900 | loss: 0.6448
2025-08-28 04:44:37,354 - INFO -   LR: 0.100000
2025-08-28 04:44:37,367 - INFO - 
Epoch: 28, lr = 0.1
2025-08-28 04:44:37,535 - INFO - Epoch: [28][0/391] Time 0.167 (0.167) Data 0.123 (0.123) Loss 0.3421 (0.3421) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 04:44:39,343 - INFO - Pruning info: sparsity=0.377
2025-08-28 04:44:39,343 - INFO -   Reactivation rate: 0.0045
2025-08-28 04:44:39,503 - INFO - Epoch: [28][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4617 (0.4518) Acc@1 80.469 (84.561) Acc@5 100.000 (99.358)
2025-08-28 04:44:41,361 - INFO - Epoch: [28][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4725 (0.4577) Acc@1 84.375 (84.289) Acc@5 99.219 (99.374)
2025-08-28 04:44:42,361 - INFO - Pruning info: sparsity=0.377
2025-08-28 04:44:42,361 - INFO -   Reactivation rate: 0.0029
2025-08-28 04:44:43,353 - INFO - Epoch: [28][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4617 (0.4599) Acc@1 79.688 (84.199) Acc@5 100.000 (99.304)
2025-08-28 04:44:45,242 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6407 (0.6407) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 04:44:46,087 - INFO - Epoch 28:
2025-08-28 04:44:46,087 - INFO -   Train: acc1: 84.1560 | acc5: 99.2820 | loss: 0.4597 | sparsity: 0.3770 | reactivation_rate: 0.0034
2025-08-28 04:44:46,087 - INFO -   Val:   acc1: 76.1800 | acc5: 98.8100 | loss: 0.7403
2025-08-28 04:44:46,088 - INFO -   LR: 0.100000
2025-08-28 04:44:46,099 - INFO - 
Epoch: 29, lr = 0.1
2025-08-28 04:44:46,292 - INFO - Epoch: [29][0/391] Time 0.193 (0.193) Data 0.166 (0.166) Loss 0.6258 (0.6258) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-28 04:44:46,697 - INFO - Pruning info: sparsity=0.385
2025-08-28 04:44:46,697 - INFO -   Reactivation rate: 0.0064
2025-08-28 04:44:48,148 - INFO - Epoch: [29][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4434 (0.4545) Acc@1 85.156 (84.336) Acc@5 99.219 (99.180)
2025-08-28 04:44:49,690 - INFO - Pruning info: sparsity=0.385
2025-08-28 04:44:49,690 - INFO -   Reactivation rate: 0.0031
2025-08-28 04:44:50,061 - INFO - Epoch: [29][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4290 (0.4570) Acc@1 85.156 (84.453) Acc@5 100.000 (99.304)
2025-08-28 04:44:51,894 - INFO - Epoch: [29][300/391] Time 0.026 (0.019) Data 0.000 (0.002) Loss 0.5327 (0.4610) Acc@1 81.250 (84.269) Acc@5 99.219 (99.307)
2025-08-28 04:44:52,649 - INFO - Pruning info: sparsity=0.385
2025-08-28 04:44:52,649 - INFO -   Reactivation rate: 0.0025
2025-08-28 04:44:53,732 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 1.0943 (1.0943) Acc@1 68.750 (68.750) Acc@5 99.219 (99.219)
2025-08-28 04:44:54,565 - INFO - Epoch 29:
2025-08-28 04:44:54,565 - INFO -   Train: acc1: 84.2300 | acc5: 99.2920 | loss: 0.4606 | sparsity: 0.3846 | reactivation_rate: 0.0033
2025-08-28 04:44:54,565 - INFO -   Val:   acc1: 70.7400 | acc5: 97.1900 | loss: 1.1082
2025-08-28 04:44:54,565 - INFO -   LR: 0.100000
2025-08-28 04:44:54,576 - INFO - 
Epoch: 30, lr = 0.1
2025-08-28 04:44:54,752 - INFO - Epoch: [30][0/391] Time 0.176 (0.176) Data 0.138 (0.138) Loss 0.3604 (0.3604) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 04:44:56,744 - INFO - Epoch: [30][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.5005 (0.4623) Acc@1 83.594 (84.398) Acc@5 100.000 (99.234)
2025-08-28 04:44:56,933 - INFO - Pruning info: sparsity=0.392
2025-08-28 04:44:56,936 - INFO -   Reactivation rate: 0.0041
2025-08-28 04:44:58,680 - INFO - Epoch: [30][200/391] Time 0.017 (0.020) Data 0.003 (0.002) Loss 0.4680 (0.4601) Acc@1 83.594 (84.383) Acc@5 99.219 (99.219)
2025-08-28 04:45:00,022 - INFO - Pruning info: sparsity=0.392
2025-08-28 04:45:00,022 - INFO -   Reactivation rate: 0.0026
2025-08-28 04:45:00,621 - INFO - Epoch: [30][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5133 (0.4593) Acc@1 82.812 (84.437) Acc@5 100.000 (99.252)
2025-08-28 04:45:02,440 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5366 (0.5366) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 04:45:03,293 - INFO - Epoch 30:
2025-08-28 04:45:03,293 - INFO -   Train: acc1: 84.2920 | acc5: 99.2620 | loss: 0.4617 | sparsity: 0.3920 | reactivation_rate: 0.0033
2025-08-28 04:45:03,293 - INFO -   Val:   acc1: 79.6300 | acc5: 98.3000 | loss: 0.6146
2025-08-28 04:45:03,293 - INFO -   LR: 0.100000
2025-08-28 04:45:03,341 - INFO - 
Epoch: 31, lr = 0.1
2025-08-28 04:45:03,543 - INFO - Epoch: [31][0/391] Time 0.202 (0.202) Data 0.173 (0.173) Loss 0.5259 (0.5259) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 04:45:04,337 - INFO - Pruning info: sparsity=0.399
2025-08-28 04:45:04,337 - INFO -   Reactivation rate: 0.0053
2025-08-28 04:45:05,429 - INFO - Epoch: [31][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.3978 (0.4530) Acc@1 87.500 (84.429) Acc@5 99.219 (99.381)
2025-08-28 04:45:07,312 - INFO - Pruning info: sparsity=0.399
2025-08-28 04:45:07,312 - INFO -   Reactivation rate: 0.0029
2025-08-28 04:45:07,360 - INFO - Epoch: [31][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3607 (0.4522) Acc@1 85.938 (84.492) Acc@5 100.000 (99.324)
2025-08-28 04:45:09,331 - INFO - Epoch: [31][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4041 (0.4553) Acc@1 86.719 (84.328) Acc@5 99.219 (99.297)
2025-08-28 04:45:10,510 - INFO - Pruning info: sparsity=0.399
2025-08-28 04:45:10,510 - INFO -   Reactivation rate: 0.0021
2025-08-28 04:45:11,237 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6370 (0.6370) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-28 04:45:12,085 - INFO - Epoch 31:
2025-08-28 04:45:12,085 - INFO -   Train: acc1: 84.3920 | acc5: 99.2940 | loss: 0.4545 | sparsity: 0.3990 | reactivation_rate: 0.0031
2025-08-28 04:45:12,086 - INFO -   Val:   acc1: 78.9500 | acc5: 98.4900 | loss: 0.6539
2025-08-28 04:45:12,086 - INFO -   LR: 0.100000
2025-08-28 04:45:12,097 - INFO - 
Epoch: 32, lr = 0.1
2025-08-28 04:45:12,302 - INFO - Epoch: [32][0/391] Time 0.204 (0.204) Data 0.157 (0.157) Loss 0.5699 (0.5699) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 04:45:14,384 - INFO - Epoch: [32][100/391] Time 0.033 (0.023) Data 0.018 (0.003) Loss 0.3573 (0.4388) Acc@1 92.969 (85.265) Acc@5 99.219 (99.288)
2025-08-28 04:45:14,972 - INFO - Pruning info: sparsity=0.406
2025-08-28 04:45:14,972 - INFO -   Reactivation rate: 0.0032
2025-08-28 04:45:16,364 - INFO - Epoch: [32][200/391] Time 0.019 (0.021) Data 0.003 (0.002) Loss 0.4306 (0.4413) Acc@1 85.938 (85.121) Acc@5 99.219 (99.300)
2025-08-28 04:45:18,136 - INFO - Pruning info: sparsity=0.406
2025-08-28 04:45:18,136 - INFO -   Reactivation rate: 0.0023
2025-08-28 04:45:18,393 - INFO - Epoch: [32][300/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.3466 (0.4467) Acc@1 89.062 (84.749) Acc@5 100.000 (99.315)
2025-08-28 04:45:20,284 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6060 (0.6060) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 04:45:21,127 - INFO - Epoch 32:
2025-08-28 04:45:21,128 - INFO -   Train: acc1: 84.6860 | acc5: 99.3100 | loss: 0.4495 | sparsity: 0.4058 | reactivation_rate: 0.0030
2025-08-28 04:45:21,128 - INFO -   Val:   acc1: 78.8700 | acc5: 98.8100 | loss: 0.6548
2025-08-28 04:45:21,128 - INFO -   LR: 0.100000
2025-08-28 04:45:21,137 - INFO - 
Epoch: 33, lr = 0.1
2025-08-28 04:45:21,330 - INFO - Epoch: [33][0/391] Time 0.192 (0.192) Data 0.166 (0.166) Loss 0.4357 (0.4357) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 04:45:22,441 - INFO - Pruning info: sparsity=0.412
2025-08-28 04:45:22,441 - INFO -   Reactivation rate: 0.0044
2025-08-28 04:45:23,235 - INFO - Epoch: [33][100/391] Time 0.017 (0.021) Data 0.004 (0.004) Loss 0.3605 (0.4574) Acc@1 87.500 (84.220) Acc@5 99.219 (99.257)
2025-08-28 04:45:25,218 - INFO - Epoch: [33][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4645 (0.4429) Acc@1 83.594 (84.678) Acc@5 100.000 (99.366)
2025-08-28 04:45:25,556 - INFO - Pruning info: sparsity=0.412
2025-08-28 04:45:25,556 - INFO -   Reactivation rate: 0.0026
2025-08-28 04:45:27,133 - INFO - Epoch: [33][300/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.3967 (0.4457) Acc@1 86.719 (84.632) Acc@5 99.219 (99.320)
2025-08-28 04:45:28,565 - INFO - Pruning info: sparsity=0.412
2025-08-28 04:45:28,565 - INFO -   Reactivation rate: 0.0020
2025-08-28 04:45:28,939 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.4738 (0.4738) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:45:29,820 - INFO - Epoch 33:
2025-08-28 04:45:29,820 - INFO -   Train: acc1: 84.6060 | acc5: 99.3340 | loss: 0.4486 | sparsity: 0.4122 | reactivation_rate: 0.0030
2025-08-28 04:45:29,820 - INFO -   Val:   acc1: 81.4400 | acc5: 99.1100 | loss: 0.5442
2025-08-28 04:45:29,820 - INFO -   LR: 0.100000
2025-08-28 04:45:29,864 - INFO - Checkpoint saved: epoch=33, metric=81.4400
2025-08-28 04:45:29,898 - INFO - 
Epoch: 34, lr = 0.1
2025-08-28 04:45:30,093 - INFO - Epoch: [34][0/391] Time 0.195 (0.195) Data 0.172 (0.172) Loss 0.4879 (0.4879) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 04:45:32,117 - INFO - Epoch: [34][100/391] Time 0.013 (0.022) Data 0.000 (0.003) Loss 0.4308 (0.4281) Acc@1 82.812 (85.288) Acc@5 100.000 (99.312)
2025-08-28 04:45:32,971 - INFO - Pruning info: sparsity=0.418
2025-08-28 04:45:32,971 - INFO -   Reactivation rate: 0.0030
2025-08-28 04:45:34,060 - INFO - Epoch: [34][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.3367 (0.4381) Acc@1 86.719 (85.032) Acc@5 100.000 (99.324)
2025-08-28 04:45:36,061 - INFO - Epoch: [34][300/391] Time 0.015 (0.020) Data 0.001 (0.002) Loss 0.7052 (0.4449) Acc@1 75.781 (84.788) Acc@5 98.438 (99.351)
2025-08-28 04:45:36,164 - INFO - Pruning info: sparsity=0.418
2025-08-28 04:45:36,164 - INFO -   Reactivation rate: 0.0021
2025-08-28 04:45:37,910 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6679 (0.6679) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 04:45:38,766 - INFO - Epoch 34:
2025-08-28 04:45:38,766 - INFO -   Train: acc1: 84.5080 | acc5: 99.3300 | loss: 0.4528 | sparsity: 0.4183 | reactivation_rate: 0.0029
2025-08-28 04:45:38,766 - INFO -   Val:   acc1: 74.6400 | acc5: 98.4200 | loss: 0.7918
2025-08-28 04:45:38,766 - INFO -   LR: 0.100000
2025-08-28 04:45:38,777 - INFO - 
Epoch: 35, lr = 0.1
2025-08-28 04:45:38,962 - INFO - Epoch: [35][0/391] Time 0.183 (0.183) Data 0.159 (0.159) Loss 0.3505 (0.3505) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-28 04:45:40,487 - INFO - Pruning info: sparsity=0.424
2025-08-28 04:45:40,487 - INFO -   Reactivation rate: 0.0038
2025-08-28 04:45:40,925 - INFO - Epoch: [35][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4375 (0.4545) Acc@1 82.031 (84.398) Acc@5 99.219 (99.319)
2025-08-28 04:45:42,849 - INFO - Epoch: [35][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4074 (0.4442) Acc@1 85.938 (84.779) Acc@5 100.000 (99.254)
2025-08-28 04:45:43,564 - INFO - Pruning info: sparsity=0.424
2025-08-28 04:45:43,564 - INFO -   Reactivation rate: 0.0025
2025-08-28 04:45:44,850 - INFO - Epoch: [35][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.4084 (0.4493) Acc@1 87.500 (84.533) Acc@5 98.438 (99.250)
2025-08-28 04:45:46,690 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6297 (0.6297) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 04:45:47,521 - INFO - Epoch 35:
2025-08-28 04:45:47,521 - INFO -   Train: acc1: 84.4620 | acc5: 99.2920 | loss: 0.4491 | sparsity: 0.4241 | reactivation_rate: 0.0028
2025-08-28 04:45:47,521 - INFO -   Val:   acc1: 77.6800 | acc5: 98.3500 | loss: 0.6620
2025-08-28 04:45:47,521 - INFO -   LR: 0.100000
2025-08-28 04:45:47,534 - INFO - 
Epoch: 36, lr = 0.1
2025-08-28 04:45:47,716 - INFO - Epoch: [36][0/391] Time 0.181 (0.181) Data 0.164 (0.164) Loss 0.4074 (0.4074) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 04:45:47,785 - INFO - Pruning info: sparsity=0.430
2025-08-28 04:45:47,786 - INFO -   Reactivation rate: 0.0013
2025-08-28 04:45:49,688 - INFO - Epoch: [36][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4591 (0.4511) Acc@1 85.938 (84.182) Acc@5 100.000 (99.273)
2025-08-28 04:45:51,026 - INFO - Pruning info: sparsity=0.430
2025-08-28 04:45:51,026 - INFO -   Reactivation rate: 0.0027
2025-08-28 04:45:51,739 - INFO - Epoch: [36][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.3427 (0.4452) Acc@1 90.625 (84.604) Acc@5 100.000 (99.300)
2025-08-28 04:45:53,773 - INFO - Epoch: [36][300/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.5810 (0.4500) Acc@1 79.688 (84.528) Acc@5 98.438 (99.294)
2025-08-28 04:45:54,240 - INFO - Pruning info: sparsity=0.430
2025-08-28 04:45:54,240 - INFO -   Reactivation rate: 0.0020
2025-08-28 04:45:55,653 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6502 (0.6502) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 04:45:56,528 - INFO - Epoch 36:
2025-08-28 04:45:56,528 - INFO -   Train: acc1: 84.6400 | acc5: 99.3000 | loss: 0.4481 | sparsity: 0.4297 | reactivation_rate: 0.0026
2025-08-28 04:45:56,528 - INFO -   Val:   acc1: 79.0800 | acc5: 98.9000 | loss: 0.6128
2025-08-28 04:45:56,528 - INFO -   LR: 0.100000
2025-08-28 04:45:56,539 - INFO - 
Epoch: 37, lr = 0.1
2025-08-28 04:45:56,726 - INFO - Epoch: [37][0/391] Time 0.186 (0.186) Data 0.160 (0.160) Loss 0.3160 (0.3160) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 04:45:58,496 - INFO - Pruning info: sparsity=0.435
2025-08-28 04:45:58,496 - INFO -   Reactivation rate: 0.0034
2025-08-28 04:45:58,640 - INFO - Epoch: [37][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4346 (0.4435) Acc@1 84.375 (84.870) Acc@5 98.438 (99.296)
2025-08-28 04:46:00,459 - INFO - Epoch: [37][200/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4612 (0.4565) Acc@1 83.594 (84.313) Acc@5 99.219 (99.277)
2025-08-28 04:46:01,441 - INFO - Pruning info: sparsity=0.435
2025-08-28 04:46:01,442 - INFO -   Reactivation rate: 0.0022
2025-08-28 04:46:02,399 - INFO - Epoch: [37][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.5736 (0.4497) Acc@1 80.469 (84.541) Acc@5 97.656 (99.343)
2025-08-28 04:46:04,220 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7305 (0.7305) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 04:46:05,068 - INFO - Epoch 37:
2025-08-28 04:46:05,068 - INFO -   Train: acc1: 84.5200 | acc5: 99.3380 | loss: 0.4501 | sparsity: 0.4350 | reactivation_rate: 0.0026
2025-08-28 04:46:05,068 - INFO -   Val:   acc1: 77.1800 | acc5: 98.1800 | loss: 0.7189
2025-08-28 04:46:05,069 - INFO -   LR: 0.100000
2025-08-28 04:46:05,079 - INFO - 
Epoch: 38, lr = 0.1
2025-08-28 04:46:05,267 - INFO - Epoch: [38][0/391] Time 0.187 (0.187) Data 0.165 (0.165) Loss 0.2967 (0.2967) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 04:46:05,699 - INFO - Pruning info: sparsity=0.440
2025-08-28 04:46:05,699 - INFO -   Reactivation rate: 0.0047
2025-08-28 04:46:07,195 - INFO - Epoch: [38][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.5332 (0.4507) Acc@1 79.688 (84.615) Acc@5 98.438 (99.250)
2025-08-28 04:46:08,674 - INFO - Pruning info: sparsity=0.440
2025-08-28 04:46:08,675 - INFO -   Reactivation rate: 0.0024
2025-08-28 04:46:09,043 - INFO - Epoch: [38][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4021 (0.4515) Acc@1 85.938 (84.581) Acc@5 100.000 (99.312)
2025-08-28 04:46:10,988 - INFO - Epoch: [38][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.5062 (0.4529) Acc@1 82.031 (84.432) Acc@5 100.000 (99.315)
2025-08-28 04:46:11,734 - INFO - Pruning info: sparsity=0.440
2025-08-28 04:46:11,734 - INFO -   Reactivation rate: 0.0017
2025-08-28 04:46:12,816 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5726 (0.5726) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 04:46:13,619 - INFO - Epoch 38:
2025-08-28 04:46:13,619 - INFO -   Train: acc1: 84.5820 | acc5: 99.3000 | loss: 0.4499 | sparsity: 0.4400 | reactivation_rate: 0.0025
2025-08-28 04:46:13,619 - INFO -   Val:   acc1: 79.7100 | acc5: 98.9900 | loss: 0.6015
2025-08-28 04:46:13,619 - INFO -   LR: 0.100000
2025-08-28 04:46:13,630 - INFO - 
Epoch: 39, lr = 0.1
2025-08-28 04:46:13,787 - INFO - Epoch: [39][0/391] Time 0.156 (0.156) Data 0.128 (0.128) Loss 0.3344 (0.3344) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 04:46:15,678 - INFO - Epoch: [39][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4217 (0.4297) Acc@1 85.156 (85.241) Acc@5 100.000 (99.404)
2025-08-28 04:46:15,831 - INFO - Pruning info: sparsity=0.445
2025-08-28 04:46:15,832 - INFO -   Reactivation rate: 0.0030
2025-08-28 04:46:17,650 - INFO - Epoch: [39][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.5096 (0.4393) Acc@1 81.250 (84.678) Acc@5 99.219 (99.405)
2025-08-28 04:46:19,068 - INFO - Pruning info: sparsity=0.445
2025-08-28 04:46:19,069 - INFO -   Reactivation rate: 0.0019
2025-08-28 04:46:19,639 - INFO - Epoch: [39][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4204 (0.4432) Acc@1 88.281 (84.559) Acc@5 97.656 (99.377)
2025-08-28 04:46:21,582 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.6954 (0.6954) Acc@1 75.781 (75.781) Acc@5 100.000 (100.000)
2025-08-28 04:46:22,408 - INFO - Epoch 39:
2025-08-28 04:46:22,408 - INFO -   Train: acc1: 84.5160 | acc5: 99.3540 | loss: 0.4468 | sparsity: 0.4447 | reactivation_rate: 0.0024
2025-08-28 04:46:22,408 - INFO -   Val:   acc1: 80.1700 | acc5: 98.5700 | loss: 0.6297
2025-08-28 04:46:22,408 - INFO -   LR: 0.100000
2025-08-28 04:46:22,418 - INFO - 
Epoch: 40, lr = 0.1
2025-08-28 04:46:22,597 - INFO - Epoch: [40][0/391] Time 0.178 (0.178) Data 0.154 (0.154) Loss 0.3870 (0.3870) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:46:23,322 - INFO - Pruning info: sparsity=0.449
2025-08-28 04:46:23,322 - INFO -   Reactivation rate: 0.0040
2025-08-28 04:46:24,494 - INFO - Epoch: [40][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4062 (0.4363) Acc@1 83.594 (84.878) Acc@5 99.219 (99.389)
2025-08-28 04:46:26,383 - INFO - Pruning info: sparsity=0.449
2025-08-28 04:46:26,383 - INFO -   Reactivation rate: 0.0023
2025-08-28 04:46:26,399 - INFO - Epoch: [40][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.4068 (0.4308) Acc@1 89.062 (85.098) Acc@5 100.000 (99.374)
2025-08-28 04:46:28,246 - INFO - Epoch: [40][300/391] Time 0.027 (0.019) Data 0.004 (0.002) Loss 0.4883 (0.4380) Acc@1 82.812 (84.808) Acc@5 99.219 (99.390)
2025-08-28 04:46:29,397 - INFO - Pruning info: sparsity=0.449
2025-08-28 04:46:29,397 - INFO -   Reactivation rate: 0.0017
2025-08-28 04:46:30,133 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5555 (0.5555) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:46:30,963 - INFO - Epoch 40:
2025-08-28 04:46:30,963 - INFO -   Train: acc1: 84.7040 | acc5: 99.3600 | loss: 0.4431 | sparsity: 0.4492 | reactivation_rate: 0.0024
2025-08-28 04:46:30,964 - INFO -   Val:   acc1: 81.4400 | acc5: 99.0700 | loss: 0.5459
2025-08-28 04:46:30,964 - INFO -   LR: 0.100000
2025-08-28 04:46:31,011 - INFO - 
Epoch: 41, lr = 0.1
2025-08-28 04:46:31,197 - INFO - Epoch: [41][0/391] Time 0.185 (0.185) Data 0.160 (0.160) Loss 0.2935 (0.2935) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:46:33,074 - INFO - Epoch: [41][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4696 (0.4248) Acc@1 85.938 (85.528) Acc@5 100.000 (99.451)
2025-08-28 04:46:33,611 - INFO - Pruning info: sparsity=0.453
2025-08-28 04:46:33,612 - INFO -   Reactivation rate: 0.0026
2025-08-28 04:46:34,990 - INFO - Epoch: [41][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4166 (0.4357) Acc@1 86.719 (85.086) Acc@5 100.000 (99.409)
2025-08-28 04:46:36,713 - INFO - Pruning info: sparsity=0.453
2025-08-28 04:46:36,713 - INFO -   Reactivation rate: 0.0017
2025-08-28 04:46:36,940 - INFO - Epoch: [41][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3615 (0.4400) Acc@1 87.500 (84.860) Acc@5 99.219 (99.398)
2025-08-28 04:46:38,837 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.5141 (0.5141) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 04:46:39,680 - INFO - Epoch 41:
2025-08-28 04:46:39,681 - INFO -   Train: acc1: 84.6420 | acc5: 99.3720 | loss: 0.4447 | sparsity: 0.4534 | reactivation_rate: 0.0023
2025-08-28 04:46:39,681 - INFO -   Val:   acc1: 80.7600 | acc5: 99.1500 | loss: 0.5518
2025-08-28 04:46:39,681 - INFO -   LR: 0.100000
2025-08-28 04:46:39,693 - INFO - 
Epoch: 42, lr = 0.1
2025-08-28 04:46:39,878 - INFO - Epoch: [42][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.4114 (0.4114) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 04:46:40,990 - INFO - Pruning info: sparsity=0.457
2025-08-28 04:46:40,990 - INFO -   Reactivation rate: 0.0033
2025-08-28 04:46:41,809 - INFO - Epoch: [42][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.7209 (0.4233) Acc@1 75.000 (85.551) Acc@5 98.438 (99.397)
2025-08-28 04:46:43,754 - INFO - Epoch: [42][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5803 (0.4302) Acc@1 79.688 (85.300) Acc@5 96.875 (99.405)
2025-08-28 04:46:44,098 - INFO - Pruning info: sparsity=0.457
2025-08-28 04:46:44,099 - INFO -   Reactivation rate: 0.0020
2025-08-28 04:46:45,782 - INFO - Epoch: [42][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3404 (0.4391) Acc@1 88.281 (85.024) Acc@5 99.219 (99.369)
2025-08-28 04:46:47,198 - INFO - Pruning info: sparsity=0.457
2025-08-28 04:46:47,198 - INFO -   Reactivation rate: 0.0016
2025-08-28 04:46:47,578 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.6211 (0.6211) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 04:46:48,461 - INFO - Epoch 42:
2025-08-28 04:46:48,462 - INFO -   Train: acc1: 84.8080 | acc5: 99.3480 | loss: 0.4428 | sparsity: 0.4574 | reactivation_rate: 0.0023
2025-08-28 04:46:48,462 - INFO -   Val:   acc1: 81.9400 | acc5: 99.1800 | loss: 0.5656
2025-08-28 04:46:48,462 - INFO -   LR: 0.100000
2025-08-28 04:46:48,507 - INFO - Checkpoint saved: epoch=42, metric=81.9400
2025-08-28 04:46:48,543 - INFO - 
Epoch: 43, lr = 0.1
2025-08-28 04:46:48,744 - INFO - Epoch: [43][0/391] Time 0.200 (0.200) Data 0.168 (0.168) Loss 0.2581 (0.2581) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:46:50,749 - INFO - Epoch: [43][100/391] Time 0.012 (0.022) Data 0.000 (0.003) Loss 0.3984 (0.4428) Acc@1 86.719 (84.777) Acc@5 100.000 (99.381)
2025-08-28 04:46:51,676 - INFO - Pruning info: sparsity=0.461
2025-08-28 04:46:51,676 - INFO -   Reactivation rate: 0.0023
2025-08-28 04:46:52,681 - INFO - Epoch: [43][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.2943 (0.4365) Acc@1 90.625 (84.950) Acc@5 100.000 (99.413)
2025-08-28 04:46:54,632 - INFO - Epoch: [43][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2989 (0.4367) Acc@1 92.969 (84.943) Acc@5 100.000 (99.426)
2025-08-28 04:46:54,761 - INFO - Pruning info: sparsity=0.461
2025-08-28 04:46:54,761 - INFO -   Reactivation rate: 0.0016
2025-08-28 04:46:56,481 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5822 (0.5822) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-28 04:46:57,358 - INFO - Epoch 43:
2025-08-28 04:46:57,358 - INFO -   Train: acc1: 84.8660 | acc5: 99.4240 | loss: 0.4394 | sparsity: 0.4612 | reactivation_rate: 0.0022
2025-08-28 04:46:57,359 - INFO -   Val:   acc1: 81.3500 | acc5: 98.9100 | loss: 0.5679
2025-08-28 04:46:57,359 - INFO -   LR: 0.100000
2025-08-28 04:46:57,372 - INFO - 
Epoch: 44, lr = 0.1
2025-08-28 04:46:57,590 - INFO - Epoch: [44][0/391] Time 0.217 (0.217) Data 0.176 (0.176) Loss 0.4062 (0.4062) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:46:58,991 - INFO - Pruning info: sparsity=0.465
2025-08-28 04:46:58,991 - INFO -   Reactivation rate: 0.0030
2025-08-28 04:46:59,460 - INFO - Epoch: [44][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.3846 (0.4444) Acc@1 89.844 (84.623) Acc@5 99.219 (99.428)
2025-08-28 04:47:01,315 - INFO - Epoch: [44][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.4308 (0.4452) Acc@1 85.156 (84.752) Acc@5 98.438 (99.347)
2025-08-28 04:47:02,013 - INFO - Pruning info: sparsity=0.465
2025-08-28 04:47:02,013 - INFO -   Reactivation rate: 0.0018
2025-08-28 04:47:03,219 - INFO - Epoch: [44][300/391] Time 0.022 (0.019) Data 0.002 (0.002) Loss 0.2763 (0.4362) Acc@1 90.625 (85.037) Acc@5 100.000 (99.356)
2025-08-28 04:47:05,017 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.7143 (0.7143) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 04:47:05,848 - INFO - Epoch 44:
2025-08-28 04:47:05,848 - INFO -   Train: acc1: 84.9860 | acc5: 99.3600 | loss: 0.4374 | sparsity: 0.4647 | reactivation_rate: 0.0021
2025-08-28 04:47:05,848 - INFO -   Val:   acc1: 78.0800 | acc5: 99.1000 | loss: 0.6832
2025-08-28 04:47:05,848 - INFO -   LR: 0.100000
2025-08-28 04:47:05,858 - INFO - 
Epoch: 45, lr = 0.1
2025-08-28 04:47:06,029 - INFO - Epoch: [45][0/391] Time 0.170 (0.170) Data 0.139 (0.139) Loss 0.3276 (0.3276) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 04:47:06,111 - INFO - Pruning info: sparsity=0.468
2025-08-28 04:47:06,111 - INFO -   Reactivation rate: 0.0011
2025-08-28 04:47:07,900 - INFO - Epoch: [45][100/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.7041 (0.4324) Acc@1 76.562 (85.195) Acc@5 98.438 (99.366)
2025-08-28 04:47:09,164 - INFO - Pruning info: sparsity=0.468
2025-08-28 04:47:09,164 - INFO -   Reactivation rate: 0.0020
2025-08-28 04:47:09,849 - INFO - Epoch: [45][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3931 (0.4346) Acc@1 85.156 (84.985) Acc@5 100.000 (99.320)
2025-08-28 04:47:11,790 - INFO - Epoch: [45][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4188 (0.4347) Acc@1 84.375 (84.967) Acc@5 99.219 (99.351)
2025-08-28 04:47:12,277 - INFO - Pruning info: sparsity=0.468
2025-08-28 04:47:12,277 - INFO -   Reactivation rate: 0.0015
2025-08-28 04:47:13,752 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6163 (0.6163) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 04:47:14,601 - INFO - Epoch 45:
2025-08-28 04:47:14,601 - INFO -   Train: acc1: 84.9260 | acc5: 99.3540 | loss: 0.4358 | sparsity: 0.4680 | reactivation_rate: 0.0020
2025-08-28 04:47:14,601 - INFO -   Val:   acc1: 76.2300 | acc5: 97.7400 | loss: 0.7079
2025-08-28 04:47:14,601 - INFO -   LR: 0.100000
2025-08-28 04:47:14,611 - INFO - 
Epoch: 46, lr = 0.1
2025-08-28 04:47:14,793 - INFO - Epoch: [46][0/391] Time 0.181 (0.181) Data 0.148 (0.148) Loss 0.4047 (0.4047) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:47:16,477 - INFO - Pruning info: sparsity=0.471
2025-08-28 04:47:16,477 - INFO -   Reactivation rate: 0.0025
2025-08-28 04:47:16,637 - INFO - Epoch: [46][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4419 (0.4195) Acc@1 83.594 (85.636) Acc@5 98.438 (99.343)
2025-08-28 04:47:18,613 - INFO - Epoch: [46][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4023 (0.4373) Acc@1 89.844 (84.981) Acc@5 99.219 (99.363)
2025-08-28 04:47:19,627 - INFO - Pruning info: sparsity=0.471
2025-08-28 04:47:19,627 - INFO -   Reactivation rate: 0.0016
2025-08-28 04:47:20,541 - INFO - Epoch: [46][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.3349 (0.4361) Acc@1 89.062 (85.021) Acc@5 100.000 (99.356)
2025-08-28 04:47:22,488 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.7703 (0.7703) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 04:47:23,342 - INFO - Epoch 46:
2025-08-28 04:47:23,342 - INFO -   Train: acc1: 84.7880 | acc5: 99.3580 | loss: 0.4411 | sparsity: 0.4711 | reactivation_rate: 0.0020
2025-08-28 04:47:23,342 - INFO -   Val:   acc1: 78.8700 | acc5: 98.8800 | loss: 0.6804
2025-08-28 04:47:23,342 - INFO -   LR: 0.100000
2025-08-28 04:47:23,354 - INFO - 
Epoch: 47, lr = 0.1
2025-08-28 04:47:23,555 - INFO - Epoch: [47][0/391] Time 0.199 (0.199) Data 0.175 (0.175) Loss 0.5628 (0.5628) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 04:47:24,016 - INFO - Pruning info: sparsity=0.474
2025-08-28 04:47:24,017 - INFO -   Reactivation rate: 0.0033
2025-08-28 04:47:25,572 - INFO - Epoch: [47][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.3477 (0.4222) Acc@1 86.719 (85.682) Acc@5 100.000 (99.459)
2025-08-28 04:47:27,187 - INFO - Pruning info: sparsity=0.474
2025-08-28 04:47:27,188 - INFO -   Reactivation rate: 0.0019
2025-08-28 04:47:27,540 - INFO - Epoch: [47][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.5854 (0.4307) Acc@1 81.250 (85.156) Acc@5 99.219 (99.370)
2025-08-28 04:47:29,401 - INFO - Epoch: [47][300/391] Time 0.018 (0.020) Data 0.002 (0.002) Loss 0.4092 (0.4335) Acc@1 85.938 (85.130) Acc@5 100.000 (99.372)
2025-08-28 04:47:30,168 - INFO - Pruning info: sparsity=0.474
2025-08-28 04:47:30,168 - INFO -   Reactivation rate: 0.0014
2025-08-28 04:47:31,208 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6216 (0.6216) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 04:47:32,074 - INFO - Epoch 47:
2025-08-28 04:47:32,074 - INFO -   Train: acc1: 84.9880 | acc5: 99.3620 | loss: 0.4383 | sparsity: 0.4740 | reactivation_rate: 0.0019
2025-08-28 04:47:32,074 - INFO -   Val:   acc1: 77.8000 | acc5: 98.4700 | loss: 0.6893
2025-08-28 04:47:32,074 - INFO -   LR: 0.100000
2025-08-28 04:47:32,088 - INFO - 
Epoch: 48, lr = 0.1
2025-08-28 04:47:32,289 - INFO - Epoch: [48][0/391] Time 0.200 (0.200) Data 0.162 (0.162) Loss 0.4617 (0.4617) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 04:47:34,203 - INFO - Epoch: [48][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.5192 (0.4193) Acc@1 85.156 (85.644) Acc@5 99.219 (99.373)
2025-08-28 04:47:34,434 - INFO - Pruning info: sparsity=0.477
2025-08-28 04:47:34,434 - INFO -   Reactivation rate: 0.0021
2025-08-28 04:47:36,116 - INFO - Epoch: [48][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4360 (0.4197) Acc@1 82.031 (85.529) Acc@5 99.219 (99.374)
2025-08-28 04:47:37,427 - INFO - Pruning info: sparsity=0.477
2025-08-28 04:47:37,427 - INFO -   Reactivation rate: 0.0015
2025-08-28 04:47:38,007 - INFO - Epoch: [48][300/391] Time 0.038 (0.020) Data 0.022 (0.002) Loss 0.4019 (0.4290) Acc@1 89.062 (85.247) Acc@5 98.438 (99.346)
2025-08-28 04:47:39,797 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.7111 (0.7111) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 04:47:40,642 - INFO - Epoch 48:
2025-08-28 04:47:40,642 - INFO -   Train: acc1: 85.1220 | acc5: 99.3540 | loss: 0.4317 | sparsity: 0.4767 | reactivation_rate: 0.0018
2025-08-28 04:47:40,642 - INFO -   Val:   acc1: 73.7100 | acc5: 98.4600 | loss: 0.8447
2025-08-28 04:47:40,642 - INFO -   LR: 0.100000
2025-08-28 04:47:40,657 - INFO - 
Epoch: 49, lr = 0.1
2025-08-28 04:47:40,839 - INFO - Epoch: [49][0/391] Time 0.182 (0.182) Data 0.162 (0.162) Loss 0.5434 (0.5434) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 04:47:41,639 - INFO - Pruning info: sparsity=0.479
2025-08-28 04:47:41,639 - INFO -   Reactivation rate: 0.0027
2025-08-28 04:47:42,849 - INFO - Epoch: [49][100/391] Time 0.014 (0.022) Data 0.000 (0.003) Loss 0.4349 (0.4179) Acc@1 85.156 (85.597) Acc@5 100.000 (99.451)
2025-08-28 04:47:44,793 - INFO - Epoch: [49][200/391] Time 0.013 (0.021) Data 0.000 (0.002) Loss 0.3432 (0.4281) Acc@1 86.719 (85.164) Acc@5 100.000 (99.409)
2025-08-28 04:47:44,798 - INFO - Pruning info: sparsity=0.479
2025-08-28 04:47:44,799 - INFO -   Reactivation rate: 0.0017
2025-08-28 04:47:46,669 - INFO - Epoch: [49][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4350 (0.4357) Acc@1 86.719 (84.954) Acc@5 100.000 (99.369)
2025-08-28 04:47:47,892 - INFO - Pruning info: sparsity=0.479
2025-08-28 04:47:47,892 - INFO -   Reactivation rate: 0.0013
2025-08-28 04:47:48,590 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6081 (0.6081) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 04:47:49,436 - INFO - Epoch 49:
2025-08-28 04:47:49,436 - INFO -   Train: acc1: 84.9260 | acc5: 99.3360 | loss: 0.4367 | sparsity: 0.4792 | reactivation_rate: 0.0018
2025-08-28 04:47:49,436 - INFO -   Val:   acc1: 81.1600 | acc5: 99.0800 | loss: 0.5627
2025-08-28 04:47:49,437 - INFO -   LR: 0.100000
2025-08-28 04:47:49,447 - INFO - 
Epoch: 50, lr = 0.1
2025-08-28 04:47:49,644 - INFO - Epoch: [50][0/391] Time 0.194 (0.194) Data 0.168 (0.168) Loss 0.2822 (0.2822) Acc@1 92.188 (92.188) Acc@5 98.438 (98.438)
2025-08-28 04:47:51,587 - INFO - Epoch: [50][100/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.6431 (0.4228) Acc@1 81.250 (85.342) Acc@5 98.438 (99.412)
2025-08-28 04:47:52,128 - INFO - Pruning info: sparsity=0.481
2025-08-28 04:47:52,128 - INFO -   Reactivation rate: 0.0018
2025-08-28 04:47:53,510 - INFO - Epoch: [50][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2985 (0.4330) Acc@1 91.406 (85.051) Acc@5 99.219 (99.382)
2025-08-28 04:47:55,217 - INFO - Pruning info: sparsity=0.481
2025-08-28 04:47:55,217 - INFO -   Reactivation rate: 0.0014
2025-08-28 04:47:55,451 - INFO - Epoch: [50][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3725 (0.4317) Acc@1 83.594 (85.034) Acc@5 100.000 (99.411)
2025-08-28 04:47:57,340 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.8191 (0.8191) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 04:47:58,181 - INFO - Epoch 50:
2025-08-28 04:47:58,181 - INFO -   Train: acc1: 85.1040 | acc5: 99.3860 | loss: 0.4324 | sparsity: 0.4815 | reactivation_rate: 0.0017
2025-08-28 04:47:58,181 - INFO -   Val:   acc1: 77.3400 | acc5: 98.9600 | loss: 0.7447
2025-08-28 04:47:58,181 - INFO -   LR: 0.100000
2025-08-28 04:47:58,228 - INFO - 
Epoch: 51, lr = 0.1
2025-08-28 04:47:58,428 - INFO - Epoch: [51][0/391] Time 0.199 (0.199) Data 0.174 (0.174) Loss 0.5419 (0.5419) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:47:59,502 - INFO - Pruning info: sparsity=0.484
2025-08-28 04:47:59,502 - INFO -   Reactivation rate: 0.0023
2025-08-28 04:48:00,320 - INFO - Epoch: [51][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3688 (0.4187) Acc@1 86.719 (85.690) Acc@5 100.000 (99.435)
2025-08-28 04:48:02,242 - INFO - Epoch: [51][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.5035 (0.4335) Acc@1 82.812 (85.137) Acc@5 99.219 (99.401)
2025-08-28 04:48:02,606 - INFO - Pruning info: sparsity=0.484
2025-08-28 04:48:02,606 - INFO -   Reactivation rate: 0.0015
2025-08-28 04:48:04,119 - INFO - Epoch: [51][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3733 (0.4319) Acc@1 86.719 (85.190) Acc@5 99.219 (99.445)
2025-08-28 04:48:05,639 - INFO - Pruning info: sparsity=0.484
2025-08-28 04:48:05,639 - INFO -   Reactivation rate: 0.0011
2025-08-28 04:48:05,969 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6802 (0.6802) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 04:48:06,848 - INFO - Epoch 51:
2025-08-28 04:48:06,848 - INFO -   Train: acc1: 85.0940 | acc5: 99.4240 | loss: 0.4351 | sparsity: 0.4836 | reactivation_rate: 0.0016
2025-08-28 04:48:06,848 - INFO -   Val:   acc1: 75.4100 | acc5: 98.1900 | loss: 0.7461
2025-08-28 04:48:06,848 - INFO -   LR: 0.100000
2025-08-28 04:48:06,860 - INFO - 
Epoch: 52, lr = 0.1
2025-08-28 04:48:07,055 - INFO - Epoch: [52][0/391] Time 0.194 (0.194) Data 0.148 (0.148) Loss 0.4230 (0.4230) Acc@1 86.719 (86.719) Acc@5 97.656 (97.656)
2025-08-28 04:48:08,979 - INFO - Epoch: [52][100/391] Time 0.038 (0.021) Data 0.000 (0.002) Loss 0.3878 (0.4175) Acc@1 88.281 (86.139) Acc@5 99.219 (99.327)
2025-08-28 04:48:09,942 - INFO - Pruning info: sparsity=0.486
2025-08-28 04:48:09,942 - INFO -   Reactivation rate: 0.0016
2025-08-28 04:48:10,920 - INFO - Epoch: [52][200/391] Time 0.042 (0.020) Data 0.028 (0.002) Loss 0.4493 (0.4321) Acc@1 82.812 (85.471) Acc@5 100.000 (99.339)
2025-08-28 04:48:12,869 - INFO - Epoch: [52][300/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.4159 (0.4341) Acc@1 85.156 (85.250) Acc@5 99.219 (99.374)
2025-08-28 04:48:13,020 - INFO - Pruning info: sparsity=0.486
2025-08-28 04:48:13,020 - INFO -   Reactivation rate: 0.0012
2025-08-28 04:48:14,764 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.4953 (0.4953) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 04:48:15,667 - INFO - Epoch 52:
2025-08-28 04:48:15,667 - INFO -   Train: acc1: 85.2060 | acc5: 99.3780 | loss: 0.4360 | sparsity: 0.4856 | reactivation_rate: 0.0015
2025-08-28 04:48:15,667 - INFO -   Val:   acc1: 79.8000 | acc5: 99.0000 | loss: 0.6099
2025-08-28 04:48:15,667 - INFO -   LR: 0.100000
2025-08-28 04:48:15,680 - INFO - 
Epoch: 53, lr = 0.1
2025-08-28 04:48:15,872 - INFO - Epoch: [53][0/391] Time 0.191 (0.191) Data 0.166 (0.166) Loss 0.4290 (0.4290) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 04:48:17,295 - INFO - Pruning info: sparsity=0.487
2025-08-28 04:48:17,295 - INFO -   Reactivation rate: 0.0019
2025-08-28 04:48:17,749 - INFO - Epoch: [53][100/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4213 (0.4333) Acc@1 85.938 (85.156) Acc@5 99.219 (99.451)
2025-08-28 04:48:19,747 - INFO - Epoch: [53][200/391] Time 0.022 (0.020) Data 0.001 (0.002) Loss 0.4610 (0.4372) Acc@1 85.156 (84.911) Acc@5 99.219 (99.444)
2025-08-28 04:48:20,456 - INFO - Pruning info: sparsity=0.487
2025-08-28 04:48:20,456 - INFO -   Reactivation rate: 0.0013
2025-08-28 04:48:21,700 - INFO - Epoch: [53][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4027 (0.4381) Acc@1 83.594 (84.907) Acc@5 99.219 (99.406)
2025-08-28 04:48:23,529 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6936 (0.6936) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-28 04:48:24,392 - INFO - Epoch 53:
2025-08-28 04:48:24,392 - INFO -   Train: acc1: 84.8100 | acc5: 99.4060 | loss: 0.4399 | sparsity: 0.4874 | reactivation_rate: 0.0015
2025-08-28 04:48:24,392 - INFO -   Val:   acc1: 76.9500 | acc5: 98.7600 | loss: 0.6868
2025-08-28 04:48:24,392 - INFO -   LR: 0.100000
2025-08-28 04:48:24,404 - INFO - 
Epoch: 54, lr = 0.1
2025-08-28 04:48:24,605 - INFO - Epoch: [54][0/391] Time 0.200 (0.200) Data 0.175 (0.175) Loss 0.3803 (0.3803) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:48:24,717 - INFO - Pruning info: sparsity=0.489
2025-08-28 04:48:24,717 - INFO -   Reactivation rate: 0.0009
2025-08-28 04:48:26,498 - INFO - Epoch: [54][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.3611 (0.4256) Acc@1 87.500 (85.473) Acc@5 98.438 (99.366)
2025-08-28 04:48:27,776 - INFO - Pruning info: sparsity=0.489
2025-08-28 04:48:27,776 - INFO -   Reactivation rate: 0.0015
2025-08-28 04:48:28,396 - INFO - Epoch: [54][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.6155 (0.4254) Acc@1 78.125 (85.335) Acc@5 97.656 (99.398)
2025-08-28 04:48:30,352 - INFO - Epoch: [54][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5160 (0.4220) Acc@1 79.688 (85.398) Acc@5 98.438 (99.442)
2025-08-28 04:48:30,804 - INFO - Pruning info: sparsity=0.489
2025-08-28 04:48:30,804 - INFO -   Reactivation rate: 0.0011
2025-08-28 04:48:32,211 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6334 (0.6334) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:48:33,069 - INFO - Epoch 54:
2025-08-28 04:48:33,070 - INFO -   Train: acc1: 85.2980 | acc5: 99.4260 | loss: 0.4258 | sparsity: 0.4890 | reactivation_rate: 0.0014
2025-08-28 04:48:33,070 - INFO -   Val:   acc1: 77.1300 | acc5: 98.6300 | loss: 0.7190
2025-08-28 04:48:33,070 - INFO -   LR: 0.100000
2025-08-28 04:48:33,083 - INFO - 
Epoch: 55, lr = 0.1
2025-08-28 04:48:33,253 - INFO - Epoch: [55][0/391] Time 0.168 (0.168) Data 0.145 (0.145) Loss 0.3005 (0.3005) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:48:35,097 - INFO - Pruning info: sparsity=0.491
2025-08-28 04:48:35,097 - INFO -   Reactivation rate: 0.0017
2025-08-28 04:48:35,206 - INFO - Epoch: [55][100/391] Time 0.022 (0.021) Data 0.011 (0.003) Loss 0.5463 (0.4405) Acc@1 80.469 (84.731) Acc@5 99.219 (99.389)
2025-08-28 04:48:37,117 - INFO - Epoch: [55][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4401 (0.4346) Acc@1 84.375 (84.977) Acc@5 100.000 (99.405)
2025-08-28 04:48:38,116 - INFO - Pruning info: sparsity=0.491
2025-08-28 04:48:38,116 - INFO -   Reactivation rate: 0.0012
2025-08-28 04:48:38,938 - INFO - Epoch: [55][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4187 (0.4353) Acc@1 89.062 (84.936) Acc@5 100.000 (99.374)
2025-08-28 04:48:40,735 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7179 (0.7179) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-28 04:48:41,595 - INFO - Epoch 55:
2025-08-28 04:48:41,595 - INFO -   Train: acc1: 84.9660 | acc5: 99.3420 | loss: 0.4373 | sparsity: 0.4905 | reactivation_rate: 0.0013
2025-08-28 04:48:41,595 - INFO -   Val:   acc1: 75.4400 | acc5: 97.2200 | loss: 0.8203
2025-08-28 04:48:41,595 - INFO -   LR: 0.100000
2025-08-28 04:48:41,606 - INFO - 
Epoch: 56, lr = 0.1
2025-08-28 04:48:41,763 - INFO - Epoch: [56][0/391] Time 0.156 (0.156) Data 0.139 (0.139) Loss 0.3484 (0.3484) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 04:48:42,258 - INFO - Pruning info: sparsity=0.492
2025-08-28 04:48:42,258 - INFO -   Reactivation rate: 0.0020
2025-08-28 04:48:43,761 - INFO - Epoch: [56][100/391] Time 0.026 (0.021) Data 0.000 (0.003) Loss 0.4830 (0.4165) Acc@1 79.688 (85.535) Acc@5 98.438 (99.412)
2025-08-28 04:48:45,317 - INFO - Pruning info: sparsity=0.492
2025-08-28 04:48:45,318 - INFO -   Reactivation rate: 0.0012
2025-08-28 04:48:45,657 - INFO - Epoch: [56][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3919 (0.4253) Acc@1 87.500 (85.152) Acc@5 99.219 (99.417)
2025-08-28 04:48:47,601 - INFO - Epoch: [56][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4643 (0.4276) Acc@1 85.156 (85.141) Acc@5 100.000 (99.429)
2025-08-28 04:48:48,402 - INFO - Pruning info: sparsity=0.492
2025-08-28 04:48:48,402 - INFO -   Reactivation rate: 0.0009
2025-08-28 04:48:49,401 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.5092 (0.5092) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 04:48:50,272 - INFO - Epoch 56:
2025-08-28 04:48:50,272 - INFO -   Train: acc1: 85.1160 | acc5: 99.4160 | loss: 0.4281 | sparsity: 0.4919 | reactivation_rate: 0.0012
2025-08-28 04:48:50,272 - INFO -   Val:   acc1: 80.4300 | acc5: 99.1100 | loss: 0.5858
2025-08-28 04:48:50,272 - INFO -   LR: 0.100000
2025-08-28 04:48:50,283 - INFO - 
Epoch: 57, lr = 0.1
2025-08-28 04:48:50,461 - INFO - Epoch: [57][0/391] Time 0.177 (0.177) Data 0.146 (0.146) Loss 0.3314 (0.3314) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 04:48:52,382 - INFO - Epoch: [57][100/391] Time 0.018 (0.021) Data 0.003 (0.003) Loss 0.4246 (0.4308) Acc@1 83.594 (85.265) Acc@5 99.219 (99.428)
2025-08-28 04:48:52,634 - INFO - Pruning info: sparsity=0.493
2025-08-28 04:48:52,634 - INFO -   Reactivation rate: 0.0013
2025-08-28 04:48:54,240 - INFO - Epoch: [57][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4196 (0.4370) Acc@1 85.156 (84.904) Acc@5 100.000 (99.413)
2025-08-28 04:48:55,682 - INFO - Pruning info: sparsity=0.493
2025-08-28 04:48:55,683 - INFO -   Reactivation rate: 0.0010
2025-08-28 04:48:56,239 - INFO - Epoch: [57][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.4215 (0.4317) Acc@1 85.938 (85.141) Acc@5 100.000 (99.413)
2025-08-28 04:48:58,121 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.7098 (0.7098) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 04:48:58,956 - INFO - Epoch 57:
2025-08-28 04:48:58,956 - INFO -   Train: acc1: 85.1160 | acc5: 99.3840 | loss: 0.4312 | sparsity: 0.4931 | reactivation_rate: 0.0012
2025-08-28 04:48:58,956 - INFO -   Val:   acc1: 76.6600 | acc5: 98.3600 | loss: 0.7501
2025-08-28 04:48:58,956 - INFO -   LR: 0.100000
2025-08-28 04:48:58,967 - INFO - 
Epoch: 58, lr = 0.1
2025-08-28 04:48:59,159 - INFO - Epoch: [58][0/391] Time 0.191 (0.191) Data 0.166 (0.166) Loss 0.4989 (0.4989) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 04:48:59,962 - INFO - Pruning info: sparsity=0.494
2025-08-28 04:48:59,962 - INFO -   Reactivation rate: 0.0016
2025-08-28 04:49:01,143 - INFO - Epoch: [58][100/391] Time 0.024 (0.022) Data 0.000 (0.003) Loss 0.3769 (0.4364) Acc@1 88.281 (85.280) Acc@5 100.000 (99.358)
2025-08-28 04:49:02,986 - INFO - Epoch: [58][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4128 (0.4343) Acc@1 85.938 (85.316) Acc@5 99.219 (99.335)
2025-08-28 04:49:03,016 - INFO - Pruning info: sparsity=0.494
2025-08-28 04:49:03,016 - INFO -   Reactivation rate: 0.0011
2025-08-28 04:49:04,943 - INFO - Epoch: [58][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.4151 (0.4347) Acc@1 85.156 (85.200) Acc@5 99.219 (99.302)
2025-08-28 04:49:06,149 - INFO - Pruning info: sparsity=0.494
2025-08-28 04:49:06,149 - INFO -   Reactivation rate: 0.0009
2025-08-28 04:49:06,804 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5888 (0.5888) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 04:49:07,664 - INFO - Epoch 58:
2025-08-28 04:49:07,664 - INFO -   Train: acc1: 85.2560 | acc5: 99.3640 | loss: 0.4321 | sparsity: 0.4942 | reactivation_rate: 0.0012
2025-08-28 04:49:07,664 - INFO -   Val:   acc1: 79.7900 | acc5: 98.7900 | loss: 0.5950
2025-08-28 04:49:07,664 - INFO -   LR: 0.100000
2025-08-28 04:49:07,680 - INFO - 
Epoch: 59, lr = 0.1
2025-08-28 04:49:07,819 - INFO - Epoch: [59][0/391] Time 0.139 (0.139) Data 0.114 (0.114) Loss 0.4079 (0.4079) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 04:49:09,797 - INFO - Epoch: [59][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.4813 (0.4056) Acc@1 82.812 (86.231) Acc@5 96.875 (99.482)
2025-08-28 04:49:10,385 - INFO - Pruning info: sparsity=0.495
2025-08-28 04:49:10,385 - INFO -   Reactivation rate: 0.0012
2025-08-28 04:49:11,716 - INFO - Epoch: [59][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.5280 (0.4234) Acc@1 82.812 (85.518) Acc@5 98.438 (99.518)
2025-08-28 04:49:13,455 - INFO - Pruning info: sparsity=0.495
2025-08-28 04:49:13,455 - INFO -   Reactivation rate: 0.0009
2025-08-28 04:49:13,604 - INFO - Epoch: [59][300/391] Time 0.016 (0.020) Data 0.003 (0.001) Loss 0.4570 (0.4278) Acc@1 82.812 (85.294) Acc@5 99.219 (99.478)
2025-08-28 04:49:15,500 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6918 (0.6918) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-28 04:49:16,347 - INFO - Epoch 59:
2025-08-28 04:49:16,347 - INFO -   Train: acc1: 85.2560 | acc5: 99.4580 | loss: 0.4284 | sparsity: 0.4951 | reactivation_rate: 0.0011
2025-08-28 04:49:16,347 - INFO -   Val:   acc1: 74.5900 | acc5: 98.1800 | loss: 0.8066
2025-08-28 04:49:16,347 - INFO -   LR: 0.100000
2025-08-28 04:49:16,358 - INFO - 
Epoch: 60, lr = 0.1
2025-08-28 04:49:16,532 - INFO - Epoch: [60][0/391] Time 0.173 (0.173) Data 0.152 (0.152) Loss 0.4833 (0.4833) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 04:49:17,726 - INFO - Pruning info: sparsity=0.496
2025-08-28 04:49:17,726 - INFO -   Reactivation rate: 0.0013
2025-08-28 04:49:18,543 - INFO - Epoch: [60][100/391] Time 0.024 (0.022) Data 0.000 (0.003) Loss 0.3886 (0.4339) Acc@1 85.156 (84.994) Acc@5 99.219 (99.358)
2025-08-28 04:49:20,489 - INFO - Epoch: [60][200/391] Time 0.030 (0.021) Data 0.000 (0.002) Loss 0.4098 (0.4337) Acc@1 82.031 (84.974) Acc@5 100.000 (99.378)
2025-08-28 04:49:20,858 - INFO - Pruning info: sparsity=0.496
2025-08-28 04:49:20,858 - INFO -   Reactivation rate: 0.0009
2025-08-28 04:49:22,369 - INFO - Epoch: [60][300/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.5376 (0.4310) Acc@1 77.344 (85.042) Acc@5 99.219 (99.354)
2025-08-28 04:49:23,880 - INFO - Pruning info: sparsity=0.496
2025-08-28 04:49:23,881 - INFO -   Reactivation rate: 0.0007
2025-08-28 04:49:24,199 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4839 (0.4839) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 04:49:25,033 - INFO - Epoch 60:
2025-08-28 04:49:25,033 - INFO -   Train: acc1: 84.9040 | acc5: 99.3640 | loss: 0.4364 | sparsity: 0.4960 | reactivation_rate: 0.0010
2025-08-28 04:49:25,033 - INFO -   Val:   acc1: 82.0500 | acc5: 98.9100 | loss: 0.5415
2025-08-28 04:49:25,033 - INFO -   LR: 0.100000
2025-08-28 04:49:25,082 - INFO - Checkpoint saved: epoch=60, metric=82.0500
2025-08-28 04:49:25,118 - INFO - 
Epoch: 61, lr = 0.1
2025-08-28 04:49:25,316 - INFO - Epoch: [61][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.4790 (0.4790) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 04:49:27,176 - INFO - Epoch: [61][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5621 (0.4054) Acc@1 85.156 (86.154) Acc@5 100.000 (99.582)
2025-08-28 04:49:28,128 - INFO - Pruning info: sparsity=0.497
2025-08-28 04:49:28,129 - INFO -   Reactivation rate: 0.0010
2025-08-28 04:49:29,179 - INFO - Epoch: [61][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4371 (0.4277) Acc@1 87.500 (85.277) Acc@5 100.000 (99.491)
2025-08-28 04:49:31,108 - INFO - Epoch: [61][300/391] Time 0.040 (0.020) Data 0.012 (0.002) Loss 0.4373 (0.4247) Acc@1 84.375 (85.418) Acc@5 99.219 (99.445)
2025-08-28 04:49:31,258 - INFO - Pruning info: sparsity=0.497
2025-08-28 04:49:31,259 - INFO -   Reactivation rate: 0.0008
2025-08-28 04:49:33,058 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5538 (0.5538) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 04:49:33,940 - INFO - Epoch 61:
2025-08-28 04:49:33,940 - INFO -   Train: acc1: 85.0140 | acc5: 99.3800 | loss: 0.4360 | sparsity: 0.4967 | reactivation_rate: 0.0009
2025-08-28 04:49:33,940 - INFO -   Val:   acc1: 79.6000 | acc5: 98.8300 | loss: 0.6316
2025-08-28 04:49:33,940 - INFO -   LR: 0.100000
2025-08-28 04:49:33,952 - INFO - 
Epoch: 62, lr = 0.1
2025-08-28 04:49:34,132 - INFO - Epoch: [62][0/391] Time 0.179 (0.179) Data 0.154 (0.154) Loss 0.2775 (0.2775) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 04:49:35,600 - INFO - Pruning info: sparsity=0.497
2025-08-28 04:49:35,600 - INFO -   Reactivation rate: 0.0011
2025-08-28 04:49:35,962 - INFO - Epoch: [62][100/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3995 (0.4032) Acc@1 85.938 (85.883) Acc@5 99.219 (99.412)
2025-08-28 04:49:37,802 - INFO - Epoch: [62][200/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.3836 (0.4099) Acc@1 85.156 (85.910) Acc@5 99.219 (99.421)
2025-08-28 04:49:38,548 - INFO - Pruning info: sparsity=0.497
2025-08-28 04:49:38,548 - INFO -   Reactivation rate: 0.0008
2025-08-28 04:49:39,678 - INFO - Epoch: [62][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.3335 (0.4194) Acc@1 89.062 (85.597) Acc@5 100.000 (99.372)
2025-08-28 04:49:41,559 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5195 (0.5195) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:49:42,417 - INFO - Epoch 62:
2025-08-28 04:49:42,417 - INFO -   Train: acc1: 85.4340 | acc5: 99.3560 | loss: 0.4253 | sparsity: 0.4974 | reactivation_rate: 0.0009
2025-08-28 04:49:42,417 - INFO -   Val:   acc1: 79.0700 | acc5: 98.6400 | loss: 0.6393
2025-08-28 04:49:42,417 - INFO -   LR: 0.100000
2025-08-28 04:49:42,432 - INFO - 
Epoch: 63, lr = 0.1
2025-08-28 04:49:42,600 - INFO - Epoch: [63][0/391] Time 0.168 (0.168) Data 0.143 (0.143) Loss 0.4027 (0.4027) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 04:49:42,770 - INFO - Pruning info: sparsity=0.498
2025-08-28 04:49:42,770 - INFO -   Reactivation rate: 0.0006
2025-08-28 04:49:44,488 - INFO - Epoch: [63][100/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.4034 (0.4015) Acc@1 86.719 (86.231) Acc@5 100.000 (99.435)
2025-08-28 04:49:45,725 - INFO - Pruning info: sparsity=0.498
2025-08-28 04:49:45,726 - INFO -   Reactivation rate: 0.0008
2025-08-28 04:49:46,415 - INFO - Epoch: [63][200/391] Time 0.031 (0.020) Data 0.017 (0.004) Loss 0.4321 (0.4155) Acc@1 84.375 (85.786) Acc@5 100.000 (99.398)
2025-08-28 04:49:48,327 - INFO - Epoch: [63][300/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2430 (0.4246) Acc@1 89.844 (85.478) Acc@5 100.000 (99.369)
2025-08-28 04:49:48,797 - INFO - Pruning info: sparsity=0.498
2025-08-28 04:49:48,798 - INFO -   Reactivation rate: 0.0007
2025-08-28 04:49:50,170 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.8813 (0.8813) Acc@1 75.781 (75.781) Acc@5 97.656 (97.656)
2025-08-28 04:49:51,040 - INFO - Epoch 63:
2025-08-28 04:49:51,040 - INFO -   Train: acc1: 85.3180 | acc5: 99.3700 | loss: 0.4283 | sparsity: 0.4980 | reactivation_rate: 0.0008
2025-08-28 04:49:51,040 - INFO -   Val:   acc1: 76.9200 | acc5: 98.2700 | loss: 0.7820
2025-08-28 04:49:51,040 - INFO -   LR: 0.100000
2025-08-28 04:49:51,053 - INFO - 
Epoch: 64, lr = 0.1
2025-08-28 04:49:51,246 - INFO - Epoch: [64][0/391] Time 0.192 (0.192) Data 0.159 (0.159) Loss 0.2990 (0.2990) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 04:49:53,082 - INFO - Pruning info: sparsity=0.498
2025-08-28 04:49:53,082 - INFO -   Reactivation rate: 0.0008
2025-08-28 04:49:53,147 - INFO - Epoch: [64][100/391] Time 0.011 (0.021) Data 0.000 (0.005) Loss 0.3802 (0.4182) Acc@1 88.281 (85.705) Acc@5 100.000 (99.428)
2025-08-28 04:49:55,035 - INFO - Epoch: [64][200/391] Time 0.034 (0.020) Data 0.022 (0.004) Loss 0.4533 (0.4350) Acc@1 85.156 (84.989) Acc@5 100.000 (99.351)
2025-08-28 04:49:56,132 - INFO - Pruning info: sparsity=0.498
2025-08-28 04:49:56,132 - INFO -   Reactivation rate: 0.0007
2025-08-28 04:49:56,983 - INFO - Epoch: [64][300/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.5543 (0.4328) Acc@1 84.375 (85.050) Acc@5 98.438 (99.406)
2025-08-28 04:49:58,814 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.8967 (0.8967) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 04:49:59,647 - INFO - Epoch 64:
2025-08-28 04:49:59,647 - INFO -   Train: acc1: 85.2460 | acc5: 99.4120 | loss: 0.4281 | sparsity: 0.4984 | reactivation_rate: 0.0008
2025-08-28 04:49:59,647 - INFO -   Val:   acc1: 72.4700 | acc5: 98.2200 | loss: 0.9478
2025-08-28 04:49:59,647 - INFO -   LR: 0.100000
2025-08-28 04:49:59,660 - INFO - 
Epoch: 65, lr = 0.1
2025-08-28 04:49:59,836 - INFO - Epoch: [65][0/391] Time 0.174 (0.174) Data 0.152 (0.152) Loss 0.3654 (0.3654) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 04:50:00,317 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:00,318 - INFO -   Reactivation rate: 0.0009
2025-08-28 04:50:01,711 - INFO - Epoch: [65][100/391] Time 0.033 (0.020) Data 0.020 (0.003) Loss 0.4942 (0.4355) Acc@1 82.812 (84.855) Acc@5 99.219 (99.350)
2025-08-28 04:50:03,313 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:03,314 - INFO -   Reactivation rate: 0.0007
2025-08-28 04:50:03,617 - INFO - Epoch: [65][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3980 (0.4267) Acc@1 85.156 (85.222) Acc@5 100.000 (99.386)
2025-08-28 04:50:05,505 - INFO - Epoch: [65][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.4125 (0.4302) Acc@1 87.500 (85.032) Acc@5 99.219 (99.362)
2025-08-28 04:50:06,327 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:06,327 - INFO -   Reactivation rate: 0.0005
2025-08-28 04:50:07,335 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.7533 (0.7533) Acc@1 74.219 (74.219) Acc@5 98.438 (98.438)
2025-08-28 04:50:08,157 - INFO - Epoch 65:
2025-08-28 04:50:08,157 - INFO -   Train: acc1: 85.0920 | acc5: 99.3640 | loss: 0.4321 | sparsity: 0.4988 | reactivation_rate: 0.0007
2025-08-28 04:50:08,157 - INFO -   Val:   acc1: 74.9700 | acc5: 98.4000 | loss: 0.8643
2025-08-28 04:50:08,157 - INFO -   LR: 0.100000
2025-08-28 04:50:08,169 - INFO - 
Epoch: 66, lr = 0.1
2025-08-28 04:50:08,350 - INFO - Epoch: [66][0/391] Time 0.180 (0.180) Data 0.155 (0.155) Loss 0.3923 (0.3923) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:50:10,231 - INFO - Epoch: [66][100/391] Time 0.027 (0.020) Data 0.013 (0.004) Loss 0.3106 (0.4153) Acc@1 88.281 (85.984) Acc@5 100.000 (99.451)
2025-08-28 04:50:10,508 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:10,508 - INFO -   Reactivation rate: 0.0007
2025-08-28 04:50:12,217 - INFO - Epoch: [66][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5018 (0.4215) Acc@1 79.688 (85.662) Acc@5 99.219 (99.429)
2025-08-28 04:50:13,631 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:13,631 - INFO -   Reactivation rate: 0.0006
2025-08-28 04:50:14,153 - INFO - Epoch: [66][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.5206 (0.4330) Acc@1 82.031 (85.128) Acc@5 98.438 (99.442)
2025-08-28 04:50:16,007 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.4520 (0.4520) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:50:16,864 - INFO - Epoch 66:
2025-08-28 04:50:16,864 - INFO -   Train: acc1: 85.0940 | acc5: 99.4520 | loss: 0.4321 | sparsity: 0.4991 | reactivation_rate: 0.0006
2025-08-28 04:50:16,864 - INFO -   Val:   acc1: 79.7300 | acc5: 98.8600 | loss: 0.6093
2025-08-28 04:50:16,864 - INFO -   LR: 0.100000
2025-08-28 04:50:16,878 - INFO - 
Epoch: 67, lr = 0.1
2025-08-28 04:50:17,066 - INFO - Epoch: [67][0/391] Time 0.187 (0.187) Data 0.163 (0.163) Loss 0.3088 (0.3088) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 04:50:17,913 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:17,913 - INFO -   Reactivation rate: 0.0007
2025-08-28 04:50:19,098 - INFO - Epoch: [67][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.4019 (0.4119) Acc@1 85.156 (85.736) Acc@5 99.219 (99.513)
2025-08-28 04:50:21,104 - INFO - Epoch: [67][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.4150 (0.4336) Acc@1 83.594 (85.106) Acc@5 100.000 (99.444)
2025-08-28 04:50:21,157 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:21,157 - INFO -   Reactivation rate: 0.0006
2025-08-28 04:50:23,008 - INFO - Epoch: [67][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3783 (0.4296) Acc@1 86.719 (85.203) Acc@5 98.438 (99.447)
2025-08-28 04:50:24,191 - INFO - Pruning info: sparsity=0.499
2025-08-28 04:50:24,191 - INFO -   Reactivation rate: 0.0005
2025-08-28 04:50:24,820 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.7613 (0.7613) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 04:50:25,657 - INFO - Epoch 67:
2025-08-28 04:50:25,657 - INFO -   Train: acc1: 85.0040 | acc5: 99.4080 | loss: 0.4334 | sparsity: 0.4994 | reactivation_rate: 0.0006
2025-08-28 04:50:25,657 - INFO -   Val:   acc1: 78.8800 | acc5: 98.8900 | loss: 0.6559
2025-08-28 04:50:25,657 - INFO -   LR: 0.100000
2025-08-28 04:50:25,670 - INFO - 
Epoch: 68, lr = 0.1
2025-08-28 04:50:25,848 - INFO - Epoch: [68][0/391] Time 0.177 (0.177) Data 0.156 (0.156) Loss 0.3791 (0.3791) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 04:50:27,753 - INFO - Epoch: [68][100/391] Time 0.023 (0.021) Data 0.000 (0.003) Loss 0.5652 (0.4214) Acc@1 82.812 (86.038) Acc@5 99.219 (99.350)
2025-08-28 04:50:28,315 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:28,315 - INFO -   Reactivation rate: 0.0005
2025-08-28 04:50:29,655 - INFO - Epoch: [68][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.3804 (0.4224) Acc@1 87.500 (85.801) Acc@5 100.000 (99.351)
2025-08-28 04:50:31,423 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:31,423 - INFO -   Reactivation rate: 0.0005
2025-08-28 04:50:31,581 - INFO - Epoch: [68][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.5279 (0.4236) Acc@1 85.938 (85.621) Acc@5 98.438 (99.356)
2025-08-28 04:50:33,455 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.7278 (0.7278) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 04:50:34,303 - INFO - Epoch 68:
2025-08-28 04:50:34,304 - INFO -   Train: acc1: 85.5500 | acc5: 99.3680 | loss: 0.4247 | sparsity: 0.4996 | reactivation_rate: 0.0005
2025-08-28 04:50:34,304 - INFO -   Val:   acc1: 78.0300 | acc5: 98.5400 | loss: 0.7073
2025-08-28 04:50:34,304 - INFO -   LR: 0.100000
2025-08-28 04:50:34,317 - INFO - 
Epoch: 69, lr = 0.1
2025-08-28 04:50:34,474 - INFO - Epoch: [69][0/391] Time 0.155 (0.155) Data 0.136 (0.136) Loss 0.4308 (0.4308) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:50:35,701 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:35,701 - INFO -   Reactivation rate: 0.0006
2025-08-28 04:50:36,483 - INFO - Epoch: [69][100/391] Time 0.023 (0.021) Data 0.000 (0.005) Loss 0.3974 (0.4234) Acc@1 87.500 (85.319) Acc@5 99.219 (99.466)
2025-08-28 04:50:38,401 - INFO - Epoch: [69][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4233 (0.4195) Acc@1 82.812 (85.502) Acc@5 99.219 (99.491)
2025-08-28 04:50:38,790 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:38,790 - INFO -   Reactivation rate: 0.0005
2025-08-28 04:50:40,341 - INFO - Epoch: [69][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5378 (0.4258) Acc@1 84.375 (85.237) Acc@5 99.219 (99.483)
2025-08-28 04:50:41,882 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:41,882 - INFO -   Reactivation rate: 0.0004
2025-08-28 04:50:42,169 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.7806 (0.7806) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 04:50:43,042 - INFO - Epoch 69:
2025-08-28 04:50:43,042 - INFO -   Train: acc1: 85.1000 | acc5: 99.4580 | loss: 0.4297 | sparsity: 0.4997 | reactivation_rate: 0.0005
2025-08-28 04:50:43,042 - INFO -   Val:   acc1: 74.2700 | acc5: 98.7700 | loss: 0.8492
2025-08-28 04:50:43,042 - INFO -   LR: 0.100000
2025-08-28 04:50:43,055 - INFO - 
Epoch: 70, lr = 0.1
2025-08-28 04:50:43,224 - INFO - Epoch: [70][0/391] Time 0.168 (0.168) Data 0.150 (0.150) Loss 0.5473 (0.5473) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 04:50:45,236 - INFO - Epoch: [70][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.3686 (0.4099) Acc@1 87.500 (86.023) Acc@5 100.000 (99.381)
2025-08-28 04:50:46,177 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:46,177 - INFO -   Reactivation rate: 0.0004
2025-08-28 04:50:47,131 - INFO - Epoch: [70][200/391] Time 0.026 (0.020) Data 0.013 (0.002) Loss 0.3587 (0.4273) Acc@1 89.062 (85.261) Acc@5 100.000 (99.304)
2025-08-28 04:50:49,082 - INFO - Epoch: [70][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2963 (0.4269) Acc@1 90.625 (85.283) Acc@5 100.000 (99.362)
2025-08-28 04:50:49,254 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:49,254 - INFO -   Reactivation rate: 0.0004
2025-08-28 04:50:50,941 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.7472 (0.7472) Acc@1 71.875 (71.875) Acc@5 99.219 (99.219)
2025-08-28 04:50:51,787 - INFO - Epoch 70:
2025-08-28 04:50:51,788 - INFO -   Train: acc1: 85.2840 | acc5: 99.3900 | loss: 0.4262 | sparsity: 0.4999 | reactivation_rate: 0.0004
2025-08-28 04:50:51,788 - INFO -   Val:   acc1: 74.6800 | acc5: 98.4800 | loss: 0.8311
2025-08-28 04:50:51,788 - INFO -   LR: 0.100000
2025-08-28 04:50:51,835 - INFO - 
Epoch: 71, lr = 0.1
2025-08-28 04:50:52,022 - INFO - Epoch: [71][0/391] Time 0.186 (0.186) Data 0.151 (0.151) Loss 0.2582 (0.2582) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:50:53,462 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:53,462 - INFO -   Reactivation rate: 0.0004
2025-08-28 04:50:53,891 - INFO - Epoch: [71][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.3983 (0.4166) Acc@1 83.594 (85.481) Acc@5 99.219 (99.428)
2025-08-28 04:50:55,820 - INFO - Epoch: [71][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4109 (0.4242) Acc@1 85.156 (85.285) Acc@5 99.219 (99.448)
2025-08-28 04:50:56,540 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:50:56,540 - INFO -   Reactivation rate: 0.0004
2025-08-28 04:50:57,735 - INFO - Epoch: [71][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.3149 (0.4276) Acc@1 88.281 (85.244) Acc@5 100.000 (99.408)
2025-08-28 04:50:59,641 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.5536 (0.5536) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 04:51:00,492 - INFO - Epoch 71:
2025-08-28 04:51:00,492 - INFO -   Train: acc1: 85.0420 | acc5: 99.3760 | loss: 0.4309 | sparsity: 0.4999 | reactivation_rate: 0.0004
2025-08-28 04:51:00,492 - INFO -   Val:   acc1: 82.1000 | acc5: 99.1200 | loss: 0.5454
2025-08-28 04:51:00,492 - INFO -   LR: 0.100000
2025-08-28 04:51:00,540 - INFO - Checkpoint saved: epoch=71, metric=82.1000
2025-08-28 04:51:00,573 - INFO - 
Epoch: 72, lr = 0.1
2025-08-28 04:51:00,774 - INFO - Epoch: [72][0/391] Time 0.190 (0.190) Data 0.163 (0.163) Loss 0.4645 (0.4645) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 04:51:00,915 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:00,915 - INFO -   Reactivation rate: 0.0003
2025-08-28 04:51:02,759 - INFO - Epoch: [72][100/391] Time 0.022 (0.022) Data 0.000 (0.003) Loss 0.2704 (0.4108) Acc@1 92.188 (85.845) Acc@5 100.000 (99.536)
2025-08-28 04:51:04,128 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:04,128 - INFO -   Reactivation rate: 0.0003
2025-08-28 04:51:04,702 - INFO - Epoch: [72][200/391] Time 0.047 (0.020) Data 0.008 (0.002) Loss 0.4729 (0.4243) Acc@1 83.594 (85.389) Acc@5 100.000 (99.471)
2025-08-28 04:51:06,659 - INFO - Epoch: [72][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.5477 (0.4282) Acc@1 83.594 (85.359) Acc@5 98.438 (99.432)
2025-08-28 04:51:07,190 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:07,190 - INFO -   Reactivation rate: 0.0003
2025-08-28 04:51:08,503 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5352 (0.5352) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 04:51:09,346 - INFO - Epoch 72:
2025-08-28 04:51:09,347 - INFO -   Train: acc1: 85.2320 | acc5: 99.3920 | loss: 0.4303 | sparsity: 0.5000 | reactivation_rate: 0.0003
2025-08-28 04:51:09,347 - INFO -   Val:   acc1: 80.3300 | acc5: 98.9100 | loss: 0.6176
2025-08-28 04:51:09,347 - INFO -   LR: 0.100000
2025-08-28 04:51:09,362 - INFO - 
Epoch: 73, lr = 0.1
2025-08-28 04:51:09,535 - INFO - Epoch: [73][0/391] Time 0.172 (0.172) Data 0.155 (0.155) Loss 0.4179 (0.4179) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 04:51:11,376 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:11,376 - INFO -   Reactivation rate: 0.0003
2025-08-28 04:51:11,444 - INFO - Epoch: [73][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3013 (0.4065) Acc@1 90.625 (85.775) Acc@5 100.000 (99.489)
2025-08-28 04:51:13,389 - INFO - Epoch: [73][200/391] Time 0.023 (0.020) Data 0.004 (0.003) Loss 0.4425 (0.4215) Acc@1 84.375 (85.498) Acc@5 99.219 (99.429)
2025-08-28 04:51:14,447 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:14,447 - INFO -   Reactivation rate: 0.0003
2025-08-28 04:51:15,254 - INFO - Epoch: [73][300/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.3727 (0.4221) Acc@1 85.156 (85.499) Acc@5 99.219 (99.460)
2025-08-28 04:51:17,064 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5823 (0.5823) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 04:51:17,961 - INFO - Epoch 73:
2025-08-28 04:51:17,962 - INFO -   Train: acc1: 85.3860 | acc5: 99.4180 | loss: 0.4268 | sparsity: 0.5000 | reactivation_rate: 0.0003
2025-08-28 04:51:17,962 - INFO -   Val:   acc1: 77.3000 | acc5: 98.7100 | loss: 0.6968
2025-08-28 04:51:17,962 - INFO -   LR: 0.100000
2025-08-28 04:51:17,976 - INFO - 
Epoch: 74, lr = 0.1
2025-08-28 04:51:18,163 - INFO - Epoch: [74][0/391] Time 0.186 (0.186) Data 0.167 (0.167) Loss 0.4481 (0.4481) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 04:51:18,681 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:18,681 - INFO -   Reactivation rate: 0.0003
2025-08-28 04:51:20,267 - INFO - Epoch: [74][100/391] Time 0.026 (0.023) Data 0.000 (0.003) Loss 0.4559 (0.4239) Acc@1 86.719 (85.713) Acc@5 100.000 (99.350)
2025-08-28 04:51:21,994 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:21,994 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:22,238 - INFO - Epoch: [74][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.4918 (0.4243) Acc@1 80.469 (85.510) Acc@5 99.219 (99.359)
2025-08-28 04:51:24,059 - INFO - Epoch: [74][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3891 (0.4257) Acc@1 85.938 (85.452) Acc@5 99.219 (99.369)
2025-08-28 04:51:24,960 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:24,960 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:25,976 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6640 (0.6640) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 04:51:26,832 - INFO - Epoch 74:
2025-08-28 04:51:26,832 - INFO -   Train: acc1: 85.2960 | acc5: 99.3740 | loss: 0.4291 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-28 04:51:26,833 - INFO -   Val:   acc1: 76.3800 | acc5: 98.7800 | loss: 0.7081
2025-08-28 04:51:26,833 - INFO -   LR: 0.100000
2025-08-28 04:51:26,845 - INFO - 
Epoch: 75, lr = 0.1
2025-08-28 04:51:27,034 - INFO - Epoch: [75][0/391] Time 0.189 (0.189) Data 0.157 (0.157) Loss 0.3785 (0.3785) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:51:29,032 - INFO - Epoch: [75][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.4373 (0.4140) Acc@1 86.719 (85.845) Acc@5 98.438 (99.489)
2025-08-28 04:51:29,285 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:29,285 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:30,940 - INFO - Epoch: [75][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3596 (0.4223) Acc@1 88.281 (85.545) Acc@5 99.219 (99.382)
2025-08-28 04:51:32,412 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:32,413 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:32,874 - INFO - Epoch: [75][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.6267 (0.4278) Acc@1 78.906 (85.338) Acc@5 97.656 (99.390)
2025-08-28 04:51:34,705 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.6605 (0.6605) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 04:51:35,579 - INFO - Epoch 75:
2025-08-28 04:51:35,579 - INFO -   Train: acc1: 85.2780 | acc5: 99.3880 | loss: 0.4277 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-28 04:51:35,579 - INFO -   Val:   acc1: 76.2400 | acc5: 98.4600 | loss: 0.7501
2025-08-28 04:51:35,579 - INFO -   LR: 0.100000
2025-08-28 04:51:35,592 - INFO - 
Epoch: 76, lr = 0.1
2025-08-28 04:51:35,786 - INFO - Epoch: [76][0/391] Time 0.192 (0.192) Data 0.160 (0.160) Loss 0.4688 (0.4688) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 04:51:36,620 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:36,621 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:37,693 - INFO - Epoch: [76][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.3692 (0.4191) Acc@1 87.500 (85.721) Acc@5 100.000 (99.335)
2025-08-28 04:51:39,565 - INFO - Epoch: [76][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3805 (0.4216) Acc@1 89.844 (85.576) Acc@5 98.438 (99.382)
2025-08-28 04:51:39,638 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:39,638 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:41,547 - INFO - Epoch: [76][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4196 (0.4258) Acc@1 85.938 (85.364) Acc@5 100.000 (99.367)
2025-08-28 04:51:42,777 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:42,777 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:43,361 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6538 (0.6538) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 04:51:44,244 - INFO - Epoch 76:
2025-08-28 04:51:44,244 - INFO -   Train: acc1: 85.3780 | acc5: 99.3600 | loss: 0.4254 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-28 04:51:44,244 - INFO -   Val:   acc1: 77.9900 | acc5: 98.7300 | loss: 0.7232
2025-08-28 04:51:44,244 - INFO -   LR: 0.100000
2025-08-28 04:51:44,259 - INFO - 
Epoch: 77, lr = 0.1
2025-08-28 04:51:44,485 - INFO - Epoch: [77][0/391] Time 0.226 (0.226) Data 0.168 (0.168) Loss 0.3951 (0.3951) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 04:51:46,390 - INFO - Epoch: [77][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4359 (0.4226) Acc@1 85.938 (85.272) Acc@5 100.000 (99.451)
2025-08-28 04:51:47,044 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:47,045 - INFO -   Reactivation rate: 0.0002
2025-08-28 04:51:48,349 - INFO - Epoch: [77][200/391] Time 0.029 (0.020) Data 0.013 (0.002) Loss 0.4132 (0.4286) Acc@1 86.719 (84.904) Acc@5 100.000 (99.444)
2025-08-28 04:51:50,141 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:50,141 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:51:50,291 - INFO - Epoch: [77][300/391] Time 0.033 (0.020) Data 0.009 (0.003) Loss 0.4519 (0.4275) Acc@1 86.719 (85.045) Acc@5 99.219 (99.439)
2025-08-28 04:51:52,034 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.5552 (0.5552) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 04:51:52,907 - INFO - Epoch 77:
2025-08-28 04:51:52,908 - INFO -   Train: acc1: 84.9180 | acc5: 99.4340 | loss: 0.4322 | sparsity: 0.5000 | reactivation_rate: 0.0002
2025-08-28 04:51:52,908 - INFO -   Val:   acc1: 81.1800 | acc5: 98.8000 | loss: 0.5799
2025-08-28 04:51:52,908 - INFO -   LR: 0.100000
2025-08-28 04:51:52,921 - INFO - 
Epoch: 78, lr = 0.1
2025-08-28 04:51:53,112 - INFO - Epoch: [78][0/391] Time 0.190 (0.190) Data 0.160 (0.160) Loss 0.4656 (0.4656) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 04:51:54,326 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:54,326 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:51:55,092 - INFO - Epoch: [78][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.3988 (0.4074) Acc@1 85.938 (85.968) Acc@5 100.000 (99.497)
2025-08-28 04:51:56,950 - INFO - Epoch: [78][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4153 (0.4248) Acc@1 85.938 (85.424) Acc@5 100.000 (99.409)
2025-08-28 04:51:57,397 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:51:57,397 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:51:58,951 - INFO - Epoch: [78][300/391] Time 0.025 (0.020) Data 0.013 (0.002) Loss 0.4440 (0.4295) Acc@1 83.594 (85.242) Acc@5 100.000 (99.393)
2025-08-28 04:52:00,513 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:00,513 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:00,787 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.7251 (0.7251) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 04:52:01,624 - INFO - Epoch 78:
2025-08-28 04:52:01,624 - INFO -   Train: acc1: 85.2860 | acc5: 99.3820 | loss: 0.4305 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:01,624 - INFO -   Val:   acc1: 75.3300 | acc5: 98.9600 | loss: 0.7667
2025-08-28 04:52:01,624 - INFO -   LR: 0.100000
2025-08-28 04:52:01,638 - INFO - 
Epoch: 79, lr = 0.1
2025-08-28 04:52:01,812 - INFO - Epoch: [79][0/391] Time 0.173 (0.173) Data 0.148 (0.148) Loss 0.5657 (0.5657) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-28 04:52:03,641 - INFO - Epoch: [79][100/391] Time 0.028 (0.020) Data 0.013 (0.005) Loss 0.5429 (0.4237) Acc@1 78.906 (85.342) Acc@5 98.438 (99.381)
2025-08-28 04:52:04,586 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:04,586 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:05,540 - INFO - Epoch: [79][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3592 (0.4277) Acc@1 86.719 (85.253) Acc@5 100.000 (99.429)
2025-08-28 04:52:07,433 - INFO - Epoch: [79][300/391] Time 0.018 (0.019) Data 0.001 (0.003) Loss 0.4975 (0.4274) Acc@1 84.375 (85.385) Acc@5 100.000 (99.429)
2025-08-28 04:52:07,583 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:07,583 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:09,242 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6219 (0.6219) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 04:52:10,109 - INFO - Epoch 79:
2025-08-28 04:52:10,109 - INFO -   Train: acc1: 85.2200 | acc5: 99.4180 | loss: 0.4296 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:10,109 - INFO -   Val:   acc1: 80.4600 | acc5: 98.7900 | loss: 0.6329
2025-08-28 04:52:10,109 - INFO -   LR: 0.100000
2025-08-28 04:52:10,123 - INFO - 
Epoch: 80, lr = 0.1
2025-08-28 04:52:10,303 - INFO - Epoch: [80][0/391] Time 0.180 (0.180) Data 0.139 (0.139) Loss 0.4037 (0.4037) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 04:52:11,906 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:11,906 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:12,302 - INFO - Epoch: [80][100/391] Time 0.015 (0.022) Data 0.000 (0.002) Loss 0.5515 (0.4200) Acc@1 82.031 (85.435) Acc@5 97.656 (99.404)
2025-08-28 04:52:14,181 - INFO - Epoch: [80][200/391] Time 0.035 (0.020) Data 0.021 (0.002) Loss 0.3678 (0.4247) Acc@1 91.406 (85.514) Acc@5 99.219 (99.409)
2025-08-28 04:52:14,936 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:14,936 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:16,069 - INFO - Epoch: [80][300/391] Time 0.016 (0.020) Data 0.001 (0.002) Loss 0.4693 (0.4303) Acc@1 87.500 (85.294) Acc@5 98.438 (99.390)
2025-08-28 04:52:17,926 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.5732 (0.5732) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 04:52:18,804 - INFO - Epoch 80:
2025-08-28 04:52:18,804 - INFO -   Train: acc1: 85.1900 | acc5: 99.3780 | loss: 0.4330 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:18,804 - INFO -   Val:   acc1: 75.7000 | acc5: 99.3100 | loss: 0.7212
2025-08-28 04:52:18,804 - INFO -   LR: 0.100000
2025-08-28 04:52:18,854 - INFO - 
Epoch: 81, lr = 0.1
2025-08-28 04:52:19,047 - INFO - Epoch: [81][0/391] Time 0.192 (0.192) Data 0.165 (0.165) Loss 0.4225 (0.4225) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 04:52:19,170 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:19,170 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:20,930 - INFO - Epoch: [81][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.4492 (0.4189) Acc@1 83.594 (85.767) Acc@5 99.219 (99.466)
2025-08-28 04:52:22,251 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:22,251 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:22,871 - INFO - Epoch: [81][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3826 (0.4308) Acc@1 84.375 (85.250) Acc@5 100.000 (99.405)
2025-08-28 04:52:24,773 - INFO - Epoch: [81][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4260 (0.4317) Acc@1 83.594 (85.167) Acc@5 100.000 (99.367)
2025-08-28 04:52:25,300 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:25,300 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:26,592 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.5517 (0.5517) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 04:52:27,438 - INFO - Epoch 81:
2025-08-28 04:52:27,438 - INFO -   Train: acc1: 85.0900 | acc5: 99.3860 | loss: 0.4330 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:27,438 - INFO -   Val:   acc1: 81.5400 | acc5: 98.9500 | loss: 0.5484
2025-08-28 04:52:27,438 - INFO -   LR: 0.100000
2025-08-28 04:52:27,450 - INFO - 
Epoch: 82, lr = 0.1
2025-08-28 04:52:27,634 - INFO - Epoch: [82][0/391] Time 0.183 (0.183) Data 0.159 (0.159) Loss 0.4986 (0.4986) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 04:52:29,419 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:29,422 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:29,473 - INFO - Epoch: [82][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.4010 (0.4204) Acc@1 89.062 (85.775) Acc@5 98.438 (99.412)
2025-08-28 04:52:31,275 - INFO - Epoch: [82][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.3967 (0.4345) Acc@1 83.594 (85.071) Acc@5 100.000 (99.366)
2025-08-28 04:52:32,408 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:32,408 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:33,175 - INFO - Epoch: [82][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.5045 (0.4360) Acc@1 83.594 (84.988) Acc@5 100.000 (99.343)
2025-08-28 04:52:35,049 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.9410 (0.9410) Acc@1 69.531 (69.531) Acc@5 96.875 (96.875)
2025-08-28 04:52:35,923 - INFO - Epoch 82:
2025-08-28 04:52:35,923 - INFO -   Train: acc1: 85.0880 | acc5: 99.3740 | loss: 0.4324 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:35,923 - INFO -   Val:   acc1: 71.8900 | acc5: 98.0300 | loss: 0.8712
2025-08-28 04:52:35,923 - INFO -   LR: 0.100000
2025-08-28 04:52:35,937 - INFO - 
Epoch: 83, lr = 0.1
2025-08-28 04:52:36,121 - INFO - Epoch: [83][0/391] Time 0.183 (0.183) Data 0.162 (0.162) Loss 0.4369 (0.4369) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 04:52:36,620 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:36,620 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:38,134 - INFO - Epoch: [83][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.4147 (0.4229) Acc@1 84.375 (85.597) Acc@5 100.000 (99.420)
2025-08-28 04:52:39,826 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:39,826 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:40,098 - INFO - Epoch: [83][200/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.3916 (0.4215) Acc@1 85.938 (85.576) Acc@5 100.000 (99.394)
2025-08-28 04:52:41,999 - INFO - Epoch: [83][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.5561 (0.4298) Acc@1 84.375 (85.283) Acc@5 97.656 (99.359)
2025-08-28 04:52:42,891 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:42,892 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:43,871 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.7211 (0.7211) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 04:52:44,727 - INFO - Epoch 83:
2025-08-28 04:52:44,727 - INFO -   Train: acc1: 85.3380 | acc5: 99.3580 | loss: 0.4295 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:44,727 - INFO -   Val:   acc1: 77.1800 | acc5: 98.6000 | loss: 0.7165
2025-08-28 04:52:44,727 - INFO -   LR: 0.100000
2025-08-28 04:52:44,741 - INFO - 
Epoch: 84, lr = 0.1
2025-08-28 04:52:44,929 - INFO - Epoch: [84][0/391] Time 0.188 (0.188) Data 0.165 (0.165) Loss 0.4562 (0.4562) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 04:52:46,938 - INFO - Epoch: [84][100/391] Time 0.030 (0.022) Data 0.000 (0.004) Loss 0.4991 (0.4370) Acc@1 85.938 (85.087) Acc@5 99.219 (99.435)
2025-08-28 04:52:47,226 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:47,226 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:48,911 - INFO - Epoch: [84][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.4312 (0.4319) Acc@1 85.938 (85.137) Acc@5 99.219 (99.413)
2025-08-28 04:52:50,356 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:50,357 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:50,862 - INFO - Epoch: [84][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.3275 (0.4268) Acc@1 89.062 (85.309) Acc@5 99.219 (99.406)
2025-08-28 04:52:52,674 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.6178 (0.6178) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 04:52:53,495 - INFO - Epoch 84:
2025-08-28 04:52:53,496 - INFO -   Train: acc1: 85.1620 | acc5: 99.3600 | loss: 0.4310 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:52:53,496 - INFO -   Val:   acc1: 77.0600 | acc5: 99.0500 | loss: 0.6890
2025-08-28 04:52:53,496 - INFO -   LR: 0.100000
2025-08-28 04:52:53,510 - INFO - 
Epoch: 85, lr = 0.1
2025-08-28 04:52:53,691 - INFO - Epoch: [85][0/391] Time 0.179 (0.179) Data 0.156 (0.156) Loss 0.5017 (0.5017) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 04:52:54,509 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:54,509 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:55,597 - INFO - Epoch: [85][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.4946 (0.4307) Acc@1 81.250 (85.079) Acc@5 98.438 (99.343)
2025-08-28 04:52:57,445 - INFO - Epoch: [85][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3887 (0.4244) Acc@1 87.500 (85.312) Acc@5 99.219 (99.363)
2025-08-28 04:52:57,516 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:52:57,517 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:52:59,366 - INFO - Epoch: [85][300/391] Time 0.017 (0.019) Data 0.001 (0.002) Loss 0.4635 (0.4253) Acc@1 85.938 (85.359) Acc@5 99.219 (99.354)
2025-08-28 04:53:00,656 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:00,657 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:01,265 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5269 (0.5269) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 04:53:02,154 - INFO - Epoch 85:
2025-08-28 04:53:02,154 - INFO -   Train: acc1: 85.2720 | acc5: 99.3480 | loss: 0.4283 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:02,154 - INFO -   Val:   acc1: 79.4800 | acc5: 98.8000 | loss: 0.5989
2025-08-28 04:53:02,154 - INFO -   LR: 0.100000
2025-08-28 04:53:02,169 - INFO - 
Epoch: 86, lr = 0.1
2025-08-28 04:53:02,351 - INFO - Epoch: [86][0/391] Time 0.181 (0.181) Data 0.156 (0.156) Loss 0.2712 (0.2712) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 04:53:04,264 - INFO - Epoch: [86][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.5047 (0.4224) Acc@1 86.719 (85.791) Acc@5 98.438 (99.474)
2025-08-28 04:53:04,875 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:04,875 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:06,139 - INFO - Epoch: [86][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4319 (0.4222) Acc@1 85.156 (85.479) Acc@5 99.219 (99.475)
2025-08-28 04:53:07,894 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:07,894 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:08,011 - INFO - Epoch: [86][300/391] Time 0.018 (0.019) Data 0.002 (0.003) Loss 0.4806 (0.4265) Acc@1 84.375 (85.278) Acc@5 100.000 (99.463)
2025-08-28 04:53:09,854 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.5020 (0.5020) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 04:53:10,721 - INFO - Epoch 86:
2025-08-28 04:53:10,721 - INFO -   Train: acc1: 85.3500 | acc5: 99.4200 | loss: 0.4255 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:10,721 - INFO -   Val:   acc1: 81.2100 | acc5: 99.1100 | loss: 0.5791
2025-08-28 04:53:10,721 - INFO -   LR: 0.100000
2025-08-28 04:53:10,735 - INFO - 
Epoch: 87, lr = 0.1
2025-08-28 04:53:10,921 - INFO - Epoch: [87][0/391] Time 0.184 (0.184) Data 0.155 (0.155) Loss 0.4148 (0.4148) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 04:53:12,097 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:12,097 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:12,776 - INFO - Epoch: [87][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2905 (0.4190) Acc@1 89.062 (85.976) Acc@5 100.000 (99.389)
2025-08-28 04:53:14,618 - INFO - Epoch: [87][200/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2728 (0.4291) Acc@1 92.969 (85.374) Acc@5 100.000 (99.444)
2025-08-28 04:53:15,051 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:15,051 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:16,448 - INFO - Epoch: [87][300/391] Time 0.031 (0.019) Data 0.000 (0.002) Loss 0.5209 (0.4266) Acc@1 81.250 (85.403) Acc@5 99.219 (99.411)
2025-08-28 04:53:18,040 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:18,040 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:18,296 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5453 (0.5453) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 04:53:19,180 - INFO - Epoch 87:
2025-08-28 04:53:19,180 - INFO -   Train: acc1: 85.1900 | acc5: 99.4100 | loss: 0.4281 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:19,180 - INFO -   Val:   acc1: 80.9500 | acc5: 99.0100 | loss: 0.5647
2025-08-28 04:53:19,180 - INFO -   LR: 0.100000
2025-08-28 04:53:19,193 - INFO - 
Epoch: 88, lr = 0.1
2025-08-28 04:53:19,388 - INFO - Epoch: [88][0/391] Time 0.194 (0.194) Data 0.172 (0.172) Loss 0.4450 (0.4450) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 04:53:21,278 - INFO - Epoch: [88][100/391] Time 0.020 (0.021) Data 0.004 (0.003) Loss 0.5005 (0.4362) Acc@1 82.031 (85.032) Acc@5 100.000 (99.435)
2025-08-28 04:53:22,214 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:22,214 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:23,138 - INFO - Epoch: [88][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.4077 (0.4259) Acc@1 84.375 (85.211) Acc@5 99.219 (99.409)
2025-08-28 04:53:25,067 - INFO - Epoch: [88][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.5619 (0.4234) Acc@1 82.031 (85.307) Acc@5 100.000 (99.398)
2025-08-28 04:53:25,278 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:25,279 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:26,895 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.7667 (0.7667) Acc@1 75.000 (75.000) Acc@5 100.000 (100.000)
2025-08-28 04:53:27,728 - INFO - Epoch 88:
2025-08-28 04:53:27,728 - INFO -   Train: acc1: 85.1980 | acc5: 99.4140 | loss: 0.4266 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:27,728 - INFO -   Val:   acc1: 75.3400 | acc5: 98.5900 | loss: 0.7597
2025-08-28 04:53:27,728 - INFO -   LR: 0.100000
2025-08-28 04:53:27,741 - INFO - 
Epoch: 89, lr = 0.1
2025-08-28 04:53:27,932 - INFO - Epoch: [89][0/391] Time 0.190 (0.190) Data 0.167 (0.167) Loss 0.4050 (0.4050) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 04:53:29,552 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:29,552 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:29,967 - INFO - Epoch: [89][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.5152 (0.4122) Acc@1 80.469 (85.876) Acc@5 100.000 (99.420)
2025-08-28 04:53:31,964 - INFO - Epoch: [89][200/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.3705 (0.4221) Acc@1 86.719 (85.568) Acc@5 100.000 (99.471)
2025-08-28 04:53:32,768 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:32,769 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:33,948 - INFO - Epoch: [89][300/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.5639 (0.4263) Acc@1 79.688 (85.416) Acc@5 99.219 (99.439)
2025-08-28 04:53:35,766 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6095 (0.6095) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 04:53:36,601 - INFO - Epoch 89:
2025-08-28 04:53:36,602 - INFO -   Train: acc1: 85.3560 | acc5: 99.4380 | loss: 0.4282 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:36,602 - INFO -   Val:   acc1: 79.5800 | acc5: 99.0700 | loss: 0.6154
2025-08-28 04:53:36,602 - INFO -   LR: 0.100000
2025-08-28 04:53:36,616 - INFO - 
Epoch: 90, lr = 0.1
2025-08-28 04:53:36,796 - INFO - Epoch: [90][0/391] Time 0.180 (0.180) Data 0.152 (0.152) Loss 0.4697 (0.4697) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 04:53:37,008 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:37,008 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:38,712 - INFO - Epoch: [90][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.5879 (0.4274) Acc@1 82.031 (85.551) Acc@5 98.438 (99.312)
2025-08-28 04:53:40,024 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:40,024 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:40,620 - INFO - Epoch: [90][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.4510 (0.4242) Acc@1 88.281 (85.456) Acc@5 99.219 (99.394)
2025-08-28 04:53:42,467 - INFO - Epoch: [90][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5131 (0.4233) Acc@1 83.594 (85.426) Acc@5 99.219 (99.442)
2025-08-28 04:53:43,124 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:43,124 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:44,413 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.8594 (0.8594) Acc@1 70.312 (70.312) Acc@5 99.219 (99.219)
2025-08-28 04:53:45,248 - INFO - Epoch 90:
2025-08-28 04:53:45,249 - INFO -   Train: acc1: 85.3800 | acc5: 99.4300 | loss: 0.4245 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:45,249 - INFO -   Val:   acc1: 72.1600 | acc5: 98.0200 | loss: 0.9125
2025-08-28 04:53:45,249 - INFO -   LR: 0.100000
2025-08-28 04:53:45,299 - INFO - 
Epoch: 91, lr = 0.1
2025-08-28 04:53:45,486 - INFO - Epoch: [91][0/391] Time 0.186 (0.186) Data 0.154 (0.154) Loss 0.4321 (0.4321) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 04:53:47,519 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:47,520 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:47,553 - INFO - Epoch: [91][100/391] Time 0.015 (0.022) Data 0.000 (0.004) Loss 0.5476 (0.4102) Acc@1 85.156 (85.907) Acc@5 97.656 (99.575)
2025-08-28 04:53:49,427 - INFO - Epoch: [91][200/391] Time 0.017 (0.021) Data 0.001 (0.003) Loss 0.4377 (0.4232) Acc@1 85.938 (85.537) Acc@5 99.219 (99.421)
2025-08-28 04:53:50,546 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:50,546 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:51,315 - INFO - Epoch: [91][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.3937 (0.4265) Acc@1 85.156 (85.400) Acc@5 100.000 (99.377)
2025-08-28 04:53:53,128 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5704 (0.5704) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 04:53:54,015 - INFO - Epoch 91:
2025-08-28 04:53:54,015 - INFO -   Train: acc1: 85.1840 | acc5: 99.3720 | loss: 0.4318 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:53:54,015 - INFO -   Val:   acc1: 79.7800 | acc5: 99.1700 | loss: 0.6227
2025-08-28 04:53:54,016 - INFO -   LR: 0.100000
2025-08-28 04:53:54,028 - INFO - 
Epoch: 92, lr = 0.1
2025-08-28 04:53:54,224 - INFO - Epoch: [92][0/391] Time 0.196 (0.196) Data 0.166 (0.166) Loss 0.4320 (0.4320) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 04:53:54,747 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:54,747 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:56,309 - INFO - Epoch: [92][100/391] Time 0.016 (0.023) Data 0.000 (0.004) Loss 0.5244 (0.4202) Acc@1 83.594 (85.760) Acc@5 100.000 (99.335)
2025-08-28 04:53:57,953 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:53:57,954 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:53:58,189 - INFO - Epoch: [92][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.2809 (0.4192) Acc@1 89.844 (85.494) Acc@5 100.000 (99.405)
2025-08-28 04:54:00,083 - INFO - Epoch: [92][300/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.3480 (0.4237) Acc@1 90.625 (85.392) Acc@5 100.000 (99.372)
2025-08-28 04:54:01,012 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:01,012 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:54:01,986 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.5067 (0.5067) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 04:54:02,847 - INFO - Epoch 92:
2025-08-28 04:54:02,847 - INFO -   Train: acc1: 85.2660 | acc5: 99.3820 | loss: 0.4281 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:54:02,847 - INFO -   Val:   acc1: 79.9800 | acc5: 99.1800 | loss: 0.5810
2025-08-28 04:54:02,847 - INFO -   LR: 0.100000
2025-08-28 04:54:02,945 - INFO - 
Epoch: 93, lr = 0.1
2025-08-28 04:54:03,147 - INFO - Epoch: [93][0/391] Time 0.201 (0.201) Data 0.175 (0.175) Loss 0.4098 (0.4098) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 04:54:05,138 - INFO - Epoch: [93][100/391] Time 0.026 (0.022) Data 0.015 (0.003) Loss 0.2846 (0.4304) Acc@1 92.188 (85.257) Acc@5 100.000 (99.389)
2025-08-28 04:54:05,466 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:05,466 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:54:06,960 - INFO - Epoch: [93][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3556 (0.4265) Acc@1 86.719 (85.331) Acc@5 100.000 (99.382)
2025-08-28 04:54:08,461 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:08,461 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:54:08,933 - INFO - Epoch: [93][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4364 (0.4277) Acc@1 85.938 (85.244) Acc@5 98.438 (99.385)
2025-08-28 04:54:10,750 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.7534 (0.7534) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 04:54:11,631 - INFO - Epoch 93:
2025-08-28 04:54:11,632 - INFO -   Train: acc1: 85.1120 | acc5: 99.3660 | loss: 0.4313 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:54:11,632 - INFO -   Val:   acc1: 75.6500 | acc5: 97.0100 | loss: 0.7595
2025-08-28 04:54:11,632 - INFO -   LR: 0.100000
2025-08-28 04:54:11,646 - INFO - 
Epoch: 94, lr = 0.1
2025-08-28 04:54:11,955 - INFO - Epoch: [94][0/391] Time 0.308 (0.308) Data 0.279 (0.279) Loss 0.4965 (0.4965) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 04:54:12,959 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:12,959 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:54:14,029 - INFO - Epoch: [94][100/391] Time 0.021 (0.024) Data 0.003 (0.004) Loss 0.3535 (0.4145) Acc@1 89.844 (85.667) Acc@5 100.000 (99.381)
2025-08-28 04:54:15,900 - INFO - Epoch: [94][200/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3592 (0.4232) Acc@1 85.156 (85.300) Acc@5 99.219 (99.436)
2025-08-28 04:54:16,025 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:16,025 - INFO -   Reactivation rate: 0.0001
2025-08-28 04:54:17,801 - INFO - Epoch: [94][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4587 (0.4215) Acc@1 86.719 (85.457) Acc@5 98.438 (99.450)
2025-08-28 04:54:19,050 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:19,050 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:19,668 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.8089 (0.8089) Acc@1 71.875 (71.875) Acc@5 96.094 (96.094)
2025-08-28 04:54:20,534 - INFO - Epoch 94:
2025-08-28 04:54:20,534 - INFO -   Train: acc1: 85.2720 | acc5: 99.4080 | loss: 0.4290 | sparsity: 0.5000 | reactivation_rate: 0.0001
2025-08-28 04:54:20,534 - INFO -   Val:   acc1: 74.6400 | acc5: 97.5200 | loss: 0.7861
2025-08-28 04:54:20,534 - INFO -   LR: 0.100000
2025-08-28 04:54:20,553 - INFO - 
Epoch: 95, lr = 0.1
2025-08-28 04:54:20,751 - INFO - Epoch: [95][0/391] Time 0.197 (0.197) Data 0.174 (0.174) Loss 0.3351 (0.3351) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 04:54:22,726 - INFO - Epoch: [95][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.5930 (0.4170) Acc@1 78.125 (86.023) Acc@5 100.000 (99.335)
2025-08-28 04:54:23,336 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:23,336 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:24,617 - INFO - Epoch: [95][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.5497 (0.4229) Acc@1 81.250 (85.599) Acc@5 100.000 (99.398)
2025-08-28 04:54:26,432 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:26,432 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:26,542 - INFO - Epoch: [95][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3595 (0.4280) Acc@1 88.281 (85.463) Acc@5 100.000 (99.385)
2025-08-28 04:54:28,431 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5303 (0.5303) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 04:54:29,288 - INFO - Epoch 95:
2025-08-28 04:54:29,288 - INFO -   Train: acc1: 85.5300 | acc5: 99.4040 | loss: 0.4253 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:54:29,288 - INFO -   Val:   acc1: 76.7400 | acc5: 98.2400 | loss: 0.7264
2025-08-28 04:54:29,288 - INFO -   LR: 0.100000
2025-08-28 04:54:29,304 - INFO - 
Epoch: 96, lr = 0.1
2025-08-28 04:54:29,476 - INFO - Epoch: [96][0/391] Time 0.171 (0.171) Data 0.137 (0.137) Loss 0.4830 (0.4830) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 04:54:30,798 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:30,798 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:31,538 - INFO - Epoch: [96][100/391] Time 0.025 (0.022) Data 0.001 (0.002) Loss 0.4034 (0.4257) Acc@1 86.719 (84.886) Acc@5 100.000 (99.482)
2025-08-28 04:54:33,581 - INFO - Epoch: [96][200/391] Time 0.035 (0.021) Data 0.013 (0.002) Loss 0.6180 (0.4329) Acc@1 76.562 (84.888) Acc@5 99.219 (99.394)
2025-08-28 04:54:34,085 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:34,085 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:35,623 - INFO - Epoch: [96][300/391] Time 0.019 (0.021) Data 0.000 (0.001) Loss 0.3661 (0.4393) Acc@1 88.281 (84.710) Acc@5 99.219 (99.387)
2025-08-28 04:54:37,206 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:37,207 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:37,460 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3295 (0.3295) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 04:54:38,332 - INFO - Epoch 96:
2025-08-28 04:54:38,332 - INFO -   Train: acc1: 84.9240 | acc5: 99.4100 | loss: 0.4358 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:54:38,332 - INFO -   Val:   acc1: 84.2800 | acc5: 99.1500 | loss: 0.4751
2025-08-28 04:54:38,333 - INFO -   LR: 0.100000
2025-08-28 04:54:38,384 - INFO - Checkpoint saved: epoch=96, metric=84.2800
2025-08-28 04:54:38,415 - INFO - 
Epoch: 97, lr = 0.1
2025-08-28 04:54:38,601 - INFO - Epoch: [97][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.3774 (0.3774) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 04:54:40,537 - INFO - Epoch: [97][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4470 (0.4098) Acc@1 82.812 (85.613) Acc@5 100.000 (99.497)
2025-08-28 04:54:41,489 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:41,489 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:42,367 - INFO - Epoch: [97][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4324 (0.4246) Acc@1 85.938 (85.195) Acc@5 99.219 (99.479)
2025-08-28 04:54:44,283 - INFO - Epoch: [97][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.3591 (0.4270) Acc@1 85.156 (85.115) Acc@5 99.219 (99.421)
2025-08-28 04:54:44,504 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:44,504 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:46,071 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.8050 (0.8050) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 04:54:46,934 - INFO - Epoch 97:
2025-08-28 04:54:46,934 - INFO -   Train: acc1: 85.0240 | acc5: 99.3880 | loss: 0.4314 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:54:46,935 - INFO -   Val:   acc1: 76.4400 | acc5: 98.7200 | loss: 0.7499
2025-08-28 04:54:46,935 - INFO -   LR: 0.100000
2025-08-28 04:54:46,949 - INFO - 
Epoch: 98, lr = 0.1
2025-08-28 04:54:47,135 - INFO - Epoch: [98][0/391] Time 0.185 (0.185) Data 0.164 (0.164) Loss 0.4750 (0.4750) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 04:54:48,696 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:48,696 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:49,068 - INFO - Epoch: [98][100/391] Time 0.034 (0.021) Data 0.000 (0.003) Loss 0.3591 (0.4103) Acc@1 86.719 (85.999) Acc@5 99.219 (99.513)
2025-08-28 04:54:50,976 - INFO - Epoch: [98][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.5541 (0.4172) Acc@1 78.906 (85.805) Acc@5 98.438 (99.436)
2025-08-28 04:54:51,818 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:51,819 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:53,057 - INFO - Epoch: [98][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3954 (0.4208) Acc@1 85.156 (85.686) Acc@5 99.219 (99.421)
2025-08-28 04:54:54,963 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.8108 (0.8108) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 04:54:55,880 - INFO - Epoch 98:
2025-08-28 04:54:55,880 - INFO -   Train: acc1: 85.5240 | acc5: 99.4100 | loss: 0.4236 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:54:55,880 - INFO -   Val:   acc1: 74.4000 | acc5: 97.2600 | loss: 0.8512
2025-08-28 04:54:55,880 - INFO -   LR: 0.100000
2025-08-28 04:54:55,896 - INFO - 
Epoch: 99, lr = 0.1
2025-08-28 04:54:56,098 - INFO - Epoch: [99][0/391] Time 0.201 (0.201) Data 0.172 (0.172) Loss 0.4539 (0.4539) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 04:54:56,286 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:56,286 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:58,038 - INFO - Epoch: [99][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.5265 (0.4322) Acc@1 85.156 (85.118) Acc@5 99.219 (99.373)
2025-08-28 04:54:59,354 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:54:59,354 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:54:59,891 - INFO - Epoch: [99][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2928 (0.4390) Acc@1 92.188 (85.036) Acc@5 100.000 (99.394)
2025-08-28 04:55:01,791 - INFO - Epoch: [99][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3644 (0.4370) Acc@1 88.281 (85.180) Acc@5 99.219 (99.369)
2025-08-28 04:55:02,385 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:02,385 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:03,704 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5431 (0.5431) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 04:55:04,531 - INFO - Epoch 99:
2025-08-28 04:55:04,531 - INFO -   Train: acc1: 85.1660 | acc5: 99.3760 | loss: 0.4355 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:04,531 - INFO -   Val:   acc1: 80.2200 | acc5: 98.9300 | loss: 0.6023
2025-08-28 04:55:04,531 - INFO -   LR: 0.010000
2025-08-28 04:55:04,544 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-28 04:55:04,729 - INFO - Epoch: [100][0/391] Time 0.184 (0.184) Data 0.165 (0.165) Loss 0.3576 (0.3576) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-28 04:55:06,748 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:06,748 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:06,765 - INFO - Epoch: [100][100/391] Time 0.026 (0.022) Data 0.000 (0.003) Loss 0.2393 (0.3390) Acc@1 91.406 (88.274) Acc@5 100.000 (99.652)
2025-08-28 04:55:08,623 - INFO - Epoch: [100][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3576 (0.3190) Acc@1 87.500 (89.148) Acc@5 98.438 (99.689)
2025-08-28 04:55:09,761 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:09,761 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:10,552 - INFO - Epoch: [100][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2224 (0.3057) Acc@1 92.188 (89.623) Acc@5 100.000 (99.722)
2025-08-28 04:55:12,395 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2093 (0.2093) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:55:13,244 - INFO - Epoch 100:
2025-08-28 04:55:13,244 - INFO -   Train: acc1: 89.9720 | acc5: 99.7160 | loss: 0.2961 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:13,244 - INFO -   Val:   acc1: 89.5300 | acc5: 99.7100 | loss: 0.3084
2025-08-28 04:55:13,244 - INFO -   LR: 0.010000
2025-08-28 04:55:13,294 - INFO - Checkpoint saved: epoch=100, metric=89.5300
2025-08-28 04:55:13,326 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-28 04:55:13,507 - INFO - Epoch: [101][0/391] Time 0.180 (0.180) Data 0.163 (0.163) Loss 0.3075 (0.3075) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 04:55:14,069 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:14,069 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:15,510 - INFO - Epoch: [101][100/391] Time 0.011 (0.022) Data 0.000 (0.003) Loss 0.1748 (0.2494) Acc@1 96.094 (91.623) Acc@5 100.000 (99.807)
2025-08-28 04:55:17,255 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:17,255 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:17,480 - INFO - Epoch: [101][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.1629 (0.2481) Acc@1 94.531 (91.612) Acc@5 99.219 (99.802)
2025-08-28 04:55:19,329 - INFO - Epoch: [101][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2658 (0.2470) Acc@1 89.844 (91.523) Acc@5 100.000 (99.805)
2025-08-28 04:55:20,320 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:20,320 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:21,247 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2177 (0.2177) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 04:55:22,083 - INFO - Epoch 101:
2025-08-28 04:55:22,083 - INFO -   Train: acc1: 91.5100 | acc5: 99.7960 | loss: 0.2478 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:22,083 - INFO -   Val:   acc1: 89.9600 | acc5: 99.6900 | loss: 0.3013
2025-08-28 04:55:22,083 - INFO -   LR: 0.010000
2025-08-28 04:55:22,132 - INFO - Checkpoint saved: epoch=101, metric=89.9600
2025-08-28 04:55:22,164 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-28 04:55:22,349 - INFO - Epoch: [102][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.2369 (0.2369) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:55:24,242 - INFO - Epoch: [102][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.2470 (0.2384) Acc@1 91.406 (92.110) Acc@5 100.000 (99.807)
2025-08-28 04:55:24,584 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:24,584 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:26,121 - INFO - Epoch: [102][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1738 (0.2348) Acc@1 93.750 (92.153) Acc@5 100.000 (99.821)
2025-08-28 04:55:27,482 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:27,482 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:27,960 - INFO - Epoch: [102][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.2132 (0.2327) Acc@1 92.969 (92.164) Acc@5 100.000 (99.826)
2025-08-28 04:55:29,845 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2169 (0.2169) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:55:30,683 - INFO - Epoch 102:
2025-08-28 04:55:30,683 - INFO -   Train: acc1: 92.2880 | acc5: 99.8220 | loss: 0.2301 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:30,683 - INFO -   Val:   acc1: 89.9700 | acc5: 99.6700 | loss: 0.3017
2025-08-28 04:55:30,683 - INFO -   LR: 0.010000
2025-08-28 04:55:30,734 - INFO - Checkpoint saved: epoch=102, metric=89.9700
2025-08-28 04:55:30,765 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-28 04:55:30,959 - INFO - Epoch: [103][0/391] Time 0.194 (0.194) Data 0.163 (0.163) Loss 0.3602 (0.3602) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 04:55:31,834 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:31,834 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:32,873 - INFO - Epoch: [103][100/391] Time 0.027 (0.021) Data 0.000 (0.003) Loss 0.2300 (0.2148) Acc@1 92.969 (92.729) Acc@5 99.219 (99.783)
2025-08-28 04:55:34,838 - INFO - Epoch: [103][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2905 (0.2190) Acc@1 92.188 (92.545) Acc@5 100.000 (99.798)
2025-08-28 04:55:34,960 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:34,960 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:36,679 - INFO - Epoch: [103][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3688 (0.2184) Acc@1 90.625 (92.587) Acc@5 98.438 (99.795)
2025-08-28 04:55:37,931 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:37,931 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:38,459 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2125 (0.2125) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:55:39,316 - INFO - Epoch 103:
2025-08-28 04:55:39,316 - INFO -   Train: acc1: 92.5720 | acc5: 99.8060 | loss: 0.2186 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:39,316 - INFO -   Val:   acc1: 89.8800 | acc5: 99.7300 | loss: 0.2968
2025-08-28 04:55:39,316 - INFO -   LR: 0.010000
2025-08-28 04:55:39,329 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-28 04:55:39,509 - INFO - Epoch: [104][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.2136 (0.2136) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:55:41,438 - INFO - Epoch: [104][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.1483 (0.2033) Acc@1 95.312 (93.031) Acc@5 100.000 (99.853)
2025-08-28 04:55:42,130 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:42,130 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:43,329 - INFO - Epoch: [104][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2229 (0.2064) Acc@1 92.969 (92.922) Acc@5 100.000 (99.845)
2025-08-28 04:55:45,164 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:45,165 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:45,259 - INFO - Epoch: [104][300/391] Time 0.028 (0.020) Data 0.000 (0.001) Loss 0.1764 (0.2072) Acc@1 93.750 (92.855) Acc@5 100.000 (99.834)
2025-08-28 04:55:47,124 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2073 (0.2073) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:55:47,970 - INFO - Epoch 104:
2025-08-28 04:55:47,970 - INFO -   Train: acc1: 92.6900 | acc5: 99.8380 | loss: 0.2102 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:47,970 - INFO -   Val:   acc1: 90.2200 | acc5: 99.7100 | loss: 0.2921
2025-08-28 04:55:47,970 - INFO -   LR: 0.010000
2025-08-28 04:55:48,021 - INFO - Checkpoint saved: epoch=104, metric=90.2200
2025-08-28 04:55:48,052 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-28 04:55:48,241 - INFO - Epoch: [105][0/391] Time 0.188 (0.188) Data 0.154 (0.154) Loss 0.1698 (0.1698) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 04:55:49,535 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:49,535 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:50,201 - INFO - Epoch: [105][100/391] Time 0.026 (0.021) Data 0.006 (0.003) Loss 0.1722 (0.1955) Acc@1 93.750 (93.479) Acc@5 100.000 (99.853)
2025-08-28 04:55:52,148 - INFO - Epoch: [105][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.1290 (0.2006) Acc@1 95.312 (93.249) Acc@5 100.000 (99.883)
2025-08-28 04:55:52,629 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:52,629 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:54,031 - INFO - Epoch: [105][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1724 (0.2029) Acc@1 93.750 (93.070) Acc@5 100.000 (99.881)
2025-08-28 04:55:55,648 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:55,648 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:55:55,945 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.1847 (0.1847) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 04:55:56,796 - INFO - Epoch 105:
2025-08-28 04:55:56,796 - INFO -   Train: acc1: 93.0820 | acc5: 99.8760 | loss: 0.2029 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:55:56,796 - INFO -   Val:   acc1: 90.0400 | acc5: 99.6900 | loss: 0.2979
2025-08-28 04:55:56,796 - INFO -   LR: 0.010000
2025-08-28 04:55:56,811 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-28 04:55:57,005 - INFO - Epoch: [106][0/391] Time 0.194 (0.194) Data 0.172 (0.172) Loss 0.1283 (0.1283) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 04:55:58,947 - INFO - Epoch: [106][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1018 (0.1902) Acc@1 98.438 (93.595) Acc@5 100.000 (99.876)
2025-08-28 04:55:59,891 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:55:59,891 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:00,769 - INFO - Epoch: [106][200/391] Time 0.030 (0.020) Data 0.005 (0.002) Loss 0.1671 (0.1902) Acc@1 93.750 (93.486) Acc@5 100.000 (99.880)
2025-08-28 04:56:02,716 - INFO - Epoch: [106][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3373 (0.1935) Acc@1 87.500 (93.376) Acc@5 98.438 (99.868)
2025-08-28 04:56:02,975 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:02,975 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:04,652 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.1729 (0.1729) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:56:05,540 - INFO - Epoch 106:
2025-08-28 04:56:05,540 - INFO -   Train: acc1: 93.1480 | acc5: 99.8680 | loss: 0.1992 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:05,540 - INFO -   Val:   acc1: 90.4500 | acc5: 99.7500 | loss: 0.2833
2025-08-28 04:56:05,540 - INFO -   LR: 0.010000
2025-08-28 04:56:05,591 - INFO - Checkpoint saved: epoch=106, metric=90.4500
2025-08-28 04:56:05,623 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-28 04:56:05,812 - INFO - Epoch: [107][0/391] Time 0.189 (0.189) Data 0.149 (0.149) Loss 0.1563 (0.1563) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:56:07,390 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:07,390 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:07,716 - INFO - Epoch: [107][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.1282 (0.1902) Acc@1 96.094 (93.812) Acc@5 100.000 (99.861)
2025-08-28 04:56:09,596 - INFO - Epoch: [107][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3098 (0.1903) Acc@1 90.625 (93.579) Acc@5 100.000 (99.868)
2025-08-28 04:56:10,453 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:10,453 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:11,599 - INFO - Epoch: [107][300/391] Time 0.026 (0.020) Data 0.000 (0.001) Loss 0.2188 (0.1909) Acc@1 92.969 (93.519) Acc@5 100.000 (99.875)
2025-08-28 04:56:13,469 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2173 (0.2173) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 04:56:14,338 - INFO - Epoch 107:
2025-08-28 04:56:14,338 - INFO -   Train: acc1: 93.3900 | acc5: 99.8660 | loss: 0.1948 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:14,339 - INFO -   Val:   acc1: 90.4200 | acc5: 99.7200 | loss: 0.2876
2025-08-28 04:56:14,339 - INFO -   LR: 0.010000
2025-08-28 04:56:14,352 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-28 04:56:14,539 - INFO - Epoch: [108][0/391] Time 0.186 (0.186) Data 0.163 (0.163) Loss 0.1163 (0.1163) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 04:56:14,744 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:14,744 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:16,436 - INFO - Epoch: [108][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.2051 (0.1825) Acc@1 89.844 (93.727) Acc@5 100.000 (99.876)
2025-08-28 04:56:17,799 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:17,799 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:18,263 - INFO - Epoch: [108][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2040 (0.1865) Acc@1 91.406 (93.696) Acc@5 100.000 (99.872)
2025-08-28 04:56:20,099 - INFO - Epoch: [108][300/391] Time 0.028 (0.019) Data 0.012 (0.002) Loss 0.1662 (0.1867) Acc@1 96.094 (93.708) Acc@5 100.000 (99.865)
2025-08-28 04:56:20,633 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:20,634 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:21,976 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.2602 (0.2602) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:56:22,834 - INFO - Epoch 108:
2025-08-28 04:56:22,834 - INFO -   Train: acc1: 93.6620 | acc5: 99.8760 | loss: 0.1872 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:22,834 - INFO -   Val:   acc1: 90.4200 | acc5: 99.7500 | loss: 0.2933
2025-08-28 04:56:22,835 - INFO -   LR: 0.010000
2025-08-28 04:56:22,849 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-28 04:56:23,018 - INFO - Epoch: [109][0/391] Time 0.168 (0.168) Data 0.139 (0.139) Loss 0.1578 (0.1578) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:56:24,989 - INFO - Epoch: [109][100/391] Time 0.028 (0.021) Data 0.000 (0.002) Loss 0.1649 (0.1838) Acc@1 94.531 (93.564) Acc@5 99.219 (99.907)
2025-08-28 04:56:24,994 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:24,995 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:26,832 - INFO - Epoch: [109][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1496 (0.1798) Acc@1 93.750 (93.738) Acc@5 100.000 (99.883)
2025-08-28 04:56:27,985 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:27,985 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:28,772 - INFO - Epoch: [109][300/391] Time 0.027 (0.020) Data 0.000 (0.002) Loss 0.2579 (0.1828) Acc@1 90.625 (93.683) Acc@5 100.000 (99.881)
2025-08-28 04:56:30,589 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.1762 (0.1762) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:56:31,426 - INFO - Epoch 109:
2025-08-28 04:56:31,426 - INFO -   Train: acc1: 93.6820 | acc5: 99.8800 | loss: 0.1839 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:31,426 - INFO -   Val:   acc1: 90.5300 | acc5: 99.7500 | loss: 0.2875
2025-08-28 04:56:31,427 - INFO -   LR: 0.010000
2025-08-28 04:56:31,476 - INFO - Checkpoint saved: epoch=109, metric=90.5300
2025-08-28 04:56:31,507 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-28 04:56:31,687 - INFO - Epoch: [110][0/391] Time 0.179 (0.179) Data 0.159 (0.159) Loss 0.1410 (0.1410) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 04:56:32,262 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:32,262 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:33,637 - INFO - Epoch: [110][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1685 (0.1759) Acc@1 93.750 (94.028) Acc@5 100.000 (99.884)
2025-08-28 04:56:35,226 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:35,226 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:35,419 - INFO - Epoch: [110][200/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.1880 (0.1779) Acc@1 93.750 (94.010) Acc@5 100.000 (99.907)
2025-08-28 04:56:37,326 - INFO - Epoch: [110][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.2178 (0.1795) Acc@1 92.188 (93.888) Acc@5 100.000 (99.886)
2025-08-28 04:56:38,290 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:38,291 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:39,126 - INFO - Test: [0/79] Time 0.100 (0.100) Loss 0.2339 (0.2339) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:56:39,985 - INFO - Epoch 110:
2025-08-28 04:56:39,986 - INFO -   Train: acc1: 93.8940 | acc5: 99.8840 | loss: 0.1802 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:39,986 - INFO -   Val:   acc1: 90.2400 | acc5: 99.6900 | loss: 0.2938
2025-08-28 04:56:39,986 - INFO -   LR: 0.010000
2025-08-28 04:56:40,038 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-28 04:56:40,216 - INFO - Epoch: [111][0/391] Time 0.177 (0.177) Data 0.147 (0.147) Loss 0.1379 (0.1379) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 04:56:42,277 - INFO - Epoch: [111][100/391] Time 0.014 (0.022) Data 0.000 (0.003) Loss 0.1926 (0.1713) Acc@1 92.969 (94.291) Acc@5 100.000 (99.923)
2025-08-28 04:56:42,645 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:42,645 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:44,175 - INFO - Epoch: [111][200/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.1610 (0.1770) Acc@1 93.750 (94.131) Acc@5 100.000 (99.911)
2025-08-28 04:56:45,685 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:45,686 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:46,105 - INFO - Epoch: [111][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2051 (0.1778) Acc@1 94.531 (94.017) Acc@5 100.000 (99.896)
2025-08-28 04:56:47,883 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.1780 (0.1780) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:56:48,731 - INFO - Epoch 111:
2025-08-28 04:56:48,731 - INFO -   Train: acc1: 94.0020 | acc5: 99.9040 | loss: 0.1771 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:48,731 - INFO -   Val:   acc1: 90.2000 | acc5: 99.7000 | loss: 0.3076
2025-08-28 04:56:48,731 - INFO -   LR: 0.010000
2025-08-28 04:56:48,749 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-28 04:56:48,930 - INFO - Epoch: [112][0/391] Time 0.178 (0.178) Data 0.136 (0.136) Loss 0.1515 (0.1515) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:56:49,818 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:49,818 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:50,857 - INFO - Epoch: [112][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.1878 (0.1708) Acc@1 90.625 (94.067) Acc@5 100.000 (99.907)
2025-08-28 04:56:52,681 - INFO - Epoch: [112][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1725 (0.1682) Acc@1 93.750 (94.197) Acc@5 100.000 (99.934)
2025-08-28 04:56:52,835 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:52,835 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:54,629 - INFO - Epoch: [112][300/391] Time 0.024 (0.020) Data 0.012 (0.003) Loss 0.1529 (0.1699) Acc@1 92.969 (94.069) Acc@5 100.000 (99.925)
2025-08-28 04:56:55,944 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:56:55,945 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:56:56,482 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.1962 (0.1962) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:56:57,378 - INFO - Epoch 112:
2025-08-28 04:56:57,378 - INFO -   Train: acc1: 93.9100 | acc5: 99.9040 | loss: 0.1748 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:56:57,378 - INFO -   Val:   acc1: 90.1300 | acc5: 99.7500 | loss: 0.2996
2025-08-28 04:56:57,378 - INFO -   LR: 0.010000
2025-08-28 04:56:57,394 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-28 04:56:57,580 - INFO - Epoch: [113][0/391] Time 0.185 (0.185) Data 0.169 (0.169) Loss 0.1721 (0.1721) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:56:59,601 - INFO - Epoch: [113][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.1629 (0.1660) Acc@1 94.531 (94.469) Acc@5 100.000 (99.907)
2025-08-28 04:57:00,310 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:00,311 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:01,538 - INFO - Epoch: [113][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.1659 (0.1688) Acc@1 92.969 (94.349) Acc@5 100.000 (99.903)
2025-08-28 04:57:03,340 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:03,340 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:03,416 - INFO - Epoch: [113][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1981 (0.1690) Acc@1 93.750 (94.238) Acc@5 100.000 (99.917)
2025-08-28 04:57:05,274 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2139 (0.2139) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:57:06,123 - INFO - Epoch 113:
2025-08-28 04:57:06,124 - INFO -   Train: acc1: 94.0380 | acc5: 99.9020 | loss: 0.1734 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:06,124 - INFO -   Val:   acc1: 89.9300 | acc5: 99.7200 | loss: 0.3112
2025-08-28 04:57:06,124 - INFO -   LR: 0.010000
2025-08-28 04:57:06,140 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-28 04:57:06,331 - INFO - Epoch: [114][0/391] Time 0.190 (0.190) Data 0.168 (0.168) Loss 0.1071 (0.1071) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 04:57:07,571 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:07,571 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:08,276 - INFO - Epoch: [114][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.2432 (0.1672) Acc@1 92.969 (94.330) Acc@5 99.219 (99.923)
2025-08-28 04:57:10,291 - INFO - Epoch: [114][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.2013 (0.1708) Acc@1 93.750 (94.111) Acc@5 100.000 (99.903)
2025-08-28 04:57:10,795 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:10,795 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:12,299 - INFO - Epoch: [114][300/391] Time 0.031 (0.020) Data 0.014 (0.002) Loss 0.0960 (0.1709) Acc@1 97.656 (94.160) Acc@5 100.000 (99.901)
2025-08-28 04:57:14,014 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:14,015 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:14,213 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.2560 (0.2560) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 04:57:15,102 - INFO - Epoch 114:
2025-08-28 04:57:15,102 - INFO -   Train: acc1: 94.0680 | acc5: 99.9020 | loss: 0.1741 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:15,102 - INFO -   Val:   acc1: 89.8900 | acc5: 99.7300 | loss: 0.3166
2025-08-28 04:57:15,102 - INFO -   LR: 0.010000
2025-08-28 04:57:15,117 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-28 04:57:15,313 - INFO - Epoch: [115][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.1881 (0.1881) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 04:57:17,336 - INFO - Epoch: [115][100/391] Time 0.021 (0.022) Data 0.000 (0.004) Loss 0.2782 (0.1537) Acc@1 92.188 (95.158) Acc@5 99.219 (99.923)
2025-08-28 04:57:18,394 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:18,394 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:19,264 - INFO - Epoch: [115][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.1847 (0.1622) Acc@1 93.750 (94.578) Acc@5 100.000 (99.922)
2025-08-28 04:57:21,155 - INFO - Epoch: [115][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.1457 (0.1671) Acc@1 94.531 (94.342) Acc@5 100.000 (99.920)
2025-08-28 04:57:21,454 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:21,454 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:23,060 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2089 (0.2089) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:57:23,910 - INFO - Epoch 115:
2025-08-28 04:57:23,910 - INFO -   Train: acc1: 94.1960 | acc5: 99.9260 | loss: 0.1698 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:23,910 - INFO -   Val:   acc1: 90.3900 | acc5: 99.7200 | loss: 0.2974
2025-08-28 04:57:23,910 - INFO -   LR: 0.010000
2025-08-28 04:57:23,927 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-28 04:57:24,135 - INFO - Epoch: [116][0/391] Time 0.207 (0.207) Data 0.175 (0.175) Loss 0.2067 (0.2067) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:57:25,784 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:25,784 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:26,128 - INFO - Epoch: [116][100/391] Time 0.028 (0.022) Data 0.000 (0.003) Loss 0.2009 (0.1633) Acc@1 93.750 (94.384) Acc@5 98.438 (99.923)
2025-08-28 04:57:28,039 - INFO - Epoch: [116][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1853 (0.1666) Acc@1 96.875 (94.232) Acc@5 99.219 (99.895)
2025-08-28 04:57:28,880 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:28,880 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:29,993 - INFO - Epoch: [116][300/391] Time 0.033 (0.020) Data 0.009 (0.002) Loss 0.1782 (0.1665) Acc@1 93.750 (94.228) Acc@5 100.000 (99.896)
2025-08-28 04:57:31,873 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.1709 (0.1709) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:57:32,771 - INFO - Epoch 116:
2025-08-28 04:57:32,771 - INFO -   Train: acc1: 94.1220 | acc5: 99.8980 | loss: 0.1685 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:32,771 - INFO -   Val:   acc1: 90.1200 | acc5: 99.7000 | loss: 0.3053
2025-08-28 04:57:32,771 - INFO -   LR: 0.010000
2025-08-28 04:57:32,787 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-28 04:57:32,956 - INFO - Epoch: [117][0/391] Time 0.168 (0.168) Data 0.150 (0.150) Loss 0.1828 (0.1828) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:57:33,224 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:33,224 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:34,999 - INFO - Epoch: [117][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.1234 (0.1629) Acc@1 96.875 (94.454) Acc@5 100.000 (99.954)
2025-08-28 04:57:36,390 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:36,390 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:36,850 - INFO - Epoch: [117][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.2460 (0.1676) Acc@1 92.188 (94.255) Acc@5 99.219 (99.914)
2025-08-28 04:57:38,806 - INFO - Epoch: [117][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.2116 (0.1660) Acc@1 90.625 (94.272) Acc@5 100.000 (99.922)
2025-08-28 04:57:39,442 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:39,442 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:40,619 - INFO - Test: [0/79] Time 0.107 (0.107) Loss 0.1829 (0.1829) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:57:41,511 - INFO - Epoch 117:
2025-08-28 04:57:41,511 - INFO -   Train: acc1: 94.2000 | acc5: 99.9240 | loss: 0.1684 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:41,511 - INFO -   Val:   acc1: 89.9700 | acc5: 99.7100 | loss: 0.3146
2025-08-28 04:57:41,511 - INFO -   LR: 0.010000
2025-08-28 04:57:41,524 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-28 04:57:41,710 - INFO - Epoch: [118][0/391] Time 0.185 (0.185) Data 0.166 (0.166) Loss 0.1267 (0.1267) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:57:43,711 - INFO - Epoch: [118][100/391] Time 0.025 (0.022) Data 0.001 (0.004) Loss 0.2100 (0.1638) Acc@1 89.844 (94.423) Acc@5 100.000 (99.915)
2025-08-28 04:57:43,741 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:43,741 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:45,618 - INFO - Epoch: [118][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.1503 (0.1644) Acc@1 94.531 (94.399) Acc@5 100.000 (99.922)
2025-08-28 04:57:46,771 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:46,771 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:47,526 - INFO - Epoch: [118][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1951 (0.1658) Acc@1 92.188 (94.370) Acc@5 100.000 (99.917)
2025-08-28 04:57:49,402 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.1631 (0.1631) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 04:57:50,270 - INFO - Epoch 118:
2025-08-28 04:57:50,270 - INFO -   Train: acc1: 94.2720 | acc5: 99.9100 | loss: 0.1679 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:50,271 - INFO -   Val:   acc1: 89.4200 | acc5: 99.6400 | loss: 0.3260
2025-08-28 04:57:50,271 - INFO -   LR: 0.010000
2025-08-28 04:57:50,285 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-28 04:57:50,465 - INFO - Epoch: [119][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.1218 (0.1218) Acc@1 97.656 (97.656) Acc@5 99.219 (99.219)
2025-08-28 04:57:50,989 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:50,989 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:52,373 - INFO - Epoch: [119][100/391] Time 0.011 (0.021) Data 0.000 (0.002) Loss 0.0871 (0.1621) Acc@1 97.656 (94.346) Acc@5 100.000 (99.938)
2025-08-28 04:57:54,073 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:54,074 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:54,258 - INFO - Epoch: [119][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1384 (0.1685) Acc@1 96.875 (94.162) Acc@5 100.000 (99.918)
2025-08-28 04:57:56,109 - INFO - Epoch: [119][300/391] Time 0.013 (0.019) Data 0.000 (0.001) Loss 0.2358 (0.1670) Acc@1 92.969 (94.176) Acc@5 100.000 (99.917)
2025-08-28 04:57:57,121 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:57:57,121 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:57:58,024 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2529 (0.2529) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:57:58,851 - INFO - Epoch 119:
2025-08-28 04:57:58,852 - INFO -   Train: acc1: 94.1960 | acc5: 99.9140 | loss: 0.1671 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:57:58,852 - INFO -   Val:   acc1: 89.9400 | acc5: 99.6200 | loss: 0.3236
2025-08-28 04:57:58,852 - INFO -   LR: 0.010000
2025-08-28 04:57:58,867 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-28 04:57:59,083 - INFO - Epoch: [120][0/391] Time 0.215 (0.215) Data 0.185 (0.185) Loss 0.1723 (0.1723) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:58:00,989 - INFO - Epoch: [120][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.1063 (0.1566) Acc@1 96.094 (94.585) Acc@5 100.000 (99.892)
2025-08-28 04:58:01,359 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:01,360 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:02,913 - INFO - Epoch: [120][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1302 (0.1589) Acc@1 95.312 (94.547) Acc@5 100.000 (99.911)
2025-08-28 04:58:04,415 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:04,415 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:04,824 - INFO - Epoch: [120][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1821 (0.1628) Acc@1 94.531 (94.472) Acc@5 100.000 (99.909)
2025-08-28 04:58:06,698 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.1704 (0.1704) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:58:07,575 - INFO - Epoch 120:
2025-08-28 04:58:07,575 - INFO -   Train: acc1: 94.3840 | acc5: 99.9180 | loss: 0.1644 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:07,575 - INFO -   Val:   acc1: 89.5300 | acc5: 99.7200 | loss: 0.3308
2025-08-28 04:58:07,575 - INFO -   LR: 0.010000
2025-08-28 04:58:07,624 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-28 04:58:07,809 - INFO - Epoch: [121][0/391] Time 0.184 (0.184) Data 0.157 (0.157) Loss 0.1737 (0.1737) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 04:58:08,768 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:08,768 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:09,782 - INFO - Epoch: [121][100/391] Time 0.025 (0.021) Data 0.009 (0.003) Loss 0.1204 (0.1575) Acc@1 95.312 (94.493) Acc@5 100.000 (99.938)
2025-08-28 04:58:11,633 - INFO - Epoch: [121][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1476 (0.1589) Acc@1 96.094 (94.364) Acc@5 100.000 (99.934)
2025-08-28 04:58:11,789 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:11,790 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:13,530 - INFO - Epoch: [121][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1606 (0.1640) Acc@1 96.094 (94.183) Acc@5 100.000 (99.922)
2025-08-28 04:58:14,839 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:14,839 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:15,388 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2273 (0.2273) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:58:16,239 - INFO - Epoch 121:
2025-08-28 04:58:16,239 - INFO -   Train: acc1: 94.1980 | acc5: 99.9180 | loss: 0.1651 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:16,239 - INFO -   Val:   acc1: 89.7300 | acc5: 99.6100 | loss: 0.3316
2025-08-28 04:58:16,239 - INFO -   LR: 0.010000
2025-08-28 04:58:16,254 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-28 04:58:16,442 - INFO - Epoch: [122][0/391] Time 0.187 (0.187) Data 0.164 (0.164) Loss 0.0827 (0.0827) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 04:58:18,304 - INFO - Epoch: [122][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2335 (0.1639) Acc@1 92.188 (94.415) Acc@5 100.000 (99.923)
2025-08-28 04:58:19,045 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:19,045 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:20,257 - INFO - Epoch: [122][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.2245 (0.1643) Acc@1 92.188 (94.286) Acc@5 100.000 (99.922)
2025-08-28 04:58:22,030 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:22,030 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:22,097 - INFO - Epoch: [122][300/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.1466 (0.1636) Acc@1 92.188 (94.331) Acc@5 100.000 (99.914)
2025-08-28 04:58:23,944 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2170 (0.2170) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:58:24,787 - INFO - Epoch 122:
2025-08-28 04:58:24,787 - INFO -   Train: acc1: 94.2140 | acc5: 99.8980 | loss: 0.1658 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:24,787 - INFO -   Val:   acc1: 89.5600 | acc5: 99.7200 | loss: 0.3262
2025-08-28 04:58:24,787 - INFO -   LR: 0.010000
2025-08-28 04:58:24,803 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-28 04:58:24,971 - INFO - Epoch: [123][0/391] Time 0.167 (0.167) Data 0.142 (0.142) Loss 0.1128 (0.1128) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 04:58:26,308 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:26,308 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:26,946 - INFO - Epoch: [123][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.1369 (0.1667) Acc@1 96.875 (94.090) Acc@5 100.000 (99.930)
2025-08-28 04:58:28,828 - INFO - Epoch: [123][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1867 (0.1606) Acc@1 93.750 (94.450) Acc@5 100.000 (99.922)
2025-08-28 04:58:29,362 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:29,362 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:30,771 - INFO - Epoch: [123][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1380 (0.1621) Acc@1 94.531 (94.401) Acc@5 100.000 (99.920)
2025-08-28 04:58:32,352 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:32,353 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:32,608 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.2227 (0.2227) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 04:58:33,475 - INFO - Epoch 123:
2025-08-28 04:58:33,475 - INFO -   Train: acc1: 94.2680 | acc5: 99.9120 | loss: 0.1677 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:33,475 - INFO -   Val:   acc1: 89.6100 | acc5: 99.6200 | loss: 0.3337
2025-08-28 04:58:33,475 - INFO -   LR: 0.010000
2025-08-28 04:58:33,492 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-28 04:58:33,647 - INFO - Epoch: [124][0/391] Time 0.154 (0.154) Data 0.133 (0.133) Loss 0.2018 (0.2018) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 04:58:35,571 - INFO - Epoch: [124][100/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.1684 (0.1533) Acc@1 94.531 (94.756) Acc@5 100.000 (99.923)
2025-08-28 04:58:36,648 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:36,649 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:37,529 - INFO - Epoch: [124][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.1876 (0.1607) Acc@1 92.969 (94.640) Acc@5 100.000 (99.934)
2025-08-28 04:58:39,425 - INFO - Epoch: [124][300/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.1894 (0.1636) Acc@1 91.406 (94.510) Acc@5 100.000 (99.933)
2025-08-28 04:58:39,703 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:39,703 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:41,235 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2387 (0.2387) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 04:58:42,089 - INFO - Epoch 124:
2025-08-28 04:58:42,090 - INFO -   Train: acc1: 94.4080 | acc5: 99.9300 | loss: 0.1640 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:42,090 - INFO -   Val:   acc1: 89.6300 | acc5: 99.6300 | loss: 0.3235
2025-08-28 04:58:42,090 - INFO -   LR: 0.010000
2025-08-28 04:58:42,106 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-28 04:58:42,285 - INFO - Epoch: [125][0/391] Time 0.179 (0.179) Data 0.148 (0.148) Loss 0.1442 (0.1442) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 04:58:43,940 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:43,940 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:44,243 - INFO - Epoch: [125][100/391] Time 0.026 (0.021) Data 0.000 (0.002) Loss 0.1502 (0.1576) Acc@1 96.094 (94.647) Acc@5 100.000 (99.899)
2025-08-28 04:58:46,206 - INFO - Epoch: [125][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1101 (0.1620) Acc@1 96.094 (94.555) Acc@5 100.000 (99.903)
2025-08-28 04:58:47,050 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:47,050 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:48,119 - INFO - Epoch: [125][300/391] Time 0.015 (0.020) Data 0.000 (0.001) Loss 0.1021 (0.1602) Acc@1 96.094 (94.627) Acc@5 100.000 (99.901)
2025-08-28 04:58:50,043 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2021 (0.2021) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 04:58:50,869 - INFO - Epoch 125:
2025-08-28 04:58:50,869 - INFO -   Train: acc1: 94.4600 | acc5: 99.9080 | loss: 0.1639 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:50,869 - INFO -   Val:   acc1: 89.5200 | acc5: 99.6600 | loss: 0.3307
2025-08-28 04:58:50,869 - INFO -   LR: 0.010000
2025-08-28 04:58:50,884 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-28 04:58:51,015 - INFO - Epoch: [126][0/391] Time 0.130 (0.130) Data 0.105 (0.105) Loss 0.2180 (0.2180) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:58:51,361 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:51,361 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:53,010 - INFO - Epoch: [126][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1405 (0.1513) Acc@1 96.875 (94.933) Acc@5 99.219 (99.884)
2025-08-28 04:58:54,377 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:54,377 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:54,868 - INFO - Epoch: [126][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1561 (0.1566) Acc@1 95.312 (94.663) Acc@5 100.000 (99.891)
2025-08-28 04:58:56,753 - INFO - Epoch: [126][300/391] Time 0.023 (0.019) Data 0.012 (0.002) Loss 0.1897 (0.1592) Acc@1 94.531 (94.570) Acc@5 100.000 (99.907)
2025-08-28 04:58:57,425 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:58:57,425 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:58:58,605 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3410 (0.3410) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 04:58:59,414 - INFO - Epoch 126:
2025-08-28 04:58:59,415 - INFO -   Train: acc1: 94.4540 | acc5: 99.9020 | loss: 0.1623 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:58:59,415 - INFO -   Val:   acc1: 89.3500 | acc5: 99.6700 | loss: 0.3387
2025-08-28 04:58:59,415 - INFO -   LR: 0.010000
2025-08-28 04:58:59,433 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-28 04:58:59,626 - INFO - Epoch: [127][0/391] Time 0.192 (0.192) Data 0.172 (0.172) Loss 0.1148 (0.1148) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 04:59:01,524 - INFO - Epoch: [127][100/391] Time 0.022 (0.021) Data 0.003 (0.003) Loss 0.1720 (0.1582) Acc@1 92.969 (94.578) Acc@5 100.000 (99.899)
2025-08-28 04:59:01,564 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:01,565 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:03,406 - INFO - Epoch: [127][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.1544 (0.1598) Acc@1 94.531 (94.442) Acc@5 100.000 (99.938)
2025-08-28 04:59:04,660 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:04,661 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:05,432 - INFO - Epoch: [127][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2049 (0.1628) Acc@1 93.750 (94.342) Acc@5 100.000 (99.925)
2025-08-28 04:59:07,315 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2442 (0.2442) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 04:59:08,189 - INFO - Epoch 127:
2025-08-28 04:59:08,189 - INFO -   Train: acc1: 94.2240 | acc5: 99.9220 | loss: 0.1663 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:59:08,189 - INFO -   Val:   acc1: 89.1600 | acc5: 99.5300 | loss: 0.3380
2025-08-28 04:59:08,189 - INFO -   LR: 0.010000
2025-08-28 04:59:08,205 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-28 04:59:08,409 - INFO - Epoch: [128][0/391] Time 0.203 (0.203) Data 0.168 (0.168) Loss 0.1757 (0.1757) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:59:09,035 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:09,035 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:10,368 - INFO - Epoch: [128][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.1102 (0.1629) Acc@1 96.875 (94.191) Acc@5 100.000 (99.954)
2025-08-28 04:59:12,128 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:12,128 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:12,289 - INFO - Epoch: [128][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.1444 (0.1620) Acc@1 95.312 (94.352) Acc@5 100.000 (99.949)
2025-08-28 04:59:14,282 - INFO - Epoch: [128][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1538 (0.1670) Acc@1 95.312 (94.217) Acc@5 100.000 (99.933)
2025-08-28 04:59:15,227 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:15,227 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:16,061 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3351 (0.3351) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 04:59:16,916 - INFO - Epoch 128:
2025-08-28 04:59:16,917 - INFO -   Train: acc1: 94.1180 | acc5: 99.9200 | loss: 0.1691 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:59:16,917 - INFO -   Val:   acc1: 88.8900 | acc5: 99.7500 | loss: 0.3657
2025-08-28 04:59:16,917 - INFO -   LR: 0.010000
2025-08-28 04:59:16,931 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-28 04:59:17,101 - INFO - Epoch: [129][0/391] Time 0.170 (0.170) Data 0.148 (0.148) Loss 0.1387 (0.1387) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 04:59:19,055 - INFO - Epoch: [129][100/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.1674 (0.1557) Acc@1 92.969 (94.802) Acc@5 100.000 (99.946)
2025-08-28 04:59:19,480 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:19,481 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:20,952 - INFO - Epoch: [129][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1260 (0.1612) Acc@1 93.750 (94.438) Acc@5 100.000 (99.934)
2025-08-28 04:59:22,449 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:22,449 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:22,793 - INFO - Epoch: [129][300/391] Time 0.013 (0.019) Data 0.000 (0.001) Loss 0.1769 (0.1630) Acc@1 93.750 (94.391) Acc@5 100.000 (99.933)
2025-08-28 04:59:24,596 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2090 (0.2090) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:59:25,495 - INFO - Epoch 129:
2025-08-28 04:59:25,495 - INFO -   Train: acc1: 94.2300 | acc5: 99.9340 | loss: 0.1675 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:59:25,495 - INFO -   Val:   acc1: 89.2500 | acc5: 99.6900 | loss: 0.3336
2025-08-28 04:59:25,495 - INFO -   LR: 0.010000
2025-08-28 04:59:25,513 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-28 04:59:25,705 - INFO - Epoch: [130][0/391] Time 0.191 (0.191) Data 0.170 (0.170) Loss 0.1190 (0.1190) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 04:59:26,699 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:26,699 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:27,696 - INFO - Epoch: [130][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 0.1870 (0.1583) Acc@1 92.969 (94.709) Acc@5 100.000 (99.938)
2025-08-28 04:59:29,554 - INFO - Epoch: [130][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.1831 (0.1625) Acc@1 92.969 (94.372) Acc@5 100.000 (99.949)
2025-08-28 04:59:29,775 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:29,775 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:31,545 - INFO - Epoch: [130][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2494 (0.1660) Acc@1 92.969 (94.285) Acc@5 100.000 (99.925)
2025-08-28 04:59:32,803 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:32,804 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:33,343 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2273 (0.2273) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 04:59:34,177 - INFO - Epoch 130:
2025-08-28 04:59:34,177 - INFO -   Train: acc1: 94.2780 | acc5: 99.9220 | loss: 0.1665 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:59:34,177 - INFO -   Val:   acc1: 89.6300 | acc5: 99.7100 | loss: 0.3209
2025-08-28 04:59:34,177 - INFO -   LR: 0.010000
2025-08-28 04:59:34,227 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-28 04:59:34,412 - INFO - Epoch: [131][0/391] Time 0.184 (0.184) Data 0.158 (0.158) Loss 0.0574 (0.0574) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 04:59:36,400 - INFO - Epoch: [131][100/391] Time 0.028 (0.021) Data 0.000 (0.004) Loss 0.1269 (0.1500) Acc@1 96.094 (95.003) Acc@5 100.000 (99.938)
2025-08-28 04:59:37,145 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:37,145 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:38,327 - INFO - Epoch: [131][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1390 (0.1566) Acc@1 94.531 (94.671) Acc@5 100.000 (99.938)
2025-08-28 04:59:40,243 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:40,244 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:40,283 - INFO - Epoch: [131][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1724 (0.1593) Acc@1 92.969 (94.544) Acc@5 100.000 (99.930)
2025-08-28 04:59:42,181 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2378 (0.2378) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 04:59:43,055 - INFO - Epoch 131:
2025-08-28 04:59:43,055 - INFO -   Train: acc1: 94.4240 | acc5: 99.9280 | loss: 0.1621 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:59:43,055 - INFO -   Val:   acc1: 89.4900 | acc5: 99.6600 | loss: 0.3221
2025-08-28 04:59:43,055 - INFO -   LR: 0.010000
2025-08-28 04:59:43,069 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-28 04:59:43,243 - INFO - Epoch: [132][0/391] Time 0.173 (0.173) Data 0.147 (0.147) Loss 0.2319 (0.2319) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:59:44,633 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:44,633 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:45,295 - INFO - Epoch: [132][100/391] Time 0.025 (0.022) Data 0.000 (0.002) Loss 0.1075 (0.1567) Acc@1 96.875 (94.384) Acc@5 100.000 (99.954)
2025-08-28 04:59:47,123 - INFO - Epoch: [132][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1209 (0.1562) Acc@1 96.094 (94.504) Acc@5 100.000 (99.938)
2025-08-28 04:59:47,685 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:47,685 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:49,114 - INFO - Epoch: [132][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1882 (0.1603) Acc@1 94.531 (94.427) Acc@5 100.000 (99.938)
2025-08-28 04:59:50,750 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:50,750 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:50,953 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2166 (0.2166) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 04:59:51,809 - INFO - Epoch 132:
2025-08-28 04:59:51,810 - INFO -   Train: acc1: 94.2100 | acc5: 99.9360 | loss: 0.1654 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 04:59:51,810 - INFO -   Val:   acc1: 89.4600 | acc5: 99.7500 | loss: 0.3245
2025-08-28 04:59:51,810 - INFO -   LR: 0.010000
2025-08-28 04:59:51,826 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-28 04:59:51,986 - INFO - Epoch: [133][0/391] Time 0.159 (0.159) Data 0.127 (0.127) Loss 0.1077 (0.1077) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 04:59:53,949 - INFO - Epoch: [133][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.2213 (0.1632) Acc@1 91.406 (94.431) Acc@5 100.000 (99.954)
2025-08-28 04:59:55,079 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:55,079 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:55,913 - INFO - Epoch: [133][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1696 (0.1660) Acc@1 93.750 (94.345) Acc@5 100.000 (99.934)
2025-08-28 04:59:57,831 - INFO - Epoch: [133][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.1558 (0.1646) Acc@1 93.750 (94.360) Acc@5 100.000 (99.933)
2025-08-28 04:59:58,154 - INFO - Pruning info: sparsity=0.500
2025-08-28 04:59:58,155 - INFO -   Reactivation rate: 0.0000
2025-08-28 04:59:59,671 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.1743 (0.1743) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:00:00,501 - INFO - Epoch 133:
2025-08-28 05:00:00,501 - INFO -   Train: acc1: 94.2040 | acc5: 99.9240 | loss: 0.1668 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:00,501 - INFO -   Val:   acc1: 89.5600 | acc5: 99.7700 | loss: 0.3199
2025-08-28 05:00:00,501 - INFO -   LR: 0.010000
2025-08-28 05:00:00,518 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-28 05:00:00,690 - INFO - Epoch: [134][0/391] Time 0.172 (0.172) Data 0.141 (0.141) Loss 0.1605 (0.1605) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:00:02,460 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:02,460 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:02,736 - INFO - Epoch: [134][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.1493 (0.1592) Acc@1 96.094 (94.508) Acc@5 100.000 (99.930)
2025-08-28 05:00:04,638 - INFO - Epoch: [134][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1488 (0.1600) Acc@1 94.531 (94.531) Acc@5 100.000 (99.942)
2025-08-28 05:00:05,509 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:05,509 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:06,571 - INFO - Epoch: [134][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2325 (0.1651) Acc@1 90.625 (94.370) Acc@5 100.000 (99.948)
2025-08-28 05:00:08,496 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2493 (0.2493) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:00:09,350 - INFO - Epoch 134:
2025-08-28 05:00:09,350 - INFO -   Train: acc1: 94.2700 | acc5: 99.9360 | loss: 0.1673 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:09,350 - INFO -   Val:   acc1: 89.4700 | acc5: 99.7200 | loss: 0.3257
2025-08-28 05:00:09,350 - INFO -   LR: 0.010000
2025-08-28 05:00:09,368 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-28 05:00:09,544 - INFO - Epoch: [135][0/391] Time 0.176 (0.176) Data 0.159 (0.159) Loss 0.2077 (0.2077) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:00:09,793 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:09,794 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:11,422 - INFO - Epoch: [135][100/391] Time 0.035 (0.020) Data 0.021 (0.003) Loss 0.1809 (0.1594) Acc@1 93.750 (94.732) Acc@5 100.000 (99.946)
2025-08-28 05:00:12,869 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:12,869 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:13,329 - INFO - Epoch: [135][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1912 (0.1633) Acc@1 94.531 (94.508) Acc@5 100.000 (99.922)
2025-08-28 05:00:15,139 - INFO - Epoch: [135][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2305 (0.1640) Acc@1 91.406 (94.404) Acc@5 100.000 (99.925)
2025-08-28 05:00:15,872 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:15,872 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:17,066 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2593 (0.2593) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:00:17,917 - INFO - Epoch 135:
2025-08-28 05:00:17,918 - INFO -   Train: acc1: 94.3100 | acc5: 99.9300 | loss: 0.1663 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:17,918 - INFO -   Val:   acc1: 88.6300 | acc5: 99.6600 | loss: 0.3532
2025-08-28 05:00:17,918 - INFO -   LR: 0.010000
2025-08-28 05:00:17,934 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-28 05:00:18,136 - INFO - Epoch: [136][0/391] Time 0.200 (0.200) Data 0.183 (0.183) Loss 0.1474 (0.1474) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-28 05:00:20,096 - INFO - Epoch: [136][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1289 (0.1674) Acc@1 95.312 (94.137) Acc@5 100.000 (99.954)
2025-08-28 05:00:20,166 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:20,166 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:22,026 - INFO - Epoch: [136][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.1570 (0.1677) Acc@1 95.312 (94.139) Acc@5 99.219 (99.934)
2025-08-28 05:00:23,264 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:23,264 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:23,902 - INFO - Epoch: [136][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2022 (0.1669) Acc@1 92.969 (94.132) Acc@5 100.000 (99.938)
2025-08-28 05:00:25,773 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2685 (0.2685) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:00:26,610 - INFO - Epoch 136:
2025-08-28 05:00:26,611 - INFO -   Train: acc1: 94.1280 | acc5: 99.9360 | loss: 0.1682 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:26,611 - INFO -   Val:   acc1: 89.4400 | acc5: 99.5100 | loss: 0.3518
2025-08-28 05:00:26,611 - INFO -   LR: 0.010000
2025-08-28 05:00:26,629 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-28 05:00:26,807 - INFO - Epoch: [137][0/391] Time 0.177 (0.177) Data 0.154 (0.154) Loss 0.2312 (0.2312) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:00:27,431 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:27,431 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:28,792 - INFO - Epoch: [137][100/391] Time 0.032 (0.021) Data 0.015 (0.005) Loss 0.1077 (0.1567) Acc@1 95.312 (94.562) Acc@5 100.000 (99.946)
2025-08-28 05:00:30,473 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:30,473 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:30,626 - INFO - Epoch: [137][200/391] Time 0.022 (0.020) Data 0.004 (0.003) Loss 0.1612 (0.1600) Acc@1 94.531 (94.527) Acc@5 99.219 (99.914)
2025-08-28 05:00:32,505 - INFO - Epoch: [137][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2689 (0.1651) Acc@1 91.406 (94.305) Acc@5 100.000 (99.917)
2025-08-28 05:00:33,503 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:33,503 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:34,348 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2205 (0.2205) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:00:35,215 - INFO - Epoch 137:
2025-08-28 05:00:35,215 - INFO -   Train: acc1: 94.1920 | acc5: 99.9120 | loss: 0.1674 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:35,215 - INFO -   Val:   acc1: 89.4100 | acc5: 99.6700 | loss: 0.3292
2025-08-28 05:00:35,215 - INFO -   LR: 0.010000
2025-08-28 05:00:35,233 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-28 05:00:35,389 - INFO - Epoch: [138][0/391] Time 0.155 (0.155) Data 0.131 (0.131) Loss 0.1707 (0.1707) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:00:37,315 - INFO - Epoch: [138][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.1512 (0.1574) Acc@1 96.094 (94.601) Acc@5 99.219 (99.930)
2025-08-28 05:00:37,730 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:37,731 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:39,272 - INFO - Epoch: [138][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1256 (0.1590) Acc@1 95.312 (94.469) Acc@5 100.000 (99.926)
2025-08-28 05:00:40,872 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:40,873 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:41,220 - INFO - Epoch: [138][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1825 (0.1622) Acc@1 93.750 (94.331) Acc@5 100.000 (99.927)
2025-08-28 05:00:43,060 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2612 (0.2612) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:00:43,925 - INFO - Epoch 138:
2025-08-28 05:00:43,925 - INFO -   Train: acc1: 94.2000 | acc5: 99.9280 | loss: 0.1653 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:43,925 - INFO -   Val:   acc1: 87.8800 | acc5: 99.5200 | loss: 0.3953
2025-08-28 05:00:43,925 - INFO -   LR: 0.010000
2025-08-28 05:00:43,939 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-28 05:00:44,156 - INFO - Epoch: [139][0/391] Time 0.216 (0.216) Data 0.187 (0.187) Loss 0.2093 (0.2093) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:00:45,112 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:45,113 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:46,026 - INFO - Epoch: [139][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.1439 (0.1520) Acc@1 95.312 (94.895) Acc@5 100.000 (99.930)
2025-08-28 05:00:47,985 - INFO - Epoch: [139][200/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1412 (0.1598) Acc@1 96.094 (94.481) Acc@5 99.219 (99.911)
2025-08-28 05:00:48,197 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:48,197 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:49,914 - INFO - Epoch: [139][300/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.2147 (0.1639) Acc@1 93.750 (94.318) Acc@5 100.000 (99.920)
2025-08-28 05:00:51,242 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:51,242 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:51,753 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.1902 (0.1902) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:00:52,607 - INFO - Epoch 139:
2025-08-28 05:00:52,607 - INFO -   Train: acc1: 94.2120 | acc5: 99.9080 | loss: 0.1669 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:00:52,607 - INFO -   Val:   acc1: 88.7000 | acc5: 99.5000 | loss: 0.3666
2025-08-28 05:00:52,607 - INFO -   LR: 0.010000
2025-08-28 05:00:52,625 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-28 05:00:52,818 - INFO - Epoch: [140][0/391] Time 0.192 (0.192) Data 0.166 (0.166) Loss 0.1278 (0.1278) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:00:54,761 - INFO - Epoch: [140][100/391] Time 0.020 (0.021) Data 0.001 (0.003) Loss 0.2118 (0.1579) Acc@1 88.281 (94.268) Acc@5 100.000 (99.938)
2025-08-28 05:00:55,572 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:55,573 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:56,797 - INFO - Epoch: [140][200/391] Time 0.013 (0.021) Data 0.002 (0.002) Loss 0.2014 (0.1672) Acc@1 93.750 (94.088) Acc@5 100.000 (99.930)
2025-08-28 05:00:58,802 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:00:58,802 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:00:58,814 - INFO - Epoch: [140][300/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.1058 (0.1668) Acc@1 96.875 (94.204) Acc@5 100.000 (99.927)
2025-08-28 05:01:00,721 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2844 (0.2844) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:01:01,577 - INFO - Epoch 140:
2025-08-28 05:01:01,578 - INFO -   Train: acc1: 94.1340 | acc5: 99.9220 | loss: 0.1680 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:01,578 - INFO -   Val:   acc1: 89.2800 | acc5: 99.6400 | loss: 0.3383
2025-08-28 05:01:01,578 - INFO -   LR: 0.010000
2025-08-28 05:01:01,631 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-28 05:01:01,829 - INFO - Epoch: [141][0/391] Time 0.197 (0.197) Data 0.171 (0.171) Loss 0.2250 (0.2250) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:01:03,169 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:03,169 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:03,744 - INFO - Epoch: [141][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.1664 (0.1665) Acc@1 94.531 (94.044) Acc@5 100.000 (99.915)
2025-08-28 05:01:05,686 - INFO - Epoch: [141][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0789 (0.1637) Acc@1 99.219 (94.317) Acc@5 100.000 (99.911)
2025-08-28 05:01:06,232 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:06,232 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:07,623 - INFO - Epoch: [141][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.0439 (0.1663) Acc@1 99.219 (94.264) Acc@5 100.000 (99.920)
2025-08-28 05:01:09,253 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:09,254 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:09,443 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3100 (0.3100) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:01:10,298 - INFO - Epoch 141:
2025-08-28 05:01:10,298 - INFO -   Train: acc1: 94.2380 | acc5: 99.9280 | loss: 0.1673 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:10,298 - INFO -   Val:   acc1: 89.0200 | acc5: 99.6600 | loss: 0.3455
2025-08-28 05:01:10,298 - INFO -   LR: 0.010000
2025-08-28 05:01:10,314 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-28 05:01:10,486 - INFO - Epoch: [142][0/391] Time 0.171 (0.171) Data 0.135 (0.135) Loss 0.1387 (0.1387) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:01:12,415 - INFO - Epoch: [142][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1811 (0.1636) Acc@1 92.969 (94.454) Acc@5 100.000 (99.969)
2025-08-28 05:01:13,537 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:13,537 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:14,393 - INFO - Epoch: [142][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1641 (0.1635) Acc@1 94.531 (94.461) Acc@5 100.000 (99.953)
2025-08-28 05:01:16,254 - INFO - Epoch: [142][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2408 (0.1672) Acc@1 92.969 (94.300) Acc@5 100.000 (99.938)
2025-08-28 05:01:16,587 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:16,587 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:18,146 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2617 (0.2617) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:01:19,018 - INFO - Epoch 142:
2025-08-28 05:01:19,019 - INFO -   Train: acc1: 94.2360 | acc5: 99.9260 | loss: 0.1688 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:19,019 - INFO -   Val:   acc1: 89.3900 | acc5: 99.6600 | loss: 0.3249
2025-08-28 05:01:19,019 - INFO -   LR: 0.010000
2025-08-28 05:01:19,037 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-28 05:01:19,228 - INFO - Epoch: [143][0/391] Time 0.190 (0.190) Data 0.169 (0.169) Loss 0.1676 (0.1676) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:01:20,896 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:20,896 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:21,178 - INFO - Epoch: [143][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.1050 (0.1479) Acc@1 96.875 (95.158) Acc@5 100.000 (99.915)
2025-08-28 05:01:23,162 - INFO - Epoch: [143][200/391] Time 0.026 (0.021) Data 0.000 (0.002) Loss 0.1187 (0.1541) Acc@1 95.312 (94.757) Acc@5 100.000 (99.922)
2025-08-28 05:01:24,063 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:24,064 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:25,117 - INFO - Epoch: [143][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1303 (0.1580) Acc@1 95.312 (94.539) Acc@5 100.000 (99.922)
2025-08-28 05:01:26,989 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2127 (0.2127) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:01:27,828 - INFO - Epoch 143:
2025-08-28 05:01:27,828 - INFO -   Train: acc1: 94.3580 | acc5: 99.9240 | loss: 0.1622 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:27,828 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6300 | loss: 0.3853
2025-08-28 05:01:27,828 - INFO -   LR: 0.010000
2025-08-28 05:01:28,052 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-28 05:01:28,234 - INFO - Epoch: [144][0/391] Time 0.181 (0.181) Data 0.149 (0.149) Loss 0.1925 (0.1925) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:01:28,566 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:28,567 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:30,159 - INFO - Epoch: [144][100/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.1621 (0.1629) Acc@1 92.969 (94.423) Acc@5 100.000 (99.907)
2025-08-28 05:01:31,559 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:31,559 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:32,028 - INFO - Epoch: [144][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1814 (0.1688) Acc@1 92.188 (94.131) Acc@5 100.000 (99.911)
2025-08-28 05:01:33,983 - INFO - Epoch: [144][300/391] Time 0.019 (0.020) Data 0.000 (0.001) Loss 0.1519 (0.1698) Acc@1 92.188 (94.116) Acc@5 100.000 (99.909)
2025-08-28 05:01:34,670 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:34,670 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:35,798 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.2433 (0.2433) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:01:36,700 - INFO - Epoch 144:
2025-08-28 05:01:36,700 - INFO -   Train: acc1: 94.0700 | acc5: 99.9000 | loss: 0.1717 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:36,700 - INFO -   Val:   acc1: 89.2100 | acc5: 99.6800 | loss: 0.3432
2025-08-28 05:01:36,700 - INFO -   LR: 0.010000
2025-08-28 05:01:36,716 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-28 05:01:36,904 - INFO - Epoch: [145][0/391] Time 0.187 (0.187) Data 0.160 (0.160) Loss 0.1679 (0.1679) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:01:38,785 - INFO - Epoch: [145][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1690 (0.1499) Acc@1 95.312 (94.756) Acc@5 100.000 (99.899)
2025-08-28 05:01:38,899 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:38,900 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:40,761 - INFO - Epoch: [145][200/391] Time 0.019 (0.020) Data 0.002 (0.004) Loss 0.1575 (0.1540) Acc@1 95.312 (94.694) Acc@5 100.000 (99.918)
2025-08-28 05:01:42,063 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:42,063 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:42,777 - INFO - Epoch: [145][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2611 (0.1586) Acc@1 91.406 (94.516) Acc@5 100.000 (99.925)
2025-08-28 05:01:44,710 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.1757 (0.1757) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:01:45,592 - INFO - Epoch 145:
2025-08-28 05:01:45,592 - INFO -   Train: acc1: 94.3020 | acc5: 99.9260 | loss: 0.1650 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:45,592 - INFO -   Val:   acc1: 88.9400 | acc5: 99.6300 | loss: 0.3471
2025-08-28 05:01:45,593 - INFO -   LR: 0.010000
2025-08-28 05:01:45,608 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-28 05:01:45,789 - INFO - Epoch: [146][0/391] Time 0.180 (0.180) Data 0.159 (0.159) Loss 0.1591 (0.1591) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:01:46,485 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:46,485 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:47,844 - INFO - Epoch: [146][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.1291 (0.1538) Acc@1 96.094 (94.709) Acc@5 100.000 (99.930)
2025-08-28 05:01:49,800 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:49,800 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:49,951 - INFO - Epoch: [146][200/391] Time 0.038 (0.022) Data 0.000 (0.002) Loss 0.1393 (0.1591) Acc@1 93.750 (94.457) Acc@5 100.000 (99.942)
2025-08-28 05:01:51,924 - INFO - Epoch: [146][300/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.1049 (0.1599) Acc@1 96.875 (94.440) Acc@5 100.000 (99.945)
2025-08-28 05:01:53,080 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:53,080 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:53,883 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.1945 (0.1945) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:01:54,745 - INFO - Epoch 146:
2025-08-28 05:01:54,745 - INFO -   Train: acc1: 94.2980 | acc5: 99.9500 | loss: 0.1634 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:01:54,745 - INFO -   Val:   acc1: 89.8200 | acc5: 99.6700 | loss: 0.3221
2025-08-28 05:01:54,746 - INFO -   LR: 0.010000
2025-08-28 05:01:54,764 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-28 05:01:54,950 - INFO - Epoch: [147][0/391] Time 0.186 (0.186) Data 0.167 (0.167) Loss 0.1700 (0.1700) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 05:01:56,850 - INFO - Epoch: [147][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.1264 (0.1588) Acc@1 96.094 (94.694) Acc@5 100.000 (99.938)
2025-08-28 05:01:57,270 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:01:57,271 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:01:58,809 - INFO - Epoch: [147][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.3238 (0.1623) Acc@1 89.844 (94.481) Acc@5 100.000 (99.938)
2025-08-28 05:02:00,366 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:00,366 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:00,711 - INFO - Epoch: [147][300/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.1809 (0.1659) Acc@1 94.531 (94.331) Acc@5 100.000 (99.938)
2025-08-28 05:02:02,620 - INFO - Test: [0/79] Time 0.117 (0.117) Loss 0.2179 (0.2179) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:02:03,543 - INFO - Epoch 147:
2025-08-28 05:02:03,543 - INFO -   Train: acc1: 94.2840 | acc5: 99.9280 | loss: 0.1669 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:03,543 - INFO -   Val:   acc1: 89.0700 | acc5: 99.6100 | loss: 0.3419
2025-08-28 05:02:03,543 - INFO -   LR: 0.010000
2025-08-28 05:02:03,560 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-28 05:02:03,752 - INFO - Epoch: [148][0/391] Time 0.192 (0.192) Data 0.162 (0.162) Loss 0.1694 (0.1694) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 05:02:04,787 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:04,787 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:05,755 - INFO - Epoch: [148][100/391] Time 0.029 (0.022) Data 0.000 (0.003) Loss 0.1968 (0.1621) Acc@1 92.969 (94.307) Acc@5 100.000 (99.899)
2025-08-28 05:02:07,630 - INFO - Epoch: [148][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.1352 (0.1601) Acc@1 95.312 (94.360) Acc@5 100.000 (99.914)
2025-08-28 05:02:07,846 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:07,846 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:09,533 - INFO - Epoch: [148][300/391] Time 0.017 (0.020) Data 0.006 (0.002) Loss 0.1701 (0.1643) Acc@1 93.750 (94.259) Acc@5 100.000 (99.912)
2025-08-28 05:02:10,928 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:10,928 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:11,413 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2589 (0.2589) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:02:12,279 - INFO - Epoch 148:
2025-08-28 05:02:12,279 - INFO -   Train: acc1: 94.2460 | acc5: 99.9200 | loss: 0.1655 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:12,279 - INFO -   Val:   acc1: 88.8700 | acc5: 99.6000 | loss: 0.3538
2025-08-28 05:02:12,279 - INFO -   LR: 0.010000
2025-08-28 05:02:12,295 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-28 05:02:12,491 - INFO - Epoch: [149][0/391] Time 0.195 (0.195) Data 0.179 (0.179) Loss 0.2388 (0.2388) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:02:14,439 - INFO - Epoch: [149][100/391] Time 0.024 (0.021) Data 0.005 (0.003) Loss 0.2376 (0.1590) Acc@1 88.281 (94.500) Acc@5 100.000 (99.930)
2025-08-28 05:02:15,251 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:15,251 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:16,391 - INFO - Epoch: [149][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2186 (0.1668) Acc@1 91.406 (94.181) Acc@5 100.000 (99.922)
2025-08-28 05:02:18,253 - INFO - Epoch: [149][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2044 (0.1677) Acc@1 93.750 (94.145) Acc@5 99.219 (99.914)
2025-08-28 05:02:18,263 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:18,263 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:20,134 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2591 (0.2591) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:02:20,982 - INFO - Epoch 149:
2025-08-28 05:02:20,982 - INFO -   Train: acc1: 94.1880 | acc5: 99.9160 | loss: 0.1668 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:20,982 - INFO -   Val:   acc1: 87.4600 | acc5: 99.5400 | loss: 0.3907
2025-08-28 05:02:20,982 - INFO -   LR: 0.001000
2025-08-28 05:02:20,999 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-28 05:02:21,173 - INFO - Epoch: [150][0/391] Time 0.170 (0.170) Data 0.150 (0.150) Loss 0.2003 (0.2003) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:02:22,553 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:22,554 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:23,175 - INFO - Epoch: [150][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1470 (0.1407) Acc@1 94.531 (95.227) Acc@5 100.000 (99.954)
2025-08-28 05:02:25,081 - INFO - Epoch: [150][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.0798 (0.1313) Acc@1 97.656 (95.581) Acc@5 100.000 (99.942)
2025-08-28 05:02:25,686 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:25,687 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:27,114 - INFO - Epoch: [150][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1805 (0.1277) Acc@1 92.188 (95.710) Acc@5 100.000 (99.953)
2025-08-28 05:02:28,754 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:28,754 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:28,937 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.1344 (0.1344) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:02:29,776 - INFO - Epoch 150:
2025-08-28 05:02:29,776 - INFO -   Train: acc1: 95.8700 | acc5: 99.9520 | loss: 0.1239 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:29,776 - INFO -   Val:   acc1: 91.7200 | acc5: 99.8200 | loss: 0.2613
2025-08-28 05:02:29,776 - INFO -   LR: 0.001000
2025-08-28 05:02:29,830 - INFO - Checkpoint saved: epoch=150, metric=91.7200
2025-08-28 05:02:29,862 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-28 05:02:30,044 - INFO - Epoch: [151][0/391] Time 0.181 (0.181) Data 0.144 (0.144) Loss 0.1109 (0.1109) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:02:32,045 - INFO - Epoch: [151][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.1005 (0.1043) Acc@1 96.094 (96.558) Acc@5 100.000 (99.946)
2025-08-28 05:02:33,186 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:33,187 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:33,981 - INFO - Epoch: [151][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1215 (0.1045) Acc@1 96.094 (96.576) Acc@5 100.000 (99.965)
2025-08-28 05:02:35,874 - INFO - Epoch: [151][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0544 (0.1034) Acc@1 98.438 (96.608) Acc@5 100.000 (99.958)
2025-08-28 05:02:36,234 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:36,234 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:37,739 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.1440 (0.1440) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:02:38,570 - INFO - Epoch 151:
2025-08-28 05:02:38,571 - INFO -   Train: acc1: 96.6140 | acc5: 99.9640 | loss: 0.1032 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:38,571 - INFO -   Val:   acc1: 91.8100 | acc5: 99.8200 | loss: 0.2638
2025-08-28 05:02:38,571 - INFO -   LR: 0.001000
2025-08-28 05:02:38,623 - INFO - Checkpoint saved: epoch=151, metric=91.8100
2025-08-28 05:02:38,655 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-28 05:02:38,851 - INFO - Epoch: [152][0/391] Time 0.195 (0.195) Data 0.149 (0.149) Loss 0.2364 (0.2364) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:02:40,609 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:40,609 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:40,817 - INFO - Epoch: [152][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.0546 (0.1014) Acc@1 99.219 (96.581) Acc@5 100.000 (99.946)
2025-08-28 05:02:42,664 - INFO - Epoch: [152][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.0961 (0.0981) Acc@1 95.312 (96.875) Acc@5 100.000 (99.957)
2025-08-28 05:02:43,580 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:43,581 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:44,666 - INFO - Epoch: [152][300/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.0657 (0.0978) Acc@1 96.875 (96.885) Acc@5 100.000 (99.966)
2025-08-28 05:02:46,496 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.1323 (0.1323) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:02:47,355 - INFO - Epoch 152:
2025-08-28 05:02:47,355 - INFO -   Train: acc1: 96.8820 | acc5: 99.9680 | loss: 0.0973 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:47,355 - INFO -   Val:   acc1: 91.9100 | acc5: 99.8200 | loss: 0.2607
2025-08-28 05:02:47,355 - INFO -   LR: 0.001000
2025-08-28 05:02:47,408 - INFO - Checkpoint saved: epoch=152, metric=91.9100
2025-08-28 05:02:47,442 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-28 05:02:47,612 - INFO - Epoch: [153][0/391] Time 0.169 (0.169) Data 0.144 (0.144) Loss 0.1462 (0.1462) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:02:47,978 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:47,978 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:49,680 - INFO - Epoch: [153][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.0625 (0.0911) Acc@1 96.875 (97.138) Acc@5 100.000 (99.969)
2025-08-28 05:02:51,124 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:51,125 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:51,565 - INFO - Epoch: [153][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.0753 (0.0922) Acc@1 98.438 (97.116) Acc@5 100.000 (99.973)
2025-08-28 05:02:53,494 - INFO - Epoch: [153][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0574 (0.0926) Acc@1 98.438 (97.166) Acc@5 100.000 (99.971)
2025-08-28 05:02:54,186 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:54,186 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:02:55,385 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.1383 (0.1383) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:02:56,239 - INFO - Epoch 153:
2025-08-28 05:02:56,239 - INFO -   Train: acc1: 97.1440 | acc5: 99.9660 | loss: 0.0926 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:02:56,239 - INFO -   Val:   acc1: 91.8300 | acc5: 99.7900 | loss: 0.2603
2025-08-28 05:02:56,239 - INFO -   LR: 0.001000
2025-08-28 05:02:56,257 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-28 05:02:56,441 - INFO - Epoch: [154][0/391] Time 0.183 (0.183) Data 0.159 (0.159) Loss 0.0792 (0.0792) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:02:58,366 - INFO - Epoch: [154][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.1440 (0.0902) Acc@1 93.750 (97.169) Acc@5 100.000 (99.977)
2025-08-28 05:02:58,479 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:02:58,479 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:00,263 - INFO - Epoch: [154][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0972 (0.0897) Acc@1 96.875 (97.139) Acc@5 100.000 (99.988)
2025-08-28 05:03:01,540 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:01,540 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:02,218 - INFO - Epoch: [154][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.0748 (0.0887) Acc@1 97.656 (97.231) Acc@5 100.000 (99.990)
2025-08-28 05:03:03,992 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.1324 (0.1324) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:03:04,890 - INFO - Epoch 154:
2025-08-28 05:03:04,891 - INFO -   Train: acc1: 97.1940 | acc5: 99.9840 | loss: 0.0888 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:04,891 - INFO -   Val:   acc1: 91.6200 | acc5: 99.8100 | loss: 0.2638
2025-08-28 05:03:04,891 - INFO -   LR: 0.001000
2025-08-28 05:03:05,793 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-28 05:03:05,982 - INFO - Epoch: [155][0/391] Time 0.188 (0.188) Data 0.161 (0.161) Loss 0.0694 (0.0694) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:03:06,683 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:06,683 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:08,043 - INFO - Epoch: [155][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.0887 (0.0890) Acc@1 97.656 (97.246) Acc@5 100.000 (99.985)
2025-08-28 05:03:09,764 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:09,764 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:09,866 - INFO - Epoch: [155][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1358 (0.0867) Acc@1 96.094 (97.365) Acc@5 100.000 (99.988)
2025-08-28 05:03:11,846 - INFO - Epoch: [155][300/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1020 (0.0867) Acc@1 97.656 (97.353) Acc@5 100.000 (99.977)
2025-08-28 05:03:12,858 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:12,858 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:13,639 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.1530 (0.1530) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:03:14,449 - INFO - Epoch 155:
2025-08-28 05:03:14,449 - INFO -   Train: acc1: 97.3260 | acc5: 99.9740 | loss: 0.0871 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:14,449 - INFO -   Val:   acc1: 91.7400 | acc5: 99.8400 | loss: 0.2632
2025-08-28 05:03:14,449 - INFO -   LR: 0.001000
2025-08-28 05:03:14,468 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-28 05:03:14,633 - INFO - Epoch: [156][0/391] Time 0.164 (0.164) Data 0.145 (0.145) Loss 0.1189 (0.1189) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:03:16,621 - INFO - Epoch: [156][100/391] Time 0.022 (0.021) Data 0.003 (0.003) Loss 0.0792 (0.0859) Acc@1 98.438 (97.308) Acc@5 100.000 (99.985)
2025-08-28 05:03:17,106 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:17,106 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:18,604 - INFO - Epoch: [156][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.0746 (0.0840) Acc@1 96.875 (97.365) Acc@5 100.000 (99.992)
2025-08-28 05:03:20,182 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:20,183 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:20,514 - INFO - Epoch: [156][300/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.0687 (0.0850) Acc@1 97.656 (97.358) Acc@5 100.000 (99.990)
2025-08-28 05:03:22,395 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.1424 (0.1424) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:03:23,257 - INFO - Epoch 156:
2025-08-28 05:03:23,257 - INFO -   Train: acc1: 97.3700 | acc5: 99.9840 | loss: 0.0844 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:23,257 - INFO -   Val:   acc1: 91.6300 | acc5: 99.7700 | loss: 0.2649
2025-08-28 05:03:23,257 - INFO -   LR: 0.001000
2025-08-28 05:03:23,274 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-28 05:03:23,462 - INFO - Epoch: [157][0/391] Time 0.187 (0.187) Data 0.155 (0.155) Loss 0.0786 (0.0786) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:03:24,537 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:24,537 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:25,476 - INFO - Epoch: [157][100/391] Time 0.029 (0.022) Data 0.013 (0.003) Loss 0.0774 (0.0813) Acc@1 97.656 (97.424) Acc@5 100.000 (99.977)
2025-08-28 05:03:27,335 - INFO - Epoch: [157][200/391] Time 0.018 (0.020) Data 0.002 (0.002) Loss 0.0629 (0.0842) Acc@1 98.438 (97.376) Acc@5 100.000 (99.981)
2025-08-28 05:03:27,582 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:27,582 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:29,190 - INFO - Epoch: [157][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1387 (0.0835) Acc@1 94.531 (97.433) Acc@5 99.219 (99.974)
2025-08-28 05:03:30,563 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:30,564 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:31,006 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.1513 (0.1513) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:03:31,844 - INFO - Epoch 157:
2025-08-28 05:03:31,844 - INFO -   Train: acc1: 97.4200 | acc5: 99.9740 | loss: 0.0835 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:31,844 - INFO -   Val:   acc1: 91.6000 | acc5: 99.7900 | loss: 0.2638
2025-08-28 05:03:31,844 - INFO -   LR: 0.001000
2025-08-28 05:03:31,863 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-28 05:03:32,051 - INFO - Epoch: [158][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.1097 (0.1097) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:03:34,060 - INFO - Epoch: [158][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.0808 (0.0845) Acc@1 96.875 (97.393) Acc@5 100.000 (100.000)
2025-08-28 05:03:34,809 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:34,810 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:35,952 - INFO - Epoch: [158][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0587 (0.0834) Acc@1 96.875 (97.384) Acc@5 100.000 (99.992)
2025-08-28 05:03:38,006 - INFO - Epoch: [158][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.0765 (0.0820) Acc@1 96.875 (97.462) Acc@5 100.000 (99.982)
2025-08-28 05:03:38,037 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:38,037 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:39,948 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.1654 (0.1654) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:03:40,820 - INFO - Epoch 158:
2025-08-28 05:03:40,820 - INFO -   Train: acc1: 97.4060 | acc5: 99.9800 | loss: 0.0821 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:40,820 - INFO -   Val:   acc1: 91.5200 | acc5: 99.8200 | loss: 0.2686
2025-08-28 05:03:40,820 - INFO -   LR: 0.001000
2025-08-28 05:03:40,838 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-28 05:03:41,024 - INFO - Epoch: [159][0/391] Time 0.185 (0.185) Data 0.167 (0.167) Loss 0.1132 (0.1132) Acc@1 96.875 (96.875) Acc@5 99.219 (99.219)
2025-08-28 05:03:42,390 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:42,391 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:42,971 - INFO - Epoch: [159][100/391] Time 0.030 (0.021) Data 0.009 (0.003) Loss 0.0890 (0.0814) Acc@1 97.656 (97.409) Acc@5 100.000 (99.961)
2025-08-28 05:03:44,937 - INFO - Epoch: [159][200/391] Time 0.019 (0.020) Data 0.007 (0.002) Loss 0.0560 (0.0787) Acc@1 98.438 (97.520) Acc@5 100.000 (99.973)
2025-08-28 05:03:45,477 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:45,477 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:46,854 - INFO - Epoch: [159][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.1072 (0.0791) Acc@1 93.750 (97.513) Acc@5 100.000 (99.977)
2025-08-28 05:03:48,659 - INFO - Test: [0/79] Time 0.111 (0.111) Loss 0.1574 (0.1574) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:03:49,519 - INFO - Epoch 159:
2025-08-28 05:03:49,520 - INFO -   Train: acc1: 97.4820 | acc5: 99.9760 | loss: 0.0797 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:49,520 - INFO -   Val:   acc1: 91.9000 | acc5: 99.8000 | loss: 0.2649
2025-08-28 05:03:49,520 - INFO -   LR: 0.001000
2025-08-28 05:03:49,537 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-28 05:03:49,693 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:49,694 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:49,722 - INFO - Epoch: [160][0/391] Time 0.184 (0.184) Data 0.144 (0.144) Loss 0.0486 (0.0486) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-28 05:03:51,588 - INFO - Epoch: [160][100/391] Time 0.027 (0.020) Data 0.000 (0.003) Loss 0.0214 (0.0736) Acc@1 100.000 (97.765) Acc@5 100.000 (99.977)
2025-08-28 05:03:52,750 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:52,751 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:53,549 - INFO - Epoch: [160][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.0876 (0.0783) Acc@1 96.094 (97.505) Acc@5 100.000 (99.981)
2025-08-28 05:03:55,530 - INFO - Epoch: [160][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0582 (0.0793) Acc@1 98.438 (97.498) Acc@5 100.000 (99.982)
2025-08-28 05:03:55,911 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:03:55,911 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:03:57,359 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.1565 (0.1565) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:03:58,243 - INFO - Epoch 160:
2025-08-28 05:03:58,243 - INFO -   Train: acc1: 97.5500 | acc5: 99.9800 | loss: 0.0791 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:03:58,243 - INFO -   Val:   acc1: 91.6100 | acc5: 99.8200 | loss: 0.2735
2025-08-28 05:03:58,243 - INFO -   LR: 0.001000
2025-08-28 05:03:58,296 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-28 05:03:58,477 - INFO - Epoch: [161][0/391] Time 0.181 (0.181) Data 0.155 (0.155) Loss 0.0926 (0.0926) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:04:00,178 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:00,178 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:00,413 - INFO - Epoch: [161][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.0545 (0.0768) Acc@1 98.438 (97.765) Acc@5 100.000 (99.977)
2025-08-28 05:04:02,220 - INFO - Epoch: [161][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.0429 (0.0770) Acc@1 100.000 (97.734) Acc@5 100.000 (99.981)
2025-08-28 05:04:03,184 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:03,184 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:04,234 - INFO - Epoch: [161][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0702 (0.0769) Acc@1 96.875 (97.716) Acc@5 100.000 (99.982)
2025-08-28 05:04:06,067 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.1538 (0.1538) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:04:06,913 - INFO - Epoch 161:
2025-08-28 05:04:06,913 - INFO -   Train: acc1: 97.7160 | acc5: 99.9780 | loss: 0.0762 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:06,913 - INFO -   Val:   acc1: 91.4900 | acc5: 99.8100 | loss: 0.2706
2025-08-28 05:04:06,913 - INFO -   LR: 0.001000
2025-08-28 05:04:06,931 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-28 05:04:07,114 - INFO - Epoch: [162][0/391] Time 0.182 (0.182) Data 0.151 (0.151) Loss 0.0644 (0.0644) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:04:07,485 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:07,485 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:09,094 - INFO - Epoch: [162][100/391] Time 0.012 (0.021) Data 0.000 (0.005) Loss 0.0585 (0.0729) Acc@1 98.438 (97.788) Acc@5 100.000 (99.992)
2025-08-28 05:04:10,534 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:10,534 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:10,905 - INFO - Epoch: [162][200/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.0372 (0.0739) Acc@1 98.438 (97.718) Acc@5 100.000 (99.992)
2025-08-28 05:04:12,877 - INFO - Epoch: [162][300/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.0756 (0.0752) Acc@1 96.094 (97.747) Acc@5 100.000 (99.984)
2025-08-28 05:04:13,605 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:13,605 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:14,777 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.1480 (0.1480) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:04:15,618 - INFO - Epoch 162:
2025-08-28 05:04:15,618 - INFO -   Train: acc1: 97.7400 | acc5: 99.9780 | loss: 0.0756 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:15,618 - INFO -   Val:   acc1: 91.6500 | acc5: 99.8500 | loss: 0.2707
2025-08-28 05:04:15,618 - INFO -   LR: 0.001000
2025-08-28 05:04:15,634 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-28 05:04:15,830 - INFO - Epoch: [163][0/391] Time 0.195 (0.195) Data 0.165 (0.165) Loss 0.0746 (0.0746) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:04:17,682 - INFO - Epoch: [163][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.0543 (0.0721) Acc@1 98.438 (97.857) Acc@5 100.000 (99.985)
2025-08-28 05:04:17,817 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:17,817 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:19,624 - INFO - Epoch: [163][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.0578 (0.0720) Acc@1 98.438 (97.812) Acc@5 100.000 (99.992)
2025-08-28 05:04:20,908 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:20,909 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:21,574 - INFO - Epoch: [163][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0634 (0.0732) Acc@1 98.438 (97.804) Acc@5 100.000 (99.987)
2025-08-28 05:04:23,413 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.1646 (0.1646) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:04:24,308 - INFO - Epoch 163:
2025-08-28 05:04:24,308 - INFO -   Train: acc1: 97.7520 | acc5: 99.9860 | loss: 0.0742 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:24,308 - INFO -   Val:   acc1: 91.6100 | acc5: 99.8300 | loss: 0.2709
2025-08-28 05:04:24,308 - INFO -   LR: 0.001000
2025-08-28 05:04:24,327 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-28 05:04:24,499 - INFO - Epoch: [164][0/391] Time 0.170 (0.170) Data 0.148 (0.148) Loss 0.0722 (0.0722) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:04:25,137 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:25,137 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:26,379 - INFO - Epoch: [164][100/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.0978 (0.0743) Acc@1 96.875 (97.757) Acc@5 100.000 (99.992)
2025-08-28 05:04:28,180 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:28,180 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:28,246 - INFO - Epoch: [164][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1013 (0.0755) Acc@1 96.875 (97.722) Acc@5 100.000 (99.977)
2025-08-28 05:04:30,188 - INFO - Epoch: [164][300/391] Time 0.033 (0.019) Data 0.021 (0.003) Loss 0.0801 (0.0738) Acc@1 96.875 (97.768) Acc@5 100.000 (99.979)
2025-08-28 05:04:31,245 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:31,246 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:32,047 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.1733 (0.1733) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:04:32,920 - INFO - Epoch 164:
2025-08-28 05:04:32,920 - INFO -   Train: acc1: 97.7400 | acc5: 99.9780 | loss: 0.0739 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:32,920 - INFO -   Val:   acc1: 91.6000 | acc5: 99.8000 | loss: 0.2708
2025-08-28 05:04:32,920 - INFO -   LR: 0.001000
2025-08-28 05:04:32,939 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-28 05:04:33,120 - INFO - Epoch: [165][0/391] Time 0.180 (0.180) Data 0.148 (0.148) Loss 0.0801 (0.0801) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:04:35,128 - INFO - Epoch: [165][100/391] Time 0.020 (0.022) Data 0.000 (0.002) Loss 0.0837 (0.0766) Acc@1 95.312 (97.649) Acc@5 100.000 (99.977)
2025-08-28 05:04:35,589 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:35,589 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:37,000 - INFO - Epoch: [165][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.0519 (0.0734) Acc@1 97.656 (97.738) Acc@5 100.000 (99.988)
2025-08-28 05:04:38,620 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:38,621 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:38,828 - INFO - Epoch: [165][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.0682 (0.0738) Acc@1 98.438 (97.742) Acc@5 100.000 (99.984)
2025-08-28 05:04:40,761 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.1584 (0.1584) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:04:41,604 - INFO - Epoch 165:
2025-08-28 05:04:41,604 - INFO -   Train: acc1: 97.7680 | acc5: 99.9860 | loss: 0.0734 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:41,604 - INFO -   Val:   acc1: 91.5300 | acc5: 99.7700 | loss: 0.2738
2025-08-28 05:04:41,604 - INFO -   LR: 0.001000
2025-08-28 05:04:41,622 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-28 05:04:41,812 - INFO - Epoch: [166][0/391] Time 0.189 (0.189) Data 0.160 (0.160) Loss 0.0888 (0.0888) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:04:42,890 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:42,890 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:43,756 - INFO - Epoch: [166][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.0293 (0.0684) Acc@1 100.000 (98.012) Acc@5 100.000 (99.992)
2025-08-28 05:04:45,705 - INFO - Epoch: [166][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0681 (0.0693) Acc@1 98.438 (97.963) Acc@5 100.000 (99.977)
2025-08-28 05:04:45,951 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:45,951 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:47,596 - INFO - Epoch: [166][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0512 (0.0690) Acc@1 97.656 (97.973) Acc@5 100.000 (99.982)
2025-08-28 05:04:49,059 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:49,060 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:49,489 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.1382 (0.1382) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:04:50,406 - INFO - Epoch 166:
2025-08-28 05:04:50,406 - INFO -   Train: acc1: 97.9320 | acc5: 99.9780 | loss: 0.0703 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:50,406 - INFO -   Val:   acc1: 91.6200 | acc5: 99.8200 | loss: 0.2753
2025-08-28 05:04:50,406 - INFO -   LR: 0.001000
2025-08-28 05:04:50,424 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-28 05:04:50,568 - INFO - Epoch: [167][0/391] Time 0.144 (0.144) Data 0.117 (0.117) Loss 0.0426 (0.0426) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:04:52,574 - INFO - Epoch: [167][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.0641 (0.0715) Acc@1 96.875 (97.981) Acc@5 100.000 (99.977)
2025-08-28 05:04:53,429 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:53,429 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:54,600 - INFO - Epoch: [167][200/391] Time 0.035 (0.021) Data 0.014 (0.002) Loss 0.0492 (0.0713) Acc@1 99.219 (97.952) Acc@5 100.000 (99.969)
2025-08-28 05:04:56,524 - INFO - Epoch: [167][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.0601 (0.0719) Acc@1 98.438 (97.887) Acc@5 100.000 (99.969)
2025-08-28 05:04:56,566 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:04:56,567 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:04:58,337 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.1609 (0.1609) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:04:59,187 - INFO - Epoch 167:
2025-08-28 05:04:59,187 - INFO -   Train: acc1: 97.8720 | acc5: 99.9720 | loss: 0.0715 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:04:59,188 - INFO -   Val:   acc1: 91.6700 | acc5: 99.8100 | loss: 0.2757
2025-08-28 05:04:59,188 - INFO -   LR: 0.001000
2025-08-28 05:04:59,207 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-28 05:04:59,413 - INFO - Epoch: [168][0/391] Time 0.205 (0.205) Data 0.186 (0.186) Loss 0.0987 (0.0987) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:05:00,739 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:00,739 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:01,270 - INFO - Epoch: [168][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.0638 (0.0699) Acc@1 96.875 (97.973) Acc@5 100.000 (99.985)
2025-08-28 05:05:03,108 - INFO - Epoch: [168][200/391] Time 0.026 (0.019) Data 0.000 (0.002) Loss 0.0898 (0.0719) Acc@1 96.094 (97.831) Acc@5 100.000 (99.969)
2025-08-28 05:05:03,724 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:03,725 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:05,047 - INFO - Epoch: [168][300/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.0550 (0.0729) Acc@1 98.438 (97.804) Acc@5 100.000 (99.974)
2025-08-28 05:05:06,866 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.1669 (0.1669) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:05:07,687 - INFO - Epoch 168:
2025-08-28 05:05:07,688 - INFO -   Train: acc1: 97.8140 | acc5: 99.9760 | loss: 0.0730 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:05:07,688 - INFO -   Val:   acc1: 91.4500 | acc5: 99.7900 | loss: 0.2751
2025-08-28 05:05:07,688 - INFO -   LR: 0.001000
2025-08-28 05:05:07,706 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-28 05:05:07,885 - INFO - Epoch: [169][0/391] Time 0.179 (0.179) Data 0.153 (0.153) Loss 0.0766 (0.0766) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:05:07,911 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:07,911 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:09,832 - INFO - Epoch: [169][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.0605 (0.0694) Acc@1 99.219 (97.765) Acc@5 100.000 (99.977)
2025-08-28 05:05:11,052 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:11,052 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:11,857 - INFO - Epoch: [169][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.0740 (0.0689) Acc@1 97.656 (97.878) Acc@5 100.000 (99.977)
2025-08-28 05:05:13,789 - INFO - Epoch: [169][300/391] Time 0.020 (0.020) Data 0.006 (0.002) Loss 0.0643 (0.0695) Acc@1 98.438 (97.846) Acc@5 100.000 (99.982)
2025-08-28 05:05:14,143 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:14,143 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:15,657 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.1850 (0.1850) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:05:16,531 - INFO - Epoch 169:
2025-08-28 05:05:16,531 - INFO -   Train: acc1: 97.8140 | acc5: 99.9840 | loss: 0.0705 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:05:16,531 - INFO -   Val:   acc1: 91.5000 | acc5: 99.8000 | loss: 0.2796
2025-08-28 05:05:16,531 - INFO -   LR: 0.001000
2025-08-28 05:05:16,548 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-28 05:05:16,741 - INFO - Epoch: [170][0/391] Time 0.191 (0.191) Data 0.152 (0.152) Loss 0.1045 (0.1045) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:05:18,538 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:18,538 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:18,752 - INFO - Epoch: [170][100/391] Time 0.023 (0.022) Data 0.000 (0.003) Loss 0.0795 (0.0692) Acc@1 96.875 (98.020) Acc@5 100.000 (99.977)
2025-08-28 05:05:20,614 - INFO - Epoch: [170][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0673 (0.0700) Acc@1 97.656 (97.905) Acc@5 100.000 (99.984)
2025-08-28 05:05:21,551 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:21,551 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:22,578 - INFO - Epoch: [170][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0969 (0.0704) Acc@1 97.656 (97.879) Acc@5 100.000 (99.987)
2025-08-28 05:05:24,421 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.1668 (0.1668) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:05:25,246 - INFO - Epoch 170:
2025-08-28 05:05:25,246 - INFO -   Train: acc1: 97.8840 | acc5: 99.9900 | loss: 0.0701 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:05:25,246 - INFO -   Val:   acc1: 91.7900 | acc5: 99.7800 | loss: 0.2738
2025-08-28 05:05:25,246 - INFO -   LR: 0.001000
2025-08-28 05:05:25,301 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-28 05:05:25,487 - INFO - Epoch: [171][0/391] Time 0.186 (0.186) Data 0.161 (0.161) Loss 0.0391 (0.0391) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-28 05:05:25,856 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:25,856 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:27,447 - INFO - Epoch: [171][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.0500 (0.0670) Acc@1 99.219 (98.004) Acc@5 100.000 (99.985)
2025-08-28 05:05:28,980 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:28,981 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:29,443 - INFO - Epoch: [171][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.1164 (0.0677) Acc@1 96.875 (97.959) Acc@5 100.000 (99.988)
2025-08-28 05:05:31,344 - INFO - Epoch: [171][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.0821 (0.0667) Acc@1 97.656 (98.007) Acc@5 100.000 (99.992)
2025-08-28 05:05:32,078 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:32,078 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:33,210 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2019 (0.2019) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:05:34,087 - INFO - Epoch 171:
2025-08-28 05:05:34,087 - INFO -   Train: acc1: 97.9740 | acc5: 99.9920 | loss: 0.0672 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:05:34,087 - INFO -   Val:   acc1: 91.5800 | acc5: 99.8200 | loss: 0.2795
2025-08-28 05:05:34,087 - INFO -   LR: 0.001000
2025-08-28 05:05:34,106 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-28 05:05:34,302 - INFO - Epoch: [172][0/391] Time 0.195 (0.195) Data 0.165 (0.165) Loss 0.0973 (0.0973) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:05:36,311 - INFO - Epoch: [172][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.0813 (0.0669) Acc@1 96.875 (98.105) Acc@5 100.000 (100.000)
2025-08-28 05:05:36,445 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:36,445 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:38,238 - INFO - Epoch: [172][200/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.0291 (0.0660) Acc@1 100.000 (98.053) Acc@5 100.000 (99.992)
2025-08-28 05:05:39,573 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:39,574 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:40,215 - INFO - Epoch: [172][300/391] Time 0.028 (0.020) Data 0.007 (0.002) Loss 0.0421 (0.0674) Acc@1 98.438 (98.022) Acc@5 100.000 (99.987)
2025-08-28 05:05:42,068 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2125 (0.2125) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:05:42,940 - INFO - Epoch 172:
2025-08-28 05:05:42,940 - INFO -   Train: acc1: 98.0260 | acc5: 99.9880 | loss: 0.0673 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:05:42,940 - INFO -   Val:   acc1: 91.6100 | acc5: 99.8000 | loss: 0.2740
2025-08-28 05:05:42,940 - INFO -   LR: 0.001000
2025-08-28 05:05:42,957 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-28 05:05:43,143 - INFO - Epoch: [173][0/391] Time 0.185 (0.185) Data 0.156 (0.156) Loss 0.0797 (0.0797) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:05:43,837 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:43,837 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:45,051 - INFO - Epoch: [173][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.0637 (0.0629) Acc@1 99.219 (98.213) Acc@5 100.000 (99.969)
2025-08-28 05:05:46,971 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:46,971 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:47,055 - INFO - Epoch: [173][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0474 (0.0640) Acc@1 99.219 (98.189) Acc@5 100.000 (99.981)
2025-08-28 05:05:49,058 - INFO - Epoch: [173][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0966 (0.0647) Acc@1 97.656 (98.134) Acc@5 100.000 (99.982)
2025-08-28 05:05:50,095 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:50,095 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:50,897 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.1811 (0.1811) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:05:51,731 - INFO - Epoch 173:
2025-08-28 05:05:51,732 - INFO -   Train: acc1: 98.0580 | acc5: 99.9820 | loss: 0.0662 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:05:51,732 - INFO -   Val:   acc1: 91.3600 | acc5: 99.8300 | loss: 0.2794
2025-08-28 05:05:51,732 - INFO -   LR: 0.001000
2025-08-28 05:05:51,751 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-28 05:05:51,930 - INFO - Epoch: [174][0/391] Time 0.178 (0.178) Data 0.155 (0.155) Loss 0.0640 (0.0640) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:05:53,904 - INFO - Epoch: [174][100/391] Time 0.027 (0.021) Data 0.000 (0.003) Loss 0.0845 (0.0642) Acc@1 97.656 (98.097) Acc@5 100.000 (99.977)
2025-08-28 05:05:54,430 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:54,430 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:55,879 - INFO - Epoch: [174][200/391] Time 0.015 (0.021) Data 0.000 (0.002) Loss 0.0407 (0.0660) Acc@1 100.000 (97.991) Acc@5 100.000 (99.981)
2025-08-28 05:05:57,481 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:05:57,481 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:05:57,698 - INFO - Epoch: [174][300/391] Time 0.037 (0.020) Data 0.025 (0.002) Loss 0.0505 (0.0666) Acc@1 98.438 (97.921) Acc@5 100.000 (99.979)
2025-08-28 05:05:59,603 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.1972 (0.1972) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:06:00,460 - INFO - Epoch 174:
2025-08-28 05:06:00,461 - INFO -   Train: acc1: 97.9060 | acc5: 99.9820 | loss: 0.0669 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:00,461 - INFO -   Val:   acc1: 91.4800 | acc5: 99.8300 | loss: 0.2805
2025-08-28 05:06:00,461 - INFO -   LR: 0.001000
2025-08-28 05:06:00,482 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-28 05:06:00,647 - INFO - Epoch: [175][0/391] Time 0.165 (0.165) Data 0.144 (0.144) Loss 0.0905 (0.0905) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:06:01,710 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:01,710 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:02,532 - INFO - Epoch: [175][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0486 (0.0651) Acc@1 99.219 (98.028) Acc@5 100.000 (99.985)
2025-08-28 05:06:04,393 - INFO - Epoch: [175][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.0583 (0.0636) Acc@1 98.438 (98.123) Acc@5 100.000 (99.988)
2025-08-28 05:06:04,598 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:04,598 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:06,360 - INFO - Epoch: [175][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0675 (0.0641) Acc@1 98.438 (98.079) Acc@5 100.000 (99.990)
2025-08-28 05:06:07,802 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:07,802 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:08,225 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2096 (0.2096) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:06:09,104 - INFO - Epoch 175:
2025-08-28 05:06:09,104 - INFO -   Train: acc1: 98.0880 | acc5: 99.9840 | loss: 0.0643 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:09,104 - INFO -   Val:   acc1: 91.4500 | acc5: 99.7900 | loss: 0.2805
2025-08-28 05:06:09,104 - INFO -   LR: 0.001000
2025-08-28 05:06:09,120 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-28 05:06:09,325 - INFO - Epoch: [176][0/391] Time 0.204 (0.204) Data 0.165 (0.165) Loss 0.0714 (0.0714) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:06:11,180 - INFO - Epoch: [176][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.0591 (0.0656) Acc@1 98.438 (97.973) Acc@5 100.000 (99.992)
2025-08-28 05:06:12,031 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:12,031 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:13,158 - INFO - Epoch: [176][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0812 (0.0647) Acc@1 97.656 (97.991) Acc@5 100.000 (99.992)
2025-08-28 05:06:15,096 - INFO - Epoch: [176][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0343 (0.0656) Acc@1 100.000 (97.965) Acc@5 100.000 (99.990)
2025-08-28 05:06:15,167 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:15,167 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:16,961 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2064 (0.2064) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:06:17,824 - INFO - Epoch 176:
2025-08-28 05:06:17,824 - INFO -   Train: acc1: 97.9960 | acc5: 99.9920 | loss: 0.0652 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:17,824 - INFO -   Val:   acc1: 91.5700 | acc5: 99.8200 | loss: 0.2817
2025-08-28 05:06:17,824 - INFO -   LR: 0.001000
2025-08-28 05:06:17,844 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-28 05:06:18,017 - INFO - Epoch: [177][0/391] Time 0.172 (0.172) Data 0.154 (0.154) Loss 0.0449 (0.0449) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:06:19,370 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:19,371 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:19,897 - INFO - Epoch: [177][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.0537 (0.0621) Acc@1 99.219 (98.182) Acc@5 100.000 (99.985)
2025-08-28 05:06:21,945 - INFO - Epoch: [177][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.0338 (0.0616) Acc@1 100.000 (98.282) Acc@5 100.000 (99.984)
2025-08-28 05:06:22,582 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:22,582 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:23,956 - INFO - Epoch: [177][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0939 (0.0635) Acc@1 97.656 (98.160) Acc@5 100.000 (99.984)
2025-08-28 05:06:25,842 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.1818 (0.1818) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:06:26,711 - INFO - Epoch 177:
2025-08-28 05:06:26,711 - INFO -   Train: acc1: 98.1560 | acc5: 99.9860 | loss: 0.0630 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:26,711 - INFO -   Val:   acc1: 91.5000 | acc5: 99.8000 | loss: 0.2825
2025-08-28 05:06:26,711 - INFO -   LR: 0.001000
2025-08-28 05:06:26,730 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-28 05:06:26,924 - INFO - Epoch: [178][0/391] Time 0.194 (0.194) Data 0.166 (0.166) Loss 0.0406 (0.0406) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:06:26,946 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:26,946 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:28,938 - INFO - Epoch: [178][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.0205 (0.0643) Acc@1 100.000 (98.105) Acc@5 100.000 (99.977)
2025-08-28 05:06:30,136 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:30,136 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:30,899 - INFO - Epoch: [178][200/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.0883 (0.0643) Acc@1 96.094 (98.057) Acc@5 100.000 (99.984)
2025-08-28 05:06:32,861 - INFO - Epoch: [178][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.0799 (0.0636) Acc@1 96.875 (98.064) Acc@5 100.000 (99.987)
2025-08-28 05:06:33,268 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:33,269 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:34,641 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.1849 (0.1849) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:06:35,480 - INFO - Epoch 178:
2025-08-28 05:06:35,481 - INFO -   Train: acc1: 98.1080 | acc5: 99.9880 | loss: 0.0630 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:35,481 - INFO -   Val:   acc1: 91.4500 | acc5: 99.7900 | loss: 0.2868
2025-08-28 05:06:35,481 - INFO -   LR: 0.001000
2025-08-28 05:06:35,498 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-28 05:06:35,677 - INFO - Epoch: [179][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.0652 (0.0652) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:06:37,340 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:37,340 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:37,521 - INFO - Epoch: [179][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.0330 (0.0611) Acc@1 100.000 (98.244) Acc@5 100.000 (99.985)
2025-08-28 05:06:39,460 - INFO - Epoch: [179][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.0652 (0.0624) Acc@1 98.438 (98.208) Acc@5 100.000 (99.981)
2025-08-28 05:06:40,443 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:40,443 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:41,420 - INFO - Epoch: [179][300/391] Time 0.023 (0.020) Data 0.002 (0.002) Loss 0.0396 (0.0624) Acc@1 99.219 (98.181) Acc@5 100.000 (99.982)
2025-08-28 05:06:43,267 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2301 (0.2301) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:06:44,155 - INFO - Epoch 179:
2025-08-28 05:06:44,155 - INFO -   Train: acc1: 98.1860 | acc5: 99.9840 | loss: 0.0623 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:44,155 - INFO -   Val:   acc1: 91.3800 | acc5: 99.7800 | loss: 0.2859
2025-08-28 05:06:44,155 - INFO -   LR: 0.001000
2025-08-28 05:06:44,174 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-28 05:06:44,354 - INFO - Epoch: [180][0/391] Time 0.178 (0.178) Data 0.151 (0.151) Loss 0.1215 (0.1215) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:06:44,749 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:44,749 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:46,367 - INFO - Epoch: [180][100/391] Time 0.028 (0.022) Data 0.000 (0.002) Loss 0.0396 (0.0626) Acc@1 98.438 (98.205) Acc@5 100.000 (99.985)
2025-08-28 05:06:47,882 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:47,882 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:48,289 - INFO - Epoch: [180][200/391] Time 0.018 (0.020) Data 0.004 (0.002) Loss 0.0481 (0.0618) Acc@1 99.219 (98.208) Acc@5 100.000 (99.984)
2025-08-28 05:06:50,280 - INFO - Epoch: [180][300/391] Time 0.021 (0.020) Data 0.000 (0.001) Loss 0.0554 (0.0606) Acc@1 98.438 (98.227) Acc@5 100.000 (99.987)
2025-08-28 05:06:51,040 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:51,040 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:52,146 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2142 (0.2142) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:06:53,017 - INFO - Epoch 180:
2025-08-28 05:06:53,017 - INFO -   Train: acc1: 98.1780 | acc5: 99.9860 | loss: 0.0614 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:06:53,017 - INFO -   Val:   acc1: 91.6100 | acc5: 99.8000 | loss: 0.2851
2025-08-28 05:06:53,017 - INFO -   LR: 0.001000
2025-08-28 05:06:53,070 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-28 05:06:53,253 - INFO - Epoch: [181][0/391] Time 0.181 (0.181) Data 0.160 (0.160) Loss 0.0449 (0.0449) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:06:55,179 - INFO - Epoch: [181][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.0680 (0.0603) Acc@1 97.656 (98.182) Acc@5 100.000 (99.992)
2025-08-28 05:06:55,343 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:55,344 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:57,034 - INFO - Epoch: [181][200/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.0912 (0.0597) Acc@1 97.656 (98.228) Acc@5 100.000 (99.996)
2025-08-28 05:06:58,319 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:06:58,320 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:06:58,949 - INFO - Epoch: [181][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1110 (0.0608) Acc@1 94.531 (98.155) Acc@5 100.000 (99.997)
2025-08-28 05:07:00,870 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2073 (0.2073) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:07:01,710 - INFO - Epoch 181:
2025-08-28 05:07:01,710 - INFO -   Train: acc1: 98.1580 | acc5: 99.9960 | loss: 0.0612 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:01,710 - INFO -   Val:   acc1: 91.5900 | acc5: 99.7800 | loss: 0.2851
2025-08-28 05:07:01,710 - INFO -   LR: 0.001000
2025-08-28 05:07:01,732 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-28 05:07:01,906 - INFO - Epoch: [182][0/391] Time 0.173 (0.173) Data 0.151 (0.151) Loss 0.0513 (0.0513) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:07:02,691 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:02,691 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:03,922 - INFO - Epoch: [182][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.0273 (0.0599) Acc@1 100.000 (98.198) Acc@5 100.000 (99.992)
2025-08-28 05:07:05,727 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:05,727 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:05,791 - INFO - Epoch: [182][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.0639 (0.0591) Acc@1 98.438 (98.294) Acc@5 100.000 (99.988)
2025-08-28 05:07:07,700 - INFO - Epoch: [182][300/391] Time 0.021 (0.020) Data 0.000 (0.001) Loss 0.0366 (0.0605) Acc@1 99.219 (98.204) Acc@5 100.000 (99.987)
2025-08-28 05:07:08,769 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:08,769 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:09,517 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.1911 (0.1911) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:07:10,397 - INFO - Epoch 182:
2025-08-28 05:07:10,397 - INFO -   Train: acc1: 98.1900 | acc5: 99.9900 | loss: 0.0605 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:10,397 - INFO -   Val:   acc1: 91.5600 | acc5: 99.7600 | loss: 0.2840
2025-08-28 05:07:10,397 - INFO -   LR: 0.001000
2025-08-28 05:07:10,415 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-28 05:07:10,611 - INFO - Epoch: [183][0/391] Time 0.195 (0.195) Data 0.173 (0.173) Loss 0.0432 (0.0432) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-28 05:07:12,493 - INFO - Epoch: [183][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.0678 (0.0641) Acc@1 97.656 (98.120) Acc@5 100.000 (99.992)
2025-08-28 05:07:13,018 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:13,019 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:14,430 - INFO - Epoch: [183][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.0328 (0.0618) Acc@1 100.000 (98.263) Acc@5 100.000 (99.996)
2025-08-28 05:07:16,083 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:16,083 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:16,361 - INFO - Epoch: [183][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.0582 (0.0623) Acc@1 98.438 (98.238) Acc@5 100.000 (99.987)
2025-08-28 05:07:18,251 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2051 (0.2051) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:07:19,112 - INFO - Epoch 183:
2025-08-28 05:07:19,112 - INFO -   Train: acc1: 98.1980 | acc5: 99.9900 | loss: 0.0624 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:19,112 - INFO -   Val:   acc1: 91.3700 | acc5: 99.8000 | loss: 0.2853
2025-08-28 05:07:19,112 - INFO -   LR: 0.001000
2025-08-28 05:07:19,131 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-28 05:07:19,326 - INFO - Epoch: [184][0/391] Time 0.195 (0.195) Data 0.174 (0.174) Loss 0.0524 (0.0524) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 05:07:20,398 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:20,398 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:21,223 - INFO - Epoch: [184][100/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.0989 (0.0622) Acc@1 97.656 (98.167) Acc@5 100.000 (99.992)
2025-08-28 05:07:23,138 - INFO - Epoch: [184][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0729 (0.0603) Acc@1 97.656 (98.266) Acc@5 100.000 (99.988)
2025-08-28 05:07:23,449 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:23,449 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:25,134 - INFO - Epoch: [184][300/391] Time 0.020 (0.020) Data 0.000 (0.001) Loss 0.0789 (0.0595) Acc@1 97.656 (98.274) Acc@5 100.000 (99.987)
2025-08-28 05:07:26,532 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:26,532 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:26,948 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.1904 (0.1904) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:07:27,809 - INFO - Epoch 184:
2025-08-28 05:07:27,809 - INFO -   Train: acc1: 98.2660 | acc5: 99.9820 | loss: 0.0597 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:27,809 - INFO -   Val:   acc1: 91.5000 | acc5: 99.8000 | loss: 0.2865
2025-08-28 05:07:27,809 - INFO -   LR: 0.001000
2025-08-28 05:07:27,829 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-28 05:07:28,022 - INFO - Epoch: [185][0/391] Time 0.192 (0.192) Data 0.169 (0.169) Loss 0.1410 (0.1410) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:07:29,988 - INFO - Epoch: [185][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.0556 (0.0593) Acc@1 98.438 (98.275) Acc@5 100.000 (99.985)
2025-08-28 05:07:30,835 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:30,835 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:31,922 - INFO - Epoch: [185][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0592 (0.0586) Acc@1 98.438 (98.228) Acc@5 100.000 (99.992)
2025-08-28 05:07:33,799 - INFO - Epoch: [185][300/391] Time 0.020 (0.020) Data 0.004 (0.002) Loss 0.0906 (0.0593) Acc@1 96.094 (98.206) Acc@5 100.000 (99.984)
2025-08-28 05:07:33,899 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:33,899 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:35,582 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.1984 (0.1984) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:07:36,429 - INFO - Epoch 185:
2025-08-28 05:07:36,429 - INFO -   Train: acc1: 98.2340 | acc5: 99.9840 | loss: 0.0593 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:36,430 - INFO -   Val:   acc1: 91.2500 | acc5: 99.8300 | loss: 0.2875
2025-08-28 05:07:36,430 - INFO -   LR: 0.001000
2025-08-28 05:07:36,451 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-28 05:07:36,650 - INFO - Epoch: [186][0/391] Time 0.198 (0.198) Data 0.173 (0.173) Loss 0.0533 (0.0533) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:07:38,081 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:38,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:38,582 - INFO - Epoch: [186][100/391] Time 0.036 (0.021) Data 0.012 (0.002) Loss 0.0648 (0.0596) Acc@1 97.656 (98.260) Acc@5 100.000 (99.992)
2025-08-28 05:07:40,530 - INFO - Epoch: [186][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0479 (0.0593) Acc@1 97.656 (98.263) Acc@5 100.000 (99.996)
2025-08-28 05:07:41,157 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:41,157 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:42,391 - INFO - Epoch: [186][300/391] Time 0.021 (0.020) Data 0.000 (0.001) Loss 0.0447 (0.0607) Acc@1 98.438 (98.219) Acc@5 100.000 (99.987)
2025-08-28 05:07:44,191 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.1981 (0.1981) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:07:45,055 - INFO - Epoch 186:
2025-08-28 05:07:45,055 - INFO -   Train: acc1: 98.1940 | acc5: 99.9900 | loss: 0.0614 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:45,055 - INFO -   Val:   acc1: 91.2800 | acc5: 99.7900 | loss: 0.2879
2025-08-28 05:07:45,055 - INFO -   LR: 0.001000
2025-08-28 05:07:45,077 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-28 05:07:45,259 - INFO - Epoch: [187][0/391] Time 0.181 (0.181) Data 0.161 (0.161) Loss 0.0462 (0.0462) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-28 05:07:45,306 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:45,306 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:47,182 - INFO - Epoch: [187][100/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.0858 (0.0548) Acc@1 95.312 (98.391) Acc@5 100.000 (100.000)
2025-08-28 05:07:48,376 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:48,376 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:49,107 - INFO - Epoch: [187][200/391] Time 0.024 (0.020) Data 0.004 (0.002) Loss 0.0605 (0.0574) Acc@1 100.000 (98.387) Acc@5 100.000 (99.992)
2025-08-28 05:07:51,047 - INFO - Epoch: [187][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0403 (0.0591) Acc@1 99.219 (98.258) Acc@5 100.000 (99.992)
2025-08-28 05:07:51,485 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:51,486 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:52,866 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2052 (0.2052) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:07:53,711 - INFO - Epoch 187:
2025-08-28 05:07:53,711 - INFO -   Train: acc1: 98.2360 | acc5: 99.9860 | loss: 0.0596 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:07:53,711 - INFO -   Val:   acc1: 91.2600 | acc5: 99.8700 | loss: 0.2895
2025-08-28 05:07:53,711 - INFO -   LR: 0.001000
2025-08-28 05:07:53,731 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-28 05:07:53,900 - INFO - Epoch: [188][0/391] Time 0.168 (0.168) Data 0.142 (0.142) Loss 0.0821 (0.0821) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:07:55,739 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:55,739 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:55,918 - INFO - Epoch: [188][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.0563 (0.0581) Acc@1 98.438 (98.368) Acc@5 100.000 (99.985)
2025-08-28 05:07:57,870 - INFO - Epoch: [188][200/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.0585 (0.0557) Acc@1 98.438 (98.465) Acc@5 100.000 (99.988)
2025-08-28 05:07:58,865 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:07:58,865 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:07:59,845 - INFO - Epoch: [188][300/391] Time 0.031 (0.020) Data 0.000 (0.002) Loss 0.0876 (0.0569) Acc@1 97.656 (98.414) Acc@5 100.000 (99.992)
2025-08-28 05:08:01,651 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2203 (0.2203) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:08:02,499 - INFO - Epoch 188:
2025-08-28 05:08:02,500 - INFO -   Train: acc1: 98.3220 | acc5: 99.9900 | loss: 0.0583 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:02,500 - INFO -   Val:   acc1: 91.2300 | acc5: 99.8100 | loss: 0.2887
2025-08-28 05:08:02,500 - INFO -   LR: 0.001000
2025-08-28 05:08:02,519 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-28 05:08:02,712 - INFO - Epoch: [189][0/391] Time 0.192 (0.192) Data 0.166 (0.166) Loss 0.0521 (0.0521) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-28 05:08:03,109 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:03,109 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:04,674 - INFO - Epoch: [189][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1044 (0.0605) Acc@1 96.094 (98.198) Acc@5 100.000 (99.985)
2025-08-28 05:08:06,226 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:06,227 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:06,562 - INFO - Epoch: [189][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.0480 (0.0592) Acc@1 98.438 (98.231) Acc@5 100.000 (99.988)
2025-08-28 05:08:08,523 - INFO - Epoch: [189][300/391] Time 0.028 (0.020) Data 0.016 (0.003) Loss 0.0669 (0.0586) Acc@1 97.656 (98.253) Acc@5 100.000 (99.987)
2025-08-28 05:08:09,355 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:09,357 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:10,435 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.2190 (0.2190) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:08:11,294 - INFO - Epoch 189:
2025-08-28 05:08:11,295 - INFO -   Train: acc1: 98.2580 | acc5: 99.9900 | loss: 0.0585 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:11,295 - INFO -   Val:   acc1: 91.4300 | acc5: 99.7900 | loss: 0.2887
2025-08-28 05:08:11,295 - INFO -   LR: 0.001000
2025-08-28 05:08:11,316 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-28 05:08:11,482 - INFO - Epoch: [190][0/391] Time 0.165 (0.165) Data 0.150 (0.150) Loss 0.0707 (0.0707) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:08:13,440 - INFO - Epoch: [190][100/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.0797 (0.0623) Acc@1 97.656 (98.113) Acc@5 100.000 (99.985)
2025-08-28 05:08:13,638 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:13,638 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:15,409 - INFO - Epoch: [190][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.0602 (0.0598) Acc@1 98.438 (98.224) Acc@5 100.000 (99.988)
2025-08-28 05:08:16,749 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:16,749 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:17,337 - INFO - Epoch: [190][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0333 (0.0586) Acc@1 100.000 (98.271) Acc@5 100.000 (99.990)
2025-08-28 05:08:19,219 - INFO - Test: [0/79] Time 0.108 (0.108) Loss 0.1884 (0.1884) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:08:20,109 - INFO - Epoch 190:
2025-08-28 05:08:20,109 - INFO -   Train: acc1: 98.2800 | acc5: 99.9920 | loss: 0.0588 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:20,109 - INFO -   Val:   acc1: 91.3300 | acc5: 99.7500 | loss: 0.2905
2025-08-28 05:08:20,109 - INFO -   LR: 0.001000
2025-08-28 05:08:20,163 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-28 05:08:20,358 - INFO - Epoch: [191][0/391] Time 0.194 (0.194) Data 0.163 (0.163) Loss 0.0556 (0.0556) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-28 05:08:21,150 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:21,150 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:22,368 - INFO - Epoch: [191][100/391] Time 0.028 (0.022) Data 0.000 (0.003) Loss 0.0432 (0.0548) Acc@1 99.219 (98.438) Acc@5 100.000 (99.977)
2025-08-28 05:08:24,304 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:24,304 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:24,338 - INFO - Epoch: [191][200/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.0531 (0.0554) Acc@1 97.656 (98.348) Acc@5 100.000 (99.973)
2025-08-28 05:08:26,267 - INFO - Epoch: [191][300/391] Time 0.033 (0.020) Data 0.020 (0.002) Loss 0.0427 (0.0548) Acc@1 98.438 (98.419) Acc@5 100.000 (99.982)
2025-08-28 05:08:27,267 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:27,267 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:28,052 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2118 (0.2118) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:08:28,891 - INFO - Epoch 191:
2025-08-28 05:08:28,891 - INFO -   Train: acc1: 98.3420 | acc5: 99.9840 | loss: 0.0569 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:28,891 - INFO -   Val:   acc1: 90.9300 | acc5: 99.8400 | loss: 0.2991
2025-08-28 05:08:28,891 - INFO -   LR: 0.001000
2025-08-28 05:08:28,912 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-28 05:08:29,100 - INFO - Epoch: [192][0/391] Time 0.186 (0.186) Data 0.152 (0.152) Loss 0.0373 (0.0373) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-28 05:08:31,022 - INFO - Epoch: [192][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.0666 (0.0567) Acc@1 97.656 (98.321) Acc@5 100.000 (99.992)
2025-08-28 05:08:31,568 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:31,568 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:32,902 - INFO - Epoch: [192][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0497 (0.0563) Acc@1 100.000 (98.282) Acc@5 100.000 (99.996)
2025-08-28 05:08:34,576 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:34,576 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:34,856 - INFO - Epoch: [192][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.0562 (0.0557) Acc@1 98.438 (98.344) Acc@5 100.000 (99.992)
2025-08-28 05:08:36,705 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2239 (0.2239) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:08:37,536 - INFO - Epoch 192:
2025-08-28 05:08:37,536 - INFO -   Train: acc1: 98.3040 | acc5: 99.9900 | loss: 0.0568 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:37,536 - INFO -   Val:   acc1: 91.3400 | acc5: 99.7700 | loss: 0.2930
2025-08-28 05:08:37,536 - INFO -   LR: 0.001000
2025-08-28 05:08:37,556 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-28 05:08:37,758 - INFO - Epoch: [193][0/391] Time 0.201 (0.201) Data 0.175 (0.175) Loss 0.0509 (0.0509) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:08:38,863 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:38,863 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:39,730 - INFO - Epoch: [193][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.0945 (0.0564) Acc@1 95.312 (98.383) Acc@5 100.000 (99.992)
2025-08-28 05:08:41,727 - INFO - Epoch: [193][200/391] Time 0.011 (0.021) Data 0.000 (0.002) Loss 0.0359 (0.0571) Acc@1 100.000 (98.309) Acc@5 100.000 (99.988)
2025-08-28 05:08:42,035 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:42,035 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:43,592 - INFO - Epoch: [193][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0882 (0.0571) Acc@1 97.656 (98.321) Acc@5 100.000 (99.992)
2025-08-28 05:08:45,032 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:45,033 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:45,423 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2139 (0.2139) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:08:46,282 - INFO - Epoch 193:
2025-08-28 05:08:46,282 - INFO -   Train: acc1: 98.3320 | acc5: 99.9840 | loss: 0.0570 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:46,282 - INFO -   Val:   acc1: 91.2900 | acc5: 99.8100 | loss: 0.2948
2025-08-28 05:08:46,282 - INFO -   LR: 0.001000
2025-08-28 05:08:46,303 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-28 05:08:46,481 - INFO - Epoch: [194][0/391] Time 0.177 (0.177) Data 0.148 (0.148) Loss 0.0410 (0.0410) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:08:48,389 - INFO - Epoch: [194][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.0344 (0.0524) Acc@1 98.438 (98.538) Acc@5 100.000 (99.969)
2025-08-28 05:08:49,252 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:49,253 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:50,251 - INFO - Epoch: [194][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.0376 (0.0544) Acc@1 99.219 (98.426) Acc@5 100.000 (99.984)
2025-08-28 05:08:52,210 - INFO - Epoch: [194][300/391] Time 0.023 (0.020) Data 0.008 (0.002) Loss 0.0375 (0.0550) Acc@1 98.438 (98.401) Acc@5 100.000 (99.987)
2025-08-28 05:08:52,312 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:52,313 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:54,091 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2158 (0.2158) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:08:54,961 - INFO - Epoch 194:
2025-08-28 05:08:54,961 - INFO -   Train: acc1: 98.3660 | acc5: 99.9860 | loss: 0.0555 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:08:54,961 - INFO -   Val:   acc1: 91.4300 | acc5: 99.8000 | loss: 0.2947
2025-08-28 05:08:54,961 - INFO -   LR: 0.001000
2025-08-28 05:08:54,980 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-28 05:08:55,152 - INFO - Epoch: [195][0/391] Time 0.171 (0.171) Data 0.144 (0.144) Loss 0.0700 (0.0700) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:08:56,602 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:56,602 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:08:57,060 - INFO - Epoch: [195][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.0272 (0.0554) Acc@1 100.000 (98.414) Acc@5 100.000 (99.992)
2025-08-28 05:08:59,003 - INFO - Epoch: [195][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.0696 (0.0551) Acc@1 97.656 (98.379) Acc@5 100.000 (99.996)
2025-08-28 05:08:59,716 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:08:59,716 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:01,005 - INFO - Epoch: [195][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.0632 (0.0554) Acc@1 99.219 (98.365) Acc@5 100.000 (99.990)
2025-08-28 05:09:02,855 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2318 (0.2318) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:09:03,703 - INFO - Epoch 195:
2025-08-28 05:09:03,703 - INFO -   Train: acc1: 98.3860 | acc5: 99.9920 | loss: 0.0551 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:09:03,703 - INFO -   Val:   acc1: 91.2300 | acc5: 99.8300 | loss: 0.2954
2025-08-28 05:09:03,703 - INFO -   LR: 0.001000
2025-08-28 05:09:03,723 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-28 05:09:03,889 - INFO - Epoch: [196][0/391] Time 0.165 (0.165) Data 0.134 (0.134) Loss 0.0778 (0.0778) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 05:09:03,965 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:03,966 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:05,843 - INFO - Epoch: [196][100/391] Time 0.026 (0.021) Data 0.000 (0.003) Loss 0.0748 (0.0558) Acc@1 97.656 (98.391) Acc@5 100.000 (99.985)
2025-08-28 05:09:07,063 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:07,063 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:07,733 - INFO - Epoch: [196][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.0368 (0.0550) Acc@1 99.219 (98.434) Acc@5 100.000 (99.988)
2025-08-28 05:09:09,649 - INFO - Epoch: [196][300/391] Time 0.020 (0.020) Data 0.004 (0.002) Loss 0.0323 (0.0545) Acc@1 99.219 (98.440) Acc@5 100.000 (99.990)
2025-08-28 05:09:10,096 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:10,097 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:11,526 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2168 (0.2168) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:09:12,434 - INFO - Epoch 196:
2025-08-28 05:09:12,434 - INFO -   Train: acc1: 98.4440 | acc5: 99.9900 | loss: 0.0550 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:09:12,434 - INFO -   Val:   acc1: 91.2900 | acc5: 99.8000 | loss: 0.2958
2025-08-28 05:09:12,434 - INFO -   LR: 0.001000
2025-08-28 05:09:12,452 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-28 05:09:12,610 - INFO - Epoch: [197][0/391] Time 0.157 (0.157) Data 0.137 (0.137) Loss 0.0565 (0.0565) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 05:09:14,478 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:14,478 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:14,630 - INFO - Epoch: [197][100/391] Time 0.018 (0.022) Data 0.000 (0.003) Loss 0.0578 (0.0549) Acc@1 98.438 (98.306) Acc@5 100.000 (99.992)
2025-08-28 05:09:16,496 - INFO - Epoch: [197][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.0561 (0.0540) Acc@1 97.656 (98.426) Acc@5 100.000 (99.988)
2025-08-28 05:09:17,472 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:17,472 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:18,297 - INFO - Epoch: [197][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.0434 (0.0540) Acc@1 98.438 (98.417) Acc@5 100.000 (99.987)
2025-08-28 05:09:20,183 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.2159 (0.2159) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:09:21,048 - INFO - Epoch 197:
2025-08-28 05:09:21,048 - INFO -   Train: acc1: 98.4040 | acc5: 99.9880 | loss: 0.0545 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:09:21,048 - INFO -   Val:   acc1: 91.3100 | acc5: 99.7600 | loss: 0.2939
2025-08-28 05:09:21,048 - INFO -   LR: 0.001000
2025-08-28 05:09:21,069 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-28 05:09:21,250 - INFO - Epoch: [198][0/391] Time 0.181 (0.181) Data 0.158 (0.158) Loss 0.0230 (0.0230) Acc@1 100.000 (100.000) Acc@5 100.000 (100.000)
2025-08-28 05:09:21,700 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:21,700 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:23,134 - INFO - Epoch: [198][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0474 (0.0553) Acc@1 99.219 (98.314) Acc@5 100.000 (99.985)
2025-08-28 05:09:24,649 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:24,649 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:24,995 - INFO - Epoch: [198][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.0296 (0.0564) Acc@1 100.000 (98.317) Acc@5 100.000 (99.988)
2025-08-28 05:09:26,848 - INFO - Epoch: [198][300/391] Time 0.021 (0.019) Data 0.009 (0.002) Loss 0.0565 (0.0563) Acc@1 97.656 (98.331) Acc@5 100.000 (99.992)
2025-08-28 05:09:27,608 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:27,608 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:28,684 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2164 (0.2164) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:09:29,534 - INFO - Epoch 198:
2025-08-28 05:09:29,534 - INFO -   Train: acc1: 98.3460 | acc5: 99.9940 | loss: 0.0555 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:09:29,534 - INFO -   Val:   acc1: 91.3400 | acc5: 99.7900 | loss: 0.2915
2025-08-28 05:09:29,534 - INFO -   LR: 0.001000
2025-08-28 05:09:29,553 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-28 05:09:29,727 - INFO - Epoch: [199][0/391] Time 0.172 (0.172) Data 0.147 (0.147) Loss 0.0392 (0.0392) Acc@1 99.219 (99.219) Acc@5 100.000 (100.000)
2025-08-28 05:09:31,648 - INFO - Epoch: [199][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.0823 (0.0537) Acc@1 99.219 (98.399) Acc@5 100.000 (100.000)
2025-08-28 05:09:31,856 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:31,856 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:33,621 - INFO - Epoch: [199][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.0286 (0.0549) Acc@1 100.000 (98.414) Acc@5 100.000 (99.996)
2025-08-28 05:09:34,985 - INFO - Pruning info: sparsity=0.500
2025-08-28 05:09:34,985 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:09:35,535 - INFO - Epoch: [199][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.0256 (0.0556) Acc@1 100.000 (98.386) Acc@5 100.000 (99.995)
2025-08-28 05:09:37,414 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2415 (0.2415) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:09:38,267 - INFO - Epoch 199:
2025-08-28 05:09:38,267 - INFO -   Train: acc1: 98.3600 | acc5: 99.9960 | loss: 0.0553 | sparsity: 0.5000 | reactivation_rate: 0.0000
2025-08-28 05:09:38,268 - INFO -   Val:   acc1: 91.3400 | acc5: 99.7700 | loss: 0.2944
2025-08-28 05:09:38,268 - INFO -   LR: 0.001000
2025-08-28 05:09:38,287 - INFO - training time: 00h 29m 08.99s
2025-08-28 05:09:38,287 - INFO - 
Training completed!
2025-08-28 05:09:38,287 - INFO - Best accuracy: 91.9100
2025-08-28 05:09:38,287 - INFO - Total training time: 0.49 hours
2025-08-28 05:09:38,288 - INFO - total_experiment time: 00h 29m 10.34s
2025-08-28 05:09:38,288 - INFO - Experiment completed successfully
2025-08-28 05:09:38,289 - INFO - Total time: 0.49 hours
