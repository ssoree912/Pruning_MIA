2025-08-27 16:57:37,553 - INFO - Starting experiment: dpf_sparsity0.8_seed42
2025-08-27 16:57:37,553 - INFO - Save directory: ./runs/dpf/sparsity0.8/seed42
2025-08-27 16:57:37,554 - INFO - Hyperparameters:
2025-08-27 16:57:37,554 - INFO -   name: dpf_sparsity0.8_seed42
2025-08-27 16:57:37,554 - INFO -   description: DPF pruning 80% (seed=42)
2025-08-27 16:57:37,554 - INFO -   save_dir: ./runs
2025-08-27 16:57:37,554 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 16:57:37,554 - INFO -   model: {'arch': 'resnet', 'layers': 18, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 16:57:37,554 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 16:57:37,554 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.8, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 16:57:37,554 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 16:57:37,554 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 16:57:37,594 - INFO - System Information:
2025-08-27 16:57:37,594 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 16:57:37,594 - INFO -   python_version: 3.9.18
2025-08-27 16:57:37,594 - INFO -   pytorch_version: 2.1.0
2025-08-27 16:57:37,594 - INFO -   cuda_available: True
2025-08-27 16:57:37,594 - INFO -   cpu_count: 4
2025-08-27 16:57:37,594 - INFO -   memory_total_gb: 11.0
2025-08-27 16:57:37,594 - INFO -   timestamp: 1756281457.593909
2025-08-27 16:57:37,594 - INFO -   cuda_version: 11.8
2025-08-27 16:57:37,594 - INFO -   gpu_count: 1
2025-08-27 16:57:37,594 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 16:57:37,600 - INFO - Starting experiment: dpf_sparsity0.8_seed42
2025-08-27 16:57:37,600 - INFO - Model: resnet-18
2025-08-27 16:57:37,600 - INFO - Dataset: cifar10
2025-08-27 16:57:37,600 - INFO - Pruning: dpf (80.00%)
2025-08-27 18:17:08,658 - INFO - Starting experiment: dpf_sparsity0.8_seed42
2025-08-27 18:17:08,658 - INFO - Save directory: ./runs/dpf/sparsity0.8/seed42
2025-08-27 18:17:08,659 - INFO - Hyperparameters:
2025-08-27 18:17:08,659 - INFO -   name: dpf_sparsity0.8_seed42
2025-08-27 18:17:08,659 - INFO -   description: DPF pruning 80% (seed=42)
2025-08-27 18:17:08,659 - INFO -   save_dir: ./runs
2025-08-27 18:17:08,659 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 18:17:08,659 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 18:17:08,659 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 18:17:08,659 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.8, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 18:17:08,659 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 18:17:08,659 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 18:17:08,692 - INFO - System Information:
2025-08-27 18:17:08,692 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 18:17:08,692 - INFO -   python_version: 3.9.18
2025-08-27 18:17:08,692 - INFO -   pytorch_version: 2.1.0
2025-08-27 18:17:08,692 - INFO -   cuda_available: True
2025-08-27 18:17:08,692 - INFO -   cpu_count: 4
2025-08-27 18:17:08,693 - INFO -   memory_total_gb: 11.0
2025-08-27 18:17:08,693 - INFO -   timestamp: 1756286228.6924286
2025-08-27 18:17:08,693 - INFO -   cuda_version: 11.8
2025-08-27 18:17:08,693 - INFO -   gpu_count: 1
2025-08-27 18:17:08,693 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 18:17:08,699 - INFO - Starting experiment: dpf_sparsity0.8_seed42
2025-08-27 18:17:08,699 - INFO - Model: resnet-20
2025-08-27 18:17:08,699 - INFO - Dataset: cifar10
2025-08-27 18:17:08,699 - INFO - Pruning: dpf (80.00%)
2025-08-27 18:17:08,886 - INFO - Model Information:
2025-08-27 18:17:08,886 - INFO -   Type: pruned
2025-08-27 18:17:08,886 - INFO -   Total parameters: 544,948
2025-08-27 18:17:08,886 - INFO -   Trainable parameters: 274,692
2025-08-27 18:17:08,886 - INFO -   Sparsity: 80.00%
2025-08-27 18:17:09,862 - INFO - Starting training...
2025-08-27 18:17:09,862 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 18:17:10,651 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:17:10,651 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:17:11,173 - INFO - Epoch: [0][0/391] Time 1.310 (1.310) Data 0.647 (0.647) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 18:17:13,182 - INFO - Epoch: [0][100/391] Time 0.020 (0.033) Data 0.000 (0.008) Loss 1.6624 (1.9148) Acc@1 40.625 (26.153) Acc@5 91.406 (81.211)
2025-08-27 18:17:14,314 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:17:14,315 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:17:15,141 - INFO - Epoch: [0][200/391] Time 0.017 (0.026) Data 0.000 (0.005) Loss 1.4511 (1.7803) Acc@1 42.188 (31.880) Acc@5 93.750 (85.250)
2025-08-27 18:17:17,099 - INFO - Epoch: [0][300/391] Time 0.020 (0.024) Data 0.003 (0.004) Loss 1.4839 (1.6826) Acc@1 41.406 (36.358) Acc@5 89.844 (87.443)
2025-08-27 18:17:17,470 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:17:17,471 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:17:19,183 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 1.4382 (1.4382) Acc@1 50.781 (50.781) Acc@5 94.531 (94.531)
2025-08-27 18:17:20,085 - INFO - Epoch 0:
2025-08-27 18:17:20,085 - INFO -   Train: acc1: 39.5940 | acc5: 88.8100 | loss: 1.6090 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 18:17:20,085 - INFO -   Val:   acc1: 49.1700 | acc5: 93.9500 | loss: 1.4592
2025-08-27 18:17:20,085 - INFO -   LR: 0.100000
2025-08-27 18:17:20,130 - INFO - Checkpoint saved: epoch=0, metric=49.1700
2025-08-27 18:17:20,160 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 18:17:20,339 - INFO - Epoch: [1][0/391] Time 0.177 (0.177) Data 0.150 (0.150) Loss 1.3764 (1.3764) Acc@1 50.000 (50.000) Acc@5 92.969 (92.969)
2025-08-27 18:17:22,084 - INFO - Pruning info: sparsity=0.032
2025-08-27 18:17:22,084 - INFO -   Reactivation rate: 0.0085
2025-08-27 18:17:22,305 - INFO - Epoch: [1][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 1.1417 (1.2002) Acc@1 57.812 (55.894) Acc@5 93.750 (94.980)
2025-08-27 18:17:24,246 - INFO - Epoch: [1][200/391] Time 0.017 (0.020) Data 0.001 (0.002) Loss 0.9286 (1.1583) Acc@1 67.969 (57.863) Acc@5 98.438 (95.410)
2025-08-27 18:17:25,138 - INFO - Pruning info: sparsity=0.032
2025-08-27 18:17:25,138 - INFO -   Reactivation rate: 0.0057
2025-08-27 18:17:26,140 - INFO - Epoch: [1][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.9092 (1.1186) Acc@1 62.500 (59.445) Acc@5 96.875 (95.793)
2025-08-27 18:17:28,068 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 1.1426 (1.1426) Acc@1 57.812 (57.812) Acc@5 98.438 (98.438)
2025-08-27 18:17:28,896 - INFO - Epoch 1:
2025-08-27 18:17:28,896 - INFO -   Train: acc1: 60.7120 | acc5: 96.0360 | loss: 1.0882 | sparsity: 0.0316 | reactivation_rate: 0.0066
2025-08-27 18:17:28,896 - INFO -   Val:   acc1: 57.4000 | acc5: 94.9500 | loss: 1.2326
2025-08-27 18:17:28,896 - INFO -   LR: 0.100000
2025-08-27 18:17:28,943 - INFO - Checkpoint saved: epoch=1, metric=57.4000
2025-08-27 18:17:28,976 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 18:17:29,156 - INFO - Epoch: [2][0/391] Time 0.179 (0.179) Data 0.150 (0.150) Loss 0.8279 (0.8279) Acc@1 71.875 (71.875) Acc@5 98.438 (98.438)
2025-08-27 18:17:29,497 - INFO - Pruning info: sparsity=0.062
2025-08-27 18:17:29,497 - INFO -   Reactivation rate: 0.0137
2025-08-27 18:17:31,162 - INFO - Epoch: [2][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.9177 (0.9357) Acc@1 67.969 (67.056) Acc@5 96.094 (97.223)
2025-08-27 18:17:32,667 - INFO - Pruning info: sparsity=0.062
2025-08-27 18:17:32,668 - INFO -   Reactivation rate: 0.0071
2025-08-27 18:17:33,090 - INFO - Epoch: [2][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.8161 (0.9111) Acc@1 69.531 (67.681) Acc@5 100.000 (97.540)
2025-08-27 18:17:35,058 - INFO - Epoch: [2][300/391] Time 0.013 (0.020) Data 0.001 (0.002) Loss 0.9234 (0.8920) Acc@1 65.625 (68.597) Acc@5 100.000 (97.558)
2025-08-27 18:17:35,824 - INFO - Pruning info: sparsity=0.062
2025-08-27 18:17:35,824 - INFO -   Reactivation rate: 0.0052
2025-08-27 18:17:37,018 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.9569 (0.9569) Acc@1 64.844 (64.844) Acc@5 99.219 (99.219)
2025-08-27 18:17:37,892 - INFO - Epoch 2:
2025-08-27 18:17:37,892 - INFO -   Train: acc1: 69.1880 | acc5: 97.6060 | loss: 0.8760 | sparsity: 0.0623 | reactivation_rate: 0.0072
2025-08-27 18:17:37,892 - INFO -   Val:   acc1: 65.3600 | acc5: 96.4300 | loss: 1.0243
2025-08-27 18:17:37,892 - INFO -   LR: 0.100000
2025-08-27 18:17:38,008 - INFO - Checkpoint saved: epoch=2, metric=65.3600
2025-08-27 18:17:38,039 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 18:17:38,228 - INFO - Epoch: [3][0/391] Time 0.188 (0.188) Data 0.167 (0.167) Loss 0.8316 (0.8316) Acc@1 67.969 (67.969) Acc@5 96.094 (96.094)
2025-08-27 18:17:40,125 - INFO - Epoch: [3][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.7643 (0.7744) Acc@1 72.656 (73.167) Acc@5 96.094 (97.912)
2025-08-27 18:17:40,246 - INFO - Pruning info: sparsity=0.092
2025-08-27 18:17:40,246 - INFO -   Reactivation rate: 0.0088
2025-08-27 18:17:42,048 - INFO - Epoch: [3][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.7024 (0.7668) Acc@1 74.219 (73.671) Acc@5 97.656 (98.053)
2025-08-27 18:17:43,336 - INFO - Pruning info: sparsity=0.092
2025-08-27 18:17:43,336 - INFO -   Reactivation rate: 0.0060
2025-08-27 18:17:44,026 - INFO - Epoch: [3][300/391] Time 0.038 (0.020) Data 0.012 (0.002) Loss 0.7861 (0.7625) Acc@1 74.219 (73.785) Acc@5 98.438 (98.087)
2025-08-27 18:17:45,817 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.7991 (0.7991) Acc@1 71.875 (71.875) Acc@5 99.219 (99.219)
2025-08-27 18:17:46,672 - INFO - Epoch 3:
2025-08-27 18:17:46,672 - INFO -   Train: acc1: 73.6800 | acc5: 98.0880 | loss: 0.7640 | sparsity: 0.0922 | reactivation_rate: 0.0071
2025-08-27 18:17:46,672 - INFO -   Val:   acc1: 68.6600 | acc5: 97.1800 | loss: 0.9580
2025-08-27 18:17:46,672 - INFO -   LR: 0.100000
2025-08-27 18:17:46,716 - INFO - Checkpoint saved: epoch=3, metric=68.6600
2025-08-27 18:17:46,747 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 18:17:46,923 - INFO - Epoch: [4][0/391] Time 0.175 (0.175) Data 0.146 (0.146) Loss 0.7272 (0.7272) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-27 18:17:47,594 - INFO - Pruning info: sparsity=0.121
2025-08-27 18:17:47,595 - INFO -   Reactivation rate: 0.0110
2025-08-27 18:17:48,873 - INFO - Epoch: [4][100/391] Time 0.026 (0.021) Data 0.000 (0.003) Loss 0.6595 (0.7155) Acc@1 79.688 (75.147) Acc@5 97.656 (98.283)
2025-08-27 18:17:50,788 - INFO - Pruning info: sparsity=0.121
2025-08-27 18:17:50,788 - INFO -   Reactivation rate: 0.0066
2025-08-27 18:17:50,889 - INFO - Epoch: [4][200/391] Time 0.024 (0.021) Data 0.000 (0.002) Loss 0.7214 (0.7048) Acc@1 72.656 (75.529) Acc@5 99.219 (98.340)
2025-08-27 18:17:52,898 - INFO - Epoch: [4][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.7480 (0.7019) Acc@1 71.875 (75.529) Acc@5 96.875 (98.305)
2025-08-27 18:17:53,956 - INFO - Pruning info: sparsity=0.121
2025-08-27 18:17:53,956 - INFO -   Reactivation rate: 0.0049
2025-08-27 18:17:54,744 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 1.0618 (1.0618) Acc@1 66.406 (66.406) Acc@5 97.656 (97.656)
2025-08-27 18:17:55,586 - INFO - Epoch 4:
2025-08-27 18:17:55,586 - INFO -   Train: acc1: 75.7380 | acc5: 98.3540 | loss: 0.6978 | sparsity: 0.1213 | reactivation_rate: 0.0069
2025-08-27 18:17:55,587 - INFO -   Val:   acc1: 64.7200 | acc5: 97.5700 | loss: 1.0773
2025-08-27 18:17:55,587 - INFO -   LR: 0.100000
2025-08-27 18:17:55,595 - INFO - training time: 00h 00m 45.73s
2025-08-27 18:17:55,595 - INFO - 
Training completed!
2025-08-27 18:17:55,595 - INFO - Best accuracy: 68.6600
2025-08-27 18:17:55,595 - INFO - Total training time: 0.01 hours
2025-08-27 18:17:55,595 - INFO - total_experiment time: 00h 00m 46.94s
2025-08-27 18:17:55,597 - INFO - Experiment completed successfully
2025-08-27 18:17:55,597 - INFO - Total time: 0.01 hours
2025-08-27 22:16:36,665 - INFO - Starting experiment: dpf_sparsity0.8_seed42
2025-08-27 22:16:36,666 - INFO - Save directory: ./runs/dpf/sparsity0.8/seed42
2025-08-27 22:16:36,666 - INFO - Hyperparameters:
2025-08-27 22:16:36,666 - INFO -   name: dpf_sparsity0.8_seed42
2025-08-27 22:16:36,666 - INFO -   description: DPF pruning 80% (seed=42)
2025-08-27 22:16:36,666 - INFO -   save_dir: ./runs
2025-08-27 22:16:36,666 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 22:16:36,666 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 22:16:36,666 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 22:16:36,666 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.8, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 22:16:36,666 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 22:16:36,666 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 22:16:36,723 - INFO - System Information:
2025-08-27 22:16:36,723 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 22:16:36,723 - INFO -   python_version: 3.9.18
2025-08-27 22:16:36,724 - INFO -   pytorch_version: 2.1.0
2025-08-27 22:16:36,724 - INFO -   cuda_available: True
2025-08-27 22:16:36,724 - INFO -   cpu_count: 4
2025-08-27 22:16:36,724 - INFO -   memory_total_gb: 11.0
2025-08-27 22:16:36,724 - INFO -   timestamp: 1756300596.7235966
2025-08-27 22:16:36,724 - INFO -   cuda_version: 11.8
2025-08-27 22:16:36,724 - INFO -   gpu_count: 1
2025-08-27 22:16:36,724 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 22:16:36,730 - INFO - Starting experiment: dpf_sparsity0.8_seed42
2025-08-27 22:16:36,730 - INFO - Model: resnet-20
2025-08-27 22:16:36,730 - INFO - Dataset: cifar10
2025-08-27 22:16:36,730 - INFO - Pruning: dpf (80.00%)
2025-08-27 22:16:36,862 - INFO - Model Information:
2025-08-27 22:16:36,863 - INFO -   Type: pruned
2025-08-27 22:16:36,863 - INFO -   Total parameters: 544,948
2025-08-27 22:16:36,863 - INFO -   Trainable parameters: 274,692
2025-08-27 22:16:36,863 - INFO -   Sparsity: 80.00%
2025-08-27 22:16:37,890 - INFO - Starting training...
2025-08-27 22:16:37,890 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 22:16:38,598 - INFO - Pruning info: sparsity=0.000
2025-08-27 22:16:38,598 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:39,113 - INFO - Epoch: [0][0/391] Time 1.223 (1.223) Data 0.557 (0.557) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 22:16:41,115 - INFO - Epoch: [0][100/391] Time 0.018 (0.032) Data 0.000 (0.007) Loss 1.7275 (1.9442) Acc@1 39.062 (25.982) Acc@5 85.938 (80.593)
2025-08-27 22:16:42,189 - INFO - Pruning info: sparsity=0.000
2025-08-27 22:16:42,189 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:42,903 - INFO - Epoch: [0][200/391] Time 0.012 (0.025) Data 0.001 (0.004) Loss 1.4843 (1.7867) Acc@1 42.188 (32.746) Acc@5 92.969 (85.234)
2025-08-27 22:16:44,715 - INFO - Epoch: [0][300/391] Time 0.016 (0.023) Data 0.000 (0.004) Loss 1.3457 (1.6745) Acc@1 50.781 (37.552) Acc@5 96.094 (87.666)
2025-08-27 22:16:45,035 - INFO - Pruning info: sparsity=0.000
2025-08-27 22:16:45,036 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:16:46,672 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 1.2495 (1.2495) Acc@1 53.906 (53.906) Acc@5 95.312 (95.312)
2025-08-27 22:16:47,614 - INFO - Epoch 0:
2025-08-27 22:16:47,615 - INFO -   Train: acc1: 40.7740 | acc5: 89.0740 | loss: 1.5953 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 22:16:47,615 - INFO -   Val:   acc1: 54.7200 | acc5: 95.0200 | loss: 1.2801
2025-08-27 22:16:47,615 - INFO -   LR: 0.100000
2025-08-27 22:16:47,661 - INFO - Checkpoint saved: epoch=0, metric=54.7200
2025-08-27 22:16:47,692 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 22:16:47,896 - INFO - Epoch: [1][0/391] Time 0.204 (0.204) Data 0.165 (0.165) Loss 1.3867 (1.3867) Acc@1 48.438 (48.438) Acc@5 95.312 (95.312)
2025-08-27 22:16:49,533 - INFO - Pruning info: sparsity=0.032
2025-08-27 22:16:49,533 - INFO -   Reactivation rate: 0.0082
2025-08-27 22:16:49,738 - INFO - Epoch: [1][100/391] Time 0.031 (0.020) Data 0.019 (0.005) Loss 1.0109 (1.1932) Acc@1 61.719 (56.853) Acc@5 97.656 (95.305)
2025-08-27 22:16:51,586 - INFO - Epoch: [1][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.9905 (1.1479) Acc@1 63.281 (58.718) Acc@5 97.656 (95.530)
2025-08-27 22:16:52,492 - INFO - Pruning info: sparsity=0.032
2025-08-27 22:16:52,492 - INFO -   Reactivation rate: 0.0061
2025-08-27 22:16:53,447 - INFO - Epoch: [1][300/391] Time 0.029 (0.019) Data 0.003 (0.003) Loss 0.9798 (1.1086) Acc@1 64.844 (60.099) Acc@5 97.656 (95.878)
2025-08-27 22:16:55,210 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 1.0025 (1.0025) Acc@1 64.844 (64.844) Acc@5 99.219 (99.219)
2025-08-27 22:16:56,068 - INFO - Epoch 1:
2025-08-27 22:16:56,068 - INFO -   Train: acc1: 61.1960 | acc5: 96.1060 | loss: 1.0803 | sparsity: 0.0316 | reactivation_rate: 0.0066
2025-08-27 22:16:56,068 - INFO -   Val:   acc1: 60.4600 | acc5: 95.9300 | loss: 1.1682
2025-08-27 22:16:56,068 - INFO -   LR: 0.100000
2025-08-27 22:16:56,119 - INFO - Checkpoint saved: epoch=1, metric=60.4600
2025-08-27 22:16:56,152 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 22:16:56,339 - INFO - Epoch: [2][0/391] Time 0.186 (0.186) Data 0.170 (0.170) Loss 0.9356 (0.9356) Acc@1 67.188 (67.188) Acc@5 96.875 (96.875)
2025-08-27 22:16:56,614 - INFO - Pruning info: sparsity=0.062
2025-08-27 22:16:56,615 - INFO -   Reactivation rate: 0.0128
2025-08-27 22:16:58,172 - INFO - Epoch: [2][100/391] Time 0.024 (0.020) Data 0.000 (0.004) Loss 0.8094 (0.9419) Acc@1 71.094 (66.012) Acc@5 96.875 (97.355)
2025-08-27 22:16:59,585 - INFO - Pruning info: sparsity=0.062
2025-08-27 22:16:59,585 - INFO -   Reactivation rate: 0.0067
2025-08-27 22:17:00,027 - INFO - Epoch: [2][200/391] Time 0.018 (0.019) Data 0.002 (0.003) Loss 0.7735 (0.9130) Acc@1 71.094 (67.188) Acc@5 99.219 (97.512)
2025-08-27 22:17:01,887 - INFO - Epoch: [2][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.8337 (0.8983) Acc@1 66.406 (67.958) Acc@5 99.219 (97.477)
2025-08-27 22:17:02,557 - INFO - Pruning info: sparsity=0.062
2025-08-27 22:17:02,557 - INFO -   Reactivation rate: 0.0055
2025-08-27 22:17:03,646 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 1.0402 (1.0402) Acc@1 64.844 (64.844) Acc@5 96.875 (96.875)
2025-08-27 22:17:04,504 - INFO - Epoch 2:
2025-08-27 22:17:04,504 - INFO -   Train: acc1: 68.6520 | acc5: 97.5620 | loss: 0.8800 | sparsity: 0.0623 | reactivation_rate: 0.0070
2025-08-27 22:17:04,504 - INFO -   Val:   acc1: 65.3200 | acc5: 96.5300 | loss: 1.0578
2025-08-27 22:17:04,504 - INFO -   LR: 0.100000
2025-08-27 22:17:04,549 - INFO - Checkpoint saved: epoch=2, metric=65.3200
2025-08-27 22:17:04,582 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 22:17:04,747 - INFO - Epoch: [3][0/391] Time 0.164 (0.164) Data 0.147 (0.147) Loss 0.8461 (0.8461) Acc@1 70.312 (70.312) Acc@5 96.875 (96.875)
2025-08-27 22:17:06,567 - INFO - Epoch: [3][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.8116 (0.7673) Acc@1 71.094 (73.159) Acc@5 97.656 (98.213)
2025-08-27 22:17:06,678 - INFO - Pruning info: sparsity=0.092
2025-08-27 22:17:06,679 - INFO -   Reactivation rate: 0.0086
2025-08-27 22:17:08,355 - INFO - Epoch: [3][200/391] Time 0.022 (0.019) Data 0.011 (0.003) Loss 0.7702 (0.7673) Acc@1 74.219 (73.197) Acc@5 94.531 (98.158)
2025-08-27 22:17:09,495 - INFO - Pruning info: sparsity=0.092
2025-08-27 22:17:09,495 - INFO -   Reactivation rate: 0.0063
2025-08-27 22:17:10,122 - INFO - Epoch: [3][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.8290 (0.7634) Acc@1 71.094 (73.357) Acc@5 97.656 (98.173)
2025-08-27 22:17:11,895 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.8819 (0.8819) Acc@1 65.625 (65.625) Acc@5 98.438 (98.438)
2025-08-27 22:17:12,709 - INFO - Epoch 3:
2025-08-27 22:17:12,709 - INFO -   Train: acc1: 73.5860 | acc5: 98.1880 | loss: 0.7608 | sparsity: 0.0922 | reactivation_rate: 0.0072
2025-08-27 22:17:12,709 - INFO -   Val:   acc1: 69.4800 | acc5: 97.8700 | loss: 0.9102
2025-08-27 22:17:12,709 - INFO -   LR: 0.100000
2025-08-27 22:17:12,752 - INFO - Checkpoint saved: epoch=3, metric=69.4800
2025-08-27 22:17:12,783 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 22:17:12,963 - INFO - Epoch: [4][0/391] Time 0.179 (0.179) Data 0.159 (0.159) Loss 0.8288 (0.8288) Acc@1 65.625 (65.625) Acc@5 98.438 (98.438)
2025-08-27 22:17:13,565 - INFO - Pruning info: sparsity=0.121
2025-08-27 22:17:13,566 - INFO -   Reactivation rate: 0.0114
2025-08-27 22:17:14,719 - INFO - Epoch: [4][100/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.7161 (0.7125) Acc@1 79.688 (75.271) Acc@5 96.875 (98.383)
2025-08-27 22:17:16,418 - INFO - Pruning info: sparsity=0.121
2025-08-27 22:17:16,418 - INFO -   Reactivation rate: 0.0067
2025-08-27 22:17:16,488 - INFO - Epoch: [4][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.7156 (0.7044) Acc@1 73.438 (75.587) Acc@5 99.219 (98.371)
2025-08-27 22:17:18,233 - INFO - Epoch: [4][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.6556 (0.6993) Acc@1 81.250 (75.794) Acc@5 96.094 (98.425)
2025-08-27 22:17:19,221 - INFO - Pruning info: sparsity=0.121
2025-08-27 22:17:19,221 - INFO -   Reactivation rate: 0.0050
2025-08-27 22:17:19,955 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 1.2872 (1.2872) Acc@1 57.812 (57.812) Acc@5 98.438 (98.438)
2025-08-27 22:17:20,765 - INFO - Epoch 4:
2025-08-27 22:17:20,765 - INFO -   Train: acc1: 75.9380 | acc5: 98.4280 | loss: 0.6954 | sparsity: 0.1213 | reactivation_rate: 0.0070
2025-08-27 22:17:20,765 - INFO -   Val:   acc1: 61.7500 | acc5: 96.1200 | loss: 1.2511
2025-08-27 22:17:20,765 - INFO -   LR: 0.100000
2025-08-27 22:17:20,773 - INFO - 
Epoch: 5, lr = 0.1
2025-08-27 22:17:20,954 - INFO - Epoch: [5][0/391] Time 0.181 (0.181) Data 0.163 (0.163) Loss 0.7816 (0.7816) Acc@1 73.438 (73.438) Acc@5 97.656 (97.656)
2025-08-27 22:17:22,698 - INFO - Epoch: [5][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.6584 (0.6722) Acc@1 78.906 (76.648) Acc@5 100.000 (98.538)
2025-08-27 22:17:23,204 - INFO - Pruning info: sparsity=0.150
2025-08-27 22:17:23,204 - INFO -   Reactivation rate: 0.0080
2025-08-27 22:17:24,519 - INFO - Epoch: [5][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.6351 (0.6600) Acc@1 79.688 (77.134) Acc@5 98.438 (98.562)
2025-08-27 22:17:26,013 - INFO - Pruning info: sparsity=0.150
2025-08-27 22:17:26,013 - INFO -   Reactivation rate: 0.0055
2025-08-27 22:17:26,283 - INFO - Epoch: [5][300/391] Time 0.021 (0.018) Data 0.008 (0.003) Loss 0.7264 (0.6590) Acc@1 70.312 (77.110) Acc@5 97.656 (98.593)
2025-08-27 22:17:28,042 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.8604 (0.8604) Acc@1 74.219 (74.219) Acc@5 96.875 (96.875)
2025-08-27 22:17:28,864 - INFO - Epoch 5:
2025-08-27 22:17:28,864 - INFO -   Train: acc1: 77.1340 | acc5: 98.6320 | loss: 0.6589 | sparsity: 0.1496 | reactivation_rate: 0.0069
2025-08-27 22:17:28,864 - INFO -   Val:   acc1: 69.4600 | acc5: 97.4500 | loss: 0.9413
2025-08-27 22:17:28,864 - INFO -   LR: 0.100000
2025-08-27 22:17:28,873 - INFO - 
Epoch: 6, lr = 0.1
2025-08-27 22:17:29,067 - INFO - Epoch: [6][0/391] Time 0.193 (0.193) Data 0.168 (0.168) Loss 0.5145 (0.5145) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:17:29,986 - INFO - Pruning info: sparsity=0.177
2025-08-27 22:17:29,986 - INFO -   Reactivation rate: 0.0102
2025-08-27 22:17:30,794 - INFO - Epoch: [6][100/391] Time 0.023 (0.019) Data 0.000 (0.005) Loss 0.6291 (0.6152) Acc@1 80.469 (78.690) Acc@5 98.438 (98.731)
2025-08-27 22:17:32,544 - INFO - Epoch: [6][200/391] Time 0.012 (0.018) Data 0.000 (0.004) Loss 0.6316 (0.6235) Acc@1 74.219 (78.323) Acc@5 99.219 (98.690)
2025-08-27 22:17:32,806 - INFO - Pruning info: sparsity=0.177
2025-08-27 22:17:32,806 - INFO -   Reactivation rate: 0.0063
2025-08-27 22:17:34,391 - INFO - Epoch: [6][300/391] Time 0.025 (0.018) Data 0.002 (0.003) Loss 0.6586 (0.6297) Acc@1 78.125 (78.195) Acc@5 98.438 (98.697)
2025-08-27 22:17:35,715 - INFO - Pruning info: sparsity=0.177
2025-08-27 22:17:35,716 - INFO -   Reactivation rate: 0.0049
2025-08-27 22:17:36,120 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5629 (0.5629) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 22:17:36,929 - INFO - Epoch 6:
2025-08-27 22:17:36,929 - INFO -   Train: acc1: 78.3980 | acc5: 98.7440 | loss: 0.6275 | sparsity: 0.1771 | reactivation_rate: 0.0068
2025-08-27 22:17:36,929 - INFO -   Val:   acc1: 75.8400 | acc5: 98.4400 | loss: 0.7045
2025-08-27 22:17:36,929 - INFO -   LR: 0.100000
2025-08-27 22:17:36,970 - INFO - Checkpoint saved: epoch=6, metric=75.8400
2025-08-27 22:17:37,000 - INFO - 
Epoch: 7, lr = 0.1
2025-08-27 22:17:37,167 - INFO - Epoch: [7][0/391] Time 0.166 (0.166) Data 0.145 (0.145) Loss 0.5948 (0.5948) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 22:17:38,997 - INFO - Epoch: [7][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.6587 (0.6092) Acc@1 76.562 (79.185) Acc@5 98.438 (98.708)
2025-08-27 22:17:39,802 - INFO - Pruning info: sparsity=0.204
2025-08-27 22:17:39,802 - INFO -   Reactivation rate: 0.0076
2025-08-27 22:17:40,834 - INFO - Epoch: [7][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5034 (0.6035) Acc@1 82.812 (79.256) Acc@5 99.219 (98.799)
2025-08-27 22:17:42,544 - INFO - Epoch: [7][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4793 (0.6013) Acc@1 83.594 (79.311) Acc@5 98.438 (98.783)
2025-08-27 22:17:42,625 - INFO - Pruning info: sparsity=0.204
2025-08-27 22:17:42,625 - INFO -   Reactivation rate: 0.0054
2025-08-27 22:17:44,297 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 1.0244 (1.0244) Acc@1 71.094 (71.094) Acc@5 96.875 (96.875)
2025-08-27 22:17:45,134 - INFO - Epoch 7:
2025-08-27 22:17:45,134 - INFO -   Train: acc1: 79.3020 | acc5: 98.8120 | loss: 0.5992 | sparsity: 0.2037 | reactivation_rate: 0.0067
2025-08-27 22:17:45,134 - INFO -   Val:   acc1: 67.6200 | acc5: 93.9700 | loss: 1.1895
2025-08-27 22:17:45,134 - INFO -   LR: 0.100000
2025-08-27 22:17:45,142 - INFO - 
Epoch: 8, lr = 0.1
2025-08-27 22:17:45,333 - INFO - Epoch: [8][0/391] Time 0.191 (0.191) Data 0.167 (0.167) Loss 0.5184 (0.5184) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-27 22:17:46,571 - INFO - Pruning info: sparsity=0.230
2025-08-27 22:17:46,571 - INFO -   Reactivation rate: 0.0091
2025-08-27 22:17:47,080 - INFO - Epoch: [8][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5563 (0.5884) Acc@1 75.781 (79.873) Acc@5 100.000 (98.731)
2025-08-27 22:17:48,846 - INFO - Epoch: [8][200/391] Time 0.029 (0.018) Data 0.000 (0.003) Loss 0.4669 (0.5766) Acc@1 86.719 (80.236) Acc@5 99.219 (98.803)
2025-08-27 22:17:49,401 - INFO - Pruning info: sparsity=0.230
2025-08-27 22:17:49,414 - INFO -   Reactivation rate: 0.0055
2025-08-27 22:17:50,621 - INFO - Epoch: [8][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.6671 (0.5843) Acc@1 78.125 (79.983) Acc@5 97.656 (98.832)
2025-08-27 22:17:52,371 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.8845 (0.8845) Acc@1 68.750 (68.750) Acc@5 99.219 (99.219)
2025-08-27 22:17:53,176 - INFO - Epoch 8:
2025-08-27 22:17:53,177 - INFO -   Train: acc1: 80.0640 | acc5: 98.9020 | loss: 0.5802 | sparsity: 0.2297 | reactivation_rate: 0.0065
2025-08-27 22:17:53,177 - INFO -   Val:   acc1: 74.5900 | acc5: 98.1800 | loss: 0.7567
2025-08-27 22:17:53,177 - INFO -   LR: 0.100000
2025-08-27 22:17:53,185 - INFO - 
Epoch: 9, lr = 0.1
2025-08-27 22:17:53,359 - INFO - Epoch: [9][0/391] Time 0.163 (0.163) Data 0.131 (0.131) Loss 0.4481 (0.4481) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:17:53,365 - INFO - Pruning info: sparsity=0.255
2025-08-27 22:17:53,365 - INFO -   Reactivation rate: 0.0011
2025-08-27 22:17:55,124 - INFO - Epoch: [9][100/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.4855 (0.5657) Acc@1 83.594 (80.368) Acc@5 97.656 (98.940)
2025-08-27 22:17:56,237 - INFO - Pruning info: sparsity=0.255
2025-08-27 22:17:56,238 - INFO -   Reactivation rate: 0.0065
2025-08-27 22:17:56,946 - INFO - Epoch: [9][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.5268 (0.5643) Acc@1 84.375 (80.329) Acc@5 100.000 (98.954)
2025-08-27 22:17:58,763 - INFO - Epoch: [9][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.7714 (0.5673) Acc@1 73.438 (80.196) Acc@5 96.875 (98.910)
2025-08-27 22:17:59,160 - INFO - Pruning info: sparsity=0.255
2025-08-27 22:17:59,160 - INFO -   Reactivation rate: 0.0046
2025-08-27 22:18:00,568 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.9532 (0.9532) Acc@1 67.969 (67.969) Acc@5 96.875 (96.875)
2025-08-27 22:18:01,410 - INFO - Epoch 9:
2025-08-27 22:18:01,411 - INFO -   Train: acc1: 80.2140 | acc5: 98.9320 | loss: 0.5679 | sparsity: 0.2548 | reactivation_rate: 0.0063
2025-08-27 22:18:01,411 - INFO -   Val:   acc1: 72.9800 | acc5: 97.5800 | loss: 0.8167
2025-08-27 22:18:01,411 - INFO -   LR: 0.100000
2025-08-27 22:18:01,421 - INFO - 
Epoch: 10, lr = 0.1
2025-08-27 22:18:01,581 - INFO - Epoch: [10][0/391] Time 0.159 (0.159) Data 0.136 (0.136) Loss 0.5258 (0.5258) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:18:03,204 - INFO - Pruning info: sparsity=0.279
2025-08-27 22:18:03,204 - INFO -   Reactivation rate: 0.0076
2025-08-27 22:18:03,447 - INFO - Epoch: [10][100/391] Time 0.019 (0.020) Data 0.001 (0.003) Loss 0.4334 (0.5396) Acc@1 85.156 (81.761) Acc@5 99.219 (99.033)
2025-08-27 22:18:05,226 - INFO - Epoch: [10][200/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.5232 (0.5443) Acc@1 82.812 (81.359) Acc@5 100.000 (99.067)
2025-08-27 22:18:06,198 - INFO - Pruning info: sparsity=0.279
2025-08-27 22:18:06,198 - INFO -   Reactivation rate: 0.0051
2025-08-27 22:18:07,103 - INFO - Epoch: [10][300/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.7589 (0.5455) Acc@1 80.469 (81.279) Acc@5 97.656 (99.047)
2025-08-27 22:18:08,886 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.7057 (0.7057) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-27 22:18:09,749 - INFO - Epoch 10:
2025-08-27 22:18:09,750 - INFO -   Train: acc1: 81.1540 | acc5: 99.0120 | loss: 0.5488 | sparsity: 0.2792 | reactivation_rate: 0.0060
2025-08-27 22:18:09,750 - INFO -   Val:   acc1: 73.7000 | acc5: 98.2400 | loss: 0.8259
2025-08-27 22:18:09,750 - INFO -   LR: 0.100000
2025-08-27 22:18:09,791 - INFO - 
Epoch: 11, lr = 0.1
2025-08-27 22:18:09,980 - INFO - Epoch: [11][0/391] Time 0.188 (0.188) Data 0.158 (0.158) Loss 0.5922 (0.5922) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 22:18:10,314 - INFO - Pruning info: sparsity=0.303
2025-08-27 22:18:10,315 - INFO -   Reactivation rate: 0.0109
2025-08-27 22:18:11,755 - INFO - Epoch: [11][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5015 (0.5305) Acc@1 85.938 (81.513) Acc@5 99.219 (99.226)
2025-08-27 22:18:13,210 - INFO - Pruning info: sparsity=0.303
2025-08-27 22:18:13,210 - INFO -   Reactivation rate: 0.0056
2025-08-27 22:18:13,615 - INFO - Epoch: [11][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.6524 (0.5328) Acc@1 78.906 (81.503) Acc@5 97.656 (99.164)
2025-08-27 22:18:15,449 - INFO - Epoch: [11][300/391] Time 0.028 (0.019) Data 0.014 (0.004) Loss 0.6383 (0.5379) Acc@1 78.906 (81.382) Acc@5 96.875 (99.128)
2025-08-27 22:18:16,136 - INFO - Pruning info: sparsity=0.303
2025-08-27 22:18:16,136 - INFO -   Reactivation rate: 0.0043
2025-08-27 22:18:17,217 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.7269 (0.7269) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 22:18:18,044 - INFO - Epoch 11:
2025-08-27 22:18:18,044 - INFO -   Train: acc1: 81.3180 | acc5: 99.1060 | loss: 0.5401 | sparsity: 0.3029 | reactivation_rate: 0.0058
2025-08-27 22:18:18,044 - INFO -   Val:   acc1: 72.4000 | acc5: 98.2600 | loss: 0.8700
2025-08-27 22:18:18,044 - INFO -   LR: 0.100000
2025-08-27 22:18:18,053 - INFO - 
Epoch: 12, lr = 0.1
2025-08-27 22:18:18,233 - INFO - Epoch: [12][0/391] Time 0.180 (0.180) Data 0.161 (0.161) Loss 0.5317 (0.5317) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 22:18:20,034 - INFO - Epoch: [12][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4617 (0.5396) Acc@1 82.031 (81.320) Acc@5 100.000 (99.025)
2025-08-27 22:18:20,170 - INFO - Pruning info: sparsity=0.326
2025-08-27 22:18:20,171 - INFO -   Reactivation rate: 0.0069
2025-08-27 22:18:21,806 - INFO - Epoch: [12][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.7570 (0.5232) Acc@1 75.000 (81.950) Acc@5 99.219 (99.118)
2025-08-27 22:18:23,036 - INFO - Pruning info: sparsity=0.326
2025-08-27 22:18:23,049 - INFO -   Reactivation rate: 0.0046
2025-08-27 22:18:23,611 - INFO - Epoch: [12][300/391] Time 0.022 (0.018) Data 0.000 (0.003) Loss 0.5179 (0.5285) Acc@1 83.594 (81.834) Acc@5 100.000 (99.115)
2025-08-27 22:18:25,393 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.7205 (0.7205) Acc@1 73.438 (73.438) Acc@5 97.656 (97.656)
2025-08-27 22:18:26,263 - INFO - Epoch 12:
2025-08-27 22:18:26,264 - INFO -   Train: acc1: 81.8920 | acc5: 99.1340 | loss: 0.5297 | sparsity: 0.3258 | reactivation_rate: 0.0058
2025-08-27 22:18:26,264 - INFO -   Val:   acc1: 72.4600 | acc5: 97.6900 | loss: 0.9043
2025-08-27 22:18:26,264 - INFO -   LR: 0.100000
2025-08-27 22:18:26,271 - INFO - 
Epoch: 13, lr = 0.1
2025-08-27 22:18:26,462 - INFO - Epoch: [13][0/391] Time 0.190 (0.190) Data 0.162 (0.162) Loss 0.5094 (0.5094) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 22:18:27,111 - INFO - Pruning info: sparsity=0.348
2025-08-27 22:18:27,111 - INFO -   Reactivation rate: 0.0088
2025-08-27 22:18:28,300 - INFO - Epoch: [13][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4844 (0.5030) Acc@1 83.594 (82.650) Acc@5 97.656 (99.103)
2025-08-27 22:18:30,117 - INFO - Pruning info: sparsity=0.348
2025-08-27 22:18:30,118 - INFO -   Reactivation rate: 0.0051
2025-08-27 22:18:30,208 - INFO - Epoch: [13][200/391] Time 0.025 (0.020) Data 0.012 (0.003) Loss 0.3576 (0.5172) Acc@1 86.719 (82.035) Acc@5 99.219 (99.129)
2025-08-27 22:18:32,025 - INFO - Epoch: [13][300/391] Time 0.053 (0.019) Data 0.041 (0.003) Loss 0.5689 (0.5220) Acc@1 82.812 (81.896) Acc@5 99.219 (99.138)
2025-08-27 22:18:33,093 - INFO - Pruning info: sparsity=0.348
2025-08-27 22:18:33,094 - INFO -   Reactivation rate: 0.0039
2025-08-27 22:18:33,795 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.7280 (0.7280) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 22:18:34,681 - INFO - Epoch 13:
2025-08-27 22:18:34,682 - INFO -   Train: acc1: 81.8960 | acc5: 99.0900 | loss: 0.5239 | sparsity: 0.3481 | reactivation_rate: 0.0054
2025-08-27 22:18:34,682 - INFO -   Val:   acc1: 75.0000 | acc5: 98.5200 | loss: 0.7612
2025-08-27 22:18:34,682 - INFO -   LR: 0.100000
2025-08-27 22:18:34,693 - INFO - 
Epoch: 14, lr = 0.1
2025-08-27 22:18:34,876 - INFO - Epoch: [14][0/391] Time 0.182 (0.182) Data 0.150 (0.150) Loss 0.4902 (0.4902) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:18:36,694 - INFO - Epoch: [14][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.6508 (0.5043) Acc@1 75.781 (82.519) Acc@5 97.656 (99.172)
2025-08-27 22:18:37,227 - INFO - Pruning info: sparsity=0.370
2025-08-27 22:18:37,228 - INFO -   Reactivation rate: 0.0064
2025-08-27 22:18:38,532 - INFO - Epoch: [14][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5427 (0.5102) Acc@1 85.938 (82.160) Acc@5 100.000 (99.180)
2025-08-27 22:18:40,131 - INFO - Pruning info: sparsity=0.370
2025-08-27 22:18:40,144 - INFO -   Reactivation rate: 0.0042
2025-08-27 22:18:40,434 - INFO - Epoch: [14][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3846 (0.5109) Acc@1 86.719 (82.065) Acc@5 100.000 (99.182)
2025-08-27 22:18:42,192 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.8852 (0.8852) Acc@1 74.219 (74.219) Acc@5 95.312 (95.312)
2025-08-27 22:18:43,025 - INFO - Epoch 14:
2025-08-27 22:18:43,025 - INFO -   Train: acc1: 81.9640 | acc5: 99.1460 | loss: 0.5158 | sparsity: 0.3696 | reactivation_rate: 0.0053
2025-08-27 22:18:43,025 - INFO -   Val:   acc1: 74.1900 | acc5: 97.2300 | loss: 0.8306
2025-08-27 22:18:43,025 - INFO -   LR: 0.100000
2025-08-27 22:18:43,034 - INFO - 
Epoch: 15, lr = 0.1
2025-08-27 22:18:43,239 - INFO - Epoch: [15][0/391] Time 0.202 (0.202) Data 0.180 (0.180) Loss 0.5088 (0.5088) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-27 22:18:44,204 - INFO - Pruning info: sparsity=0.390
2025-08-27 22:18:44,204 - INFO -   Reactivation rate: 0.0077
2025-08-27 22:18:45,036 - INFO - Epoch: [15][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4354 (0.4952) Acc@1 84.375 (82.689) Acc@5 100.000 (99.281)
2025-08-27 22:18:46,893 - INFO - Epoch: [15][200/391] Time 0.021 (0.019) Data 0.006 (0.004) Loss 0.6818 (0.5087) Acc@1 77.344 (82.443) Acc@5 99.219 (99.149)
2025-08-27 22:18:47,141 - INFO - Pruning info: sparsity=0.390
2025-08-27 22:18:47,141 - INFO -   Reactivation rate: 0.0046
2025-08-27 22:18:48,668 - INFO - Epoch: [15][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4630 (0.5081) Acc@1 87.500 (82.496) Acc@5 97.656 (99.175)
2025-08-27 22:18:49,989 - INFO - Pruning info: sparsity=0.390
2025-08-27 22:18:49,995 - INFO -   Reactivation rate: 0.0035
2025-08-27 22:18:50,401 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.6631 (0.6631) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:18:51,221 - INFO - Epoch 15:
2025-08-27 22:18:51,221 - INFO -   Train: acc1: 82.4560 | acc5: 99.1760 | loss: 0.5086 | sparsity: 0.3904 | reactivation_rate: 0.0051
2025-08-27 22:18:51,221 - INFO -   Val:   acc1: 78.9400 | acc5: 98.8800 | loss: 0.6414
2025-08-27 22:18:51,221 - INFO -   LR: 0.100000
2025-08-27 22:18:51,264 - INFO - Checkpoint saved: epoch=15, metric=78.9400
2025-08-27 22:18:51,297 - INFO - 
Epoch: 16, lr = 0.1
2025-08-27 22:18:51,504 - INFO - Epoch: [16][0/391] Time 0.206 (0.206) Data 0.160 (0.160) Loss 0.5234 (0.5234) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 22:18:53,302 - INFO - Epoch: [16][100/391] Time 0.035 (0.020) Data 0.013 (0.004) Loss 0.5249 (0.5017) Acc@1 82.812 (82.604) Acc@5 99.219 (99.188)
2025-08-27 22:18:54,045 - INFO - Pruning info: sparsity=0.411
2025-08-27 22:18:54,046 - INFO -   Reactivation rate: 0.0052
2025-08-27 22:18:55,098 - INFO - Epoch: [16][200/391] Time 0.027 (0.019) Data 0.013 (0.003) Loss 0.5549 (0.4992) Acc@1 81.250 (82.746) Acc@5 99.219 (99.211)
2025-08-27 22:18:56,925 - INFO - Epoch: [16][300/391] Time 0.031 (0.019) Data 0.002 (0.003) Loss 0.6529 (0.5006) Acc@1 79.688 (82.620) Acc@5 100.000 (99.211)
2025-08-27 22:18:57,004 - INFO - Pruning info: sparsity=0.411
2025-08-27 22:18:57,004 - INFO -   Reactivation rate: 0.0038
2025-08-27 22:18:58,667 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.6383 (0.6383) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:18:59,545 - INFO - Epoch 16:
2025-08-27 22:18:59,545 - INFO -   Train: acc1: 82.6880 | acc5: 99.2120 | loss: 0.4994 | sparsity: 0.4105 | reactivation_rate: 0.0049
2025-08-27 22:18:59,546 - INFO -   Val:   acc1: 78.3300 | acc5: 98.9300 | loss: 0.6537
2025-08-27 22:18:59,546 - INFO -   LR: 0.100000
2025-08-27 22:18:59,554 - INFO - 
Epoch: 17, lr = 0.1
2025-08-27 22:18:59,761 - INFO - Epoch: [17][0/391] Time 0.207 (0.207) Data 0.179 (0.179) Loss 0.4635 (0.4635) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:19:01,073 - INFO - Pruning info: sparsity=0.430
2025-08-27 22:19:01,073 - INFO -   Reactivation rate: 0.0068
2025-08-27 22:19:01,591 - INFO - Epoch: [17][100/391] Time 0.012 (0.020) Data 0.001 (0.004) Loss 0.3874 (0.4906) Acc@1 90.625 (83.060) Acc@5 100.000 (99.257)
2025-08-27 22:19:03,477 - INFO - Epoch: [17][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4577 (0.4904) Acc@1 84.375 (83.057) Acc@5 99.219 (99.265)
2025-08-27 22:19:04,033 - INFO - Pruning info: sparsity=0.430
2025-08-27 22:19:04,046 - INFO -   Reactivation rate: 0.0041
2025-08-27 22:19:05,348 - INFO - Epoch: [17][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.5112 (0.4998) Acc@1 82.031 (82.654) Acc@5 100.000 (99.237)
2025-08-27 22:19:07,172 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.7597 (0.7597) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:19:08,011 - INFO - Epoch 17:
2025-08-27 22:19:08,011 - INFO -   Train: acc1: 82.7960 | acc5: 99.2280 | loss: 0.4980 | sparsity: 0.4300 | reactivation_rate: 0.0048
2025-08-27 22:19:08,011 - INFO -   Val:   acc1: 73.6300 | acc5: 98.3000 | loss: 0.8421
2025-08-27 22:19:08,011 - INFO -   LR: 0.100000
2025-08-27 22:19:08,020 - INFO - 
Epoch: 18, lr = 0.1
2025-08-27 22:19:08,213 - INFO - Epoch: [18][0/391] Time 0.191 (0.191) Data 0.173 (0.173) Loss 0.4350 (0.4350) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:19:08,233 - INFO - Pruning info: sparsity=0.449
2025-08-27 22:19:08,233 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:19:09,978 - INFO - Epoch: [18][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5021 (0.4845) Acc@1 84.375 (83.377) Acc@5 98.438 (99.219)
2025-08-27 22:19:11,065 - INFO - Pruning info: sparsity=0.449
2025-08-27 22:19:11,073 - INFO -   Reactivation rate: 0.0045
2025-08-27 22:19:11,815 - INFO - Epoch: [18][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.4893 (0.4899) Acc@1 85.938 (83.225) Acc@5 97.656 (99.215)
2025-08-27 22:19:13,604 - INFO - Epoch: [18][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.5783 (0.4892) Acc@1 80.469 (83.233) Acc@5 99.219 (99.193)
2025-08-27 22:19:14,007 - INFO - Pruning info: sparsity=0.449
2025-08-27 22:19:14,007 - INFO -   Reactivation rate: 0.0033
2025-08-27 22:19:15,376 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 1.0804 (1.0804) Acc@1 69.531 (69.531) Acc@5 96.094 (96.094)
2025-08-27 22:19:16,217 - INFO - Epoch 18:
2025-08-27 22:19:16,217 - INFO -   Train: acc1: 83.1700 | acc5: 99.2140 | loss: 0.4898 | sparsity: 0.4488 | reactivation_rate: 0.0044
2025-08-27 22:19:16,218 - INFO -   Val:   acc1: 64.9400 | acc5: 95.8800 | loss: 1.2735
2025-08-27 22:19:16,218 - INFO -   LR: 0.100000
2025-08-27 22:19:16,226 - INFO - 
Epoch: 19, lr = 0.1
2025-08-27 22:19:16,410 - INFO - Epoch: [19][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.4791 (0.4791) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:19:18,094 - INFO - Pruning info: sparsity=0.467
2025-08-27 22:19:18,094 - INFO -   Reactivation rate: 0.0057
2025-08-27 22:19:18,258 - INFO - Epoch: [19][100/391] Time 0.024 (0.020) Data 0.000 (0.005) Loss 0.4281 (0.4932) Acc@1 81.250 (83.122) Acc@5 100.000 (99.319)
2025-08-27 22:19:20,111 - INFO - Epoch: [19][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4169 (0.4898) Acc@1 85.938 (83.182) Acc@5 99.219 (99.296)
2025-08-27 22:19:21,054 - INFO - Pruning info: sparsity=0.467
2025-08-27 22:19:21,054 - INFO -   Reactivation rate: 0.0037
2025-08-27 22:19:22,022 - INFO - Epoch: [19][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.3389 (0.4931) Acc@1 88.281 (83.036) Acc@5 100.000 (99.294)
2025-08-27 22:19:23,796 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5505 (0.5505) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:19:24,623 - INFO - Epoch 19:
2025-08-27 22:19:24,623 - INFO -   Train: acc1: 83.1400 | acc5: 99.2640 | loss: 0.4900 | sparsity: 0.4670 | reactivation_rate: 0.0044
2025-08-27 22:19:24,623 - INFO -   Val:   acc1: 77.9800 | acc5: 98.8700 | loss: 0.6727
2025-08-27 22:19:24,624 - INFO -   LR: 0.100000
2025-08-27 22:19:24,633 - INFO - 
Epoch: 20, lr = 0.1
2025-08-27 22:19:24,795 - INFO - Epoch: [20][0/391] Time 0.161 (0.161) Data 0.143 (0.143) Loss 0.4961 (0.4961) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:19:25,178 - INFO - Pruning info: sparsity=0.485
2025-08-27 22:19:25,179 - INFO -   Reactivation rate: 0.0078
2025-08-27 22:19:26,626 - INFO - Epoch: [20][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2980 (0.4699) Acc@1 91.406 (83.779) Acc@5 99.219 (99.288)
2025-08-27 22:19:28,029 - INFO - Pruning info: sparsity=0.485
2025-08-27 22:19:28,041 - INFO -   Reactivation rate: 0.0043
2025-08-27 22:19:28,388 - INFO - Epoch: [20][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4450 (0.4817) Acc@1 83.594 (83.415) Acc@5 100.000 (99.238)
2025-08-27 22:19:30,228 - INFO - Epoch: [20][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4635 (0.4804) Acc@1 82.812 (83.464) Acc@5 97.656 (99.203)
2025-08-27 22:19:30,952 - INFO - Pruning info: sparsity=0.485
2025-08-27 22:19:30,952 - INFO -   Reactivation rate: 0.0029
2025-08-27 22:19:31,978 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.7293 (0.7293) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 22:19:32,799 - INFO - Epoch 20:
2025-08-27 22:19:32,799 - INFO -   Train: acc1: 83.2800 | acc5: 99.2260 | loss: 0.4835 | sparsity: 0.4845 | reactivation_rate: 0.0042
2025-08-27 22:19:32,799 - INFO -   Val:   acc1: 76.9000 | acc5: 98.8000 | loss: 0.7153
2025-08-27 22:19:32,799 - INFO -   LR: 0.100000
2025-08-27 22:19:32,845 - INFO - 
Epoch: 21, lr = 0.1
2025-08-27 22:19:33,018 - INFO - Epoch: [21][0/391] Time 0.172 (0.172) Data 0.149 (0.149) Loss 0.3876 (0.3876) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:19:34,768 - INFO - Epoch: [21][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5203 (0.4540) Acc@1 81.250 (84.592) Acc@5 99.219 (99.188)
2025-08-27 22:19:34,905 - INFO - Pruning info: sparsity=0.501
2025-08-27 22:19:34,905 - INFO -   Reactivation rate: 0.0052
2025-08-27 22:19:36,577 - INFO - Epoch: [21][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5326 (0.4686) Acc@1 80.469 (83.940) Acc@5 98.438 (99.176)
2025-08-27 22:19:37,795 - INFO - Pruning info: sparsity=0.501
2025-08-27 22:19:37,795 - INFO -   Reactivation rate: 0.0033
2025-08-27 22:19:38,323 - INFO - Epoch: [21][300/391] Time 0.030 (0.018) Data 0.016 (0.004) Loss 0.4872 (0.4730) Acc@1 82.812 (83.747) Acc@5 99.219 (99.198)
2025-08-27 22:19:40,050 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.6854 (0.6854) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-27 22:19:40,890 - INFO - Epoch 21:
2025-08-27 22:19:40,890 - INFO -   Train: acc1: 83.5780 | acc5: 99.2000 | loss: 0.4773 | sparsity: 0.5014 | reactivation_rate: 0.0040
2025-08-27 22:19:40,890 - INFO -   Val:   acc1: 79.2600 | acc5: 98.9300 | loss: 0.6146
2025-08-27 22:19:40,890 - INFO -   LR: 0.100000
2025-08-27 22:19:40,931 - INFO - Checkpoint saved: epoch=21, metric=79.2600
2025-08-27 22:19:40,963 - INFO - 
Epoch: 22, lr = 0.1
2025-08-27 22:19:41,147 - INFO - Epoch: [22][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.4488 (0.4488) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:19:41,785 - INFO - Pruning info: sparsity=0.518
2025-08-27 22:19:41,786 - INFO -   Reactivation rate: 0.0063
2025-08-27 22:19:42,915 - INFO - Epoch: [22][100/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.4967 (0.4616) Acc@1 82.812 (84.205) Acc@5 99.219 (99.281)
2025-08-27 22:19:44,612 - INFO - Pruning info: sparsity=0.518
2025-08-27 22:19:44,612 - INFO -   Reactivation rate: 0.0037
2025-08-27 22:19:44,680 - INFO - Epoch: [22][200/391] Time 0.022 (0.018) Data 0.000 (0.003) Loss 0.4470 (0.4612) Acc@1 85.156 (84.157) Acc@5 99.219 (99.269)
2025-08-27 22:19:46,448 - INFO - Epoch: [22][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.3452 (0.4647) Acc@1 89.062 (84.030) Acc@5 100.000 (99.289)
2025-08-27 22:19:47,460 - INFO - Pruning info: sparsity=0.518
2025-08-27 22:19:47,460 - INFO -   Reactivation rate: 0.0027
2025-08-27 22:19:48,155 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.7016 (0.7016) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 22:19:49,041 - INFO - Epoch 22:
2025-08-27 22:19:49,041 - INFO -   Train: acc1: 83.9180 | acc5: 99.2840 | loss: 0.4683 | sparsity: 0.5177 | reactivation_rate: 0.0038
2025-08-27 22:19:49,041 - INFO -   Val:   acc1: 77.4200 | acc5: 99.1100 | loss: 0.6738
2025-08-27 22:19:49,041 - INFO -   LR: 0.100000
2025-08-27 22:19:49,051 - INFO - 
Epoch: 23, lr = 0.1
2025-08-27 22:19:49,238 - INFO - Epoch: [23][0/391] Time 0.186 (0.186) Data 0.167 (0.167) Loss 0.4364 (0.4364) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 22:19:51,039 - INFO - Epoch: [23][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.5319 (0.4612) Acc@1 81.250 (84.646) Acc@5 97.656 (99.296)
2025-08-27 22:19:51,547 - INFO - Pruning info: sparsity=0.533
2025-08-27 22:19:51,547 - INFO -   Reactivation rate: 0.0045
2025-08-27 22:19:52,860 - INFO - Epoch: [23][200/391] Time 0.025 (0.019) Data 0.000 (0.004) Loss 0.5096 (0.4729) Acc@1 83.594 (83.994) Acc@5 98.438 (99.296)
2025-08-27 22:19:54,357 - INFO - Pruning info: sparsity=0.533
2025-08-27 22:19:54,358 - INFO -   Reactivation rate: 0.0029
2025-08-27 22:19:54,603 - INFO - Epoch: [23][300/391] Time 0.026 (0.018) Data 0.000 (0.003) Loss 0.4698 (0.4706) Acc@1 83.594 (84.030) Acc@5 100.000 (99.336)
2025-08-27 22:19:56,435 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.7146 (0.7146) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 22:19:57,296 - INFO - Epoch 23:
2025-08-27 22:19:57,296 - INFO -   Train: acc1: 83.8620 | acc5: 99.2900 | loss: 0.4726 | sparsity: 0.5334 | reactivation_rate: 0.0038
2025-08-27 22:19:57,296 - INFO -   Val:   acc1: 76.4000 | acc5: 98.8900 | loss: 0.7458
2025-08-27 22:19:57,296 - INFO -   LR: 0.100000
2025-08-27 22:19:57,308 - INFO - 
Epoch: 24, lr = 0.1
2025-08-27 22:19:57,488 - INFO - Epoch: [24][0/391] Time 0.179 (0.179) Data 0.159 (0.159) Loss 0.3920 (0.3920) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:19:58,419 - INFO - Pruning info: sparsity=0.548
2025-08-27 22:19:58,420 - INFO -   Reactivation rate: 0.0051
2025-08-27 22:19:59,280 - INFO - Epoch: [24][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.5763 (0.4792) Acc@1 75.781 (83.748) Acc@5 99.219 (99.234)
2025-08-27 22:20:01,087 - INFO - Epoch: [24][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.5677 (0.4749) Acc@1 81.250 (83.625) Acc@5 99.219 (99.296)
2025-08-27 22:20:01,414 - INFO - Pruning info: sparsity=0.548
2025-08-27 22:20:01,414 - INFO -   Reactivation rate: 0.0033
2025-08-27 22:20:02,931 - INFO - Epoch: [24][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4484 (0.4694) Acc@1 83.594 (83.721) Acc@5 100.000 (99.297)
2025-08-27 22:20:04,290 - INFO - Pruning info: sparsity=0.548
2025-08-27 22:20:04,291 - INFO -   Reactivation rate: 0.0026
2025-08-27 22:20:04,727 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 1.1218 (1.1218) Acc@1 67.969 (67.969) Acc@5 93.750 (93.750)
2025-08-27 22:20:05,557 - INFO - Epoch 24:
2025-08-27 22:20:05,557 - INFO -   Train: acc1: 83.7220 | acc5: 99.2540 | loss: 0.4692 | sparsity: 0.5485 | reactivation_rate: 0.0036
2025-08-27 22:20:05,557 - INFO -   Val:   acc1: 70.8700 | acc5: 96.1600 | loss: 0.9980
2025-08-27 22:20:05,557 - INFO -   LR: 0.100000
2025-08-27 22:20:05,567 - INFO - 
Epoch: 25, lr = 0.1
2025-08-27 22:20:05,739 - INFO - Epoch: [25][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 0.4469 (0.4469) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 22:20:07,578 - INFO - Epoch: [25][100/391] Time 0.028 (0.020) Data 0.017 (0.005) Loss 0.4623 (0.4394) Acc@1 84.375 (84.986) Acc@5 97.656 (99.335)
2025-08-27 22:20:08,361 - INFO - Pruning info: sparsity=0.563
2025-08-27 22:20:08,361 - INFO -   Reactivation rate: 0.0038
2025-08-27 22:20:09,335 - INFO - Epoch: [25][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.6239 (0.4603) Acc@1 80.469 (84.091) Acc@5 96.875 (99.339)
2025-08-27 22:20:11,186 - INFO - Epoch: [25][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4263 (0.4614) Acc@1 86.719 (84.209) Acc@5 99.219 (99.328)
2025-08-27 22:20:11,247 - INFO - Pruning info: sparsity=0.563
2025-08-27 22:20:11,249 - INFO -   Reactivation rate: 0.0025
2025-08-27 22:20:12,918 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.6276 (0.6276) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:20:13,732 - INFO - Epoch 25:
2025-08-27 22:20:13,732 - INFO -   Train: acc1: 84.0460 | acc5: 99.3200 | loss: 0.4649 | sparsity: 0.5630 | reactivation_rate: 0.0034
2025-08-27 22:20:13,732 - INFO -   Val:   acc1: 77.6000 | acc5: 99.0800 | loss: 0.6543
2025-08-27 22:20:13,732 - INFO -   LR: 0.100000
2025-08-27 22:20:13,743 - INFO - 
Epoch: 26, lr = 0.1
2025-08-27 22:20:13,914 - INFO - Epoch: [26][0/391] Time 0.169 (0.169) Data 0.133 (0.133) Loss 0.3223 (0.3223) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:20:15,259 - INFO - Pruning info: sparsity=0.577
2025-08-27 22:20:15,259 - INFO -   Reactivation rate: 0.0046
2025-08-27 22:20:15,718 - INFO - Epoch: [26][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.5514 (0.4593) Acc@1 82.031 (83.864) Acc@5 98.438 (99.312)
2025-08-27 22:20:17,532 - INFO - Epoch: [26][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.5374 (0.4572) Acc@1 81.250 (84.060) Acc@5 99.219 (99.277)
2025-08-27 22:20:18,169 - INFO - Pruning info: sparsity=0.577
2025-08-27 22:20:18,169 - INFO -   Reactivation rate: 0.0029
2025-08-27 22:20:19,342 - INFO - Epoch: [26][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6119 (0.4664) Acc@1 77.344 (83.620) Acc@5 100.000 (99.297)
2025-08-27 22:20:21,092 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.6112 (0.6112) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:20:21,937 - INFO - Epoch 26:
2025-08-27 22:20:21,937 - INFO -   Train: acc1: 83.7820 | acc5: 99.3040 | loss: 0.4619 | sparsity: 0.5769 | reactivation_rate: 0.0033
2025-08-27 22:20:21,937 - INFO -   Val:   acc1: 78.0300 | acc5: 99.0000 | loss: 0.6703
2025-08-27 22:20:21,937 - INFO -   LR: 0.100000
2025-08-27 22:20:21,946 - INFO - 
Epoch: 27, lr = 0.1
2025-08-27 22:20:22,127 - INFO - Epoch: [27][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.5116 (0.5116) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:20:22,345 - INFO - Pruning info: sparsity=0.590
2025-08-27 22:20:22,346 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:20:24,133 - INFO - Epoch: [27][100/391] Time 0.011 (0.022) Data 0.000 (0.005) Loss 0.6220 (0.4414) Acc@1 78.906 (85.079) Acc@5 99.219 (99.304)
2025-08-27 22:20:25,221 - INFO - Pruning info: sparsity=0.590
2025-08-27 22:20:25,221 - INFO -   Reactivation rate: 0.0033
2025-08-27 22:20:25,904 - INFO - Epoch: [27][200/391] Time 0.019 (0.020) Data 0.008 (0.004) Loss 0.3637 (0.4474) Acc@1 86.719 (84.593) Acc@5 99.219 (99.304)
2025-08-27 22:20:27,712 - INFO - Epoch: [27][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4509 (0.4495) Acc@1 84.375 (84.583) Acc@5 99.219 (99.354)
2025-08-27 22:20:28,142 - INFO - Pruning info: sparsity=0.590
2025-08-27 22:20:28,142 - INFO -   Reactivation rate: 0.0022
2025-08-27 22:20:29,471 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5809 (0.5809) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:20:30,310 - INFO - Epoch 27:
2025-08-27 22:20:30,311 - INFO -   Train: acc1: 84.3780 | acc5: 99.3120 | loss: 0.4546 | sparsity: 0.5903 | reactivation_rate: 0.0030
2025-08-27 22:20:30,311 - INFO -   Val:   acc1: 78.9900 | acc5: 98.8200 | loss: 0.6115
2025-08-27 22:20:30,311 - INFO -   LR: 0.100000
2025-08-27 22:20:30,321 - INFO - 
Epoch: 28, lr = 0.1
2025-08-27 22:20:30,495 - INFO - Epoch: [28][0/391] Time 0.173 (0.173) Data 0.153 (0.153) Loss 0.3417 (0.3417) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:20:32,160 - INFO - Pruning info: sparsity=0.603
2025-08-27 22:20:32,161 - INFO -   Reactivation rate: 0.0039
2025-08-27 22:20:32,305 - INFO - Epoch: [28][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4985 (0.4500) Acc@1 79.688 (84.553) Acc@5 99.219 (99.343)
2025-08-27 22:20:34,125 - INFO - Epoch: [28][200/391] Time 0.015 (0.019) Data 0.000 (0.005) Loss 0.4585 (0.4596) Acc@1 85.156 (84.157) Acc@5 98.438 (99.378)
2025-08-27 22:20:35,086 - INFO - Pruning info: sparsity=0.603
2025-08-27 22:20:35,099 - INFO -   Reactivation rate: 0.0025
2025-08-27 22:20:35,970 - INFO - Epoch: [28][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.4645 (0.4565) Acc@1 80.469 (84.196) Acc@5 99.219 (99.369)
2025-08-27 22:20:37,795 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.5965 (0.5965) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:20:38,643 - INFO - Epoch 28:
2025-08-27 22:20:38,643 - INFO -   Train: acc1: 84.2520 | acc5: 99.3760 | loss: 0.4553 | sparsity: 0.6031 | reactivation_rate: 0.0030
2025-08-27 22:20:38,643 - INFO -   Val:   acc1: 81.3600 | acc5: 98.9200 | loss: 0.5661
2025-08-27 22:20:38,643 - INFO -   LR: 0.100000
2025-08-27 22:20:38,690 - INFO - Checkpoint saved: epoch=28, metric=81.3600
2025-08-27 22:20:38,721 - INFO - 
Epoch: 29, lr = 0.1
2025-08-27 22:20:38,912 - INFO - Epoch: [29][0/391] Time 0.190 (0.190) Data 0.163 (0.163) Loss 0.5613 (0.5613) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-27 22:20:39,290 - INFO - Pruning info: sparsity=0.615
2025-08-27 22:20:39,291 - INFO -   Reactivation rate: 0.0051
2025-08-27 22:20:40,751 - INFO - Epoch: [29][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.4515 (0.4407) Acc@1 85.156 (84.514) Acc@5 98.438 (99.366)
2025-08-27 22:20:42,135 - INFO - Pruning info: sparsity=0.615
2025-08-27 22:20:42,135 - INFO -   Reactivation rate: 0.0028
2025-08-27 22:20:42,506 - INFO - Epoch: [29][200/391] Time 0.032 (0.019) Data 0.020 (0.004) Loss 0.4699 (0.4464) Acc@1 84.375 (84.635) Acc@5 100.000 (99.316)
2025-08-27 22:20:44,462 - INFO - Epoch: [29][300/391] Time 0.026 (0.019) Data 0.001 (0.003) Loss 0.4813 (0.4502) Acc@1 85.938 (84.489) Acc@5 99.219 (99.323)
2025-08-27 22:20:45,212 - INFO - Pruning info: sparsity=0.615
2025-08-27 22:20:45,222 - INFO -   Reactivation rate: 0.0019
2025-08-27 22:20:46,228 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.7062 (0.7062) Acc@1 78.125 (78.125) Acc@5 96.875 (96.875)
2025-08-27 22:20:47,062 - INFO - Epoch 29:
2025-08-27 22:20:47,063 - INFO -   Train: acc1: 84.5400 | acc5: 99.3460 | loss: 0.4479 | sparsity: 0.6154 | reactivation_rate: 0.0028
2025-08-27 22:20:47,063 - INFO -   Val:   acc1: 79.6600 | acc5: 98.3200 | loss: 0.6457
2025-08-27 22:20:47,063 - INFO -   LR: 0.100000
2025-08-27 22:20:47,071 - INFO - 
Epoch: 30, lr = 0.1
2025-08-27 22:20:47,264 - INFO - Epoch: [30][0/391] Time 0.192 (0.192) Data 0.170 (0.170) Loss 0.3162 (0.3162) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:20:49,042 - INFO - Epoch: [30][100/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.4304 (0.4554) Acc@1 85.938 (84.530) Acc@5 100.000 (99.281)
2025-08-27 22:20:49,249 - INFO - Pruning info: sparsity=0.627
2025-08-27 22:20:49,249 - INFO -   Reactivation rate: 0.0035
2025-08-27 22:20:50,862 - INFO - Epoch: [30][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4605 (0.4498) Acc@1 86.719 (84.628) Acc@5 99.219 (99.273)
2025-08-27 22:20:52,141 - INFO - Pruning info: sparsity=0.627
2025-08-27 22:20:52,141 - INFO -   Reactivation rate: 0.0024
2025-08-27 22:20:52,754 - INFO - Epoch: [30][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.4871 (0.4532) Acc@1 85.938 (84.422) Acc@5 100.000 (99.307)
2025-08-27 22:20:54,497 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.7094 (0.7094) Acc@1 76.562 (76.562) Acc@5 97.656 (97.656)
2025-08-27 22:20:55,399 - INFO - Epoch 30:
2025-08-27 22:20:55,399 - INFO -   Train: acc1: 84.4080 | acc5: 99.3180 | loss: 0.4532 | sparsity: 0.6272 | reactivation_rate: 0.0028
2025-08-27 22:20:55,399 - INFO -   Val:   acc1: 78.3700 | acc5: 98.5100 | loss: 0.7205
2025-08-27 22:20:55,400 - INFO -   LR: 0.100000
2025-08-27 22:20:55,449 - INFO - 
Epoch: 31, lr = 0.1
2025-08-27 22:20:55,619 - INFO - Epoch: [31][0/391] Time 0.170 (0.170) Data 0.140 (0.140) Loss 0.4978 (0.4978) Acc@1 86.719 (86.719) Acc@5 96.875 (96.875)
2025-08-27 22:20:56,338 - INFO - Pruning info: sparsity=0.638
2025-08-27 22:20:56,338 - INFO -   Reactivation rate: 0.0040
2025-08-27 22:20:57,484 - INFO - Epoch: [31][100/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.4150 (0.4350) Acc@1 83.594 (85.179) Acc@5 99.219 (99.443)
2025-08-27 22:20:59,344 - INFO - Pruning info: sparsity=0.638
2025-08-27 22:20:59,345 - INFO -   Reactivation rate: 0.0025
2025-08-27 22:20:59,376 - INFO - Epoch: [31][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3891 (0.4366) Acc@1 83.594 (85.160) Acc@5 99.219 (99.374)
2025-08-27 22:21:01,140 - INFO - Epoch: [31][300/391] Time 0.026 (0.019) Data 0.001 (0.003) Loss 0.4238 (0.4457) Acc@1 86.719 (84.819) Acc@5 99.219 (99.341)
2025-08-27 22:21:02,216 - INFO - Pruning info: sparsity=0.638
2025-08-27 22:21:02,217 - INFO -   Reactivation rate: 0.0019
2025-08-27 22:21:02,910 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.5792 (0.5792) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:21:03,736 - INFO - Epoch 31:
2025-08-27 22:21:03,737 - INFO -   Train: acc1: 84.6900 | acc5: 99.3480 | loss: 0.4468 | sparsity: 0.6385 | reactivation_rate: 0.0026
2025-08-27 22:21:03,737 - INFO -   Val:   acc1: 77.1000 | acc5: 98.6000 | loss: 0.6995
2025-08-27 22:21:03,737 - INFO -   LR: 0.100000
2025-08-27 22:21:03,747 - INFO - 
Epoch: 32, lr = 0.1
2025-08-27 22:21:03,940 - INFO - Epoch: [32][0/391] Time 0.192 (0.192) Data 0.146 (0.146) Loss 0.5225 (0.5225) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:21:05,767 - INFO - Epoch: [32][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3882 (0.4290) Acc@1 84.375 (85.203) Acc@5 100.000 (99.435)
2025-08-27 22:21:06,240 - INFO - Pruning info: sparsity=0.649
2025-08-27 22:21:06,241 - INFO -   Reactivation rate: 0.0027
2025-08-27 22:21:07,541 - INFO - Epoch: [32][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.4445 (0.4325) Acc@1 82.812 (85.063) Acc@5 99.219 (99.452)
2025-08-27 22:21:09,203 - INFO - Pruning info: sparsity=0.649
2025-08-27 22:21:09,203 - INFO -   Reactivation rate: 0.0020
2025-08-27 22:21:09,449 - INFO - Epoch: [32][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.3665 (0.4405) Acc@1 89.844 (84.785) Acc@5 100.000 (99.426)
2025-08-27 22:21:11,220 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.5036 (0.5036) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:21:12,072 - INFO - Epoch 32:
2025-08-27 22:21:12,072 - INFO -   Train: acc1: 84.7340 | acc5: 99.4160 | loss: 0.4433 | sparsity: 0.6492 | reactivation_rate: 0.0025
2025-08-27 22:21:12,072 - INFO -   Val:   acc1: 82.3100 | acc5: 98.9600 | loss: 0.5407
2025-08-27 22:21:12,072 - INFO -   LR: 0.100000
2025-08-27 22:21:12,120 - INFO - Checkpoint saved: epoch=32, metric=82.3100
2025-08-27 22:21:12,154 - INFO - 
Epoch: 33, lr = 0.1
2025-08-27 22:21:12,358 - INFO - Epoch: [33][0/391] Time 0.203 (0.203) Data 0.178 (0.178) Loss 0.3580 (0.3580) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:21:13,411 - INFO - Pruning info: sparsity=0.660
2025-08-27 22:21:13,411 - INFO -   Reactivation rate: 0.0036
2025-08-27 22:21:14,207 - INFO - Epoch: [33][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.3955 (0.4529) Acc@1 83.594 (84.267) Acc@5 99.219 (99.273)
2025-08-27 22:21:16,049 - INFO - Epoch: [33][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5611 (0.4380) Acc@1 79.688 (84.799) Acc@5 99.219 (99.335)
2025-08-27 22:21:16,330 - INFO - Pruning info: sparsity=0.660
2025-08-27 22:21:16,330 - INFO -   Reactivation rate: 0.0022
2025-08-27 22:21:17,885 - INFO - Epoch: [33][300/391] Time 0.035 (0.019) Data 0.017 (0.002) Loss 0.4563 (0.4389) Acc@1 84.375 (84.840) Acc@5 99.219 (99.362)
2025-08-27 22:21:19,253 - INFO - Pruning info: sparsity=0.660
2025-08-27 22:21:19,254 - INFO -   Reactivation rate: 0.0015
2025-08-27 22:21:19,668 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6074 (0.6074) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:21:20,525 - INFO - Epoch 33:
2025-08-27 22:21:20,526 - INFO -   Train: acc1: 84.6840 | acc5: 99.3360 | loss: 0.4432 | sparsity: 0.6595 | reactivation_rate: 0.0024
2025-08-27 22:21:20,526 - INFO -   Val:   acc1: 77.2700 | acc5: 98.8000 | loss: 0.7138
2025-08-27 22:21:20,526 - INFO -   LR: 0.100000
2025-08-27 22:21:20,536 - INFO - 
Epoch: 34, lr = 0.1
2025-08-27 22:21:20,725 - INFO - Epoch: [34][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.4848 (0.4848) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:21:22,574 - INFO - Epoch: [34][100/391] Time 0.017 (0.020) Data 0.002 (0.003) Loss 0.4750 (0.4228) Acc@1 84.375 (85.528) Acc@5 99.219 (99.366)
2025-08-27 22:21:23,365 - INFO - Pruning info: sparsity=0.669
2025-08-27 22:21:23,365 - INFO -   Reactivation rate: 0.0024
2025-08-27 22:21:24,352 - INFO - Epoch: [34][200/391] Time 0.022 (0.019) Data 0.010 (0.003) Loss 0.4332 (0.4278) Acc@1 82.031 (85.246) Acc@5 100.000 (99.409)
2025-08-27 22:21:26,191 - INFO - Epoch: [34][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.5346 (0.4339) Acc@1 79.688 (85.060) Acc@5 98.438 (99.424)
2025-08-27 22:21:26,291 - INFO - Pruning info: sparsity=0.669
2025-08-27 22:21:26,299 - INFO -   Reactivation rate: 0.0016
2025-08-27 22:21:27,966 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.6233 (0.6233) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:21:28,813 - INFO - Epoch 34:
2025-08-27 22:21:28,813 - INFO -   Train: acc1: 84.7560 | acc5: 99.4240 | loss: 0.4402 | sparsity: 0.6693 | reactivation_rate: 0.0022
2025-08-27 22:21:28,813 - INFO -   Val:   acc1: 78.3700 | acc5: 98.7500 | loss: 0.6945
2025-08-27 22:21:28,813 - INFO -   LR: 0.100000
2025-08-27 22:21:28,823 - INFO - 
Epoch: 35, lr = 0.1
2025-08-27 22:21:29,021 - INFO - Epoch: [35][0/391] Time 0.197 (0.197) Data 0.174 (0.174) Loss 0.3669 (0.3669) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-27 22:21:30,345 - INFO - Pruning info: sparsity=0.679
2025-08-27 22:21:30,345 - INFO -   Reactivation rate: 0.0030
2025-08-27 22:21:30,818 - INFO - Epoch: [35][100/391] Time 0.022 (0.020) Data 0.008 (0.004) Loss 0.6225 (0.4340) Acc@1 81.250 (84.916) Acc@5 97.656 (99.343)
2025-08-27 22:21:32,609 - INFO - Epoch: [35][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3670 (0.4287) Acc@1 87.500 (85.110) Acc@5 100.000 (99.401)
2025-08-27 22:21:33,261 - INFO - Pruning info: sparsity=0.679
2025-08-27 22:21:33,261 - INFO -   Reactivation rate: 0.0019
2025-08-27 22:21:34,455 - INFO - Epoch: [35][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4146 (0.4359) Acc@1 85.938 (84.907) Acc@5 99.219 (99.356)
2025-08-27 22:21:36,244 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.6316 (0.6316) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:21:37,079 - INFO - Epoch 35:
2025-08-27 22:21:37,079 - INFO -   Train: acc1: 84.8620 | acc5: 99.3460 | loss: 0.4357 | sparsity: 0.6786 | reactivation_rate: 0.0022
2025-08-27 22:21:37,079 - INFO -   Val:   acc1: 78.7200 | acc5: 98.6100 | loss: 0.6556
2025-08-27 22:21:37,079 - INFO -   LR: 0.100000
2025-08-27 22:21:37,090 - INFO - 
Epoch: 36, lr = 0.1
2025-08-27 22:21:37,269 - INFO - Epoch: [36][0/391] Time 0.178 (0.178) Data 0.138 (0.138) Loss 0.4943 (0.4943) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:21:37,342 - INFO - Pruning info: sparsity=0.688
2025-08-27 22:21:37,342 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:21:39,118 - INFO - Epoch: [36][100/391] Time 0.029 (0.020) Data 0.000 (0.004) Loss 0.3573 (0.4337) Acc@1 84.375 (85.032) Acc@5 100.000 (99.397)
2025-08-27 22:21:40,261 - INFO - Pruning info: sparsity=0.688
2025-08-27 22:21:40,266 - INFO -   Reactivation rate: 0.0022
2025-08-27 22:21:40,906 - INFO - Epoch: [36][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.3321 (0.4362) Acc@1 89.844 (85.110) Acc@5 99.219 (99.363)
2025-08-27 22:21:42,788 - INFO - Epoch: [36][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.5327 (0.4402) Acc@1 78.906 (84.801) Acc@5 99.219 (99.354)
2025-08-27 22:21:43,247 - INFO - Pruning info: sparsity=0.688
2025-08-27 22:21:43,247 - INFO -   Reactivation rate: 0.0015
2025-08-27 22:21:44,571 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.7588 (0.7588) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 22:21:45,433 - INFO - Epoch 36:
2025-08-27 22:21:45,433 - INFO -   Train: acc1: 84.9040 | acc5: 99.3580 | loss: 0.4393 | sparsity: 0.6875 | reactivation_rate: 0.0021
2025-08-27 22:21:45,433 - INFO -   Val:   acc1: 74.9100 | acc5: 97.7600 | loss: 0.8046
2025-08-27 22:21:45,433 - INFO -   LR: 0.100000
2025-08-27 22:21:45,442 - INFO - 
Epoch: 37, lr = 0.1
2025-08-27 22:21:45,606 - INFO - Epoch: [37][0/391] Time 0.163 (0.163) Data 0.143 (0.143) Loss 0.3200 (0.3200) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:21:47,292 - INFO - Pruning info: sparsity=0.696
2025-08-27 22:21:47,301 - INFO -   Reactivation rate: 0.0026
2025-08-27 22:21:47,429 - INFO - Epoch: [37][100/391] Time 0.023 (0.020) Data 0.000 (0.005) Loss 0.4163 (0.4256) Acc@1 85.156 (85.234) Acc@5 100.000 (99.420)
2025-08-27 22:21:49,278 - INFO - Epoch: [37][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3963 (0.4436) Acc@1 88.281 (84.721) Acc@5 100.000 (99.405)
2025-08-27 22:21:50,193 - INFO - Pruning info: sparsity=0.696
2025-08-27 22:21:50,197 - INFO -   Reactivation rate: 0.0017
2025-08-27 22:21:51,141 - INFO - Epoch: [37][300/391] Time 0.032 (0.019) Data 0.009 (0.003) Loss 0.5901 (0.4411) Acc@1 78.906 (84.824) Acc@5 100.000 (99.413)
2025-08-27 22:21:52,871 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7273 (0.7273) Acc@1 75.781 (75.781) Acc@5 96.094 (96.094)
2025-08-27 22:21:53,722 - INFO - Epoch 37:
2025-08-27 22:21:53,722 - INFO -   Train: acc1: 84.8760 | acc5: 99.3940 | loss: 0.4394 | sparsity: 0.6959 | reactivation_rate: 0.0020
2025-08-27 22:21:53,722 - INFO -   Val:   acc1: 73.2400 | acc5: 97.3000 | loss: 0.8255
2025-08-27 22:21:53,722 - INFO -   LR: 0.100000
2025-08-27 22:21:53,732 - INFO - 
Epoch: 38, lr = 0.1
2025-08-27 22:21:53,901 - INFO - Epoch: [38][0/391] Time 0.167 (0.167) Data 0.146 (0.146) Loss 0.3616 (0.3616) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:21:54,307 - INFO - Pruning info: sparsity=0.704
2025-08-27 22:21:54,308 - INFO -   Reactivation rate: 0.0036
2025-08-27 22:21:55,711 - INFO - Epoch: [38][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4902 (0.4323) Acc@1 84.375 (85.002) Acc@5 98.438 (99.428)
2025-08-27 22:21:57,202 - INFO - Pruning info: sparsity=0.704
2025-08-27 22:21:57,203 - INFO -   Reactivation rate: 0.0019
2025-08-27 22:21:57,506 - INFO - Epoch: [38][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.3817 (0.4281) Acc@1 85.938 (85.269) Acc@5 100.000 (99.394)
2025-08-27 22:21:59,346 - INFO - Epoch: [38][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4617 (0.4348) Acc@1 87.500 (84.998) Acc@5 98.438 (99.382)
2025-08-27 22:22:00,079 - INFO - Pruning info: sparsity=0.704
2025-08-27 22:22:00,079 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:22:01,035 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5980 (0.5980) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 22:22:01,858 - INFO - Epoch 38:
2025-08-27 22:22:01,858 - INFO -   Train: acc1: 85.0460 | acc5: 99.3540 | loss: 0.4348 | sparsity: 0.7039 | reactivation_rate: 0.0019
2025-08-27 22:22:01,858 - INFO -   Val:   acc1: 80.4800 | acc5: 99.2000 | loss: 0.5929
2025-08-27 22:22:01,858 - INFO -   LR: 0.100000
2025-08-27 22:22:01,867 - INFO - 
Epoch: 39, lr = 0.1
2025-08-27 22:22:02,051 - INFO - Epoch: [39][0/391] Time 0.183 (0.183) Data 0.163 (0.163) Loss 0.3837 (0.3837) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:22:03,763 - INFO - Epoch: [39][100/391] Time 0.023 (0.019) Data 0.013 (0.004) Loss 0.4285 (0.4246) Acc@1 86.719 (85.388) Acc@5 99.219 (99.350)
2025-08-27 22:22:03,959 - INFO - Pruning info: sparsity=0.712
2025-08-27 22:22:03,971 - INFO -   Reactivation rate: 0.0022
2025-08-27 22:22:05,604 - INFO - Epoch: [39][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.5041 (0.4286) Acc@1 81.250 (85.242) Acc@5 98.438 (99.324)
2025-08-27 22:22:06,856 - INFO - Pruning info: sparsity=0.712
2025-08-27 22:22:06,857 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:22:07,377 - INFO - Epoch: [39][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.4285 (0.4282) Acc@1 82.031 (85.247) Acc@5 99.219 (99.302)
2025-08-27 22:22:09,111 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.5498 (0.5498) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:22:09,923 - INFO - Epoch 39:
2025-08-27 22:22:09,924 - INFO -   Train: acc1: 85.2900 | acc5: 99.3100 | loss: 0.4302 | sparsity: 0.7115 | reactivation_rate: 0.0018
2025-08-27 22:22:09,924 - INFO -   Val:   acc1: 82.8400 | acc5: 99.2600 | loss: 0.5183
2025-08-27 22:22:09,924 - INFO -   LR: 0.100000
2025-08-27 22:22:09,970 - INFO - Checkpoint saved: epoch=39, metric=82.8400
2025-08-27 22:22:10,001 - INFO - 
Epoch: 40, lr = 0.1
2025-08-27 22:22:10,174 - INFO - Epoch: [40][0/391] Time 0.171 (0.171) Data 0.150 (0.150) Loss 0.4160 (0.4160) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:22:10,879 - INFO - Pruning info: sparsity=0.719
2025-08-27 22:22:10,879 - INFO -   Reactivation rate: 0.0029
2025-08-27 22:22:11,918 - INFO - Epoch: [40][100/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3608 (0.4163) Acc@1 84.375 (85.334) Acc@5 100.000 (99.489)
2025-08-27 22:22:13,705 - INFO - Pruning info: sparsity=0.719
2025-08-27 22:22:13,705 - INFO -   Reactivation rate: 0.0016
2025-08-27 22:22:13,717 - INFO - Epoch: [40][200/391] Time 0.018 (0.018) Data 0.000 (0.002) Loss 0.3950 (0.4161) Acc@1 89.062 (85.459) Acc@5 99.219 (99.440)
2025-08-27 22:22:15,455 - INFO - Epoch: [40][300/391] Time 0.026 (0.018) Data 0.000 (0.003) Loss 0.5382 (0.4251) Acc@1 82.031 (85.244) Acc@5 100.000 (99.400)
2025-08-27 22:22:16,487 - INFO - Pruning info: sparsity=0.719
2025-08-27 22:22:16,494 - INFO -   Reactivation rate: 0.0013
2025-08-27 22:22:17,150 - INFO - Test: [0/79] Time 0.110 (0.110) Loss 0.5451 (0.5451) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 22:22:18,001 - INFO - Epoch 40:
2025-08-27 22:22:18,001 - INFO -   Train: acc1: 85.1780 | acc5: 99.3920 | loss: 0.4280 | sparsity: 0.7187 | reactivation_rate: 0.0018
2025-08-27 22:22:18,001 - INFO -   Val:   acc1: 81.0200 | acc5: 99.1300 | loss: 0.5728
2025-08-27 22:22:18,001 - INFO -   LR: 0.100000
2025-08-27 22:22:18,046 - INFO - 
Epoch: 41, lr = 0.1
2025-08-27 22:22:18,217 - INFO - Epoch: [41][0/391] Time 0.170 (0.170) Data 0.154 (0.154) Loss 0.4389 (0.4389) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:22:19,980 - INFO - Epoch: [41][100/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.5378 (0.4228) Acc@1 80.469 (85.303) Acc@5 98.438 (99.335)
2025-08-27 22:22:20,507 - INFO - Pruning info: sparsity=0.725
2025-08-27 22:22:20,507 - INFO -   Reactivation rate: 0.0018
2025-08-27 22:22:21,731 - INFO - Epoch: [41][200/391] Time 0.012 (0.018) Data 0.001 (0.003) Loss 0.4050 (0.4233) Acc@1 83.594 (85.343) Acc@5 100.000 (99.359)
2025-08-27 22:22:23,296 - INFO - Pruning info: sparsity=0.725
2025-08-27 22:22:23,296 - INFO -   Reactivation rate: 0.0013
2025-08-27 22:22:23,533 - INFO - Epoch: [41][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.4398 (0.4270) Acc@1 82.812 (85.346) Acc@5 100.000 (99.377)
2025-08-27 22:22:25,222 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.4730 (0.4730) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:22:26,027 - INFO - Epoch 41:
2025-08-27 22:22:26,027 - INFO -   Train: acc1: 85.0940 | acc5: 99.3940 | loss: 0.4312 | sparsity: 0.7255 | reactivation_rate: 0.0016
2025-08-27 22:22:26,027 - INFO -   Val:   acc1: 81.6900 | acc5: 99.1700 | loss: 0.5452
2025-08-27 22:22:26,027 - INFO -   LR: 0.100000
2025-08-27 22:22:26,037 - INFO - 
Epoch: 42, lr = 0.1
2025-08-27 22:22:26,214 - INFO - Epoch: [42][0/391] Time 0.176 (0.176) Data 0.151 (0.151) Loss 0.4526 (0.4526) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:22:27,202 - INFO - Pruning info: sparsity=0.732
2025-08-27 22:22:27,202 - INFO -   Reactivation rate: 0.0022
2025-08-27 22:22:27,942 - INFO - Epoch: [42][100/391] Time 0.021 (0.019) Data 0.009 (0.004) Loss 0.6366 (0.4081) Acc@1 82.031 (86.069) Acc@5 99.219 (99.373)
2025-08-27 22:22:29,746 - INFO - Epoch: [42][200/391] Time 0.016 (0.018) Data 0.000 (0.003) Loss 0.5715 (0.4149) Acc@1 82.812 (85.743) Acc@5 99.219 (99.468)
2025-08-27 22:22:30,064 - INFO - Pruning info: sparsity=0.732
2025-08-27 22:22:30,064 - INFO -   Reactivation rate: 0.0016
2025-08-27 22:22:31,512 - INFO - Epoch: [42][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.2776 (0.4243) Acc@1 89.844 (85.439) Acc@5 100.000 (99.437)
2025-08-27 22:22:32,887 - INFO - Pruning info: sparsity=0.732
2025-08-27 22:22:32,887 - INFO -   Reactivation rate: 0.0011
2025-08-27 22:22:33,234 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.6501 (0.6501) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 22:22:34,060 - INFO - Epoch 42:
2025-08-27 22:22:34,060 - INFO -   Train: acc1: 85.4800 | acc5: 99.4380 | loss: 0.4237 | sparsity: 0.7319 | reactivation_rate: 0.0016
2025-08-27 22:22:34,060 - INFO -   Val:   acc1: 80.8800 | acc5: 99.1500 | loss: 0.5763
2025-08-27 22:22:34,060 - INFO -   LR: 0.100000
2025-08-27 22:22:34,069 - INFO - 
Epoch: 43, lr = 0.1
2025-08-27 22:22:34,262 - INFO - Epoch: [43][0/391] Time 0.192 (0.192) Data 0.175 (0.175) Loss 0.2669 (0.2669) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:22:35,997 - INFO - Epoch: [43][100/391] Time 0.023 (0.019) Data 0.000 (0.005) Loss 0.4089 (0.4273) Acc@1 85.938 (85.365) Acc@5 100.000 (99.544)
2025-08-27 22:22:36,795 - INFO - Pruning info: sparsity=0.738
2025-08-27 22:22:36,795 - INFO -   Reactivation rate: 0.0015
2025-08-27 22:22:37,711 - INFO - Epoch: [43][200/391] Time 0.016 (0.018) Data 0.005 (0.003) Loss 0.3154 (0.4234) Acc@1 86.719 (85.448) Acc@5 100.000 (99.468)
2025-08-27 22:22:39,557 - INFO - Epoch: [43][300/391] Time 0.016 (0.018) Data 0.000 (0.003) Loss 0.3074 (0.4251) Acc@1 90.625 (85.418) Acc@5 100.000 (99.465)
2025-08-27 22:22:39,675 - INFO - Pruning info: sparsity=0.738
2025-08-27 22:22:39,688 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:22:41,263 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6380 (0.6380) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:22:42,094 - INFO - Epoch 43:
2025-08-27 22:22:42,094 - INFO -   Train: acc1: 85.2560 | acc5: 99.4500 | loss: 0.4286 | sparsity: 0.7379 | reactivation_rate: 0.0015
2025-08-27 22:22:42,094 - INFO -   Val:   acc1: 81.2700 | acc5: 99.2600 | loss: 0.5599
2025-08-27 22:22:42,094 - INFO -   LR: 0.100000
2025-08-27 22:22:42,104 - INFO - 
Epoch: 44, lr = 0.1
2025-08-27 22:22:42,282 - INFO - Epoch: [44][0/391] Time 0.177 (0.177) Data 0.156 (0.156) Loss 0.3215 (0.3215) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:22:43,640 - INFO - Pruning info: sparsity=0.744
2025-08-27 22:22:43,640 - INFO -   Reactivation rate: 0.0021
2025-08-27 22:22:44,083 - INFO - Epoch: [44][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3974 (0.4163) Acc@1 87.500 (85.690) Acc@5 100.000 (99.312)
2025-08-27 22:22:45,835 - INFO - Epoch: [44][200/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.3994 (0.4209) Acc@1 86.719 (85.580) Acc@5 99.219 (99.339)
2025-08-27 22:22:46,540 - INFO - Pruning info: sparsity=0.744
2025-08-27 22:22:46,541 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:22:47,655 - INFO - Epoch: [44][300/391] Time 0.019 (0.018) Data 0.000 (0.003) Loss 0.3251 (0.4200) Acc@1 88.281 (85.496) Acc@5 100.000 (99.380)
2025-08-27 22:22:49,384 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.5833 (0.5833) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:22:50,197 - INFO - Epoch 44:
2025-08-27 22:22:50,197 - INFO -   Train: acc1: 85.4940 | acc5: 99.4020 | loss: 0.4204 | sparsity: 0.7435 | reactivation_rate: 0.0014
2025-08-27 22:22:50,197 - INFO -   Val:   acc1: 80.7000 | acc5: 99.1300 | loss: 0.5766
2025-08-27 22:22:50,197 - INFO -   LR: 0.100000
2025-08-27 22:22:50,206 - INFO - 
Epoch: 45, lr = 0.1
2025-08-27 22:22:50,393 - INFO - Epoch: [45][0/391] Time 0.187 (0.187) Data 0.166 (0.166) Loss 0.3390 (0.3390) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:22:50,495 - INFO - Pruning info: sparsity=0.749
2025-08-27 22:22:50,496 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:22:52,155 - INFO - Epoch: [45][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.6190 (0.4203) Acc@1 82.031 (85.968) Acc@5 99.219 (99.288)
2025-08-27 22:22:53,318 - INFO - Pruning info: sparsity=0.749
2025-08-27 22:22:53,318 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:22:54,002 - INFO - Epoch: [45][200/391] Time 0.021 (0.019) Data 0.009 (0.003) Loss 0.3731 (0.4296) Acc@1 85.938 (85.498) Acc@5 100.000 (99.289)
2025-08-27 22:22:55,895 - INFO - Epoch: [45][300/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.4057 (0.4276) Acc@1 88.281 (85.551) Acc@5 99.219 (99.315)
2025-08-27 22:22:56,300 - INFO - Pruning info: sparsity=0.749
2025-08-27 22:22:56,300 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:22:57,638 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.4993 (0.4993) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 22:22:58,501 - INFO - Epoch 45:
2025-08-27 22:22:58,502 - INFO -   Train: acc1: 85.4720 | acc5: 99.3380 | loss: 0.4281 | sparsity: 0.7488 | reactivation_rate: 0.0014
2025-08-27 22:22:58,502 - INFO -   Val:   acc1: 81.2100 | acc5: 99.1800 | loss: 0.5806
2025-08-27 22:22:58,502 - INFO -   LR: 0.100000
2025-08-27 22:22:58,513 - INFO - 
Epoch: 46, lr = 0.1
2025-08-27 22:22:58,713 - INFO - Epoch: [46][0/391] Time 0.200 (0.200) Data 0.179 (0.179) Loss 0.3912 (0.3912) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-27 22:23:00,336 - INFO - Pruning info: sparsity=0.754
2025-08-27 22:23:00,336 - INFO -   Reactivation rate: 0.0018
2025-08-27 22:23:00,495 - INFO - Epoch: [46][100/391] Time 0.022 (0.020) Data 0.000 (0.005) Loss 0.4363 (0.4045) Acc@1 85.156 (86.332) Acc@5 100.000 (99.404)
2025-08-27 22:23:02,299 - INFO - Epoch: [46][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4320 (0.4136) Acc@1 86.719 (85.868) Acc@5 99.219 (99.378)
2025-08-27 22:23:03,230 - INFO - Pruning info: sparsity=0.754
2025-08-27 22:23:03,231 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:23:04,136 - INFO - Epoch: [46][300/391] Time 0.024 (0.019) Data 0.011 (0.003) Loss 0.3517 (0.4151) Acc@1 85.938 (85.751) Acc@5 100.000 (99.374)
2025-08-27 22:23:05,956 - INFO - Test: [0/79] Time 0.165 (0.165) Loss 0.5528 (0.5528) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:23:06,817 - INFO - Epoch 46:
2025-08-27 22:23:06,817 - INFO -   Train: acc1: 85.4280 | acc5: 99.3780 | loss: 0.4218 | sparsity: 0.7538 | reactivation_rate: 0.0013
2025-08-27 22:23:06,817 - INFO -   Val:   acc1: 79.4800 | acc5: 98.6000 | loss: 0.6392
2025-08-27 22:23:06,817 - INFO -   LR: 0.100000
2025-08-27 22:23:06,828 - INFO - 
Epoch: 47, lr = 0.1
2025-08-27 22:23:07,007 - INFO - Epoch: [47][0/391] Time 0.178 (0.178) Data 0.160 (0.160) Loss 0.4620 (0.4620) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:23:07,403 - INFO - Pruning info: sparsity=0.758
2025-08-27 22:23:07,404 - INFO -   Reactivation rate: 0.0024
2025-08-27 22:23:08,828 - INFO - Epoch: [47][100/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.3652 (0.4129) Acc@1 86.719 (85.675) Acc@5 100.000 (99.528)
2025-08-27 22:23:10,313 - INFO - Pruning info: sparsity=0.758
2025-08-27 22:23:10,313 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:23:10,653 - INFO - Epoch: [47][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4966 (0.4173) Acc@1 85.156 (85.502) Acc@5 99.219 (99.468)
2025-08-27 22:23:12,496 - INFO - Epoch: [47][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4203 (0.4220) Acc@1 84.375 (85.296) Acc@5 99.219 (99.416)
2025-08-27 22:23:13,309 - INFO - Pruning info: sparsity=0.758
2025-08-27 22:23:13,309 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:23:14,286 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.5422 (0.5422) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 22:23:15,134 - INFO - Epoch 47:
2025-08-27 22:23:15,134 - INFO -   Train: acc1: 85.1320 | acc5: 99.3800 | loss: 0.4272 | sparsity: 0.7584 | reactivation_rate: 0.0013
2025-08-27 22:23:15,134 - INFO -   Val:   acc1: 81.3800 | acc5: 99.2200 | loss: 0.5465
2025-08-27 22:23:15,134 - INFO -   LR: 0.100000
2025-08-27 22:23:15,146 - INFO - 
Epoch: 48, lr = 0.1
2025-08-27 22:23:15,332 - INFO - Epoch: [48][0/391] Time 0.185 (0.185) Data 0.147 (0.147) Loss 0.4538 (0.4538) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:23:17,165 - INFO - Epoch: [48][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4172 (0.4127) Acc@1 86.719 (85.775) Acc@5 99.219 (99.536)
2025-08-27 22:23:17,347 - INFO - Pruning info: sparsity=0.763
2025-08-27 22:23:17,347 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:23:18,951 - INFO - Epoch: [48][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4597 (0.4115) Acc@1 84.375 (85.731) Acc@5 99.219 (99.444)
2025-08-27 22:23:20,307 - INFO - Pruning info: sparsity=0.763
2025-08-27 22:23:20,307 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:23:20,882 - INFO - Epoch: [48][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.4027 (0.4167) Acc@1 89.062 (85.665) Acc@5 100.000 (99.447)
2025-08-27 22:23:22,693 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6858 (0.6858) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 22:23:23,551 - INFO - Epoch 48:
2025-08-27 22:23:23,551 - INFO -   Train: acc1: 85.6040 | acc5: 99.4260 | loss: 0.4191 | sparsity: 0.7627 | reactivation_rate: 0.0012
2025-08-27 22:23:23,551 - INFO -   Val:   acc1: 78.7100 | acc5: 98.8000 | loss: 0.6529
2025-08-27 22:23:23,551 - INFO -   LR: 0.100000
2025-08-27 22:23:23,561 - INFO - 
Epoch: 49, lr = 0.1
2025-08-27 22:23:23,755 - INFO - Epoch: [49][0/391] Time 0.194 (0.194) Data 0.160 (0.160) Loss 0.4665 (0.4665) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:23:24,452 - INFO - Pruning info: sparsity=0.767
2025-08-27 22:23:24,453 - INFO -   Reactivation rate: 0.0020
2025-08-27 22:23:25,567 - INFO - Epoch: [49][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4444 (0.4197) Acc@1 87.500 (85.357) Acc@5 98.438 (99.373)
2025-08-27 22:23:27,373 - INFO - Epoch: [49][200/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.3257 (0.4175) Acc@1 90.625 (85.592) Acc@5 100.000 (99.413)
2025-08-27 22:23:27,380 - INFO - Pruning info: sparsity=0.767
2025-08-27 22:23:27,380 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:23:29,217 - INFO - Epoch: [49][300/391] Time 0.023 (0.019) Data 0.009 (0.003) Loss 0.4568 (0.4254) Acc@1 83.594 (85.250) Acc@5 100.000 (99.395)
2025-08-27 22:23:30,344 - INFO - Pruning info: sparsity=0.767
2025-08-27 22:23:30,344 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:23:31,064 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5170 (0.5170) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:23:31,900 - INFO - Epoch 49:
2025-08-27 22:23:31,900 - INFO -   Train: acc1: 85.3740 | acc5: 99.4120 | loss: 0.4219 | sparsity: 0.7667 | reactivation_rate: 0.0012
2025-08-27 22:23:31,900 - INFO -   Val:   acc1: 81.2900 | acc5: 99.2000 | loss: 0.5504
2025-08-27 22:23:31,900 - INFO -   LR: 0.100000
2025-08-27 22:23:31,912 - INFO - 
Epoch: 50, lr = 0.1
2025-08-27 22:23:32,085 - INFO - Epoch: [50][0/391] Time 0.172 (0.172) Data 0.151 (0.151) Loss 0.3078 (0.3078) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:23:33,877 - INFO - Epoch: [50][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5244 (0.4144) Acc@1 80.469 (85.806) Acc@5 100.000 (99.389)
2025-08-27 22:23:34,408 - INFO - Pruning info: sparsity=0.770
2025-08-27 22:23:34,408 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:23:35,655 - INFO - Epoch: [50][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.3380 (0.4207) Acc@1 89.844 (85.502) Acc@5 100.000 (99.417)
2025-08-27 22:23:37,350 - INFO - Pruning info: sparsity=0.770
2025-08-27 22:23:37,350 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:23:37,485 - INFO - Epoch: [50][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.2508 (0.4196) Acc@1 91.406 (85.605) Acc@5 100.000 (99.419)
2025-08-27 22:23:39,281 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5842 (0.5842) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-27 22:23:40,133 - INFO - Epoch 50:
2025-08-27 22:23:40,133 - INFO -   Train: acc1: 85.6480 | acc5: 99.3980 | loss: 0.4201 | sparsity: 0.7704 | reactivation_rate: 0.0011
2025-08-27 22:23:40,133 - INFO -   Val:   acc1: 77.7600 | acc5: 99.0400 | loss: 0.6577
2025-08-27 22:23:40,133 - INFO -   LR: 0.100000
2025-08-27 22:23:40,178 - INFO - 
Epoch: 51, lr = 0.1
2025-08-27 22:23:40,340 - INFO - Epoch: [51][0/391] Time 0.161 (0.161) Data 0.145 (0.145) Loss 0.4743 (0.4743) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:23:41,378 - INFO - Pruning info: sparsity=0.774
2025-08-27 22:23:41,378 - INFO -   Reactivation rate: 0.0017
2025-08-27 22:23:42,153 - INFO - Epoch: [51][100/391] Time 0.026 (0.020) Data 0.006 (0.004) Loss 0.3959 (0.4079) Acc@1 85.938 (85.999) Acc@5 99.219 (99.420)
2025-08-27 22:23:44,099 - INFO - Epoch: [51][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5078 (0.4136) Acc@1 81.250 (85.751) Acc@5 99.219 (99.452)
2025-08-27 22:23:44,430 - INFO - Pruning info: sparsity=0.774
2025-08-27 22:23:44,431 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:23:45,923 - INFO - Epoch: [51][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3218 (0.4149) Acc@1 90.625 (85.761) Acc@5 100.000 (99.450)
2025-08-27 22:23:47,296 - INFO - Pruning info: sparsity=0.774
2025-08-27 22:23:47,296 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:23:47,658 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.8527 (0.8527) Acc@1 73.438 (73.438) Acc@5 96.875 (96.875)
2025-08-27 22:23:48,510 - INFO - Epoch 51:
2025-08-27 22:23:48,510 - INFO -   Train: acc1: 85.6240 | acc5: 99.4180 | loss: 0.4202 | sparsity: 0.7738 | reactivation_rate: 0.0011
2025-08-27 22:23:48,510 - INFO -   Val:   acc1: 75.3400 | acc5: 97.4100 | loss: 0.8014
2025-08-27 22:23:48,510 - INFO -   LR: 0.100000
2025-08-27 22:23:48,522 - INFO - 
Epoch: 52, lr = 0.1
2025-08-27 22:23:48,706 - INFO - Epoch: [52][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.4371 (0.4371) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 22:23:50,498 - INFO - Epoch: [52][100/391] Time 0.029 (0.020) Data 0.000 (0.005) Loss 0.4378 (0.4075) Acc@1 85.156 (86.007) Acc@5 100.000 (99.420)
2025-08-27 22:23:51,326 - INFO - Pruning info: sparsity=0.777
2025-08-27 22:23:51,326 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:23:52,324 - INFO - Epoch: [52][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4051 (0.4251) Acc@1 83.594 (85.374) Acc@5 100.000 (99.409)
2025-08-27 22:23:54,105 - INFO - Epoch: [52][300/391] Time 0.020 (0.019) Data 0.008 (0.003) Loss 0.3934 (0.4252) Acc@1 85.938 (85.444) Acc@5 99.219 (99.442)
2025-08-27 22:23:54,262 - INFO - Pruning info: sparsity=0.777
2025-08-27 22:23:54,262 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:23:55,879 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.4939 (0.4939) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 22:23:56,729 - INFO - Epoch 52:
2025-08-27 22:23:56,730 - INFO -   Train: acc1: 85.3540 | acc5: 99.4340 | loss: 0.4264 | sparsity: 0.7769 | reactivation_rate: 0.0010
2025-08-27 22:23:56,730 - INFO -   Val:   acc1: 82.6700 | acc5: 99.2100 | loss: 0.5139
2025-08-27 22:23:56,730 - INFO -   LR: 0.100000
2025-08-27 22:23:56,740 - INFO - 
Epoch: 53, lr = 0.1
2025-08-27 22:23:56,920 - INFO - Epoch: [53][0/391] Time 0.180 (0.180) Data 0.148 (0.148) Loss 0.4890 (0.4890) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 22:23:58,264 - INFO - Pruning info: sparsity=0.780
2025-08-27 22:23:58,264 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:23:58,700 - INFO - Epoch: [53][100/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4357 (0.4198) Acc@1 85.156 (85.558) Acc@5 100.000 (99.428)
2025-08-27 22:24:00,545 - INFO - Epoch: [53][200/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.4082 (0.4251) Acc@1 86.719 (85.288) Acc@5 99.219 (99.475)
2025-08-27 22:24:01,195 - INFO - Pruning info: sparsity=0.780
2025-08-27 22:24:01,195 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:24:02,347 - INFO - Epoch: [53][300/391] Time 0.032 (0.019) Data 0.000 (0.003) Loss 0.3975 (0.4278) Acc@1 85.156 (85.159) Acc@5 100.000 (99.413)
2025-08-27 22:24:04,094 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5747 (0.5747) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 22:24:04,937 - INFO - Epoch 53:
2025-08-27 22:24:04,937 - INFO -   Train: acc1: 85.2200 | acc5: 99.4260 | loss: 0.4263 | sparsity: 0.7798 | reactivation_rate: 0.0010
2025-08-27 22:24:04,937 - INFO -   Val:   acc1: 79.3100 | acc5: 99.1100 | loss: 0.6168
2025-08-27 22:24:04,938 - INFO -   LR: 0.100000
2025-08-27 22:24:04,948 - INFO - 
Epoch: 54, lr = 0.1
2025-08-27 22:24:05,138 - INFO - Epoch: [54][0/391] Time 0.190 (0.190) Data 0.161 (0.161) Loss 0.4142 (0.4142) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:24:05,204 - INFO - Pruning info: sparsity=0.782
2025-08-27 22:24:05,205 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:24:06,881 - INFO - Epoch: [54][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3447 (0.4127) Acc@1 91.406 (85.860) Acc@5 99.219 (99.459)
2025-08-27 22:24:08,038 - INFO - Pruning info: sparsity=0.782
2025-08-27 22:24:08,047 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:24:08,683 - INFO - Epoch: [54][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.6056 (0.4204) Acc@1 77.344 (85.448) Acc@5 100.000 (99.468)
2025-08-27 22:24:10,485 - INFO - Epoch: [54][300/391] Time 0.024 (0.018) Data 0.012 (0.003) Loss 0.3720 (0.4131) Acc@1 85.938 (85.691) Acc@5 100.000 (99.481)
2025-08-27 22:24:10,904 - INFO - Pruning info: sparsity=0.782
2025-08-27 22:24:10,910 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:24:12,237 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5172 (0.5172) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 22:24:13,055 - INFO - Epoch 54:
2025-08-27 22:24:13,055 - INFO -   Train: acc1: 85.5320 | acc5: 99.4780 | loss: 0.4167 | sparsity: 0.7824 | reactivation_rate: 0.0009
2025-08-27 22:24:13,055 - INFO -   Val:   acc1: 79.2500 | acc5: 98.9400 | loss: 0.6389
2025-08-27 22:24:13,055 - INFO -   LR: 0.100000
2025-08-27 22:24:13,068 - INFO - 
Epoch: 55, lr = 0.1
2025-08-27 22:24:13,261 - INFO - Epoch: [55][0/391] Time 0.193 (0.193) Data 0.170 (0.170) Loss 0.2702 (0.2702) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:24:14,992 - INFO - Pruning info: sparsity=0.785
2025-08-27 22:24:14,992 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:24:15,082 - INFO - Epoch: [55][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.5679 (0.4159) Acc@1 80.469 (85.930) Acc@5 100.000 (99.404)
2025-08-27 22:24:16,918 - INFO - Epoch: [55][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4373 (0.4176) Acc@1 86.719 (85.778) Acc@5 100.000 (99.464)
2025-08-27 22:24:17,915 - INFO - Pruning info: sparsity=0.785
2025-08-27 22:24:17,915 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:24:18,758 - INFO - Epoch: [55][300/391] Time 0.037 (0.019) Data 0.024 (0.003) Loss 0.4378 (0.4188) Acc@1 85.156 (85.649) Acc@5 99.219 (99.437)
2025-08-27 22:24:20,527 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.7038 (0.7038) Acc@1 76.562 (76.562) Acc@5 97.656 (97.656)
2025-08-27 22:24:21,353 - INFO - Epoch 55:
2025-08-27 22:24:21,353 - INFO -   Train: acc1: 85.5840 | acc5: 99.4060 | loss: 0.4214 | sparsity: 0.7848 | reactivation_rate: 0.0009
2025-08-27 22:24:21,354 - INFO -   Val:   acc1: 75.8600 | acc5: 98.8500 | loss: 0.7523
2025-08-27 22:24:21,354 - INFO -   LR: 0.100000
2025-08-27 22:24:21,365 - INFO - 
Epoch: 56, lr = 0.1
2025-08-27 22:24:21,534 - INFO - Epoch: [56][0/391] Time 0.168 (0.168) Data 0.140 (0.140) Loss 0.4185 (0.4185) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 22:24:21,960 - INFO - Pruning info: sparsity=0.787
2025-08-27 22:24:21,961 - INFO -   Reactivation rate: 0.0015
2025-08-27 22:24:23,379 - INFO - Epoch: [56][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.4487 (0.4023) Acc@1 89.062 (86.046) Acc@5 99.219 (99.497)
2025-08-27 22:24:24,973 - INFO - Pruning info: sparsity=0.787
2025-08-27 22:24:24,975 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:24:25,285 - INFO - Epoch: [56][200/391] Time 0.042 (0.019) Data 0.007 (0.002) Loss 0.4102 (0.4206) Acc@1 89.062 (85.545) Acc@5 100.000 (99.468)
2025-08-27 22:24:27,110 - INFO - Epoch: [56][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.4145 (0.4204) Acc@1 84.375 (85.546) Acc@5 100.000 (99.468)
2025-08-27 22:24:27,847 - INFO - Pruning info: sparsity=0.787
2025-08-27 22:24:27,847 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:24:28,848 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.4401 (0.4401) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:24:29,665 - INFO - Epoch 56:
2025-08-27 22:24:29,665 - INFO -   Train: acc1: 85.4180 | acc5: 99.4600 | loss: 0.4222 | sparsity: 0.7870 | reactivation_rate: 0.0008
2025-08-27 22:24:29,665 - INFO -   Val:   acc1: 80.8800 | acc5: 99.1500 | loss: 0.5793
2025-08-27 22:24:29,665 - INFO -   LR: 0.100000
2025-08-27 22:24:29,697 - INFO - 
Epoch: 57, lr = 0.1
2025-08-27 22:24:29,875 - INFO - Epoch: [57][0/391] Time 0.177 (0.177) Data 0.156 (0.156) Loss 0.2678 (0.2678) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:24:31,618 - INFO - Epoch: [57][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4454 (0.4288) Acc@1 85.156 (85.149) Acc@5 100.000 (99.343)
2025-08-27 22:24:31,856 - INFO - Pruning info: sparsity=0.789
2025-08-27 22:24:31,856 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:24:33,399 - INFO - Epoch: [57][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3821 (0.4298) Acc@1 83.594 (85.024) Acc@5 99.219 (99.394)
2025-08-27 22:24:34,761 - INFO - Pruning info: sparsity=0.789
2025-08-27 22:24:34,762 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:24:35,268 - INFO - Epoch: [57][300/391] Time 0.019 (0.018) Data 0.008 (0.003) Loss 0.3582 (0.4220) Acc@1 85.938 (85.263) Acc@5 100.000 (99.437)
2025-08-27 22:24:37,123 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.4473 (0.4473) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:24:37,981 - INFO - Epoch 57:
2025-08-27 22:24:37,982 - INFO -   Train: acc1: 85.2880 | acc5: 99.4280 | loss: 0.4242 | sparsity: 0.7889 | reactivation_rate: 0.0008
2025-08-27 22:24:37,982 - INFO -   Val:   acc1: 81.7900 | acc5: 98.9300 | loss: 0.5481
2025-08-27 22:24:37,982 - INFO -   LR: 0.100000
2025-08-27 22:24:38,013 - INFO - 
Epoch: 58, lr = 0.1
2025-08-27 22:24:38,203 - INFO - Epoch: [58][0/391] Time 0.189 (0.189) Data 0.167 (0.167) Loss 0.4726 (0.4726) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 22:24:38,921 - INFO - Pruning info: sparsity=0.791
2025-08-27 22:24:38,921 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:24:39,955 - INFO - Epoch: [58][100/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.3405 (0.4162) Acc@1 89.844 (85.992) Acc@5 99.219 (99.358)
2025-08-27 22:24:41,721 - INFO - Epoch: [58][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4342 (0.4204) Acc@1 87.500 (85.704) Acc@5 98.438 (99.343)
2025-08-27 22:24:41,754 - INFO - Pruning info: sparsity=0.791
2025-08-27 22:24:41,754 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:24:43,676 - INFO - Epoch: [58][300/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.3814 (0.4195) Acc@1 87.500 (85.719) Acc@5 100.000 (99.310)
2025-08-27 22:24:44,741 - INFO - Pruning info: sparsity=0.791
2025-08-27 22:24:44,741 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:24:45,404 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6482 (0.6482) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 22:24:46,279 - INFO - Epoch 58:
2025-08-27 22:24:46,280 - INFO -   Train: acc1: 85.7480 | acc5: 99.3540 | loss: 0.4168 | sparsity: 0.7907 | reactivation_rate: 0.0007
2025-08-27 22:24:46,280 - INFO -   Val:   acc1: 77.6000 | acc5: 98.6700 | loss: 0.7323
2025-08-27 22:24:46,280 - INFO -   LR: 0.100000
2025-08-27 22:24:46,291 - INFO - 
Epoch: 59, lr = 0.1
2025-08-27 22:24:46,488 - INFO - Epoch: [59][0/391] Time 0.196 (0.196) Data 0.171 (0.171) Loss 0.3660 (0.3660) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:24:48,264 - INFO - Epoch: [59][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.4113 (0.4030) Acc@1 85.156 (85.907) Acc@5 100.000 (99.505)
2025-08-27 22:24:48,840 - INFO - Pruning info: sparsity=0.792
2025-08-27 22:24:48,840 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:24:50,132 - INFO - Epoch: [59][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5852 (0.4140) Acc@1 81.250 (85.564) Acc@5 97.656 (99.452)
2025-08-27 22:24:51,778 - INFO - Pruning info: sparsity=0.792
2025-08-27 22:24:51,778 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:24:51,954 - INFO - Epoch: [59][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4391 (0.4204) Acc@1 84.375 (85.250) Acc@5 99.219 (99.458)
2025-08-27 22:24:53,715 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5649 (0.5649) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:24:54,564 - INFO - Epoch 59:
2025-08-27 22:24:54,564 - INFO -   Train: acc1: 85.2540 | acc5: 99.4360 | loss: 0.4221 | sparsity: 0.7922 | reactivation_rate: 0.0007
2025-08-27 22:24:54,564 - INFO -   Val:   acc1: 78.0600 | acc5: 98.7200 | loss: 0.6650
2025-08-27 22:24:54,564 - INFO -   LR: 0.100000
2025-08-27 22:24:54,578 - INFO - 
Epoch: 60, lr = 0.1
2025-08-27 22:24:54,760 - INFO - Epoch: [60][0/391] Time 0.182 (0.182) Data 0.148 (0.148) Loss 0.3309 (0.3309) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:24:55,872 - INFO - Pruning info: sparsity=0.794
2025-08-27 22:24:55,872 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:24:56,636 - INFO - Epoch: [60][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.3855 (0.4128) Acc@1 85.156 (85.721) Acc@5 98.438 (99.358)
2025-08-27 22:24:58,568 - INFO - Epoch: [60][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.2945 (0.4223) Acc@1 88.281 (85.253) Acc@5 100.000 (99.343)
2025-08-27 22:24:58,912 - INFO - Pruning info: sparsity=0.794
2025-08-27 22:24:58,913 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:25:00,384 - INFO - Epoch: [60][300/391] Time 0.046 (0.019) Data 0.018 (0.002) Loss 0.4379 (0.4197) Acc@1 82.031 (85.447) Acc@5 99.219 (99.382)
2025-08-27 22:25:01,866 - INFO - Pruning info: sparsity=0.794
2025-08-27 22:25:01,867 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:25:02,204 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5587 (0.5587) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:25:03,036 - INFO - Epoch 60:
2025-08-27 22:25:03,036 - INFO -   Train: acc1: 85.5540 | acc5: 99.4180 | loss: 0.4174 | sparsity: 0.7936 | reactivation_rate: 0.0007
2025-08-27 22:25:03,036 - INFO -   Val:   acc1: 80.0100 | acc5: 98.8400 | loss: 0.6046
2025-08-27 22:25:03,036 - INFO -   LR: 0.100000
2025-08-27 22:25:03,083 - INFO - 
Epoch: 61, lr = 0.1
2025-08-27 22:25:03,261 - INFO - Epoch: [61][0/391] Time 0.177 (0.177) Data 0.154 (0.154) Loss 0.4398 (0.4398) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:25:05,053 - INFO - Epoch: [61][100/391] Time 0.024 (0.019) Data 0.000 (0.005) Loss 0.4169 (0.3844) Acc@1 88.281 (86.719) Acc@5 99.219 (99.528)
2025-08-27 22:25:05,985 - INFO - Pruning info: sparsity=0.795
2025-08-27 22:25:05,985 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:25:06,946 - INFO - Epoch: [61][200/391] Time 0.013 (0.019) Data 0.000 (0.005) Loss 0.4390 (0.4068) Acc@1 87.500 (85.961) Acc@5 100.000 (99.487)
2025-08-27 22:25:08,777 - INFO - Epoch: [61][300/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.4340 (0.4129) Acc@1 83.594 (85.771) Acc@5 100.000 (99.476)
2025-08-27 22:25:08,962 - INFO - Pruning info: sparsity=0.795
2025-08-27 22:25:08,963 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:25:10,613 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5350 (0.5350) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:25:11,455 - INFO - Epoch 61:
2025-08-27 22:25:11,456 - INFO -   Train: acc1: 85.5800 | acc5: 99.4520 | loss: 0.4201 | sparsity: 0.7948 | reactivation_rate: 0.0006
2025-08-27 22:25:11,456 - INFO -   Val:   acc1: 81.5800 | acc5: 99.1100 | loss: 0.5679
2025-08-27 22:25:11,456 - INFO -   LR: 0.100000
2025-08-27 22:25:11,466 - INFO - 
Epoch: 62, lr = 0.1
2025-08-27 22:25:11,652 - INFO - Epoch: [62][0/391] Time 0.185 (0.185) Data 0.160 (0.160) Loss 0.2668 (0.2668) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:25:13,034 - INFO - Pruning info: sparsity=0.796
2025-08-27 22:25:13,035 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:25:13,480 - INFO - Epoch: [62][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4291 (0.3980) Acc@1 84.375 (86.262) Acc@5 99.219 (99.513)
2025-08-27 22:25:15,307 - INFO - Epoch: [62][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3785 (0.4034) Acc@1 85.938 (85.972) Acc@5 99.219 (99.471)
2025-08-27 22:25:16,015 - INFO - Pruning info: sparsity=0.796
2025-08-27 22:25:16,015 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:25:17,145 - INFO - Epoch: [62][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.3731 (0.4078) Acc@1 85.156 (85.984) Acc@5 100.000 (99.458)
2025-08-27 22:25:19,002 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5795 (0.5795) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:25:19,863 - INFO - Epoch 62:
2025-08-27 22:25:19,864 - INFO -   Train: acc1: 85.7840 | acc5: 99.4440 | loss: 0.4146 | sparsity: 0.7958 | reactivation_rate: 0.0006
2025-08-27 22:25:19,864 - INFO -   Val:   acc1: 80.6900 | acc5: 99.1400 | loss: 0.5853
2025-08-27 22:25:19,864 - INFO -   LR: 0.100000
2025-08-27 22:25:19,875 - INFO - 
Epoch: 63, lr = 0.1
2025-08-27 22:25:20,056 - INFO - Epoch: [63][0/391] Time 0.180 (0.180) Data 0.151 (0.151) Loss 0.3025 (0.3025) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 22:25:20,200 - INFO - Pruning info: sparsity=0.797
2025-08-27 22:25:20,200 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:25:21,939 - INFO - Epoch: [63][100/391] Time 0.019 (0.020) Data 0.000 (0.005) Loss 0.4626 (0.3881) Acc@1 84.375 (86.595) Acc@5 99.219 (99.435)
2025-08-27 22:25:23,119 - INFO - Pruning info: sparsity=0.797
2025-08-27 22:25:23,119 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:25:23,717 - INFO - Epoch: [63][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4348 (0.4045) Acc@1 82.812 (85.945) Acc@5 100.000 (99.452)
2025-08-27 22:25:25,596 - INFO - Epoch: [63][300/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.3565 (0.4121) Acc@1 88.281 (85.634) Acc@5 100.000 (99.471)
2025-08-27 22:25:26,075 - INFO - Pruning info: sparsity=0.797
2025-08-27 22:25:26,075 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:25:27,351 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.8976 (0.8976) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-27 22:25:28,181 - INFO - Epoch 63:
2025-08-27 22:25:28,181 - INFO -   Train: acc1: 85.5840 | acc5: 99.4520 | loss: 0.4143 | sparsity: 0.7967 | reactivation_rate: 0.0005
2025-08-27 22:25:28,181 - INFO -   Val:   acc1: 73.3900 | acc5: 98.5000 | loss: 0.9184
2025-08-27 22:25:28,181 - INFO -   LR: 0.100000
2025-08-27 22:25:28,193 - INFO - 
Epoch: 64, lr = 0.1
2025-08-27 22:25:28,386 - INFO - Epoch: [64][0/391] Time 0.192 (0.192) Data 0.162 (0.162) Loss 0.3496 (0.3496) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:25:30,096 - INFO - Pruning info: sparsity=0.797
2025-08-27 22:25:30,096 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:25:30,164 - INFO - Epoch: [64][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.3962 (0.4118) Acc@1 83.594 (85.899) Acc@5 100.000 (99.466)
2025-08-27 22:25:31,982 - INFO - Epoch: [64][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.4053 (0.4214) Acc@1 82.812 (85.529) Acc@5 100.000 (99.440)
2025-08-27 22:25:32,969 - INFO - Pruning info: sparsity=0.797
2025-08-27 22:25:32,969 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:25:33,828 - INFO - Epoch: [64][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4730 (0.4213) Acc@1 83.594 (85.579) Acc@5 100.000 (99.476)
2025-08-27 22:25:35,578 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.5894 (0.5894) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 22:25:36,429 - INFO - Epoch 64:
2025-08-27 22:25:36,429 - INFO -   Train: acc1: 85.5840 | acc5: 99.4600 | loss: 0.4199 | sparsity: 0.7975 | reactivation_rate: 0.0005
2025-08-27 22:25:36,430 - INFO -   Val:   acc1: 80.7700 | acc5: 99.0000 | loss: 0.5973
2025-08-27 22:25:36,430 - INFO -   LR: 0.100000
2025-08-27 22:25:36,441 - INFO - 
Epoch: 65, lr = 0.1
2025-08-27 22:25:36,633 - INFO - Epoch: [65][0/391] Time 0.191 (0.191) Data 0.166 (0.166) Loss 0.3529 (0.3529) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:25:37,059 - INFO - Pruning info: sparsity=0.798
2025-08-27 22:25:37,059 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:25:38,445 - INFO - Epoch: [65][100/391] Time 0.041 (0.020) Data 0.027 (0.003) Loss 0.4123 (0.4168) Acc@1 85.156 (85.605) Acc@5 99.219 (99.520)
2025-08-27 22:25:39,949 - INFO - Pruning info: sparsity=0.798
2025-08-27 22:25:39,962 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:25:40,231 - INFO - Epoch: [65][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3852 (0.4187) Acc@1 85.156 (85.502) Acc@5 100.000 (99.471)
2025-08-27 22:25:42,009 - INFO - Epoch: [65][300/391] Time 0.011 (0.018) Data 0.000 (0.002) Loss 0.3521 (0.4232) Acc@1 87.500 (85.250) Acc@5 100.000 (99.439)
2025-08-27 22:25:42,763 - INFO - Pruning info: sparsity=0.798
2025-08-27 22:25:42,763 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:25:43,709 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.8203 (0.8203) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 22:25:44,532 - INFO - Epoch 65:
2025-08-27 22:25:44,532 - INFO -   Train: acc1: 85.2680 | acc5: 99.4360 | loss: 0.4233 | sparsity: 0.7981 | reactivation_rate: 0.0004
2025-08-27 22:25:44,532 - INFO -   Val:   acc1: 75.3500 | acc5: 98.8100 | loss: 0.7947
2025-08-27 22:25:44,532 - INFO -   LR: 0.100000
2025-08-27 22:25:44,545 - INFO - 
Epoch: 66, lr = 0.1
2025-08-27 22:25:44,718 - INFO - Epoch: [66][0/391] Time 0.172 (0.172) Data 0.143 (0.143) Loss 0.3873 (0.3873) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-27 22:25:46,459 - INFO - Epoch: [66][100/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.3138 (0.3988) Acc@1 89.062 (86.278) Acc@5 100.000 (99.443)
2025-08-27 22:25:46,716 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:25:46,716 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:25:48,317 - INFO - Epoch: [66][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.5899 (0.4075) Acc@1 78.906 (85.891) Acc@5 98.438 (99.386)
2025-08-27 22:25:49,613 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:25:49,613 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:25:50,103 - INFO - Epoch: [66][300/391] Time 0.044 (0.018) Data 0.032 (0.003) Loss 0.4771 (0.4203) Acc@1 83.594 (85.366) Acc@5 99.219 (99.403)
2025-08-27 22:25:51,809 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.9005 (0.9005) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-27 22:25:52,623 - INFO - Epoch 66:
2025-08-27 22:25:52,623 - INFO -   Train: acc1: 85.4980 | acc5: 99.4220 | loss: 0.4187 | sparsity: 0.7986 | reactivation_rate: 0.0004
2025-08-27 22:25:52,623 - INFO -   Val:   acc1: 67.1700 | acc5: 96.0300 | loss: 1.1347
2025-08-27 22:25:52,623 - INFO -   LR: 0.100000
2025-08-27 22:25:52,634 - INFO - 
Epoch: 67, lr = 0.1
2025-08-27 22:25:52,830 - INFO - Epoch: [67][0/391] Time 0.196 (0.196) Data 0.164 (0.164) Loss 0.3757 (0.3757) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:25:53,581 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:25:53,581 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:25:54,538 - INFO - Epoch: [67][100/391] Time 0.027 (0.019) Data 0.013 (0.004) Loss 0.4321 (0.4081) Acc@1 84.375 (85.891) Acc@5 99.219 (99.520)
2025-08-27 22:25:56,288 - INFO - Epoch: [67][200/391] Time 0.018 (0.018) Data 0.005 (0.003) Loss 0.3737 (0.4232) Acc@1 83.594 (85.417) Acc@5 100.000 (99.448)
2025-08-27 22:25:56,329 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:25:56,342 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:25:58,054 - INFO - Epoch: [67][300/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.3369 (0.4159) Acc@1 88.281 (85.649) Acc@5 97.656 (99.419)
2025-08-27 22:25:59,128 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:25:59,129 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:25:59,759 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.7303 (0.7303) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:26:00,577 - INFO - Epoch 67:
2025-08-27 22:26:00,577 - INFO -   Train: acc1: 85.5460 | acc5: 99.4020 | loss: 0.4182 | sparsity: 0.7990 | reactivation_rate: 0.0004
2025-08-27 22:26:00,577 - INFO -   Val:   acc1: 77.7900 | acc5: 98.4000 | loss: 0.6908
2025-08-27 22:26:00,577 - INFO -   LR: 0.100000
2025-08-27 22:26:00,588 - INFO - 
Epoch: 68, lr = 0.1
2025-08-27 22:26:00,771 - INFO - Epoch: [68][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.3191 (0.3191) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:26:02,490 - INFO - Epoch: [68][100/391] Time 0.027 (0.019) Data 0.000 (0.005) Loss 0.4935 (0.4062) Acc@1 81.250 (85.999) Acc@5 100.000 (99.551)
2025-08-27 22:26:03,015 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:26:03,016 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:26:04,305 - INFO - Epoch: [68][200/391] Time 0.034 (0.018) Data 0.013 (0.004) Loss 0.4452 (0.4116) Acc@1 85.938 (85.833) Acc@5 100.000 (99.405)
2025-08-27 22:26:05,872 - INFO - Pruning info: sparsity=0.799
2025-08-27 22:26:05,872 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:26:06,049 - INFO - Epoch: [68][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.4497 (0.4132) Acc@1 84.375 (85.761) Acc@5 99.219 (99.413)
2025-08-27 22:26:07,816 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.5280 (0.5280) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:26:08,621 - INFO - Epoch 68:
2025-08-27 22:26:08,621 - INFO -   Train: acc1: 85.7720 | acc5: 99.4180 | loss: 0.4126 | sparsity: 0.7993 | reactivation_rate: 0.0003
2025-08-27 22:26:08,621 - INFO -   Val:   acc1: 80.3200 | acc5: 98.8800 | loss: 0.5985
2025-08-27 22:26:08,621 - INFO -   LR: 0.100000
2025-08-27 22:26:08,634 - INFO - 
Epoch: 69, lr = 0.1
2025-08-27 22:26:08,804 - INFO - Epoch: [69][0/391] Time 0.169 (0.169) Data 0.132 (0.132) Loss 0.4497 (0.4497) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:26:09,900 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:09,901 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:26:10,583 - INFO - Epoch: [69][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3923 (0.4141) Acc@1 88.281 (85.458) Acc@5 100.000 (99.451)
2025-08-27 22:26:12,378 - INFO - Epoch: [69][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4755 (0.4165) Acc@1 82.812 (85.494) Acc@5 98.438 (99.444)
2025-08-27 22:26:12,734 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:12,735 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:26:14,154 - INFO - Epoch: [69][300/391] Time 0.016 (0.018) Data 0.000 (0.003) Loss 0.4696 (0.4219) Acc@1 82.812 (85.387) Acc@5 100.000 (99.450)
2025-08-27 22:26:15,566 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:15,567 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:26:15,882 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.8230 (0.8230) Acc@1 78.906 (78.906) Acc@5 96.094 (96.094)
2025-08-27 22:26:16,722 - INFO - Epoch 69:
2025-08-27 22:26:16,722 - INFO -   Train: acc1: 85.3680 | acc5: 99.4500 | loss: 0.4225 | sparsity: 0.7996 | reactivation_rate: 0.0003
2025-08-27 22:26:16,722 - INFO -   Val:   acc1: 74.9900 | acc5: 97.5500 | loss: 0.8833
2025-08-27 22:26:16,722 - INFO -   LR: 0.100000
2025-08-27 22:26:16,735 - INFO - 
Epoch: 70, lr = 0.1
2025-08-27 22:26:16,909 - INFO - Epoch: [70][0/391] Time 0.172 (0.172) Data 0.151 (0.151) Loss 0.5347 (0.5347) Acc@1 83.594 (83.594) Acc@5 97.656 (97.656)
2025-08-27 22:26:18,706 - INFO - Epoch: [70][100/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4023 (0.4135) Acc@1 83.594 (85.644) Acc@5 99.219 (99.381)
2025-08-27 22:26:19,589 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:19,589 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:26:20,494 - INFO - Epoch: [70][200/391] Time 0.025 (0.019) Data 0.006 (0.002) Loss 0.4431 (0.4175) Acc@1 83.594 (85.560) Acc@5 100.000 (99.378)
2025-08-27 22:26:22,230 - INFO - Epoch: [70][300/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.1995 (0.4189) Acc@1 94.531 (85.649) Acc@5 100.000 (99.382)
2025-08-27 22:26:22,414 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:22,414 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:26:23,950 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.5112 (0.5112) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:26:24,770 - INFO - Epoch 70:
2025-08-27 22:26:24,770 - INFO -   Train: acc1: 85.6800 | acc5: 99.4260 | loss: 0.4175 | sparsity: 0.7998 | reactivation_rate: 0.0002
2025-08-27 22:26:24,770 - INFO -   Val:   acc1: 80.6400 | acc5: 98.8500 | loss: 0.6106
2025-08-27 22:26:24,770 - INFO -   LR: 0.100000
2025-08-27 22:26:24,815 - INFO - 
Epoch: 71, lr = 0.1
2025-08-27 22:26:24,987 - INFO - Epoch: [71][0/391] Time 0.172 (0.172) Data 0.152 (0.152) Loss 0.2839 (0.2839) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:26:26,376 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:26,376 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:26:26,797 - INFO - Epoch: [71][100/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.3405 (0.3980) Acc@1 85.156 (86.239) Acc@5 100.000 (99.466)
2025-08-27 22:26:28,639 - INFO - Epoch: [71][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.3434 (0.4083) Acc@1 86.719 (85.887) Acc@5 99.219 (99.433)
2025-08-27 22:26:29,261 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:29,262 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:26:30,379 - INFO - Epoch: [71][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.4185 (0.4151) Acc@1 82.031 (85.657) Acc@5 100.000 (99.476)
2025-08-27 22:26:32,129 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6514 (0.6514) Acc@1 81.250 (81.250) Acc@5 96.875 (96.875)
2025-08-27 22:26:32,949 - INFO - Epoch 71:
2025-08-27 22:26:32,949 - INFO -   Train: acc1: 85.5580 | acc5: 99.4440 | loss: 0.4183 | sparsity: 0.7999 | reactivation_rate: 0.0002
2025-08-27 22:26:32,949 - INFO -   Val:   acc1: 81.6600 | acc5: 99.0100 | loss: 0.5632
2025-08-27 22:26:32,949 - INFO -   LR: 0.100000
2025-08-27 22:26:32,964 - INFO - 
Epoch: 72, lr = 0.1
2025-08-27 22:26:33,115 - INFO - Epoch: [72][0/391] Time 0.150 (0.150) Data 0.126 (0.126) Loss 0.4276 (0.4276) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:26:33,285 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:33,285 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:35,036 - INFO - Epoch: [72][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.2735 (0.3953) Acc@1 89.844 (86.293) Acc@5 99.219 (99.443)
2025-08-27 22:26:36,271 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:36,272 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:26:36,884 - INFO - Epoch: [72][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4555 (0.4138) Acc@1 82.812 (85.798) Acc@5 100.000 (99.366)
2025-08-27 22:26:38,664 - INFO - Epoch: [72][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5166 (0.4181) Acc@1 82.812 (85.662) Acc@5 98.438 (99.382)
2025-08-27 22:26:39,188 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:39,188 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:40,447 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.5515 (0.5515) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:26:41,279 - INFO - Epoch 72:
2025-08-27 22:26:41,279 - INFO -   Train: acc1: 85.5400 | acc5: 99.4080 | loss: 0.4193 | sparsity: 0.7999 | reactivation_rate: 0.0002
2025-08-27 22:26:41,279 - INFO -   Val:   acc1: 79.4200 | acc5: 98.6900 | loss: 0.6460
2025-08-27 22:26:41,279 - INFO -   LR: 0.100000
2025-08-27 22:26:41,293 - INFO - 
Epoch: 73, lr = 0.1
2025-08-27 22:26:41,462 - INFO - Epoch: [73][0/391] Time 0.168 (0.168) Data 0.152 (0.152) Loss 0.4275 (0.4275) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:26:43,277 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:43,277 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:43,358 - INFO - Epoch: [73][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.2535 (0.4033) Acc@1 90.625 (85.961) Acc@5 100.000 (99.528)
2025-08-27 22:26:45,176 - INFO - Epoch: [73][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.4492 (0.4093) Acc@1 84.375 (85.829) Acc@5 100.000 (99.479)
2025-08-27 22:26:46,208 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:46,208 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:46,995 - INFO - Epoch: [73][300/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.4187 (0.4124) Acc@1 83.594 (85.722) Acc@5 100.000 (99.460)
2025-08-27 22:26:48,793 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.6904 (0.6904) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 22:26:49,632 - INFO - Epoch 73:
2025-08-27 22:26:49,632 - INFO -   Train: acc1: 85.7280 | acc5: 99.4460 | loss: 0.4127 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-27 22:26:49,632 - INFO -   Val:   acc1: 75.5700 | acc5: 98.6300 | loss: 0.7673
2025-08-27 22:26:49,632 - INFO -   LR: 0.100000
2025-08-27 22:26:49,645 - INFO - 
Epoch: 74, lr = 0.1
2025-08-27 22:26:49,829 - INFO - Epoch: [74][0/391] Time 0.184 (0.184) Data 0.160 (0.160) Loss 0.4821 (0.4821) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:26:50,366 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:50,366 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:51,775 - INFO - Epoch: [74][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.4065 (0.4235) Acc@1 83.594 (85.481) Acc@5 99.219 (99.296)
2025-08-27 22:26:53,338 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:53,338 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:53,605 - INFO - Epoch: [74][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.4606 (0.4164) Acc@1 85.938 (85.724) Acc@5 99.219 (99.366)
2025-08-27 22:26:55,431 - INFO - Epoch: [74][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3623 (0.4184) Acc@1 86.719 (85.585) Acc@5 100.000 (99.403)
2025-08-27 22:26:56,258 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:26:56,258 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:26:57,213 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.8059 (0.8059) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 22:26:58,048 - INFO - Epoch 74:
2025-08-27 22:26:58,048 - INFO -   Train: acc1: 85.5840 | acc5: 99.4000 | loss: 0.4202 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-27 22:26:58,048 - INFO -   Val:   acc1: 78.8100 | acc5: 98.6800 | loss: 0.6854
2025-08-27 22:26:58,048 - INFO -   LR: 0.100000
2025-08-27 22:26:58,060 - INFO - 
Epoch: 75, lr = 0.1
2025-08-27 22:26:58,246 - INFO - Epoch: [75][0/391] Time 0.185 (0.185) Data 0.166 (0.166) Loss 0.2946 (0.2946) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:27:00,049 - INFO - Epoch: [75][100/391] Time 0.029 (0.020) Data 0.010 (0.004) Loss 0.4194 (0.4096) Acc@1 87.500 (85.860) Acc@5 98.438 (99.505)
2025-08-27 22:27:00,252 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:00,253 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:01,783 - INFO - Epoch: [75][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3191 (0.4126) Acc@1 90.625 (85.825) Acc@5 99.219 (99.448)
2025-08-27 22:27:03,137 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:03,138 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:03,602 - INFO - Epoch: [75][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.6075 (0.4167) Acc@1 81.250 (85.597) Acc@5 96.094 (99.445)
2025-08-27 22:27:05,371 - INFO - Test: [0/79] Time 0.105 (0.105) Loss 0.6413 (0.6413) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 22:27:06,234 - INFO - Epoch 75:
2025-08-27 22:27:06,234 - INFO -   Train: acc1: 85.6640 | acc5: 99.4220 | loss: 0.4155 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-27 22:27:06,234 - INFO -   Val:   acc1: 79.8300 | acc5: 98.5900 | loss: 0.6091
2025-08-27 22:27:06,234 - INFO -   LR: 0.100000
2025-08-27 22:27:06,246 - INFO - 
Epoch: 76, lr = 0.1
2025-08-27 22:27:06,423 - INFO - Epoch: [76][0/391] Time 0.176 (0.176) Data 0.152 (0.152) Loss 0.4028 (0.4028) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:27:07,168 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:07,168 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:08,237 - INFO - Epoch: [76][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.3444 (0.4048) Acc@1 86.719 (85.744) Acc@5 100.000 (99.489)
2025-08-27 22:27:10,034 - INFO - Epoch: [76][200/391] Time 0.025 (0.019) Data 0.014 (0.003) Loss 0.4692 (0.4115) Acc@1 87.500 (85.568) Acc@5 98.438 (99.506)
2025-08-27 22:27:10,094 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:10,094 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:11,872 - INFO - Epoch: [76][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.5279 (0.4153) Acc@1 86.719 (85.504) Acc@5 97.656 (99.458)
2025-08-27 22:27:12,962 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:12,962 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:13,566 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5410 (0.5410) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:27:14,403 - INFO - Epoch 76:
2025-08-27 22:27:14,403 - INFO -   Train: acc1: 85.7040 | acc5: 99.4460 | loss: 0.4126 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-27 22:27:14,404 - INFO -   Val:   acc1: 80.8100 | acc5: 99.0700 | loss: 0.5785
2025-08-27 22:27:14,404 - INFO -   LR: 0.100000
2025-08-27 22:27:14,416 - INFO - 
Epoch: 77, lr = 0.1
2025-08-27 22:27:14,606 - INFO - Epoch: [77][0/391] Time 0.189 (0.189) Data 0.157 (0.157) Loss 0.3973 (0.3973) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:27:16,421 - INFO - Epoch: [77][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4530 (0.4195) Acc@1 81.250 (85.373) Acc@5 99.219 (99.497)
2025-08-27 22:27:17,033 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:17,033 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:18,230 - INFO - Epoch: [77][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.3830 (0.4243) Acc@1 88.281 (85.102) Acc@5 98.438 (99.448)
2025-08-27 22:27:20,010 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:20,011 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:20,166 - INFO - Epoch: [77][300/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.3514 (0.4168) Acc@1 89.062 (85.512) Acc@5 100.000 (99.413)
2025-08-27 22:27:21,998 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5314 (0.5314) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:27:22,856 - INFO - Epoch 77:
2025-08-27 22:27:22,856 - INFO -   Train: acc1: 85.4740 | acc5: 99.4160 | loss: 0.4189 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-27 22:27:22,856 - INFO -   Val:   acc1: 82.2800 | acc5: 99.3300 | loss: 0.5200
2025-08-27 22:27:22,856 - INFO -   LR: 0.100000
2025-08-27 22:27:22,870 - INFO - 
Epoch: 78, lr = 0.1
2025-08-27 22:27:23,055 - INFO - Epoch: [78][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.3485 (0.3485) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:27:24,138 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:24,138 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:24,851 - INFO - Epoch: [78][100/391] Time 0.020 (0.020) Data 0.000 (0.005) Loss 0.3909 (0.3974) Acc@1 86.719 (86.541) Acc@5 100.000 (99.520)
2025-08-27 22:27:26,662 - INFO - Epoch: [78][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4242 (0.4140) Acc@1 84.375 (85.766) Acc@5 99.219 (99.510)
2025-08-27 22:27:27,022 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:27,023 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:28,403 - INFO - Epoch: [78][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.4381 (0.4174) Acc@1 82.812 (85.655) Acc@5 100.000 (99.476)
2025-08-27 22:27:29,910 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:29,910 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:30,218 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.7109 (0.7109) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 22:27:31,052 - INFO - Epoch 78:
2025-08-27 22:27:31,053 - INFO -   Train: acc1: 85.5080 | acc5: 99.4580 | loss: 0.4193 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-27 22:27:31,053 - INFO -   Val:   acc1: 76.8900 | acc5: 98.8000 | loss: 0.7700
2025-08-27 22:27:31,053 - INFO -   LR: 0.100000
2025-08-27 22:27:31,067 - INFO - 
Epoch: 79, lr = 0.1
2025-08-27 22:27:31,251 - INFO - Epoch: [79][0/391] Time 0.183 (0.183) Data 0.161 (0.161) Loss 0.4328 (0.4328) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:27:33,024 - INFO - Epoch: [79][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4783 (0.4188) Acc@1 84.375 (85.767) Acc@5 97.656 (99.296)
2025-08-27 22:27:33,971 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:33,972 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:27:34,867 - INFO - Epoch: [79][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4602 (0.4148) Acc@1 85.156 (85.669) Acc@5 99.219 (99.343)
2025-08-27 22:27:36,666 - INFO - Epoch: [79][300/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.5423 (0.4177) Acc@1 87.500 (85.605) Acc@5 97.656 (99.356)
2025-08-27 22:27:36,850 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:36,850 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:38,432 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.5710 (0.5710) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 22:27:39,262 - INFO - Epoch 79:
2025-08-27 22:27:39,262 - INFO -   Train: acc1: 85.5760 | acc5: 99.3860 | loss: 0.4202 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:27:39,262 - INFO -   Val:   acc1: 81.1800 | acc5: 98.9400 | loss: 0.5697
2025-08-27 22:27:39,262 - INFO -   LR: 0.100000
2025-08-27 22:27:39,273 - INFO - 
Epoch: 80, lr = 0.1
2025-08-27 22:27:39,452 - INFO - Epoch: [80][0/391] Time 0.178 (0.178) Data 0.152 (0.152) Loss 0.3113 (0.3113) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:27:40,767 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:40,767 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:41,156 - INFO - Epoch: [80][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.5173 (0.4006) Acc@1 79.688 (86.224) Acc@5 97.656 (99.466)
2025-08-27 22:27:42,899 - INFO - Epoch: [80][200/391] Time 0.011 (0.018) Data 0.000 (0.004) Loss 0.2657 (0.4073) Acc@1 91.406 (86.019) Acc@5 100.000 (99.475)
2025-08-27 22:27:43,567 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:43,567 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:44,645 - INFO - Epoch: [80][300/391] Time 0.036 (0.018) Data 0.005 (0.003) Loss 0.5044 (0.4088) Acc@1 82.812 (85.865) Acc@5 100.000 (99.437)
2025-08-27 22:27:46,383 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4400 (0.4400) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:27:47,214 - INFO - Epoch 80:
2025-08-27 22:27:47,214 - INFO -   Train: acc1: 85.6700 | acc5: 99.4080 | loss: 0.4170 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:27:47,214 - INFO -   Val:   acc1: 84.0000 | acc5: 99.1200 | loss: 0.4791
2025-08-27 22:27:47,215 - INFO -   LR: 0.100000
2025-08-27 22:27:47,260 - INFO - Checkpoint saved: epoch=80, metric=84.0000
2025-08-27 22:27:47,310 - INFO - 
Epoch: 81, lr = 0.1
2025-08-27 22:27:47,487 - INFO - Epoch: [81][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.4049 (0.4049) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-27 22:27:47,618 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:47,618 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:49,183 - INFO - Epoch: [81][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3257 (0.4019) Acc@1 90.625 (86.347) Acc@5 100.000 (99.358)
2025-08-27 22:27:50,423 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:50,424 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:50,992 - INFO - Epoch: [81][200/391] Time 0.040 (0.018) Data 0.012 (0.004) Loss 0.4074 (0.4126) Acc@1 88.281 (85.829) Acc@5 100.000 (99.378)
2025-08-27 22:27:52,864 - INFO - Epoch: [81][300/391] Time 0.011 (0.018) Data 0.001 (0.004) Loss 0.4383 (0.4156) Acc@1 85.156 (85.727) Acc@5 100.000 (99.406)
2025-08-27 22:27:53,401 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:53,401 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:54,605 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6478 (0.6478) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-27 22:27:55,430 - INFO - Epoch 81:
2025-08-27 22:27:55,430 - INFO -   Train: acc1: 85.6880 | acc5: 99.4000 | loss: 0.4156 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:27:55,430 - INFO -   Val:   acc1: 80.4900 | acc5: 98.8600 | loss: 0.5894
2025-08-27 22:27:55,430 - INFO -   LR: 0.100000
2025-08-27 22:27:55,442 - INFO - 
Epoch: 82, lr = 0.1
2025-08-27 22:27:55,625 - INFO - Epoch: [82][0/391] Time 0.182 (0.182) Data 0.165 (0.165) Loss 0.4604 (0.4604) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:27:57,488 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:27:57,488 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:27:57,527 - INFO - Epoch: [82][100/391] Time 0.015 (0.021) Data 0.000 (0.005) Loss 0.4573 (0.4168) Acc@1 84.375 (85.744) Acc@5 99.219 (99.412)
2025-08-27 22:27:59,373 - INFO - Epoch: [82][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3975 (0.4193) Acc@1 85.156 (85.751) Acc@5 100.000 (99.425)
2025-08-27 22:28:00,370 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:00,371 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:01,150 - INFO - Epoch: [82][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3832 (0.4206) Acc@1 87.500 (85.732) Acc@5 100.000 (99.434)
2025-08-27 22:28:02,856 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6452 (0.6452) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 22:28:03,681 - INFO - Epoch 82:
2025-08-27 22:28:03,682 - INFO -   Train: acc1: 85.7980 | acc5: 99.4140 | loss: 0.4186 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:03,682 - INFO -   Val:   acc1: 76.3400 | acc5: 98.7700 | loss: 0.7368
2025-08-27 22:28:03,682 - INFO -   LR: 0.100000
2025-08-27 22:28:03,696 - INFO - 
Epoch: 83, lr = 0.1
2025-08-27 22:28:03,875 - INFO - Epoch: [83][0/391] Time 0.178 (0.178) Data 0.158 (0.158) Loss 0.4637 (0.4637) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:28:04,323 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:04,323 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:05,866 - INFO - Epoch: [83][100/391] Time 0.014 (0.021) Data 0.000 (0.006) Loss 0.3937 (0.4149) Acc@1 86.719 (85.582) Acc@5 100.000 (99.412)
2025-08-27 22:28:07,439 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:07,439 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:07,690 - INFO - Epoch: [83][200/391] Time 0.023 (0.020) Data 0.000 (0.005) Loss 0.3832 (0.4091) Acc@1 88.281 (85.906) Acc@5 100.000 (99.429)
2025-08-27 22:28:09,713 - INFO - Epoch: [83][300/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.6140 (0.4190) Acc@1 80.469 (85.582) Acc@5 97.656 (99.377)
2025-08-27 22:28:10,611 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:10,611 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:11,557 - INFO - Test: [0/79] Time 0.108 (0.108) Loss 0.6976 (0.6976) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:28:12,422 - INFO - Epoch 83:
2025-08-27 22:28:12,422 - INFO -   Train: acc1: 85.5320 | acc5: 99.3760 | loss: 0.4215 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:12,422 - INFO -   Val:   acc1: 77.5900 | acc5: 98.5600 | loss: 0.6986
2025-08-27 22:28:12,422 - INFO -   LR: 0.100000
2025-08-27 22:28:12,438 - INFO - 
Epoch: 84, lr = 0.1
2025-08-27 22:28:12,591 - INFO - Epoch: [84][0/391] Time 0.151 (0.151) Data 0.134 (0.134) Loss 0.4596 (0.4596) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:28:14,677 - INFO - Epoch: [84][100/391] Time 0.017 (0.022) Data 0.000 (0.004) Loss 0.3858 (0.4202) Acc@1 88.281 (85.605) Acc@5 99.219 (99.551)
2025-08-27 22:28:15,004 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:15,005 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:16,617 - INFO - Epoch: [84][200/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.4551 (0.4101) Acc@1 83.594 (85.821) Acc@5 99.219 (99.576)
2025-08-27 22:28:17,922 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:17,922 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:18,413 - INFO - Epoch: [84][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2950 (0.4127) Acc@1 92.188 (85.727) Acc@5 100.000 (99.535)
2025-08-27 22:28:20,172 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6045 (0.6045) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-27 22:28:21,139 - INFO - Epoch 84:
2025-08-27 22:28:21,139 - INFO -   Train: acc1: 85.5940 | acc5: 99.5000 | loss: 0.4185 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:21,139 - INFO -   Val:   acc1: 76.1100 | acc5: 98.6000 | loss: 0.7097
2025-08-27 22:28:21,139 - INFO -   LR: 0.100000
2025-08-27 22:28:21,152 - INFO - 
Epoch: 85, lr = 0.1
2025-08-27 22:28:21,480 - INFO - Epoch: [85][0/391] Time 0.327 (0.327) Data 0.308 (0.308) Loss 0.4852 (0.4852) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:28:22,413 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:22,413 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:23,457 - INFO - Epoch: [85][100/391] Time 0.012 (0.023) Data 0.000 (0.006) Loss 0.4843 (0.4129) Acc@1 83.594 (85.938) Acc@5 99.219 (99.459)
2025-08-27 22:28:25,275 - INFO - Epoch: [85][200/391] Time 0.039 (0.020) Data 0.022 (0.005) Loss 0.4446 (0.4118) Acc@1 85.156 (85.934) Acc@5 99.219 (99.506)
2025-08-27 22:28:25,356 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:25,357 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:27,109 - INFO - Epoch: [85][300/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4537 (0.4106) Acc@1 83.594 (86.044) Acc@5 100.000 (99.473)
2025-08-27 22:28:28,278 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:28,278 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:28,908 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.6857 (0.6857) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-27 22:28:29,746 - INFO - Epoch 85:
2025-08-27 22:28:29,746 - INFO -   Train: acc1: 85.9940 | acc5: 99.4480 | loss: 0.4123 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:29,746 - INFO -   Val:   acc1: 76.9900 | acc5: 98.6500 | loss: 0.7113
2025-08-27 22:28:29,746 - INFO -   LR: 0.100000
2025-08-27 22:28:29,760 - INFO - 
Epoch: 86, lr = 0.1
2025-08-27 22:28:29,937 - INFO - Epoch: [86][0/391] Time 0.177 (0.177) Data 0.153 (0.153) Loss 0.2868 (0.2868) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:28:31,746 - INFO - Epoch: [86][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4408 (0.4136) Acc@1 85.156 (85.535) Acc@5 100.000 (99.482)
2025-08-27 22:28:32,353 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:32,353 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:33,584 - INFO - Epoch: [86][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3854 (0.4163) Acc@1 86.719 (85.611) Acc@5 99.219 (99.468)
2025-08-27 22:28:35,297 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:35,297 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:35,415 - INFO - Epoch: [86][300/391] Time 0.030 (0.019) Data 0.018 (0.003) Loss 0.4076 (0.4195) Acc@1 85.156 (85.468) Acc@5 100.000 (99.413)
2025-08-27 22:28:37,146 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.5418 (0.5418) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 22:28:37,983 - INFO - Epoch 86:
2025-08-27 22:28:37,983 - INFO -   Train: acc1: 85.6000 | acc5: 99.4060 | loss: 0.4181 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:37,983 - INFO -   Val:   acc1: 78.8600 | acc5: 99.0100 | loss: 0.6436
2025-08-27 22:28:37,983 - INFO -   LR: 0.100000
2025-08-27 22:28:37,996 - INFO - 
Epoch: 87, lr = 0.1
2025-08-27 22:28:38,197 - INFO - Epoch: [87][0/391] Time 0.199 (0.199) Data 0.166 (0.166) Loss 0.3676 (0.3676) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:28:39,383 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:39,383 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:40,069 - INFO - Epoch: [87][100/391] Time 0.014 (0.021) Data 0.000 (0.005) Loss 0.2723 (0.4214) Acc@1 88.281 (85.589) Acc@5 100.000 (99.366)
2025-08-27 22:28:41,852 - INFO - Epoch: [87][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2594 (0.4182) Acc@1 89.844 (85.557) Acc@5 100.000 (99.425)
2025-08-27 22:28:42,235 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:42,235 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:43,715 - INFO - Epoch: [87][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5094 (0.4175) Acc@1 83.594 (85.587) Acc@5 99.219 (99.408)
2025-08-27 22:28:45,311 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:45,311 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:45,570 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.6413 (0.6413) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:28:46,460 - INFO - Epoch 87:
2025-08-27 22:28:46,460 - INFO -   Train: acc1: 85.5620 | acc5: 99.4280 | loss: 0.4176 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:46,460 - INFO -   Val:   acc1: 77.4300 | acc5: 98.4200 | loss: 0.6957
2025-08-27 22:28:46,460 - INFO -   LR: 0.100000
2025-08-27 22:28:46,473 - INFO - 
Epoch: 88, lr = 0.1
2025-08-27 22:28:46,679 - INFO - Epoch: [88][0/391] Time 0.206 (0.206) Data 0.178 (0.178) Loss 0.4424 (0.4424) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:28:48,482 - INFO - Epoch: [88][100/391] Time 0.014 (0.020) Data 0.000 (0.006) Loss 0.4291 (0.4215) Acc@1 83.594 (85.195) Acc@5 100.000 (99.451)
2025-08-27 22:28:49,469 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:49,470 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:50,311 - INFO - Epoch: [88][200/391] Time 0.028 (0.019) Data 0.000 (0.005) Loss 0.4533 (0.4112) Acc@1 84.375 (85.759) Acc@5 100.000 (99.499)
2025-08-27 22:28:52,177 - INFO - Epoch: [88][300/391] Time 0.028 (0.019) Data 0.005 (0.004) Loss 0.4907 (0.4147) Acc@1 83.594 (85.587) Acc@5 100.000 (99.468)
2025-08-27 22:28:52,356 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:52,356 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:53,902 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5047 (0.5047) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:28:54,798 - INFO - Epoch 88:
2025-08-27 22:28:54,799 - INFO -   Train: acc1: 85.5000 | acc5: 99.4380 | loss: 0.4171 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:28:54,799 - INFO -   Val:   acc1: 80.7200 | acc5: 99.0700 | loss: 0.5510
2025-08-27 22:28:54,799 - INFO -   LR: 0.100000
2025-08-27 22:28:54,812 - INFO - 
Epoch: 89, lr = 0.1
2025-08-27 22:28:54,990 - INFO - Epoch: [89][0/391] Time 0.177 (0.177) Data 0.161 (0.161) Loss 0.4454 (0.4454) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:28:56,440 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:56,441 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:28:56,803 - INFO - Epoch: [89][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.5235 (0.3920) Acc@1 82.812 (86.440) Acc@5 98.438 (99.443)
2025-08-27 22:28:58,655 - INFO - Epoch: [89][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3456 (0.4058) Acc@1 89.062 (86.046) Acc@5 98.438 (99.468)
2025-08-27 22:28:59,397 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:28:59,397 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:00,467 - INFO - Epoch: [89][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.6286 (0.4106) Acc@1 78.125 (85.816) Acc@5 99.219 (99.439)
2025-08-27 22:29:02,213 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7588 (0.7588) Acc@1 74.219 (74.219) Acc@5 98.438 (98.438)
2025-08-27 22:29:03,061 - INFO - Epoch 89:
2025-08-27 22:29:03,062 - INFO -   Train: acc1: 85.7780 | acc5: 99.4300 | loss: 0.4128 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:03,062 - INFO -   Val:   acc1: 77.4000 | acc5: 98.6300 | loss: 0.7424
2025-08-27 22:29:03,062 - INFO -   LR: 0.100000
2025-08-27 22:29:03,083 - INFO - 
Epoch: 90, lr = 0.1
2025-08-27 22:29:03,281 - INFO - Epoch: [90][0/391] Time 0.197 (0.197) Data 0.181 (0.181) Loss 0.4362 (0.4362) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:29:03,445 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:03,446 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:05,115 - INFO - Epoch: [90][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4335 (0.3984) Acc@1 85.938 (86.409) Acc@5 99.219 (99.428)
2025-08-27 22:29:06,366 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:06,366 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:06,899 - INFO - Epoch: [90][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.3920 (0.4073) Acc@1 85.156 (86.116) Acc@5 100.000 (99.456)
2025-08-27 22:29:08,777 - INFO - Epoch: [90][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4369 (0.4083) Acc@1 85.156 (86.013) Acc@5 99.219 (99.465)
2025-08-27 22:29:09,340 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:09,341 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:10,537 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6284 (0.6284) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-27 22:29:11,391 - INFO - Epoch 90:
2025-08-27 22:29:11,392 - INFO -   Train: acc1: 85.8400 | acc5: 99.4480 | loss: 0.4130 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:11,392 - INFO -   Val:   acc1: 74.7800 | acc5: 98.6000 | loss: 0.7716
2025-08-27 22:29:11,392 - INFO -   LR: 0.100000
2025-08-27 22:29:11,439 - INFO - 
Epoch: 91, lr = 0.1
2025-08-27 22:29:11,609 - INFO - Epoch: [91][0/391] Time 0.169 (0.169) Data 0.146 (0.146) Loss 0.4446 (0.4446) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:29:13,413 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:13,414 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:13,441 - INFO - Epoch: [91][100/391] Time 0.012 (0.020) Data 0.000 (0.006) Loss 0.3744 (0.3898) Acc@1 88.281 (86.626) Acc@5 100.000 (99.536)
2025-08-27 22:29:15,237 - INFO - Epoch: [91][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5910 (0.4065) Acc@1 84.375 (86.058) Acc@5 98.438 (99.479)
2025-08-27 22:29:16,298 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:16,298 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:17,072 - INFO - Epoch: [91][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3905 (0.4133) Acc@1 87.500 (85.803) Acc@5 99.219 (99.458)
2025-08-27 22:29:18,983 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5883 (0.5883) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:29:19,827 - INFO - Epoch 91:
2025-08-27 22:29:19,827 - INFO -   Train: acc1: 85.5680 | acc5: 99.4420 | loss: 0.4213 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:19,827 - INFO -   Val:   acc1: 80.9100 | acc5: 99.0200 | loss: 0.5783
2025-08-27 22:29:19,827 - INFO -   LR: 0.100000
2025-08-27 22:29:19,840 - INFO - 
Epoch: 92, lr = 0.1
2025-08-27 22:29:20,043 - INFO - Epoch: [92][0/391] Time 0.202 (0.202) Data 0.180 (0.180) Loss 0.4127 (0.4127) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:29:20,511 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:20,511 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:21,866 - INFO - Epoch: [92][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4285 (0.4037) Acc@1 86.719 (86.317) Acc@5 100.000 (99.443)
2025-08-27 22:29:23,427 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:23,427 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:23,634 - INFO - Epoch: [92][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2516 (0.4068) Acc@1 92.188 (86.050) Acc@5 100.000 (99.421)
2025-08-27 22:29:25,522 - INFO - Epoch: [92][300/391] Time 0.053 (0.019) Data 0.017 (0.004) Loss 0.3734 (0.4095) Acc@1 85.156 (85.808) Acc@5 100.000 (99.450)
2025-08-27 22:29:26,339 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:26,339 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:27,339 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.8412 (0.8412) Acc@1 74.219 (74.219) Acc@5 97.656 (97.656)
2025-08-27 22:29:28,184 - INFO - Epoch 92:
2025-08-27 22:29:28,184 - INFO -   Train: acc1: 85.7900 | acc5: 99.4480 | loss: 0.4125 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:28,184 - INFO -   Val:   acc1: 73.6500 | acc5: 98.5400 | loss: 0.8661
2025-08-27 22:29:28,185 - INFO -   LR: 0.100000
2025-08-27 22:29:28,197 - INFO - 
Epoch: 93, lr = 0.1
2025-08-27 22:29:28,372 - INFO - Epoch: [93][0/391] Time 0.173 (0.173) Data 0.151 (0.151) Loss 0.3631 (0.3631) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:29:30,180 - INFO - Epoch: [93][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.3122 (0.4169) Acc@1 89.844 (85.876) Acc@5 100.000 (99.551)
2025-08-27 22:29:30,454 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:30,454 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:32,020 - INFO - Epoch: [93][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3029 (0.4122) Acc@1 89.062 (85.794) Acc@5 100.000 (99.499)
2025-08-27 22:29:33,434 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:33,434 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:33,881 - INFO - Epoch: [93][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3900 (0.4132) Acc@1 84.375 (85.725) Acc@5 99.219 (99.450)
2025-08-27 22:29:35,598 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.7117 (0.7117) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-27 22:29:36,458 - INFO - Epoch 93:
2025-08-27 22:29:36,458 - INFO -   Train: acc1: 85.7120 | acc5: 99.4260 | loss: 0.4166 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:36,458 - INFO -   Val:   acc1: 75.7000 | acc5: 98.3800 | loss: 0.7663
2025-08-27 22:29:36,458 - INFO -   LR: 0.100000
2025-08-27 22:29:36,471 - INFO - 
Epoch: 94, lr = 0.1
2025-08-27 22:29:36,664 - INFO - Epoch: [94][0/391] Time 0.192 (0.192) Data 0.173 (0.173) Loss 0.4355 (0.4355) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:29:37,528 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:37,528 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:38,478 - INFO - Epoch: [94][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3522 (0.4047) Acc@1 88.281 (86.262) Acc@5 100.000 (99.397)
2025-08-27 22:29:40,242 - INFO - Epoch: [94][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4084 (0.4078) Acc@1 86.719 (86.151) Acc@5 100.000 (99.468)
2025-08-27 22:29:40,344 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:40,345 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:42,082 - INFO - Epoch: [94][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4813 (0.4101) Acc@1 83.594 (85.961) Acc@5 100.000 (99.458)
2025-08-27 22:29:43,413 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:43,414 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:43,954 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.6839 (0.6839) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 22:29:44,825 - INFO - Epoch 94:
2025-08-27 22:29:44,825 - INFO -   Train: acc1: 85.7540 | acc5: 99.4360 | loss: 0.4165 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:44,825 - INFO -   Val:   acc1: 76.3700 | acc5: 98.6600 | loss: 0.7170
2025-08-27 22:29:44,825 - INFO -   LR: 0.100000
2025-08-27 22:29:44,839 - INFO - 
Epoch: 95, lr = 0.1
2025-08-27 22:29:45,012 - INFO - Epoch: [95][0/391] Time 0.172 (0.172) Data 0.145 (0.145) Loss 0.3462 (0.3462) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:29:46,890 - INFO - Epoch: [95][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4552 (0.4035) Acc@1 83.594 (86.115) Acc@5 100.000 (99.373)
2025-08-27 22:29:47,498 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:47,498 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:48,684 - INFO - Epoch: [95][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4874 (0.4116) Acc@1 82.031 (85.871) Acc@5 100.000 (99.440)
2025-08-27 22:29:50,451 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:50,452 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:50,562 - INFO - Epoch: [95][300/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.3034 (0.4166) Acc@1 89.844 (85.621) Acc@5 100.000 (99.458)
2025-08-27 22:29:52,315 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5368 (0.5368) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:29:53,153 - INFO - Epoch 95:
2025-08-27 22:29:53,154 - INFO -   Train: acc1: 85.6400 | acc5: 99.4580 | loss: 0.4153 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:29:53,154 - INFO -   Val:   acc1: 77.8300 | acc5: 99.1300 | loss: 0.6371
2025-08-27 22:29:53,154 - INFO -   LR: 0.100000
2025-08-27 22:29:53,167 - INFO - 
Epoch: 96, lr = 0.1
2025-08-27 22:29:53,368 - INFO - Epoch: [96][0/391] Time 0.199 (0.199) Data 0.172 (0.172) Loss 0.5876 (0.5876) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 22:29:54,515 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:54,515 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:55,230 - INFO - Epoch: [96][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.3878 (0.4035) Acc@1 84.375 (85.876) Acc@5 99.219 (99.459)
2025-08-27 22:29:56,990 - INFO - Epoch: [96][200/391] Time 0.028 (0.019) Data 0.016 (0.003) Loss 0.5166 (0.4078) Acc@1 84.375 (85.743) Acc@5 99.219 (99.491)
2025-08-27 22:29:57,431 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:29:57,431 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:29:58,811 - INFO - Epoch: [96][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4169 (0.4170) Acc@1 83.594 (85.488) Acc@5 100.000 (99.437)
2025-08-27 22:30:00,361 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:00,361 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:00,635 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5272 (0.5272) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:30:01,453 - INFO - Epoch 96:
2025-08-27 22:30:01,453 - INFO -   Train: acc1: 85.5740 | acc5: 99.4420 | loss: 0.4166 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:01,453 - INFO -   Val:   acc1: 79.0600 | acc5: 99.1300 | loss: 0.6180
2025-08-27 22:30:01,453 - INFO -   LR: 0.100000
2025-08-27 22:30:01,556 - INFO - 
Epoch: 97, lr = 0.1
2025-08-27 22:30:01,748 - INFO - Epoch: [97][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.3614 (0.3614) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-27 22:30:03,581 - INFO - Epoch: [97][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3799 (0.4098) Acc@1 88.281 (86.069) Acc@5 100.000 (99.505)
2025-08-27 22:30:04,453 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:04,453 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:05,287 - INFO - Epoch: [97][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4417 (0.4142) Acc@1 85.938 (85.638) Acc@5 97.656 (99.487)
2025-08-27 22:30:07,058 - INFO - Epoch: [97][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3305 (0.4149) Acc@1 85.156 (85.629) Acc@5 100.000 (99.468)
2025-08-27 22:30:07,264 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:07,264 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:08,755 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5768 (0.5768) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 22:30:09,566 - INFO - Epoch 97:
2025-08-27 22:30:09,566 - INFO -   Train: acc1: 85.5860 | acc5: 99.4280 | loss: 0.4167 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:09,566 - INFO -   Val:   acc1: 79.8300 | acc5: 98.2100 | loss: 0.6418
2025-08-27 22:30:09,566 - INFO -   LR: 0.100000
2025-08-27 22:30:09,579 - INFO - 
Epoch: 98, lr = 0.1
2025-08-27 22:30:09,746 - INFO - Epoch: [98][0/391] Time 0.166 (0.166) Data 0.146 (0.146) Loss 0.4598 (0.4598) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 22:30:11,129 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:11,129 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:11,491 - INFO - Epoch: [98][100/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.3577 (0.4072) Acc@1 86.719 (85.930) Acc@5 100.000 (99.451)
2025-08-27 22:30:13,227 - INFO - Epoch: [98][200/391] Time 0.011 (0.018) Data 0.000 (0.004) Loss 0.4717 (0.4172) Acc@1 85.938 (85.592) Acc@5 99.219 (99.401)
2025-08-27 22:30:13,953 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:13,953 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:15,071 - INFO - Epoch: [98][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3721 (0.4179) Acc@1 88.281 (85.592) Acc@5 100.000 (99.416)
2025-08-27 22:30:16,762 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.4503 (0.4503) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-27 22:30:17,585 - INFO - Epoch 98:
2025-08-27 22:30:17,586 - INFO -   Train: acc1: 85.5640 | acc5: 99.4040 | loss: 0.4189 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:17,586 - INFO -   Val:   acc1: 84.2900 | acc5: 99.2800 | loss: 0.4606
2025-08-27 22:30:17,586 - INFO -   LR: 0.100000
2025-08-27 22:30:17,632 - INFO - Checkpoint saved: epoch=98, metric=84.2900
2025-08-27 22:30:17,663 - INFO - 
Epoch: 99, lr = 0.1
2025-08-27 22:30:17,830 - INFO - Epoch: [99][0/391] Time 0.165 (0.165) Data 0.141 (0.141) Loss 0.4587 (0.4587) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:30:18,023 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:18,023 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:19,559 - INFO - Epoch: [99][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4968 (0.4197) Acc@1 85.156 (85.450) Acc@5 98.438 (99.381)
2025-08-27 22:30:20,797 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:20,798 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:21,344 - INFO - Epoch: [99][200/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.2964 (0.4226) Acc@1 92.188 (85.405) Acc@5 98.438 (99.382)
2025-08-27 22:30:23,103 - INFO - Epoch: [99][300/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.3139 (0.4206) Acc@1 89.062 (85.507) Acc@5 99.219 (99.359)
2025-08-27 22:30:23,650 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:23,651 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:24,858 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6243 (0.6243) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:30:25,703 - INFO - Epoch 99:
2025-08-27 22:30:25,703 - INFO -   Train: acc1: 85.5820 | acc5: 99.3940 | loss: 0.4183 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:25,703 - INFO -   Val:   acc1: 80.0300 | acc5: 99.1200 | loss: 0.6184
2025-08-27 22:30:25,703 - INFO -   LR: 0.010000
2025-08-27 22:30:25,716 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-27 22:30:25,907 - INFO - Epoch: [100][0/391] Time 0.190 (0.190) Data 0.168 (0.168) Loss 0.3323 (0.3323) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:30:27,662 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:27,662 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:27,678 - INFO - Epoch: [100][100/391] Time 0.038 (0.019) Data 0.018 (0.005) Loss 0.2311 (0.3296) Acc@1 92.969 (88.475) Acc@5 100.000 (99.613)
2025-08-27 22:30:29,419 - INFO - Epoch: [100][200/391] Time 0.012 (0.018) Data 0.000 (0.004) Loss 0.3627 (0.3146) Acc@1 87.500 (89.202) Acc@5 100.000 (99.646)
2025-08-27 22:30:30,485 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:30,486 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:31,233 - INFO - Epoch: [100][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1864 (0.3056) Acc@1 93.750 (89.501) Acc@5 100.000 (99.689)
2025-08-27 22:30:32,924 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2561 (0.2561) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:30:33,730 - INFO - Epoch 100:
2025-08-27 22:30:33,730 - INFO -   Train: acc1: 89.7080 | acc5: 99.6620 | loss: 0.2992 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:33,730 - INFO -   Val:   acc1: 89.0300 | acc5: 99.5900 | loss: 0.3233
2025-08-27 22:30:33,730 - INFO -   LR: 0.010000
2025-08-27 22:30:33,775 - INFO - Checkpoint saved: epoch=100, metric=89.0300
2025-08-27 22:30:33,807 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-27 22:30:33,991 - INFO - Epoch: [101][0/391] Time 0.183 (0.183) Data 0.164 (0.164) Loss 0.3108 (0.3108) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-27 22:30:34,480 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:34,481 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:35,742 - INFO - Epoch: [101][100/391] Time 0.012 (0.019) Data 0.000 (0.005) Loss 0.1702 (0.2604) Acc@1 95.312 (91.391) Acc@5 100.000 (99.706)
2025-08-27 22:30:37,309 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:37,309 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:37,473 - INFO - Epoch: [101][200/391] Time 0.019 (0.018) Data 0.004 (0.003) Loss 0.2158 (0.2580) Acc@1 90.625 (91.410) Acc@5 100.000 (99.747)
2025-08-27 22:30:39,300 - INFO - Epoch: [101][300/391] Time 0.019 (0.018) Data 0.000 (0.003) Loss 0.3502 (0.2590) Acc@1 86.719 (91.240) Acc@5 100.000 (99.753)
2025-08-27 22:30:40,155 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:40,156 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:41,035 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2296 (0.2296) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:30:41,865 - INFO - Epoch 101:
2025-08-27 22:30:41,865 - INFO -   Train: acc1: 91.1540 | acc5: 99.7640 | loss: 0.2605 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:41,865 - INFO -   Val:   acc1: 88.9300 | acc5: 99.5900 | loss: 0.3221
2025-08-27 22:30:41,865 - INFO -   LR: 0.010000
2025-08-27 22:30:41,879 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-27 22:30:42,057 - INFO - Epoch: [102][0/391] Time 0.177 (0.177) Data 0.156 (0.156) Loss 0.2623 (0.2623) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:30:43,846 - INFO - Epoch: [102][100/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2925 (0.2551) Acc@1 90.625 (91.507) Acc@5 100.000 (99.776)
2025-08-27 22:30:44,157 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:44,157 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:45,622 - INFO - Epoch: [102][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1835 (0.2505) Acc@1 91.406 (91.612) Acc@5 100.000 (99.782)
2025-08-27 22:30:47,082 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:47,082 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:47,511 - INFO - Epoch: [102][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.2757 (0.2499) Acc@1 92.188 (91.585) Acc@5 100.000 (99.785)
2025-08-27 22:30:49,218 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2789 (0.2789) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:30:50,039 - INFO - Epoch 102:
2025-08-27 22:30:50,039 - INFO -   Train: acc1: 91.5920 | acc5: 99.7880 | loss: 0.2486 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:50,039 - INFO -   Val:   acc1: 89.0000 | acc5: 99.6700 | loss: 0.3138
2025-08-27 22:30:50,039 - INFO -   LR: 0.010000
2025-08-27 22:30:50,051 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-27 22:30:50,192 - INFO - Epoch: [103][0/391] Time 0.139 (0.139) Data 0.122 (0.122) Loss 0.2748 (0.2748) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:30:51,003 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:51,003 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:51,936 - INFO - Epoch: [103][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2663 (0.2313) Acc@1 92.188 (91.971) Acc@5 100.000 (99.814)
2025-08-27 22:30:53,688 - INFO - Epoch: [103][200/391] Time 0.024 (0.018) Data 0.014 (0.004) Loss 0.2542 (0.2334) Acc@1 91.406 (91.923) Acc@5 100.000 (99.817)
2025-08-27 22:30:53,799 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:53,799 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:55,477 - INFO - Epoch: [103][300/391] Time 0.040 (0.018) Data 0.022 (0.003) Loss 0.3734 (0.2336) Acc@1 87.500 (91.969) Acc@5 98.438 (99.808)
2025-08-27 22:30:56,656 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:30:56,656 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:30:57,252 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2746 (0.2746) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:30:58,075 - INFO - Epoch 103:
2025-08-27 22:30:58,075 - INFO -   Train: acc1: 91.9120 | acc5: 99.8200 | loss: 0.2351 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:30:58,075 - INFO -   Val:   acc1: 89.0100 | acc5: 99.6400 | loss: 0.3190
2025-08-27 22:30:58,075 - INFO -   LR: 0.010000
2025-08-27 22:30:58,090 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-27 22:30:58,284 - INFO - Epoch: [104][0/391] Time 0.194 (0.194) Data 0.174 (0.174) Loss 0.2630 (0.2630) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:31:00,186 - INFO - Epoch: [104][100/391] Time 0.013 (0.021) Data 0.000 (0.008) Loss 0.2524 (0.2320) Acc@1 92.188 (91.894) Acc@5 100.000 (99.861)
2025-08-27 22:31:00,916 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:00,916 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:02,058 - INFO - Epoch: [104][200/391] Time 0.017 (0.020) Data 0.000 (0.005) Loss 0.1960 (0.2328) Acc@1 93.750 (91.927) Acc@5 99.219 (99.810)
2025-08-27 22:31:03,735 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:03,735 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:03,827 - INFO - Epoch: [104][300/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.1950 (0.2318) Acc@1 92.969 (91.995) Acc@5 100.000 (99.798)
2025-08-27 22:31:05,614 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2825 (0.2825) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:31:06,452 - INFO - Epoch 104:
2025-08-27 22:31:06,452 - INFO -   Train: acc1: 91.9120 | acc5: 99.8040 | loss: 0.2337 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:06,452 - INFO -   Val:   acc1: 89.5200 | acc5: 99.6500 | loss: 0.3112
2025-08-27 22:31:06,452 - INFO -   LR: 0.010000
2025-08-27 22:31:06,501 - INFO - Checkpoint saved: epoch=104, metric=89.5200
2025-08-27 22:31:06,533 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-27 22:31:06,723 - INFO - Epoch: [105][0/391] Time 0.189 (0.189) Data 0.171 (0.171) Loss 0.1899 (0.1899) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:31:07,840 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:07,840 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:08,489 - INFO - Epoch: [105][100/391] Time 0.024 (0.019) Data 0.013 (0.004) Loss 0.2361 (0.2162) Acc@1 89.062 (92.760) Acc@5 100.000 (99.807)
2025-08-27 22:31:10,280 - INFO - Epoch: [105][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1642 (0.2204) Acc@1 94.531 (92.487) Acc@5 100.000 (99.841)
2025-08-27 22:31:10,745 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:10,745 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:12,123 - INFO - Epoch: [105][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2158 (0.2246) Acc@1 93.750 (92.320) Acc@5 100.000 (99.824)
2025-08-27 22:31:13,716 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:13,716 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:13,967 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2704 (0.2704) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:31:14,806 - INFO - Epoch 105:
2025-08-27 22:31:14,806 - INFO -   Train: acc1: 92.2520 | acc5: 99.8100 | loss: 0.2254 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:14,806 - INFO -   Val:   acc1: 89.4600 | acc5: 99.6800 | loss: 0.3178
2025-08-27 22:31:14,806 - INFO -   LR: 0.010000
2025-08-27 22:31:14,819 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-27 22:31:15,013 - INFO - Epoch: [106][0/391] Time 0.192 (0.192) Data 0.167 (0.167) Loss 0.1414 (0.1414) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:31:16,772 - INFO - Epoch: [106][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.1552 (0.2182) Acc@1 96.094 (92.528) Acc@5 100.000 (99.799)
2025-08-27 22:31:17,784 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:17,784 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:18,622 - INFO - Epoch: [106][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2570 (0.2176) Acc@1 89.844 (92.549) Acc@5 100.000 (99.817)
2025-08-27 22:31:20,437 - INFO - Epoch: [106][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3872 (0.2208) Acc@1 86.719 (92.411) Acc@5 100.000 (99.818)
2025-08-27 22:31:20,682 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:20,682 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:22,209 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2466 (0.2466) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:31:23,039 - INFO - Epoch 106:
2025-08-27 22:31:23,039 - INFO -   Train: acc1: 92.2660 | acc5: 99.8200 | loss: 0.2241 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:23,039 - INFO -   Val:   acc1: 89.4100 | acc5: 99.7100 | loss: 0.3135
2025-08-27 22:31:23,040 - INFO -   LR: 0.010000
2025-08-27 22:31:23,054 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-27 22:31:23,210 - INFO - Epoch: [107][0/391] Time 0.155 (0.155) Data 0.138 (0.138) Loss 0.1323 (0.1323) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:31:24,735 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:24,736 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:25,044 - INFO - Epoch: [107][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1454 (0.2155) Acc@1 93.750 (92.443) Acc@5 100.000 (99.814)
2025-08-27 22:31:26,864 - INFO - Epoch: [107][200/391] Time 0.051 (0.019) Data 0.038 (0.003) Loss 0.2954 (0.2199) Acc@1 87.500 (92.277) Acc@5 100.000 (99.825)
2025-08-27 22:31:27,696 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:27,696 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:28,714 - INFO - Epoch: [107][300/391] Time 0.019 (0.019) Data 0.004 (0.003) Loss 0.2994 (0.2205) Acc@1 90.625 (92.299) Acc@5 99.219 (99.821)
2025-08-27 22:31:30,405 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.2510 (0.2510) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:31:31,243 - INFO - Epoch 107:
2025-08-27 22:31:31,243 - INFO -   Train: acc1: 92.2260 | acc5: 99.8160 | loss: 0.2229 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:31,243 - INFO -   Val:   acc1: 89.5700 | acc5: 99.7100 | loss: 0.3150
2025-08-27 22:31:31,243 - INFO -   LR: 0.010000
2025-08-27 22:31:31,290 - INFO - Checkpoint saved: epoch=107, metric=89.5700
2025-08-27 22:31:31,321 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-27 22:31:31,511 - INFO - Epoch: [108][0/391] Time 0.188 (0.188) Data 0.172 (0.172) Loss 0.1250 (0.1250) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:31:31,702 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:31,703 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:33,339 - INFO - Epoch: [108][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.2316 (0.2122) Acc@1 93.750 (92.814) Acc@5 99.219 (99.884)
2025-08-27 22:31:34,691 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:34,691 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:35,181 - INFO - Epoch: [108][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2574 (0.2140) Acc@1 91.406 (92.763) Acc@5 100.000 (99.872)
2025-08-27 22:31:37,062 - INFO - Epoch: [108][300/391] Time 0.046 (0.019) Data 0.030 (0.004) Loss 0.1647 (0.2150) Acc@1 95.312 (92.652) Acc@5 100.000 (99.857)
2025-08-27 22:31:37,670 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:37,670 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:38,824 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2972 (0.2972) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:31:39,648 - INFO - Epoch 108:
2025-08-27 22:31:39,648 - INFO -   Train: acc1: 92.6740 | acc5: 99.8420 | loss: 0.2157 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:39,648 - INFO -   Val:   acc1: 89.5700 | acc5: 99.7200 | loss: 0.3102
2025-08-27 22:31:39,648 - INFO -   LR: 0.010000
2025-08-27 22:31:39,664 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-27 22:31:39,858 - INFO - Epoch: [109][0/391] Time 0.193 (0.193) Data 0.173 (0.173) Loss 0.1818 (0.1818) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:31:41,644 - INFO - Epoch: [109][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2116 (0.2094) Acc@1 92.969 (92.528) Acc@5 100.000 (99.845)
2025-08-27 22:31:41,649 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:41,649 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:43,528 - INFO - Epoch: [109][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1904 (0.2108) Acc@1 92.188 (92.537) Acc@5 99.219 (99.841)
2025-08-27 22:31:44,595 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:44,595 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:45,394 - INFO - Epoch: [109][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2562 (0.2124) Acc@1 90.625 (92.561) Acc@5 100.000 (99.842)
2025-08-27 22:31:47,175 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2521 (0.2521) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:31:48,027 - INFO - Epoch 109:
2025-08-27 22:31:48,027 - INFO -   Train: acc1: 92.5100 | acc5: 99.8460 | loss: 0.2150 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:48,027 - INFO -   Val:   acc1: 89.5500 | acc5: 99.7400 | loss: 0.3178
2025-08-27 22:31:48,027 - INFO -   LR: 0.010000
2025-08-27 22:31:48,040 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-27 22:31:48,246 - INFO - Epoch: [110][0/391] Time 0.205 (0.205) Data 0.176 (0.176) Loss 0.1992 (0.1992) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:31:48,753 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:48,754 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:50,073 - INFO - Epoch: [110][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2639 (0.2027) Acc@1 92.969 (93.309) Acc@5 100.000 (99.783)
2025-08-27 22:31:51,756 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:51,757 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:51,962 - INFO - Epoch: [110][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1870 (0.2082) Acc@1 93.750 (92.903) Acc@5 100.000 (99.848)
2025-08-27 22:31:53,730 - INFO - Epoch: [110][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2106 (0.2111) Acc@1 92.969 (92.735) Acc@5 100.000 (99.834)
2025-08-27 22:31:54,666 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:54,666 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:31:55,548 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3209 (0.3209) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:31:56,369 - INFO - Epoch 110:
2025-08-27 22:31:56,369 - INFO -   Train: acc1: 92.7060 | acc5: 99.8320 | loss: 0.2115 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:31:56,369 - INFO -   Val:   acc1: 89.4000 | acc5: 99.6300 | loss: 0.3204
2025-08-27 22:31:56,369 - INFO -   LR: 0.010000
2025-08-27 22:31:56,418 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-27 22:31:56,608 - INFO - Epoch: [111][0/391] Time 0.189 (0.189) Data 0.172 (0.172) Loss 0.1675 (0.1675) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:31:58,413 - INFO - Epoch: [111][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2096 (0.2008) Acc@1 92.188 (93.170) Acc@5 100.000 (99.861)
2025-08-27 22:31:58,766 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:31:58,766 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:00,221 - INFO - Epoch: [111][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2064 (0.2060) Acc@1 92.969 (92.992) Acc@5 100.000 (99.883)
2025-08-27 22:32:01,641 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:01,641 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:02,070 - INFO - Epoch: [111][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2232 (0.2095) Acc@1 91.406 (92.761) Acc@5 99.219 (99.860)
2025-08-27 22:32:03,873 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2777 (0.2777) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:32:04,694 - INFO - Epoch 111:
2025-08-27 22:32:04,695 - INFO -   Train: acc1: 92.7960 | acc5: 99.8580 | loss: 0.2089 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:04,695 - INFO -   Val:   acc1: 89.1700 | acc5: 99.6800 | loss: 0.3295
2025-08-27 22:32:04,695 - INFO -   LR: 0.010000
2025-08-27 22:32:06,876 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-27 22:32:07,077 - INFO - Epoch: [112][0/391] Time 0.200 (0.200) Data 0.157 (0.157) Loss 0.2046 (0.2046) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:32:07,926 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:07,926 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:08,906 - INFO - Epoch: [112][100/391] Time 0.011 (0.020) Data 0.001 (0.004) Loss 0.2462 (0.2025) Acc@1 90.625 (93.216) Acc@5 99.219 (99.876)
2025-08-27 22:32:10,794 - INFO - Epoch: [112][200/391] Time 0.027 (0.019) Data 0.010 (0.003) Loss 0.2334 (0.2039) Acc@1 91.406 (93.019) Acc@5 99.219 (99.876)
2025-08-27 22:32:10,950 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:10,950 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:12,661 - INFO - Epoch: [112][300/391] Time 0.032 (0.019) Data 0.013 (0.003) Loss 0.1319 (0.2033) Acc@1 96.094 (93.106) Acc@5 100.000 (99.873)
2025-08-27 22:32:13,874 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:13,874 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:14,399 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2827 (0.2827) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:32:15,228 - INFO - Epoch 112:
2025-08-27 22:32:15,228 - INFO -   Train: acc1: 92.8900 | acc5: 99.8500 | loss: 0.2080 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:15,228 - INFO -   Val:   acc1: 88.8800 | acc5: 99.7400 | loss: 0.3378
2025-08-27 22:32:15,228 - INFO -   LR: 0.010000
2025-08-27 22:32:15,243 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-27 22:32:15,420 - INFO - Epoch: [113][0/391] Time 0.176 (0.176) Data 0.145 (0.145) Loss 0.2134 (0.2134) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:32:17,257 - INFO - Epoch: [113][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.1954 (0.2047) Acc@1 93.750 (92.946) Acc@5 100.000 (99.830)
2025-08-27 22:32:17,906 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:17,906 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:19,090 - INFO - Epoch: [113][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1392 (0.2032) Acc@1 95.312 (92.980) Acc@5 100.000 (99.841)
2025-08-27 22:32:20,955 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:20,956 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:21,047 - INFO - Epoch: [113][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2591 (0.2049) Acc@1 89.062 (92.927) Acc@5 100.000 (99.836)
2025-08-27 22:32:22,812 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2969 (0.2969) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:32:23,664 - INFO - Epoch 113:
2025-08-27 22:32:23,665 - INFO -   Train: acc1: 92.8460 | acc5: 99.8380 | loss: 0.2070 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:23,665 - INFO -   Val:   acc1: 89.6000 | acc5: 99.6900 | loss: 0.3142
2025-08-27 22:32:23,665 - INFO -   LR: 0.010000
2025-08-27 22:32:23,712 - INFO - Checkpoint saved: epoch=113, metric=89.6000
2025-08-27 22:32:23,743 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-27 22:32:23,941 - INFO - Epoch: [114][0/391] Time 0.196 (0.196) Data 0.169 (0.169) Loss 0.1051 (0.1051) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:32:25,147 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:25,147 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:25,824 - INFO - Epoch: [114][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.2413 (0.2023) Acc@1 89.062 (93.031) Acc@5 100.000 (99.892)
2025-08-27 22:32:27,672 - INFO - Epoch: [114][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2852 (0.2075) Acc@1 85.938 (92.883) Acc@5 99.219 (99.841)
2025-08-27 22:32:28,143 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:28,143 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:29,449 - INFO - Epoch: [114][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1032 (0.2065) Acc@1 97.656 (92.919) Acc@5 100.000 (99.862)
2025-08-27 22:32:31,103 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:31,104 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:31,327 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3383 (0.3383) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:32:32,153 - INFO - Epoch 114:
2025-08-27 22:32:32,153 - INFO -   Train: acc1: 92.7600 | acc5: 99.8640 | loss: 0.2101 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:32,153 - INFO -   Val:   acc1: 89.3300 | acc5: 99.7500 | loss: 0.3255
2025-08-27 22:32:32,153 - INFO -   LR: 0.010000
2025-08-27 22:32:32,167 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-27 22:32:32,363 - INFO - Epoch: [115][0/391] Time 0.195 (0.195) Data 0.167 (0.167) Loss 0.2070 (0.2070) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-27 22:32:34,191 - INFO - Epoch: [115][100/391] Time 0.017 (0.020) Data 0.000 (0.005) Loss 0.2816 (0.1948) Acc@1 91.406 (93.464) Acc@5 100.000 (99.907)
2025-08-27 22:32:35,181 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:35,181 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:35,977 - INFO - Epoch: [115][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2455 (0.1946) Acc@1 91.406 (93.435) Acc@5 100.000 (99.911)
2025-08-27 22:32:37,821 - INFO - Epoch: [115][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2409 (0.1987) Acc@1 89.844 (93.322) Acc@5 100.000 (99.878)
2025-08-27 22:32:38,084 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:38,084 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:39,634 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.3066 (0.3066) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:32:40,478 - INFO - Epoch 115:
2025-08-27 22:32:40,478 - INFO -   Train: acc1: 93.1560 | acc5: 99.8640 | loss: 0.2029 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:40,478 - INFO -   Val:   acc1: 89.2700 | acc5: 99.6800 | loss: 0.3251
2025-08-27 22:32:40,478 - INFO -   LR: 0.010000
2025-08-27 22:32:40,493 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-27 22:32:40,688 - INFO - Epoch: [116][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.2958 (0.2958) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:32:42,208 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:42,208 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:42,496 - INFO - Epoch: [116][100/391] Time 0.026 (0.020) Data 0.000 (0.005) Loss 0.2080 (0.2035) Acc@1 92.188 (93.000) Acc@5 100.000 (99.892)
2025-08-27 22:32:44,327 - INFO - Epoch: [116][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.2381 (0.2064) Acc@1 90.625 (92.953) Acc@5 100.000 (99.856)
2025-08-27 22:32:45,031 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:45,031 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:46,107 - INFO - Epoch: [116][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2128 (0.2066) Acc@1 89.844 (92.938) Acc@5 100.000 (99.839)
2025-08-27 22:32:47,882 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2617 (0.2617) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:32:48,730 - INFO - Epoch 116:
2025-08-27 22:32:48,730 - INFO -   Train: acc1: 92.8660 | acc5: 99.8360 | loss: 0.2079 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:48,730 - INFO -   Val:   acc1: 89.1900 | acc5: 99.6900 | loss: 0.3214
2025-08-27 22:32:48,730 - INFO -   LR: 0.010000
2025-08-27 22:32:48,744 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-27 22:32:48,937 - INFO - Epoch: [117][0/391] Time 0.193 (0.193) Data 0.171 (0.171) Loss 0.2484 (0.2484) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:32:49,176 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:49,176 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:50,748 - INFO - Epoch: [117][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.2172 (0.2004) Acc@1 93.750 (93.162) Acc@5 100.000 (99.768)
2025-08-27 22:32:52,080 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:52,080 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:52,636 - INFO - Epoch: [117][200/391] Time 0.021 (0.019) Data 0.002 (0.003) Loss 0.2298 (0.2039) Acc@1 91.406 (92.980) Acc@5 99.219 (99.817)
2025-08-27 22:32:54,408 - INFO - Epoch: [117][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2651 (0.2049) Acc@1 89.062 (92.883) Acc@5 100.000 (99.821)
2025-08-27 22:32:55,022 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:55,022 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:32:56,149 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2529 (0.2529) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:32:56,988 - INFO - Epoch 117:
2025-08-27 22:32:56,988 - INFO -   Train: acc1: 92.8940 | acc5: 99.8340 | loss: 0.2056 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:32:56,988 - INFO -   Val:   acc1: 89.4600 | acc5: 99.7100 | loss: 0.3197
2025-08-27 22:32:56,988 - INFO -   LR: 0.010000
2025-08-27 22:32:57,001 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-27 22:32:57,187 - INFO - Epoch: [118][0/391] Time 0.185 (0.185) Data 0.159 (0.159) Loss 0.1978 (0.1978) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:32:59,053 - INFO - Epoch: [118][100/391] Time 0.035 (0.020) Data 0.019 (0.006) Loss 0.2436 (0.2010) Acc@1 89.062 (93.131) Acc@5 100.000 (99.876)
2025-08-27 22:32:59,086 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:32:59,086 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:00,905 - INFO - Epoch: [118][200/391] Time 0.018 (0.019) Data 0.002 (0.004) Loss 0.1676 (0.2037) Acc@1 95.312 (92.953) Acc@5 100.000 (99.868)
2025-08-27 22:33:02,012 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:02,013 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:02,744 - INFO - Epoch: [118][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2261 (0.2032) Acc@1 90.625 (92.930) Acc@5 100.000 (99.873)
2025-08-27 22:33:04,487 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2435 (0.2435) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:33:05,298 - INFO - Epoch 118:
2025-08-27 22:33:05,298 - INFO -   Train: acc1: 92.8580 | acc5: 99.8460 | loss: 0.2063 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:05,298 - INFO -   Val:   acc1: 88.9700 | acc5: 99.6600 | loss: 0.3259
2025-08-27 22:33:05,298 - INFO -   LR: 0.010000
2025-08-27 22:33:05,313 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-27 22:33:05,496 - INFO - Epoch: [119][0/391] Time 0.181 (0.181) Data 0.146 (0.146) Loss 0.1867 (0.1867) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:33:06,048 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:06,049 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:07,279 - INFO - Epoch: [119][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1013 (0.1959) Acc@1 97.656 (93.216) Acc@5 100.000 (99.868)
2025-08-27 22:33:08,866 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:08,874 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:09,086 - INFO - Epoch: [119][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2047 (0.1992) Acc@1 92.969 (93.148) Acc@5 100.000 (99.876)
2025-08-27 22:33:10,875 - INFO - Epoch: [119][300/391] Time 0.016 (0.018) Data 0.005 (0.003) Loss 0.2180 (0.1999) Acc@1 92.969 (93.163) Acc@5 100.000 (99.875)
2025-08-27 22:33:11,823 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:11,823 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:12,702 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.3123 (0.3123) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:33:13,581 - INFO - Epoch 119:
2025-08-27 22:33:13,582 - INFO -   Train: acc1: 93.0560 | acc5: 99.8640 | loss: 0.2018 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:13,582 - INFO -   Val:   acc1: 89.1800 | acc5: 99.6600 | loss: 0.3335
2025-08-27 22:33:13,582 - INFO -   LR: 0.010000
2025-08-27 22:33:13,597 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-27 22:33:13,789 - INFO - Epoch: [120][0/391] Time 0.191 (0.191) Data 0.169 (0.169) Loss 0.1816 (0.1816) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:33:15,579 - INFO - Epoch: [120][100/391] Time 0.020 (0.020) Data 0.002 (0.004) Loss 0.2446 (0.2006) Acc@1 93.750 (93.077) Acc@5 100.000 (99.884)
2025-08-27 22:33:15,924 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:15,925 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:17,398 - INFO - Epoch: [120][200/391] Time 0.032 (0.019) Data 0.001 (0.003) Loss 0.1564 (0.2040) Acc@1 94.531 (92.992) Acc@5 100.000 (99.880)
2025-08-27 22:33:18,801 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:18,801 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:19,126 - INFO - Epoch: [120][300/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.1846 (0.2044) Acc@1 94.531 (92.945) Acc@5 100.000 (99.881)
2025-08-27 22:33:20,891 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3244 (0.3244) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:33:21,749 - INFO - Epoch 120:
2025-08-27 22:33:21,750 - INFO -   Train: acc1: 92.8420 | acc5: 99.8680 | loss: 0.2070 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:21,750 - INFO -   Val:   acc1: 88.7800 | acc5: 99.5700 | loss: 0.3382
2025-08-27 22:33:21,750 - INFO -   LR: 0.010000
2025-08-27 22:33:21,796 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-27 22:33:21,971 - INFO - Epoch: [121][0/391] Time 0.174 (0.174) Data 0.157 (0.157) Loss 0.2519 (0.2519) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:33:22,778 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:22,779 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:23,682 - INFO - Epoch: [121][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1347 (0.1980) Acc@1 92.969 (93.069) Acc@5 100.000 (99.868)
2025-08-27 22:33:25,504 - INFO - Epoch: [121][200/391] Time 0.036 (0.018) Data 0.016 (0.003) Loss 0.2074 (0.2015) Acc@1 92.188 (93.058) Acc@5 99.219 (99.860)
2025-08-27 22:33:25,645 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:25,645 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:27,288 - INFO - Epoch: [121][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3400 (0.2058) Acc@1 90.625 (92.823) Acc@5 100.000 (99.855)
2025-08-27 22:33:28,509 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:28,509 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:29,056 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3205 (0.3205) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:33:29,940 - INFO - Epoch 121:
2025-08-27 22:33:29,940 - INFO -   Train: acc1: 92.8400 | acc5: 99.8620 | loss: 0.2060 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:29,940 - INFO -   Val:   acc1: 89.1500 | acc5: 99.7400 | loss: 0.3256
2025-08-27 22:33:29,941 - INFO -   LR: 0.010000
2025-08-27 22:33:29,956 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-27 22:33:30,164 - INFO - Epoch: [122][0/391] Time 0.206 (0.206) Data 0.162 (0.162) Loss 0.1877 (0.1877) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:33:31,907 - INFO - Epoch: [122][100/391] Time 0.021 (0.019) Data 0.009 (0.005) Loss 0.3285 (0.1976) Acc@1 87.500 (93.108) Acc@5 100.000 (99.845)
2025-08-27 22:33:32,573 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:32,574 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:33,763 - INFO - Epoch: [122][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2268 (0.2051) Acc@1 93.750 (92.883) Acc@5 99.219 (99.860)
2025-08-27 22:33:35,558 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:35,558 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:35,619 - INFO - Epoch: [122][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2722 (0.2039) Acc@1 91.406 (92.891) Acc@5 100.000 (99.868)
2025-08-27 22:33:37,392 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2875 (0.2875) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:33:38,261 - INFO - Epoch 122:
2025-08-27 22:33:38,262 - INFO -   Train: acc1: 92.7980 | acc5: 99.8640 | loss: 0.2069 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:38,262 - INFO -   Val:   acc1: 89.4300 | acc5: 99.7000 | loss: 0.3216
2025-08-27 22:33:38,262 - INFO -   LR: 0.010000
2025-08-27 22:33:38,277 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-27 22:33:38,468 - INFO - Epoch: [123][0/391] Time 0.190 (0.190) Data 0.174 (0.174) Loss 0.2008 (0.2008) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:33:39,677 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:39,677 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:40,303 - INFO - Epoch: [123][100/391] Time 0.041 (0.020) Data 0.012 (0.004) Loss 0.1428 (0.2098) Acc@1 96.094 (92.791) Acc@5 100.000 (99.853)
2025-08-27 22:33:42,120 - INFO - Epoch: [123][200/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.1902 (0.2026) Acc@1 95.312 (93.000) Acc@5 100.000 (99.868)
2025-08-27 22:33:42,592 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:42,592 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:43,978 - INFO - Epoch: [123][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2198 (0.2031) Acc@1 92.969 (92.938) Acc@5 100.000 (99.873)
2025-08-27 22:33:45,629 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:45,630 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:45,851 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3152 (0.3152) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:33:46,699 - INFO - Epoch 123:
2025-08-27 22:33:46,699 - INFO -   Train: acc1: 92.8700 | acc5: 99.8780 | loss: 0.2054 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:46,700 - INFO -   Val:   acc1: 89.1300 | acc5: 99.7000 | loss: 0.3321
2025-08-27 22:33:46,700 - INFO -   LR: 0.010000
2025-08-27 22:33:46,714 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-27 22:33:46,899 - INFO - Epoch: [124][0/391] Time 0.184 (0.184) Data 0.164 (0.164) Loss 0.1831 (0.1831) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:33:48,701 - INFO - Epoch: [124][100/391] Time 0.033 (0.020) Data 0.022 (0.004) Loss 0.3050 (0.1938) Acc@1 89.062 (93.278) Acc@5 100.000 (99.884)
2025-08-27 22:33:49,704 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:49,704 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:50,499 - INFO - Epoch: [124][200/391] Time 0.032 (0.019) Data 0.000 (0.003) Loss 0.1515 (0.2009) Acc@1 96.094 (92.899) Acc@5 100.000 (99.883)
2025-08-27 22:33:52,374 - INFO - Epoch: [124][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2729 (0.2047) Acc@1 91.406 (92.878) Acc@5 99.219 (99.868)
2025-08-27 22:33:52,616 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:52,616 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:54,162 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2823 (0.2823) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:33:55,019 - INFO - Epoch 124:
2025-08-27 22:33:55,019 - INFO -   Train: acc1: 92.8120 | acc5: 99.8580 | loss: 0.2073 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:33:55,019 - INFO -   Val:   acc1: 88.9700 | acc5: 99.7200 | loss: 0.3288
2025-08-27 22:33:55,019 - INFO -   LR: 0.010000
2025-08-27 22:33:55,034 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-27 22:33:55,201 - INFO - Epoch: [125][0/391] Time 0.166 (0.166) Data 0.151 (0.151) Loss 0.2113 (0.2113) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:33:56,713 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:56,713 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:33:57,018 - INFO - Epoch: [125][100/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.2062 (0.1978) Acc@1 90.625 (93.309) Acc@5 100.000 (99.861)
2025-08-27 22:33:58,783 - INFO - Epoch: [125][200/391] Time 0.024 (0.019) Data 0.013 (0.003) Loss 0.1334 (0.2006) Acc@1 96.875 (93.194) Acc@5 100.000 (99.876)
2025-08-27 22:33:59,584 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:33:59,585 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:00,574 - INFO - Epoch: [125][300/391] Time 0.024 (0.018) Data 0.013 (0.003) Loss 0.1621 (0.2019) Acc@1 93.750 (93.036) Acc@5 100.000 (99.873)
2025-08-27 22:34:02,340 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3115 (0.3115) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:34:03,186 - INFO - Epoch 125:
2025-08-27 22:34:03,187 - INFO -   Train: acc1: 92.9540 | acc5: 99.8760 | loss: 0.2043 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:03,187 - INFO -   Val:   acc1: 88.4000 | acc5: 99.6400 | loss: 0.3544
2025-08-27 22:34:03,187 - INFO -   LR: 0.010000
2025-08-27 22:34:03,202 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-27 22:34:03,393 - INFO - Epoch: [126][0/391] Time 0.190 (0.190) Data 0.172 (0.172) Loss 0.2560 (0.2560) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:34:03,600 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:03,600 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:05,165 - INFO - Epoch: [126][100/391] Time 0.016 (0.019) Data 0.004 (0.005) Loss 0.2694 (0.2022) Acc@1 90.625 (92.922) Acc@5 100.000 (99.899)
2025-08-27 22:34:06,530 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:06,530 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:06,997 - INFO - Epoch: [126][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2108 (0.2075) Acc@1 92.969 (92.930) Acc@5 99.219 (99.848)
2025-08-27 22:34:08,776 - INFO - Epoch: [126][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.2053 (0.2066) Acc@1 92.969 (92.860) Acc@5 100.000 (99.844)
2025-08-27 22:34:09,364 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:09,365 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:10,570 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2830 (0.2830) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:34:11,471 - INFO - Epoch 126:
2025-08-27 22:34:11,472 - INFO -   Train: acc1: 92.8360 | acc5: 99.8500 | loss: 0.2074 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:11,472 - INFO -   Val:   acc1: 88.8600 | acc5: 99.6500 | loss: 0.3496
2025-08-27 22:34:11,472 - INFO -   LR: 0.010000
2025-08-27 22:34:11,486 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-27 22:34:11,675 - INFO - Epoch: [127][0/391] Time 0.188 (0.188) Data 0.169 (0.169) Loss 0.1189 (0.1189) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:34:13,419 - INFO - Epoch: [127][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3202 (0.2058) Acc@1 89.844 (92.775) Acc@5 100.000 (99.868)
2025-08-27 22:34:13,468 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:13,468 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:15,284 - INFO - Epoch: [127][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.2807 (0.2053) Acc@1 92.188 (92.840) Acc@5 100.000 (99.883)
2025-08-27 22:34:16,541 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:16,541 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:17,308 - INFO - Epoch: [127][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.2050 (0.2034) Acc@1 92.969 (92.969) Acc@5 100.000 (99.881)
2025-08-27 22:34:19,131 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3306 (0.3306) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:34:19,992 - INFO - Epoch 127:
2025-08-27 22:34:19,992 - INFO -   Train: acc1: 92.8480 | acc5: 99.8760 | loss: 0.2071 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:19,992 - INFO -   Val:   acc1: 88.2100 | acc5: 99.6200 | loss: 0.3643
2025-08-27 22:34:19,992 - INFO -   LR: 0.010000
2025-08-27 22:34:20,046 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-27 22:34:20,248 - INFO - Epoch: [128][0/391] Time 0.201 (0.201) Data 0.165 (0.165) Loss 0.2078 (0.2078) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:34:20,905 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:20,905 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:22,147 - INFO - Epoch: [128][100/391] Time 0.041 (0.021) Data 0.030 (0.004) Loss 0.1716 (0.1962) Acc@1 95.312 (93.294) Acc@5 100.000 (99.892)
2025-08-27 22:34:23,798 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:23,798 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:23,986 - INFO - Epoch: [128][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1702 (0.2012) Acc@1 92.969 (93.128) Acc@5 100.000 (99.860)
2025-08-27 22:34:25,920 - INFO - Epoch: [128][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1933 (0.2066) Acc@1 92.969 (92.912) Acc@5 100.000 (99.862)
2025-08-27 22:34:26,890 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:26,890 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:27,735 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3422 (0.3422) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:34:28,585 - INFO - Epoch 128:
2025-08-27 22:34:28,585 - INFO -   Train: acc1: 92.8620 | acc5: 99.8520 | loss: 0.2076 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:28,585 - INFO -   Val:   acc1: 88.4400 | acc5: 99.6800 | loss: 0.3533
2025-08-27 22:34:28,585 - INFO -   LR: 0.010000
2025-08-27 22:34:28,602 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-27 22:34:28,808 - INFO - Epoch: [129][0/391] Time 0.206 (0.206) Data 0.182 (0.182) Loss 0.1553 (0.1553) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:34:30,596 - INFO - Epoch: [129][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.1559 (0.2002) Acc@1 94.531 (93.147) Acc@5 100.000 (99.861)
2025-08-27 22:34:30,995 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:30,995 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:32,418 - INFO - Epoch: [129][200/391] Time 0.036 (0.019) Data 0.021 (0.003) Loss 0.1728 (0.2015) Acc@1 94.531 (92.988) Acc@5 100.000 (99.864)
2025-08-27 22:34:33,923 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:33,924 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:34,285 - INFO - Epoch: [129][300/391] Time 0.030 (0.019) Data 0.009 (0.003) Loss 0.1727 (0.2029) Acc@1 92.969 (92.974) Acc@5 100.000 (99.852)
2025-08-27 22:34:36,157 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2352 (0.2352) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:34:37,053 - INFO - Epoch 129:
2025-08-27 22:34:37,054 - INFO -   Train: acc1: 92.7500 | acc5: 99.8540 | loss: 0.2083 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:37,054 - INFO -   Val:   acc1: 88.8400 | acc5: 99.6400 | loss: 0.3455
2025-08-27 22:34:37,054 - INFO -   LR: 0.010000
2025-08-27 22:34:37,068 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-27 22:34:37,259 - INFO - Epoch: [130][0/391] Time 0.189 (0.189) Data 0.170 (0.170) Loss 0.2010 (0.2010) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:34:38,163 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:38,163 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:39,122 - INFO - Epoch: [130][100/391] Time 0.023 (0.020) Data 0.002 (0.004) Loss 0.2588 (0.1987) Acc@1 88.281 (92.992) Acc@5 98.438 (99.876)
2025-08-27 22:34:40,905 - INFO - Epoch: [130][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1550 (0.2054) Acc@1 94.531 (93.050) Acc@5 100.000 (99.872)
2025-08-27 22:34:41,065 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:41,066 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:42,750 - INFO - Epoch: [130][300/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.2923 (0.2078) Acc@1 90.625 (92.922) Acc@5 100.000 (99.865)
2025-08-27 22:34:43,960 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:43,960 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:44,454 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3183 (0.3183) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:34:45,294 - INFO - Epoch 130:
2025-08-27 22:34:45,294 - INFO -   Train: acc1: 92.8440 | acc5: 99.8540 | loss: 0.2089 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:45,294 - INFO -   Val:   acc1: 88.8000 | acc5: 99.6800 | loss: 0.3399
2025-08-27 22:34:45,295 - INFO -   LR: 0.010000
2025-08-27 22:34:45,343 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-27 22:34:45,538 - INFO - Epoch: [131][0/391] Time 0.194 (0.194) Data 0.176 (0.176) Loss 0.1526 (0.1526) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:34:47,298 - INFO - Epoch: [131][100/391] Time 0.025 (0.019) Data 0.015 (0.005) Loss 0.1986 (0.1997) Acc@1 94.531 (93.147) Acc@5 100.000 (99.868)
2025-08-27 22:34:48,036 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:48,037 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:49,157 - INFO - Epoch: [131][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1591 (0.2052) Acc@1 96.094 (92.848) Acc@5 100.000 (99.864)
2025-08-27 22:34:50,963 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:50,964 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:50,995 - INFO - Epoch: [131][300/391] Time 0.021 (0.019) Data 0.001 (0.003) Loss 0.3276 (0.2059) Acc@1 89.062 (92.821) Acc@5 100.000 (99.852)
2025-08-27 22:34:52,734 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3167 (0.3167) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:34:53,619 - INFO - Epoch 131:
2025-08-27 22:34:53,619 - INFO -   Train: acc1: 92.7820 | acc5: 99.8540 | loss: 0.2073 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:34:53,619 - INFO -   Val:   acc1: 88.2400 | acc5: 99.5600 | loss: 0.3485
2025-08-27 22:34:53,619 - INFO -   LR: 0.010000
2025-08-27 22:34:53,635 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-27 22:34:53,825 - INFO - Epoch: [132][0/391] Time 0.189 (0.189) Data 0.153 (0.153) Loss 0.2270 (0.2270) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:34:55,056 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:55,057 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:55,710 - INFO - Epoch: [132][100/391] Time 0.032 (0.021) Data 0.000 (0.005) Loss 0.1999 (0.2106) Acc@1 92.969 (92.559) Acc@5 100.000 (99.899)
2025-08-27 22:34:57,513 - INFO - Epoch: [132][200/391] Time 0.016 (0.019) Data 0.002 (0.003) Loss 0.1514 (0.2096) Acc@1 95.312 (92.704) Acc@5 100.000 (99.876)
2025-08-27 22:34:58,032 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:34:58,032 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:34:59,367 - INFO - Epoch: [132][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2380 (0.2085) Acc@1 89.062 (92.813) Acc@5 100.000 (99.888)
2025-08-27 22:35:00,973 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:00,973 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:01,184 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3627 (0.3627) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:35:02,024 - INFO - Epoch 132:
2025-08-27 22:35:02,024 - INFO -   Train: acc1: 92.6740 | acc5: 99.8700 | loss: 0.2134 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:02,024 - INFO -   Val:   acc1: 87.6900 | acc5: 99.6700 | loss: 0.3758
2025-08-27 22:35:02,024 - INFO -   LR: 0.010000
2025-08-27 22:35:02,039 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-27 22:35:02,242 - INFO - Epoch: [133][0/391] Time 0.202 (0.202) Data 0.182 (0.182) Loss 0.1635 (0.1635) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:35:04,002 - INFO - Epoch: [133][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1981 (0.2058) Acc@1 93.750 (92.713) Acc@5 100.000 (99.884)
2025-08-27 22:35:05,097 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:05,098 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:05,833 - INFO - Epoch: [133][200/391] Time 0.020 (0.019) Data 0.008 (0.003) Loss 0.2352 (0.2080) Acc@1 92.188 (92.712) Acc@5 100.000 (99.868)
2025-08-27 22:35:07,669 - INFO - Epoch: [133][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.3104 (0.2101) Acc@1 89.844 (92.766) Acc@5 99.219 (99.857)
2025-08-27 22:35:07,939 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:07,939 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:09,357 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2536 (0.2536) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:35:10,179 - INFO - Epoch 133:
2025-08-27 22:35:10,179 - INFO -   Train: acc1: 92.6980 | acc5: 99.8500 | loss: 0.2119 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:10,179 - INFO -   Val:   acc1: 89.0400 | acc5: 99.7400 | loss: 0.3275
2025-08-27 22:35:10,179 - INFO -   LR: 0.010000
2025-08-27 22:35:10,196 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-27 22:35:10,362 - INFO - Epoch: [134][0/391] Time 0.165 (0.165) Data 0.145 (0.145) Loss 0.1752 (0.1752) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:35:11,859 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:11,859 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:12,103 - INFO - Epoch: [134][100/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.1704 (0.2014) Acc@1 92.188 (93.108) Acc@5 100.000 (99.899)
2025-08-27 22:35:13,831 - INFO - Epoch: [134][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.2153 (0.2024) Acc@1 91.406 (93.078) Acc@5 100.000 (99.880)
2025-08-27 22:35:14,655 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:14,655 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:15,603 - INFO - Epoch: [134][300/391] Time 0.020 (0.018) Data 0.008 (0.003) Loss 0.3183 (0.2080) Acc@1 88.281 (92.844) Acc@5 100.000 (99.868)
2025-08-27 22:35:17,341 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3159 (0.3159) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:35:18,163 - INFO - Epoch 134:
2025-08-27 22:35:18,163 - INFO -   Train: acc1: 92.7560 | acc5: 99.8680 | loss: 0.2103 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:18,163 - INFO -   Val:   acc1: 89.0900 | acc5: 99.6400 | loss: 0.3446
2025-08-27 22:35:18,163 - INFO -   LR: 0.010000
2025-08-27 22:35:18,178 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-27 22:35:18,373 - INFO - Epoch: [135][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.2803 (0.2803) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:35:18,621 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:18,621 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:20,115 - INFO - Epoch: [135][100/391] Time 0.019 (0.019) Data 0.000 (0.005) Loss 0.2649 (0.2057) Acc@1 90.625 (92.783) Acc@5 100.000 (99.853)
2025-08-27 22:35:21,422 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:21,427 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:21,866 - INFO - Epoch: [135][200/391] Time 0.023 (0.018) Data 0.011 (0.004) Loss 0.2774 (0.2067) Acc@1 92.969 (92.751) Acc@5 100.000 (99.876)
2025-08-27 22:35:23,658 - INFO - Epoch: [135][300/391] Time 0.018 (0.018) Data 0.000 (0.003) Loss 0.2745 (0.2084) Acc@1 88.281 (92.670) Acc@5 100.000 (99.878)
2025-08-27 22:35:24,263 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:24,263 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:25,325 - INFO - Test: [0/79] Time 0.095 (0.095) Loss 0.2994 (0.2994) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:35:26,192 - INFO - Epoch 135:
2025-08-27 22:35:26,192 - INFO -   Train: acc1: 92.6280 | acc5: 99.8620 | loss: 0.2102 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:26,192 - INFO -   Val:   acc1: 88.7600 | acc5: 99.6000 | loss: 0.3362
2025-08-27 22:35:26,192 - INFO -   LR: 0.010000
2025-08-27 22:35:26,208 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-27 22:35:26,378 - INFO - Epoch: [136][0/391] Time 0.169 (0.169) Data 0.146 (0.146) Loss 0.1784 (0.1784) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-27 22:35:28,133 - INFO - Epoch: [136][100/391] Time 0.025 (0.019) Data 0.003 (0.004) Loss 0.1779 (0.2128) Acc@1 92.969 (92.528) Acc@5 100.000 (99.791)
2025-08-27 22:35:28,186 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:28,186 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:29,888 - INFO - Epoch: [136][200/391] Time 0.039 (0.018) Data 0.002 (0.004) Loss 0.2058 (0.2083) Acc@1 96.094 (92.615) Acc@5 99.219 (99.845)
2025-08-27 22:35:31,017 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:31,018 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:31,715 - INFO - Epoch: [136][300/391] Time 0.011 (0.018) Data 0.000 (0.004) Loss 0.2947 (0.2116) Acc@1 90.625 (92.642) Acc@5 100.000 (99.860)
2025-08-27 22:35:33,508 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.2894 (0.2894) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:35:34,381 - INFO - Epoch 136:
2025-08-27 22:35:34,381 - INFO -   Train: acc1: 92.6700 | acc5: 99.8580 | loss: 0.2108 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:34,382 - INFO -   Val:   acc1: 88.2100 | acc5: 99.6200 | loss: 0.3652
2025-08-27 22:35:34,382 - INFO -   LR: 0.010000
2025-08-27 22:35:34,395 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-27 22:35:34,585 - INFO - Epoch: [137][0/391] Time 0.189 (0.189) Data 0.157 (0.157) Loss 0.2439 (0.2439) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:35:35,210 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:35,210 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:36,458 - INFO - Epoch: [137][100/391] Time 0.020 (0.020) Data 0.007 (0.003) Loss 0.1307 (0.1977) Acc@1 96.875 (93.116) Acc@5 100.000 (99.915)
2025-08-27 22:35:38,142 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:38,142 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:38,278 - INFO - Epoch: [137][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.1633 (0.2035) Acc@1 95.312 (92.973) Acc@5 100.000 (99.880)
2025-08-27 22:35:40,086 - INFO - Epoch: [137][300/391] Time 0.014 (0.019) Data 0.001 (0.002) Loss 0.2768 (0.2067) Acc@1 90.625 (92.821) Acc@5 100.000 (99.868)
2025-08-27 22:35:41,027 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:41,027 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:41,886 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3259 (0.3259) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:35:42,737 - INFO - Epoch 137:
2025-08-27 22:35:42,737 - INFO -   Train: acc1: 92.7160 | acc5: 99.8560 | loss: 0.2101 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:42,737 - INFO -   Val:   acc1: 88.5700 | acc5: 99.6500 | loss: 0.3432
2025-08-27 22:35:42,737 - INFO -   LR: 0.010000
2025-08-27 22:35:42,753 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-27 22:35:42,950 - INFO - Epoch: [138][0/391] Time 0.196 (0.196) Data 0.175 (0.175) Loss 0.1435 (0.1435) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:35:44,786 - INFO - Epoch: [138][100/391] Time 0.028 (0.020) Data 0.016 (0.005) Loss 0.2103 (0.1993) Acc@1 92.969 (93.069) Acc@5 99.219 (99.915)
2025-08-27 22:35:45,184 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:45,184 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:46,619 - INFO - Epoch: [138][200/391] Time 0.039 (0.019) Data 0.025 (0.004) Loss 0.1542 (0.2042) Acc@1 91.406 (92.840) Acc@5 100.000 (99.903)
2025-08-27 22:35:48,103 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:48,103 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:48,462 - INFO - Epoch: [138][300/391] Time 0.055 (0.019) Data 0.043 (0.004) Loss 0.1492 (0.2073) Acc@1 96.094 (92.771) Acc@5 100.000 (99.873)
2025-08-27 22:35:50,250 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2839 (0.2839) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:35:51,077 - INFO - Epoch 138:
2025-08-27 22:35:51,077 - INFO -   Train: acc1: 92.6060 | acc5: 99.8660 | loss: 0.2105 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:51,077 - INFO -   Val:   acc1: 88.2000 | acc5: 99.6300 | loss: 0.3749
2025-08-27 22:35:51,077 - INFO -   LR: 0.010000
2025-08-27 22:35:51,092 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-27 22:35:51,273 - INFO - Epoch: [139][0/391] Time 0.179 (0.179) Data 0.164 (0.164) Loss 0.2705 (0.2705) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:35:52,159 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:52,165 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:53,080 - INFO - Epoch: [139][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.2380 (0.2070) Acc@1 90.625 (92.768) Acc@5 100.000 (99.899)
2025-08-27 22:35:54,901 - INFO - Epoch: [139][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2295 (0.2117) Acc@1 94.531 (92.611) Acc@5 100.000 (99.880)
2025-08-27 22:35:55,056 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:55,057 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:56,671 - INFO - Epoch: [139][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2997 (0.2122) Acc@1 89.062 (92.561) Acc@5 100.000 (99.875)
2025-08-27 22:35:57,999 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:35:58,000 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:35:58,507 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3066 (0.3066) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:35:59,353 - INFO - Epoch 139:
2025-08-27 22:35:59,354 - INFO -   Train: acc1: 92.5100 | acc5: 99.8680 | loss: 0.2136 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:35:59,354 - INFO -   Val:   acc1: 88.3900 | acc5: 99.5100 | loss: 0.3601
2025-08-27 22:35:59,354 - INFO -   LR: 0.010000
2025-08-27 22:35:59,370 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-27 22:35:59,541 - INFO - Epoch: [140][0/391] Time 0.170 (0.170) Data 0.152 (0.152) Loss 0.1259 (0.1259) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:36:01,328 - INFO - Epoch: [140][100/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.1874 (0.1975) Acc@1 92.188 (93.054) Acc@5 100.000 (99.884)
2025-08-27 22:36:02,054 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:02,054 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:03,168 - INFO - Epoch: [140][200/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.2867 (0.2073) Acc@1 90.625 (92.786) Acc@5 100.000 (99.852)
2025-08-27 22:36:04,968 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:04,968 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:04,984 - INFO - Epoch: [140][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.1841 (0.2099) Acc@1 94.531 (92.751) Acc@5 100.000 (99.860)
2025-08-27 22:36:06,718 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2406 (0.2406) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:36:07,534 - INFO - Epoch 140:
2025-08-27 22:36:07,534 - INFO -   Train: acc1: 92.7160 | acc5: 99.8600 | loss: 0.2107 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:07,534 - INFO -   Val:   acc1: 88.1000 | acc5: 99.5900 | loss: 0.3768
2025-08-27 22:36:07,534 - INFO -   LR: 0.010000
2025-08-27 22:36:07,584 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-27 22:36:07,778 - INFO - Epoch: [141][0/391] Time 0.194 (0.194) Data 0.167 (0.167) Loss 0.2735 (0.2735) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:36:09,034 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:09,035 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:09,628 - INFO - Epoch: [141][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.1571 (0.2088) Acc@1 92.188 (92.721) Acc@5 100.000 (99.807)
2025-08-27 22:36:11,457 - INFO - Epoch: [141][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1678 (0.2060) Acc@1 93.750 (92.693) Acc@5 100.000 (99.841)
2025-08-27 22:36:11,969 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:11,969 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:13,273 - INFO - Epoch: [141][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1462 (0.2105) Acc@1 92.188 (92.577) Acc@5 100.000 (99.847)
2025-08-27 22:36:14,860 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:14,860 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:15,049 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.3366 (0.3366) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:36:15,878 - INFO - Epoch 141:
2025-08-27 22:36:15,879 - INFO -   Train: acc1: 92.5260 | acc5: 99.8600 | loss: 0.2127 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:15,879 - INFO -   Val:   acc1: 88.5200 | acc5: 99.6200 | loss: 0.3562
2025-08-27 22:36:15,879 - INFO -   LR: 0.010000
2025-08-27 22:36:15,895 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-27 22:36:16,084 - INFO - Epoch: [142][0/391] Time 0.188 (0.188) Data 0.159 (0.159) Loss 0.2053 (0.2053) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:36:17,950 - INFO - Epoch: [142][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2560 (0.2133) Acc@1 91.406 (92.783) Acc@5 100.000 (99.822)
2025-08-27 22:36:18,966 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:18,966 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:19,816 - INFO - Epoch: [142][200/391] Time 0.020 (0.019) Data 0.006 (0.004) Loss 0.1978 (0.2101) Acc@1 95.312 (92.767) Acc@5 100.000 (99.837)
2025-08-27 22:36:21,633 - INFO - Epoch: [142][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2593 (0.2114) Acc@1 90.625 (92.701) Acc@5 99.219 (99.849)
2025-08-27 22:36:21,931 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:21,932 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:23,405 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2728 (0.2728) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:36:24,232 - INFO - Epoch 142:
2025-08-27 22:36:24,232 - INFO -   Train: acc1: 92.6540 | acc5: 99.8400 | loss: 0.2139 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:24,232 - INFO -   Val:   acc1: 88.7200 | acc5: 99.6000 | loss: 0.3478
2025-08-27 22:36:24,232 - INFO -   LR: 0.010000
2025-08-27 22:36:24,247 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-27 22:36:24,445 - INFO - Epoch: [143][0/391] Time 0.197 (0.197) Data 0.180 (0.180) Loss 0.2654 (0.2654) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:36:26,010 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:26,010 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:26,261 - INFO - Epoch: [143][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.1623 (0.2060) Acc@1 90.625 (92.984) Acc@5 100.000 (99.899)
2025-08-27 22:36:28,079 - INFO - Epoch: [143][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1362 (0.2069) Acc@1 96.875 (92.988) Acc@5 100.000 (99.868)
2025-08-27 22:36:28,958 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:28,959 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:29,855 - INFO - Epoch: [143][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1661 (0.2092) Acc@1 96.875 (92.870) Acc@5 100.000 (99.870)
2025-08-27 22:36:31,661 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3908 (0.3908) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:36:32,478 - INFO - Epoch 143:
2025-08-27 22:36:32,479 - INFO -   Train: acc1: 92.6980 | acc5: 99.8720 | loss: 0.2112 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:32,479 - INFO -   Val:   acc1: 88.0100 | acc5: 99.6200 | loss: 0.3854
2025-08-27 22:36:32,479 - INFO -   LR: 0.010000
2025-08-27 22:36:32,494 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-27 22:36:32,686 - INFO - Epoch: [144][0/391] Time 0.191 (0.191) Data 0.146 (0.146) Loss 0.2525 (0.2525) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:36:32,987 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:32,987 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:34,503 - INFO - Epoch: [144][100/391] Time 0.015 (0.020) Data 0.000 (0.005) Loss 0.2036 (0.2091) Acc@1 94.531 (92.992) Acc@5 100.000 (99.814)
2025-08-27 22:36:35,902 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:35,902 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:36,295 - INFO - Epoch: [144][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2055 (0.2140) Acc@1 92.188 (92.743) Acc@5 100.000 (99.852)
2025-08-27 22:36:38,169 - INFO - Epoch: [144][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1764 (0.2154) Acc@1 95.312 (92.587) Acc@5 100.000 (99.855)
2025-08-27 22:36:38,823 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:38,823 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:39,934 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2969 (0.2969) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:36:40,794 - INFO - Epoch 144:
2025-08-27 22:36:40,795 - INFO -   Train: acc1: 92.6000 | acc5: 99.8440 | loss: 0.2158 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:40,795 - INFO -   Val:   acc1: 87.6400 | acc5: 99.5200 | loss: 0.3794
2025-08-27 22:36:40,795 - INFO -   LR: 0.010000
2025-08-27 22:36:40,811 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-27 22:36:40,990 - INFO - Epoch: [145][0/391] Time 0.178 (0.178) Data 0.151 (0.151) Loss 0.2481 (0.2481) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:36:42,825 - INFO - Epoch: [145][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2562 (0.1990) Acc@1 89.062 (93.100) Acc@5 100.000 (99.899)
2025-08-27 22:36:42,888 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:42,888 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:44,625 - INFO - Epoch: [145][200/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.1844 (0.2063) Acc@1 92.969 (92.910) Acc@5 100.000 (99.860)
2025-08-27 22:36:45,770 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:45,779 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:46,442 - INFO - Epoch: [145][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.2342 (0.2102) Acc@1 90.625 (92.782) Acc@5 100.000 (99.857)
2025-08-27 22:36:48,194 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2794 (0.2794) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:36:49,061 - INFO - Epoch 145:
2025-08-27 22:36:49,061 - INFO -   Train: acc1: 92.7860 | acc5: 99.8580 | loss: 0.2114 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:49,061 - INFO -   Val:   acc1: 88.0500 | acc5: 99.4900 | loss: 0.3839
2025-08-27 22:36:49,061 - INFO -   LR: 0.010000
2025-08-27 22:36:49,077 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-27 22:36:49,270 - INFO - Epoch: [146][0/391] Time 0.192 (0.192) Data 0.156 (0.156) Loss 0.2817 (0.2817) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:36:49,893 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:49,893 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:51,155 - INFO - Epoch: [146][100/391] Time 0.029 (0.021) Data 0.013 (0.006) Loss 0.1821 (0.2035) Acc@1 92.969 (92.907) Acc@5 100.000 (99.907)
2025-08-27 22:36:52,850 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:52,850 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:52,970 - INFO - Epoch: [146][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2484 (0.2100) Acc@1 92.969 (92.607) Acc@5 100.000 (99.868)
2025-08-27 22:36:54,775 - INFO - Epoch: [146][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1757 (0.2091) Acc@1 92.969 (92.699) Acc@5 100.000 (99.881)
2025-08-27 22:36:55,715 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:55,715 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:36:56,533 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3281 (0.3281) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:36:57,370 - INFO - Epoch 146:
2025-08-27 22:36:57,371 - INFO -   Train: acc1: 92.6140 | acc5: 99.8740 | loss: 0.2114 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:36:57,371 - INFO -   Val:   acc1: 89.0100 | acc5: 99.6800 | loss: 0.3283
2025-08-27 22:36:57,371 - INFO -   LR: 0.010000
2025-08-27 22:36:57,386 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-27 22:36:57,556 - INFO - Epoch: [147][0/391] Time 0.170 (0.170) Data 0.148 (0.148) Loss 0.2260 (0.2260) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:36:59,395 - INFO - Epoch: [147][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1814 (0.2093) Acc@1 92.188 (92.628) Acc@5 100.000 (99.853)
2025-08-27 22:36:59,772 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:36:59,772 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:01,173 - INFO - Epoch: [147][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2836 (0.2131) Acc@1 89.844 (92.471) Acc@5 100.000 (99.872)
2025-08-27 22:37:02,758 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:02,758 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:03,038 - INFO - Epoch: [147][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1800 (0.2162) Acc@1 94.531 (92.411) Acc@5 100.000 (99.875)
2025-08-27 22:37:04,856 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3594 (0.3594) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:37:05,721 - INFO - Epoch 147:
2025-08-27 22:37:05,722 - INFO -   Train: acc1: 92.5900 | acc5: 99.8620 | loss: 0.2139 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:05,722 - INFO -   Val:   acc1: 88.0500 | acc5: 99.4000 | loss: 0.3775
2025-08-27 22:37:05,722 - INFO -   LR: 0.010000
2025-08-27 22:37:05,742 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-27 22:37:05,908 - INFO - Epoch: [148][0/391] Time 0.166 (0.166) Data 0.135 (0.135) Loss 0.2671 (0.2671) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:37:06,930 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:06,930 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:07,834 - INFO - Epoch: [148][100/391] Time 0.016 (0.021) Data 0.000 (0.002) Loss 0.2934 (0.2063) Acc@1 91.406 (92.814) Acc@5 100.000 (99.899)
2025-08-27 22:37:09,632 - INFO - Epoch: [148][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.1646 (0.2094) Acc@1 94.531 (92.809) Acc@5 100.000 (99.864)
2025-08-27 22:37:09,866 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:09,867 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:11,520 - INFO - Epoch: [148][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2456 (0.2118) Acc@1 89.844 (92.608) Acc@5 100.000 (99.862)
2025-08-27 22:37:12,830 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:12,831 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:13,344 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.3597 (0.3597) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:37:14,209 - INFO - Epoch 148:
2025-08-27 22:37:14,210 - INFO -   Train: acc1: 92.5080 | acc5: 99.8660 | loss: 0.2140 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:14,210 - INFO -   Val:   acc1: 88.2800 | acc5: 99.4800 | loss: 0.3663
2025-08-27 22:37:14,210 - INFO -   LR: 0.010000
2025-08-27 22:37:14,225 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-27 22:37:14,413 - INFO - Epoch: [149][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.2551 (0.2551) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:37:16,195 - INFO - Epoch: [149][100/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.2502 (0.2011) Acc@1 92.969 (93.007) Acc@5 99.219 (99.853)
2025-08-27 22:37:16,896 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:16,896 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:18,006 - INFO - Epoch: [149][200/391] Time 0.031 (0.019) Data 0.000 (0.003) Loss 0.2667 (0.2106) Acc@1 90.625 (92.576) Acc@5 100.000 (99.883)
2025-08-27 22:37:19,837 - INFO - Epoch: [149][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1805 (0.2130) Acc@1 94.531 (92.502) Acc@5 99.219 (99.875)
2025-08-27 22:37:19,842 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:19,843 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:21,613 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3489 (0.3489) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:37:22,453 - INFO - Epoch 149:
2025-08-27 22:37:22,453 - INFO -   Train: acc1: 92.4920 | acc5: 99.8580 | loss: 0.2141 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:22,453 - INFO -   Val:   acc1: 88.6600 | acc5: 99.6600 | loss: 0.3393
2025-08-27 22:37:22,453 - INFO -   LR: 0.001000
2025-08-27 22:37:22,468 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-27 22:37:22,657 - INFO - Epoch: [150][0/391] Time 0.189 (0.189) Data 0.171 (0.171) Loss 0.3000 (0.3000) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:37:23,917 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:23,917 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:24,434 - INFO - Epoch: [150][100/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.1822 (0.1846) Acc@1 93.750 (93.719) Acc@5 100.000 (99.884)
2025-08-27 22:37:26,311 - INFO - Epoch: [150][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2024 (0.1788) Acc@1 92.969 (93.843) Acc@5 100.000 (99.914)
2025-08-27 22:37:26,854 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:26,854 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:28,142 - INFO - Epoch: [150][300/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.2341 (0.1784) Acc@1 88.281 (93.885) Acc@5 100.000 (99.912)
2025-08-27 22:37:29,740 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:29,740 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:29,934 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2468 (0.2468) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:37:30,833 - INFO - Epoch 150:
2025-08-27 22:37:30,833 - INFO -   Train: acc1: 94.0340 | acc5: 99.9100 | loss: 0.1754 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:30,833 - INFO -   Val:   acc1: 90.3600 | acc5: 99.7200 | loss: 0.2905
2025-08-27 22:37:30,833 - INFO -   LR: 0.001000
2025-08-27 22:37:30,882 - INFO - Checkpoint saved: epoch=150, metric=90.3600
2025-08-27 22:37:30,916 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-27 22:37:31,086 - INFO - Epoch: [151][0/391] Time 0.170 (0.170) Data 0.151 (0.151) Loss 0.1618 (0.1618) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:37:32,935 - INFO - Epoch: [151][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1714 (0.1572) Acc@1 94.531 (94.709) Acc@5 100.000 (99.915)
2025-08-27 22:37:34,053 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:34,054 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:34,836 - INFO - Epoch: [151][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2436 (0.1572) Acc@1 92.969 (94.714) Acc@5 100.000 (99.914)
2025-08-27 22:37:36,698 - INFO - Epoch: [151][300/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.1021 (0.1572) Acc@1 97.656 (94.700) Acc@5 100.000 (99.912)
2025-08-27 22:37:36,981 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:36,981 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:38,472 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2424 (0.2424) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:37:39,362 - INFO - Epoch 151:
2025-08-27 22:37:39,362 - INFO -   Train: acc1: 94.7060 | acc5: 99.9180 | loss: 0.1582 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:39,363 - INFO -   Val:   acc1: 90.4200 | acc5: 99.7100 | loss: 0.2886
2025-08-27 22:37:39,363 - INFO -   LR: 0.001000
2025-08-27 22:37:39,411 - INFO - Checkpoint saved: epoch=151, metric=90.4200
2025-08-27 22:37:39,446 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-27 22:37:39,640 - INFO - Epoch: [152][0/391] Time 0.193 (0.193) Data 0.177 (0.177) Loss 0.2888 (0.2888) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:37:41,239 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:41,239 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:41,521 - INFO - Epoch: [152][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.1526 (0.1562) Acc@1 95.312 (94.887) Acc@5 100.000 (99.915)
2025-08-27 22:37:43,319 - INFO - Epoch: [152][200/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.1326 (0.1556) Acc@1 97.656 (94.908) Acc@5 100.000 (99.938)
2025-08-27 22:37:44,171 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:44,172 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:45,184 - INFO - Epoch: [152][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.0687 (0.1557) Acc@1 100.000 (94.845) Acc@5 100.000 (99.933)
2025-08-27 22:37:46,932 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2356 (0.2356) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:37:47,822 - INFO - Epoch 152:
2025-08-27 22:37:47,822 - INFO -   Train: acc1: 94.8260 | acc5: 99.9280 | loss: 0.1554 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:47,822 - INFO -   Val:   acc1: 90.1900 | acc5: 99.7100 | loss: 0.2934
2025-08-27 22:37:47,822 - INFO -   LR: 0.001000
2025-08-27 22:37:47,839 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-27 22:37:48,020 - INFO - Epoch: [153][0/391] Time 0.180 (0.180) Data 0.149 (0.149) Loss 0.2105 (0.2105) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:37:48,325 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:48,325 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:49,844 - INFO - Epoch: [153][100/391] Time 0.030 (0.020) Data 0.010 (0.003) Loss 0.1743 (0.1517) Acc@1 92.969 (95.073) Acc@5 100.000 (99.923)
2025-08-27 22:37:51,239 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:51,239 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:51,657 - INFO - Epoch: [153][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1320 (0.1537) Acc@1 97.656 (94.955) Acc@5 100.000 (99.942)
2025-08-27 22:37:53,476 - INFO - Epoch: [153][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1025 (0.1531) Acc@1 96.875 (94.991) Acc@5 100.000 (99.925)
2025-08-27 22:37:54,115 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:54,126 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:55,208 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2267 (0.2267) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:37:56,073 - INFO - Epoch 153:
2025-08-27 22:37:56,073 - INFO -   Train: acc1: 94.9840 | acc5: 99.9260 | loss: 0.1531 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:37:56,073 - INFO -   Val:   acc1: 90.5500 | acc5: 99.7100 | loss: 0.2880
2025-08-27 22:37:56,073 - INFO -   LR: 0.001000
2025-08-27 22:37:56,126 - INFO - Checkpoint saved: epoch=153, metric=90.5500
2025-08-27 22:37:56,158 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-27 22:37:56,353 - INFO - Epoch: [154][0/391] Time 0.194 (0.194) Data 0.171 (0.171) Loss 0.1289 (0.1289) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:37:58,124 - INFO - Epoch: [154][100/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.1512 (0.1462) Acc@1 96.875 (95.173) Acc@5 100.000 (99.954)
2025-08-27 22:37:58,215 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:37:58,216 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:37:59,989 - INFO - Epoch: [154][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.1874 (0.1500) Acc@1 94.531 (94.982) Acc@5 100.000 (99.934)
2025-08-27 22:38:01,167 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:01,167 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:01,793 - INFO - Epoch: [154][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.1408 (0.1489) Acc@1 92.188 (94.985) Acc@5 100.000 (99.938)
2025-08-27 22:38:03,549 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2131 (0.2131) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:38:04,448 - INFO - Epoch 154:
2025-08-27 22:38:04,448 - INFO -   Train: acc1: 94.9520 | acc5: 99.9400 | loss: 0.1492 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:04,448 - INFO -   Val:   acc1: 90.5200 | acc5: 99.7300 | loss: 0.2896
2025-08-27 22:38:04,448 - INFO -   LR: 0.001000
2025-08-27 22:38:04,465 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-27 22:38:04,646 - INFO - Epoch: [155][0/391] Time 0.180 (0.180) Data 0.163 (0.163) Loss 0.1686 (0.1686) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:38:05,300 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:05,300 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:06,489 - INFO - Epoch: [155][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1105 (0.1473) Acc@1 97.656 (95.065) Acc@5 100.000 (99.876)
2025-08-27 22:38:08,289 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:08,290 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:08,363 - INFO - Epoch: [155][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2198 (0.1449) Acc@1 92.188 (95.130) Acc@5 99.219 (99.914)
2025-08-27 22:38:10,169 - INFO - Epoch: [155][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1627 (0.1451) Acc@1 93.750 (95.154) Acc@5 100.000 (99.917)
2025-08-27 22:38:11,147 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:11,147 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:11,909 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2358 (0.2358) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:38:12,768 - INFO - Epoch 155:
2025-08-27 22:38:12,768 - INFO -   Train: acc1: 95.1080 | acc5: 99.9260 | loss: 0.1462 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:12,768 - INFO -   Val:   acc1: 90.4800 | acc5: 99.7000 | loss: 0.2876
2025-08-27 22:38:12,768 - INFO -   LR: 0.001000
2025-08-27 22:38:12,787 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-27 22:38:12,974 - INFO - Epoch: [156][0/391] Time 0.186 (0.186) Data 0.150 (0.150) Loss 0.1493 (0.1493) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:38:14,750 - INFO - Epoch: [156][100/391] Time 0.018 (0.019) Data 0.007 (0.004) Loss 0.1640 (0.1476) Acc@1 94.531 (94.980) Acc@5 100.000 (99.946)
2025-08-27 22:38:15,181 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:15,181 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:16,629 - INFO - Epoch: [156][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1815 (0.1458) Acc@1 92.969 (95.079) Acc@5 100.000 (99.942)
2025-08-27 22:38:18,132 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:18,132 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:18,468 - INFO - Epoch: [156][300/391] Time 0.035 (0.019) Data 0.013 (0.003) Loss 0.1176 (0.1473) Acc@1 95.312 (95.081) Acc@5 100.000 (99.935)
2025-08-27 22:38:20,180 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2389 (0.2389) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:38:21,037 - INFO - Epoch 156:
2025-08-27 22:38:21,037 - INFO -   Train: acc1: 95.0940 | acc5: 99.9380 | loss: 0.1464 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:21,037 - INFO -   Val:   acc1: 90.2300 | acc5: 99.7300 | loss: 0.2934
2025-08-27 22:38:21,037 - INFO -   LR: 0.001000
2025-08-27 22:38:21,054 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-27 22:38:21,259 - INFO - Epoch: [157][0/391] Time 0.204 (0.204) Data 0.174 (0.174) Loss 0.2151 (0.2151) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:38:22,177 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:22,177 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:23,023 - INFO - Epoch: [157][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1189 (0.1434) Acc@1 96.094 (95.142) Acc@5 100.000 (99.938)
2025-08-27 22:38:24,787 - INFO - Epoch: [157][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1546 (0.1458) Acc@1 95.312 (95.091) Acc@5 100.000 (99.942)
2025-08-27 22:38:25,029 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:25,029 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:26,579 - INFO - Epoch: [157][300/391] Time 0.026 (0.018) Data 0.014 (0.003) Loss 0.1592 (0.1457) Acc@1 95.312 (95.094) Acc@5 100.000 (99.938)
2025-08-27 22:38:27,912 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:27,912 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:28,374 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2278 (0.2278) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:38:29,221 - INFO - Epoch 157:
2025-08-27 22:38:29,222 - INFO -   Train: acc1: 95.1640 | acc5: 99.9400 | loss: 0.1444 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:29,222 - INFO -   Val:   acc1: 90.6000 | acc5: 99.6800 | loss: 0.2921
2025-08-27 22:38:29,222 - INFO -   LR: 0.001000
2025-08-27 22:38:29,273 - INFO - Checkpoint saved: epoch=157, metric=90.6000
2025-08-27 22:38:29,305 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-27 22:38:29,507 - INFO - Epoch: [158][0/391] Time 0.201 (0.201) Data 0.176 (0.176) Loss 0.1085 (0.1085) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:38:31,317 - INFO - Epoch: [158][100/391] Time 0.025 (0.020) Data 0.000 (0.005) Loss 0.1791 (0.1487) Acc@1 93.750 (95.073) Acc@5 100.000 (99.946)
2025-08-27 22:38:32,064 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:32,064 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:33,078 - INFO - Epoch: [158][200/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.1399 (0.1451) Acc@1 93.750 (95.219) Acc@5 100.000 (99.926)
2025-08-27 22:38:34,915 - INFO - Epoch: [158][300/391] Time 0.021 (0.019) Data 0.006 (0.004) Loss 0.1102 (0.1435) Acc@1 96.875 (95.263) Acc@5 100.000 (99.930)
2025-08-27 22:38:34,933 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:34,933 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:36,696 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2518 (0.2518) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:38:37,507 - INFO - Epoch 158:
2025-08-27 22:38:37,507 - INFO -   Train: acc1: 95.2940 | acc5: 99.9300 | loss: 0.1427 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:37,507 - INFO -   Val:   acc1: 90.5900 | acc5: 99.7000 | loss: 0.2935
2025-08-27 22:38:37,507 - INFO -   LR: 0.001000
2025-08-27 22:38:37,524 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-27 22:38:37,722 - INFO - Epoch: [159][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.1268 (0.1268) Acc@1 96.875 (96.875) Acc@5 99.219 (99.219)
2025-08-27 22:38:38,961 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:38,961 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:39,510 - INFO - Epoch: [159][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1255 (0.1380) Acc@1 95.312 (95.521) Acc@5 100.000 (99.915)
2025-08-27 22:38:41,390 - INFO - Epoch: [159][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0936 (0.1383) Acc@1 96.875 (95.441) Acc@5 100.000 (99.938)
2025-08-27 22:38:41,921 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:41,921 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:43,221 - INFO - Epoch: [159][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2023 (0.1408) Acc@1 92.969 (95.354) Acc@5 100.000 (99.938)
2025-08-27 22:38:45,006 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2413 (0.2413) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:38:45,858 - INFO - Epoch 159:
2025-08-27 22:38:45,858 - INFO -   Train: acc1: 95.2640 | acc5: 99.9380 | loss: 0.1416 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:45,858 - INFO -   Val:   acc1: 90.4400 | acc5: 99.7000 | loss: 0.2930
2025-08-27 22:38:45,858 - INFO -   LR: 0.001000
2025-08-27 22:38:45,874 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-27 22:38:46,046 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:46,046 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:46,065 - INFO - Epoch: [160][0/391] Time 0.190 (0.190) Data 0.160 (0.160) Loss 0.1052 (0.1052) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:38:47,830 - INFO - Epoch: [160][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.0726 (0.1343) Acc@1 97.656 (95.444) Acc@5 100.000 (99.923)
2025-08-27 22:38:48,887 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:48,887 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:49,674 - INFO - Epoch: [160][200/391] Time 0.036 (0.019) Data 0.025 (0.004) Loss 0.1640 (0.1404) Acc@1 93.750 (95.219) Acc@5 100.000 (99.914)
2025-08-27 22:38:51,501 - INFO - Epoch: [160][300/391] Time 0.060 (0.019) Data 0.048 (0.004) Loss 0.1229 (0.1416) Acc@1 95.312 (95.235) Acc@5 100.000 (99.933)
2025-08-27 22:38:51,851 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:51,851 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:53,263 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2355 (0.2355) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:38:54,109 - INFO - Epoch 160:
2025-08-27 22:38:54,109 - INFO -   Train: acc1: 95.2720 | acc5: 99.9360 | loss: 0.1402 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:38:54,109 - INFO -   Val:   acc1: 90.5600 | acc5: 99.7200 | loss: 0.2924
2025-08-27 22:38:54,109 - INFO -   LR: 0.001000
2025-08-27 22:38:54,161 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-27 22:38:54,336 - INFO - Epoch: [161][0/391] Time 0.174 (0.174) Data 0.154 (0.154) Loss 0.1753 (0.1753) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:38:56,020 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:56,021 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:56,213 - INFO - Epoch: [161][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1744 (0.1400) Acc@1 94.531 (95.436) Acc@5 100.000 (99.946)
2025-08-27 22:38:57,984 - INFO - Epoch: [161][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1201 (0.1392) Acc@1 96.094 (95.460) Acc@5 100.000 (99.949)
2025-08-27 22:38:58,848 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:38:58,848 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:38:59,786 - INFO - Epoch: [161][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1623 (0.1406) Acc@1 92.969 (95.401) Acc@5 100.000 (99.927)
2025-08-27 22:39:01,574 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2495 (0.2495) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:39:02,407 - INFO - Epoch 161:
2025-08-27 22:39:02,407 - INFO -   Train: acc1: 95.4220 | acc5: 99.9340 | loss: 0.1398 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:02,407 - INFO -   Val:   acc1: 90.5400 | acc5: 99.7000 | loss: 0.2937
2025-08-27 22:39:02,407 - INFO -   LR: 0.001000
2025-08-27 22:39:02,424 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-27 22:39:02,588 - INFO - Epoch: [162][0/391] Time 0.163 (0.163) Data 0.147 (0.147) Loss 0.1290 (0.1290) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:39:02,897 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:02,898 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:04,407 - INFO - Epoch: [162][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1496 (0.1351) Acc@1 95.312 (95.606) Acc@5 100.000 (99.961)
2025-08-27 22:39:05,820 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:05,821 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:06,188 - INFO - Epoch: [162][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1179 (0.1336) Acc@1 95.312 (95.623) Acc@5 100.000 (99.957)
2025-08-27 22:39:07,940 - INFO - Epoch: [162][300/391] Time 0.018 (0.018) Data 0.000 (0.003) Loss 0.1330 (0.1365) Acc@1 95.312 (95.510) Acc@5 100.000 (99.951)
2025-08-27 22:39:08,570 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:08,571 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:09,650 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2500 (0.2500) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:39:10,446 - INFO - Epoch 162:
2025-08-27 22:39:10,446 - INFO -   Train: acc1: 95.4340 | acc5: 99.9600 | loss: 0.1373 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:10,446 - INFO -   Val:   acc1: 90.4400 | acc5: 99.6800 | loss: 0.2952
2025-08-27 22:39:10,446 - INFO -   LR: 0.001000
2025-08-27 22:39:10,463 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-27 22:39:10,625 - INFO - Epoch: [163][0/391] Time 0.162 (0.162) Data 0.141 (0.141) Loss 0.1828 (0.1828) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:39:12,389 - INFO - Epoch: [163][100/391] Time 0.034 (0.019) Data 0.018 (0.005) Loss 0.1270 (0.1373) Acc@1 95.312 (95.568) Acc@5 100.000 (99.969)
2025-08-27 22:39:12,519 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:12,519 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:14,143 - INFO - Epoch: [163][200/391] Time 0.032 (0.018) Data 0.000 (0.003) Loss 0.0866 (0.1381) Acc@1 96.875 (95.530) Acc@5 100.000 (99.965)
2025-08-27 22:39:15,308 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:15,308 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:15,894 - INFO - Epoch: [163][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1335 (0.1403) Acc@1 95.312 (95.486) Acc@5 100.000 (99.943)
2025-08-27 22:39:17,659 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2366 (0.2366) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:39:18,475 - INFO - Epoch 163:
2025-08-27 22:39:18,475 - INFO -   Train: acc1: 95.4960 | acc5: 99.9520 | loss: 0.1390 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:18,475 - INFO -   Val:   acc1: 90.4700 | acc5: 99.7200 | loss: 0.2945
2025-08-27 22:39:18,475 - INFO -   LR: 0.001000
2025-08-27 22:39:18,491 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-27 22:39:18,672 - INFO - Epoch: [164][0/391] Time 0.179 (0.179) Data 0.164 (0.164) Loss 0.2133 (0.2133) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:39:19,261 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:19,261 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:20,416 - INFO - Epoch: [164][100/391] Time 0.031 (0.019) Data 0.011 (0.004) Loss 0.1753 (0.1410) Acc@1 93.750 (95.142) Acc@5 100.000 (99.938)
2025-08-27 22:39:22,176 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:22,176 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:22,257 - INFO - Epoch: [164][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1542 (0.1391) Acc@1 93.750 (95.262) Acc@5 100.000 (99.949)
2025-08-27 22:39:24,000 - INFO - Epoch: [164][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.1477 (0.1368) Acc@1 95.312 (95.377) Acc@5 100.000 (99.948)
2025-08-27 22:39:24,976 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:24,977 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:25,724 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2744 (0.2744) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:39:26,526 - INFO - Epoch 164:
2025-08-27 22:39:26,527 - INFO -   Train: acc1: 95.3220 | acc5: 99.9500 | loss: 0.1379 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:26,527 - INFO -   Val:   acc1: 90.4800 | acc5: 99.6800 | loss: 0.2960
2025-08-27 22:39:26,527 - INFO -   LR: 0.001000
2025-08-27 22:39:26,545 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-27 22:39:26,728 - INFO - Epoch: [165][0/391] Time 0.182 (0.182) Data 0.160 (0.160) Loss 0.1406 (0.1406) Acc@1 96.875 (96.875) Acc@5 99.219 (99.219)
2025-08-27 22:39:28,475 - INFO - Epoch: [165][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1045 (0.1394) Acc@1 94.531 (95.312) Acc@5 100.000 (99.938)
2025-08-27 22:39:28,923 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:28,923 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:30,213 - INFO - Epoch: [165][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1272 (0.1348) Acc@1 94.531 (95.515) Acc@5 100.000 (99.949)
2025-08-27 22:39:31,701 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:31,701 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:31,979 - INFO - Epoch: [165][300/391] Time 0.011 (0.018) Data 0.000 (0.002) Loss 0.1509 (0.1361) Acc@1 95.312 (95.432) Acc@5 100.000 (99.945)
2025-08-27 22:39:33,682 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.2724 (0.2724) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:39:34,510 - INFO - Epoch 165:
2025-08-27 22:39:34,510 - INFO -   Train: acc1: 95.4200 | acc5: 99.9360 | loss: 0.1363 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:34,510 - INFO -   Val:   acc1: 90.3500 | acc5: 99.7200 | loss: 0.2989
2025-08-27 22:39:34,510 - INFO -   LR: 0.001000
2025-08-27 22:39:34,526 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-27 22:39:34,674 - INFO - Epoch: [166][0/391] Time 0.146 (0.146) Data 0.130 (0.130) Loss 0.1189 (0.1189) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:39:35,620 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:35,621 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:36,472 - INFO - Epoch: [166][100/391] Time 0.016 (0.019) Data 0.004 (0.004) Loss 0.0859 (0.1330) Acc@1 96.094 (95.552) Acc@5 100.000 (99.915)
2025-08-27 22:39:38,265 - INFO - Epoch: [166][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1122 (0.1336) Acc@1 95.312 (95.581) Acc@5 100.000 (99.926)
2025-08-27 22:39:38,503 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:38,503 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:39,986 - INFO - Epoch: [166][300/391] Time 0.022 (0.018) Data 0.000 (0.003) Loss 0.0764 (0.1326) Acc@1 96.875 (95.585) Acc@5 100.000 (99.935)
2025-08-27 22:39:41,310 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:41,311 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:41,735 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2562 (0.2562) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:39:42,570 - INFO - Epoch 166:
2025-08-27 22:39:42,570 - INFO -   Train: acc1: 95.5360 | acc5: 99.9360 | loss: 0.1341 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:42,570 - INFO -   Val:   acc1: 90.4500 | acc5: 99.7200 | loss: 0.2983
2025-08-27 22:39:42,570 - INFO -   LR: 0.001000
2025-08-27 22:39:42,587 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-27 22:39:42,778 - INFO - Epoch: [167][0/391] Time 0.190 (0.190) Data 0.165 (0.165) Loss 0.0945 (0.0945) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:39:44,550 - INFO - Epoch: [167][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1175 (0.1311) Acc@1 96.094 (95.645) Acc@5 100.000 (99.930)
2025-08-27 22:39:45,309 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:45,309 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:46,410 - INFO - Epoch: [167][200/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.0911 (0.1302) Acc@1 98.438 (95.717) Acc@5 100.000 (99.942)
2025-08-27 22:39:48,237 - INFO - Epoch: [167][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.0877 (0.1308) Acc@1 97.656 (95.699) Acc@5 100.000 (99.943)
2025-08-27 22:39:48,271 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:48,271 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:50,040 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2685 (0.2685) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:39:50,873 - INFO - Epoch 167:
2025-08-27 22:39:50,874 - INFO -   Train: acc1: 95.6640 | acc5: 99.9360 | loss: 0.1313 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:50,874 - INFO -   Val:   acc1: 90.5400 | acc5: 99.7200 | loss: 0.2944
2025-08-27 22:39:50,874 - INFO -   LR: 0.001000
2025-08-27 22:39:50,891 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-27 22:39:51,043 - INFO - Epoch: [168][0/391] Time 0.151 (0.151) Data 0.135 (0.135) Loss 0.1793 (0.1793) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:39:52,359 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:52,365 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:52,875 - INFO - Epoch: [168][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.0709 (0.1339) Acc@1 97.656 (95.545) Acc@5 100.000 (99.961)
2025-08-27 22:39:54,687 - INFO - Epoch: [168][200/391] Time 0.029 (0.019) Data 0.008 (0.003) Loss 0.1679 (0.1329) Acc@1 91.406 (95.592) Acc@5 100.000 (99.965)
2025-08-27 22:39:55,255 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:55,255 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:39:56,537 - INFO - Epoch: [168][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.1099 (0.1338) Acc@1 98.438 (95.556) Acc@5 100.000 (99.964)
2025-08-27 22:39:58,286 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2480 (0.2480) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:39:59,142 - INFO - Epoch 168:
2025-08-27 22:39:59,142 - INFO -   Train: acc1: 95.5260 | acc5: 99.9660 | loss: 0.1342 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:39:59,142 - INFO -   Val:   acc1: 90.5400 | acc5: 99.7200 | loss: 0.2999
2025-08-27 22:39:59,142 - INFO -   LR: 0.001000
2025-08-27 22:39:59,161 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-27 22:39:59,327 - INFO - Epoch: [169][0/391] Time 0.165 (0.165) Data 0.133 (0.133) Loss 0.1159 (0.1159) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:39:59,340 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:39:59,340 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:01,055 - INFO - Epoch: [169][100/391] Time 0.015 (0.019) Data 0.003 (0.004) Loss 0.1476 (0.1307) Acc@1 94.531 (95.692) Acc@5 100.000 (99.954)
2025-08-27 22:40:02,216 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:02,216 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:02,953 - INFO - Epoch: [169][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.0825 (0.1309) Acc@1 97.656 (95.690) Acc@5 100.000 (99.953)
2025-08-27 22:40:04,726 - INFO - Epoch: [169][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1166 (0.1308) Acc@1 95.312 (95.673) Acc@5 100.000 (99.956)
2025-08-27 22:40:05,128 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:05,128 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:06,519 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2439 (0.2439) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:40:07,388 - INFO - Epoch 169:
2025-08-27 22:40:07,388 - INFO -   Train: acc1: 95.6500 | acc5: 99.9540 | loss: 0.1313 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:07,388 - INFO -   Val:   acc1: 90.6500 | acc5: 99.7200 | loss: 0.2957
2025-08-27 22:40:07,388 - INFO -   LR: 0.001000
2025-08-27 22:40:07,441 - INFO - Checkpoint saved: epoch=169, metric=90.6500
2025-08-27 22:40:07,472 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-27 22:40:07,645 - INFO - Epoch: [170][0/391] Time 0.172 (0.172) Data 0.144 (0.144) Loss 0.1019 (0.1019) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:40:09,293 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:09,294 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:09,479 - INFO - Epoch: [170][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1347 (0.1350) Acc@1 96.094 (95.498) Acc@5 100.000 (99.915)
2025-08-27 22:40:11,255 - INFO - Epoch: [170][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1276 (0.1342) Acc@1 96.094 (95.577) Acc@5 100.000 (99.922)
2025-08-27 22:40:12,160 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:12,160 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:13,092 - INFO - Epoch: [170][300/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.1162 (0.1343) Acc@1 96.094 (95.569) Acc@5 100.000 (99.938)
2025-08-27 22:40:14,919 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2533 (0.2533) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:40:15,790 - INFO - Epoch 170:
2025-08-27 22:40:15,790 - INFO -   Train: acc1: 95.5800 | acc5: 99.9500 | loss: 0.1335 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:15,790 - INFO -   Val:   acc1: 90.5700 | acc5: 99.6900 | loss: 0.2971
2025-08-27 22:40:15,790 - INFO -   LR: 0.001000
2025-08-27 22:40:15,841 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-27 22:40:16,020 - INFO - Epoch: [171][0/391] Time 0.178 (0.178) Data 0.152 (0.152) Loss 0.1072 (0.1072) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:40:16,370 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:16,370 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:17,819 - INFO - Epoch: [171][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1444 (0.1319) Acc@1 95.312 (95.583) Acc@5 100.000 (99.977)
2025-08-27 22:40:19,268 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:19,268 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:19,669 - INFO - Epoch: [171][200/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.1952 (0.1302) Acc@1 96.875 (95.759) Acc@5 100.000 (99.957)
2025-08-27 22:40:21,452 - INFO - Epoch: [171][300/391] Time 0.019 (0.019) Data 0.009 (0.003) Loss 0.1240 (0.1289) Acc@1 97.656 (95.733) Acc@5 100.000 (99.961)
2025-08-27 22:40:22,196 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:22,196 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:23,277 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.2554 (0.2554) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:40:24,103 - INFO - Epoch 171:
2025-08-27 22:40:24,103 - INFO -   Train: acc1: 95.6480 | acc5: 99.9620 | loss: 0.1308 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:24,104 - INFO -   Val:   acc1: 90.4300 | acc5: 99.6900 | loss: 0.3003
2025-08-27 22:40:24,104 - INFO -   LR: 0.001000
2025-08-27 22:40:24,122 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-27 22:40:24,314 - INFO - Epoch: [172][0/391] Time 0.192 (0.192) Data 0.169 (0.169) Loss 0.1133 (0.1133) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:40:26,070 - INFO - Epoch: [172][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1455 (0.1256) Acc@1 92.969 (95.668) Acc@5 100.000 (99.969)
2025-08-27 22:40:26,216 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:26,217 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:27,930 - INFO - Epoch: [172][200/391] Time 0.021 (0.019) Data 0.009 (0.004) Loss 0.0804 (0.1262) Acc@1 98.438 (95.767) Acc@5 100.000 (99.957)
2025-08-27 22:40:29,069 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:29,069 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:29,678 - INFO - Epoch: [172][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.1001 (0.1302) Acc@1 96.875 (95.590) Acc@5 100.000 (99.961)
2025-08-27 22:40:31,475 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2569 (0.2569) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:40:32,339 - INFO - Epoch 172:
2025-08-27 22:40:32,340 - INFO -   Train: acc1: 95.5800 | acc5: 99.9560 | loss: 0.1298 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:32,340 - INFO -   Val:   acc1: 90.6100 | acc5: 99.7000 | loss: 0.2960
2025-08-27 22:40:32,340 - INFO -   LR: 0.001000
2025-08-27 22:40:32,356 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-27 22:40:32,556 - INFO - Epoch: [173][0/391] Time 0.199 (0.199) Data 0.172 (0.172) Loss 0.1461 (0.1461) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:40:33,163 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:33,163 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:34,288 - INFO - Epoch: [173][100/391] Time 0.039 (0.019) Data 0.027 (0.004) Loss 0.1217 (0.1275) Acc@1 95.312 (95.815) Acc@5 100.000 (99.954)
2025-08-27 22:40:36,010 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:36,010 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:36,083 - INFO - Epoch: [173][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1099 (0.1295) Acc@1 97.656 (95.647) Acc@5 100.000 (99.938)
2025-08-27 22:40:37,954 - INFO - Epoch: [173][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1496 (0.1311) Acc@1 95.312 (95.621) Acc@5 100.000 (99.945)
2025-08-27 22:40:39,003 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:39,003 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:39,779 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2406 (0.2406) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:40:40,644 - INFO - Epoch 173:
2025-08-27 22:40:40,645 - INFO -   Train: acc1: 95.5800 | acc5: 99.9380 | loss: 0.1320 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:40,645 - INFO -   Val:   acc1: 90.4500 | acc5: 99.7300 | loss: 0.2958
2025-08-27 22:40:40,645 - INFO -   LR: 0.001000
2025-08-27 22:40:40,662 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-27 22:40:40,858 - INFO - Epoch: [174][0/391] Time 0.195 (0.195) Data 0.171 (0.171) Loss 0.1413 (0.1413) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-27 22:40:42,611 - INFO - Epoch: [174][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1171 (0.1310) Acc@1 95.312 (95.645) Acc@5 100.000 (99.946)
2025-08-27 22:40:43,070 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:43,075 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:44,522 - INFO - Epoch: [174][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1495 (0.1307) Acc@1 95.312 (95.600) Acc@5 100.000 (99.938)
2025-08-27 22:40:46,107 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:46,108 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:46,365 - INFO - Epoch: [174][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.0855 (0.1321) Acc@1 97.656 (95.546) Acc@5 100.000 (99.927)
2025-08-27 22:40:48,183 - INFO - Test: [0/79] Time 0.100 (0.100) Loss 0.2593 (0.2593) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:40:49,102 - INFO - Epoch 174:
2025-08-27 22:40:49,102 - INFO -   Train: acc1: 95.5620 | acc5: 99.9260 | loss: 0.1325 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:49,102 - INFO -   Val:   acc1: 90.5200 | acc5: 99.6900 | loss: 0.2955
2025-08-27 22:40:49,102 - INFO -   LR: 0.001000
2025-08-27 22:40:49,120 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-27 22:40:49,320 - INFO - Epoch: [175][0/391] Time 0.200 (0.200) Data 0.177 (0.177) Loss 0.1870 (0.1870) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:40:50,269 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:50,269 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:51,136 - INFO - Epoch: [175][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.0984 (0.1300) Acc@1 98.438 (95.722) Acc@5 100.000 (99.923)
2025-08-27 22:40:52,979 - INFO - Epoch: [175][200/391] Time 0.022 (0.019) Data 0.009 (0.003) Loss 0.1281 (0.1301) Acc@1 95.312 (95.620) Acc@5 100.000 (99.934)
2025-08-27 22:40:53,264 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:53,264 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:54,800 - INFO - Epoch: [175][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1354 (0.1301) Acc@1 96.094 (95.627) Acc@5 100.000 (99.943)
2025-08-27 22:40:56,321 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:40:56,321 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:40:56,699 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2523 (0.2523) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:40:57,542 - INFO - Epoch 175:
2025-08-27 22:40:57,543 - INFO -   Train: acc1: 95.6580 | acc5: 99.9420 | loss: 0.1303 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:40:57,543 - INFO -   Val:   acc1: 90.2800 | acc5: 99.6700 | loss: 0.2960
2025-08-27 22:40:57,543 - INFO -   LR: 0.001000
2025-08-27 22:40:57,560 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-27 22:40:57,755 - INFO - Epoch: [176][0/391] Time 0.194 (0.194) Data 0.170 (0.170) Loss 0.1295 (0.1295) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:40:59,578 - INFO - Epoch: [176][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1629 (0.1278) Acc@1 94.531 (95.862) Acc@5 100.000 (99.985)
2025-08-27 22:41:00,329 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:00,329 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:01,354 - INFO - Epoch: [176][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1097 (0.1280) Acc@1 98.438 (95.779) Acc@5 100.000 (99.969)
2025-08-27 22:41:03,169 - INFO - Epoch: [176][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1143 (0.1300) Acc@1 96.875 (95.691) Acc@5 100.000 (99.964)
2025-08-27 22:41:03,232 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:03,232 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:04,982 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2425 (0.2425) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:41:05,829 - INFO - Epoch 176:
2025-08-27 22:41:05,829 - INFO -   Train: acc1: 95.7340 | acc5: 99.9620 | loss: 0.1289 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:05,829 - INFO -   Val:   acc1: 90.3600 | acc5: 99.6800 | loss: 0.2996
2025-08-27 22:41:05,829 - INFO -   LR: 0.001000
2025-08-27 22:41:05,845 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-27 22:41:06,047 - INFO - Epoch: [177][0/391] Time 0.200 (0.200) Data 0.174 (0.174) Loss 0.0925 (0.0925) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:41:07,383 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:07,383 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:07,901 - INFO - Epoch: [177][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1107 (0.1253) Acc@1 97.656 (95.955) Acc@5 100.000 (99.930)
2025-08-27 22:41:09,662 - INFO - Epoch: [177][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1069 (0.1237) Acc@1 96.094 (95.954) Acc@5 100.000 (99.942)
2025-08-27 22:41:10,265 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:10,266 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:11,432 - INFO - Epoch: [177][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1426 (0.1280) Acc@1 94.531 (95.754) Acc@5 100.000 (99.943)
2025-08-27 22:41:13,144 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.2444 (0.2444) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:41:13,962 - INFO - Epoch 177:
2025-08-27 22:41:13,962 - INFO -   Train: acc1: 95.7300 | acc5: 99.9520 | loss: 0.1281 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:13,962 - INFO -   Val:   acc1: 90.3700 | acc5: 99.6900 | loss: 0.3003
2025-08-27 22:41:13,962 - INFO -   LR: 0.001000
2025-08-27 22:41:13,979 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-27 22:41:14,171 - INFO - Epoch: [178][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.0898 (0.0898) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:41:14,205 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:14,212 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:16,020 - INFO - Epoch: [178][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.0899 (0.1298) Acc@1 96.875 (95.645) Acc@5 100.000 (99.969)
2025-08-27 22:41:17,098 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:17,101 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:17,762 - INFO - Epoch: [178][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1089 (0.1288) Acc@1 96.094 (95.674) Acc@5 100.000 (99.957)
2025-08-27 22:41:19,541 - INFO - Epoch: [178][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.1058 (0.1269) Acc@1 95.312 (95.715) Acc@5 100.000 (99.964)
2025-08-27 22:41:19,944 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:19,945 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:21,270 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2777 (0.2777) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:41:22,096 - INFO - Epoch 178:
2025-08-27 22:41:22,096 - INFO -   Train: acc1: 95.7280 | acc5: 99.9580 | loss: 0.1273 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:22,096 - INFO -   Val:   acc1: 90.1800 | acc5: 99.7300 | loss: 0.3037
2025-08-27 22:41:22,096 - INFO -   LR: 0.001000
2025-08-27 22:41:22,113 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-27 22:41:22,308 - INFO - Epoch: [179][0/391] Time 0.195 (0.195) Data 0.175 (0.175) Loss 0.1031 (0.1031) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:41:23,891 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:23,891 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:24,056 - INFO - Epoch: [179][100/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1109 (0.1269) Acc@1 95.312 (95.753) Acc@5 100.000 (99.946)
2025-08-27 22:41:25,884 - INFO - Epoch: [179][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1532 (0.1255) Acc@1 94.531 (95.752) Acc@5 100.000 (99.957)
2025-08-27 22:41:26,752 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:26,753 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:27,629 - INFO - Epoch: [179][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.0999 (0.1274) Acc@1 97.656 (95.720) Acc@5 100.000 (99.951)
2025-08-27 22:41:29,327 - INFO - Test: [0/79] Time 0.115 (0.115) Loss 0.2638 (0.2638) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:41:30,171 - INFO - Epoch 179:
2025-08-27 22:41:30,171 - INFO -   Train: acc1: 95.7180 | acc5: 99.9560 | loss: 0.1271 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:30,171 - INFO -   Val:   acc1: 90.4600 | acc5: 99.6900 | loss: 0.3001
2025-08-27 22:41:30,171 - INFO -   LR: 0.001000
2025-08-27 22:41:30,190 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-27 22:41:30,352 - INFO - Epoch: [180][0/391] Time 0.161 (0.161) Data 0.133 (0.133) Loss 0.2285 (0.2285) Acc@1 93.750 (93.750) Acc@5 98.438 (98.438)
2025-08-27 22:41:30,774 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:30,774 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:32,182 - INFO - Epoch: [180][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1213 (0.1287) Acc@1 95.312 (95.761) Acc@5 99.219 (99.923)
2025-08-27 22:41:33,573 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:33,573 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:33,965 - INFO - Epoch: [180][200/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.1401 (0.1278) Acc@1 96.094 (95.818) Acc@5 100.000 (99.938)
2025-08-27 22:41:35,777 - INFO - Epoch: [180][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.1265 (0.1268) Acc@1 96.875 (95.845) Acc@5 100.000 (99.948)
2025-08-27 22:41:36,441 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:36,441 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:37,539 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2572 (0.2572) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:41:38,395 - INFO - Epoch 180:
2025-08-27 22:41:38,396 - INFO -   Train: acc1: 95.8380 | acc5: 99.9540 | loss: 0.1266 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:38,396 - INFO -   Val:   acc1: 90.5100 | acc5: 99.6900 | loss: 0.2960
2025-08-27 22:41:38,396 - INFO -   LR: 0.001000
2025-08-27 22:41:38,448 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-27 22:41:38,642 - INFO - Epoch: [181][0/391] Time 0.193 (0.193) Data 0.170 (0.170) Loss 0.1498 (0.1498) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:41:40,505 - INFO - Epoch: [181][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.1298 (0.1278) Acc@1 94.531 (95.699) Acc@5 100.000 (99.938)
2025-08-27 22:41:40,700 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:40,700 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:42,341 - INFO - Epoch: [181][200/391] Time 0.032 (0.019) Data 0.005 (0.003) Loss 0.1519 (0.1248) Acc@1 94.531 (95.798) Acc@5 100.000 (99.949)
2025-08-27 22:41:43,562 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:43,562 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:44,187 - INFO - Epoch: [181][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1725 (0.1264) Acc@1 92.969 (95.769) Acc@5 99.219 (99.948)
2025-08-27 22:41:46,010 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2451 (0.2451) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:41:46,855 - INFO - Epoch 181:
2025-08-27 22:41:46,855 - INFO -   Train: acc1: 95.7920 | acc5: 99.9460 | loss: 0.1266 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:46,855 - INFO -   Val:   acc1: 90.5600 | acc5: 99.7000 | loss: 0.2996
2025-08-27 22:41:46,855 - INFO -   LR: 0.001000
2025-08-27 22:41:46,873 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-27 22:41:47,059 - INFO - Epoch: [182][0/391] Time 0.186 (0.186) Data 0.165 (0.165) Loss 0.0797 (0.0797) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:41:47,743 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:47,744 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:48,904 - INFO - Epoch: [182][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.0631 (0.1261) Acc@1 98.438 (95.877) Acc@5 100.000 (99.961)
2025-08-27 22:41:50,632 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:50,632 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:50,702 - INFO - Epoch: [182][200/391] Time 0.042 (0.019) Data 0.024 (0.003) Loss 0.1187 (0.1238) Acc@1 96.094 (95.938) Acc@5 100.000 (99.973)
2025-08-27 22:41:52,534 - INFO - Epoch: [182][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.1120 (0.1260) Acc@1 96.094 (95.834) Acc@5 100.000 (99.966)
2025-08-27 22:41:53,557 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:53,557 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:54,250 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2515 (0.2515) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:41:55,083 - INFO - Epoch 182:
2025-08-27 22:41:55,083 - INFO -   Train: acc1: 95.7240 | acc5: 99.9560 | loss: 0.1271 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:41:55,083 - INFO -   Val:   acc1: 90.5200 | acc5: 99.6900 | loss: 0.3015
2025-08-27 22:41:55,083 - INFO -   LR: 0.001000
2025-08-27 22:41:55,100 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-27 22:41:55,285 - INFO - Epoch: [183][0/391] Time 0.184 (0.184) Data 0.162 (0.162) Loss 0.1121 (0.1121) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:41:57,044 - INFO - Epoch: [183][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.1003 (0.1266) Acc@1 97.656 (95.846) Acc@5 100.000 (99.923)
2025-08-27 22:41:57,505 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:41:57,506 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:41:58,801 - INFO - Epoch: [183][200/391] Time 0.024 (0.018) Data 0.000 (0.004) Loss 0.1498 (0.1271) Acc@1 92.188 (95.798) Acc@5 100.000 (99.942)
2025-08-27 22:42:00,355 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:00,368 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:00,579 - INFO - Epoch: [183][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1062 (0.1277) Acc@1 96.094 (95.762) Acc@5 100.000 (99.930)
2025-08-27 22:42:02,269 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.2451 (0.2451) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:42:03,117 - INFO - Epoch 183:
2025-08-27 22:42:03,117 - INFO -   Train: acc1: 95.7360 | acc5: 99.9380 | loss: 0.1286 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:03,117 - INFO -   Val:   acc1: 90.2100 | acc5: 99.7000 | loss: 0.3022
2025-08-27 22:42:03,117 - INFO -   LR: 0.001000
2025-08-27 22:42:03,134 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-27 22:42:03,322 - INFO - Epoch: [184][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.1411 (0.1411) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:42:04,292 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:04,292 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:05,130 - INFO - Epoch: [184][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1827 (0.1195) Acc@1 92.188 (96.040) Acc@5 100.000 (99.969)
2025-08-27 22:42:06,906 - INFO - Epoch: [184][200/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.0778 (0.1230) Acc@1 97.656 (95.950) Acc@5 100.000 (99.965)
2025-08-27 22:42:07,157 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:07,157 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:08,643 - INFO - Epoch: [184][300/391] Time 0.019 (0.018) Data 0.009 (0.003) Loss 0.1650 (0.1232) Acc@1 95.312 (95.899) Acc@5 100.000 (99.964)
2025-08-27 22:42:09,943 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:09,943 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:10,390 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2656 (0.2656) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:42:11,210 - INFO - Epoch 184:
2025-08-27 22:42:11,210 - INFO -   Train: acc1: 95.8660 | acc5: 99.9600 | loss: 0.1237 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:11,210 - INFO -   Val:   acc1: 90.3600 | acc5: 99.6700 | loss: 0.3014
2025-08-27 22:42:11,210 - INFO -   LR: 0.001000
2025-08-27 22:42:11,242 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-27 22:42:11,413 - INFO - Epoch: [185][0/391] Time 0.171 (0.171) Data 0.143 (0.143) Loss 0.2333 (0.2333) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:42:13,250 - INFO - Epoch: [185][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.1224 (0.1244) Acc@1 96.094 (95.924) Acc@5 100.000 (99.923)
2025-08-27 22:42:14,017 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:14,017 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:14,995 - INFO - Epoch: [185][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1022 (0.1236) Acc@1 96.875 (95.907) Acc@5 100.000 (99.934)
2025-08-27 22:42:16,807 - INFO - Epoch: [185][300/391] Time 0.016 (0.018) Data 0.000 (0.003) Loss 0.1907 (0.1249) Acc@1 93.750 (95.855) Acc@5 100.000 (99.927)
2025-08-27 22:42:16,865 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:16,865 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:18,521 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2609 (0.2609) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 22:42:19,346 - INFO - Epoch 185:
2025-08-27 22:42:19,346 - INFO -   Train: acc1: 95.8400 | acc5: 99.9380 | loss: 0.1253 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:19,346 - INFO -   Val:   acc1: 90.4700 | acc5: 99.6600 | loss: 0.3035
2025-08-27 22:42:19,346 - INFO -   LR: 0.001000
2025-08-27 22:42:19,363 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-27 22:42:19,540 - INFO - Epoch: [186][0/391] Time 0.177 (0.177) Data 0.158 (0.158) Loss 0.1288 (0.1288) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:42:20,850 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:20,850 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:21,338 - INFO - Epoch: [186][100/391] Time 0.025 (0.020) Data 0.000 (0.004) Loss 0.1044 (0.1187) Acc@1 96.094 (96.086) Acc@5 100.000 (99.961)
2025-08-27 22:42:23,106 - INFO - Epoch: [186][200/391] Time 0.024 (0.019) Data 0.012 (0.003) Loss 0.1201 (0.1209) Acc@1 96.094 (96.063) Acc@5 100.000 (99.961)
2025-08-27 22:42:23,738 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:23,738 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:24,913 - INFO - Epoch: [186][300/391] Time 0.024 (0.018) Data 0.000 (0.003) Loss 0.1180 (0.1240) Acc@1 94.531 (95.938) Acc@5 100.000 (99.958)
2025-08-27 22:42:26,688 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2628 (0.2628) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:42:27,516 - INFO - Epoch 186:
2025-08-27 22:42:27,516 - INFO -   Train: acc1: 95.9700 | acc5: 99.9480 | loss: 0.1245 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:27,516 - INFO -   Val:   acc1: 90.5500 | acc5: 99.6900 | loss: 0.3020
2025-08-27 22:42:27,516 - INFO -   LR: 0.001000
2025-08-27 22:42:27,534 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-27 22:42:27,720 - INFO - Epoch: [187][0/391] Time 0.184 (0.184) Data 0.164 (0.164) Loss 0.1157 (0.1157) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:42:27,774 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:27,775 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:29,508 - INFO - Epoch: [187][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1843 (0.1220) Acc@1 92.188 (96.086) Acc@5 100.000 (99.969)
2025-08-27 22:42:30,643 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:30,643 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:31,306 - INFO - Epoch: [187][200/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.1578 (0.1250) Acc@1 93.750 (95.958) Acc@5 100.000 (99.961)
2025-08-27 22:42:33,148 - INFO - Epoch: [187][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.0601 (0.1264) Acc@1 98.438 (95.873) Acc@5 100.000 (99.958)
2025-08-27 22:42:33,568 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:33,577 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:34,913 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2680 (0.2680) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:42:35,780 - INFO - Epoch 187:
2025-08-27 22:42:35,781 - INFO -   Train: acc1: 95.8680 | acc5: 99.9500 | loss: 0.1261 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:35,781 - INFO -   Val:   acc1: 90.6000 | acc5: 99.7200 | loss: 0.3040
2025-08-27 22:42:35,781 - INFO -   LR: 0.001000
2025-08-27 22:42:35,799 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-27 22:42:35,995 - INFO - Epoch: [188][0/391] Time 0.194 (0.194) Data 0.176 (0.176) Loss 0.1268 (0.1268) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:42:37,665 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:37,665 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:37,777 - INFO - Epoch: [188][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1008 (0.1266) Acc@1 96.875 (95.823) Acc@5 100.000 (99.946)
2025-08-27 22:42:39,622 - INFO - Epoch: [188][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1750 (0.1260) Acc@1 95.312 (95.872) Acc@5 100.000 (99.953)
2025-08-27 22:42:40,610 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:40,610 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:41,470 - INFO - Epoch: [188][300/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.0921 (0.1252) Acc@1 96.875 (95.868) Acc@5 100.000 (99.948)
2025-08-27 22:42:43,284 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2538 (0.2538) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:42:44,136 - INFO - Epoch 188:
2025-08-27 22:42:44,136 - INFO -   Train: acc1: 95.8340 | acc5: 99.9520 | loss: 0.1252 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:44,136 - INFO -   Val:   acc1: 90.2100 | acc5: 99.6600 | loss: 0.3098
2025-08-27 22:42:44,136 - INFO -   LR: 0.001000
2025-08-27 22:42:44,154 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-27 22:42:44,347 - INFO - Epoch: [189][0/391] Time 0.192 (0.192) Data 0.169 (0.169) Loss 0.0960 (0.0960) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:42:44,779 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:44,780 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:46,172 - INFO - Epoch: [189][100/391] Time 0.022 (0.020) Data 0.009 (0.003) Loss 0.1576 (0.1227) Acc@1 94.531 (95.808) Acc@5 100.000 (99.961)
2025-08-27 22:42:47,595 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:47,596 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:47,973 - INFO - Epoch: [189][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1509 (0.1231) Acc@1 94.531 (95.767) Acc@5 100.000 (99.957)
2025-08-27 22:42:49,805 - INFO - Epoch: [189][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.1510 (0.1225) Acc@1 92.969 (95.894) Acc@5 100.000 (99.956)
2025-08-27 22:42:50,528 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:50,528 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:51,615 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2668 (0.2668) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:42:52,470 - INFO - Epoch 189:
2025-08-27 22:42:52,470 - INFO -   Train: acc1: 95.8600 | acc5: 99.9540 | loss: 0.1234 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:42:52,470 - INFO -   Val:   acc1: 90.5100 | acc5: 99.6800 | loss: 0.3075
2025-08-27 22:42:52,470 - INFO -   LR: 0.001000
2025-08-27 22:42:52,491 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-27 22:42:52,681 - INFO - Epoch: [190][0/391] Time 0.188 (0.188) Data 0.157 (0.157) Loss 0.1294 (0.1294) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:42:54,501 - INFO - Epoch: [190][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2006 (0.1314) Acc@1 92.188 (95.591) Acc@5 100.000 (99.938)
2025-08-27 22:42:54,639 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:54,639 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:56,270 - INFO - Epoch: [190][200/391] Time 0.024 (0.019) Data 0.010 (0.003) Loss 0.1171 (0.1294) Acc@1 96.875 (95.666) Acc@5 100.000 (99.938)
2025-08-27 22:42:57,550 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:42:57,557 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:42:58,132 - INFO - Epoch: [190][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0940 (0.1270) Acc@1 97.656 (95.746) Acc@5 100.000 (99.945)
2025-08-27 22:42:59,917 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.2799 (0.2799) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:43:00,788 - INFO - Epoch 190:
2025-08-27 22:43:00,789 - INFO -   Train: acc1: 95.7600 | acc5: 99.9540 | loss: 0.1264 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:00,789 - INFO -   Val:   acc1: 90.5200 | acc5: 99.7400 | loss: 0.3035
2025-08-27 22:43:00,789 - INFO -   LR: 0.001000
2025-08-27 22:43:00,844 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-27 22:43:01,031 - INFO - Epoch: [191][0/391] Time 0.186 (0.186) Data 0.162 (0.162) Loss 0.1453 (0.1453) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:43:01,704 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:01,706 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:02,816 - INFO - Epoch: [191][100/391] Time 0.022 (0.020) Data 0.007 (0.004) Loss 0.0997 (0.1205) Acc@1 96.875 (96.024) Acc@5 100.000 (99.954)
2025-08-27 22:43:04,683 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:04,683 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:04,729 - INFO - Epoch: [191][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.0898 (0.1219) Acc@1 97.656 (95.985) Acc@5 100.000 (99.946)
2025-08-27 22:43:06,492 - INFO - Epoch: [191][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1524 (0.1188) Acc@1 93.750 (96.013) Acc@5 100.000 (99.951)
2025-08-27 22:43:07,574 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:07,574 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:08,297 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.2669 (0.2669) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:43:09,162 - INFO - Epoch 191:
2025-08-27 22:43:09,162 - INFO -   Train: acc1: 95.9600 | acc5: 99.9560 | loss: 0.1206 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:09,162 - INFO -   Val:   acc1: 90.3200 | acc5: 99.6800 | loss: 0.3114
2025-08-27 22:43:09,162 - INFO -   LR: 0.001000
2025-08-27 22:43:09,180 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-27 22:43:09,399 - INFO - Epoch: [192][0/391] Time 0.218 (0.218) Data 0.192 (0.192) Loss 0.0682 (0.0682) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-27 22:43:11,123 - INFO - Epoch: [192][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1360 (0.1208) Acc@1 93.750 (95.993) Acc@5 100.000 (99.969)
2025-08-27 22:43:11,685 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:11,685 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:13,028 - INFO - Epoch: [192][200/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.1526 (0.1208) Acc@1 94.531 (95.931) Acc@5 100.000 (99.969)
2025-08-27 22:43:14,620 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:14,620 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:14,839 - INFO - Epoch: [192][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.0990 (0.1207) Acc@1 96.094 (95.951) Acc@5 100.000 (99.961)
2025-08-27 22:43:16,619 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2380 (0.2380) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:43:17,506 - INFO - Epoch 192:
2025-08-27 22:43:17,506 - INFO -   Train: acc1: 95.8680 | acc5: 99.9540 | loss: 0.1229 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:17,507 - INFO -   Val:   acc1: 90.5200 | acc5: 99.6400 | loss: 0.3075
2025-08-27 22:43:17,507 - INFO -   LR: 0.001000
2025-08-27 22:43:17,526 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-27 22:43:17,718 - INFO - Epoch: [193][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.1317 (0.1317) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:43:18,751 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:18,751 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:19,590 - INFO - Epoch: [193][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1354 (0.1181) Acc@1 94.531 (96.016) Acc@5 100.000 (99.946)
2025-08-27 22:43:21,391 - INFO - Epoch: [193][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1447 (0.1204) Acc@1 95.312 (95.965) Acc@5 100.000 (99.961)
2025-08-27 22:43:21,699 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:21,700 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:23,169 - INFO - Epoch: [193][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1191 (0.1206) Acc@1 96.094 (95.941) Acc@5 100.000 (99.966)
2025-08-27 22:43:24,593 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:24,593 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:24,966 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2470 (0.2470) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:43:25,847 - INFO - Epoch 193:
2025-08-27 22:43:25,847 - INFO -   Train: acc1: 95.9460 | acc5: 99.9600 | loss: 0.1208 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:25,847 - INFO -   Val:   acc1: 90.4100 | acc5: 99.7000 | loss: 0.3074
2025-08-27 22:43:25,847 - INFO -   LR: 0.001000
2025-08-27 22:43:25,866 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-27 22:43:26,065 - INFO - Epoch: [194][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.1328 (0.1328) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 22:43:27,856 - INFO - Epoch: [194][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.1204 (0.1229) Acc@1 96.875 (95.869) Acc@5 100.000 (99.954)
2025-08-27 22:43:28,668 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:28,668 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:29,627 - INFO - Epoch: [194][200/391] Time 0.019 (0.019) Data 0.008 (0.004) Loss 0.1005 (0.1235) Acc@1 96.875 (95.728) Acc@5 100.000 (99.949)
2025-08-27 22:43:31,491 - INFO - Epoch: [194][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1026 (0.1232) Acc@1 96.875 (95.803) Acc@5 100.000 (99.951)
2025-08-27 22:43:31,580 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:31,580 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:33,222 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2369 (0.2369) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:43:34,102 - INFO - Epoch 194:
2025-08-27 22:43:34,102 - INFO -   Train: acc1: 95.8780 | acc5: 99.9540 | loss: 0.1222 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:34,102 - INFO -   Val:   acc1: 90.4100 | acc5: 99.7400 | loss: 0.3100
2025-08-27 22:43:34,102 - INFO -   LR: 0.001000
2025-08-27 22:43:34,124 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-27 22:43:34,322 - INFO - Epoch: [195][0/391] Time 0.198 (0.198) Data 0.179 (0.179) Loss 0.1117 (0.1117) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:43:35,706 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:35,706 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:36,161 - INFO - Epoch: [195][100/391] Time 0.013 (0.020) Data 0.000 (0.006) Loss 0.0591 (0.1148) Acc@1 98.438 (96.140) Acc@5 100.000 (99.938)
2025-08-27 22:43:38,002 - INFO - Epoch: [195][200/391] Time 0.020 (0.019) Data 0.000 (0.005) Loss 0.1215 (0.1176) Acc@1 95.312 (96.063) Acc@5 99.219 (99.938)
2025-08-27 22:43:38,600 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:38,600 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:39,793 - INFO - Epoch: [195][300/391] Time 0.030 (0.019) Data 0.019 (0.005) Loss 0.0969 (0.1203) Acc@1 96.875 (95.933) Acc@5 100.000 (99.935)
2025-08-27 22:43:41,571 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2666 (0.2666) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:43:42,429 - INFO - Epoch 195:
2025-08-27 22:43:42,429 - INFO -   Train: acc1: 95.9260 | acc5: 99.9460 | loss: 0.1210 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:42,429 - INFO -   Val:   acc1: 90.5100 | acc5: 99.7200 | loss: 0.3069
2025-08-27 22:43:42,429 - INFO -   LR: 0.001000
2025-08-27 22:43:42,448 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-27 22:43:42,645 - INFO - Epoch: [196][0/391] Time 0.196 (0.196) Data 0.165 (0.165) Loss 0.1523 (0.1523) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:43:42,689 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:42,689 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:44,467 - INFO - Epoch: [196][100/391] Time 0.017 (0.020) Data 0.000 (0.005) Loss 0.1010 (0.1176) Acc@1 96.875 (96.303) Acc@5 100.000 (99.946)
2025-08-27 22:43:45,619 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:45,626 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:46,307 - INFO - Epoch: [196][200/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.0924 (0.1182) Acc@1 96.094 (96.210) Acc@5 100.000 (99.961)
2025-08-27 22:43:48,102 - INFO - Epoch: [196][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1363 (0.1189) Acc@1 96.094 (96.133) Acc@5 100.000 (99.966)
2025-08-27 22:43:48,545 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:48,546 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:49,906 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2862 (0.2862) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:43:50,731 - INFO - Epoch 196:
2025-08-27 22:43:50,731 - INFO -   Train: acc1: 96.1220 | acc5: 99.9720 | loss: 0.1200 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:50,731 - INFO -   Val:   acc1: 90.2700 | acc5: 99.6600 | loss: 0.3170
2025-08-27 22:43:50,731 - INFO -   LR: 0.001000
2025-08-27 22:43:50,750 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-27 22:43:50,936 - INFO - Epoch: [197][0/391] Time 0.186 (0.186) Data 0.161 (0.161) Loss 0.1373 (0.1373) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:43:52,623 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:52,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:52,747 - INFO - Epoch: [197][100/391] Time 0.015 (0.020) Data 0.002 (0.003) Loss 0.1335 (0.1265) Acc@1 94.531 (95.684) Acc@5 100.000 (99.961)
2025-08-27 22:43:54,577 - INFO - Epoch: [197][200/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.1055 (0.1223) Acc@1 96.875 (95.853) Acc@5 100.000 (99.949)
2025-08-27 22:43:55,531 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:55,531 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:43:56,378 - INFO - Epoch: [197][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.1105 (0.1210) Acc@1 94.531 (95.886) Acc@5 100.000 (99.951)
2025-08-27 22:43:58,219 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2642 (0.2642) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:43:59,090 - INFO - Epoch 197:
2025-08-27 22:43:59,090 - INFO -   Train: acc1: 95.9400 | acc5: 99.9540 | loss: 0.1204 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:43:59,090 - INFO -   Val:   acc1: 90.2700 | acc5: 99.7000 | loss: 0.3144
2025-08-27 22:43:59,090 - INFO -   LR: 0.001000
2025-08-27 22:43:59,110 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-27 22:43:59,315 - INFO - Epoch: [198][0/391] Time 0.204 (0.204) Data 0.185 (0.185) Loss 0.1187 (0.1187) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 22:43:59,731 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:43:59,731 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:01,157 - INFO - Epoch: [198][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.0703 (0.1154) Acc@1 99.219 (96.171) Acc@5 100.000 (99.961)
2025-08-27 22:44:02,623 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:44:02,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:02,973 - INFO - Epoch: [198][200/391] Time 0.029 (0.019) Data 0.018 (0.003) Loss 0.1127 (0.1208) Acc@1 96.875 (95.977) Acc@5 100.000 (99.946)
2025-08-27 22:44:04,839 - INFO - Epoch: [198][300/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.1336 (0.1190) Acc@1 95.312 (95.990) Acc@5 100.000 (99.956)
2025-08-27 22:44:05,613 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:44:05,614 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:06,595 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2405 (0.2405) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:44:07,504 - INFO - Epoch 198:
2025-08-27 22:44:07,504 - INFO -   Train: acc1: 96.0160 | acc5: 99.9620 | loss: 0.1193 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:44:07,505 - INFO -   Val:   acc1: 90.3100 | acc5: 99.6900 | loss: 0.3128
2025-08-27 22:44:07,505 - INFO -   LR: 0.001000
2025-08-27 22:44:07,524 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-27 22:44:07,717 - INFO - Epoch: [199][0/391] Time 0.192 (0.192) Data 0.175 (0.175) Loss 0.0757 (0.0757) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 22:44:09,484 - INFO - Epoch: [199][100/391] Time 0.024 (0.019) Data 0.012 (0.004) Loss 0.1614 (0.1157) Acc@1 94.531 (96.163) Acc@5 100.000 (99.992)
2025-08-27 22:44:09,667 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:44:09,667 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:11,251 - INFO - Epoch: [199][200/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.0920 (0.1181) Acc@1 97.656 (95.993) Acc@5 100.000 (99.981)
2025-08-27 22:44:12,517 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:44:12,517 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:13,063 - INFO - Epoch: [199][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.1447 (0.1204) Acc@1 93.750 (95.938) Acc@5 100.000 (99.974)
2025-08-27 22:44:14,846 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.2857 (0.2857) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:44:15,705 - INFO - Epoch 199:
2025-08-27 22:44:15,705 - INFO -   Train: acc1: 95.9200 | acc5: 99.9740 | loss: 0.1221 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-27 22:44:15,705 - INFO -   Val:   acc1: 90.3400 | acc5: 99.7000 | loss: 0.3098
2025-08-27 22:44:15,705 - INFO -   LR: 0.001000
2025-08-27 22:44:15,724 - INFO - training time: 00h 27m 37.83s
2025-08-27 22:44:15,724 - INFO - 
Training completed!
2025-08-27 22:44:15,724 - INFO - Best accuracy: 90.6500
2025-08-27 22:44:15,725 - INFO - Total training time: 0.46 hours
2025-08-27 22:44:15,725 - INFO - total_experiment time: 00h 27m 39.06s
2025-08-27 22:44:15,737 - INFO - Experiment completed successfully
2025-08-27 22:44:15,737 - INFO - Total time: 0.46 hours
