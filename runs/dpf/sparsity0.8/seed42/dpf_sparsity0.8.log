2025-08-28 01:38:01,436 - INFO - Starting experiment: dpf_sparsity0.8
2025-08-28 01:38:01,436 - INFO - Save directory: ./runs/dpf/sparsity0.8/seed42
2025-08-28 01:38:01,436 - INFO - Hyperparameters:
2025-08-28 01:38:01,436 - INFO -   name: dpf_sparsity0.8
2025-08-28 01:38:01,436 - INFO -   description: 
2025-08-28 01:38:01,437 - INFO -   save_dir: ./runs
2025-08-28 01:38:01,437 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 01:38:01,437 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 01:38:01,437 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 01:38:01,437 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.8, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 01:38:01,437 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 01:38:01,437 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 01:38:01,472 - INFO - System Information:
2025-08-28 01:38:01,472 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 01:38:01,472 - INFO -   python_version: 3.9.18
2025-08-28 01:38:01,472 - INFO -   pytorch_version: 2.1.0
2025-08-28 01:38:01,472 - INFO -   cuda_available: True
2025-08-28 01:38:01,472 - INFO -   cpu_count: 4
2025-08-28 01:38:01,472 - INFO -   memory_total_gb: 11.0
2025-08-28 01:38:01,472 - INFO -   timestamp: 1756312681.472078
2025-08-28 01:38:01,472 - INFO -   cuda_version: 11.8
2025-08-28 01:38:01,472 - INFO -   gpu_count: 1
2025-08-28 01:38:01,472 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 01:38:01,479 - INFO - Starting experiment: dpf_sparsity0.8
2025-08-28 01:38:01,479 - INFO - Model: resnet-20
2025-08-28 01:38:01,479 - INFO - Dataset: cifar10
2025-08-28 01:38:01,479 - INFO - Pruning: dpf (80.00%)
2025-08-28 01:38:01,615 - INFO - Model Information:
2025-08-28 01:38:01,615 - INFO -   Type: pruned
2025-08-28 01:38:01,615 - INFO -   Total parameters: 544,948
2025-08-28 01:38:01,615 - INFO -   Trainable parameters: 274,692
2025-08-28 01:38:01,615 - INFO -   Sparsity: 80.00%
2025-08-28 01:38:02,643 - INFO - Starting training...
2025-08-28 01:38:02,643 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 01:38:03,312 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:38:03,312 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:38:03,819 - INFO - Epoch: [0][0/391] Time 1.175 (1.175) Data 0.532 (0.532) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 01:38:05,641 - INFO - Epoch: [0][100/391] Time 0.011 (0.030) Data 0.000 (0.007) Loss 1.7128 (1.9198) Acc@1 39.844 (26.787) Acc@5 88.281 (81.714)
2025-08-28 01:38:06,744 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:38:06,744 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:38:07,518 - INFO - Epoch: [0][200/391] Time 0.015 (0.024) Data 0.001 (0.005) Loss 1.4662 (1.7709) Acc@1 39.844 (32.906) Acc@5 93.750 (86.074)
2025-08-28 01:38:09,402 - INFO - Epoch: [0][300/391] Time 0.014 (0.022) Data 0.000 (0.004) Loss 1.3557 (1.6714) Acc@1 51.562 (37.230) Acc@5 95.312 (88.177)
2025-08-28 01:38:09,704 - INFO - Pruning info: sparsity=0.000
2025-08-28 01:38:09,704 - INFO -   Reactivation rate: 0.0000
2025-08-28 01:38:11,343 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 1.6348 (1.6348) Acc@1 46.875 (46.875) Acc@5 93.750 (93.750)
2025-08-28 05:38:10,913 - INFO - Starting experiment: dpf_sparsity0.8
2025-08-28 05:38:10,913 - INFO - Save directory: ./runs/dpf/sparsity0.8/seed42
2025-08-28 05:38:10,913 - INFO - Hyperparameters:
2025-08-28 05:38:10,913 - INFO -   name: dpf_sparsity0.8
2025-08-28 05:38:10,913 - INFO -   description: 
2025-08-28 05:38:10,913 - INFO -   save_dir: ./runs
2025-08-28 05:38:10,913 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 05:38:10,913 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 05:38:10,913 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 05:38:10,913 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.8, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 05:38:10,913 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 05:38:10,913 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 05:38:10,947 - INFO - System Information:
2025-08-28 05:38:10,947 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 05:38:10,947 - INFO -   python_version: 3.9.18
2025-08-28 05:38:10,947 - INFO -   pytorch_version: 2.1.0
2025-08-28 05:38:10,947 - INFO -   cuda_available: True
2025-08-28 05:38:10,947 - INFO -   cpu_count: 4
2025-08-28 05:38:10,947 - INFO -   memory_total_gb: 11.0
2025-08-28 05:38:10,947 - INFO -   timestamp: 1756327090.9472542
2025-08-28 05:38:10,947 - INFO -   cuda_version: 11.8
2025-08-28 05:38:10,947 - INFO -   gpu_count: 1
2025-08-28 05:38:10,947 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 05:38:10,954 - INFO - Starting experiment: dpf_sparsity0.8
2025-08-28 05:38:10,954 - INFO - Model: resnet-20
2025-08-28 05:38:10,954 - INFO - Dataset: cifar10
2025-08-28 05:38:10,954 - INFO - Pruning: dpf (80.00%)
2025-08-28 05:38:11,119 - INFO - Model Information:
2025-08-28 05:38:11,119 - INFO -   Type: pruned
2025-08-28 05:38:11,119 - INFO -   Total parameters: 544,948
2025-08-28 05:38:11,119 - INFO -   Trainable parameters: 274,692
2025-08-28 05:38:11,119 - INFO -   Sparsity: 80.00%
2025-08-28 05:38:12,168 - INFO - Starting training...
2025-08-28 05:38:12,168 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 05:38:12,911 - INFO - Pruning info: sparsity=0.000
2025-08-28 05:38:12,912 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:38:13,555 - INFO - Epoch: [0][0/391] Time 1.386 (1.386) Data 0.547 (0.547) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 05:38:15,431 - INFO - Epoch: [0][100/391] Time 0.012 (0.032) Data 0.000 (0.008) Loss 1.6914 (1.9312) Acc@1 38.281 (26.122) Acc@5 87.500 (81.389)
2025-08-28 05:38:16,460 - INFO - Pruning info: sparsity=0.000
2025-08-28 05:38:16,460 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:38:17,177 - INFO - Epoch: [0][200/391] Time 0.011 (0.025) Data 0.000 (0.005) Loss 1.4822 (1.7763) Acc@1 46.875 (32.478) Acc@5 93.750 (85.494)
2025-08-28 05:38:18,951 - INFO - Epoch: [0][300/391] Time 0.019 (0.023) Data 0.000 (0.004) Loss 1.3619 (1.6653) Acc@1 49.219 (37.370) Acc@5 94.531 (87.757)
2025-08-28 05:38:19,252 - INFO - Pruning info: sparsity=0.000
2025-08-28 05:38:19,252 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:38:20,863 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 1.5608 (1.5608) Acc@1 46.875 (46.875) Acc@5 92.188 (92.188)
2025-08-28 05:38:21,786 - INFO - Epoch 0:
2025-08-28 05:38:21,786 - INFO -   Train: acc1: 40.7920 | acc5: 89.1460 | loss: 1.5844 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 05:38:21,786 - INFO -   Val:   acc1: 45.3100 | acc5: 92.7000 | loss: 1.5778
2025-08-28 05:38:21,786 - INFO -   LR: 0.100000
2025-08-28 05:38:21,830 - INFO - Checkpoint saved: epoch=0, metric=45.3100
2025-08-28 05:38:21,860 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 05:38:22,059 - INFO - Epoch: [1][0/391] Time 0.198 (0.198) Data 0.161 (0.161) Loss 1.4714 (1.4714) Acc@1 48.438 (48.438) Acc@5 91.406 (91.406)
2025-08-28 05:38:23,641 - INFO - Pruning info: sparsity=0.032
2025-08-28 05:38:23,641 - INFO -   Reactivation rate: 0.0085
2025-08-28 05:38:23,821 - INFO - Epoch: [1][100/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 1.1182 (1.1876) Acc@1 57.031 (57.000) Acc@5 96.094 (95.305)
2025-08-28 05:38:25,608 - INFO - Epoch: [1][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.9553 (1.1412) Acc@1 66.406 (58.718) Acc@5 97.656 (95.670)
2025-08-28 05:38:26,465 - INFO - Pruning info: sparsity=0.032
2025-08-28 05:38:26,465 - INFO -   Reactivation rate: 0.0058
2025-08-28 05:38:27,383 - INFO - Epoch: [1][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 1.0629 (1.1083) Acc@1 60.938 (60.151) Acc@5 94.531 (95.954)
2025-08-28 05:38:29,088 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 1.2380 (1.2380) Acc@1 56.250 (56.250) Acc@5 95.312 (95.312)
2025-08-28 05:38:29,982 - INFO - Epoch 1:
2025-08-28 05:38:29,983 - INFO -   Train: acc1: 61.2600 | acc5: 96.1740 | loss: 1.0801 | sparsity: 0.0316 | reactivation_rate: 0.0066
2025-08-28 05:38:29,983 - INFO -   Val:   acc1: 57.5000 | acc5: 94.4900 | loss: 1.3228
2025-08-28 05:38:29,983 - INFO -   LR: 0.100000
2025-08-28 05:38:30,026 - INFO - Checkpoint saved: epoch=1, metric=57.5000
2025-08-28 05:38:30,058 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 05:38:30,232 - INFO - Epoch: [2][0/391] Time 0.173 (0.173) Data 0.139 (0.139) Loss 0.9486 (0.9486) Acc@1 69.531 (69.531) Acc@5 97.656 (97.656)
2025-08-28 05:38:30,508 - INFO - Pruning info: sparsity=0.062
2025-08-28 05:38:30,508 - INFO -   Reactivation rate: 0.0127
2025-08-28 05:38:32,089 - INFO - Epoch: [2][100/391] Time 0.036 (0.020) Data 0.022 (0.004) Loss 0.8915 (0.9443) Acc@1 71.094 (66.097) Acc@5 96.094 (96.960)
2025-08-28 05:38:33,442 - INFO - Pruning info: sparsity=0.062
2025-08-28 05:38:33,442 - INFO -   Reactivation rate: 0.0072
2025-08-28 05:38:33,899 - INFO - Epoch: [2][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.8319 (0.9162) Acc@1 70.312 (67.281) Acc@5 99.219 (97.260)
2025-08-28 05:38:35,697 - INFO - Epoch: [2][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.8497 (0.8992) Acc@1 71.875 (68.187) Acc@5 98.438 (97.397)
2025-08-28 05:38:36,372 - INFO - Pruning info: sparsity=0.062
2025-08-28 05:38:36,372 - INFO -   Reactivation rate: 0.0054
2025-08-28 05:38:37,415 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 1.3830 (1.3830) Acc@1 60.156 (60.156) Acc@5 92.969 (92.969)
2025-08-28 05:38:38,242 - INFO - Epoch 2:
2025-08-28 05:38:38,242 - INFO -   Train: acc1: 68.8280 | acc5: 97.4500 | loss: 0.8811 | sparsity: 0.0623 | reactivation_rate: 0.0072
2025-08-28 05:38:38,242 - INFO -   Val:   acc1: 57.6400 | acc5: 93.4600 | loss: 1.4396
2025-08-28 05:38:38,242 - INFO -   LR: 0.100000
2025-08-28 05:38:38,285 - INFO - Checkpoint saved: epoch=2, metric=57.6400
2025-08-28 05:38:38,316 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 05:38:38,505 - INFO - Epoch: [3][0/391] Time 0.189 (0.189) Data 0.150 (0.150) Loss 0.8549 (0.8549) Acc@1 68.750 (68.750) Acc@5 96.875 (96.875)
2025-08-28 05:38:40,249 - INFO - Epoch: [3][100/391] Time 0.012 (0.019) Data 0.001 (0.004) Loss 0.8331 (0.7692) Acc@1 67.969 (73.190) Acc@5 95.312 (98.120)
2025-08-28 05:38:40,384 - INFO - Pruning info: sparsity=0.092
2025-08-28 05:38:40,384 - INFO -   Reactivation rate: 0.0085
2025-08-28 05:38:42,050 - INFO - Epoch: [3][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.6918 (0.7615) Acc@1 75.781 (73.457) Acc@5 98.438 (98.197)
2025-08-28 05:38:43,229 - INFO - Pruning info: sparsity=0.092
2025-08-28 05:38:43,229 - INFO -   Reactivation rate: 0.0061
2025-08-28 05:38:43,862 - INFO - Epoch: [3][300/391] Time 0.024 (0.018) Data 0.000 (0.003) Loss 0.7651 (0.7595) Acc@1 74.219 (73.562) Acc@5 99.219 (98.170)
2025-08-28 05:38:45,632 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.8526 (0.8526) Acc@1 71.094 (71.094) Acc@5 98.438 (98.438)
2025-08-28 05:38:46,530 - INFO - Epoch 3:
2025-08-28 05:38:46,531 - INFO -   Train: acc1: 73.7080 | acc5: 98.2060 | loss: 0.7565 | sparsity: 0.0922 | reactivation_rate: 0.0072
2025-08-28 05:38:46,531 - INFO -   Val:   acc1: 70.4900 | acc5: 97.7100 | loss: 0.8827
2025-08-28 05:38:46,531 - INFO -   LR: 0.100000
2025-08-28 05:38:46,574 - INFO - Checkpoint saved: epoch=3, metric=70.4900
2025-08-28 05:38:46,605 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 05:38:46,817 - INFO - Epoch: [4][0/391] Time 0.211 (0.211) Data 0.189 (0.189) Loss 0.6620 (0.6620) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 05:38:47,487 - INFO - Pruning info: sparsity=0.121
2025-08-28 05:38:47,488 - INFO -   Reactivation rate: 0.0119
2025-08-28 05:38:48,712 - INFO - Epoch: [4][100/391] Time 0.017 (0.021) Data 0.000 (0.006) Loss 0.7653 (0.7137) Acc@1 77.344 (75.023) Acc@5 96.875 (98.314)
2025-08-28 05:38:50,429 - INFO - Pruning info: sparsity=0.121
2025-08-28 05:38:50,429 - INFO -   Reactivation rate: 0.0066
2025-08-28 05:38:50,509 - INFO - Epoch: [4][200/391] Time 0.013 (0.019) Data 0.000 (0.005) Loss 0.6391 (0.6979) Acc@1 77.344 (75.824) Acc@5 100.000 (98.399)
2025-08-28 05:38:52,338 - INFO - Epoch: [4][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.7128 (0.6948) Acc@1 71.094 (76.010) Acc@5 98.438 (98.419)
2025-08-28 05:38:53,426 - INFO - Pruning info: sparsity=0.121
2025-08-28 05:38:53,427 - INFO -   Reactivation rate: 0.0050
2025-08-28 05:38:54,202 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 1.2713 (1.2713) Acc@1 57.812 (57.812) Acc@5 92.969 (92.969)
2025-08-28 05:38:55,089 - INFO - Epoch 4:
2025-08-28 05:38:55,089 - INFO -   Train: acc1: 76.0780 | acc5: 98.4640 | loss: 0.6897 | sparsity: 0.1213 | reactivation_rate: 0.0071
2025-08-28 05:38:55,089 - INFO -   Val:   acc1: 61.9500 | acc5: 94.8100 | loss: 1.2526
2025-08-28 05:38:55,089 - INFO -   LR: 0.100000
2025-08-28 05:38:55,100 - INFO - 
Epoch: 5, lr = 0.1
2025-08-28 05:38:55,297 - INFO - Epoch: [5][0/391] Time 0.196 (0.196) Data 0.178 (0.178) Loss 0.7409 (0.7409) Acc@1 71.875 (71.875) Acc@5 99.219 (99.219)
2025-08-28 05:38:57,236 - INFO - Epoch: [5][100/391] Time 0.031 (0.021) Data 0.000 (0.003) Loss 0.6139 (0.6807) Acc@1 78.125 (76.183) Acc@5 100.000 (98.600)
2025-08-28 05:38:57,675 - INFO - Pruning info: sparsity=0.150
2025-08-28 05:38:57,675 - INFO -   Reactivation rate: 0.0081
2025-08-28 05:38:59,003 - INFO - Epoch: [5][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.6487 (0.6613) Acc@1 78.125 (76.908) Acc@5 99.219 (98.628)
2025-08-28 05:39:00,580 - INFO - Pruning info: sparsity=0.150
2025-08-28 05:39:00,581 - INFO -   Reactivation rate: 0.0057
2025-08-28 05:39:00,888 - INFO - Epoch: [5][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.7379 (0.6600) Acc@1 74.219 (77.121) Acc@5 98.438 (98.614)
2025-08-28 05:39:02,652 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 1.3265 (1.3265) Acc@1 66.406 (66.406) Acc@5 93.750 (93.750)
2025-08-28 05:39:03,470 - INFO - Epoch 5:
2025-08-28 05:39:03,470 - INFO -   Train: acc1: 77.3680 | acc5: 98.6380 | loss: 0.6566 | sparsity: 0.1496 | reactivation_rate: 0.0071
2025-08-28 05:39:03,470 - INFO -   Val:   acc1: 62.9400 | acc5: 96.9100 | loss: 1.2157
2025-08-28 05:39:03,470 - INFO -   LR: 0.100000
2025-08-28 05:39:03,478 - INFO - 
Epoch: 6, lr = 0.1
2025-08-28 05:39:03,695 - INFO - Epoch: [6][0/391] Time 0.216 (0.216) Data 0.194 (0.194) Loss 0.4878 (0.4878) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:39:04,696 - INFO - Pruning info: sparsity=0.177
2025-08-28 05:39:04,696 - INFO -   Reactivation rate: 0.0101
2025-08-28 05:39:05,552 - INFO - Epoch: [6][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.6051 (0.6102) Acc@1 77.344 (78.844) Acc@5 97.656 (98.878)
2025-08-28 05:39:07,402 - INFO - Epoch: [6][200/391] Time 0.019 (0.019) Data 0.005 (0.003) Loss 0.6783 (0.6180) Acc@1 75.781 (78.677) Acc@5 98.438 (98.807)
2025-08-28 05:39:07,593 - INFO - Pruning info: sparsity=0.177
2025-08-28 05:39:07,594 - INFO -   Reactivation rate: 0.0065
2025-08-28 05:39:09,144 - INFO - Epoch: [6][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.6536 (0.6237) Acc@1 77.344 (78.527) Acc@5 99.219 (98.752)
2025-08-28 05:39:10,530 - INFO - Pruning info: sparsity=0.177
2025-08-28 05:39:10,531 - INFO -   Reactivation rate: 0.0049
2025-08-28 05:39:10,975 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.7554 (0.7554) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 05:39:11,855 - INFO - Epoch 6:
2025-08-28 05:39:11,855 - INFO -   Train: acc1: 78.5940 | acc5: 98.7680 | loss: 0.6236 | sparsity: 0.1771 | reactivation_rate: 0.0068
2025-08-28 05:39:11,855 - INFO -   Val:   acc1: 71.2300 | acc5: 97.1800 | loss: 0.9091
2025-08-28 05:39:11,855 - INFO -   LR: 0.100000
2025-08-28 05:39:11,901 - INFO - Checkpoint saved: epoch=6, metric=71.2300
2025-08-28 05:39:11,933 - INFO - 
Epoch: 7, lr = 0.1
2025-08-28 05:39:12,126 - INFO - Epoch: [7][0/391] Time 0.192 (0.192) Data 0.164 (0.164) Loss 0.5726 (0.5726) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 05:39:13,983 - INFO - Epoch: [7][100/391] Time 0.020 (0.020) Data 0.000 (0.005) Loss 0.7133 (0.6130) Acc@1 75.781 (79.069) Acc@5 99.219 (98.739)
2025-08-28 05:39:14,700 - INFO - Pruning info: sparsity=0.204
2025-08-28 05:39:14,700 - INFO -   Reactivation rate: 0.0077
2025-08-28 05:39:15,829 - INFO - Epoch: [7][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.5396 (0.6067) Acc@1 82.812 (79.159) Acc@5 99.219 (98.803)
2025-08-28 05:39:17,699 - INFO - Epoch: [7][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4833 (0.6029) Acc@1 82.812 (79.267) Acc@5 99.219 (98.845)
2025-08-28 05:39:17,738 - INFO - Pruning info: sparsity=0.204
2025-08-28 05:39:17,739 - INFO -   Reactivation rate: 0.0053
2025-08-28 05:39:20,354 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.8630 (0.8630) Acc@1 71.094 (71.094) Acc@5 96.875 (96.875)
2025-08-28 05:39:21,181 - INFO - Epoch 7:
2025-08-28 05:39:21,181 - INFO -   Train: acc1: 79.2240 | acc5: 98.8620 | loss: 0.6030 | sparsity: 0.2037 | reactivation_rate: 0.0068
2025-08-28 05:39:21,181 - INFO -   Val:   acc1: 68.5700 | acc5: 96.0500 | loss: 1.0255
2025-08-28 05:39:21,181 - INFO -   LR: 0.100000
2025-08-28 05:39:21,314 - INFO - 
Epoch: 8, lr = 0.1
2025-08-28 05:39:21,515 - INFO - Epoch: [8][0/391] Time 0.200 (0.200) Data 0.164 (0.164) Loss 0.5065 (0.5065) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:39:22,898 - INFO - Pruning info: sparsity=0.230
2025-08-28 05:39:22,898 - INFO -   Reactivation rate: 0.0093
2025-08-28 05:39:23,452 - INFO - Epoch: [8][100/391] Time 0.014 (0.021) Data 0.000 (0.007) Loss 0.5478 (0.5779) Acc@1 79.688 (79.780) Acc@5 99.219 (98.902)
2025-08-28 05:39:25,274 - INFO - Epoch: [8][200/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.4630 (0.5715) Acc@1 85.156 (80.181) Acc@5 99.219 (98.943)
2025-08-28 05:39:25,812 - INFO - Pruning info: sparsity=0.230
2025-08-28 05:39:25,812 - INFO -   Reactivation rate: 0.0059
2025-08-28 05:39:27,077 - INFO - Epoch: [8][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.6719 (0.5801) Acc@1 77.344 (79.955) Acc@5 98.438 (98.946)
2025-08-28 05:39:28,861 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.7540 (0.7540) Acc@1 75.000 (75.000) Acc@5 96.094 (96.094)
2025-08-28 05:39:29,706 - INFO - Epoch 8:
2025-08-28 05:39:29,706 - INFO -   Train: acc1: 79.9700 | acc5: 98.9700 | loss: 0.5791 | sparsity: 0.2297 | reactivation_rate: 0.0066
2025-08-28 05:39:29,706 - INFO -   Val:   acc1: 75.1300 | acc5: 98.0200 | loss: 0.7448
2025-08-28 05:39:29,706 - INFO -   LR: 0.100000
2025-08-28 05:39:29,749 - INFO - Checkpoint saved: epoch=8, metric=75.1300
2025-08-28 05:39:29,781 - INFO - 
Epoch: 9, lr = 0.1
2025-08-28 05:39:29,976 - INFO - Epoch: [9][0/391] Time 0.194 (0.194) Data 0.176 (0.176) Loss 0.4797 (0.4797) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 05:39:29,982 - INFO - Pruning info: sparsity=0.255
2025-08-28 05:39:29,982 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:39:31,907 - INFO - Epoch: [9][100/391] Time 0.021 (0.021) Data 0.000 (0.005) Loss 0.5088 (0.5518) Acc@1 84.375 (80.863) Acc@5 96.094 (98.948)
2025-08-28 05:39:33,064 - INFO - Pruning info: sparsity=0.255
2025-08-28 05:39:33,064 - INFO -   Reactivation rate: 0.0064
2025-08-28 05:39:33,760 - INFO - Epoch: [9][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.5045 (0.5548) Acc@1 83.594 (80.745) Acc@5 97.656 (98.978)
2025-08-28 05:39:35,568 - INFO - Epoch: [9][300/391] Time 0.023 (0.019) Data 0.009 (0.004) Loss 0.7130 (0.5635) Acc@1 78.125 (80.565) Acc@5 95.312 (98.980)
2025-08-28 05:39:35,983 - INFO - Pruning info: sparsity=0.255
2025-08-28 05:39:35,983 - INFO -   Reactivation rate: 0.0047
2025-08-28 05:39:37,387 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.8177 (0.8177) Acc@1 71.875 (71.875) Acc@5 100.000 (100.000)
2025-08-28 05:39:38,267 - INFO - Epoch 9:
2025-08-28 05:39:38,267 - INFO -   Train: acc1: 80.4820 | acc5: 99.0020 | loss: 0.5640 | sparsity: 0.2548 | reactivation_rate: 0.0063
2025-08-28 05:39:38,267 - INFO -   Val:   acc1: 71.3300 | acc5: 98.4500 | loss: 0.8830
2025-08-28 05:39:38,267 - INFO -   LR: 0.100000
2025-08-28 05:39:38,277 - INFO - 
Epoch: 10, lr = 0.1
2025-08-28 05:39:38,473 - INFO - Epoch: [10][0/391] Time 0.195 (0.195) Data 0.178 (0.178) Loss 0.5343 (0.5343) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:39:40,134 - INFO - Pruning info: sparsity=0.279
2025-08-28 05:39:40,134 - INFO -   Reactivation rate: 0.0081
2025-08-28 05:39:40,299 - INFO - Epoch: [10][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4281 (0.5415) Acc@1 86.719 (81.242) Acc@5 99.219 (99.049)
2025-08-28 05:39:42,135 - INFO - Epoch: [10][200/391] Time 0.021 (0.019) Data 0.007 (0.003) Loss 0.4510 (0.5400) Acc@1 88.281 (81.231) Acc@5 99.219 (99.032)
2025-08-28 05:39:43,051 - INFO - Pruning info: sparsity=0.279
2025-08-28 05:39:43,051 - INFO -   Reactivation rate: 0.0052
2025-08-28 05:39:43,936 - INFO - Epoch: [10][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.7410 (0.5467) Acc@1 81.250 (81.068) Acc@5 98.438 (98.998)
2025-08-28 05:39:45,715 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.8756 (0.8756) Acc@1 71.875 (71.875) Acc@5 97.656 (97.656)
2025-08-28 05:39:46,561 - INFO - Epoch 10:
2025-08-28 05:39:46,561 - INFO -   Train: acc1: 81.0060 | acc5: 99.0180 | loss: 0.5488 | sparsity: 0.2792 | reactivation_rate: 0.0061
2025-08-28 05:39:46,562 - INFO -   Val:   acc1: 69.6300 | acc5: 96.5300 | loss: 0.9767
2025-08-28 05:39:46,562 - INFO -   LR: 0.100000
2025-08-28 05:39:46,609 - INFO - 
Epoch: 11, lr = 0.1
2025-08-28 05:39:46,821 - INFO - Epoch: [11][0/391] Time 0.210 (0.210) Data 0.175 (0.175) Loss 0.6134 (0.6134) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-28 05:39:47,150 - INFO - Pruning info: sparsity=0.303
2025-08-28 05:39:47,152 - INFO -   Reactivation rate: 0.0112
2025-08-28 05:39:48,742 - INFO - Epoch: [11][100/391] Time 0.013 (0.021) Data 0.002 (0.004) Loss 0.4927 (0.5402) Acc@1 85.938 (81.381) Acc@5 99.219 (99.196)
2025-08-28 05:39:50,164 - INFO - Pruning info: sparsity=0.303
2025-08-28 05:39:50,164 - INFO -   Reactivation rate: 0.0057
2025-08-28 05:39:50,563 - INFO - Epoch: [11][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.5911 (0.5342) Acc@1 81.250 (81.557) Acc@5 98.438 (99.114)
2025-08-28 05:39:52,396 - INFO - Epoch: [11][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.7210 (0.5351) Acc@1 72.656 (81.639) Acc@5 98.438 (99.086)
2025-08-28 05:39:53,130 - INFO - Pruning info: sparsity=0.303
2025-08-28 05:39:53,130 - INFO -   Reactivation rate: 0.0041
2025-08-28 05:39:54,264 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5510 (0.5510) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 05:39:55,109 - INFO - Epoch 11:
2025-08-28 05:39:55,110 - INFO -   Train: acc1: 81.5300 | acc5: 99.0500 | loss: 0.5384 | sparsity: 0.3029 | reactivation_rate: 0.0058
2025-08-28 05:39:55,110 - INFO -   Val:   acc1: 74.7500 | acc5: 97.8500 | loss: 0.7628
2025-08-28 05:39:55,110 - INFO -   LR: 0.100000
2025-08-28 05:39:55,119 - INFO - 
Epoch: 12, lr = 0.1
2025-08-28 05:39:55,306 - INFO - Epoch: [12][0/391] Time 0.186 (0.186) Data 0.161 (0.161) Loss 0.5419 (0.5419) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 05:39:57,183 - INFO - Epoch: [12][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4197 (0.5379) Acc@1 86.719 (81.227) Acc@5 100.000 (99.134)
2025-08-28 05:39:57,326 - INFO - Pruning info: sparsity=0.326
2025-08-28 05:39:57,326 - INFO -   Reactivation rate: 0.0070
2025-08-28 05:39:59,038 - INFO - Epoch: [12][200/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.6861 (0.5252) Acc@1 74.219 (81.852) Acc@5 100.000 (99.094)
2025-08-28 05:40:00,232 - INFO - Pruning info: sparsity=0.326
2025-08-28 05:40:00,232 - INFO -   Reactivation rate: 0.0047
2025-08-28 05:40:00,828 - INFO - Epoch: [12][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.5384 (0.5291) Acc@1 81.250 (81.699) Acc@5 98.438 (99.105)
2025-08-28 05:40:02,598 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6111 (0.6111) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 05:40:03,440 - INFO - Epoch 12:
2025-08-28 05:40:03,440 - INFO -   Train: acc1: 81.6940 | acc5: 99.1020 | loss: 0.5290 | sparsity: 0.3258 | reactivation_rate: 0.0057
2025-08-28 05:40:03,440 - INFO -   Val:   acc1: 76.1700 | acc5: 98.4800 | loss: 0.6997
2025-08-28 05:40:03,440 - INFO -   LR: 0.100000
2025-08-28 05:40:03,485 - INFO - Checkpoint saved: epoch=12, metric=76.1700
2025-08-28 05:40:03,517 - INFO - 
Epoch: 13, lr = 0.1
2025-08-28 05:40:03,714 - INFO - Epoch: [13][0/391] Time 0.196 (0.196) Data 0.162 (0.162) Loss 0.5414 (0.5414) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 05:40:04,432 - INFO - Pruning info: sparsity=0.348
2025-08-28 05:40:04,433 - INFO -   Reactivation rate: 0.0092
2025-08-28 05:40:05,601 - INFO - Epoch: [13][100/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.5444 (0.5141) Acc@1 84.375 (82.325) Acc@5 99.219 (99.103)
2025-08-28 05:40:07,542 - INFO - Pruning info: sparsity=0.348
2025-08-28 05:40:07,542 - INFO -   Reactivation rate: 0.0054
2025-08-28 05:40:07,625 - INFO - Epoch: [13][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3467 (0.5179) Acc@1 87.500 (82.105) Acc@5 100.000 (99.122)
2025-08-28 05:40:09,462 - INFO - Epoch: [13][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5431 (0.5238) Acc@1 80.469 (81.907) Acc@5 100.000 (99.081)
2025-08-28 05:40:10,512 - INFO - Pruning info: sparsity=0.348
2025-08-28 05:40:10,513 - INFO -   Reactivation rate: 0.0040
2025-08-28 05:40:11,264 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.8579 (0.8579) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 05:40:12,113 - INFO - Epoch 13:
2025-08-28 05:40:12,113 - INFO -   Train: acc1: 81.8660 | acc5: 99.0700 | loss: 0.5275 | sparsity: 0.3481 | reactivation_rate: 0.0055
2025-08-28 05:40:12,113 - INFO -   Val:   acc1: 71.5800 | acc5: 98.0900 | loss: 0.8928
2025-08-28 05:40:12,113 - INFO -   LR: 0.100000
2025-08-28 05:40:12,123 - INFO - 
Epoch: 14, lr = 0.1
2025-08-28 05:40:12,281 - INFO - Epoch: [14][0/391] Time 0.157 (0.157) Data 0.129 (0.129) Loss 0.5682 (0.5682) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 05:40:14,312 - INFO - Epoch: [14][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.6453 (0.4924) Acc@1 76.562 (82.898) Acc@5 98.438 (99.134)
2025-08-28 05:40:14,835 - INFO - Pruning info: sparsity=0.370
2025-08-28 05:40:14,836 - INFO -   Reactivation rate: 0.0060
2025-08-28 05:40:16,206 - INFO - Epoch: [14][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5184 (0.5029) Acc@1 82.812 (82.568) Acc@5 98.438 (99.114)
2025-08-28 05:40:17,884 - INFO - Pruning info: sparsity=0.370
2025-08-28 05:40:17,884 - INFO -   Reactivation rate: 0.0042
2025-08-28 05:40:18,146 - INFO - Epoch: [14][300/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3508 (0.5069) Acc@1 89.844 (82.421) Acc@5 100.000 (99.156)
2025-08-28 05:40:20,040 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.8850 (0.8850) Acc@1 71.875 (71.875) Acc@5 100.000 (100.000)
2025-08-28 05:40:20,882 - INFO - Epoch 14:
2025-08-28 05:40:20,882 - INFO -   Train: acc1: 82.4000 | acc5: 99.1560 | loss: 0.5106 | sparsity: 0.3696 | reactivation_rate: 0.0052
2025-08-28 05:40:20,882 - INFO -   Val:   acc1: 74.7200 | acc5: 98.1300 | loss: 0.8388
2025-08-28 05:40:20,883 - INFO -   LR: 0.100000
2025-08-28 05:40:20,892 - INFO - 
Epoch: 15, lr = 0.1
2025-08-28 05:40:21,110 - INFO - Epoch: [15][0/391] Time 0.217 (0.217) Data 0.183 (0.183) Loss 0.5121 (0.5121) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:40:22,083 - INFO - Pruning info: sparsity=0.390
2025-08-28 05:40:22,083 - INFO -   Reactivation rate: 0.0076
2025-08-28 05:40:22,896 - INFO - Epoch: [15][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4998 (0.4920) Acc@1 83.594 (82.967) Acc@5 100.000 (99.288)
2025-08-28 05:40:24,758 - INFO - Epoch: [15][200/391] Time 0.055 (0.019) Data 0.044 (0.004) Loss 0.5288 (0.5129) Acc@1 79.688 (82.494) Acc@5 100.000 (99.141)
2025-08-28 05:40:25,044 - INFO - Pruning info: sparsity=0.390
2025-08-28 05:40:25,044 - INFO -   Reactivation rate: 0.0044
2025-08-28 05:40:26,662 - INFO - Epoch: [15][300/391] Time 0.027 (0.019) Data 0.000 (0.004) Loss 0.4354 (0.5133) Acc@1 84.375 (82.415) Acc@5 98.438 (99.151)
2025-08-28 05:40:28,057 - INFO - Pruning info: sparsity=0.390
2025-08-28 05:40:28,058 - INFO -   Reactivation rate: 0.0035
2025-08-28 05:40:28,473 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.7358 (0.7358) Acc@1 75.781 (75.781) Acc@5 100.000 (100.000)
2025-08-28 05:40:29,312 - INFO - Epoch 15:
2025-08-28 05:40:29,312 - INFO -   Train: acc1: 82.4040 | acc5: 99.1280 | loss: 0.5135 | sparsity: 0.3904 | reactivation_rate: 0.0051
2025-08-28 05:40:29,312 - INFO -   Val:   acc1: 74.9500 | acc5: 98.0500 | loss: 0.7642
2025-08-28 05:40:29,312 - INFO -   LR: 0.100000
2025-08-28 05:40:29,320 - INFO - 
Epoch: 16, lr = 0.1
2025-08-28 05:40:29,531 - INFO - Epoch: [16][0/391] Time 0.210 (0.210) Data 0.180 (0.180) Loss 0.5311 (0.5311) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:40:31,387 - INFO - Epoch: [16][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.5808 (0.4965) Acc@1 78.906 (82.743) Acc@5 97.656 (99.126)
2025-08-28 05:40:32,177 - INFO - Pruning info: sparsity=0.411
2025-08-28 05:40:32,177 - INFO -   Reactivation rate: 0.0053
2025-08-28 05:40:33,233 - INFO - Epoch: [16][200/391] Time 0.021 (0.019) Data 0.003 (0.004) Loss 0.6181 (0.5020) Acc@1 78.906 (82.715) Acc@5 99.219 (99.145)
2025-08-28 05:40:35,058 - INFO - Epoch: [16][300/391] Time 0.026 (0.019) Data 0.008 (0.003) Loss 0.6389 (0.5045) Acc@1 78.125 (82.644) Acc@5 100.000 (99.162)
2025-08-28 05:40:35,128 - INFO - Pruning info: sparsity=0.411
2025-08-28 05:40:35,128 - INFO -   Reactivation rate: 0.0036
2025-08-28 05:40:36,870 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7353 (0.7353) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 05:40:37,720 - INFO - Epoch 16:
2025-08-28 05:40:37,720 - INFO -   Train: acc1: 82.6940 | acc5: 99.1460 | loss: 0.5039 | sparsity: 0.4105 | reactivation_rate: 0.0050
2025-08-28 05:40:37,720 - INFO -   Val:   acc1: 73.2900 | acc5: 97.8300 | loss: 0.8473
2025-08-28 05:40:37,720 - INFO -   LR: 0.100000
2025-08-28 05:40:37,729 - INFO - 
Epoch: 17, lr = 0.1
2025-08-28 05:40:37,919 - INFO - Epoch: [17][0/391] Time 0.190 (0.190) Data 0.174 (0.174) Loss 0.5100 (0.5100) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 05:40:39,248 - INFO - Pruning info: sparsity=0.430
2025-08-28 05:40:39,249 - INFO -   Reactivation rate: 0.0067
2025-08-28 05:40:39,732 - INFO - Epoch: [17][100/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.4505 (0.4926) Acc@1 82.812 (82.936) Acc@5 99.219 (99.304)
2025-08-28 05:40:41,611 - INFO - Epoch: [17][200/391] Time 0.028 (0.019) Data 0.018 (0.005) Loss 0.4560 (0.4931) Acc@1 83.594 (82.949) Acc@5 100.000 (99.234)
2025-08-28 05:40:42,187 - INFO - Pruning info: sparsity=0.430
2025-08-28 05:40:42,187 - INFO -   Reactivation rate: 0.0041
2025-08-28 05:40:43,510 - INFO - Epoch: [17][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.5112 (0.4990) Acc@1 84.375 (82.831) Acc@5 98.438 (99.193)
2025-08-28 05:40:45,385 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.6796 (0.6796) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 05:40:46,253 - INFO - Epoch 17:
2025-08-28 05:40:46,253 - INFO -   Train: acc1: 82.8960 | acc5: 99.1900 | loss: 0.4970 | sparsity: 0.4300 | reactivation_rate: 0.0047
2025-08-28 05:40:46,253 - INFO -   Val:   acc1: 75.3000 | acc5: 97.3100 | loss: 0.7767
2025-08-28 05:40:46,254 - INFO -   LR: 0.100000
2025-08-28 05:40:46,264 - INFO - 
Epoch: 18, lr = 0.1
2025-08-28 05:40:46,476 - INFO - Epoch: [18][0/391] Time 0.211 (0.211) Data 0.182 (0.182) Loss 0.4320 (0.4320) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:40:46,501 - INFO - Pruning info: sparsity=0.449
2025-08-28 05:40:46,502 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:40:48,305 - INFO - Epoch: [18][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.3804 (0.4900) Acc@1 86.719 (83.416) Acc@5 99.219 (99.172)
2025-08-28 05:40:49,437 - INFO - Pruning info: sparsity=0.449
2025-08-28 05:40:49,437 - INFO -   Reactivation rate: 0.0045
2025-08-28 05:40:50,143 - INFO - Epoch: [18][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4259 (0.4880) Acc@1 84.375 (83.302) Acc@5 97.656 (99.164)
2025-08-28 05:40:52,001 - INFO - Epoch: [18][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.5723 (0.4896) Acc@1 84.375 (83.204) Acc@5 99.219 (99.149)
2025-08-28 05:40:52,400 - INFO - Pruning info: sparsity=0.449
2025-08-28 05:40:52,401 - INFO -   Reactivation rate: 0.0035
2025-08-28 05:40:53,924 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.9886 (0.9886) Acc@1 65.625 (65.625) Acc@5 96.875 (96.875)
2025-08-28 05:40:54,748 - INFO - Epoch 18:
2025-08-28 05:40:54,748 - INFO -   Train: acc1: 83.1380 | acc5: 99.1520 | loss: 0.4904 | sparsity: 0.4488 | reactivation_rate: 0.0045
2025-08-28 05:40:54,748 - INFO -   Val:   acc1: 64.7300 | acc5: 95.8300 | loss: 1.2028
2025-08-28 05:40:54,748 - INFO -   LR: 0.100000
2025-08-28 05:40:54,757 - INFO - 
Epoch: 19, lr = 0.1
2025-08-28 05:40:54,952 - INFO - Epoch: [19][0/391] Time 0.193 (0.193) Data 0.172 (0.172) Loss 0.3950 (0.3950) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:40:56,622 - INFO - Pruning info: sparsity=0.467
2025-08-28 05:40:56,622 - INFO -   Reactivation rate: 0.0059
2025-08-28 05:40:56,794 - INFO - Epoch: [19][100/391] Time 0.028 (0.020) Data 0.017 (0.005) Loss 0.3662 (0.4741) Acc@1 86.719 (83.625) Acc@5 100.000 (99.281)
2025-08-28 05:40:58,595 - INFO - Epoch: [19][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.3888 (0.4818) Acc@1 86.719 (83.427) Acc@5 100.000 (99.285)
2025-08-28 05:40:59,527 - INFO - Pruning info: sparsity=0.467
2025-08-28 05:40:59,527 - INFO -   Reactivation rate: 0.0037
2025-08-28 05:41:00,444 - INFO - Epoch: [19][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4477 (0.4873) Acc@1 84.375 (83.186) Acc@5 99.219 (99.286)
2025-08-28 05:41:02,261 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5717 (0.5717) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:41:03,088 - INFO - Epoch 19:
2025-08-28 05:41:03,089 - INFO -   Train: acc1: 83.2560 | acc5: 99.2520 | loss: 0.4864 | sparsity: 0.4670 | reactivation_rate: 0.0044
2025-08-28 05:41:03,089 - INFO -   Val:   acc1: 76.9400 | acc5: 98.9100 | loss: 0.6950
2025-08-28 05:41:03,089 - INFO -   LR: 0.100000
2025-08-28 05:41:03,134 - INFO - Checkpoint saved: epoch=19, metric=76.9400
2025-08-28 05:41:03,166 - INFO - 
Epoch: 20, lr = 0.1
2025-08-28 05:41:03,369 - INFO - Epoch: [20][0/391] Time 0.203 (0.203) Data 0.179 (0.179) Loss 0.4365 (0.4365) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 05:41:03,677 - INFO - Pruning info: sparsity=0.485
2025-08-28 05:41:03,677 - INFO -   Reactivation rate: 0.0078
2025-08-28 05:41:05,259 - INFO - Epoch: [20][100/391] Time 0.017 (0.021) Data 0.000 (0.007) Loss 0.3833 (0.4709) Acc@1 86.719 (83.555) Acc@5 99.219 (99.281)
2025-08-28 05:41:06,608 - INFO - Pruning info: sparsity=0.485
2025-08-28 05:41:06,608 - INFO -   Reactivation rate: 0.0042
2025-08-28 05:41:07,007 - INFO - Epoch: [20][200/391] Time 0.015 (0.019) Data 0.000 (0.005) Loss 0.4858 (0.4783) Acc@1 85.156 (83.547) Acc@5 99.219 (99.230)
2025-08-28 05:41:08,753 - INFO - Epoch: [20][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5223 (0.4771) Acc@1 82.812 (83.560) Acc@5 97.656 (99.201)
2025-08-28 05:41:09,518 - INFO - Pruning info: sparsity=0.485
2025-08-28 05:41:09,518 - INFO -   Reactivation rate: 0.0032
2025-08-28 05:41:10,572 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.5830 (0.5830) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 05:41:11,430 - INFO - Epoch 20:
2025-08-28 05:41:11,430 - INFO -   Train: acc1: 83.4700 | acc5: 99.2140 | loss: 0.4799 | sparsity: 0.4845 | reactivation_rate: 0.0042
2025-08-28 05:41:11,430 - INFO -   Val:   acc1: 79.1900 | acc5: 98.5600 | loss: 0.6521
2025-08-28 05:41:11,430 - INFO -   LR: 0.100000
2025-08-28 05:41:11,477 - INFO - Checkpoint saved: epoch=20, metric=79.1900
2025-08-28 05:41:11,508 - INFO - 
Epoch: 21, lr = 0.1
2025-08-28 05:41:11,699 - INFO - Epoch: [21][0/391] Time 0.190 (0.190) Data 0.163 (0.163) Loss 0.3602 (0.3602) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:41:13,510 - INFO - Epoch: [21][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.4828 (0.4541) Acc@1 84.375 (84.445) Acc@5 98.438 (99.281)
2025-08-28 05:41:13,641 - INFO - Pruning info: sparsity=0.501
2025-08-28 05:41:13,642 - INFO -   Reactivation rate: 0.0049
2025-08-28 05:41:15,374 - INFO - Epoch: [21][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5208 (0.4667) Acc@1 82.812 (84.025) Acc@5 100.000 (99.234)
2025-08-28 05:41:16,760 - INFO - Pruning info: sparsity=0.501
2025-08-28 05:41:16,760 - INFO -   Reactivation rate: 0.0033
2025-08-28 05:41:17,387 - INFO - Epoch: [21][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5053 (0.4740) Acc@1 80.469 (83.708) Acc@5 100.000 (99.265)
2025-08-28 05:41:19,145 - INFO - Test: [0/79] Time 0.168 (0.168) Loss 0.5790 (0.5790) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 05:41:20,026 - INFO - Epoch 21:
2025-08-28 05:41:20,026 - INFO -   Train: acc1: 83.6040 | acc5: 99.2520 | loss: 0.4783 | sparsity: 0.5014 | reactivation_rate: 0.0041
2025-08-28 05:41:20,026 - INFO -   Val:   acc1: 80.0600 | acc5: 98.4900 | loss: 0.5970
2025-08-28 05:41:20,026 - INFO -   LR: 0.100000
2025-08-28 05:41:20,077 - INFO - Checkpoint saved: epoch=21, metric=80.0600
2025-08-28 05:41:20,111 - INFO - 
Epoch: 22, lr = 0.1
2025-08-28 05:41:20,274 - INFO - Epoch: [22][0/391] Time 0.162 (0.162) Data 0.134 (0.134) Loss 0.4326 (0.4326) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:41:20,985 - INFO - Pruning info: sparsity=0.518
2025-08-28 05:41:20,985 - INFO -   Reactivation rate: 0.0060
2025-08-28 05:41:22,090 - INFO - Epoch: [22][100/391] Time 0.025 (0.020) Data 0.012 (0.003) Loss 0.4699 (0.4510) Acc@1 84.375 (84.592) Acc@5 98.438 (99.296)
2025-08-28 05:41:23,944 - INFO - Pruning info: sparsity=0.518
2025-08-28 05:41:23,944 - INFO -   Reactivation rate: 0.0036
2025-08-28 05:41:23,988 - INFO - Epoch: [22][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.5372 (0.4589) Acc@1 79.688 (84.426) Acc@5 97.656 (99.269)
2025-08-28 05:41:25,842 - INFO - Epoch: [22][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4171 (0.4628) Acc@1 87.500 (84.201) Acc@5 100.000 (99.273)
2025-08-28 05:41:26,877 - INFO - Pruning info: sparsity=0.518
2025-08-28 05:41:26,878 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:41:27,640 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.7256 (0.7256) Acc@1 75.000 (75.000) Acc@5 98.438 (98.438)
2025-08-28 05:41:28,504 - INFO - Epoch 22:
2025-08-28 05:41:28,505 - INFO -   Train: acc1: 83.9660 | acc5: 99.2740 | loss: 0.4680 | sparsity: 0.5177 | reactivation_rate: 0.0038
2025-08-28 05:41:28,505 - INFO -   Val:   acc1: 75.6800 | acc5: 98.4000 | loss: 0.7498
2025-08-28 05:41:28,505 - INFO -   LR: 0.100000
2025-08-28 05:41:28,515 - INFO - 
Epoch: 23, lr = 0.1
2025-08-28 05:41:28,727 - INFO - Epoch: [23][0/391] Time 0.211 (0.211) Data 0.168 (0.168) Loss 0.5045 (0.5045) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:41:30,538 - INFO - Epoch: [23][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.4638 (0.4570) Acc@1 82.812 (84.584) Acc@5 98.438 (99.265)
2025-08-28 05:41:31,008 - INFO - Pruning info: sparsity=0.533
2025-08-28 05:41:31,009 - INFO -   Reactivation rate: 0.0043
2025-08-28 05:41:32,331 - INFO - Epoch: [23][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4700 (0.4695) Acc@1 85.156 (84.017) Acc@5 98.438 (99.265)
2025-08-28 05:41:33,982 - INFO - Pruning info: sparsity=0.533
2025-08-28 05:41:33,982 - INFO -   Reactivation rate: 0.0028
2025-08-28 05:41:34,264 - INFO - Epoch: [23][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4322 (0.4694) Acc@1 82.812 (83.983) Acc@5 100.000 (99.250)
2025-08-28 05:41:36,135 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.7338 (0.7338) Acc@1 76.562 (76.562) Acc@5 97.656 (97.656)
2025-08-28 05:41:37,019 - INFO - Epoch 23:
2025-08-28 05:41:37,020 - INFO -   Train: acc1: 83.8780 | acc5: 99.2340 | loss: 0.4707 | sparsity: 0.5334 | reactivation_rate: 0.0037
2025-08-28 05:41:37,020 - INFO -   Val:   acc1: 76.3000 | acc5: 98.0700 | loss: 0.7436
2025-08-28 05:41:37,020 - INFO -   LR: 0.100000
2025-08-28 05:41:37,033 - INFO - 
Epoch: 24, lr = 0.1
2025-08-28 05:41:37,215 - INFO - Epoch: [24][0/391] Time 0.182 (0.182) Data 0.162 (0.162) Loss 0.4202 (0.4202) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:41:38,298 - INFO - Pruning info: sparsity=0.548
2025-08-28 05:41:38,298 - INFO -   Reactivation rate: 0.0055
2025-08-28 05:41:39,136 - INFO - Epoch: [24][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4927 (0.4761) Acc@1 83.594 (83.694) Acc@5 98.438 (99.358)
2025-08-28 05:41:41,170 - INFO - Epoch: [24][200/391] Time 0.023 (0.021) Data 0.000 (0.003) Loss 0.4472 (0.4715) Acc@1 82.812 (83.776) Acc@5 100.000 (99.320)
2025-08-28 05:41:41,470 - INFO - Pruning info: sparsity=0.548
2025-08-28 05:41:41,471 - INFO -   Reactivation rate: 0.0032
2025-08-28 05:41:43,041 - INFO - Epoch: [24][300/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.5013 (0.4677) Acc@1 82.031 (83.918) Acc@5 100.000 (99.346)
2025-08-28 05:41:44,504 - INFO - Pruning info: sparsity=0.548
2025-08-28 05:41:44,504 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:41:44,909 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.7647 (0.7647) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 05:41:45,779 - INFO - Epoch 24:
2025-08-28 05:41:45,779 - INFO -   Train: acc1: 83.8620 | acc5: 99.2860 | loss: 0.4675 | sparsity: 0.5485 | reactivation_rate: 0.0036
2025-08-28 05:41:45,779 - INFO -   Val:   acc1: 75.6500 | acc5: 97.9800 | loss: 0.7866
2025-08-28 05:41:45,779 - INFO -   LR: 0.100000
2025-08-28 05:41:45,789 - INFO - 
Epoch: 25, lr = 0.1
2025-08-28 05:41:45,994 - INFO - Epoch: [25][0/391] Time 0.204 (0.204) Data 0.181 (0.181) Loss 0.3825 (0.3825) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:41:47,808 - INFO - Epoch: [25][100/391] Time 0.024 (0.020) Data 0.000 (0.004) Loss 0.4850 (0.4480) Acc@1 83.594 (84.669) Acc@5 100.000 (99.211)
2025-08-28 05:41:48,649 - INFO - Pruning info: sparsity=0.563
2025-08-28 05:41:48,649 - INFO -   Reactivation rate: 0.0036
2025-08-28 05:41:49,670 - INFO - Epoch: [25][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.5774 (0.4528) Acc@1 78.125 (84.359) Acc@5 99.219 (99.312)
2025-08-28 05:41:51,542 - INFO - Epoch: [25][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4963 (0.4595) Acc@1 79.688 (84.139) Acc@5 99.219 (99.307)
2025-08-28 05:41:51,616 - INFO - Pruning info: sparsity=0.563
2025-08-28 05:41:51,616 - INFO -   Reactivation rate: 0.0026
2025-08-28 05:41:53,355 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.7121 (0.7121) Acc@1 71.875 (71.875) Acc@5 99.219 (99.219)
2025-08-28 05:41:54,276 - INFO - Epoch 25:
2025-08-28 05:41:54,277 - INFO -   Train: acc1: 84.1320 | acc5: 99.2940 | loss: 0.4607 | sparsity: 0.5630 | reactivation_rate: 0.0034
2025-08-28 05:41:54,277 - INFO -   Val:   acc1: 76.7800 | acc5: 98.2000 | loss: 0.7128
2025-08-28 05:41:54,277 - INFO -   LR: 0.100000
2025-08-28 05:41:54,289 - INFO - 
Epoch: 26, lr = 0.1
2025-08-28 05:41:54,482 - INFO - Epoch: [26][0/391] Time 0.192 (0.192) Data 0.172 (0.172) Loss 0.3729 (0.3729) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:41:55,873 - INFO - Pruning info: sparsity=0.577
2025-08-28 05:41:55,873 - INFO -   Reactivation rate: 0.0047
2025-08-28 05:41:56,374 - INFO - Epoch: [26][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4444 (0.4522) Acc@1 82.812 (84.576) Acc@5 100.000 (99.343)
2025-08-28 05:41:58,337 - INFO - Epoch: [26][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5270 (0.4546) Acc@1 79.688 (84.558) Acc@5 100.000 (99.296)
2025-08-28 05:41:58,918 - INFO - Pruning info: sparsity=0.577
2025-08-28 05:41:58,918 - INFO -   Reactivation rate: 0.0029
2025-08-28 05:42:00,144 - INFO - Epoch: [26][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6416 (0.4603) Acc@1 78.906 (84.209) Acc@5 100.000 (99.317)
2025-08-28 05:42:01,945 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5195 (0.5195) Acc@1 78.125 (78.125) Acc@5 97.656 (97.656)
2025-08-28 05:42:02,820 - INFO - Epoch 26:
2025-08-28 05:42:02,820 - INFO -   Train: acc1: 84.3020 | acc5: 99.3500 | loss: 0.4560 | sparsity: 0.5769 | reactivation_rate: 0.0034
2025-08-28 05:42:02,820 - INFO -   Val:   acc1: 78.9000 | acc5: 98.8800 | loss: 0.6171
2025-08-28 05:42:02,820 - INFO -   LR: 0.100000
2025-08-28 05:42:02,830 - INFO - 
Epoch: 27, lr = 0.1
2025-08-28 05:42:03,014 - INFO - Epoch: [27][0/391] Time 0.183 (0.183) Data 0.156 (0.156) Loss 0.4329 (0.4329) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:42:03,056 - INFO - Pruning info: sparsity=0.590
2025-08-28 05:42:03,056 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:42:04,844 - INFO - Epoch: [27][100/391] Time 0.021 (0.020) Data 0.010 (0.004) Loss 0.5230 (0.4335) Acc@1 84.375 (85.303) Acc@5 100.000 (99.265)
2025-08-28 05:42:05,986 - INFO - Pruning info: sparsity=0.590
2025-08-28 05:42:05,986 - INFO -   Reactivation rate: 0.0031
2025-08-28 05:42:06,729 - INFO - Epoch: [27][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3386 (0.4405) Acc@1 90.625 (84.865) Acc@5 100.000 (99.347)
2025-08-28 05:42:08,613 - INFO - Epoch: [27][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4858 (0.4511) Acc@1 82.812 (84.487) Acc@5 99.219 (99.356)
2025-08-28 05:42:09,040 - INFO - Pruning info: sparsity=0.590
2025-08-28 05:42:09,040 - INFO -   Reactivation rate: 0.0024
2025-08-28 05:42:10,472 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7224 (0.7224) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 05:42:11,320 - INFO - Epoch 27:
2025-08-28 05:42:11,320 - INFO -   Train: acc1: 84.3760 | acc5: 99.3600 | loss: 0.4554 | sparsity: 0.5903 | reactivation_rate: 0.0031
2025-08-28 05:42:11,320 - INFO -   Val:   acc1: 76.6800 | acc5: 98.7200 | loss: 0.6933
2025-08-28 05:42:11,321 - INFO -   LR: 0.100000
2025-08-28 05:42:11,332 - INFO - 
Epoch: 28, lr = 0.1
2025-08-28 05:42:11,511 - INFO - Epoch: [28][0/391] Time 0.177 (0.177) Data 0.147 (0.147) Loss 0.3500 (0.3500) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-28 05:42:13,191 - INFO - Pruning info: sparsity=0.603
2025-08-28 05:42:13,191 - INFO -   Reactivation rate: 0.0039
2025-08-28 05:42:13,353 - INFO - Epoch: [28][100/391] Time 0.027 (0.020) Data 0.013 (0.003) Loss 0.5142 (0.4496) Acc@1 83.594 (84.476) Acc@5 99.219 (99.273)
2025-08-28 05:42:15,248 - INFO - Epoch: [28][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5111 (0.4561) Acc@1 85.156 (84.165) Acc@5 99.219 (99.320)
2025-08-28 05:42:16,221 - INFO - Pruning info: sparsity=0.603
2025-08-28 05:42:16,221 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:42:17,018 - INFO - Epoch: [28][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.3490 (0.4550) Acc@1 85.938 (84.180) Acc@5 100.000 (99.297)
2025-08-28 05:42:18,894 - INFO - Test: [0/79] Time 0.177 (0.177) Loss 0.5452 (0.5452) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-28 05:42:19,697 - INFO - Epoch 28:
2025-08-28 05:42:19,697 - INFO -   Train: acc1: 84.0680 | acc5: 99.2960 | loss: 0.4585 | sparsity: 0.6031 | reactivation_rate: 0.0030
2025-08-28 05:42:19,697 - INFO -   Val:   acc1: 79.3300 | acc5: 98.9100 | loss: 0.6120
2025-08-28 05:42:19,697 - INFO -   LR: 0.100000
2025-08-28 05:42:19,710 - INFO - 
Epoch: 29, lr = 0.1
2025-08-28 05:42:19,893 - INFO - Epoch: [29][0/391] Time 0.182 (0.182) Data 0.165 (0.165) Loss 0.5233 (0.5233) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 05:42:20,299 - INFO - Pruning info: sparsity=0.615
2025-08-28 05:42:20,299 - INFO -   Reactivation rate: 0.0052
2025-08-28 05:42:21,757 - INFO - Epoch: [29][100/391] Time 0.031 (0.020) Data 0.009 (0.004) Loss 0.4417 (0.4421) Acc@1 84.375 (84.638) Acc@5 99.219 (99.397)
2025-08-28 05:42:23,308 - INFO - Pruning info: sparsity=0.615
2025-08-28 05:42:23,308 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:42:23,656 - INFO - Epoch: [29][200/391] Time 0.031 (0.020) Data 0.000 (0.003) Loss 0.4160 (0.4493) Acc@1 82.031 (84.527) Acc@5 100.000 (99.398)
2025-08-28 05:42:25,516 - INFO - Epoch: [29][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5622 (0.4481) Acc@1 82.031 (84.601) Acc@5 98.438 (99.385)
2025-08-28 05:42:26,181 - INFO - Pruning info: sparsity=0.615
2025-08-28 05:42:26,181 - INFO -   Reactivation rate: 0.0020
2025-08-28 05:42:27,215 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.4429 (0.4429) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:42:28,037 - INFO - Epoch 29:
2025-08-28 05:42:28,037 - INFO -   Train: acc1: 84.5740 | acc5: 99.3760 | loss: 0.4471 | sparsity: 0.6154 | reactivation_rate: 0.0028
2025-08-28 05:42:28,037 - INFO -   Val:   acc1: 82.5500 | acc5: 99.0800 | loss: 0.5191
2025-08-28 05:42:28,038 - INFO -   LR: 0.100000
2025-08-28 05:42:28,083 - INFO - Checkpoint saved: epoch=29, metric=82.5500
2025-08-28 05:42:28,116 - INFO - 
Epoch: 30, lr = 0.1
2025-08-28 05:42:28,307 - INFO - Epoch: [30][0/391] Time 0.191 (0.191) Data 0.167 (0.167) Loss 0.3656 (0.3656) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:42:30,166 - INFO - Epoch: [30][100/391] Time 0.022 (0.020) Data 0.011 (0.004) Loss 0.4927 (0.4496) Acc@1 84.375 (84.731) Acc@5 100.000 (99.296)
2025-08-28 05:42:30,339 - INFO - Pruning info: sparsity=0.627
2025-08-28 05:42:30,339 - INFO -   Reactivation rate: 0.0036
2025-08-28 05:42:31,907 - INFO - Epoch: [30][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4555 (0.4471) Acc@1 85.156 (84.740) Acc@5 98.438 (99.312)
2025-08-28 05:42:33,175 - INFO - Pruning info: sparsity=0.627
2025-08-28 05:42:33,175 - INFO -   Reactivation rate: 0.0023
2025-08-28 05:42:33,768 - INFO - Epoch: [30][300/391] Time 0.033 (0.019) Data 0.000 (0.003) Loss 0.4768 (0.4471) Acc@1 82.812 (84.712) Acc@5 97.656 (99.338)
2025-08-28 05:42:35,499 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.5906 (0.5906) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:42:36,360 - INFO - Epoch 30:
2025-08-28 05:42:36,360 - INFO -   Train: acc1: 84.7140 | acc5: 99.3640 | loss: 0.4469 | sparsity: 0.6272 | reactivation_rate: 0.0028
2025-08-28 05:42:36,360 - INFO -   Val:   acc1: 81.2300 | acc5: 98.8600 | loss: 0.5679
2025-08-28 05:42:36,360 - INFO -   LR: 0.100000
2025-08-28 05:42:36,404 - INFO - 
Epoch: 31, lr = 0.1
2025-08-28 05:42:36,595 - INFO - Epoch: [31][0/391] Time 0.190 (0.190) Data 0.155 (0.155) Loss 0.4757 (0.4757) Acc@1 85.938 (85.938) Acc@5 98.438 (98.438)
2025-08-28 05:42:37,357 - INFO - Pruning info: sparsity=0.638
2025-08-28 05:42:37,357 - INFO -   Reactivation rate: 0.0041
2025-08-28 05:42:38,490 - INFO - Epoch: [31][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4178 (0.4329) Acc@1 86.719 (85.210) Acc@5 100.000 (99.435)
2025-08-28 05:42:40,222 - INFO - Pruning info: sparsity=0.638
2025-08-28 05:42:40,222 - INFO -   Reactivation rate: 0.0026
2025-08-28 05:42:40,251 - INFO - Epoch: [31][200/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.4817 (0.4408) Acc@1 83.594 (84.892) Acc@5 98.438 (99.401)
2025-08-28 05:42:42,055 - INFO - Epoch: [31][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.3976 (0.4464) Acc@1 86.719 (84.635) Acc@5 99.219 (99.380)
2025-08-28 05:42:43,096 - INFO - Pruning info: sparsity=0.638
2025-08-28 05:42:43,096 - INFO -   Reactivation rate: 0.0018
2025-08-28 05:42:43,810 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.4795 (0.4795) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 05:42:44,684 - INFO - Epoch 31:
2025-08-28 05:42:44,684 - INFO -   Train: acc1: 84.5620 | acc5: 99.3440 | loss: 0.4491 | sparsity: 0.6385 | reactivation_rate: 0.0027
2025-08-28 05:42:44,684 - INFO -   Val:   acc1: 82.4100 | acc5: 98.9800 | loss: 0.5369
2025-08-28 05:42:44,684 - INFO -   LR: 0.100000
2025-08-28 05:42:44,695 - INFO - 
Epoch: 32, lr = 0.1
2025-08-28 05:42:44,901 - INFO - Epoch: [32][0/391] Time 0.204 (0.204) Data 0.158 (0.158) Loss 0.5514 (0.5514) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 05:42:46,631 - INFO - Epoch: [32][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4359 (0.4359) Acc@1 88.281 (84.855) Acc@5 99.219 (99.250)
2025-08-28 05:42:47,160 - INFO - Pruning info: sparsity=0.649
2025-08-28 05:42:47,161 - INFO -   Reactivation rate: 0.0027
2025-08-28 05:42:48,501 - INFO - Epoch: [32][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.4848 (0.4367) Acc@1 84.375 (84.997) Acc@5 97.656 (99.328)
2025-08-28 05:42:50,133 - INFO - Pruning info: sparsity=0.649
2025-08-28 05:42:50,134 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:42:50,350 - INFO - Epoch: [32][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3671 (0.4428) Acc@1 88.281 (84.876) Acc@5 99.219 (99.328)
2025-08-28 05:42:52,190 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.6567 (0.6567) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 05:42:53,047 - INFO - Epoch 32:
2025-08-28 05:42:53,048 - INFO -   Train: acc1: 84.7860 | acc5: 99.3340 | loss: 0.4448 | sparsity: 0.6492 | reactivation_rate: 0.0025
2025-08-28 05:42:53,048 - INFO -   Val:   acc1: 77.9900 | acc5: 98.7400 | loss: 0.6720
2025-08-28 05:42:53,048 - INFO -   LR: 0.100000
2025-08-28 05:42:53,060 - INFO - 
Epoch: 33, lr = 0.1
2025-08-28 05:42:53,259 - INFO - Epoch: [33][0/391] Time 0.198 (0.198) Data 0.167 (0.167) Loss 0.3380 (0.3380) Acc@1 92.188 (92.188) Acc@5 98.438 (98.438)
2025-08-28 05:42:54,316 - INFO - Pruning info: sparsity=0.660
2025-08-28 05:42:54,316 - INFO -   Reactivation rate: 0.0037
2025-08-28 05:42:55,089 - INFO - Epoch: [33][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.4885 (0.4442) Acc@1 81.250 (84.677) Acc@5 100.000 (99.435)
2025-08-28 05:42:56,923 - INFO - Epoch: [33][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4800 (0.4300) Acc@1 82.812 (85.253) Acc@5 99.219 (99.413)
2025-08-28 05:42:57,206 - INFO - Pruning info: sparsity=0.660
2025-08-28 05:42:57,207 - INFO -   Reactivation rate: 0.0022
2025-08-28 05:42:58,722 - INFO - Epoch: [33][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4088 (0.4363) Acc@1 85.156 (85.065) Acc@5 99.219 (99.413)
2025-08-28 05:43:00,137 - INFO - Pruning info: sparsity=0.660
2025-08-28 05:43:00,137 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:43:00,557 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.8403 (0.8403) Acc@1 72.656 (72.656) Acc@5 99.219 (99.219)
2025-08-28 05:43:01,443 - INFO - Epoch 33:
2025-08-28 05:43:01,443 - INFO -   Train: acc1: 85.0040 | acc5: 99.4000 | loss: 0.4375 | sparsity: 0.6595 | reactivation_rate: 0.0024
2025-08-28 05:43:01,443 - INFO -   Val:   acc1: 76.4800 | acc5: 98.5900 | loss: 0.7402
2025-08-28 05:43:01,443 - INFO -   LR: 0.100000
2025-08-28 05:43:01,454 - INFO - 
Epoch: 34, lr = 0.1
2025-08-28 05:43:01,661 - INFO - Epoch: [34][0/391] Time 0.206 (0.206) Data 0.180 (0.180) Loss 0.4929 (0.4929) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:43:03,590 - INFO - Epoch: [34][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.5098 (0.4282) Acc@1 82.812 (85.381) Acc@5 99.219 (99.335)
2025-08-28 05:43:04,426 - INFO - Pruning info: sparsity=0.669
2025-08-28 05:43:04,426 - INFO -   Reactivation rate: 0.0026
2025-08-28 05:43:05,495 - INFO - Epoch: [34][200/391] Time 0.024 (0.020) Data 0.011 (0.003) Loss 0.3856 (0.4297) Acc@1 87.500 (85.257) Acc@5 98.438 (99.351)
2025-08-28 05:43:07,287 - INFO - Epoch: [34][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5897 (0.4363) Acc@1 80.469 (85.003) Acc@5 99.219 (99.356)
2025-08-28 05:43:07,376 - INFO - Pruning info: sparsity=0.669
2025-08-28 05:43:07,376 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:43:09,054 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.6805 (0.6805) Acc@1 75.781 (75.781) Acc@5 100.000 (100.000)
2025-08-28 05:43:09,930 - INFO - Epoch 34:
2025-08-28 05:43:09,930 - INFO -   Train: acc1: 84.8020 | acc5: 99.3540 | loss: 0.4424 | sparsity: 0.6693 | reactivation_rate: 0.0023
2025-08-28 05:43:09,930 - INFO -   Val:   acc1: 75.1100 | acc5: 98.5700 | loss: 0.7797
2025-08-28 05:43:09,930 - INFO -   LR: 0.100000
2025-08-28 05:43:09,941 - INFO - 
Epoch: 35, lr = 0.1
2025-08-28 05:43:10,152 - INFO - Epoch: [35][0/391] Time 0.211 (0.211) Data 0.190 (0.190) Loss 0.3432 (0.3432) Acc@1 89.062 (89.062) Acc@5 98.438 (98.438)
2025-08-28 05:43:11,469 - INFO - Pruning info: sparsity=0.679
2025-08-28 05:43:11,470 - INFO -   Reactivation rate: 0.0031
2025-08-28 05:43:11,895 - INFO - Epoch: [35][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.5086 (0.4287) Acc@1 82.812 (85.265) Acc@5 96.875 (99.373)
2025-08-28 05:43:13,749 - INFO - Epoch: [35][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3472 (0.4276) Acc@1 91.406 (85.273) Acc@5 99.219 (99.339)
2025-08-28 05:43:14,366 - INFO - Pruning info: sparsity=0.679
2025-08-28 05:43:14,366 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:43:15,563 - INFO - Epoch: [35][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3437 (0.4329) Acc@1 86.719 (85.117) Acc@5 100.000 (99.302)
2025-08-28 05:43:17,363 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.6588 (0.6588) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 05:43:18,168 - INFO - Epoch 35:
2025-08-28 05:43:18,168 - INFO -   Train: acc1: 85.1240 | acc5: 99.3280 | loss: 0.4330 | sparsity: 0.6786 | reactivation_rate: 0.0022
2025-08-28 05:43:18,168 - INFO -   Val:   acc1: 80.0400 | acc5: 98.9500 | loss: 0.5952
2025-08-28 05:43:18,168 - INFO -   LR: 0.100000
2025-08-28 05:43:18,181 - INFO - 
Epoch: 36, lr = 0.1
2025-08-28 05:43:18,377 - INFO - Epoch: [36][0/391] Time 0.195 (0.195) Data 0.171 (0.171) Loss 0.3415 (0.3415) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:43:18,433 - INFO - Pruning info: sparsity=0.688
2025-08-28 05:43:18,433 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:43:20,178 - INFO - Epoch: [36][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.5238 (0.4292) Acc@1 85.156 (85.837) Acc@5 100.000 (99.459)
2025-08-28 05:43:21,449 - INFO - Pruning info: sparsity=0.688
2025-08-28 05:43:21,449 - INFO -   Reactivation rate: 0.0022
2025-08-28 05:43:22,098 - INFO - Epoch: [36][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3882 (0.4322) Acc@1 88.281 (85.358) Acc@5 100.000 (99.386)
2025-08-28 05:43:23,933 - INFO - Epoch: [36][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4875 (0.4340) Acc@1 85.156 (85.273) Acc@5 100.000 (99.395)
2025-08-28 05:43:24,396 - INFO - Pruning info: sparsity=0.688
2025-08-28 05:43:24,397 - INFO -   Reactivation rate: 0.0016
2025-08-28 05:43:25,758 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.6061 (0.6061) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:43:26,603 - INFO - Epoch 36:
2025-08-28 05:43:26,603 - INFO -   Train: acc1: 85.1540 | acc5: 99.3940 | loss: 0.4382 | sparsity: 0.6875 | reactivation_rate: 0.0021
2025-08-28 05:43:26,603 - INFO -   Val:   acc1: 81.0700 | acc5: 99.0900 | loss: 0.5566
2025-08-28 05:43:26,603 - INFO -   LR: 0.100000
2025-08-28 05:43:26,616 - INFO - 
Epoch: 37, lr = 0.1
2025-08-28 05:43:26,809 - INFO - Epoch: [37][0/391] Time 0.191 (0.191) Data 0.173 (0.173) Loss 0.4507 (0.4507) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:43:28,534 - INFO - Pruning info: sparsity=0.696
2025-08-28 05:43:28,534 - INFO -   Reactivation rate: 0.0027
2025-08-28 05:43:28,663 - INFO - Epoch: [37][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4240 (0.4285) Acc@1 84.375 (85.063) Acc@5 100.000 (99.443)
2025-08-28 05:43:30,524 - INFO - Epoch: [37][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3557 (0.4350) Acc@1 84.375 (84.822) Acc@5 100.000 (99.452)
2025-08-28 05:43:31,473 - INFO - Pruning info: sparsity=0.696
2025-08-28 05:43:31,474 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:43:32,402 - INFO - Epoch: [37][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.5762 (0.4298) Acc@1 78.906 (85.143) Acc@5 97.656 (99.413)
2025-08-28 05:43:34,282 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.4530 (0.4530) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:43:35,113 - INFO - Epoch 37:
2025-08-28 05:43:35,113 - INFO -   Train: acc1: 84.9800 | acc5: 99.3920 | loss: 0.4348 | sparsity: 0.6959 | reactivation_rate: 0.0020
2025-08-28 05:43:35,113 - INFO -   Val:   acc1: 83.1000 | acc5: 99.2400 | loss: 0.4986
2025-08-28 05:43:35,114 - INFO -   LR: 0.100000
2025-08-28 05:43:35,161 - INFO - Checkpoint saved: epoch=37, metric=83.1000
2025-08-28 05:43:35,195 - INFO - 
Epoch: 38, lr = 0.1
2025-08-28 05:43:35,385 - INFO - Epoch: [38][0/391] Time 0.190 (0.190) Data 0.169 (0.169) Loss 0.2811 (0.2811) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 05:43:35,749 - INFO - Pruning info: sparsity=0.704
2025-08-28 05:43:35,749 - INFO -   Reactivation rate: 0.0033
2025-08-28 05:43:37,327 - INFO - Epoch: [38][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.4360 (0.4350) Acc@1 82.031 (85.203) Acc@5 99.219 (99.443)
2025-08-28 05:43:38,873 - INFO - Pruning info: sparsity=0.704
2025-08-28 05:43:38,874 - INFO -   Reactivation rate: 0.0018
2025-08-28 05:43:39,209 - INFO - Epoch: [38][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3405 (0.4282) Acc@1 88.281 (85.351) Acc@5 100.000 (99.440)
2025-08-28 05:43:41,012 - INFO - Epoch: [38][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4485 (0.4330) Acc@1 85.156 (85.169) Acc@5 100.000 (99.406)
2025-08-28 05:43:41,837 - INFO - Pruning info: sparsity=0.704
2025-08-28 05:43:41,837 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:43:42,882 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.5263 (0.5263) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:43:43,707 - INFO - Epoch 38:
2025-08-28 05:43:43,707 - INFO -   Train: acc1: 85.1300 | acc5: 99.3940 | loss: 0.4337 | sparsity: 0.7039 | reactivation_rate: 0.0019
2025-08-28 05:43:43,707 - INFO -   Val:   acc1: 82.1900 | acc5: 99.0500 | loss: 0.5404
2025-08-28 05:43:43,707 - INFO -   LR: 0.100000
2025-08-28 05:43:43,719 - INFO - 
Epoch: 39, lr = 0.1
2025-08-28 05:43:43,919 - INFO - Epoch: [39][0/391] Time 0.198 (0.198) Data 0.163 (0.163) Loss 0.3546 (0.3546) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:43:45,757 - INFO - Epoch: [39][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4896 (0.4152) Acc@1 83.594 (85.829) Acc@5 98.438 (99.373)
2025-08-28 05:43:45,941 - INFO - Pruning info: sparsity=0.712
2025-08-28 05:43:45,942 - INFO -   Reactivation rate: 0.0022
2025-08-28 05:43:47,616 - INFO - Epoch: [39][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4913 (0.4198) Acc@1 82.031 (85.463) Acc@5 100.000 (99.436)
2025-08-28 05:43:48,898 - INFO - Pruning info: sparsity=0.712
2025-08-28 05:43:48,898 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:43:49,481 - INFO - Epoch: [39][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4833 (0.4226) Acc@1 85.938 (85.392) Acc@5 98.438 (99.463)
2025-08-28 05:43:51,426 - INFO - Test: [0/79] Time 0.171 (0.171) Loss 0.5894 (0.5894) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 05:43:52,270 - INFO - Epoch 39:
2025-08-28 05:43:52,270 - INFO -   Train: acc1: 85.3600 | acc5: 99.4420 | loss: 0.4250 | sparsity: 0.7115 | reactivation_rate: 0.0019
2025-08-28 05:43:52,270 - INFO -   Val:   acc1: 79.7000 | acc5: 98.5900 | loss: 0.6116
2025-08-28 05:43:52,270 - INFO -   LR: 0.100000
2025-08-28 05:43:52,282 - INFO - 
Epoch: 40, lr = 0.1
2025-08-28 05:43:52,473 - INFO - Epoch: [40][0/391] Time 0.190 (0.190) Data 0.167 (0.167) Loss 0.3174 (0.3174) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:43:53,188 - INFO - Pruning info: sparsity=0.719
2025-08-28 05:43:53,188 - INFO -   Reactivation rate: 0.0030
2025-08-28 05:43:54,342 - INFO - Epoch: [40][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.3223 (0.4249) Acc@1 89.062 (85.210) Acc@5 99.219 (99.435)
2025-08-28 05:43:56,172 - INFO - Pruning info: sparsity=0.719
2025-08-28 05:43:56,172 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:43:56,187 - INFO - Epoch: [40][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4250 (0.4204) Acc@1 85.156 (85.413) Acc@5 99.219 (99.401)
2025-08-28 05:43:57,998 - INFO - Epoch: [40][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4332 (0.4252) Acc@1 85.156 (85.341) Acc@5 99.219 (99.403)
2025-08-28 05:43:59,120 - INFO - Pruning info: sparsity=0.719
2025-08-28 05:43:59,121 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:43:59,913 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.4521 (0.4521) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:44:00,744 - INFO - Epoch 40:
2025-08-28 05:44:00,744 - INFO -   Train: acc1: 85.2600 | acc5: 99.3820 | loss: 0.4276 | sparsity: 0.7187 | reactivation_rate: 0.0018
2025-08-28 05:44:00,745 - INFO -   Val:   acc1: 82.5700 | acc5: 99.2100 | loss: 0.5184
2025-08-28 05:44:00,745 - INFO -   LR: 0.100000
2025-08-28 05:44:00,792 - INFO - 
Epoch: 41, lr = 0.1
2025-08-28 05:44:00,990 - INFO - Epoch: [41][0/391] Time 0.197 (0.197) Data 0.158 (0.158) Loss 0.3675 (0.3675) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-28 05:44:02,784 - INFO - Epoch: [41][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.5649 (0.4139) Acc@1 83.594 (85.473) Acc@5 99.219 (99.520)
2025-08-28 05:44:03,335 - INFO - Pruning info: sparsity=0.725
2025-08-28 05:44:03,335 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:44:04,670 - INFO - Epoch: [41][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.4261 (0.4254) Acc@1 86.719 (85.137) Acc@5 98.438 (99.479)
2025-08-28 05:44:06,259 - INFO - Pruning info: sparsity=0.725
2025-08-28 05:44:06,259 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:44:06,468 - INFO - Epoch: [41][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3616 (0.4270) Acc@1 88.281 (85.268) Acc@5 100.000 (99.445)
2025-08-28 05:44:08,257 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5219 (0.5219) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-28 05:44:09,091 - INFO - Epoch 41:
2025-08-28 05:44:09,091 - INFO -   Train: acc1: 85.2040 | acc5: 99.4080 | loss: 0.4302 | sparsity: 0.7255 | reactivation_rate: 0.0017
2025-08-28 05:44:09,091 - INFO -   Val:   acc1: 80.8700 | acc5: 98.8700 | loss: 0.5738
2025-08-28 05:44:09,091 - INFO -   LR: 0.100000
2025-08-28 05:44:09,103 - INFO - 
Epoch: 42, lr = 0.1
2025-08-28 05:44:09,259 - INFO - Epoch: [42][0/391] Time 0.156 (0.156) Data 0.140 (0.140) Loss 0.4611 (0.4611) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:44:10,338 - INFO - Pruning info: sparsity=0.732
2025-08-28 05:44:10,338 - INFO -   Reactivation rate: 0.0025
2025-08-28 05:44:11,146 - INFO - Epoch: [42][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.6477 (0.4211) Acc@1 78.125 (85.558) Acc@5 97.656 (99.358)
2025-08-28 05:44:12,951 - INFO - Epoch: [42][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.5474 (0.4222) Acc@1 82.031 (85.475) Acc@5 98.438 (99.378)
2025-08-28 05:44:13,252 - INFO - Pruning info: sparsity=0.732
2025-08-28 05:44:13,252 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:44:14,782 - INFO - Epoch: [42][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3479 (0.4261) Acc@1 89.844 (85.385) Acc@5 98.438 (99.390)
2025-08-28 05:44:16,231 - INFO - Pruning info: sparsity=0.732
2025-08-28 05:44:16,231 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:44:16,631 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5147 (0.5147) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 05:44:17,489 - INFO - Epoch 42:
2025-08-28 05:44:17,489 - INFO -   Train: acc1: 85.2360 | acc5: 99.3700 | loss: 0.4301 | sparsity: 0.7319 | reactivation_rate: 0.0016
2025-08-28 05:44:17,489 - INFO -   Val:   acc1: 82.6200 | acc5: 99.1400 | loss: 0.5202
2025-08-28 05:44:17,489 - INFO -   LR: 0.100000
2025-08-28 05:44:17,503 - INFO - 
Epoch: 43, lr = 0.1
2025-08-28 05:44:17,694 - INFO - Epoch: [43][0/391] Time 0.191 (0.191) Data 0.157 (0.157) Loss 0.2310 (0.2310) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:44:19,681 - INFO - Epoch: [43][100/391] Time 0.016 (0.022) Data 0.000 (0.003) Loss 0.3510 (0.4267) Acc@1 88.281 (85.334) Acc@5 99.219 (99.381)
2025-08-28 05:44:20,608 - INFO - Pruning info: sparsity=0.738
2025-08-28 05:44:20,608 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:44:21,540 - INFO - Epoch: [43][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3438 (0.4153) Acc@1 89.844 (85.755) Acc@5 100.000 (99.374)
2025-08-28 05:44:23,335 - INFO - Epoch: [43][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.2570 (0.4206) Acc@1 92.188 (85.538) Acc@5 100.000 (99.385)
2025-08-28 05:44:23,428 - INFO - Pruning info: sparsity=0.738
2025-08-28 05:44:23,428 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:44:25,100 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.7929 (0.7929) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 05:44:25,961 - INFO - Epoch 43:
2025-08-28 05:44:25,961 - INFO -   Train: acc1: 85.4480 | acc5: 99.3920 | loss: 0.4220 | sparsity: 0.7379 | reactivation_rate: 0.0015
2025-08-28 05:44:25,961 - INFO -   Val:   acc1: 76.6700 | acc5: 98.5300 | loss: 0.7416
2025-08-28 05:44:25,961 - INFO -   LR: 0.100000
2025-08-28 05:44:25,978 - INFO - 
Epoch: 44, lr = 0.1
2025-08-28 05:44:26,184 - INFO - Epoch: [44][0/391] Time 0.205 (0.205) Data 0.179 (0.179) Loss 0.4122 (0.4122) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:44:27,585 - INFO - Pruning info: sparsity=0.744
2025-08-28 05:44:27,585 - INFO -   Reactivation rate: 0.0020
2025-08-28 05:44:28,026 - INFO - Epoch: [44][100/391] Time 0.011 (0.020) Data 0.001 (0.005) Loss 0.3128 (0.4123) Acc@1 87.500 (85.837) Acc@5 100.000 (99.536)
2025-08-28 05:44:29,870 - INFO - Epoch: [44][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4579 (0.4195) Acc@1 85.156 (85.840) Acc@5 99.219 (99.448)
2025-08-28 05:44:30,510 - INFO - Pruning info: sparsity=0.744
2025-08-28 05:44:30,510 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:44:31,693 - INFO - Epoch: [44][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.3232 (0.4199) Acc@1 85.938 (85.743) Acc@5 100.000 (99.432)
2025-08-28 05:44:33,473 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.8214 (0.8214) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-28 05:44:34,332 - INFO - Epoch 44:
2025-08-28 05:44:34,333 - INFO -   Train: acc1: 85.7280 | acc5: 99.4420 | loss: 0.4206 | sparsity: 0.7435 | reactivation_rate: 0.0015
2025-08-28 05:44:34,333 - INFO -   Val:   acc1: 76.0600 | acc5: 98.5400 | loss: 0.8144
2025-08-28 05:44:34,333 - INFO -   LR: 0.100000
2025-08-28 05:44:34,344 - INFO - 
Epoch: 45, lr = 0.1
2025-08-28 05:44:34,507 - INFO - Epoch: [45][0/391] Time 0.163 (0.163) Data 0.139 (0.139) Loss 0.2668 (0.2668) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:44:34,593 - INFO - Pruning info: sparsity=0.749
2025-08-28 05:44:34,593 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:44:36,352 - INFO - Epoch: [45][100/391] Time 0.030 (0.020) Data 0.014 (0.006) Loss 0.6454 (0.4188) Acc@1 80.469 (85.574) Acc@5 98.438 (99.350)
2025-08-28 05:44:37,485 - INFO - Pruning info: sparsity=0.749
2025-08-28 05:44:37,496 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:44:38,116 - INFO - Epoch: [45][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.3895 (0.4254) Acc@1 85.938 (85.471) Acc@5 99.219 (99.331)
2025-08-28 05:44:39,889 - INFO - Epoch: [45][300/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.4198 (0.4231) Acc@1 83.594 (85.553) Acc@5 99.219 (99.382)
2025-08-28 05:44:40,356 - INFO - Pruning info: sparsity=0.749
2025-08-28 05:44:40,357 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:44:41,765 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.4323 (0.4323) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:44:42,611 - INFO - Epoch 45:
2025-08-28 05:44:42,611 - INFO -   Train: acc1: 85.4620 | acc5: 99.3900 | loss: 0.4247 | sparsity: 0.7488 | reactivation_rate: 0.0014
2025-08-28 05:44:42,611 - INFO -   Val:   acc1: 80.6600 | acc5: 98.9200 | loss: 0.5825
2025-08-28 05:44:42,611 - INFO -   LR: 0.100000
2025-08-28 05:44:42,623 - INFO - 
Epoch: 46, lr = 0.1
2025-08-28 05:44:42,792 - INFO - Epoch: [46][0/391] Time 0.168 (0.168) Data 0.142 (0.142) Loss 0.3396 (0.3396) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:44:44,479 - INFO - Pruning info: sparsity=0.754
2025-08-28 05:44:44,479 - INFO -   Reactivation rate: 0.0019
2025-08-28 05:44:44,620 - INFO - Epoch: [46][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.3984 (0.4083) Acc@1 85.156 (85.992) Acc@5 100.000 (99.466)
2025-08-28 05:44:46,452 - INFO - Epoch: [46][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4596 (0.4223) Acc@1 82.031 (85.545) Acc@5 100.000 (99.386)
2025-08-28 05:44:47,413 - INFO - Pruning info: sparsity=0.754
2025-08-28 05:44:47,413 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:44:48,233 - INFO - Epoch: [46][300/391] Time 0.030 (0.019) Data 0.000 (0.003) Loss 0.4197 (0.4199) Acc@1 84.375 (85.546) Acc@5 99.219 (99.385)
2025-08-28 05:44:50,065 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.7371 (0.7371) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-28 05:44:50,902 - INFO - Epoch 46:
2025-08-28 05:44:50,903 - INFO -   Train: acc1: 85.3020 | acc5: 99.3680 | loss: 0.4257 | sparsity: 0.7538 | reactivation_rate: 0.0013
2025-08-28 05:44:50,903 - INFO -   Val:   acc1: 78.2500 | acc5: 98.5900 | loss: 0.6901
2025-08-28 05:44:50,903 - INFO -   LR: 0.100000
2025-08-28 05:44:50,913 - INFO - 
Epoch: 47, lr = 0.1
2025-08-28 05:44:51,126 - INFO - Epoch: [47][0/391] Time 0.212 (0.212) Data 0.187 (0.187) Loss 0.4593 (0.4593) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:44:51,518 - INFO - Pruning info: sparsity=0.758
2025-08-28 05:44:51,518 - INFO -   Reactivation rate: 0.0023
2025-08-28 05:44:53,019 - INFO - Epoch: [47][100/391] Time 0.013 (0.021) Data 0.000 (0.005) Loss 0.3969 (0.4039) Acc@1 87.500 (86.347) Acc@5 99.219 (99.404)
2025-08-28 05:44:54,608 - INFO - Pruning info: sparsity=0.758
2025-08-28 05:44:54,608 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:44:55,006 - INFO - Epoch: [47][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5645 (0.4172) Acc@1 80.469 (85.662) Acc@5 99.219 (99.363)
2025-08-28 05:44:56,747 - INFO - Epoch: [47][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4673 (0.4220) Acc@1 82.031 (85.408) Acc@5 100.000 (99.346)
2025-08-28 05:44:57,587 - INFO - Pruning info: sparsity=0.758
2025-08-28 05:44:57,588 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:44:58,565 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.6923 (0.6923) Acc@1 72.656 (72.656) Acc@5 100.000 (100.000)
2025-08-28 05:44:59,449 - INFO - Epoch 47:
2025-08-28 05:44:59,449 - INFO -   Train: acc1: 85.3140 | acc5: 99.3360 | loss: 0.4260 | sparsity: 0.7584 | reactivation_rate: 0.0013
2025-08-28 05:44:59,449 - INFO -   Val:   acc1: 77.6700 | acc5: 98.6900 | loss: 0.6670
2025-08-28 05:44:59,449 - INFO -   LR: 0.100000
2025-08-28 05:44:59,462 - INFO - 
Epoch: 48, lr = 0.1
2025-08-28 05:44:59,663 - INFO - Epoch: [48][0/391] Time 0.200 (0.200) Data 0.175 (0.175) Loss 0.5161 (0.5161) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 05:45:01,461 - INFO - Epoch: [48][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4196 (0.4110) Acc@1 85.938 (85.883) Acc@5 99.219 (99.582)
2025-08-28 05:45:01,686 - INFO - Pruning info: sparsity=0.763
2025-08-28 05:45:01,686 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:45:03,366 - INFO - Epoch: [48][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3670 (0.4135) Acc@1 85.938 (85.739) Acc@5 99.219 (99.510)
2025-08-28 05:45:04,631 - INFO - Pruning info: sparsity=0.763
2025-08-28 05:45:04,631 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:45:05,128 - INFO - Epoch: [48][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4421 (0.4200) Acc@1 83.594 (85.577) Acc@5 99.219 (99.515)
2025-08-28 05:45:06,849 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.6485 (0.6485) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 05:45:07,734 - INFO - Epoch 48:
2025-08-28 05:45:07,734 - INFO -   Train: acc1: 85.5020 | acc5: 99.4880 | loss: 0.4226 | sparsity: 0.7627 | reactivation_rate: 0.0012
2025-08-28 05:45:07,734 - INFO -   Val:   acc1: 78.6600 | acc5: 98.7200 | loss: 0.6562
2025-08-28 05:45:07,734 - INFO -   LR: 0.100000
2025-08-28 05:45:07,745 - INFO - 
Epoch: 49, lr = 0.1
2025-08-28 05:45:07,950 - INFO - Epoch: [49][0/391] Time 0.203 (0.203) Data 0.185 (0.185) Loss 0.4721 (0.4721) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:45:08,680 - INFO - Pruning info: sparsity=0.767
2025-08-28 05:45:08,680 - INFO -   Reactivation rate: 0.0020
2025-08-28 05:45:09,776 - INFO - Epoch: [49][100/391] Time 0.030 (0.020) Data 0.014 (0.004) Loss 0.5382 (0.4142) Acc@1 82.031 (85.775) Acc@5 99.219 (99.482)
2025-08-28 05:45:11,542 - INFO - Epoch: [49][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3517 (0.4142) Acc@1 87.500 (85.728) Acc@5 100.000 (99.429)
2025-08-28 05:45:11,556 - INFO - Pruning info: sparsity=0.767
2025-08-28 05:45:11,556 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:45:13,438 - INFO - Epoch: [49][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3339 (0.4211) Acc@1 88.281 (85.553) Acc@5 100.000 (99.406)
2025-08-28 05:45:14,548 - INFO - Pruning info: sparsity=0.767
2025-08-28 05:45:14,548 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:45:15,263 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.4367 (0.4367) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:45:16,191 - INFO - Epoch 49:
2025-08-28 05:45:16,191 - INFO -   Train: acc1: 85.5140 | acc5: 99.3820 | loss: 0.4231 | sparsity: 0.7667 | reactivation_rate: 0.0012
2025-08-28 05:45:16,191 - INFO -   Val:   acc1: 82.3400 | acc5: 99.1600 | loss: 0.5464
2025-08-28 05:45:16,191 - INFO -   LR: 0.100000
2025-08-28 05:45:16,204 - INFO - 
Epoch: 50, lr = 0.1
2025-08-28 05:45:16,399 - INFO - Epoch: [50][0/391] Time 0.194 (0.194) Data 0.175 (0.175) Loss 0.2348 (0.2348) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:45:18,221 - INFO - Epoch: [50][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.5494 (0.4134) Acc@1 81.250 (85.783) Acc@5 98.438 (99.466)
2025-08-28 05:45:18,738 - INFO - Pruning info: sparsity=0.770
2025-08-28 05:45:18,738 - INFO -   Reactivation rate: 0.0012
2025-08-28 05:45:20,092 - INFO - Epoch: [50][200/391] Time 0.020 (0.019) Data 0.005 (0.004) Loss 0.2839 (0.4173) Acc@1 89.062 (85.584) Acc@5 100.000 (99.475)
2025-08-28 05:45:21,666 - INFO - Pruning info: sparsity=0.770
2025-08-28 05:45:21,667 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:45:21,866 - INFO - Epoch: [50][300/391] Time 0.022 (0.019) Data 0.003 (0.003) Loss 0.3586 (0.4157) Acc@1 86.719 (85.634) Acc@5 100.000 (99.481)
2025-08-28 05:45:23,706 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.8506 (0.8506) Acc@1 73.438 (73.438) Acc@5 96.875 (96.875)
2025-08-28 05:45:24,548 - INFO - Epoch 50:
2025-08-28 05:45:24,548 - INFO -   Train: acc1: 85.5920 | acc5: 99.4500 | loss: 0.4173 | sparsity: 0.7704 | reactivation_rate: 0.0011
2025-08-28 05:45:24,548 - INFO -   Val:   acc1: 77.1800 | acc5: 99.0000 | loss: 0.6865
2025-08-28 05:45:24,549 - INFO -   LR: 0.100000
2025-08-28 05:45:24,596 - INFO - 
Epoch: 51, lr = 0.1
2025-08-28 05:45:24,782 - INFO - Epoch: [51][0/391] Time 0.185 (0.185) Data 0.156 (0.156) Loss 0.4312 (0.4312) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:45:25,898 - INFO - Pruning info: sparsity=0.774
2025-08-28 05:45:25,898 - INFO -   Reactivation rate: 0.0017
2025-08-28 05:45:26,672 - INFO - Epoch: [51][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.3790 (0.4132) Acc@1 87.500 (85.914) Acc@5 99.219 (99.428)
2025-08-28 05:45:28,512 - INFO - Epoch: [51][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.5091 (0.4136) Acc@1 84.375 (85.969) Acc@5 99.219 (99.436)
2025-08-28 05:45:28,916 - INFO - Pruning info: sparsity=0.774
2025-08-28 05:45:28,916 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:45:30,377 - INFO - Epoch: [51][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3054 (0.4175) Acc@1 91.406 (85.699) Acc@5 99.219 (99.424)
2025-08-28 05:45:31,800 - INFO - Pruning info: sparsity=0.774
2025-08-28 05:45:31,800 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:45:32,167 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.7618 (0.7618) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 05:45:33,013 - INFO - Epoch 51:
2025-08-28 05:45:33,013 - INFO -   Train: acc1: 85.5960 | acc5: 99.4300 | loss: 0.4205 | sparsity: 0.7738 | reactivation_rate: 0.0011
2025-08-28 05:45:33,013 - INFO -   Val:   acc1: 76.2200 | acc5: 98.3200 | loss: 0.7947
2025-08-28 05:45:33,013 - INFO -   LR: 0.100000
2025-08-28 05:45:33,024 - INFO - 
Epoch: 52, lr = 0.1
2025-08-28 05:45:33,205 - INFO - Epoch: [52][0/391] Time 0.180 (0.180) Data 0.159 (0.159) Loss 0.4909 (0.4909) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-28 05:45:35,118 - INFO - Epoch: [52][100/391] Time 0.019 (0.021) Data 0.000 (0.005) Loss 0.3156 (0.4045) Acc@1 89.844 (86.216) Acc@5 100.000 (99.466)
2025-08-28 05:45:35,960 - INFO - Pruning info: sparsity=0.777
2025-08-28 05:45:35,960 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:45:36,878 - INFO - Epoch: [52][200/391] Time 0.018 (0.019) Data 0.005 (0.004) Loss 0.3409 (0.4233) Acc@1 88.281 (85.483) Acc@5 98.438 (99.421)
2025-08-28 05:45:38,723 - INFO - Epoch: [52][300/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.4009 (0.4210) Acc@1 87.500 (85.569) Acc@5 99.219 (99.439)
2025-08-28 05:45:38,870 - INFO - Pruning info: sparsity=0.777
2025-08-28 05:45:38,870 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:45:40,508 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6202 (0.6202) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-28 05:45:41,406 - INFO - Epoch 52:
2025-08-28 05:45:41,406 - INFO -   Train: acc1: 85.5580 | acc5: 99.4400 | loss: 0.4222 | sparsity: 0.7769 | reactivation_rate: 0.0011
2025-08-28 05:45:41,406 - INFO -   Val:   acc1: 81.0000 | acc5: 98.9900 | loss: 0.5855
2025-08-28 05:45:41,406 - INFO -   LR: 0.100000
2025-08-28 05:45:41,420 - INFO - 
Epoch: 53, lr = 0.1
2025-08-28 05:45:41,598 - INFO - Epoch: [53][0/391] Time 0.177 (0.177) Data 0.152 (0.152) Loss 0.4782 (0.4782) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 05:45:43,011 - INFO - Pruning info: sparsity=0.780
2025-08-28 05:45:43,012 - INFO -   Reactivation rate: 0.0014
2025-08-28 05:45:43,513 - INFO - Epoch: [53][100/391] Time 0.028 (0.021) Data 0.009 (0.004) Loss 0.4036 (0.4173) Acc@1 84.375 (85.659) Acc@5 99.219 (99.459)
2025-08-28 05:45:45,352 - INFO - Epoch: [53][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.3973 (0.4174) Acc@1 88.281 (85.735) Acc@5 100.000 (99.471)
2025-08-28 05:45:45,989 - INFO - Pruning info: sparsity=0.780
2025-08-28 05:45:45,989 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:45:47,222 - INFO - Epoch: [53][300/391] Time 0.033 (0.019) Data 0.009 (0.003) Loss 0.4538 (0.4204) Acc@1 81.250 (85.496) Acc@5 99.219 (99.468)
2025-08-28 05:45:48,989 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.4790 (0.4790) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:45:49,811 - INFO - Epoch 53:
2025-08-28 05:45:49,811 - INFO -   Train: acc1: 85.4720 | acc5: 99.4740 | loss: 0.4204 | sparsity: 0.7798 | reactivation_rate: 0.0010
2025-08-28 05:45:49,811 - INFO -   Val:   acc1: 81.8100 | acc5: 99.0500 | loss: 0.5556
2025-08-28 05:45:49,811 - INFO -   LR: 0.100000
2025-08-28 05:45:49,825 - INFO - 
Epoch: 54, lr = 0.1
2025-08-28 05:45:50,008 - INFO - Epoch: [54][0/391] Time 0.182 (0.182) Data 0.166 (0.166) Loss 0.3228 (0.3228) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:45:50,106 - INFO - Pruning info: sparsity=0.782
2025-08-28 05:45:50,107 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:45:51,793 - INFO - Epoch: [54][100/391] Time 0.029 (0.019) Data 0.017 (0.005) Loss 0.3772 (0.4197) Acc@1 88.281 (85.481) Acc@5 99.219 (99.443)
2025-08-28 05:45:52,925 - INFO - Pruning info: sparsity=0.782
2025-08-28 05:45:52,925 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:45:53,559 - INFO - Epoch: [54][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4853 (0.4163) Acc@1 82.031 (85.553) Acc@5 100.000 (99.506)
2025-08-28 05:45:55,325 - INFO - Epoch: [54][300/391] Time 0.010 (0.018) Data 0.000 (0.004) Loss 0.4030 (0.4115) Acc@1 85.938 (85.735) Acc@5 98.438 (99.491)
2025-08-28 05:45:55,794 - INFO - Pruning info: sparsity=0.782
2025-08-28 05:45:55,795 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:45:57,070 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.6831 (0.6831) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:45:57,910 - INFO - Epoch 54:
2025-08-28 05:45:57,910 - INFO -   Train: acc1: 85.6600 | acc5: 99.4620 | loss: 0.4170 | sparsity: 0.7824 | reactivation_rate: 0.0009
2025-08-28 05:45:57,910 - INFO -   Val:   acc1: 78.3900 | acc5: 98.8300 | loss: 0.6820
2025-08-28 05:45:57,910 - INFO -   LR: 0.100000
2025-08-28 05:45:57,922 - INFO - 
Epoch: 55, lr = 0.1
2025-08-28 05:45:58,099 - INFO - Epoch: [55][0/391] Time 0.176 (0.176) Data 0.156 (0.156) Loss 0.3410 (0.3410) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:45:59,821 - INFO - Pruning info: sparsity=0.785
2025-08-28 05:45:59,821 - INFO -   Reactivation rate: 0.0011
2025-08-28 05:45:59,902 - INFO - Epoch: [55][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4552 (0.4115) Acc@1 81.250 (86.023) Acc@5 100.000 (99.451)
2025-08-28 05:46:01,652 - INFO - Epoch: [55][200/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.4243 (0.4149) Acc@1 85.938 (85.751) Acc@5 100.000 (99.471)
2025-08-28 05:46:02,618 - INFO - Pruning info: sparsity=0.785
2025-08-28 05:46:02,618 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:46:03,402 - INFO - Epoch: [55][300/391] Time 0.020 (0.018) Data 0.000 (0.004) Loss 0.3816 (0.4172) Acc@1 87.500 (85.621) Acc@5 99.219 (99.442)
2025-08-28 05:46:05,154 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.4527 (0.4527) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:46:05,995 - INFO - Epoch 55:
2025-08-28 05:46:05,995 - INFO -   Train: acc1: 85.5100 | acc5: 99.4200 | loss: 0.4202 | sparsity: 0.7848 | reactivation_rate: 0.0008
2025-08-28 05:46:05,995 - INFO -   Val:   acc1: 82.5600 | acc5: 99.1600 | loss: 0.5328
2025-08-28 05:46:05,995 - INFO -   LR: 0.100000
2025-08-28 05:46:06,007 - INFO - 
Epoch: 56, lr = 0.1
2025-08-28 05:46:06,197 - INFO - Epoch: [56][0/391] Time 0.189 (0.189) Data 0.157 (0.157) Loss 0.3984 (0.3984) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:46:06,600 - INFO - Pruning info: sparsity=0.787
2025-08-28 05:46:06,600 - INFO -   Reactivation rate: 0.0015
2025-08-28 05:46:07,941 - INFO - Epoch: [56][100/391] Time 0.028 (0.019) Data 0.015 (0.004) Loss 0.4714 (0.4032) Acc@1 77.344 (85.953) Acc@5 99.219 (99.397)
2025-08-28 05:46:09,401 - INFO - Pruning info: sparsity=0.787
2025-08-28 05:46:09,401 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:46:09,738 - INFO - Epoch: [56][200/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.4290 (0.4122) Acc@1 85.938 (85.638) Acc@5 99.219 (99.370)
2025-08-28 05:46:11,477 - INFO - Epoch: [56][300/391] Time 0.026 (0.018) Data 0.015 (0.003) Loss 0.3134 (0.4151) Acc@1 89.062 (85.595) Acc@5 100.000 (99.393)
2025-08-28 05:46:12,232 - INFO - Pruning info: sparsity=0.787
2025-08-28 05:46:12,232 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:46:13,262 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.5032 (0.5032) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:46:14,062 - INFO - Epoch 56:
2025-08-28 05:46:14,062 - INFO -   Train: acc1: 85.5820 | acc5: 99.3840 | loss: 0.4185 | sparsity: 0.7870 | reactivation_rate: 0.0008
2025-08-28 05:46:14,062 - INFO -   Val:   acc1: 80.0900 | acc5: 99.2100 | loss: 0.5828
2025-08-28 05:46:14,062 - INFO -   LR: 0.100000
2025-08-28 05:46:14,074 - INFO - 
Epoch: 57, lr = 0.1
2025-08-28 05:46:14,255 - INFO - Epoch: [57][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.2959 (0.2959) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:46:16,013 - INFO - Epoch: [57][100/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.3975 (0.4056) Acc@1 87.500 (85.783) Acc@5 99.219 (99.366)
2025-08-28 05:46:16,238 - INFO - Pruning info: sparsity=0.789
2025-08-28 05:46:16,239 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:46:17,764 - INFO - Epoch: [57][200/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.3353 (0.4163) Acc@1 89.062 (85.751) Acc@5 100.000 (99.413)
2025-08-28 05:46:19,091 - INFO - Pruning info: sparsity=0.789
2025-08-28 05:46:19,092 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:46:19,575 - INFO - Epoch: [57][300/391] Time 0.012 (0.018) Data 0.001 (0.004) Loss 0.4481 (0.4146) Acc@1 84.375 (85.813) Acc@5 99.219 (99.465)
2025-08-28 05:46:21,312 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.6975 (0.6975) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 05:46:22,137 - INFO - Epoch 57:
2025-08-28 05:46:22,137 - INFO -   Train: acc1: 85.8120 | acc5: 99.4480 | loss: 0.4148 | sparsity: 0.7889 | reactivation_rate: 0.0008
2025-08-28 05:46:22,137 - INFO -   Val:   acc1: 78.9800 | acc5: 98.7900 | loss: 0.6574
2025-08-28 05:46:22,137 - INFO -   LR: 0.100000
2025-08-28 05:46:22,149 - INFO - 
Epoch: 58, lr = 0.1
2025-08-28 05:46:22,331 - INFO - Epoch: [58][0/391] Time 0.180 (0.180) Data 0.164 (0.164) Loss 0.4083 (0.4083) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:46:23,072 - INFO - Pruning info: sparsity=0.791
2025-08-28 05:46:23,072 - INFO -   Reactivation rate: 0.0013
2025-08-28 05:46:24,141 - INFO - Epoch: [58][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.3378 (0.4141) Acc@1 92.188 (85.713) Acc@5 99.219 (99.459)
2025-08-28 05:46:25,837 - INFO - Epoch: [58][200/391] Time 0.013 (0.018) Data 0.002 (0.003) Loss 0.4323 (0.4216) Acc@1 83.594 (85.514) Acc@5 98.438 (99.409)
2025-08-28 05:46:25,860 - INFO - Pruning info: sparsity=0.791
2025-08-28 05:46:25,860 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:46:27,616 - INFO - Epoch: [58][300/391] Time 0.012 (0.018) Data 0.000 (0.004) Loss 0.4291 (0.4250) Acc@1 84.375 (85.379) Acc@5 100.000 (99.403)
2025-08-28 05:46:28,697 - INFO - Pruning info: sparsity=0.791
2025-08-28 05:46:28,698 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:46:29,323 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.9231 (0.9231) Acc@1 71.875 (71.875) Acc@5 97.656 (97.656)
2025-08-28 05:46:30,149 - INFO - Epoch 58:
2025-08-28 05:46:30,150 - INFO -   Train: acc1: 85.4520 | acc5: 99.3940 | loss: 0.4243 | sparsity: 0.7907 | reactivation_rate: 0.0008
2025-08-28 05:46:30,150 - INFO -   Val:   acc1: 72.9800 | acc5: 97.5300 | loss: 0.8771
2025-08-28 05:46:30,150 - INFO -   LR: 0.100000
2025-08-28 05:46:30,163 - INFO - 
Epoch: 59, lr = 0.1
2025-08-28 05:46:30,332 - INFO - Epoch: [59][0/391] Time 0.167 (0.167) Data 0.144 (0.144) Loss 0.4453 (0.4453) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:46:32,147 - INFO - Epoch: [59][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.4264 (0.3965) Acc@1 85.156 (86.262) Acc@5 100.000 (99.575)
2025-08-28 05:46:32,655 - INFO - Pruning info: sparsity=0.792
2025-08-28 05:46:32,655 - INFO -   Reactivation rate: 0.0009
2025-08-28 05:46:33,914 - INFO - Epoch: [59][200/391] Time 0.029 (0.019) Data 0.015 (0.004) Loss 0.5002 (0.4106) Acc@1 84.375 (85.731) Acc@5 98.438 (99.537)
2025-08-28 05:46:35,515 - INFO - Pruning info: sparsity=0.792
2025-08-28 05:46:35,516 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:46:35,651 - INFO - Epoch: [59][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4984 (0.4152) Acc@1 81.250 (85.530) Acc@5 99.219 (99.468)
2025-08-28 05:46:37,410 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5461 (0.5461) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:46:38,230 - INFO - Epoch 59:
2025-08-28 05:46:38,230 - INFO -   Train: acc1: 85.5920 | acc5: 99.4440 | loss: 0.4150 | sparsity: 0.7922 | reactivation_rate: 0.0007
2025-08-28 05:46:38,230 - INFO -   Val:   acc1: 77.3800 | acc5: 98.9600 | loss: 0.6706
2025-08-28 05:46:38,230 - INFO -   LR: 0.100000
2025-08-28 05:46:38,244 - INFO - 
Epoch: 60, lr = 0.1
2025-08-28 05:46:38,456 - INFO - Epoch: [60][0/391] Time 0.211 (0.211) Data 0.188 (0.188) Loss 0.4601 (0.4601) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 05:46:39,591 - INFO - Pruning info: sparsity=0.794
2025-08-28 05:46:39,591 - INFO -   Reactivation rate: 0.0010
2025-08-28 05:46:40,361 - INFO - Epoch: [60][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4837 (0.4079) Acc@1 79.688 (85.992) Acc@5 98.438 (99.435)
2025-08-28 05:46:42,257 - INFO - Epoch: [60][200/391] Time 0.028 (0.020) Data 0.008 (0.003) Loss 0.3422 (0.4146) Acc@1 89.844 (85.724) Acc@5 100.000 (99.409)
2025-08-28 05:46:42,549 - INFO - Pruning info: sparsity=0.794
2025-08-28 05:46:42,549 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:46:44,120 - INFO - Epoch: [60][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3376 (0.4149) Acc@1 89.062 (85.751) Acc@5 99.219 (99.419)
2025-08-28 05:46:45,535 - INFO - Pruning info: sparsity=0.794
2025-08-28 05:46:45,535 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:46:45,890 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.6107 (0.6107) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 05:46:46,748 - INFO - Epoch 60:
2025-08-28 05:46:46,748 - INFO -   Train: acc1: 85.5860 | acc5: 99.4100 | loss: 0.4167 | sparsity: 0.7936 | reactivation_rate: 0.0007
2025-08-28 05:46:46,748 - INFO -   Val:   acc1: 78.5600 | acc5: 98.4100 | loss: 0.6581
2025-08-28 05:46:46,748 - INFO -   LR: 0.100000
2025-08-28 05:46:47,040 - INFO - 
Epoch: 61, lr = 0.1
2025-08-28 05:46:47,234 - INFO - Epoch: [61][0/391] Time 0.192 (0.192) Data 0.168 (0.168) Loss 0.4303 (0.4303) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:46:49,048 - INFO - Epoch: [61][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4023 (0.3912) Acc@1 87.500 (86.603) Acc@5 100.000 (99.613)
2025-08-28 05:46:49,947 - INFO - Pruning info: sparsity=0.795
2025-08-28 05:46:49,947 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:46:50,904 - INFO - Epoch: [61][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4126 (0.4113) Acc@1 87.500 (85.786) Acc@5 100.000 (99.510)
2025-08-28 05:46:52,708 - INFO - Epoch: [61][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.4635 (0.4109) Acc@1 82.812 (85.901) Acc@5 100.000 (99.476)
2025-08-28 05:46:52,844 - INFO - Pruning info: sparsity=0.795
2025-08-28 05:46:52,845 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:46:54,503 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.5155 (0.5155) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:46:55,362 - INFO - Epoch 61:
2025-08-28 05:46:55,362 - INFO -   Train: acc1: 85.6920 | acc5: 99.4460 | loss: 0.4180 | sparsity: 0.7948 | reactivation_rate: 0.0006
2025-08-28 05:46:55,362 - INFO -   Val:   acc1: 82.5700 | acc5: 99.1400 | loss: 0.5335
2025-08-28 05:46:55,362 - INFO -   LR: 0.100000
2025-08-28 05:46:55,376 - INFO - 
Epoch: 62, lr = 0.1
2025-08-28 05:46:55,564 - INFO - Epoch: [62][0/391] Time 0.187 (0.187) Data 0.149 (0.149) Loss 0.3795 (0.3795) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:46:57,021 - INFO - Pruning info: sparsity=0.796
2025-08-28 05:46:57,022 - INFO -   Reactivation rate: 0.0007
2025-08-28 05:46:57,468 - INFO - Epoch: [62][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.4416 (0.4091) Acc@1 82.812 (85.721) Acc@5 100.000 (99.528)
2025-08-28 05:46:59,250 - INFO - Epoch: [62][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3366 (0.4072) Acc@1 89.844 (85.945) Acc@5 99.219 (99.495)
2025-08-28 05:46:59,943 - INFO - Pruning info: sparsity=0.796
2025-08-28 05:46:59,943 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:47:01,173 - INFO - Epoch: [62][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3273 (0.4112) Acc@1 89.844 (85.995) Acc@5 100.000 (99.437)
2025-08-28 05:47:02,935 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5289 (0.5289) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:47:03,763 - INFO - Epoch 62:
2025-08-28 05:47:03,763 - INFO -   Train: acc1: 85.7400 | acc5: 99.4040 | loss: 0.4174 | sparsity: 0.7958 | reactivation_rate: 0.0006
2025-08-28 05:47:03,763 - INFO -   Val:   acc1: 81.3700 | acc5: 99.2900 | loss: 0.5677
2025-08-28 05:47:03,763 - INFO -   LR: 0.100000
2025-08-28 05:47:03,775 - INFO - 
Epoch: 63, lr = 0.1
2025-08-28 05:47:03,962 - INFO - Epoch: [63][0/391] Time 0.186 (0.186) Data 0.149 (0.149) Loss 0.3966 (0.3966) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:47:04,084 - INFO - Pruning info: sparsity=0.797
2025-08-28 05:47:04,084 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:47:05,867 - INFO - Epoch: [63][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.4425 (0.3800) Acc@1 83.594 (86.959) Acc@5 99.219 (99.482)
2025-08-28 05:47:07,066 - INFO - Pruning info: sparsity=0.797
2025-08-28 05:47:07,066 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:47:07,669 - INFO - Epoch: [63][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4918 (0.3980) Acc@1 83.594 (86.311) Acc@5 99.219 (99.444)
2025-08-28 05:47:09,566 - INFO - Epoch: [63][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.3706 (0.4047) Acc@1 85.938 (85.969) Acc@5 100.000 (99.447)
2025-08-28 05:47:10,058 - INFO - Pruning info: sparsity=0.797
2025-08-28 05:47:10,058 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:11,427 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.8217 (0.8217) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 05:47:12,269 - INFO - Epoch 63:
2025-08-28 05:47:12,270 - INFO -   Train: acc1: 85.7040 | acc5: 99.4540 | loss: 0.4120 | sparsity: 0.7967 | reactivation_rate: 0.0005
2025-08-28 05:47:12,270 - INFO -   Val:   acc1: 73.0500 | acc5: 97.7900 | loss: 0.8575
2025-08-28 05:47:12,270 - INFO -   LR: 0.100000
2025-08-28 05:47:12,284 - INFO - 
Epoch: 64, lr = 0.1
2025-08-28 05:47:12,463 - INFO - Epoch: [64][0/391] Time 0.178 (0.178) Data 0.153 (0.153) Loss 0.2883 (0.2883) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:47:14,264 - INFO - Pruning info: sparsity=0.797
2025-08-28 05:47:14,264 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:47:14,389 - INFO - Epoch: [64][100/391] Time 0.026 (0.021) Data 0.000 (0.004) Loss 0.4713 (0.4107) Acc@1 85.156 (86.286) Acc@5 100.000 (99.497)
2025-08-28 05:47:16,192 - INFO - Epoch: [64][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.4326 (0.4151) Acc@1 85.156 (85.833) Acc@5 100.000 (99.456)
2025-08-28 05:47:17,187 - INFO - Pruning info: sparsity=0.797
2025-08-28 05:47:17,187 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:18,021 - INFO - Epoch: [64][300/391] Time 0.019 (0.019) Data 0.005 (0.003) Loss 0.5247 (0.4159) Acc@1 82.812 (85.753) Acc@5 99.219 (99.463)
2025-08-28 05:47:19,817 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.6586 (0.6586) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 05:47:20,661 - INFO - Epoch 64:
2025-08-28 05:47:20,661 - INFO -   Train: acc1: 85.8320 | acc5: 99.4320 | loss: 0.4152 | sparsity: 0.7975 | reactivation_rate: 0.0005
2025-08-28 05:47:20,661 - INFO -   Val:   acc1: 76.2500 | acc5: 98.0000 | loss: 0.7066
2025-08-28 05:47:20,661 - INFO -   LR: 0.100000
2025-08-28 05:47:20,675 - INFO - 
Epoch: 65, lr = 0.1
2025-08-28 05:47:20,863 - INFO - Epoch: [65][0/391] Time 0.187 (0.187) Data 0.161 (0.161) Loss 0.2918 (0.2918) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:47:21,275 - INFO - Pruning info: sparsity=0.798
2025-08-28 05:47:21,277 - INFO -   Reactivation rate: 0.0008
2025-08-28 05:47:22,702 - INFO - Epoch: [65][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3895 (0.4150) Acc@1 87.500 (85.938) Acc@5 99.219 (99.505)
2025-08-28 05:47:24,222 - INFO - Pruning info: sparsity=0.798
2025-08-28 05:47:24,222 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:24,502 - INFO - Epoch: [65][200/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.4429 (0.4108) Acc@1 88.281 (86.035) Acc@5 100.000 (99.506)
2025-08-28 05:47:26,320 - INFO - Epoch: [65][300/391] Time 0.016 (0.019) Data 0.001 (0.003) Loss 0.3742 (0.4138) Acc@1 88.281 (85.886) Acc@5 98.438 (99.473)
2025-08-28 05:47:27,058 - INFO - Pruning info: sparsity=0.798
2025-08-28 05:47:27,058 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:28,047 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.5515 (0.5515) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:47:28,938 - INFO - Epoch 65:
2025-08-28 05:47:28,938 - INFO -   Train: acc1: 85.7100 | acc5: 99.4380 | loss: 0.4182 | sparsity: 0.7981 | reactivation_rate: 0.0005
2025-08-28 05:47:28,939 - INFO -   Val:   acc1: 80.5800 | acc5: 99.1600 | loss: 0.5637
2025-08-28 05:47:28,939 - INFO -   LR: 0.100000
2025-08-28 05:47:28,952 - INFO - 
Epoch: 66, lr = 0.1
2025-08-28 05:47:29,154 - INFO - Epoch: [66][0/391] Time 0.200 (0.200) Data 0.169 (0.169) Loss 0.3216 (0.3216) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:47:30,963 - INFO - Epoch: [66][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.2921 (0.3984) Acc@1 89.844 (86.139) Acc@5 100.000 (99.505)
2025-08-28 05:47:31,194 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:31,195 - INFO -   Reactivation rate: 0.0005
2025-08-28 05:47:32,787 - INFO - Epoch: [66][200/391] Time 0.021 (0.019) Data 0.010 (0.004) Loss 0.5071 (0.4081) Acc@1 81.250 (85.887) Acc@5 99.219 (99.433)
2025-08-28 05:47:34,148 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:34,149 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:34,661 - INFO - Epoch: [66][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4714 (0.4196) Acc@1 86.719 (85.413) Acc@5 98.438 (99.393)
2025-08-28 05:47:36,458 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.8682 (0.8682) Acc@1 71.875 (71.875) Acc@5 100.000 (100.000)
2025-08-28 05:47:37,313 - INFO - Epoch 66:
2025-08-28 05:47:37,313 - INFO -   Train: acc1: 85.5340 | acc5: 99.4020 | loss: 0.4173 | sparsity: 0.7986 | reactivation_rate: 0.0004
2025-08-28 05:47:37,313 - INFO -   Val:   acc1: 71.5900 | acc5: 97.9000 | loss: 0.9352
2025-08-28 05:47:37,314 - INFO -   LR: 0.100000
2025-08-28 05:47:37,326 - INFO - 
Epoch: 67, lr = 0.1
2025-08-28 05:47:37,510 - INFO - Epoch: [67][0/391] Time 0.183 (0.183) Data 0.163 (0.163) Loss 0.3892 (0.3892) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 05:47:38,256 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:38,256 - INFO -   Reactivation rate: 0.0006
2025-08-28 05:47:39,353 - INFO - Epoch: [67][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.3501 (0.3990) Acc@1 89.062 (86.665) Acc@5 100.000 (99.443)
2025-08-28 05:47:41,222 - INFO - Epoch: [67][200/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.3111 (0.4151) Acc@1 88.281 (85.922) Acc@5 100.000 (99.436)
2025-08-28 05:47:41,259 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:41,259 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:47:43,058 - INFO - Epoch: [67][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.3711 (0.4098) Acc@1 87.500 (86.062) Acc@5 99.219 (99.452)
2025-08-28 05:47:44,204 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:44,204 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:47:44,861 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.7377 (0.7377) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 05:47:45,699 - INFO - Epoch 67:
2025-08-28 05:47:45,699 - INFO -   Train: acc1: 85.9540 | acc5: 99.4220 | loss: 0.4130 | sparsity: 0.7990 | reactivation_rate: 0.0004
2025-08-28 05:47:45,699 - INFO -   Val:   acc1: 76.9000 | acc5: 98.4500 | loss: 0.7378
2025-08-28 05:47:45,699 - INFO -   LR: 0.100000
2025-08-28 05:47:46,542 - INFO - 
Epoch: 68, lr = 0.1
2025-08-28 05:47:46,721 - INFO - Epoch: [68][0/391] Time 0.178 (0.178) Data 0.151 (0.151) Loss 0.3063 (0.3063) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:47:48,521 - INFO - Epoch: [68][100/391] Time 0.025 (0.020) Data 0.000 (0.004) Loss 0.4513 (0.4079) Acc@1 84.375 (85.976) Acc@5 99.219 (99.435)
2025-08-28 05:47:49,100 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:49,100 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:50,372 - INFO - Epoch: [68][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4369 (0.4133) Acc@1 86.719 (85.615) Acc@5 100.000 (99.394)
2025-08-28 05:47:51,990 - INFO - Pruning info: sparsity=0.799
2025-08-28 05:47:51,990 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:47:52,109 - INFO - Epoch: [68][300/391] Time 0.012 (0.018) Data 0.000 (0.002) Loss 0.4580 (0.4137) Acc@1 85.156 (85.605) Acc@5 99.219 (99.400)
2025-08-28 05:47:53,922 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6427 (0.6427) Acc@1 75.781 (75.781) Acc@5 98.438 (98.438)
2025-08-28 05:47:54,790 - INFO - Epoch 68:
2025-08-28 05:47:54,791 - INFO -   Train: acc1: 85.6880 | acc5: 99.3840 | loss: 0.4134 | sparsity: 0.7993 | reactivation_rate: 0.0003
2025-08-28 05:47:54,791 - INFO -   Val:   acc1: 79.6000 | acc5: 97.9500 | loss: 0.6603
2025-08-28 05:47:54,791 - INFO -   LR: 0.100000
2025-08-28 05:47:54,805 - INFO - 
Epoch: 69, lr = 0.1
2025-08-28 05:47:55,002 - INFO - Epoch: [69][0/391] Time 0.197 (0.197) Data 0.178 (0.178) Loss 0.4080 (0.4080) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:47:56,163 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:47:56,163 - INFO -   Reactivation rate: 0.0004
2025-08-28 05:47:56,860 - INFO - Epoch: [69][100/391] Time 0.033 (0.020) Data 0.021 (0.004) Loss 0.4006 (0.4100) Acc@1 87.500 (85.767) Acc@5 100.000 (99.544)
2025-08-28 05:47:58,710 - INFO - Epoch: [69][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4576 (0.4103) Acc@1 86.719 (85.654) Acc@5 99.219 (99.514)
2025-08-28 05:47:59,096 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:47:59,097 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:48:00,580 - INFO - Epoch: [69][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.5090 (0.4152) Acc@1 82.812 (85.657) Acc@5 100.000 (99.512)
2025-08-28 05:48:02,017 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:02,017 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:02,345 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.8218 (0.8218) Acc@1 72.656 (72.656) Acc@5 100.000 (100.000)
2025-08-28 05:48:03,197 - INFO - Epoch 69:
2025-08-28 05:48:03,198 - INFO -   Train: acc1: 85.5460 | acc5: 99.4860 | loss: 0.4173 | sparsity: 0.7996 | reactivation_rate: 0.0003
2025-08-28 05:48:03,198 - INFO -   Val:   acc1: 75.3300 | acc5: 98.8100 | loss: 0.7892
2025-08-28 05:48:03,198 - INFO -   LR: 0.100000
2025-08-28 05:48:03,214 - INFO - 
Epoch: 70, lr = 0.1
2025-08-28 05:48:03,388 - INFO - Epoch: [70][0/391] Time 0.173 (0.173) Data 0.143 (0.143) Loss 0.5346 (0.5346) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 05:48:05,257 - INFO - Epoch: [70][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.3938 (0.4013) Acc@1 87.500 (85.930) Acc@5 100.000 (99.520)
2025-08-28 05:48:06,169 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:06,169 - INFO -   Reactivation rate: 0.0003
2025-08-28 05:48:07,095 - INFO - Epoch: [70][200/391] Time 0.012 (0.019) Data 0.001 (0.002) Loss 0.3160 (0.4115) Acc@1 89.062 (85.786) Acc@5 99.219 (99.390)
2025-08-28 05:48:08,912 - INFO - Epoch: [70][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.2486 (0.4156) Acc@1 91.406 (85.655) Acc@5 100.000 (99.387)
2025-08-28 05:48:09,078 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:09,078 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:10,751 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.6394 (0.6394) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:48:11,591 - INFO - Epoch 70:
2025-08-28 05:48:11,591 - INFO -   Train: acc1: 85.9000 | acc5: 99.4000 | loss: 0.4119 | sparsity: 0.7998 | reactivation_rate: 0.0003
2025-08-28 05:48:11,592 - INFO -   Val:   acc1: 78.7400 | acc5: 98.8900 | loss: 0.6688
2025-08-28 05:48:11,592 - INFO -   LR: 0.100000
2025-08-28 05:48:11,639 - INFO - 
Epoch: 71, lr = 0.1
2025-08-28 05:48:11,825 - INFO - Epoch: [71][0/391] Time 0.186 (0.186) Data 0.164 (0.164) Loss 0.3010 (0.3010) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:48:13,265 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:13,265 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:13,660 - INFO - Epoch: [71][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3755 (0.4006) Acc@1 86.719 (86.309) Acc@5 98.438 (99.536)
2025-08-28 05:48:15,576 - INFO - Epoch: [71][200/391] Time 0.050 (0.020) Data 0.037 (0.005) Loss 0.3813 (0.4083) Acc@1 88.281 (86.042) Acc@5 99.219 (99.491)
2025-08-28 05:48:16,293 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:16,293 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:17,451 - INFO - Epoch: [71][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.3320 (0.4111) Acc@1 86.719 (85.873) Acc@5 100.000 (99.473)
2025-08-28 05:48:19,212 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.4815 (0.4815) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:48:20,057 - INFO - Epoch 71:
2025-08-28 05:48:20,057 - INFO -   Train: acc1: 85.6520 | acc5: 99.4360 | loss: 0.4149 | sparsity: 0.7999 | reactivation_rate: 0.0002
2025-08-28 05:48:20,058 - INFO -   Val:   acc1: 83.2800 | acc5: 99.3000 | loss: 0.4816
2025-08-28 05:48:20,058 - INFO -   LR: 0.100000
2025-08-28 05:48:20,107 - INFO - Checkpoint saved: epoch=71, metric=83.2800
2025-08-28 05:48:20,139 - INFO - 
Epoch: 72, lr = 0.1
2025-08-28 05:48:20,325 - INFO - Epoch: [72][0/391] Time 0.186 (0.186) Data 0.149 (0.149) Loss 0.4268 (0.4268) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:48:20,516 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:20,517 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:22,149 - INFO - Epoch: [72][100/391] Time 0.015 (0.020) Data 0.004 (0.004) Loss 0.2743 (0.4030) Acc@1 89.062 (86.108) Acc@5 100.000 (99.505)
2025-08-28 05:48:23,400 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:23,400 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:23,997 - INFO - Epoch: [72][200/391] Time 0.045 (0.019) Data 0.015 (0.003) Loss 0.4761 (0.4177) Acc@1 83.594 (85.541) Acc@5 99.219 (99.386)
2025-08-28 05:48:25,918 - INFO - Epoch: [72][300/391] Time 0.019 (0.019) Data 0.008 (0.003) Loss 0.5196 (0.4191) Acc@1 85.156 (85.579) Acc@5 97.656 (99.424)
2025-08-28 05:48:26,433 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:26,433 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:27,699 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.5940 (0.5940) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:48:28,566 - INFO - Epoch 72:
2025-08-28 05:48:28,566 - INFO -   Train: acc1: 85.5740 | acc5: 99.4540 | loss: 0.4187 | sparsity: 0.7999 | reactivation_rate: 0.0002
2025-08-28 05:48:28,566 - INFO -   Val:   acc1: 81.1200 | acc5: 98.7500 | loss: 0.6097
2025-08-28 05:48:28,566 - INFO -   LR: 0.100000
2025-08-28 05:48:28,578 - INFO - 
Epoch: 73, lr = 0.1
2025-08-28 05:48:28,780 - INFO - Epoch: [73][0/391] Time 0.201 (0.201) Data 0.180 (0.180) Loss 0.3191 (0.3191) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:48:30,590 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:30,591 - INFO -   Reactivation rate: 0.0002
2025-08-28 05:48:30,656 - INFO - Epoch: [73][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.3056 (0.3995) Acc@1 88.281 (86.185) Acc@5 100.000 (99.551)
2025-08-28 05:48:32,479 - INFO - Epoch: [73][200/391] Time 0.033 (0.019) Data 0.022 (0.004) Loss 0.4376 (0.4096) Acc@1 85.938 (85.794) Acc@5 100.000 (99.491)
2025-08-28 05:48:33,485 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:33,485 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:34,270 - INFO - Epoch: [73][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3589 (0.4116) Acc@1 85.156 (85.847) Acc@5 100.000 (99.502)
2025-08-28 05:48:36,070 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3606 (0.3606) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:48:36,921 - INFO - Epoch 73:
2025-08-28 05:48:36,921 - INFO -   Train: acc1: 85.9780 | acc5: 99.4680 | loss: 0.4126 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:48:36,921 - INFO -   Val:   acc1: 82.2000 | acc5: 99.2800 | loss: 0.5272
2025-08-28 05:48:36,921 - INFO -   LR: 0.100000
2025-08-28 05:48:36,936 - INFO - 
Epoch: 74, lr = 0.1
2025-08-28 05:48:37,131 - INFO - Epoch: [74][0/391] Time 0.193 (0.193) Data 0.171 (0.171) Loss 0.5596 (0.5596) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 05:48:37,631 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:37,631 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:39,025 - INFO - Epoch: [74][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3977 (0.4170) Acc@1 85.156 (85.814) Acc@5 100.000 (99.350)
2025-08-28 05:48:40,584 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:40,585 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:40,859 - INFO - Epoch: [74][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4522 (0.4125) Acc@1 83.594 (85.731) Acc@5 99.219 (99.421)
2025-08-28 05:48:42,707 - INFO - Epoch: [74][300/391] Time 0.019 (0.019) Data 0.006 (0.003) Loss 0.3525 (0.4121) Acc@1 86.719 (85.795) Acc@5 98.438 (99.450)
2025-08-28 05:48:43,517 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:43,517 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:44,446 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5523 (0.5523) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 05:48:45,302 - INFO - Epoch 74:
2025-08-28 05:48:45,302 - INFO -   Train: acc1: 85.6360 | acc5: 99.4480 | loss: 0.4164 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:48:45,302 - INFO -   Val:   acc1: 80.0800 | acc5: 99.2200 | loss: 0.5785
2025-08-28 05:48:45,302 - INFO -   LR: 0.100000
2025-08-28 05:48:45,316 - INFO - 
Epoch: 75, lr = 0.1
2025-08-28 05:48:45,519 - INFO - Epoch: [75][0/391] Time 0.202 (0.202) Data 0.173 (0.173) Loss 0.2800 (0.2800) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:48:47,539 - INFO - Epoch: [75][100/391] Time 0.012 (0.022) Data 0.000 (0.004) Loss 0.4034 (0.4075) Acc@1 87.500 (86.046) Acc@5 98.438 (99.551)
2025-08-28 05:48:47,737 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:47,737 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:49,389 - INFO - Epoch: [75][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3115 (0.4105) Acc@1 89.062 (85.918) Acc@5 100.000 (99.553)
2025-08-28 05:48:50,768 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:50,768 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:51,262 - INFO - Epoch: [75][300/391] Time 0.028 (0.020) Data 0.015 (0.002) Loss 0.6282 (0.4139) Acc@1 80.469 (85.639) Acc@5 98.438 (99.509)
2025-08-28 05:48:53,057 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.7751 (0.7751) Acc@1 75.000 (75.000) Acc@5 94.531 (94.531)
2025-08-28 05:48:53,912 - INFO - Epoch 75:
2025-08-28 05:48:53,912 - INFO -   Train: acc1: 85.6220 | acc5: 99.4960 | loss: 0.4150 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:48:53,912 - INFO -   Val:   acc1: 77.6700 | acc5: 97.8000 | loss: 0.7021
2025-08-28 05:48:53,912 - INFO -   LR: 0.100000
2025-08-28 05:48:53,925 - INFO - 
Epoch: 76, lr = 0.1
2025-08-28 05:48:54,138 - INFO - Epoch: [76][0/391] Time 0.211 (0.211) Data 0.185 (0.185) Loss 0.4253 (0.4253) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:48:54,912 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:54,912 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:55,931 - INFO - Epoch: [76][100/391] Time 0.028 (0.020) Data 0.006 (0.003) Loss 0.4608 (0.4059) Acc@1 80.469 (86.317) Acc@5 100.000 (99.443)
2025-08-28 05:48:57,775 - INFO - Epoch: [76][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4674 (0.4122) Acc@1 82.031 (86.066) Acc@5 99.219 (99.390)
2025-08-28 05:48:57,843 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:48:57,843 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:48:59,614 - INFO - Epoch: [76][300/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.3596 (0.4170) Acc@1 88.281 (85.766) Acc@5 100.000 (99.377)
2025-08-28 05:49:00,762 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:00,762 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:01,386 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5427 (0.5427) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 05:49:02,271 - INFO - Epoch 76:
2025-08-28 05:49:02,272 - INFO -   Train: acc1: 85.9320 | acc5: 99.3900 | loss: 0.4137 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:49:02,272 - INFO -   Val:   acc1: 81.6200 | acc5: 99.0200 | loss: 0.5608
2025-08-28 05:49:02,272 - INFO -   LR: 0.100000
2025-08-28 05:49:02,287 - INFO - 
Epoch: 77, lr = 0.1
2025-08-28 05:49:02,476 - INFO - Epoch: [77][0/391] Time 0.188 (0.188) Data 0.161 (0.161) Loss 0.2640 (0.2640) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:49:04,402 - INFO - Epoch: [77][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.4577 (0.4090) Acc@1 82.031 (85.783) Acc@5 99.219 (99.366)
2025-08-28 05:49:05,021 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:05,021 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:06,261 - INFO - Epoch: [77][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4159 (0.4146) Acc@1 85.156 (85.564) Acc@5 100.000 (99.405)
2025-08-28 05:49:08,021 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:08,021 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:08,175 - INFO - Epoch: [77][300/391] Time 0.016 (0.020) Data 0.005 (0.004) Loss 0.3378 (0.4135) Acc@1 92.969 (85.753) Acc@5 100.000 (99.442)
2025-08-28 05:49:09,928 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.8793 (0.8793) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 05:49:10,731 - INFO - Epoch 77:
2025-08-28 05:49:10,732 - INFO -   Train: acc1: 85.5480 | acc5: 99.4220 | loss: 0.4198 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:49:10,732 - INFO -   Val:   acc1: 73.9700 | acc5: 98.8400 | loss: 0.8533
2025-08-28 05:49:10,732 - INFO -   LR: 0.100000
2025-08-28 05:49:10,745 - INFO - 
Epoch: 78, lr = 0.1
2025-08-28 05:49:10,940 - INFO - Epoch: [78][0/391] Time 0.193 (0.193) Data 0.177 (0.177) Loss 0.3976 (0.3976) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:49:12,050 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:12,050 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:12,772 - INFO - Epoch: [78][100/391] Time 0.026 (0.020) Data 0.012 (0.003) Loss 0.3383 (0.3970) Acc@1 87.500 (86.247) Acc@5 100.000 (99.505)
2025-08-28 05:49:14,558 - INFO - Epoch: [78][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4304 (0.4115) Acc@1 88.281 (85.829) Acc@5 99.219 (99.440)
2025-08-28 05:49:14,926 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:14,926 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:16,351 - INFO - Epoch: [78][300/391] Time 0.027 (0.019) Data 0.011 (0.003) Loss 0.4652 (0.4169) Acc@1 82.031 (85.566) Acc@5 100.000 (99.432)
2025-08-28 05:49:17,837 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:17,837 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:18,139 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.5468 (0.5468) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-28 05:49:19,011 - INFO - Epoch 78:
2025-08-28 05:49:19,011 - INFO -   Train: acc1: 85.5360 | acc5: 99.4260 | loss: 0.4188 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:49:19,011 - INFO -   Val:   acc1: 79.5700 | acc5: 99.0900 | loss: 0.6332
2025-08-28 05:49:19,011 - INFO -   LR: 0.100000
2025-08-28 05:49:19,024 - INFO - 
Epoch: 79, lr = 0.1
2025-08-28 05:49:19,216 - INFO - Epoch: [79][0/391] Time 0.191 (0.191) Data 0.159 (0.159) Loss 0.4754 (0.4754) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 05:49:21,069 - INFO - Epoch: [79][100/391] Time 0.024 (0.020) Data 0.003 (0.004) Loss 0.5528 (0.4178) Acc@1 82.031 (85.512) Acc@5 98.438 (99.389)
2025-08-28 05:49:22,097 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:22,097 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:22,981 - INFO - Epoch: [79][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3009 (0.4138) Acc@1 89.062 (85.712) Acc@5 100.000 (99.444)
2025-08-28 05:49:24,830 - INFO - Epoch: [79][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5217 (0.4150) Acc@1 83.594 (85.712) Acc@5 98.438 (99.429)
2025-08-28 05:49:24,995 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:24,996 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:26,619 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.7464 (0.7464) Acc@1 73.438 (73.438) Acc@5 97.656 (97.656)
2025-08-28 05:49:27,462 - INFO - Epoch 79:
2025-08-28 05:49:27,462 - INFO -   Train: acc1: 85.4940 | acc5: 99.4200 | loss: 0.4200 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:49:27,462 - INFO -   Val:   acc1: 76.7900 | acc5: 98.5800 | loss: 0.7291
2025-08-28 05:49:27,462 - INFO -   LR: 0.100000
2025-08-28 05:49:27,476 - INFO - 
Epoch: 80, lr = 0.1
2025-08-28 05:49:27,662 - INFO - Epoch: [80][0/391] Time 0.185 (0.185) Data 0.153 (0.153) Loss 0.3795 (0.3795) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:49:29,083 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:29,084 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:29,530 - INFO - Epoch: [80][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.5261 (0.4103) Acc@1 79.688 (85.528) Acc@5 99.219 (99.474)
2025-08-28 05:49:31,373 - INFO - Epoch: [80][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.2909 (0.4142) Acc@1 90.625 (85.533) Acc@5 99.219 (99.433)
2025-08-28 05:49:32,085 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:32,085 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:33,219 - INFO - Epoch: [80][300/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.4637 (0.4161) Acc@1 79.688 (85.616) Acc@5 100.000 (99.424)
2025-08-28 05:49:35,108 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.7323 (0.7323) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-28 05:49:35,978 - INFO - Epoch 80:
2025-08-28 05:49:35,978 - INFO -   Train: acc1: 85.5920 | acc5: 99.4300 | loss: 0.4178 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:49:35,978 - INFO -   Val:   acc1: 78.7600 | acc5: 98.6300 | loss: 0.6910
2025-08-28 05:49:35,978 - INFO -   LR: 0.100000
2025-08-28 05:49:36,027 - INFO - 
Epoch: 81, lr = 0.1
2025-08-28 05:49:36,241 - INFO - Epoch: [81][0/391] Time 0.214 (0.214) Data 0.197 (0.197) Loss 0.4456 (0.4456) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 05:49:36,505 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:36,506 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:38,181 - INFO - Epoch: [81][100/391] Time 0.015 (0.021) Data 0.000 (0.006) Loss 0.3585 (0.4050) Acc@1 87.500 (85.760) Acc@5 99.219 (99.389)
2025-08-28 05:49:39,440 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:39,440 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:39,988 - INFO - Epoch: [81][200/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.4066 (0.4091) Acc@1 85.156 (85.844) Acc@5 100.000 (99.398)
2025-08-28 05:49:41,832 - INFO - Epoch: [81][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4053 (0.4111) Acc@1 85.156 (85.790) Acc@5 100.000 (99.411)
2025-08-28 05:49:42,406 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:42,406 - INFO -   Reactivation rate: 0.0001
2025-08-28 05:49:43,817 - INFO - Test: [0/79] Time 0.296 (0.296) Loss 0.5125 (0.5125) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 05:49:44,650 - INFO - Epoch 81:
2025-08-28 05:49:44,650 - INFO -   Train: acc1: 85.6760 | acc5: 99.4020 | loss: 0.4145 | sparsity: 0.8000 | reactivation_rate: 0.0001
2025-08-28 05:49:44,650 - INFO -   Val:   acc1: 80.9900 | acc5: 98.9300 | loss: 0.5732
2025-08-28 05:49:44,650 - INFO -   LR: 0.100000
2025-08-28 05:49:44,664 - INFO - 
Epoch: 82, lr = 0.1
2025-08-28 05:49:44,993 - INFO - Epoch: [82][0/391] Time 0.328 (0.328) Data 0.312 (0.312) Loss 0.5767 (0.5767) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 05:49:46,819 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:46,820 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:49:46,874 - INFO - Epoch: [82][100/391] Time 0.012 (0.022) Data 0.000 (0.006) Loss 0.3985 (0.4095) Acc@1 86.719 (85.767) Acc@5 100.000 (99.443)
2025-08-28 05:49:48,678 - INFO - Epoch: [82][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.3455 (0.4180) Acc@1 87.500 (85.510) Acc@5 100.000 (99.413)
2025-08-28 05:49:49,765 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:49,765 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:49:50,559 - INFO - Epoch: [82][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3968 (0.4174) Acc@1 85.938 (85.590) Acc@5 100.000 (99.400)
2025-08-28 05:49:52,394 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5103 (0.5103) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 05:49:53,309 - INFO - Epoch 82:
2025-08-28 05:49:53,309 - INFO -   Train: acc1: 85.8060 | acc5: 99.4240 | loss: 0.4125 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:49:53,309 - INFO -   Val:   acc1: 80.7300 | acc5: 98.7000 | loss: 0.5758
2025-08-28 05:49:53,309 - INFO -   LR: 0.100000
2025-08-28 05:49:53,324 - INFO - 
Epoch: 83, lr = 0.1
2025-08-28 05:49:53,511 - INFO - Epoch: [83][0/391] Time 0.187 (0.187) Data 0.171 (0.171) Loss 0.5159 (0.5159) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:49:53,980 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:53,980 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:49:55,432 - INFO - Epoch: [83][100/391] Time 0.015 (0.021) Data 0.000 (0.005) Loss 0.3451 (0.4079) Acc@1 89.062 (86.239) Acc@5 100.000 (99.451)
2025-08-28 05:49:57,027 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:57,028 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:49:57,265 - INFO - Epoch: [83][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3556 (0.4084) Acc@1 86.719 (86.210) Acc@5 100.000 (99.409)
2025-08-28 05:49:59,055 - INFO - Epoch: [83][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5689 (0.4180) Acc@1 81.250 (85.745) Acc@5 98.438 (99.403)
2025-08-28 05:49:59,926 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:49:59,926 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:00,859 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.7912 (0.7912) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 05:50:01,698 - INFO - Epoch 83:
2025-08-28 05:50:01,698 - INFO -   Train: acc1: 85.6940 | acc5: 99.3900 | loss: 0.4194 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:01,698 - INFO -   Val:   acc1: 75.8100 | acc5: 98.9500 | loss: 0.7663
2025-08-28 05:50:01,698 - INFO -   LR: 0.100000
2025-08-28 05:50:01,710 - INFO - 
Epoch: 84, lr = 0.1
2025-08-28 05:50:01,906 - INFO - Epoch: [84][0/391] Time 0.195 (0.195) Data 0.177 (0.177) Loss 0.4315 (0.4315) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:50:03,772 - INFO - Epoch: [84][100/391] Time 0.032 (0.020) Data 0.000 (0.004) Loss 0.4204 (0.4210) Acc@1 85.938 (85.736) Acc@5 99.219 (99.513)
2025-08-28 05:50:04,061 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:04,061 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:05,587 - INFO - Epoch: [84][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.4864 (0.4122) Acc@1 82.031 (85.945) Acc@5 98.438 (99.514)
2025-08-28 05:50:07,016 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:07,016 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:07,528 - INFO - Epoch: [84][300/391] Time 0.035 (0.019) Data 0.000 (0.003) Loss 0.4179 (0.4144) Acc@1 86.719 (85.743) Acc@5 100.000 (99.520)
2025-08-28 05:50:09,390 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.6833 (0.6833) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:50:10,268 - INFO - Epoch 84:
2025-08-28 05:50:10,268 - INFO -   Train: acc1: 85.5520 | acc5: 99.4780 | loss: 0.4185 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:10,268 - INFO -   Val:   acc1: 77.3600 | acc5: 99.0900 | loss: 0.6657
2025-08-28 05:50:10,268 - INFO -   LR: 0.100000
2025-08-28 05:50:10,284 - INFO - 
Epoch: 85, lr = 0.1
2025-08-28 05:50:10,489 - INFO - Epoch: [85][0/391] Time 0.204 (0.204) Data 0.187 (0.187) Loss 0.4960 (0.4960) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 05:50:11,386 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:11,386 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:12,334 - INFO - Epoch: [85][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.4436 (0.4192) Acc@1 85.156 (85.558) Acc@5 99.219 (99.404)
2025-08-28 05:50:14,268 - INFO - Epoch: [85][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.3217 (0.4132) Acc@1 88.281 (85.817) Acc@5 100.000 (99.468)
2025-08-28 05:50:14,339 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:14,340 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:16,088 - INFO - Epoch: [85][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4425 (0.4103) Acc@1 82.812 (85.909) Acc@5 99.219 (99.465)
2025-08-28 05:50:17,299 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:17,299 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:17,949 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.6850 (0.6850) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 05:50:18,781 - INFO - Epoch 85:
2025-08-28 05:50:18,781 - INFO -   Train: acc1: 85.7080 | acc5: 99.4220 | loss: 0.4168 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:18,781 - INFO -   Val:   acc1: 77.5900 | acc5: 98.8800 | loss: 0.6993
2025-08-28 05:50:18,781 - INFO -   LR: 0.100000
2025-08-28 05:50:18,796 - INFO - 
Epoch: 86, lr = 0.1
2025-08-28 05:50:18,970 - INFO - Epoch: [86][0/391] Time 0.173 (0.173) Data 0.141 (0.141) Loss 0.2824 (0.2824) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:50:20,832 - INFO - Epoch: [86][100/391] Time 0.019 (0.020) Data 0.007 (0.004) Loss 0.4372 (0.4001) Acc@1 83.594 (86.177) Acc@5 100.000 (99.606)
2025-08-28 05:50:21,453 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:21,453 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:22,622 - INFO - Epoch: [86][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3337 (0.4104) Acc@1 89.844 (85.906) Acc@5 99.219 (99.537)
2025-08-28 05:50:24,425 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:24,425 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:24,548 - INFO - Epoch: [86][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4102 (0.4147) Acc@1 83.594 (85.631) Acc@5 99.219 (99.520)
2025-08-28 05:50:26,317 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.4511 (0.4511) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:50:27,181 - INFO - Epoch 86:
2025-08-28 05:50:27,181 - INFO -   Train: acc1: 85.7060 | acc5: 99.5080 | loss: 0.4127 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:27,181 - INFO -   Val:   acc1: 82.6700 | acc5: 99.1300 | loss: 0.5223
2025-08-28 05:50:27,181 - INFO -   LR: 0.100000
2025-08-28 05:50:27,195 - INFO - 
Epoch: 87, lr = 0.1
2025-08-28 05:50:27,392 - INFO - Epoch: [87][0/391] Time 0.195 (0.195) Data 0.162 (0.162) Loss 0.4461 (0.4461) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:50:28,554 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:28,554 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:29,273 - INFO - Epoch: [87][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.3241 (0.4146) Acc@1 86.719 (85.976) Acc@5 100.000 (99.381)
2025-08-28 05:50:31,054 - INFO - Epoch: [87][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3016 (0.4201) Acc@1 89.844 (85.739) Acc@5 100.000 (99.374)
2025-08-28 05:50:31,439 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:31,439 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:32,883 - INFO - Epoch: [87][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.5165 (0.4160) Acc@1 76.562 (85.862) Acc@5 99.219 (99.351)
2025-08-28 05:50:34,431 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:34,431 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:34,721 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5330 (0.5330) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:50:35,572 - INFO - Epoch 87:
2025-08-28 05:50:35,572 - INFO -   Train: acc1: 85.7200 | acc5: 99.3800 | loss: 0.4176 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:35,572 - INFO -   Val:   acc1: 79.7800 | acc5: 98.9900 | loss: 0.6266
2025-08-28 05:50:35,572 - INFO -   LR: 0.100000
2025-08-28 05:50:35,586 - INFO - 
Epoch: 88, lr = 0.1
2025-08-28 05:50:35,783 - INFO - Epoch: [88][0/391] Time 0.196 (0.196) Data 0.170 (0.170) Loss 0.3685 (0.3685) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:50:37,568 - INFO - Epoch: [88][100/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.4569 (0.4174) Acc@1 85.938 (85.489) Acc@5 100.000 (99.497)
2025-08-28 05:50:38,490 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:38,490 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:39,360 - INFO - Epoch: [88][200/391] Time 0.040 (0.019) Data 0.019 (0.003) Loss 0.4152 (0.4120) Acc@1 87.500 (85.669) Acc@5 100.000 (99.456)
2025-08-28 05:50:41,241 - INFO - Epoch: [88][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.3995 (0.4138) Acc@1 85.156 (85.561) Acc@5 100.000 (99.445)
2025-08-28 05:50:41,415 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:41,416 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:43,132 - INFO - Test: [0/79] Time 0.176 (0.176) Loss 0.8566 (0.8566) Acc@1 69.531 (69.531) Acc@5 98.438 (98.438)
2025-08-28 05:50:44,000 - INFO - Epoch 88:
2025-08-28 05:50:44,000 - INFO -   Train: acc1: 85.5380 | acc5: 99.4580 | loss: 0.4146 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:44,000 - INFO -   Val:   acc1: 72.4000 | acc5: 98.5100 | loss: 0.9063
2025-08-28 05:50:44,000 - INFO -   LR: 0.100000
2025-08-28 05:50:44,013 - INFO - 
Epoch: 89, lr = 0.1
2025-08-28 05:50:44,213 - INFO - Epoch: [89][0/391] Time 0.200 (0.200) Data 0.179 (0.179) Loss 0.3647 (0.3647) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:50:45,694 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:45,694 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:46,037 - INFO - Epoch: [89][100/391] Time 0.013 (0.020) Data 0.000 (0.006) Loss 0.4281 (0.4006) Acc@1 83.594 (86.061) Acc@5 99.219 (99.358)
2025-08-28 05:50:48,015 - INFO - Epoch: [89][200/391] Time 0.018 (0.020) Data 0.000 (0.005) Loss 0.4047 (0.4079) Acc@1 85.156 (85.914) Acc@5 98.438 (99.390)
2025-08-28 05:50:48,811 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:48,812 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:49,861 - INFO - Epoch: [89][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5607 (0.4150) Acc@1 80.469 (85.592) Acc@5 99.219 (99.439)
2025-08-28 05:50:51,684 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.6369 (0.6369) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 05:50:52,521 - INFO - Epoch 89:
2025-08-28 05:50:52,522 - INFO -   Train: acc1: 85.5540 | acc5: 99.4260 | loss: 0.4170 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:50:52,522 - INFO -   Val:   acc1: 78.0900 | acc5: 98.2500 | loss: 0.6862
2025-08-28 05:50:52,522 - INFO -   LR: 0.100000
2025-08-28 05:50:52,537 - INFO - 
Epoch: 90, lr = 0.1
2025-08-28 05:50:52,724 - INFO - Epoch: [90][0/391] Time 0.186 (0.186) Data 0.163 (0.163) Loss 0.4135 (0.4135) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:50:52,915 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:52,915 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:54,679 - INFO - Epoch: [90][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.5002 (0.4017) Acc@1 78.906 (86.030) Acc@5 100.000 (99.513)
2025-08-28 05:50:55,984 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:55,984 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:50:56,561 - INFO - Epoch: [90][200/391] Time 0.022 (0.020) Data 0.003 (0.003) Loss 0.5363 (0.4140) Acc@1 79.688 (85.759) Acc@5 98.438 (99.452)
2025-08-28 05:50:58,329 - INFO - Epoch: [90][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5545 (0.4127) Acc@1 82.031 (85.813) Acc@5 97.656 (99.447)
2025-08-28 05:50:58,862 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:50:58,862 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:00,125 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.8554 (0.8554) Acc@1 72.656 (72.656) Acc@5 96.875 (96.875)
2025-08-28 05:51:00,958 - INFO - Epoch 90:
2025-08-28 05:51:00,958 - INFO -   Train: acc1: 85.7380 | acc5: 99.4280 | loss: 0.4169 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:00,958 - INFO -   Val:   acc1: 74.9400 | acc5: 96.8400 | loss: 0.8489
2025-08-28 05:51:00,958 - INFO -   LR: 0.100000
2025-08-28 05:51:01,007 - INFO - 
Epoch: 91, lr = 0.1
2025-08-28 05:51:01,184 - INFO - Epoch: [91][0/391] Time 0.176 (0.176) Data 0.158 (0.158) Loss 0.4289 (0.4289) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:51:02,984 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:02,985 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:03,010 - INFO - Epoch: [91][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.4469 (0.4046) Acc@1 83.594 (85.883) Acc@5 100.000 (99.451)
2025-08-28 05:51:04,814 - INFO - Epoch: [91][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.5765 (0.4153) Acc@1 82.812 (85.782) Acc@5 99.219 (99.390)
2025-08-28 05:51:05,869 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:05,869 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:06,647 - INFO - Epoch: [91][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3740 (0.4166) Acc@1 88.281 (85.714) Acc@5 99.219 (99.377)
2025-08-28 05:51:08,489 - INFO - Test: [0/79] Time 0.165 (0.165) Loss 0.7331 (0.7331) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 05:51:09,355 - INFO - Epoch 91:
2025-08-28 05:51:09,355 - INFO -   Train: acc1: 85.4800 | acc5: 99.3680 | loss: 0.4233 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:09,355 - INFO -   Val:   acc1: 74.7600 | acc5: 98.6100 | loss: 0.7843
2025-08-28 05:51:09,355 - INFO -   LR: 0.100000
2025-08-28 05:51:09,370 - INFO - 
Epoch: 92, lr = 0.1
2025-08-28 05:51:09,582 - INFO - Epoch: [92][0/391] Time 0.212 (0.212) Data 0.193 (0.193) Loss 0.3967 (0.3967) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:51:10,054 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:10,055 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:11,438 - INFO - Epoch: [92][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.3994 (0.4056) Acc@1 89.062 (86.200) Acc@5 99.219 (99.420)
2025-08-28 05:51:12,999 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:12,999 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:13,245 - INFO - Epoch: [92][200/391] Time 0.031 (0.019) Data 0.000 (0.003) Loss 0.2896 (0.4056) Acc@1 89.062 (85.957) Acc@5 100.000 (99.421)
2025-08-28 05:51:15,070 - INFO - Epoch: [92][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3805 (0.4120) Acc@1 86.719 (85.681) Acc@5 99.219 (99.413)
2025-08-28 05:51:15,963 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:15,964 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:16,891 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.4607 (0.4607) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 05:51:17,752 - INFO - Epoch 92:
2025-08-28 05:51:17,752 - INFO -   Train: acc1: 85.6400 | acc5: 99.4400 | loss: 0.4137 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:17,752 - INFO -   Val:   acc1: 82.5000 | acc5: 98.8800 | loss: 0.5307
2025-08-28 05:51:17,752 - INFO -   LR: 0.100000
2025-08-28 05:51:17,769 - INFO - 
Epoch: 93, lr = 0.1
2025-08-28 05:51:17,934 - INFO - Epoch: [93][0/391] Time 0.164 (0.164) Data 0.144 (0.144) Loss 0.4024 (0.4024) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 05:51:19,871 - INFO - Epoch: [93][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3248 (0.4237) Acc@1 89.844 (85.489) Acc@5 100.000 (99.489)
2025-08-28 05:51:20,127 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:20,127 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:21,712 - INFO - Epoch: [93][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3832 (0.4132) Acc@1 85.156 (85.817) Acc@5 100.000 (99.530)
2025-08-28 05:51:23,105 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:23,106 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:23,588 - INFO - Epoch: [93][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3759 (0.4116) Acc@1 86.719 (85.797) Acc@5 100.000 (99.525)
2025-08-28 05:51:25,322 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.6982 (0.6982) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-28 05:51:26,200 - INFO - Epoch 93:
2025-08-28 05:51:26,200 - INFO -   Train: acc1: 85.7820 | acc5: 99.4740 | loss: 0.4142 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:26,200 - INFO -   Val:   acc1: 78.3200 | acc5: 98.9600 | loss: 0.7008
2025-08-28 05:51:26,200 - INFO -   LR: 0.100000
2025-08-28 05:51:26,215 - INFO - 
Epoch: 94, lr = 0.1
2025-08-28 05:51:26,419 - INFO - Epoch: [94][0/391] Time 0.204 (0.204) Data 0.182 (0.182) Loss 0.4166 (0.4166) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:51:27,219 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:27,219 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:28,244 - INFO - Epoch: [94][100/391] Time 0.015 (0.020) Data 0.000 (0.006) Loss 0.3907 (0.4161) Acc@1 86.719 (86.007) Acc@5 100.000 (99.389)
2025-08-28 05:51:30,104 - INFO - Epoch: [94][200/391] Time 0.014 (0.019) Data 0.000 (0.005) Loss 0.4293 (0.4149) Acc@1 83.594 (85.697) Acc@5 100.000 (99.440)
2025-08-28 05:51:30,182 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:30,182 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:31,905 - INFO - Epoch: [94][300/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.4830 (0.4166) Acc@1 85.156 (85.668) Acc@5 99.219 (99.413)
2025-08-28 05:51:33,091 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:33,091 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:33,771 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.7596 (0.7596) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 05:51:34,572 - INFO - Epoch 94:
2025-08-28 05:51:34,572 - INFO -   Train: acc1: 85.6220 | acc5: 99.3980 | loss: 0.4193 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:34,572 - INFO -   Val:   acc1: 77.3100 | acc5: 98.7300 | loss: 0.7159
2025-08-28 05:51:34,572 - INFO -   LR: 0.100000
2025-08-28 05:51:34,587 - INFO - 
Epoch: 95, lr = 0.1
2025-08-28 05:51:34,790 - INFO - Epoch: [95][0/391] Time 0.203 (0.203) Data 0.183 (0.183) Loss 0.3977 (0.3977) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:51:36,553 - INFO - Epoch: [95][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4084 (0.4046) Acc@1 85.156 (86.115) Acc@5 100.000 (99.466)
2025-08-28 05:51:37,260 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:37,260 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:38,416 - INFO - Epoch: [95][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.5013 (0.4121) Acc@1 82.812 (85.887) Acc@5 100.000 (99.487)
2025-08-28 05:51:40,119 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:40,119 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:40,213 - INFO - Epoch: [95][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3261 (0.4151) Acc@1 88.281 (85.800) Acc@5 100.000 (99.473)
2025-08-28 05:51:42,046 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.6396 (0.6396) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-28 05:51:42,915 - INFO - Epoch 95:
2025-08-28 05:51:42,915 - INFO -   Train: acc1: 85.8560 | acc5: 99.4640 | loss: 0.4139 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:42,915 - INFO -   Val:   acc1: 75.8400 | acc5: 98.6800 | loss: 0.7419
2025-08-28 05:51:42,915 - INFO -   LR: 0.100000
2025-08-28 05:51:42,929 - INFO - 
Epoch: 96, lr = 0.1
2025-08-28 05:51:43,174 - INFO - Epoch: [96][0/391] Time 0.245 (0.245) Data 0.201 (0.201) Loss 0.5581 (0.5581) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-28 05:51:44,383 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:44,385 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:45,062 - INFO - Epoch: [96][100/391] Time 0.032 (0.021) Data 0.019 (0.005) Loss 0.4399 (0.4081) Acc@1 86.719 (85.961) Acc@5 98.438 (99.497)
2025-08-28 05:51:46,993 - INFO - Epoch: [96][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.5877 (0.4175) Acc@1 77.344 (85.751) Acc@5 99.219 (99.429)
2025-08-28 05:51:47,403 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:47,403 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:48,814 - INFO - Epoch: [96][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3164 (0.4216) Acc@1 91.406 (85.494) Acc@5 99.219 (99.398)
2025-08-28 05:51:50,390 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:50,390 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:50,658 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.5604 (0.5604) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:51:51,500 - INFO - Epoch 96:
2025-08-28 05:51:51,500 - INFO -   Train: acc1: 85.4780 | acc5: 99.3860 | loss: 0.4228 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:51:51,500 - INFO -   Val:   acc1: 81.3500 | acc5: 99.1100 | loss: 0.5461
2025-08-28 05:51:51,500 - INFO -   LR: 0.100000
2025-08-28 05:51:51,513 - INFO - 
Epoch: 97, lr = 0.1
2025-08-28 05:51:51,719 - INFO - Epoch: [97][0/391] Time 0.203 (0.203) Data 0.177 (0.177) Loss 0.3575 (0.3575) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:51:53,568 - INFO - Epoch: [97][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.3902 (0.3993) Acc@1 85.156 (86.131) Acc@5 100.000 (99.435)
2025-08-28 05:51:54,572 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:54,572 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:55,401 - INFO - Epoch: [97][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4350 (0.4034) Acc@1 85.938 (86.000) Acc@5 98.438 (99.487)
2025-08-28 05:51:57,335 - INFO - Epoch: [97][300/391] Time 0.034 (0.019) Data 0.021 (0.003) Loss 0.4360 (0.4076) Acc@1 85.938 (85.860) Acc@5 99.219 (99.450)
2025-08-28 05:51:57,570 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:51:57,571 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:51:59,163 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.8529 (0.8529) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 05:52:00,013 - INFO - Epoch 97:
2025-08-28 05:52:00,014 - INFO -   Train: acc1: 85.6460 | acc5: 99.4220 | loss: 0.4148 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:00,014 - INFO -   Val:   acc1: 76.0700 | acc5: 98.8400 | loss: 0.7934
2025-08-28 05:52:00,014 - INFO -   LR: 0.100000
2025-08-28 05:52:00,426 - INFO - 
Epoch: 98, lr = 0.1
2025-08-28 05:52:00,616 - INFO - Epoch: [98][0/391] Time 0.189 (0.189) Data 0.168 (0.168) Loss 0.4951 (0.4951) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 05:52:02,153 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:02,153 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:02,457 - INFO - Epoch: [98][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4263 (0.4137) Acc@1 85.156 (85.605) Acc@5 100.000 (99.428)
2025-08-28 05:52:04,461 - INFO - Epoch: [98][200/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.4528 (0.4156) Acc@1 86.719 (85.525) Acc@5 98.438 (99.464)
2025-08-28 05:52:05,270 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:05,270 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:06,391 - INFO - Epoch: [98][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3590 (0.4156) Acc@1 89.062 (85.631) Acc@5 99.219 (99.452)
2025-08-28 05:52:08,186 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.4905 (0.4905) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 05:52:09,238 - INFO - Epoch 98:
2025-08-28 05:52:09,238 - INFO -   Train: acc1: 85.5820 | acc5: 99.4240 | loss: 0.4184 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:09,238 - INFO -   Val:   acc1: 81.9000 | acc5: 99.2700 | loss: 0.5231
2025-08-28 05:52:09,238 - INFO -   LR: 0.100000
2025-08-28 05:52:09,254 - INFO - 
Epoch: 99, lr = 0.1
2025-08-28 05:52:09,495 - INFO - Epoch: [99][0/391] Time 0.241 (0.241) Data 0.204 (0.204) Loss 0.4483 (0.4483) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 05:52:09,688 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:09,688 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:11,363 - INFO - Epoch: [99][100/391] Time 0.024 (0.021) Data 0.000 (0.004) Loss 0.3485 (0.4178) Acc@1 88.281 (85.543) Acc@5 99.219 (99.404)
2025-08-28 05:52:12,670 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:12,670 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:13,200 - INFO - Epoch: [99][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.3177 (0.4148) Acc@1 87.500 (85.549) Acc@5 100.000 (99.448)
2025-08-28 05:52:15,127 - INFO - Epoch: [99][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4746 (0.4160) Acc@1 83.594 (85.566) Acc@5 98.438 (99.450)
2025-08-28 05:52:15,657 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:15,657 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:16,948 - INFO - Test: [0/79] Time 0.165 (0.165) Loss 0.4718 (0.4718) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:52:17,817 - INFO - Epoch 99:
2025-08-28 05:52:17,818 - INFO -   Train: acc1: 85.6000 | acc5: 99.4460 | loss: 0.4156 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:17,818 - INFO -   Val:   acc1: 82.3300 | acc5: 99.1100 | loss: 0.5538
2025-08-28 05:52:17,818 - INFO -   LR: 0.010000
2025-08-28 05:52:17,832 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-28 05:52:18,028 - INFO - Epoch: [100][0/391] Time 0.195 (0.195) Data 0.176 (0.176) Loss 0.3703 (0.3703) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:52:19,841 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:19,841 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:19,856 - INFO - Epoch: [100][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.2493 (0.3330) Acc@1 89.844 (88.567) Acc@5 100.000 (99.621)
2025-08-28 05:52:21,705 - INFO - Epoch: [100][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3523 (0.3155) Acc@1 89.844 (89.315) Acc@5 99.219 (99.635)
2025-08-28 05:52:22,804 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:22,805 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:23,623 - INFO - Epoch: [100][300/391] Time 0.027 (0.019) Data 0.011 (0.004) Loss 0.2178 (0.3027) Acc@1 93.750 (89.745) Acc@5 100.000 (99.650)
2025-08-28 05:52:25,370 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2658 (0.2658) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:52:26,228 - INFO - Epoch 100:
2025-08-28 05:52:26,229 - INFO -   Train: acc1: 89.9640 | acc5: 99.6380 | loss: 0.2958 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:26,229 - INFO -   Val:   acc1: 89.0200 | acc5: 99.6200 | loss: 0.3244
2025-08-28 05:52:26,229 - INFO -   LR: 0.010000
2025-08-28 05:52:26,279 - INFO - Checkpoint saved: epoch=100, metric=89.0200
2025-08-28 05:52:26,310 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-28 05:52:26,495 - INFO - Epoch: [101][0/391] Time 0.184 (0.184) Data 0.155 (0.155) Loss 0.3201 (0.3201) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 05:52:27,081 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:27,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:28,387 - INFO - Epoch: [101][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.1781 (0.2571) Acc@1 96.094 (91.298) Acc@5 100.000 (99.706)
2025-08-28 05:52:29,946 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:29,946 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:30,165 - INFO - Epoch: [101][200/391] Time 0.014 (0.019) Data 0.004 (0.003) Loss 0.2073 (0.2554) Acc@1 93.750 (91.239) Acc@5 98.438 (99.701)
2025-08-28 05:52:32,067 - INFO - Epoch: [101][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2526 (0.2552) Acc@1 90.625 (91.266) Acc@5 100.000 (99.727)
2025-08-28 05:52:32,960 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:32,960 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:33,872 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2748 (0.2748) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:52:34,717 - INFO - Epoch 101:
2025-08-28 05:52:34,717 - INFO -   Train: acc1: 91.1960 | acc5: 99.7220 | loss: 0.2574 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:34,717 - INFO -   Val:   acc1: 89.0600 | acc5: 99.6300 | loss: 0.3190
2025-08-28 05:52:34,718 - INFO -   LR: 0.010000
2025-08-28 05:52:34,767 - INFO - Checkpoint saved: epoch=101, metric=89.0600
2025-08-28 05:52:34,798 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-28 05:52:35,012 - INFO - Epoch: [102][0/391] Time 0.213 (0.213) Data 0.184 (0.184) Loss 0.1997 (0.1997) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:52:36,866 - INFO - Epoch: [102][100/391] Time 0.029 (0.020) Data 0.000 (0.005) Loss 0.2287 (0.2496) Acc@1 92.969 (91.638) Acc@5 100.000 (99.814)
2025-08-28 05:52:37,202 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:37,202 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:38,727 - INFO - Epoch: [102][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1961 (0.2471) Acc@1 92.188 (91.694) Acc@5 100.000 (99.810)
2025-08-28 05:52:40,112 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:40,112 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:40,534 - INFO - Epoch: [102][300/391] Time 0.030 (0.019) Data 0.017 (0.003) Loss 0.2558 (0.2449) Acc@1 92.969 (91.713) Acc@5 100.000 (99.805)
2025-08-28 05:52:42,264 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.2681 (0.2681) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:52:43,130 - INFO - Epoch 102:
2025-08-28 05:52:43,130 - INFO -   Train: acc1: 91.8160 | acc5: 99.7980 | loss: 0.2421 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:43,131 - INFO -   Val:   acc1: 89.1800 | acc5: 99.6300 | loss: 0.3168
2025-08-28 05:52:43,131 - INFO -   LR: 0.010000
2025-08-28 05:52:43,178 - INFO - Checkpoint saved: epoch=102, metric=89.1800
2025-08-28 05:52:43,211 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-28 05:52:43,429 - INFO - Epoch: [103][0/391] Time 0.217 (0.217) Data 0.200 (0.200) Loss 0.3228 (0.3228) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 05:52:44,305 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:44,305 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:45,290 - INFO - Epoch: [103][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.3165 (0.2384) Acc@1 87.500 (91.638) Acc@5 100.000 (99.799)
2025-08-28 05:52:47,066 - INFO - Epoch: [103][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3007 (0.2365) Acc@1 90.625 (91.768) Acc@5 100.000 (99.829)
2025-08-28 05:52:47,204 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:47,204 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:48,914 - INFO - Epoch: [103][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.4050 (0.2368) Acc@1 89.062 (91.803) Acc@5 97.656 (99.803)
2025-08-28 05:52:50,158 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:50,159 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:50,713 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2796 (0.2796) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:52:51,539 - INFO - Epoch 103:
2025-08-28 05:52:51,540 - INFO -   Train: acc1: 91.8380 | acc5: 99.8020 | loss: 0.2374 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:52:51,540 - INFO -   Val:   acc1: 89.3600 | acc5: 99.6900 | loss: 0.3140
2025-08-28 05:52:51,540 - INFO -   LR: 0.010000
2025-08-28 05:52:51,592 - INFO - Checkpoint saved: epoch=103, metric=89.3600
2025-08-28 05:52:51,625 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-28 05:52:51,810 - INFO - Epoch: [104][0/391] Time 0.184 (0.184) Data 0.155 (0.155) Loss 0.2258 (0.2258) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:52:53,662 - INFO - Epoch: [104][100/391] Time 0.025 (0.020) Data 0.000 (0.004) Loss 0.2582 (0.2285) Acc@1 91.406 (92.133) Acc@5 100.000 (99.838)
2025-08-28 05:52:54,277 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:54,277 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:55,544 - INFO - Epoch: [104][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.1853 (0.2315) Acc@1 92.969 (91.981) Acc@5 100.000 (99.825)
2025-08-28 05:52:57,340 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:52:57,341 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:52:57,405 - INFO - Epoch: [104][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.1759 (0.2314) Acc@1 94.531 (92.060) Acc@5 100.000 (99.829)
2025-08-28 05:52:59,200 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2620 (0.2620) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:53:00,052 - INFO - Epoch 104:
2025-08-28 05:53:00,053 - INFO -   Train: acc1: 91.9800 | acc5: 99.8180 | loss: 0.2329 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:00,053 - INFO -   Val:   acc1: 89.2600 | acc5: 99.6600 | loss: 0.3096
2025-08-28 05:53:00,053 - INFO -   LR: 0.010000
2025-08-28 05:53:00,068 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-28 05:53:00,271 - INFO - Epoch: [105][0/391] Time 0.201 (0.201) Data 0.182 (0.182) Loss 0.2015 (0.2015) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:53:01,459 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:01,459 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:02,066 - INFO - Epoch: [105][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2127 (0.2188) Acc@1 89.844 (92.512) Acc@5 100.000 (99.807)
2025-08-28 05:53:03,838 - INFO - Epoch: [105][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.1925 (0.2262) Acc@1 93.750 (92.219) Acc@5 99.219 (99.821)
2025-08-28 05:53:04,287 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:04,287 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:05,592 - INFO - Epoch: [105][300/391] Time 0.016 (0.018) Data 0.000 (0.003) Loss 0.2630 (0.2265) Acc@1 91.406 (92.258) Acc@5 98.438 (99.808)
2025-08-28 05:53:07,148 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:07,148 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:07,400 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2777 (0.2777) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:53:08,261 - INFO - Epoch 105:
2025-08-28 05:53:08,262 - INFO -   Train: acc1: 92.2520 | acc5: 99.8240 | loss: 0.2257 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:08,262 - INFO -   Val:   acc1: 89.2300 | acc5: 99.6500 | loss: 0.3214
2025-08-28 05:53:08,262 - INFO -   LR: 0.010000
2025-08-28 05:53:08,278 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-28 05:53:08,471 - INFO - Epoch: [106][0/391] Time 0.192 (0.192) Data 0.159 (0.159) Loss 0.1819 (0.1819) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:53:10,313 - INFO - Epoch: [106][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1566 (0.2146) Acc@1 92.969 (92.520) Acc@5 100.000 (99.776)
2025-08-28 05:53:11,254 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:11,254 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:12,212 - INFO - Epoch: [106][200/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.2287 (0.2160) Acc@1 91.406 (92.463) Acc@5 100.000 (99.806)
2025-08-28 05:53:13,961 - INFO - Epoch: [106][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3643 (0.2191) Acc@1 85.938 (92.395) Acc@5 99.219 (99.808)
2025-08-28 05:53:14,223 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:14,223 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:15,766 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2443 (0.2443) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:53:16,645 - INFO - Epoch 106:
2025-08-28 05:53:16,645 - INFO -   Train: acc1: 92.2280 | acc5: 99.8060 | loss: 0.2245 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:16,645 - INFO -   Val:   acc1: 89.6200 | acc5: 99.6600 | loss: 0.3116
2025-08-28 05:53:16,645 - INFO -   LR: 0.010000
2025-08-28 05:53:16,694 - INFO - Checkpoint saved: epoch=106, metric=89.6200
2025-08-28 05:53:16,725 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-28 05:53:16,913 - INFO - Epoch: [107][0/391] Time 0.187 (0.187) Data 0.169 (0.169) Loss 0.1789 (0.1789) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:53:18,412 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:18,412 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:18,780 - INFO - Epoch: [107][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1303 (0.2181) Acc@1 93.750 (92.729) Acc@5 100.000 (99.853)
2025-08-28 05:53:20,747 - INFO - Epoch: [107][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3427 (0.2186) Acc@1 89.062 (92.596) Acc@5 100.000 (99.845)
2025-08-28 05:53:21,521 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:21,521 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:22,525 - INFO - Epoch: [107][300/391] Time 0.046 (0.019) Data 0.027 (0.003) Loss 0.2867 (0.2174) Acc@1 88.281 (92.566) Acc@5 99.219 (99.857)
2025-08-28 05:53:24,295 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2917 (0.2917) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:53:25,133 - INFO - Epoch 107:
2025-08-28 05:53:25,133 - INFO -   Train: acc1: 92.4220 | acc5: 99.8400 | loss: 0.2212 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:25,133 - INFO -   Val:   acc1: 89.3100 | acc5: 99.6700 | loss: 0.3168
2025-08-28 05:53:25,133 - INFO -   LR: 0.010000
2025-08-28 05:53:25,151 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-28 05:53:25,319 - INFO - Epoch: [108][0/391] Time 0.167 (0.167) Data 0.150 (0.150) Loss 0.1326 (0.1326) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-28 05:53:25,567 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:25,567 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:27,265 - INFO - Epoch: [108][100/391] Time 0.022 (0.021) Data 0.003 (0.004) Loss 0.2369 (0.2112) Acc@1 90.625 (92.884) Acc@5 100.000 (99.853)
2025-08-28 05:53:28,479 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:28,480 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:28,997 - INFO - Epoch: [108][200/391] Time 0.023 (0.019) Data 0.011 (0.002) Loss 0.2924 (0.2139) Acc@1 88.281 (92.716) Acc@5 100.000 (99.813)
2025-08-28 05:53:30,776 - INFO - Epoch: [108][300/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.2411 (0.2153) Acc@1 92.969 (92.574) Acc@5 100.000 (99.824)
2025-08-28 05:53:31,320 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:31,320 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:32,510 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2718 (0.2718) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:53:33,359 - INFO - Epoch 108:
2025-08-28 05:53:33,360 - INFO -   Train: acc1: 92.5300 | acc5: 99.8260 | loss: 0.2167 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:33,360 - INFO -   Val:   acc1: 89.5100 | acc5: 99.7000 | loss: 0.3119
2025-08-28 05:53:33,360 - INFO -   LR: 0.010000
2025-08-28 05:53:33,376 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-28 05:53:33,539 - INFO - Epoch: [109][0/391] Time 0.163 (0.163) Data 0.140 (0.140) Loss 0.1621 (0.1621) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:53:35,320 - INFO - Epoch: [109][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.2302 (0.2076) Acc@1 90.625 (92.683) Acc@5 100.000 (99.822)
2025-08-28 05:53:35,339 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:35,339 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:37,097 - INFO - Epoch: [109][200/391] Time 0.017 (0.018) Data 0.005 (0.003) Loss 0.2101 (0.2096) Acc@1 93.750 (92.716) Acc@5 99.219 (99.810)
2025-08-28 05:53:38,206 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:38,206 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:38,905 - INFO - Epoch: [109][300/391] Time 0.020 (0.018) Data 0.000 (0.003) Loss 0.2777 (0.2115) Acc@1 89.062 (92.673) Acc@5 100.000 (99.831)
2025-08-28 05:53:40,739 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.2712 (0.2712) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:53:41,554 - INFO - Epoch 109:
2025-08-28 05:53:41,554 - INFO -   Train: acc1: 92.6020 | acc5: 99.8220 | loss: 0.2136 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:41,554 - INFO -   Val:   acc1: 89.2400 | acc5: 99.7500 | loss: 0.3120
2025-08-28 05:53:41,554 - INFO -   LR: 0.010000
2025-08-28 05:53:41,571 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-28 05:53:41,767 - INFO - Epoch: [110][0/391] Time 0.196 (0.196) Data 0.169 (0.169) Loss 0.1824 (0.1824) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:53:42,289 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:42,291 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:43,577 - INFO - Epoch: [110][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.2119 (0.2072) Acc@1 91.406 (92.876) Acc@5 100.000 (99.845)
2025-08-28 05:53:45,203 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:45,203 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:45,422 - INFO - Epoch: [110][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1449 (0.2103) Acc@1 96.094 (92.790) Acc@5 100.000 (99.852)
2025-08-28 05:53:47,248 - INFO - Epoch: [110][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2212 (0.2107) Acc@1 91.406 (92.748) Acc@5 100.000 (99.826)
2025-08-28 05:53:48,135 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:48,135 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:49,076 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.2612 (0.2612) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:53:49,918 - INFO - Epoch 110:
2025-08-28 05:53:49,918 - INFO -   Train: acc1: 92.6520 | acc5: 99.8300 | loss: 0.2110 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:49,918 - INFO -   Val:   acc1: 88.8100 | acc5: 99.5700 | loss: 0.3360
2025-08-28 05:53:49,918 - INFO -   LR: 0.010000
2025-08-28 05:53:49,968 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-28 05:53:50,139 - INFO - Epoch: [111][0/391] Time 0.170 (0.170) Data 0.153 (0.153) Loss 0.1447 (0.1447) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:53:52,141 - INFO - Epoch: [111][100/391] Time 0.013 (0.021) Data 0.001 (0.004) Loss 0.2279 (0.2026) Acc@1 91.406 (92.953) Acc@5 100.000 (99.853)
2025-08-28 05:53:52,488 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:52,488 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:53,959 - INFO - Epoch: [111][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2459 (0.2071) Acc@1 88.281 (92.860) Acc@5 100.000 (99.872)
2025-08-28 05:53:55,420 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:55,420 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:53:55,831 - INFO - Epoch: [111][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2238 (0.2108) Acc@1 93.750 (92.720) Acc@5 100.000 (99.868)
2025-08-28 05:53:57,632 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.3151 (0.3151) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:53:58,489 - INFO - Epoch 111:
2025-08-28 05:53:58,489 - INFO -   Train: acc1: 92.7280 | acc5: 99.8600 | loss: 0.2105 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:53:58,489 - INFO -   Val:   acc1: 89.4000 | acc5: 99.7100 | loss: 0.3194
2025-08-28 05:53:58,489 - INFO -   LR: 0.010000
2025-08-28 05:53:58,546 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-28 05:53:58,757 - INFO - Epoch: [112][0/391] Time 0.210 (0.210) Data 0.187 (0.187) Loss 0.2628 (0.2628) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:53:59,645 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:53:59,645 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:00,549 - INFO - Epoch: [112][100/391] Time 0.012 (0.020) Data 0.001 (0.003) Loss 0.2027 (0.2031) Acc@1 91.406 (93.069) Acc@5 100.000 (99.915)
2025-08-28 05:54:02,362 - INFO - Epoch: [112][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1934 (0.2062) Acc@1 93.750 (92.988) Acc@5 100.000 (99.895)
2025-08-28 05:54:02,499 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:02,499 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:04,209 - INFO - Epoch: [112][300/391] Time 0.043 (0.019) Data 0.030 (0.003) Loss 0.1177 (0.2061) Acc@1 96.094 (92.948) Acc@5 100.000 (99.896)
2025-08-28 05:54:05,498 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:05,498 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:06,084 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2756 (0.2756) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:54:06,977 - INFO - Epoch 112:
2025-08-28 05:54:06,977 - INFO -   Train: acc1: 92.8520 | acc5: 99.8660 | loss: 0.2090 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:06,977 - INFO -   Val:   acc1: 88.7900 | acc5: 99.7100 | loss: 0.3388
2025-08-28 05:54:06,977 - INFO -   LR: 0.010000
2025-08-28 05:54:06,995 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-28 05:54:07,188 - INFO - Epoch: [113][0/391] Time 0.193 (0.193) Data 0.175 (0.175) Loss 0.2053 (0.2053) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:54:09,058 - INFO - Epoch: [113][100/391] Time 0.020 (0.020) Data 0.000 (0.005) Loss 0.1750 (0.1977) Acc@1 93.750 (93.270) Acc@5 100.000 (99.845)
2025-08-28 05:54:09,700 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:09,700 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:10,879 - INFO - Epoch: [113][200/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.1747 (0.1995) Acc@1 93.750 (93.202) Acc@5 100.000 (99.856)
2025-08-28 05:54:12,614 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:12,614 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:12,702 - INFO - Epoch: [113][300/391] Time 0.017 (0.019) Data 0.001 (0.003) Loss 0.2636 (0.1995) Acc@1 90.625 (93.215) Acc@5 100.000 (99.873)
2025-08-28 05:54:14,483 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3164 (0.3164) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:54:15,349 - INFO - Epoch 113:
2025-08-28 05:54:15,349 - INFO -   Train: acc1: 93.1360 | acc5: 99.8660 | loss: 0.2024 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:15,349 - INFO -   Val:   acc1: 89.1000 | acc5: 99.6500 | loss: 0.3381
2025-08-28 05:54:15,349 - INFO -   LR: 0.010000
2025-08-28 05:54:15,366 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-28 05:54:15,577 - INFO - Epoch: [114][0/391] Time 0.209 (0.209) Data 0.180 (0.180) Loss 0.1184 (0.1184) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:54:16,867 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:16,867 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:17,550 - INFO - Epoch: [114][100/391] Time 0.017 (0.022) Data 0.001 (0.003) Loss 0.2582 (0.2073) Acc@1 89.062 (93.185) Acc@5 98.438 (99.868)
2025-08-28 05:54:19,460 - INFO - Epoch: [114][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1760 (0.2057) Acc@1 95.312 (93.066) Acc@5 100.000 (99.868)
2025-08-28 05:54:19,965 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:19,965 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:21,342 - INFO - Epoch: [114][300/391] Time 0.046 (0.020) Data 0.015 (0.002) Loss 0.1267 (0.2067) Acc@1 96.094 (92.904) Acc@5 100.000 (99.868)
2025-08-28 05:54:22,911 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:22,911 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:23,157 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.4097 (0.4097) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 05:54:23,995 - INFO - Epoch 114:
2025-08-28 05:54:23,995 - INFO -   Train: acc1: 92.7640 | acc5: 99.8620 | loss: 0.2096 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:23,995 - INFO -   Val:   acc1: 89.0500 | acc5: 99.6600 | loss: 0.3331
2025-08-28 05:54:23,995 - INFO -   LR: 0.010000
2025-08-28 05:54:24,010 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-28 05:54:24,185 - INFO - Epoch: [115][0/391] Time 0.174 (0.174) Data 0.146 (0.146) Loss 0.2125 (0.2125) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:54:26,059 - INFO - Epoch: [115][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3216 (0.1867) Acc@1 89.844 (93.827) Acc@5 99.219 (99.923)
2025-08-28 05:54:27,047 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:27,047 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:27,901 - INFO - Epoch: [115][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2947 (0.1942) Acc@1 89.062 (93.361) Acc@5 99.219 (99.907)
2025-08-28 05:54:29,723 - INFO - Epoch: [115][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2674 (0.2002) Acc@1 90.625 (93.137) Acc@5 100.000 (99.875)
2025-08-28 05:54:30,016 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:30,016 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:31,567 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2895 (0.2895) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:54:32,509 - INFO - Epoch 115:
2025-08-28 05:54:32,509 - INFO -   Train: acc1: 93.0260 | acc5: 99.8800 | loss: 0.2041 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:32,509 - INFO -   Val:   acc1: 89.4800 | acc5: 99.6400 | loss: 0.3197
2025-08-28 05:54:32,509 - INFO -   LR: 0.010000
2025-08-28 05:54:32,526 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-28 05:54:32,718 - INFO - Epoch: [116][0/391] Time 0.190 (0.190) Data 0.166 (0.166) Loss 0.3465 (0.3465) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:54:34,246 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:34,246 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:34,571 - INFO - Epoch: [116][100/391] Time 0.053 (0.020) Data 0.030 (0.004) Loss 0.2064 (0.2042) Acc@1 92.188 (92.698) Acc@5 100.000 (99.899)
2025-08-28 05:54:36,338 - INFO - Epoch: [116][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1814 (0.2064) Acc@1 93.750 (92.743) Acc@5 100.000 (99.887)
2025-08-28 05:54:37,188 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:37,188 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:38,197 - INFO - Epoch: [116][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.1513 (0.2036) Acc@1 94.531 (92.860) Acc@5 100.000 (99.873)
2025-08-28 05:54:40,037 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.3115 (0.3115) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:54:40,880 - INFO - Epoch 116:
2025-08-28 05:54:40,880 - INFO -   Train: acc1: 92.8520 | acc5: 99.8620 | loss: 0.2046 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:40,880 - INFO -   Val:   acc1: 89.1700 | acc5: 99.6700 | loss: 0.3223
2025-08-28 05:54:40,880 - INFO -   LR: 0.010000
2025-08-28 05:54:40,898 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-28 05:54:41,088 - INFO - Epoch: [117][0/391] Time 0.189 (0.189) Data 0.163 (0.163) Loss 0.2253 (0.2253) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:54:41,331 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:41,332 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:42,948 - INFO - Epoch: [117][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.1740 (0.2022) Acc@1 96.094 (93.201) Acc@5 100.000 (99.838)
2025-08-28 05:54:44,215 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:44,215 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:44,734 - INFO - Epoch: [117][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2264 (0.2010) Acc@1 90.625 (93.202) Acc@5 99.219 (99.841)
2025-08-28 05:54:46,521 - INFO - Epoch: [117][300/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.2965 (0.2030) Acc@1 91.406 (93.106) Acc@5 100.000 (99.847)
2025-08-28 05:54:47,128 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:47,128 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:48,348 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2780 (0.2780) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:54:49,199 - INFO - Epoch 117:
2025-08-28 05:54:49,199 - INFO -   Train: acc1: 93.0300 | acc5: 99.8400 | loss: 0.2051 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:49,199 - INFO -   Val:   acc1: 88.2700 | acc5: 99.6500 | loss: 0.3515
2025-08-28 05:54:49,199 - INFO -   LR: 0.010000
2025-08-28 05:54:49,213 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-28 05:54:49,392 - INFO - Epoch: [118][0/391] Time 0.178 (0.178) Data 0.155 (0.155) Loss 0.1693 (0.1693) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 05:54:51,234 - INFO - Epoch: [118][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.2417 (0.2036) Acc@1 92.969 (93.185) Acc@5 100.000 (99.845)
2025-08-28 05:54:51,251 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:51,251 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:53,102 - INFO - Epoch: [118][200/391] Time 0.046 (0.019) Data 0.000 (0.003) Loss 0.2094 (0.2039) Acc@1 93.750 (93.081) Acc@5 100.000 (99.837)
2025-08-28 05:54:54,230 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:54,230 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:54,904 - INFO - Epoch: [118][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2111 (0.2030) Acc@1 92.188 (93.073) Acc@5 100.000 (99.847)
2025-08-28 05:54:56,738 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2599 (0.2599) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:54:57,594 - INFO - Epoch 118:
2025-08-28 05:54:57,594 - INFO -   Train: acc1: 93.0260 | acc5: 99.8420 | loss: 0.2052 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:54:57,594 - INFO -   Val:   acc1: 89.6100 | acc5: 99.5600 | loss: 0.3218
2025-08-28 05:54:57,595 - INFO -   LR: 0.010000
2025-08-28 05:54:57,609 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-28 05:54:57,816 - INFO - Epoch: [119][0/391] Time 0.206 (0.206) Data 0.170 (0.170) Loss 0.1886 (0.1886) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:54:58,337 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:54:58,337 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:54:59,626 - INFO - Epoch: [119][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.1086 (0.1939) Acc@1 96.875 (93.363) Acc@5 100.000 (99.853)
2025-08-28 05:55:01,322 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:01,322 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:01,526 - INFO - Epoch: [119][200/391] Time 0.021 (0.019) Data 0.010 (0.003) Loss 0.1774 (0.1996) Acc@1 94.531 (93.124) Acc@5 100.000 (99.852)
2025-08-28 05:55:03,433 - INFO - Epoch: [119][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1854 (0.2022) Acc@1 92.188 (93.000) Acc@5 100.000 (99.842)
2025-08-28 05:55:04,446 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:04,446 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:05,315 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3543 (0.3543) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:55:06,178 - INFO - Epoch 119:
2025-08-28 05:55:06,178 - INFO -   Train: acc1: 92.9220 | acc5: 99.8380 | loss: 0.2047 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:06,178 - INFO -   Val:   acc1: 89.2100 | acc5: 99.6400 | loss: 0.3342
2025-08-28 05:55:06,178 - INFO -   LR: 0.010000
2025-08-28 05:55:06,199 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-28 05:55:06,394 - INFO - Epoch: [120][0/391] Time 0.194 (0.194) Data 0.170 (0.170) Loss 0.1436 (0.1436) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:55:08,228 - INFO - Epoch: [120][100/391] Time 0.024 (0.020) Data 0.000 (0.004) Loss 0.1816 (0.2017) Acc@1 93.750 (93.263) Acc@5 99.219 (99.845)
2025-08-28 05:55:08,594 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:08,595 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:10,109 - INFO - Epoch: [120][200/391] Time 0.039 (0.019) Data 0.000 (0.003) Loss 0.1414 (0.2042) Acc@1 94.531 (93.004) Acc@5 100.000 (99.864)
2025-08-28 05:55:11,580 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:11,580 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:11,991 - INFO - Epoch: [120][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1250 (0.2046) Acc@1 95.312 (92.914) Acc@5 100.000 (99.865)
2025-08-28 05:55:13,803 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3533 (0.3533) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:55:14,646 - INFO - Epoch 120:
2025-08-28 05:55:14,646 - INFO -   Train: acc1: 92.8540 | acc5: 99.8700 | loss: 0.2058 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:14,646 - INFO -   Val:   acc1: 89.1200 | acc5: 99.6100 | loss: 0.3298
2025-08-28 05:55:14,646 - INFO -   LR: 0.010000
2025-08-28 05:55:14,696 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-28 05:55:14,866 - INFO - Epoch: [121][0/391] Time 0.169 (0.169) Data 0.153 (0.153) Loss 0.2205 (0.2205) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 05:55:15,803 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:15,806 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:16,798 - INFO - Epoch: [121][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.1374 (0.1969) Acc@1 95.312 (93.216) Acc@5 100.000 (99.899)
2025-08-28 05:55:18,558 - INFO - Epoch: [121][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2223 (0.1994) Acc@1 91.406 (93.159) Acc@5 99.219 (99.856)
2025-08-28 05:55:18,710 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:18,710 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:20,472 - INFO - Epoch: [121][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.3174 (0.2050) Acc@1 92.969 (92.974) Acc@5 100.000 (99.852)
2025-08-28 05:55:21,728 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:21,728 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:22,273 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3203 (0.3203) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:55:23,158 - INFO - Epoch 121:
2025-08-28 05:55:23,158 - INFO -   Train: acc1: 92.9040 | acc5: 99.8580 | loss: 0.2064 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:23,158 - INFO -   Val:   acc1: 89.0400 | acc5: 99.6600 | loss: 0.3369
2025-08-28 05:55:23,158 - INFO -   LR: 0.010000
2025-08-28 05:55:23,174 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-28 05:55:23,360 - INFO - Epoch: [122][0/391] Time 0.185 (0.185) Data 0.155 (0.155) Loss 0.1750 (0.1750) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:55:25,231 - INFO - Epoch: [122][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.3030 (0.1981) Acc@1 88.281 (93.209) Acc@5 100.000 (99.868)
2025-08-28 05:55:25,928 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:25,928 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:27,155 - INFO - Epoch: [122][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.2457 (0.2054) Acc@1 92.969 (92.860) Acc@5 100.000 (99.876)
2025-08-28 05:55:28,965 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:28,965 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:29,021 - INFO - Epoch: [122][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2311 (0.2037) Acc@1 93.750 (92.899) Acc@5 99.219 (99.868)
2025-08-28 05:55:30,853 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.3017 (0.3017) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:55:31,694 - INFO - Epoch 122:
2025-08-28 05:55:31,694 - INFO -   Train: acc1: 92.8460 | acc5: 99.8580 | loss: 0.2058 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:31,694 - INFO -   Val:   acc1: 89.2100 | acc5: 99.6700 | loss: 0.3270
2025-08-28 05:55:31,694 - INFO -   LR: 0.010000
2025-08-28 05:55:31,713 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-28 05:55:31,908 - INFO - Epoch: [123][0/391] Time 0.194 (0.194) Data 0.174 (0.174) Loss 0.1993 (0.1993) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:55:33,082 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:33,082 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:33,716 - INFO - Epoch: [123][100/391] Time 0.019 (0.020) Data 0.003 (0.004) Loss 0.1587 (0.2063) Acc@1 93.750 (93.038) Acc@5 100.000 (99.868)
2025-08-28 05:55:35,522 - INFO - Epoch: [123][200/391] Time 0.039 (0.019) Data 0.026 (0.003) Loss 0.2158 (0.1995) Acc@1 93.750 (93.287) Acc@5 100.000 (99.868)
2025-08-28 05:55:35,996 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:35,996 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:37,353 - INFO - Epoch: [123][300/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.1912 (0.2017) Acc@1 94.531 (93.140) Acc@5 100.000 (99.881)
2025-08-28 05:55:38,965 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:38,965 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:39,194 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3286 (0.3286) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:55:40,028 - INFO - Epoch 123:
2025-08-28 05:55:40,028 - INFO -   Train: acc1: 92.9980 | acc5: 99.8680 | loss: 0.2062 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:40,028 - INFO -   Val:   acc1: 89.4200 | acc5: 99.6000 | loss: 0.3283
2025-08-28 05:55:40,028 - INFO -   LR: 0.010000
2025-08-28 05:55:40,046 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-28 05:55:40,248 - INFO - Epoch: [124][0/391] Time 0.201 (0.201) Data 0.176 (0.176) Loss 0.1940 (0.1940) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:55:42,115 - INFO - Epoch: [124][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.2624 (0.1931) Acc@1 87.500 (93.356) Acc@5 100.000 (99.838)
2025-08-28 05:55:43,147 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:43,147 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:44,061 - INFO - Epoch: [124][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2421 (0.2030) Acc@1 90.625 (92.926) Acc@5 100.000 (99.845)
2025-08-28 05:55:45,920 - INFO - Epoch: [124][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2790 (0.2057) Acc@1 87.500 (92.766) Acc@5 100.000 (99.852)
2025-08-28 05:55:46,182 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:46,182 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:47,777 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.3339 (0.3339) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:55:48,600 - INFO - Epoch 124:
2025-08-28 05:55:48,600 - INFO -   Train: acc1: 92.7380 | acc5: 99.8580 | loss: 0.2079 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:48,600 - INFO -   Val:   acc1: 88.9400 | acc5: 99.5800 | loss: 0.3431
2025-08-28 05:55:48,600 - INFO -   LR: 0.010000
2025-08-28 05:55:48,618 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-28 05:55:48,806 - INFO - Epoch: [125][0/391] Time 0.188 (0.188) Data 0.145 (0.145) Loss 0.1834 (0.1834) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:55:50,375 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:50,375 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:50,675 - INFO - Epoch: [125][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1713 (0.2080) Acc@1 92.969 (92.837) Acc@5 100.000 (99.876)
2025-08-28 05:55:52,477 - INFO - Epoch: [125][200/391] Time 0.023 (0.019) Data 0.005 (0.003) Loss 0.1478 (0.2037) Acc@1 95.312 (93.062) Acc@5 100.000 (99.880)
2025-08-28 05:55:53,257 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:53,257 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:54,244 - INFO - Epoch: [125][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1653 (0.2028) Acc@1 92.188 (93.166) Acc@5 100.000 (99.865)
2025-08-28 05:55:56,072 - INFO - Test: [0/79] Time 0.171 (0.171) Loss 0.3403 (0.3403) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 05:55:56,922 - INFO - Epoch 125:
2025-08-28 05:55:56,922 - INFO -   Train: acc1: 93.0080 | acc5: 99.8680 | loss: 0.2055 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:55:56,922 - INFO -   Val:   acc1: 88.5500 | acc5: 99.5300 | loss: 0.3503
2025-08-28 05:55:56,922 - INFO -   LR: 0.010000
2025-08-28 05:55:56,941 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-28 05:55:57,108 - INFO - Epoch: [126][0/391] Time 0.166 (0.166) Data 0.149 (0.149) Loss 0.3148 (0.3148) Acc@1 89.062 (89.062) Acc@5 98.438 (98.438)
2025-08-28 05:55:57,378 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:55:57,378 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:55:59,049 - INFO - Epoch: [126][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.2273 (0.2001) Acc@1 93.750 (93.263) Acc@5 99.219 (99.853)
2025-08-28 05:56:00,397 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:00,397 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:00,851 - INFO - Epoch: [126][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2124 (0.2045) Acc@1 89.062 (93.019) Acc@5 100.000 (99.848)
2025-08-28 05:56:02,686 - INFO - Epoch: [126][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2122 (0.2034) Acc@1 92.188 (93.002) Acc@5 100.000 (99.852)
2025-08-28 05:56:03,294 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:03,294 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:04,475 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3168 (0.3168) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:56:05,371 - INFO - Epoch 126:
2025-08-28 05:56:05,371 - INFO -   Train: acc1: 92.9480 | acc5: 99.8480 | loss: 0.2051 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:05,371 - INFO -   Val:   acc1: 88.9500 | acc5: 99.7000 | loss: 0.3374
2025-08-28 05:56:05,371 - INFO -   LR: 0.010000
2025-08-28 05:56:05,390 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-28 05:56:05,590 - INFO - Epoch: [127][0/391] Time 0.200 (0.200) Data 0.178 (0.178) Loss 0.1346 (0.1346) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:56:07,405 - INFO - Epoch: [127][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2725 (0.1998) Acc@1 91.406 (92.922) Acc@5 100.000 (99.884)
2025-08-28 05:56:07,451 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:07,451 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:09,280 - INFO - Epoch: [127][200/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.2516 (0.2016) Acc@1 91.406 (92.961) Acc@5 100.000 (99.911)
2025-08-28 05:56:10,474 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:10,474 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:11,205 - INFO - Epoch: [127][300/391] Time 0.018 (0.019) Data 0.000 (0.005) Loss 0.3044 (0.2037) Acc@1 88.281 (92.922) Acc@5 100.000 (99.878)
2025-08-28 05:56:13,069 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.3920 (0.3920) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:56:13,933 - INFO - Epoch 127:
2025-08-28 05:56:13,933 - INFO -   Train: acc1: 92.8440 | acc5: 99.8740 | loss: 0.2069 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:13,933 - INFO -   Val:   acc1: 88.2600 | acc5: 99.4700 | loss: 0.3687
2025-08-28 05:56:13,933 - INFO -   LR: 0.010000
2025-08-28 05:56:13,951 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-28 05:56:14,159 - INFO - Epoch: [128][0/391] Time 0.207 (0.207) Data 0.182 (0.182) Loss 0.1734 (0.1734) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:56:14,738 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:14,738 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:16,004 - INFO - Epoch: [128][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1497 (0.1994) Acc@1 97.656 (93.162) Acc@5 99.219 (99.868)
2025-08-28 05:56:17,722 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:17,722 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:17,859 - INFO - Epoch: [128][200/391] Time 0.015 (0.019) Data 0.004 (0.004) Loss 0.1564 (0.1986) Acc@1 94.531 (93.089) Acc@5 100.000 (99.887)
2025-08-28 05:56:19,704 - INFO - Epoch: [128][300/391] Time 0.036 (0.019) Data 0.025 (0.004) Loss 0.1890 (0.2052) Acc@1 92.188 (92.886) Acc@5 100.000 (99.883)
2025-08-28 05:56:20,649 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:20,649 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:21,507 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2905 (0.2905) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:56:22,344 - INFO - Epoch 128:
2025-08-28 05:56:22,344 - INFO -   Train: acc1: 92.8180 | acc5: 99.8760 | loss: 0.2084 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:22,344 - INFO -   Val:   acc1: 88.6900 | acc5: 99.5800 | loss: 0.3474
2025-08-28 05:56:22,344 - INFO -   LR: 0.010000
2025-08-28 05:56:22,359 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-28 05:56:22,582 - INFO - Epoch: [129][0/391] Time 0.222 (0.222) Data 0.195 (0.195) Loss 0.1380 (0.1380) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-28 05:56:24,413 - INFO - Epoch: [129][100/391] Time 0.026 (0.020) Data 0.011 (0.005) Loss 0.1581 (0.2038) Acc@1 94.531 (92.915) Acc@5 100.000 (99.838)
2025-08-28 05:56:24,753 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:24,753 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:26,132 - INFO - Epoch: [129][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2422 (0.2032) Acc@1 91.406 (92.856) Acc@5 100.000 (99.841)
2025-08-28 05:56:27,723 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:27,723 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:28,050 - INFO - Epoch: [129][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.2143 (0.2038) Acc@1 92.188 (92.829) Acc@5 99.219 (99.852)
2025-08-28 05:56:29,862 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.3444 (0.3444) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:56:30,738 - INFO - Epoch 129:
2025-08-28 05:56:30,738 - INFO -   Train: acc1: 92.6800 | acc5: 99.8500 | loss: 0.2089 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:30,738 - INFO -   Val:   acc1: 88.5000 | acc5: 99.6000 | loss: 0.3428
2025-08-28 05:56:30,738 - INFO -   LR: 0.010000
2025-08-28 05:56:30,757 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-28 05:56:30,958 - INFO - Epoch: [130][0/391] Time 0.200 (0.200) Data 0.172 (0.172) Loss 0.2072 (0.2072) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 05:56:31,824 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:31,824 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:32,741 - INFO - Epoch: [130][100/391] Time 0.015 (0.020) Data 0.003 (0.004) Loss 0.2174 (0.1976) Acc@1 91.406 (93.255) Acc@5 99.219 (99.822)
2025-08-28 05:56:34,519 - INFO - Epoch: [130][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1694 (0.2036) Acc@1 96.875 (93.054) Acc@5 100.000 (99.845)
2025-08-28 05:56:34,709 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:34,709 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:36,351 - INFO - Epoch: [130][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2226 (0.2085) Acc@1 92.969 (92.831) Acc@5 100.000 (99.831)
2025-08-28 05:56:37,615 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:37,615 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:38,146 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.3886 (0.3886) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:56:38,994 - INFO - Epoch 130:
2025-08-28 05:56:38,995 - INFO -   Train: acc1: 92.7600 | acc5: 99.8460 | loss: 0.2099 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:38,995 - INFO -   Val:   acc1: 88.4600 | acc5: 99.5700 | loss: 0.3515
2025-08-28 05:56:38,995 - INFO -   LR: 0.010000
2025-08-28 05:56:39,043 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-28 05:56:39,233 - INFO - Epoch: [131][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.1931 (0.1931) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:56:40,993 - INFO - Epoch: [131][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2513 (0.2040) Acc@1 92.969 (92.876) Acc@5 100.000 (99.884)
2025-08-28 05:56:41,664 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:41,664 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:42,787 - INFO - Epoch: [131][200/391] Time 0.036 (0.019) Data 0.012 (0.003) Loss 0.1538 (0.2046) Acc@1 93.750 (92.813) Acc@5 100.000 (99.911)
2025-08-28 05:56:44,467 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:44,467 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:44,501 - INFO - Epoch: [131][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.2453 (0.2053) Acc@1 91.406 (92.909) Acc@5 100.000 (99.888)
2025-08-28 05:56:46,271 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.2863 (0.2863) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:56:47,090 - INFO - Epoch 131:
2025-08-28 05:56:47,090 - INFO -   Train: acc1: 92.8760 | acc5: 99.8700 | loss: 0.2068 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:47,090 - INFO -   Val:   acc1: 88.9200 | acc5: 99.5300 | loss: 0.3450
2025-08-28 05:56:47,090 - INFO -   LR: 0.010000
2025-08-28 05:56:47,107 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-28 05:56:47,267 - INFO - Epoch: [132][0/391] Time 0.159 (0.159) Data 0.142 (0.142) Loss 0.2364 (0.2364) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:56:48,558 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:48,558 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:49,196 - INFO - Epoch: [132][100/391] Time 0.025 (0.021) Data 0.000 (0.004) Loss 0.1448 (0.2069) Acc@1 96.875 (92.984) Acc@5 100.000 (99.899)
2025-08-28 05:56:50,914 - INFO - Epoch: [132][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1292 (0.2031) Acc@1 96.875 (92.984) Acc@5 100.000 (99.891)
2025-08-28 05:56:51,389 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:51,389 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:52,729 - INFO - Epoch: [132][300/391] Time 0.019 (0.019) Data 0.006 (0.003) Loss 0.1735 (0.2044) Acc@1 96.875 (93.065) Acc@5 100.000 (99.888)
2025-08-28 05:56:54,225 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:54,225 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:54,442 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3465 (0.3465) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:56:55,356 - INFO - Epoch 132:
2025-08-28 05:56:55,356 - INFO -   Train: acc1: 92.8840 | acc5: 99.8800 | loss: 0.2086 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:56:55,356 - INFO -   Val:   acc1: 88.2700 | acc5: 99.6200 | loss: 0.3562
2025-08-28 05:56:55,356 - INFO -   LR: 0.010000
2025-08-28 05:56:55,728 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-28 05:56:55,938 - INFO - Epoch: [133][0/391] Time 0.208 (0.208) Data 0.182 (0.182) Loss 0.1671 (0.1671) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:56:57,738 - INFO - Epoch: [133][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2016 (0.2069) Acc@1 92.969 (92.744) Acc@5 100.000 (99.892)
2025-08-28 05:56:58,783 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:56:58,783 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:56:59,546 - INFO - Epoch: [133][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1848 (0.2040) Acc@1 92.188 (92.856) Acc@5 100.000 (99.903)
2025-08-28 05:57:01,384 - INFO - Epoch: [133][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2435 (0.2056) Acc@1 91.406 (92.865) Acc@5 100.000 (99.886)
2025-08-28 05:57:01,645 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:01,645 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:03,119 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.4274 (0.4274) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 05:57:03,977 - INFO - Epoch 133:
2025-08-28 05:57:03,977 - INFO -   Train: acc1: 92.7540 | acc5: 99.8760 | loss: 0.2089 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:03,978 - INFO -   Val:   acc1: 88.1000 | acc5: 99.6100 | loss: 0.3634
2025-08-28 05:57:03,978 - INFO -   LR: 0.010000
2025-08-28 05:57:03,995 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-28 05:57:04,182 - INFO - Epoch: [134][0/391] Time 0.187 (0.187) Data 0.169 (0.169) Loss 0.1822 (0.1822) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 05:57:05,755 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:05,755 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:06,049 - INFO - Epoch: [134][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1440 (0.2026) Acc@1 94.531 (93.123) Acc@5 100.000 (99.907)
2025-08-28 05:57:07,963 - INFO - Epoch: [134][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.2546 (0.2043) Acc@1 88.281 (93.043) Acc@5 100.000 (99.883)
2025-08-28 05:57:08,786 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:08,787 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:09,763 - INFO - Epoch: [134][300/391] Time 0.018 (0.019) Data 0.006 (0.002) Loss 0.2540 (0.2087) Acc@1 92.188 (92.823) Acc@5 100.000 (99.878)
2025-08-28 05:57:11,538 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3295 (0.3295) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:57:12,427 - INFO - Epoch 134:
2025-08-28 05:57:12,427 - INFO -   Train: acc1: 92.7700 | acc5: 99.8480 | loss: 0.2098 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:12,427 - INFO -   Val:   acc1: 88.2600 | acc5: 99.5600 | loss: 0.3594
2025-08-28 05:57:12,427 - INFO -   LR: 0.010000
2025-08-28 05:57:12,444 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-28 05:57:12,638 - INFO - Epoch: [135][0/391] Time 0.193 (0.193) Data 0.173 (0.173) Loss 0.2776 (0.2776) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:57:12,872 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:12,872 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:14,454 - INFO - Epoch: [135][100/391] Time 0.023 (0.020) Data 0.013 (0.004) Loss 0.3096 (0.2064) Acc@1 91.406 (92.752) Acc@5 100.000 (99.884)
2025-08-28 05:57:15,724 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:15,724 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:16,185 - INFO - Epoch: [135][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2433 (0.2053) Acc@1 91.406 (92.794) Acc@5 100.000 (99.891)
2025-08-28 05:57:18,080 - INFO - Epoch: [135][300/391] Time 0.022 (0.019) Data 0.001 (0.003) Loss 0.2560 (0.2100) Acc@1 89.062 (92.631) Acc@5 100.000 (99.870)
2025-08-28 05:57:18,684 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:18,685 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:19,835 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.4276 (0.4276) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 05:57:20,666 - INFO - Epoch 135:
2025-08-28 05:57:20,666 - INFO -   Train: acc1: 92.6440 | acc5: 99.8760 | loss: 0.2112 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:20,666 - INFO -   Val:   acc1: 88.0500 | acc5: 99.5100 | loss: 0.3745
2025-08-28 05:57:20,666 - INFO -   LR: 0.010000
2025-08-28 05:57:20,685 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-28 05:57:20,878 - INFO - Epoch: [136][0/391] Time 0.192 (0.192) Data 0.167 (0.167) Loss 0.1651 (0.1651) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-28 05:57:22,689 - INFO - Epoch: [136][100/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.1719 (0.2114) Acc@1 95.312 (92.659) Acc@5 100.000 (99.861)
2025-08-28 05:57:22,736 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:22,736 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:24,552 - INFO - Epoch: [136][200/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2663 (0.2100) Acc@1 87.500 (92.802) Acc@5 99.219 (99.860)
2025-08-28 05:57:25,660 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:25,660 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:26,281 - INFO - Epoch: [136][300/391] Time 0.010 (0.019) Data 0.000 (0.002) Loss 0.3242 (0.2096) Acc@1 89.844 (92.774) Acc@5 100.000 (99.878)
2025-08-28 05:57:28,072 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.4223 (0.4223) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:57:28,944 - INFO - Epoch 136:
2025-08-28 05:57:28,944 - INFO -   Train: acc1: 92.7580 | acc5: 99.8780 | loss: 0.2101 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:28,944 - INFO -   Val:   acc1: 88.2300 | acc5: 99.7000 | loss: 0.3559
2025-08-28 05:57:28,944 - INFO -   LR: 0.010000
2025-08-28 05:57:29,305 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-28 05:57:29,498 - INFO - Epoch: [137][0/391] Time 0.191 (0.191) Data 0.167 (0.167) Loss 0.2491 (0.2491) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 05:57:30,071 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:30,071 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:31,302 - INFO - Epoch: [137][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.0799 (0.1919) Acc@1 96.875 (93.317) Acc@5 100.000 (99.954)
2025-08-28 05:57:32,950 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:32,950 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:33,107 - INFO - Epoch: [137][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2076 (0.2044) Acc@1 92.969 (92.712) Acc@5 100.000 (99.903)
2025-08-28 05:57:34,987 - INFO - Epoch: [137][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2995 (0.2072) Acc@1 89.844 (92.707) Acc@5 100.000 (99.883)
2025-08-28 05:57:35,958 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:35,959 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:36,767 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.3567 (0.3567) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:57:37,613 - INFO - Epoch 137:
2025-08-28 05:57:37,614 - INFO -   Train: acc1: 92.5900 | acc5: 99.8760 | loss: 0.2106 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:37,614 - INFO -   Val:   acc1: 89.4800 | acc5: 99.6100 | loss: 0.3247
2025-08-28 05:57:37,614 - INFO -   LR: 0.010000
2025-08-28 05:57:37,631 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-28 05:57:37,832 - INFO - Epoch: [138][0/391] Time 0.200 (0.200) Data 0.171 (0.171) Loss 0.1619 (0.1619) Acc@1 93.750 (93.750) Acc@5 99.219 (99.219)
2025-08-28 05:57:39,743 - INFO - Epoch: [138][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1749 (0.2042) Acc@1 94.531 (93.069) Acc@5 99.219 (99.915)
2025-08-28 05:57:40,083 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:40,084 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:41,517 - INFO - Epoch: [138][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1737 (0.2105) Acc@1 94.531 (92.767) Acc@5 100.000 (99.856)
2025-08-28 05:57:43,023 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:43,024 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:43,336 - INFO - Epoch: [138][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.1701 (0.2136) Acc@1 93.750 (92.616) Acc@5 100.000 (99.860)
2025-08-28 05:57:45,148 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3469 (0.3469) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:57:45,975 - INFO - Epoch 138:
2025-08-28 05:57:45,975 - INFO -   Train: acc1: 92.5940 | acc5: 99.8560 | loss: 0.2142 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:45,975 - INFO -   Val:   acc1: 87.6000 | acc5: 99.6200 | loss: 0.3816
2025-08-28 05:57:45,975 - INFO -   LR: 0.010000
2025-08-28 05:57:45,991 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-28 05:57:46,181 - INFO - Epoch: [139][0/391] Time 0.189 (0.189) Data 0.170 (0.170) Loss 0.3032 (0.3032) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 05:57:47,105 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:47,105 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:48,037 - INFO - Epoch: [139][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.1945 (0.2027) Acc@1 92.969 (93.023) Acc@5 100.000 (99.830)
2025-08-28 05:57:49,932 - INFO - Epoch: [139][200/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.2257 (0.2127) Acc@1 92.188 (92.771) Acc@5 100.000 (99.856)
2025-08-28 05:57:50,075 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:50,076 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:51,701 - INFO - Epoch: [139][300/391] Time 0.021 (0.019) Data 0.009 (0.003) Loss 0.2316 (0.2119) Acc@1 90.625 (92.764) Acc@5 100.000 (99.865)
2025-08-28 05:57:52,947 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:52,947 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:53,451 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2625 (0.2625) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:57:54,300 - INFO - Epoch 139:
2025-08-28 05:57:54,300 - INFO -   Train: acc1: 92.6680 | acc5: 99.8540 | loss: 0.2137 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:57:54,300 - INFO -   Val:   acc1: 88.7200 | acc5: 99.5600 | loss: 0.3529
2025-08-28 05:57:54,300 - INFO -   LR: 0.010000
2025-08-28 05:57:54,316 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-28 05:57:54,507 - INFO - Epoch: [140][0/391] Time 0.189 (0.189) Data 0.171 (0.171) Loss 0.1843 (0.1843) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:57:56,351 - INFO - Epoch: [140][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1393 (0.1965) Acc@1 96.094 (93.255) Acc@5 100.000 (99.892)
2025-08-28 05:57:57,060 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:57:57,060 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:57:58,204 - INFO - Epoch: [140][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2506 (0.2073) Acc@1 90.625 (92.829) Acc@5 99.219 (99.856)
2025-08-28 05:58:00,019 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:00,019 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:00,031 - INFO - Epoch: [140][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1510 (0.2112) Acc@1 96.094 (92.600) Acc@5 100.000 (99.857)
2025-08-28 05:58:01,863 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2940 (0.2940) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 05:58:02,723 - INFO - Epoch 140:
2025-08-28 05:58:02,723 - INFO -   Train: acc1: 92.5980 | acc5: 99.8520 | loss: 0.2123 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:02,723 - INFO -   Val:   acc1: 88.4600 | acc5: 99.7000 | loss: 0.3523
2025-08-28 05:58:02,723 - INFO -   LR: 0.010000
2025-08-28 05:58:02,778 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-28 05:58:02,984 - INFO - Epoch: [141][0/391] Time 0.205 (0.205) Data 0.187 (0.187) Loss 0.2835 (0.2835) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:58:04,350 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:04,352 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:04,976 - INFO - Epoch: [141][100/391] Time 0.018 (0.022) Data 0.000 (0.004) Loss 0.1815 (0.2020) Acc@1 96.094 (93.123) Acc@5 100.000 (99.830)
2025-08-28 05:58:06,816 - INFO - Epoch: [141][200/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.2343 (0.2012) Acc@1 92.969 (93.167) Acc@5 99.219 (99.860)
2025-08-28 05:58:07,264 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:07,264 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:08,683 - INFO - Epoch: [141][300/391] Time 0.035 (0.020) Data 0.018 (0.003) Loss 0.2230 (0.2111) Acc@1 92.188 (92.774) Acc@5 100.000 (99.849)
2025-08-28 05:58:10,243 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:10,244 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:10,468 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.3923 (0.3923) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 05:58:11,321 - INFO - Epoch 141:
2025-08-28 05:58:11,321 - INFO -   Train: acc1: 92.6960 | acc5: 99.8540 | loss: 0.2116 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:11,321 - INFO -   Val:   acc1: 88.2500 | acc5: 99.6000 | loss: 0.3674
2025-08-28 05:58:11,321 - INFO -   LR: 0.010000
2025-08-28 05:58:11,339 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-28 05:58:11,528 - INFO - Epoch: [142][0/391] Time 0.188 (0.188) Data 0.162 (0.162) Loss 0.2145 (0.2145) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:58:13,327 - INFO - Epoch: [142][100/391] Time 0.028 (0.020) Data 0.000 (0.004) Loss 0.2897 (0.2060) Acc@1 89.844 (92.768) Acc@5 100.000 (99.845)
2025-08-28 05:58:14,393 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:14,394 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:15,191 - INFO - Epoch: [142][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1656 (0.2047) Acc@1 95.312 (92.918) Acc@5 99.219 (99.841)
2025-08-28 05:58:17,052 - INFO - Epoch: [142][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2962 (0.2086) Acc@1 91.406 (92.795) Acc@5 99.219 (99.847)
2025-08-28 05:58:17,353 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:17,353 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:18,836 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3213 (0.3213) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 05:58:19,744 - INFO - Epoch 142:
2025-08-28 05:58:19,744 - INFO -   Train: acc1: 92.6620 | acc5: 99.8340 | loss: 0.2116 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:19,744 - INFO -   Val:   acc1: 88.4400 | acc5: 99.6500 | loss: 0.3508
2025-08-28 05:58:19,744 - INFO -   LR: 0.010000
2025-08-28 05:58:19,762 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-28 05:58:19,943 - INFO - Epoch: [143][0/391] Time 0.180 (0.180) Data 0.158 (0.158) Loss 0.2478 (0.2478) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:58:21,538 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:21,538 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:21,801 - INFO - Epoch: [143][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.1726 (0.1963) Acc@1 94.531 (93.085) Acc@5 100.000 (99.907)
2025-08-28 05:58:23,607 - INFO - Epoch: [143][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0939 (0.2072) Acc@1 97.656 (92.739) Acc@5 100.000 (99.876)
2025-08-28 05:58:24,423 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:24,423 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:25,420 - INFO - Epoch: [143][300/391] Time 0.016 (0.019) Data 0.004 (0.003) Loss 0.2135 (0.2101) Acc@1 93.750 (92.631) Acc@5 100.000 (99.868)
2025-08-28 05:58:27,333 - INFO - Test: [0/79] Time 0.168 (0.168) Loss 0.3094 (0.3094) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:58:28,158 - INFO - Epoch 143:
2025-08-28 05:58:28,158 - INFO -   Train: acc1: 92.5840 | acc5: 99.8620 | loss: 0.2108 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:28,158 - INFO -   Val:   acc1: 87.9200 | acc5: 99.5300 | loss: 0.3697
2025-08-28 05:58:28,158 - INFO -   LR: 0.010000
2025-08-28 05:58:28,178 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-28 05:58:28,383 - INFO - Epoch: [144][0/391] Time 0.204 (0.204) Data 0.175 (0.175) Loss 0.3075 (0.3075) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 05:58:28,665 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:28,665 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:30,209 - INFO - Epoch: [144][100/391] Time 0.026 (0.020) Data 0.000 (0.004) Loss 0.2555 (0.2113) Acc@1 90.625 (92.729) Acc@5 100.000 (99.814)
2025-08-28 05:58:31,605 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:31,605 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:32,036 - INFO - Epoch: [144][200/391] Time 0.027 (0.019) Data 0.004 (0.003) Loss 0.2101 (0.2153) Acc@1 92.969 (92.428) Acc@5 100.000 (99.833)
2025-08-28 05:58:33,862 - INFO - Epoch: [144][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2165 (0.2147) Acc@1 92.969 (92.528) Acc@5 100.000 (99.862)
2025-08-28 05:58:34,497 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:34,497 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:35,659 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.3232 (0.3232) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 05:58:36,541 - INFO - Epoch 144:
2025-08-28 05:58:36,541 - INFO -   Train: acc1: 92.4880 | acc5: 99.8480 | loss: 0.2166 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:36,541 - INFO -   Val:   acc1: 88.6300 | acc5: 99.5800 | loss: 0.3485
2025-08-28 05:58:36,541 - INFO -   LR: 0.010000
2025-08-28 05:58:36,560 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-28 05:58:36,763 - INFO - Epoch: [145][0/391] Time 0.203 (0.203) Data 0.178 (0.178) Loss 0.2376 (0.2376) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 05:58:38,614 - INFO - Epoch: [145][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2313 (0.1926) Acc@1 91.406 (93.866) Acc@5 100.000 (99.845)
2025-08-28 05:58:38,699 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:38,699 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:40,491 - INFO - Epoch: [145][200/391] Time 0.039 (0.020) Data 0.010 (0.003) Loss 0.2188 (0.1982) Acc@1 92.969 (93.447) Acc@5 100.000 (99.872)
2025-08-28 05:58:41,748 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:41,748 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:42,358 - INFO - Epoch: [145][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.1915 (0.2071) Acc@1 94.531 (92.984) Acc@5 100.000 (99.873)
2025-08-28 05:58:44,170 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2926 (0.2926) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:58:44,991 - INFO - Epoch 145:
2025-08-28 05:58:44,991 - INFO -   Train: acc1: 92.8500 | acc5: 99.8760 | loss: 0.2098 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:44,991 - INFO -   Val:   acc1: 88.7500 | acc5: 99.4600 | loss: 0.3624
2025-08-28 05:58:44,991 - INFO -   LR: 0.010000
2025-08-28 05:58:45,009 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-28 05:58:45,201 - INFO - Epoch: [146][0/391] Time 0.191 (0.191) Data 0.174 (0.174) Loss 0.2393 (0.2393) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 05:58:45,861 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:45,861 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:47,100 - INFO - Epoch: [146][100/391] Time 0.014 (0.021) Data 0.001 (0.004) Loss 0.2236 (0.2064) Acc@1 92.188 (92.976) Acc@5 99.219 (99.868)
2025-08-28 05:58:48,784 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:48,784 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:48,904 - INFO - Epoch: [146][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.2186 (0.2135) Acc@1 93.750 (92.724) Acc@5 100.000 (99.864)
2025-08-28 05:58:50,721 - INFO - Epoch: [146][300/391] Time 0.020 (0.019) Data 0.006 (0.003) Loss 0.1318 (0.2110) Acc@1 96.094 (92.714) Acc@5 100.000 (99.865)
2025-08-28 05:58:51,739 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:51,739 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:52,543 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.3508 (0.3508) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 05:58:53,477 - INFO - Epoch 146:
2025-08-28 05:58:53,477 - INFO -   Train: acc1: 92.6360 | acc5: 99.8540 | loss: 0.2140 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:58:53,477 - INFO -   Val:   acc1: 88.6200 | acc5: 99.5200 | loss: 0.3514
2025-08-28 05:58:53,478 - INFO -   LR: 0.010000
2025-08-28 05:58:53,496 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-28 05:58:53,705 - INFO - Epoch: [147][0/391] Time 0.207 (0.207) Data 0.185 (0.185) Loss 0.2777 (0.2777) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:58:55,612 - INFO - Epoch: [147][100/391] Time 0.021 (0.021) Data 0.010 (0.004) Loss 0.1578 (0.2057) Acc@1 94.531 (92.984) Acc@5 99.219 (99.853)
2025-08-28 05:58:56,037 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:56,037 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:57,492 - INFO - Epoch: [147][200/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.2463 (0.2093) Acc@1 91.406 (92.809) Acc@5 99.219 (99.856)
2025-08-28 05:58:58,935 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:58:58,936 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:58:59,245 - INFO - Epoch: [147][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.1984 (0.2116) Acc@1 94.531 (92.647) Acc@5 100.000 (99.862)
2025-08-28 05:59:01,147 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.4100 (0.4100) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 05:59:01,997 - INFO - Epoch 147:
2025-08-28 05:59:01,997 - INFO -   Train: acc1: 92.6900 | acc5: 99.8440 | loss: 0.2126 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:01,997 - INFO -   Val:   acc1: 87.6400 | acc5: 99.4800 | loss: 0.3919
2025-08-28 05:59:01,997 - INFO -   LR: 0.010000
2025-08-28 05:59:02,016 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-28 05:59:02,212 - INFO - Epoch: [148][0/391] Time 0.195 (0.195) Data 0.173 (0.173) Loss 0.2532 (0.2532) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:59:03,150 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:03,150 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:04,065 - INFO - Epoch: [148][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2243 (0.2038) Acc@1 91.406 (93.139) Acc@5 100.000 (99.853)
2025-08-28 05:59:05,855 - INFO - Epoch: [148][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2420 (0.2079) Acc@1 91.406 (92.848) Acc@5 100.000 (99.852)
2025-08-28 05:59:06,046 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:06,046 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:07,636 - INFO - Epoch: [148][300/391] Time 0.027 (0.019) Data 0.004 (0.003) Loss 0.2834 (0.2120) Acc@1 89.844 (92.616) Acc@5 100.000 (99.849)
2025-08-28 05:59:08,953 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:08,953 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:09,447 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3376 (0.3376) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:59:10,341 - INFO - Epoch 148:
2025-08-28 05:59:10,341 - INFO -   Train: acc1: 92.5440 | acc5: 99.8560 | loss: 0.2129 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:10,341 - INFO -   Val:   acc1: 87.7200 | acc5: 99.5300 | loss: 0.3830
2025-08-28 05:59:10,341 - INFO -   LR: 0.010000
2025-08-28 05:59:10,361 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-28 05:59:10,554 - INFO - Epoch: [149][0/391] Time 0.193 (0.193) Data 0.176 (0.176) Loss 0.2880 (0.2880) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 05:59:12,328 - INFO - Epoch: [149][100/391] Time 0.015 (0.019) Data 0.002 (0.003) Loss 0.2452 (0.2010) Acc@1 92.969 (93.185) Acc@5 100.000 (99.892)
2025-08-28 05:59:13,057 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:13,057 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:14,230 - INFO - Epoch: [149][200/391] Time 0.020 (0.019) Data 0.004 (0.003) Loss 0.3567 (0.2146) Acc@1 87.500 (92.518) Acc@5 100.000 (99.880)
2025-08-28 05:59:16,110 - INFO - Epoch: [149][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.2160 (0.2161) Acc@1 90.625 (92.473) Acc@5 100.000 (99.860)
2025-08-28 05:59:16,117 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:16,117 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:17,861 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3782 (0.3782) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 05:59:18,691 - INFO - Epoch 149:
2025-08-28 05:59:18,691 - INFO -   Train: acc1: 92.5080 | acc5: 99.8600 | loss: 0.2149 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:18,691 - INFO -   Val:   acc1: 88.7100 | acc5: 99.5800 | loss: 0.3520
2025-08-28 05:59:18,691 - INFO -   LR: 0.001000
2025-08-28 05:59:18,709 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-28 05:59:18,891 - INFO - Epoch: [150][0/391] Time 0.181 (0.181) Data 0.162 (0.162) Loss 0.2301 (0.2301) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 05:59:20,208 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:20,208 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:20,772 - INFO - Epoch: [150][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1931 (0.1917) Acc@1 94.531 (93.433) Acc@5 100.000 (99.899)
2025-08-28 05:59:22,607 - INFO - Epoch: [150][200/391] Time 0.031 (0.019) Data 0.019 (0.003) Loss 0.1306 (0.1830) Acc@1 95.312 (93.824) Acc@5 100.000 (99.911)
2025-08-28 05:59:23,171 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:23,171 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:24,499 - INFO - Epoch: [150][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2104 (0.1798) Acc@1 92.969 (93.939) Acc@5 100.000 (99.925)
2025-08-28 05:59:26,152 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:26,153 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:26,363 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.2967 (0.2967) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:59:27,205 - INFO - Epoch 150:
2025-08-28 05:59:27,205 - INFO -   Train: acc1: 94.0400 | acc5: 99.9120 | loss: 0.1762 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:27,205 - INFO -   Val:   acc1: 90.2400 | acc5: 99.7300 | loss: 0.2986
2025-08-28 05:59:27,206 - INFO -   LR: 0.001000
2025-08-28 05:59:27,258 - INFO - Checkpoint saved: epoch=150, metric=90.2400
2025-08-28 05:59:27,289 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-28 05:59:27,482 - INFO - Epoch: [151][0/391] Time 0.191 (0.191) Data 0.175 (0.175) Loss 0.1891 (0.1891) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 05:59:29,387 - INFO - Epoch: [151][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.1626 (0.1569) Acc@1 94.531 (95.003) Acc@5 100.000 (99.915)
2025-08-28 05:59:30,433 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:30,434 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:31,253 - INFO - Epoch: [151][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.2205 (0.1605) Acc@1 92.969 (94.788) Acc@5 100.000 (99.922)
2025-08-28 05:59:33,054 - INFO - Epoch: [151][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.1139 (0.1597) Acc@1 96.875 (94.736) Acc@5 100.000 (99.922)
2025-08-28 05:59:33,424 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:33,424 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:34,863 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2882 (0.2882) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 05:59:35,692 - INFO - Epoch 151:
2025-08-28 05:59:35,692 - INFO -   Train: acc1: 94.6660 | acc5: 99.9260 | loss: 0.1608 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:35,692 - INFO -   Val:   acc1: 90.2000 | acc5: 99.7200 | loss: 0.2955
2025-08-28 05:59:35,692 - INFO -   LR: 0.001000
2025-08-28 05:59:35,710 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-28 05:59:35,883 - INFO - Epoch: [152][0/391] Time 0.172 (0.172) Data 0.148 (0.148) Loss 0.1988 (0.1988) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 05:59:37,572 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:37,572 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:37,786 - INFO - Epoch: [152][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.1795 (0.1586) Acc@1 93.750 (94.879) Acc@5 100.000 (99.915)
2025-08-28 05:59:39,613 - INFO - Epoch: [152][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1042 (0.1587) Acc@1 98.438 (94.834) Acc@5 100.000 (99.903)
2025-08-28 05:59:40,434 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:40,434 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:41,407 - INFO - Epoch: [152][300/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.1021 (0.1583) Acc@1 96.094 (94.799) Acc@5 100.000 (99.901)
2025-08-28 05:59:43,244 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2922 (0.2922) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:59:44,124 - INFO - Epoch 152:
2025-08-28 05:59:44,125 - INFO -   Train: acc1: 94.7860 | acc5: 99.8980 | loss: 0.1572 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:44,125 - INFO -   Val:   acc1: 90.4600 | acc5: 99.7000 | loss: 0.2932
2025-08-28 05:59:44,125 - INFO -   LR: 0.001000
2025-08-28 05:59:44,179 - INFO - Checkpoint saved: epoch=152, metric=90.4600
2025-08-28 05:59:44,221 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-28 05:59:44,410 - INFO - Epoch: [153][0/391] Time 0.188 (0.188) Data 0.162 (0.162) Loss 0.1630 (0.1630) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-28 05:59:44,711 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:44,711 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:46,247 - INFO - Epoch: [153][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1415 (0.1517) Acc@1 95.312 (94.964) Acc@5 100.000 (99.923)
2025-08-28 05:59:47,607 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:47,607 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:48,044 - INFO - Epoch: [153][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1526 (0.1541) Acc@1 95.312 (94.799) Acc@5 100.000 (99.946)
2025-08-28 05:59:49,940 - INFO - Epoch: [153][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1128 (0.1544) Acc@1 93.750 (94.812) Acc@5 100.000 (99.943)
2025-08-28 05:59:50,577 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:50,587 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:51,703 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.3008 (0.3008) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 05:59:52,543 - INFO - Epoch 153:
2025-08-28 05:59:52,543 - INFO -   Train: acc1: 94.8760 | acc5: 99.9280 | loss: 0.1545 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 05:59:52,543 - INFO -   Val:   acc1: 90.3900 | acc5: 99.7300 | loss: 0.2953
2025-08-28 05:59:52,544 - INFO -   LR: 0.001000
2025-08-28 05:59:52,562 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-28 05:59:52,787 - INFO - Epoch: [154][0/391] Time 0.224 (0.224) Data 0.192 (0.192) Loss 0.1291 (0.1291) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 05:59:54,654 - INFO - Epoch: [154][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1639 (0.1465) Acc@1 93.750 (95.181) Acc@5 100.000 (99.954)
2025-08-28 05:59:54,746 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:54,746 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:56,427 - INFO - Epoch: [154][200/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.2064 (0.1515) Acc@1 92.969 (94.912) Acc@5 100.000 (99.942)
2025-08-28 05:59:57,589 - INFO - Pruning info: sparsity=0.800
2025-08-28 05:59:57,589 - INFO -   Reactivation rate: 0.0000
2025-08-28 05:59:58,215 - INFO - Epoch: [154][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1644 (0.1488) Acc@1 93.750 (95.079) Acc@5 100.000 (99.938)
2025-08-28 06:00:00,102 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.2918 (0.2918) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:00:00,964 - INFO - Epoch 154:
2025-08-28 06:00:00,964 - INFO -   Train: acc1: 95.0280 | acc5: 99.9260 | loss: 0.1498 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:00,964 - INFO -   Val:   acc1: 90.3300 | acc5: 99.7000 | loss: 0.2947
2025-08-28 06:00:00,964 - INFO -   LR: 0.001000
2025-08-28 06:00:00,981 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-28 06:00:01,182 - INFO - Epoch: [155][0/391] Time 0.200 (0.200) Data 0.163 (0.163) Loss 0.1190 (0.1190) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:00:01,913 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:01,913 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:03,186 - INFO - Epoch: [155][100/391] Time 0.015 (0.022) Data 0.000 (0.004) Loss 0.1467 (0.1491) Acc@1 94.531 (95.073) Acc@5 100.000 (99.923)
2025-08-28 06:00:04,980 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:04,981 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:05,093 - INFO - Epoch: [155][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.2254 (0.1481) Acc@1 91.406 (95.079) Acc@5 99.219 (99.946)
2025-08-28 06:00:06,862 - INFO - Epoch: [155][300/391] Time 0.014 (0.020) Data 0.002 (0.003) Loss 0.1200 (0.1473) Acc@1 95.312 (95.126) Acc@5 100.000 (99.933)
2025-08-28 06:00:07,956 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:07,957 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:08,822 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2942 (0.2942) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:00:09,691 - INFO - Epoch 155:
2025-08-28 06:00:09,691 - INFO -   Train: acc1: 95.0580 | acc5: 99.9280 | loss: 0.1484 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:09,691 - INFO -   Val:   acc1: 90.3700 | acc5: 99.7000 | loss: 0.2943
2025-08-28 06:00:09,691 - INFO -   LR: 0.001000
2025-08-28 06:00:09,710 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-28 06:00:09,914 - INFO - Epoch: [156][0/391] Time 0.202 (0.202) Data 0.184 (0.184) Loss 0.1806 (0.1806) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:00:11,753 - INFO - Epoch: [156][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1653 (0.1461) Acc@1 96.094 (95.111) Acc@5 100.000 (99.938)
2025-08-28 06:00:12,190 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:12,190 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:13,626 - INFO - Epoch: [156][200/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.1720 (0.1434) Acc@1 92.188 (95.219) Acc@5 100.000 (99.942)
2025-08-28 06:00:15,086 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:15,086 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:15,401 - INFO - Epoch: [156][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1216 (0.1465) Acc@1 96.094 (95.105) Acc@5 100.000 (99.925)
2025-08-28 06:00:17,343 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.3013 (0.3013) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:00:18,182 - INFO - Epoch 156:
2025-08-28 06:00:18,183 - INFO -   Train: acc1: 95.1640 | acc5: 99.9180 | loss: 0.1453 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:18,183 - INFO -   Val:   acc1: 90.2600 | acc5: 99.7000 | loss: 0.2944
2025-08-28 06:00:18,183 - INFO -   LR: 0.001000
2025-08-28 06:00:18,203 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-28 06:00:18,376 - INFO - Epoch: [157][0/391] Time 0.172 (0.172) Data 0.156 (0.156) Loss 0.1513 (0.1513) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:00:19,399 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:19,399 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:20,287 - INFO - Epoch: [157][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.1395 (0.1455) Acc@1 94.531 (95.266) Acc@5 100.000 (99.923)
2025-08-28 06:00:22,067 - INFO - Epoch: [157][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1209 (0.1473) Acc@1 96.875 (95.184) Acc@5 100.000 (99.930)
2025-08-28 06:00:22,291 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:22,291 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:23,898 - INFO - Epoch: [157][300/391] Time 0.019 (0.019) Data 0.001 (0.003) Loss 0.1798 (0.1470) Acc@1 94.531 (95.154) Acc@5 100.000 (99.938)
2025-08-28 06:00:25,214 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:25,214 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:25,707 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3018 (0.3018) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:00:26,555 - INFO - Epoch 157:
2025-08-28 06:00:26,555 - INFO -   Train: acc1: 95.1140 | acc5: 99.9360 | loss: 0.1457 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:26,556 - INFO -   Val:   acc1: 90.2600 | acc5: 99.7100 | loss: 0.2944
2025-08-28 06:00:26,556 - INFO -   LR: 0.001000
2025-08-28 06:00:26,572 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-28 06:00:26,784 - INFO - Epoch: [158][0/391] Time 0.210 (0.210) Data 0.189 (0.189) Loss 0.1306 (0.1306) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:00:28,629 - INFO - Epoch: [158][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1448 (0.1517) Acc@1 95.312 (94.941) Acc@5 100.000 (99.938)
2025-08-28 06:00:29,388 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:29,388 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:30,441 - INFO - Epoch: [158][200/391] Time 0.031 (0.019) Data 0.011 (0.003) Loss 0.0997 (0.1465) Acc@1 97.656 (95.060) Acc@5 100.000 (99.922)
2025-08-28 06:00:32,250 - INFO - Epoch: [158][300/391] Time 0.019 (0.019) Data 0.007 (0.003) Loss 0.1263 (0.1452) Acc@1 94.531 (95.105) Acc@5 100.000 (99.935)
2025-08-28 06:00:32,278 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:32,279 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:34,086 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.3170 (0.3170) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:00:34,944 - INFO - Epoch 158:
2025-08-28 06:00:34,944 - INFO -   Train: acc1: 95.1480 | acc5: 99.9320 | loss: 0.1445 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:34,944 - INFO -   Val:   acc1: 90.4100 | acc5: 99.7000 | loss: 0.2959
2025-08-28 06:00:34,945 - INFO -   LR: 0.001000
2025-08-28 06:00:34,963 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-28 06:00:35,162 - INFO - Epoch: [159][0/391] Time 0.198 (0.198) Data 0.164 (0.164) Loss 0.1612 (0.1612) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 06:00:36,445 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:36,445 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:37,031 - INFO - Epoch: [159][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.1302 (0.1446) Acc@1 96.094 (95.166) Acc@5 100.000 (99.899)
2025-08-28 06:00:38,838 - INFO - Epoch: [159][200/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.0784 (0.1439) Acc@1 99.219 (95.141) Acc@5 100.000 (99.934)
2025-08-28 06:00:39,359 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:39,359 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:40,611 - INFO - Epoch: [159][300/391] Time 0.023 (0.019) Data 0.001 (0.002) Loss 0.1778 (0.1441) Acc@1 92.969 (95.118) Acc@5 100.000 (99.935)
2025-08-28 06:00:42,384 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3070 (0.3070) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:00:43,251 - INFO - Epoch 159:
2025-08-28 06:00:43,252 - INFO -   Train: acc1: 95.0560 | acc5: 99.9380 | loss: 0.1444 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:43,252 - INFO -   Val:   acc1: 90.3400 | acc5: 99.7200 | loss: 0.2950
2025-08-28 06:00:43,252 - INFO -   LR: 0.001000
2025-08-28 06:00:43,271 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-28 06:00:43,428 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:43,428 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:43,466 - INFO - Epoch: [160][0/391] Time 0.193 (0.193) Data 0.149 (0.149) Loss 0.0872 (0.0872) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 06:00:45,361 - INFO - Epoch: [160][100/391] Time 0.014 (0.021) Data 0.002 (0.003) Loss 0.0723 (0.1369) Acc@1 97.656 (95.436) Acc@5 100.000 (99.923)
2025-08-28 06:00:46,447 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:46,447 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:47,198 - INFO - Epoch: [160][200/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.1538 (0.1422) Acc@1 94.531 (95.165) Acc@5 100.000 (99.942)
2025-08-28 06:00:49,072 - INFO - Epoch: [160][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.1237 (0.1427) Acc@1 94.531 (95.235) Acc@5 100.000 (99.948)
2025-08-28 06:00:49,449 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:49,449 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:50,932 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.3094 (0.3094) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:00:51,775 - INFO - Epoch 160:
2025-08-28 06:00:51,776 - INFO -   Train: acc1: 95.2480 | acc5: 99.9480 | loss: 0.1423 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:00:51,776 - INFO -   Val:   acc1: 90.4500 | acc5: 99.7300 | loss: 0.2927
2025-08-28 06:00:51,776 - INFO -   LR: 0.001000
2025-08-28 06:00:51,826 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-28 06:00:52,040 - INFO - Epoch: [161][0/391] Time 0.213 (0.213) Data 0.197 (0.197) Loss 0.1646 (0.1646) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:00:53,562 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:53,562 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:53,762 - INFO - Epoch: [161][100/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.1379 (0.1399) Acc@1 95.312 (95.204) Acc@5 100.000 (99.954)
2025-08-28 06:00:55,565 - INFO - Epoch: [161][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.0816 (0.1407) Acc@1 97.656 (95.243) Acc@5 100.000 (99.934)
2025-08-28 06:00:56,522 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:00:56,523 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:00:57,526 - INFO - Epoch: [161][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.1464 (0.1427) Acc@1 97.656 (95.201) Acc@5 100.000 (99.930)
2025-08-28 06:00:59,294 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.3189 (0.3189) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:01:00,135 - INFO - Epoch 161:
2025-08-28 06:01:00,135 - INFO -   Train: acc1: 95.1480 | acc5: 99.9340 | loss: 0.1433 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:00,135 - INFO -   Val:   acc1: 90.3500 | acc5: 99.7200 | loss: 0.2963
2025-08-28 06:01:00,135 - INFO -   LR: 0.001000
2025-08-28 06:01:00,155 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-28 06:01:00,360 - INFO - Epoch: [162][0/391] Time 0.203 (0.203) Data 0.181 (0.181) Loss 0.1494 (0.1494) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:01:00,675 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:00,676 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:02,327 - INFO - Epoch: [162][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.1639 (0.1373) Acc@1 92.969 (95.475) Acc@5 100.000 (99.954)
2025-08-28 06:01:03,724 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:03,724 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:04,176 - INFO - Epoch: [162][200/391] Time 0.025 (0.020) Data 0.013 (0.003) Loss 0.1123 (0.1347) Acc@1 96.875 (95.538) Acc@5 100.000 (99.953)
2025-08-28 06:01:06,030 - INFO - Epoch: [162][300/391] Time 0.016 (0.019) Data 0.002 (0.003) Loss 0.1472 (0.1388) Acc@1 92.188 (95.325) Acc@5 100.000 (99.943)
2025-08-28 06:01:06,670 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:06,670 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:07,799 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3016 (0.3016) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:01:08,669 - INFO - Epoch 162:
2025-08-28 06:01:08,669 - INFO -   Train: acc1: 95.3400 | acc5: 99.9420 | loss: 0.1392 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:08,669 - INFO -   Val:   acc1: 90.2900 | acc5: 99.6800 | loss: 0.2956
2025-08-28 06:01:08,669 - INFO -   LR: 0.001000
2025-08-28 06:01:08,688 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-28 06:01:08,883 - INFO - Epoch: [163][0/391] Time 0.194 (0.194) Data 0.167 (0.167) Loss 0.1947 (0.1947) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:01:10,773 - INFO - Epoch: [163][100/391] Time 0.020 (0.021) Data 0.007 (0.004) Loss 0.0952 (0.1311) Acc@1 96.875 (95.939) Acc@5 100.000 (99.954)
2025-08-28 06:01:10,875 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:10,875 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:12,793 - INFO - Epoch: [163][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1017 (0.1328) Acc@1 97.656 (95.662) Acc@5 100.000 (99.957)
2025-08-28 06:01:13,924 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:13,925 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:14,593 - INFO - Epoch: [163][300/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1156 (0.1367) Acc@1 96.875 (95.549) Acc@5 100.000 (99.948)
2025-08-28 06:01:16,413 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3153 (0.3153) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:01:17,257 - INFO - Epoch 163:
2025-08-28 06:01:17,257 - INFO -   Train: acc1: 95.5400 | acc5: 99.9460 | loss: 0.1377 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:17,258 - INFO -   Val:   acc1: 90.2500 | acc5: 99.7200 | loss: 0.2945
2025-08-28 06:01:17,258 - INFO -   LR: 0.001000
2025-08-28 06:01:17,275 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-28 06:01:17,486 - INFO - Epoch: [164][0/391] Time 0.210 (0.210) Data 0.181 (0.181) Loss 0.1375 (0.1375) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:01:18,141 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:18,141 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:19,403 - INFO - Epoch: [164][100/391] Time 0.027 (0.021) Data 0.000 (0.004) Loss 0.1732 (0.1362) Acc@1 95.312 (95.374) Acc@5 99.219 (99.946)
2025-08-28 06:01:21,168 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:21,168 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:21,267 - INFO - Epoch: [164][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.1298 (0.1385) Acc@1 96.875 (95.375) Acc@5 100.000 (99.953)
2025-08-28 06:01:23,063 - INFO - Epoch: [164][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1778 (0.1369) Acc@1 93.750 (95.409) Acc@5 100.000 (99.948)
2025-08-28 06:01:24,047 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:24,048 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:24,889 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.3257 (0.3257) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:01:25,720 - INFO - Epoch 164:
2025-08-28 06:01:25,720 - INFO -   Train: acc1: 95.3980 | acc5: 99.9440 | loss: 0.1376 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:25,720 - INFO -   Val:   acc1: 90.2700 | acc5: 99.7300 | loss: 0.2966
2025-08-28 06:01:25,720 - INFO -   LR: 0.001000
2025-08-28 06:01:25,738 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-28 06:01:25,936 - INFO - Epoch: [165][0/391] Time 0.197 (0.197) Data 0.172 (0.172) Loss 0.1367 (0.1367) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:01:27,801 - INFO - Epoch: [165][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1281 (0.1375) Acc@1 94.531 (95.181) Acc@5 100.000 (99.938)
2025-08-28 06:01:28,284 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:28,285 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:29,715 - INFO - Epoch: [165][200/391] Time 0.026 (0.020) Data 0.000 (0.003) Loss 0.0983 (0.1363) Acc@1 96.875 (95.406) Acc@5 100.000 (99.926)
2025-08-28 06:01:31,244 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:31,244 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:31,577 - INFO - Epoch: [165][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1390 (0.1376) Acc@1 94.531 (95.403) Acc@5 100.000 (99.907)
2025-08-28 06:01:33,372 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3311 (0.3311) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:01:34,226 - INFO - Epoch 165:
2025-08-28 06:01:34,226 - INFO -   Train: acc1: 95.3940 | acc5: 99.9160 | loss: 0.1381 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:34,226 - INFO -   Val:   acc1: 90.4000 | acc5: 99.7200 | loss: 0.2965
2025-08-28 06:01:34,226 - INFO -   LR: 0.001000
2025-08-28 06:01:34,244 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-28 06:01:34,457 - INFO - Epoch: [166][0/391] Time 0.212 (0.212) Data 0.189 (0.189) Loss 0.1844 (0.1844) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:01:35,428 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:35,428 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:36,248 - INFO - Epoch: [166][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.0896 (0.1349) Acc@1 97.656 (95.529) Acc@5 100.000 (99.969)
2025-08-28 06:01:38,132 - INFO - Epoch: [166][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1512 (0.1377) Acc@1 95.312 (95.480) Acc@5 100.000 (99.938)
2025-08-28 06:01:38,370 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:38,370 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:40,096 - INFO - Epoch: [166][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.0827 (0.1368) Acc@1 97.656 (95.388) Acc@5 100.000 (99.933)
2025-08-28 06:01:41,451 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:41,451 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:41,912 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3078 (0.3078) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:01:42,780 - INFO - Epoch 166:
2025-08-28 06:01:42,780 - INFO -   Train: acc1: 95.3440 | acc5: 99.9300 | loss: 0.1384 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:42,780 - INFO -   Val:   acc1: 90.3800 | acc5: 99.6900 | loss: 0.2972
2025-08-28 06:01:42,780 - INFO -   LR: 0.001000
2025-08-28 06:01:42,800 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-28 06:01:43,012 - INFO - Epoch: [167][0/391] Time 0.211 (0.211) Data 0.174 (0.174) Loss 0.1161 (0.1161) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:01:44,939 - INFO - Epoch: [167][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.1408 (0.1368) Acc@1 96.094 (95.367) Acc@5 100.000 (99.938)
2025-08-28 06:01:45,681 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:45,682 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:46,734 - INFO - Epoch: [167][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.0806 (0.1357) Acc@1 97.656 (95.464) Acc@5 100.000 (99.926)
2025-08-28 06:01:48,600 - INFO - Epoch: [167][300/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.1183 (0.1361) Acc@1 95.312 (95.494) Acc@5 100.000 (99.930)
2025-08-28 06:01:48,652 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:48,653 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:50,412 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.3204 (0.3204) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:01:51,271 - INFO - Epoch 167:
2025-08-28 06:01:51,271 - INFO -   Train: acc1: 95.4820 | acc5: 99.9320 | loss: 0.1362 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:51,271 - INFO -   Val:   acc1: 90.3800 | acc5: 99.6900 | loss: 0.2984
2025-08-28 06:01:51,271 - INFO -   LR: 0.001000
2025-08-28 06:01:51,293 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-28 06:01:51,493 - INFO - Epoch: [168][0/391] Time 0.199 (0.199) Data 0.181 (0.181) Loss 0.1784 (0.1784) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:01:52,804 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:52,805 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:53,380 - INFO - Epoch: [168][100/391] Time 0.027 (0.021) Data 0.008 (0.004) Loss 0.1058 (0.1300) Acc@1 97.656 (95.722) Acc@5 100.000 (99.961)
2025-08-28 06:01:55,234 - INFO - Epoch: [168][200/391] Time 0.032 (0.020) Data 0.011 (0.003) Loss 0.1338 (0.1331) Acc@1 96.875 (95.581) Acc@5 99.219 (99.934)
2025-08-28 06:01:55,772 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:01:55,772 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:01:57,113 - INFO - Epoch: [168][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.1181 (0.1343) Acc@1 96.875 (95.582) Acc@5 100.000 (99.938)
2025-08-28 06:01:58,965 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.3332 (0.3332) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:01:59,792 - INFO - Epoch 168:
2025-08-28 06:01:59,792 - INFO -   Train: acc1: 95.4780 | acc5: 99.9380 | loss: 0.1357 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:01:59,792 - INFO -   Val:   acc1: 90.4500 | acc5: 99.7300 | loss: 0.2986
2025-08-28 06:01:59,792 - INFO -   LR: 0.001000
2025-08-28 06:01:59,811 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-28 06:01:59,995 - INFO - Epoch: [169][0/391] Time 0.183 (0.183) Data 0.165 (0.165) Loss 0.1536 (0.1536) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:02:00,001 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:00,001 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:01,904 - INFO - Epoch: [169][100/391] Time 0.022 (0.021) Data 0.000 (0.004) Loss 0.1360 (0.1280) Acc@1 96.875 (95.645) Acc@5 100.000 (99.961)
2025-08-28 06:02:03,017 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:03,017 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:03,721 - INFO - Epoch: [169][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.0907 (0.1325) Acc@1 97.656 (95.538) Acc@5 100.000 (99.953)
2025-08-28 06:02:05,521 - INFO - Epoch: [169][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1907 (0.1337) Acc@1 92.969 (95.445) Acc@5 100.000 (99.956)
2025-08-28 06:02:05,962 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:05,962 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:07,362 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3133 (0.3133) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:02:08,216 - INFO - Epoch 169:
2025-08-28 06:02:08,216 - INFO -   Train: acc1: 95.5240 | acc5: 99.9480 | loss: 0.1340 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:08,216 - INFO -   Val:   acc1: 90.3400 | acc5: 99.7200 | loss: 0.2984
2025-08-28 06:02:08,216 - INFO -   LR: 0.001000
2025-08-28 06:02:08,234 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-28 06:02:08,442 - INFO - Epoch: [170][0/391] Time 0.207 (0.207) Data 0.189 (0.189) Loss 0.1992 (0.1992) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:02:10,140 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:10,141 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:10,312 - INFO - Epoch: [170][100/391] Time 0.011 (0.021) Data 0.000 (0.005) Loss 0.1501 (0.1419) Acc@1 96.094 (95.173) Acc@5 100.000 (99.938)
2025-08-28 06:02:12,120 - INFO - Epoch: [170][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1257 (0.1374) Acc@1 95.312 (95.363) Acc@5 100.000 (99.946)
2025-08-28 06:02:12,986 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:12,986 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:13,919 - INFO - Epoch: [170][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.1195 (0.1375) Acc@1 95.312 (95.341) Acc@5 100.000 (99.940)
2025-08-28 06:02:15,669 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.3132 (0.3132) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:02:16,543 - INFO - Epoch 170:
2025-08-28 06:02:16,543 - INFO -   Train: acc1: 95.4100 | acc5: 99.9360 | loss: 0.1369 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:16,543 - INFO -   Val:   acc1: 90.1600 | acc5: 99.6900 | loss: 0.2966
2025-08-28 06:02:16,543 - INFO -   LR: 0.001000
2025-08-28 06:02:16,597 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-28 06:02:16,791 - INFO - Epoch: [171][0/391] Time 0.193 (0.193) Data 0.165 (0.165) Loss 0.1097 (0.1097) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:02:17,165 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:17,165 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:18,635 - INFO - Epoch: [171][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1331 (0.1301) Acc@1 94.531 (95.738) Acc@5 100.000 (99.946)
2025-08-28 06:02:20,138 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:20,138 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:20,577 - INFO - Epoch: [171][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1995 (0.1316) Acc@1 92.969 (95.693) Acc@5 100.000 (99.926)
2025-08-28 06:02:22,411 - INFO - Epoch: [171][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.0920 (0.1305) Acc@1 97.656 (95.720) Acc@5 100.000 (99.933)
2025-08-28 06:02:23,130 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:23,130 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:24,241 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3314 (0.3314) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:02:25,120 - INFO - Epoch 171:
2025-08-28 06:02:25,120 - INFO -   Train: acc1: 95.6640 | acc5: 99.9340 | loss: 0.1321 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:25,120 - INFO -   Val:   acc1: 90.1300 | acc5: 99.6500 | loss: 0.2992
2025-08-28 06:02:25,121 - INFO -   LR: 0.001000
2025-08-28 06:02:25,140 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-28 06:02:25,329 - INFO - Epoch: [172][0/391] Time 0.189 (0.189) Data 0.168 (0.168) Loss 0.1405 (0.1405) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:02:27,205 - INFO - Epoch: [172][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1132 (0.1252) Acc@1 95.312 (95.738) Acc@5 100.000 (99.977)
2025-08-28 06:02:27,357 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:27,357 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:29,037 - INFO - Epoch: [172][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.0653 (0.1260) Acc@1 98.438 (95.829) Acc@5 100.000 (99.969)
2025-08-28 06:02:30,259 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:30,259 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:30,873 - INFO - Epoch: [172][300/391] Time 0.031 (0.019) Data 0.000 (0.003) Loss 0.1387 (0.1305) Acc@1 94.531 (95.671) Acc@5 100.000 (99.961)
2025-08-28 06:02:32,706 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3506 (0.3506) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:02:33,569 - INFO - Epoch 172:
2025-08-28 06:02:33,569 - INFO -   Train: acc1: 95.6860 | acc5: 99.9600 | loss: 0.1302 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:33,569 - INFO -   Val:   acc1: 90.2600 | acc5: 99.6800 | loss: 0.3009
2025-08-28 06:02:33,569 - INFO -   LR: 0.001000
2025-08-28 06:02:33,588 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-28 06:02:33,787 - INFO - Epoch: [173][0/391] Time 0.197 (0.197) Data 0.174 (0.174) Loss 0.1549 (0.1549) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:02:34,530 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:34,530 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:35,718 - INFO - Epoch: [173][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.1852 (0.1277) Acc@1 93.750 (95.684) Acc@5 99.219 (99.938)
2025-08-28 06:02:37,497 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:37,497 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:37,567 - INFO - Epoch: [173][200/391] Time 0.017 (0.020) Data 0.007 (0.003) Loss 0.1180 (0.1292) Acc@1 95.312 (95.674) Acc@5 100.000 (99.926)
2025-08-28 06:02:39,491 - INFO - Epoch: [173][300/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.1226 (0.1315) Acc@1 96.875 (95.637) Acc@5 100.000 (99.933)
2025-08-28 06:02:40,537 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:40,537 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:41,285 - INFO - Test: [0/79] Time 0.164 (0.164) Loss 0.3567 (0.3567) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:02:42,155 - INFO - Epoch 173:
2025-08-28 06:02:42,155 - INFO -   Train: acc1: 95.5620 | acc5: 99.9260 | loss: 0.1331 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:42,155 - INFO -   Val:   acc1: 90.1400 | acc5: 99.6900 | loss: 0.3017
2025-08-28 06:02:42,155 - INFO -   LR: 0.001000
2025-08-28 06:02:42,174 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-28 06:02:42,377 - INFO - Epoch: [174][0/391] Time 0.203 (0.203) Data 0.185 (0.185) Loss 0.1024 (0.1024) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:02:44,314 - INFO - Epoch: [174][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.1191 (0.1275) Acc@1 94.531 (95.676) Acc@5 100.000 (99.946)
2025-08-28 06:02:44,806 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:44,806 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:46,114 - INFO - Epoch: [174][200/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.1344 (0.1287) Acc@1 93.750 (95.608) Acc@5 100.000 (99.953)
2025-08-28 06:02:47,685 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:47,685 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:47,955 - INFO - Epoch: [174][300/391] Time 0.035 (0.019) Data 0.022 (0.003) Loss 0.0961 (0.1298) Acc@1 96.094 (95.567) Acc@5 100.000 (99.958)
2025-08-28 06:02:49,759 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.3450 (0.3450) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:02:50,606 - INFO - Epoch 174:
2025-08-28 06:02:50,606 - INFO -   Train: acc1: 95.5460 | acc5: 99.9540 | loss: 0.1309 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:50,606 - INFO -   Val:   acc1: 90.4700 | acc5: 99.7300 | loss: 0.2993
2025-08-28 06:02:50,606 - INFO -   LR: 0.001000
2025-08-28 06:02:50,662 - INFO - Checkpoint saved: epoch=174, metric=90.4700
2025-08-28 06:02:50,694 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-28 06:02:50,875 - INFO - Epoch: [175][0/391] Time 0.181 (0.181) Data 0.157 (0.157) Loss 0.1204 (0.1204) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:02:51,892 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:51,892 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:52,720 - INFO - Epoch: [175][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1088 (0.1295) Acc@1 95.312 (95.661) Acc@5 100.000 (99.961)
2025-08-28 06:02:54,684 - INFO - Epoch: [175][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1100 (0.1300) Acc@1 94.531 (95.620) Acc@5 100.000 (99.938)
2025-08-28 06:02:54,950 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:54,950 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:56,506 - INFO - Epoch: [175][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.1476 (0.1315) Acc@1 92.969 (95.543) Acc@5 100.000 (99.938)
2025-08-28 06:02:57,872 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:02:57,872 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:02:58,331 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3378 (0.3378) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:02:59,172 - INFO - Epoch 175:
2025-08-28 06:02:59,173 - INFO -   Train: acc1: 95.5220 | acc5: 99.9360 | loss: 0.1319 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:02:59,173 - INFO -   Val:   acc1: 90.2300 | acc5: 99.7400 | loss: 0.3026
2025-08-28 06:02:59,173 - INFO -   LR: 0.001000
2025-08-28 06:02:59,194 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-28 06:02:59,405 - INFO - Epoch: [176][0/391] Time 0.210 (0.210) Data 0.166 (0.166) Loss 0.1277 (0.1277) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:03:01,354 - INFO - Epoch: [176][100/391] Time 0.029 (0.021) Data 0.012 (0.003) Loss 0.1358 (0.1263) Acc@1 95.312 (95.947) Acc@5 100.000 (99.946)
2025-08-28 06:03:02,165 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:02,165 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:03,267 - INFO - Epoch: [176][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1169 (0.1265) Acc@1 96.094 (95.826) Acc@5 100.000 (99.957)
2025-08-28 06:03:05,018 - INFO - Epoch: [176][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1743 (0.1301) Acc@1 93.750 (95.673) Acc@5 100.000 (99.966)
2025-08-28 06:03:05,079 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:05,080 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:06,822 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3439 (0.3439) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:03:07,670 - INFO - Epoch 176:
2025-08-28 06:03:07,670 - INFO -   Train: acc1: 95.6600 | acc5: 99.9600 | loss: 0.1300 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:07,670 - INFO -   Val:   acc1: 90.3600 | acc5: 99.7000 | loss: 0.2995
2025-08-28 06:03:07,670 - INFO -   LR: 0.001000
2025-08-28 06:03:07,688 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-28 06:03:07,885 - INFO - Epoch: [177][0/391] Time 0.196 (0.196) Data 0.179 (0.179) Loss 0.0794 (0.0794) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:03:09,227 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:09,227 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:09,773 - INFO - Epoch: [177][100/391] Time 0.016 (0.021) Data 0.000 (0.005) Loss 0.0786 (0.1298) Acc@1 98.438 (95.692) Acc@5 100.000 (99.915)
2025-08-28 06:03:11,571 - INFO - Epoch: [177][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.0634 (0.1296) Acc@1 99.219 (95.635) Acc@5 100.000 (99.926)
2025-08-28 06:03:12,186 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:12,187 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:13,473 - INFO - Epoch: [177][300/391] Time 0.035 (0.019) Data 0.018 (0.004) Loss 0.1347 (0.1309) Acc@1 94.531 (95.585) Acc@5 100.000 (99.938)
2025-08-28 06:03:15,284 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3347 (0.3347) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:03:16,132 - INFO - Epoch 177:
2025-08-28 06:03:16,132 - INFO -   Train: acc1: 95.5900 | acc5: 99.9440 | loss: 0.1303 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:16,132 - INFO -   Val:   acc1: 90.3500 | acc5: 99.7100 | loss: 0.3018
2025-08-28 06:03:16,132 - INFO -   LR: 0.001000
2025-08-28 06:03:16,151 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-28 06:03:16,340 - INFO - Epoch: [178][0/391] Time 0.189 (0.189) Data 0.157 (0.157) Loss 0.0873 (0.0873) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:03:16,372 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:16,372 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:18,096 - INFO - Epoch: [178][100/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.0893 (0.1288) Acc@1 97.656 (95.560) Acc@5 100.000 (99.930)
2025-08-28 06:03:19,197 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:19,197 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:19,886 - INFO - Epoch: [178][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.1249 (0.1326) Acc@1 96.875 (95.425) Acc@5 99.219 (99.946)
2025-08-28 06:03:21,684 - INFO - Epoch: [178][300/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.1065 (0.1305) Acc@1 98.438 (95.595) Acc@5 100.000 (99.958)
2025-08-28 06:03:22,033 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:22,033 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:23,424 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.3329 (0.3329) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:03:24,256 - INFO - Epoch 178:
2025-08-28 06:03:24,256 - INFO -   Train: acc1: 95.6640 | acc5: 99.9500 | loss: 0.1290 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:24,256 - INFO -   Val:   acc1: 90.0500 | acc5: 99.7000 | loss: 0.3055
2025-08-28 06:03:24,256 - INFO -   LR: 0.001000
2025-08-28 06:03:24,276 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-28 06:03:24,481 - INFO - Epoch: [179][0/391] Time 0.205 (0.205) Data 0.182 (0.182) Loss 0.0810 (0.0810) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 06:03:26,086 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:26,087 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:26,246 - INFO - Epoch: [179][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.1135 (0.1247) Acc@1 95.312 (95.893) Acc@5 100.000 (99.961)
2025-08-28 06:03:28,025 - INFO - Epoch: [179][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1584 (0.1241) Acc@1 95.312 (95.923) Acc@5 100.000 (99.957)
2025-08-28 06:03:28,938 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:28,938 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:29,821 - INFO - Epoch: [179][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1423 (0.1252) Acc@1 94.531 (95.832) Acc@5 100.000 (99.964)
2025-08-28 06:03:31,654 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3543 (0.3543) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:03:32,505 - INFO - Epoch 179:
2025-08-28 06:03:32,505 - INFO -   Train: acc1: 95.8100 | acc5: 99.9600 | loss: 0.1261 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:32,505 - INFO -   Val:   acc1: 90.1800 | acc5: 99.7200 | loss: 0.3028
2025-08-28 06:03:32,505 - INFO -   LR: 0.001000
2025-08-28 06:03:32,527 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-28 06:03:32,731 - INFO - Epoch: [180][0/391] Time 0.204 (0.204) Data 0.176 (0.176) Loss 0.2061 (0.2061) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 06:03:33,078 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:33,078 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:34,577 - INFO - Epoch: [180][100/391] Time 0.025 (0.020) Data 0.000 (0.004) Loss 0.1263 (0.1240) Acc@1 95.312 (96.016) Acc@5 100.000 (99.946)
2025-08-28 06:03:36,034 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:36,034 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:36,432 - INFO - Epoch: [180][200/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.1325 (0.1254) Acc@1 96.875 (95.931) Acc@5 100.000 (99.926)
2025-08-28 06:03:38,313 - INFO - Epoch: [180][300/391] Time 0.021 (0.019) Data 0.000 (0.002) Loss 0.2051 (0.1259) Acc@1 92.188 (95.863) Acc@5 100.000 (99.940)
2025-08-28 06:03:39,054 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:39,055 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:40,139 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3493 (0.3493) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:03:40,974 - INFO - Epoch 180:
2025-08-28 06:03:40,974 - INFO -   Train: acc1: 95.8040 | acc5: 99.9400 | loss: 0.1264 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:40,974 - INFO -   Val:   acc1: 90.4400 | acc5: 99.7300 | loss: 0.3034
2025-08-28 06:03:40,974 - INFO -   LR: 0.001000
2025-08-28 06:03:41,031 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-28 06:03:41,211 - INFO - Epoch: [181][0/391] Time 0.179 (0.179) Data 0.163 (0.163) Loss 0.1026 (0.1026) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:03:43,072 - INFO - Epoch: [181][100/391] Time 0.030 (0.020) Data 0.007 (0.005) Loss 0.1534 (0.1305) Acc@1 94.531 (95.622) Acc@5 100.000 (99.977)
2025-08-28 06:03:43,256 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:43,256 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:44,990 - INFO - Epoch: [181][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.1229 (0.1267) Acc@1 96.094 (95.783) Acc@5 100.000 (99.961)
2025-08-28 06:03:46,224 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:46,224 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:46,762 - INFO - Epoch: [181][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1691 (0.1278) Acc@1 94.531 (95.782) Acc@5 100.000 (99.958)
2025-08-28 06:03:48,628 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3353 (0.3353) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:03:49,496 - INFO - Epoch 181:
2025-08-28 06:03:49,496 - INFO -   Train: acc1: 95.7580 | acc5: 99.9540 | loss: 0.1282 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:49,496 - INFO -   Val:   acc1: 90.2600 | acc5: 99.7100 | loss: 0.3024
2025-08-28 06:03:49,496 - INFO -   LR: 0.001000
2025-08-28 06:03:49,516 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-28 06:03:49,717 - INFO - Epoch: [182][0/391] Time 0.200 (0.200) Data 0.183 (0.183) Loss 0.0832 (0.0832) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-28 06:03:50,420 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:50,421 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:51,638 - INFO - Epoch: [182][100/391] Time 0.014 (0.021) Data 0.002 (0.004) Loss 0.0678 (0.1224) Acc@1 98.438 (96.047) Acc@5 100.000 (99.969)
2025-08-28 06:03:53,425 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:53,425 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:53,470 - INFO - Epoch: [182][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1082 (0.1240) Acc@1 95.312 (95.888) Acc@5 100.000 (99.973)
2025-08-28 06:03:55,308 - INFO - Epoch: [182][300/391] Time 0.018 (0.019) Data 0.007 (0.003) Loss 0.1100 (0.1251) Acc@1 96.875 (95.793) Acc@5 100.000 (99.958)
2025-08-28 06:03:56,375 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:03:56,375 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:03:57,170 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3129 (0.3129) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:03:58,032 - INFO - Epoch 182:
2025-08-28 06:03:58,032 - INFO -   Train: acc1: 95.7900 | acc5: 99.9600 | loss: 0.1254 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:03:58,032 - INFO -   Val:   acc1: 90.2100 | acc5: 99.6500 | loss: 0.3074
2025-08-28 06:03:58,032 - INFO -   LR: 0.001000
2025-08-28 06:03:58,052 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-28 06:03:58,216 - INFO - Epoch: [183][0/391] Time 0.163 (0.163) Data 0.145 (0.145) Loss 0.0977 (0.0977) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:04:00,099 - INFO - Epoch: [183][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.1460 (0.1287) Acc@1 94.531 (95.684) Acc@5 100.000 (99.954)
2025-08-28 06:04:00,537 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:00,537 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:01,898 - INFO - Epoch: [183][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0891 (0.1261) Acc@1 97.656 (95.833) Acc@5 100.000 (99.965)
2025-08-28 06:04:03,420 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:03,420 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:03,669 - INFO - Epoch: [183][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1205 (0.1280) Acc@1 94.531 (95.684) Acc@5 100.000 (99.948)
2025-08-28 06:04:05,455 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3554 (0.3554) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:04:06,336 - INFO - Epoch 183:
2025-08-28 06:04:06,337 - INFO -   Train: acc1: 95.7760 | acc5: 99.9480 | loss: 0.1265 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:06,337 - INFO -   Val:   acc1: 90.2600 | acc5: 99.7200 | loss: 0.3038
2025-08-28 06:04:06,337 - INFO -   LR: 0.001000
2025-08-28 06:04:06,359 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-28 06:04:06,569 - INFO - Epoch: [184][0/391] Time 0.209 (0.209) Data 0.185 (0.185) Loss 0.1334 (0.1334) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 06:04:07,619 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:07,619 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:08,438 - INFO - Epoch: [184][100/391] Time 0.019 (0.021) Data 0.000 (0.005) Loss 0.1577 (0.1221) Acc@1 96.094 (95.885) Acc@5 100.000 (99.954)
2025-08-28 06:04:10,340 - INFO - Epoch: [184][200/391] Time 0.030 (0.020) Data 0.000 (0.004) Loss 0.1378 (0.1264) Acc@1 96.094 (95.740) Acc@5 100.000 (99.934)
2025-08-28 06:04:10,574 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:10,574 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:12,133 - INFO - Epoch: [184][300/391] Time 0.031 (0.019) Data 0.019 (0.003) Loss 0.1280 (0.1258) Acc@1 95.312 (95.808) Acc@5 100.000 (99.948)
2025-08-28 06:04:13,538 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:13,538 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:13,998 - INFO - Test: [0/79] Time 0.170 (0.170) Loss 0.3563 (0.3563) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:04:14,857 - INFO - Epoch 184:
2025-08-28 06:04:14,858 - INFO -   Train: acc1: 95.7580 | acc5: 99.9400 | loss: 0.1262 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:14,858 - INFO -   Val:   acc1: 90.3000 | acc5: 99.7300 | loss: 0.3040
2025-08-28 06:04:14,858 - INFO -   LR: 0.001000
2025-08-28 06:04:14,877 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-28 06:04:15,079 - INFO - Epoch: [185][0/391] Time 0.201 (0.201) Data 0.169 (0.169) Loss 0.1850 (0.1850) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 06:04:16,904 - INFO - Epoch: [185][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.0933 (0.1262) Acc@1 96.094 (95.908) Acc@5 100.000 (99.938)
2025-08-28 06:04:17,696 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:17,696 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:18,771 - INFO - Epoch: [185][200/391] Time 0.023 (0.019) Data 0.010 (0.005) Loss 0.1296 (0.1241) Acc@1 95.312 (95.864) Acc@5 100.000 (99.953)
2025-08-28 06:04:20,656 - INFO - Epoch: [185][300/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.1458 (0.1257) Acc@1 94.531 (95.842) Acc@5 100.000 (99.940)
2025-08-28 06:04:20,712 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:20,712 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:22,439 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.3423 (0.3423) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:04:23,327 - INFO - Epoch 185:
2025-08-28 06:04:23,327 - INFO -   Train: acc1: 95.8260 | acc5: 99.9520 | loss: 0.1270 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:23,327 - INFO -   Val:   acc1: 90.3600 | acc5: 99.6500 | loss: 0.3060
2025-08-28 06:04:23,328 - INFO -   LR: 0.001000
2025-08-28 06:04:23,346 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-28 06:04:23,565 - INFO - Epoch: [186][0/391] Time 0.218 (0.218) Data 0.194 (0.194) Loss 0.0896 (0.0896) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:04:24,952 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:24,952 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:25,441 - INFO - Epoch: [186][100/391] Time 0.015 (0.021) Data 0.000 (0.005) Loss 0.1766 (0.1263) Acc@1 92.969 (95.490) Acc@5 100.000 (99.969)
2025-08-28 06:04:27,227 - INFO - Epoch: [186][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1051 (0.1268) Acc@1 96.875 (95.705) Acc@5 99.219 (99.953)
2025-08-28 06:04:27,809 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:27,809 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:29,129 - INFO - Epoch: [186][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1056 (0.1259) Acc@1 95.312 (95.728) Acc@5 100.000 (99.951)
2025-08-28 06:04:30,938 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.3037 (0.3037) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:04:31,793 - INFO - Epoch 186:
2025-08-28 06:04:31,793 - INFO -   Train: acc1: 95.6860 | acc5: 99.9500 | loss: 0.1269 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:31,793 - INFO -   Val:   acc1: 90.2700 | acc5: 99.6700 | loss: 0.3046
2025-08-28 06:04:31,793 - INFO -   LR: 0.001000
2025-08-28 06:04:31,811 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-28 06:04:31,990 - INFO - Epoch: [187][0/391] Time 0.178 (0.178) Data 0.159 (0.159) Loss 0.1301 (0.1301) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:04:32,070 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:32,070 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:33,907 - INFO - Epoch: [187][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.0994 (0.1197) Acc@1 96.875 (95.985) Acc@5 100.000 (99.946)
2025-08-28 06:04:35,081 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:35,082 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:35,770 - INFO - Epoch: [187][200/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1153 (0.1239) Acc@1 96.875 (95.888) Acc@5 100.000 (99.949)
2025-08-28 06:04:37,600 - INFO - Epoch: [187][300/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.1166 (0.1259) Acc@1 96.094 (95.800) Acc@5 100.000 (99.951)
2025-08-28 06:04:38,058 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:38,058 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:39,406 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3333 (0.3333) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:04:40,403 - INFO - Epoch 187:
2025-08-28 06:04:40,404 - INFO -   Train: acc1: 95.8260 | acc5: 99.9500 | loss: 0.1253 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:40,404 - INFO -   Val:   acc1: 90.2200 | acc5: 99.7000 | loss: 0.3038
2025-08-28 06:04:40,404 - INFO -   LR: 0.001000
2025-08-28 06:04:40,424 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-28 06:04:40,624 - INFO - Epoch: [188][0/391] Time 0.199 (0.199) Data 0.173 (0.173) Loss 0.1049 (0.1049) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:04:42,351 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:42,351 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:42,560 - INFO - Epoch: [188][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.1471 (0.1248) Acc@1 92.969 (95.916) Acc@5 100.000 (99.961)
2025-08-28 06:04:44,363 - INFO - Epoch: [188][200/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.0918 (0.1246) Acc@1 96.094 (95.876) Acc@5 100.000 (99.961)
2025-08-28 06:04:45,248 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:45,249 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:46,102 - INFO - Epoch: [188][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.1354 (0.1245) Acc@1 94.531 (95.850) Acc@5 100.000 (99.951)
2025-08-28 06:04:47,956 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.3523 (0.3523) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 06:04:48,799 - INFO - Epoch 188:
2025-08-28 06:04:48,799 - INFO -   Train: acc1: 95.8680 | acc5: 99.9480 | loss: 0.1246 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:48,799 - INFO -   Val:   acc1: 90.5200 | acc5: 99.7000 | loss: 0.3043
2025-08-28 06:04:48,799 - INFO -   LR: 0.001000
2025-08-28 06:04:48,856 - INFO - Checkpoint saved: epoch=188, metric=90.5200
2025-08-28 06:04:48,891 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-28 06:04:49,066 - INFO - Epoch: [189][0/391] Time 0.174 (0.174) Data 0.158 (0.158) Loss 0.1179 (0.1179) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:04:49,448 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:49,448 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:50,919 - INFO - Epoch: [189][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1208 (0.1240) Acc@1 96.094 (95.777) Acc@5 100.000 (99.946)
2025-08-28 06:04:52,432 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:52,432 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:52,843 - INFO - Epoch: [189][200/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.1400 (0.1237) Acc@1 93.750 (95.752) Acc@5 100.000 (99.946)
2025-08-28 06:04:54,716 - INFO - Epoch: [189][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.1356 (0.1216) Acc@1 95.312 (95.858) Acc@5 100.000 (99.945)
2025-08-28 06:04:55,573 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:55,573 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:04:56,616 - INFO - Test: [0/79] Time 0.174 (0.174) Loss 0.3470 (0.3470) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:04:57,482 - INFO - Epoch 189:
2025-08-28 06:04:57,482 - INFO -   Train: acc1: 95.8160 | acc5: 99.9440 | loss: 0.1232 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:04:57,482 - INFO -   Val:   acc1: 90.4300 | acc5: 99.6700 | loss: 0.3006
2025-08-28 06:04:57,482 - INFO -   LR: 0.001000
2025-08-28 06:04:57,504 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-28 06:04:57,700 - INFO - Epoch: [190][0/391] Time 0.195 (0.195) Data 0.169 (0.169) Loss 0.1055 (0.1055) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:04:59,635 - INFO - Epoch: [190][100/391] Time 0.033 (0.021) Data 0.021 (0.004) Loss 0.1457 (0.1330) Acc@1 96.094 (95.483) Acc@5 100.000 (99.938)
2025-08-28 06:04:59,807 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:04:59,807 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:01,514 - INFO - Epoch: [190][200/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.1454 (0.1316) Acc@1 96.094 (95.561) Acc@5 100.000 (99.946)
2025-08-28 06:05:02,713 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:02,713 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:03,290 - INFO - Epoch: [190][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1249 (0.1296) Acc@1 96.875 (95.601) Acc@5 99.219 (99.948)
2025-08-28 06:05:05,114 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.3688 (0.3688) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:05:05,942 - INFO - Epoch 190:
2025-08-28 06:05:05,942 - INFO -   Train: acc1: 95.6680 | acc5: 99.9440 | loss: 0.1286 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:05,942 - INFO -   Val:   acc1: 90.2800 | acc5: 99.7100 | loss: 0.3050
2025-08-28 06:05:05,942 - INFO -   LR: 0.001000
2025-08-28 06:05:05,999 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-28 06:05:06,202 - INFO - Epoch: [191][0/391] Time 0.202 (0.202) Data 0.176 (0.176) Loss 0.1778 (0.1778) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:05:06,887 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:06,887 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:08,075 - INFO - Epoch: [191][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.0909 (0.1227) Acc@1 96.094 (96.016) Acc@5 100.000 (99.954)
2025-08-28 06:05:09,924 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:09,925 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:09,967 - INFO - Epoch: [191][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1080 (0.1220) Acc@1 94.531 (95.989) Acc@5 100.000 (99.946)
2025-08-28 06:05:11,744 - INFO - Epoch: [191][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.1517 (0.1227) Acc@1 96.094 (95.912) Acc@5 100.000 (99.943)
2025-08-28 06:05:12,777 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:12,777 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:13,558 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.3610 (0.3610) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:05:14,372 - INFO - Epoch 191:
2025-08-28 06:05:14,372 - INFO -   Train: acc1: 95.8520 | acc5: 99.9400 | loss: 0.1244 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:14,373 - INFO -   Val:   acc1: 90.2400 | acc5: 99.6900 | loss: 0.3070
2025-08-28 06:05:14,373 - INFO -   LR: 0.001000
2025-08-28 06:05:14,393 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-28 06:05:14,586 - INFO - Epoch: [192][0/391] Time 0.192 (0.192) Data 0.167 (0.167) Loss 0.0793 (0.0793) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 06:05:16,505 - INFO - Epoch: [192][100/391] Time 0.026 (0.021) Data 0.007 (0.003) Loss 0.1085 (0.1214) Acc@1 96.094 (96.140) Acc@5 100.000 (99.977)
2025-08-28 06:05:16,976 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:16,976 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:18,356 - INFO - Epoch: [192][200/391] Time 0.029 (0.020) Data 0.009 (0.003) Loss 0.1520 (0.1204) Acc@1 93.750 (96.090) Acc@5 100.000 (99.981)
2025-08-28 06:05:19,977 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:19,977 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:20,215 - INFO - Epoch: [192][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.1149 (0.1218) Acc@1 95.312 (96.021) Acc@5 100.000 (99.961)
2025-08-28 06:05:21,978 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3527 (0.3527) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:05:22,829 - INFO - Epoch 192:
2025-08-28 06:05:22,829 - INFO -   Train: acc1: 95.8580 | acc5: 99.9460 | loss: 0.1246 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:22,830 - INFO -   Val:   acc1: 90.4000 | acc5: 99.7000 | loss: 0.3074
2025-08-28 06:05:22,830 - INFO -   LR: 0.001000
2025-08-28 06:05:22,851 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-28 06:05:23,073 - INFO - Epoch: [193][0/391] Time 0.221 (0.221) Data 0.200 (0.200) Loss 0.1877 (0.1877) Acc@1 94.531 (94.531) Acc@5 99.219 (99.219)
2025-08-28 06:05:24,092 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:24,093 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:24,952 - INFO - Epoch: [193][100/391] Time 0.023 (0.021) Data 0.000 (0.006) Loss 0.1276 (0.1197) Acc@1 96.094 (95.939) Acc@5 100.000 (99.946)
2025-08-28 06:05:26,791 - INFO - Epoch: [193][200/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1140 (0.1223) Acc@1 96.875 (95.903) Acc@5 100.000 (99.953)
2025-08-28 06:05:27,124 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:27,125 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:28,675 - INFO - Epoch: [193][300/391] Time 0.031 (0.019) Data 0.000 (0.004) Loss 0.1685 (0.1230) Acc@1 95.312 (95.878) Acc@5 100.000 (99.953)
2025-08-28 06:05:30,096 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:30,096 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:30,495 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3858 (0.3858) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:05:31,355 - INFO - Epoch 193:
2025-08-28 06:05:31,355 - INFO -   Train: acc1: 95.8800 | acc5: 99.9460 | loss: 0.1232 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:31,355 - INFO -   Val:   acc1: 90.4600 | acc5: 99.6900 | loss: 0.3069
2025-08-28 06:05:31,355 - INFO -   LR: 0.001000
2025-08-28 06:05:31,375 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-28 06:05:31,546 - INFO - Epoch: [194][0/391] Time 0.170 (0.170) Data 0.154 (0.154) Loss 0.0847 (0.0847) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:05:33,420 - INFO - Epoch: [194][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1209 (0.1262) Acc@1 96.094 (95.653) Acc@5 100.000 (99.954)
2025-08-28 06:05:34,235 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:34,235 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:35,251 - INFO - Epoch: [194][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1343 (0.1245) Acc@1 96.875 (95.794) Acc@5 100.000 (99.938)
2025-08-28 06:05:37,090 - INFO - Epoch: [194][300/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.1058 (0.1230) Acc@1 95.312 (95.884) Acc@5 100.000 (99.933)
2025-08-28 06:05:37,180 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:37,181 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:38,999 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.3517 (0.3517) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:05:39,807 - INFO - Epoch 194:
2025-08-28 06:05:39,807 - INFO -   Train: acc1: 95.9200 | acc5: 99.9400 | loss: 0.1220 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:39,807 - INFO -   Val:   acc1: 90.2600 | acc5: 99.7300 | loss: 0.3082
2025-08-28 06:05:39,807 - INFO -   LR: 0.001000
2025-08-28 06:05:39,828 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-28 06:05:40,048 - INFO - Epoch: [195][0/391] Time 0.219 (0.219) Data 0.168 (0.168) Loss 0.1142 (0.1142) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:05:41,484 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:41,484 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:41,926 - INFO - Epoch: [195][100/391] Time 0.012 (0.021) Data 0.001 (0.004) Loss 0.0517 (0.1227) Acc@1 99.219 (95.746) Acc@5 100.000 (99.969)
2025-08-28 06:05:43,863 - INFO - Epoch: [195][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1663 (0.1219) Acc@1 94.531 (95.907) Acc@5 99.219 (99.965)
2025-08-28 06:05:44,481 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:44,481 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:45,688 - INFO - Epoch: [195][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1294 (0.1236) Acc@1 95.312 (95.855) Acc@5 100.000 (99.953)
2025-08-28 06:05:47,564 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3798 (0.3798) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:05:48,459 - INFO - Epoch 195:
2025-08-28 06:05:48,459 - INFO -   Train: acc1: 95.9100 | acc5: 99.9520 | loss: 0.1230 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:48,459 - INFO -   Val:   acc1: 90.1600 | acc5: 99.7200 | loss: 0.3089
2025-08-28 06:05:48,460 - INFO -   LR: 0.001000
2025-08-28 06:05:48,479 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-28 06:05:48,648 - INFO - Epoch: [196][0/391] Time 0.168 (0.168) Data 0.139 (0.139) Loss 0.1664 (0.1664) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-28 06:05:48,761 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:48,761 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:50,572 - INFO - Epoch: [196][100/391] Time 0.035 (0.021) Data 0.010 (0.004) Loss 0.1348 (0.1201) Acc@1 96.094 (95.885) Acc@5 100.000 (99.954)
2025-08-28 06:05:51,688 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:51,688 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:52,369 - INFO - Epoch: [196][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.0885 (0.1212) Acc@1 97.656 (95.783) Acc@5 100.000 (99.957)
2025-08-28 06:05:54,233 - INFO - Epoch: [196][300/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.1240 (0.1209) Acc@1 96.875 (95.873) Acc@5 100.000 (99.969)
2025-08-28 06:05:54,651 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:54,651 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:56,068 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.4039 (0.4039) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:05:56,929 - INFO - Epoch 196:
2025-08-28 06:05:56,929 - INFO -   Train: acc1: 95.8340 | acc5: 99.9640 | loss: 0.1225 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:05:56,929 - INFO -   Val:   acc1: 90.0600 | acc5: 99.6800 | loss: 0.3099
2025-08-28 06:05:56,929 - INFO -   LR: 0.001000
2025-08-28 06:05:56,949 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-28 06:05:57,156 - INFO - Epoch: [197][0/391] Time 0.206 (0.206) Data 0.177 (0.177) Loss 0.1177 (0.1177) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:05:58,811 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:05:58,811 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:05:58,965 - INFO - Epoch: [197][100/391] Time 0.034 (0.020) Data 0.007 (0.004) Loss 0.1748 (0.1266) Acc@1 96.094 (95.692) Acc@5 100.000 (99.923)
2025-08-28 06:06:00,768 - INFO - Epoch: [197][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1497 (0.1250) Acc@1 96.094 (95.810) Acc@5 100.000 (99.938)
2025-08-28 06:06:01,719 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:06:01,719 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:02,625 - INFO - Epoch: [197][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.0953 (0.1229) Acc@1 96.875 (95.912) Acc@5 100.000 (99.930)
2025-08-28 06:06:04,407 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3684 (0.3684) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:06:05,269 - INFO - Epoch 197:
2025-08-28 06:06:05,269 - INFO -   Train: acc1: 95.9740 | acc5: 99.9380 | loss: 0.1215 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:06:05,269 - INFO -   Val:   acc1: 90.2500 | acc5: 99.6900 | loss: 0.3038
2025-08-28 06:06:05,269 - INFO -   LR: 0.001000
2025-08-28 06:06:05,292 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-28 06:06:05,496 - INFO - Epoch: [198][0/391] Time 0.203 (0.203) Data 0.168 (0.168) Loss 0.1294 (0.1294) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:06:05,867 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:06:05,867 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:07,317 - INFO - Epoch: [198][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.1012 (0.1211) Acc@1 97.656 (95.993) Acc@5 100.000 (99.946)
2025-08-28 06:06:08,841 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:06:08,842 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:09,205 - INFO - Epoch: [198][200/391] Time 0.026 (0.019) Data 0.005 (0.003) Loss 0.1578 (0.1241) Acc@1 95.312 (95.868) Acc@5 100.000 (99.949)
2025-08-28 06:06:11,023 - INFO - Epoch: [198][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1508 (0.1221) Acc@1 93.750 (95.930) Acc@5 100.000 (99.951)
2025-08-28 06:06:11,792 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:06:11,792 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:12,868 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.3633 (0.3633) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:06:13,708 - INFO - Epoch 198:
2025-08-28 06:06:13,709 - INFO -   Train: acc1: 95.9140 | acc5: 99.9520 | loss: 0.1223 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:06:13,709 - INFO -   Val:   acc1: 90.1400 | acc5: 99.6500 | loss: 0.3112
2025-08-28 06:06:13,709 - INFO -   LR: 0.001000
2025-08-28 06:06:13,731 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-28 06:06:13,924 - INFO - Epoch: [199][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.0660 (0.0660) Acc@1 98.438 (98.438) Acc@5 100.000 (100.000)
2025-08-28 06:06:15,781 - INFO - Epoch: [199][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1439 (0.1149) Acc@1 96.094 (96.287) Acc@5 100.000 (99.985)
2025-08-28 06:06:16,017 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:06:16,017 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:17,688 - INFO - Epoch: [199][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.1193 (0.1177) Acc@1 95.312 (96.121) Acc@5 100.000 (99.969)
2025-08-28 06:06:19,070 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:06:19,070 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:19,623 - INFO - Epoch: [199][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.1235 (0.1201) Acc@1 96.094 (96.016) Acc@5 99.219 (99.956)
2025-08-28 06:06:21,399 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3711 (0.3711) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:06:22,320 - INFO - Epoch 199:
2025-08-28 06:06:22,320 - INFO -   Train: acc1: 95.9960 | acc5: 99.9540 | loss: 0.1212 | sparsity: 0.8000 | reactivation_rate: 0.0000
2025-08-28 06:06:22,320 - INFO -   Val:   acc1: 90.1700 | acc5: 99.6700 | loss: 0.3063
2025-08-28 06:06:22,320 - INFO -   LR: 0.001000
2025-08-28 06:06:22,341 - INFO - training time: 00h 28m 10.17s
2025-08-28 06:06:22,342 - INFO - 
Training completed!
2025-08-28 06:06:22,342 - INFO - Best accuracy: 90.5200
2025-08-28 06:06:22,342 - INFO - Total training time: 0.47 hours
2025-08-28 06:06:22,342 - INFO - total_experiment time: 00h 28m 11.43s
2025-08-28 06:06:22,344 - INFO - Experiment completed successfully
2025-08-28 06:06:22,344 - INFO - Total time: 0.47 hours
