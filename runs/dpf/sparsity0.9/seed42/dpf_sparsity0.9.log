2025-08-28 06:06:26,610 - INFO - Starting experiment: dpf_sparsity0.9
2025-08-28 06:06:26,610 - INFO - Save directory: ./runs/dpf/sparsity0.9/seed42
2025-08-28 06:06:26,610 - INFO - Hyperparameters:
2025-08-28 06:06:26,610 - INFO -   name: dpf_sparsity0.9
2025-08-28 06:06:26,610 - INFO -   description: 
2025-08-28 06:06:26,610 - INFO -   save_dir: ./runs
2025-08-28 06:06:26,610 - INFO -   data: {'dataset': 'cifar10', 'datapath': '/home/20203168/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-28 06:06:26,610 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-28 06:06:26,610 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-28 06:06:26,610 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.9, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-28 06:06:26,610 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-28 06:06:26,610 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-28 06:06:26,644 - INFO - System Information:
2025-08-28 06:06:26,644 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-28 06:06:26,644 - INFO -   python_version: 3.9.18
2025-08-28 06:06:26,644 - INFO -   pytorch_version: 2.1.0
2025-08-28 06:06:26,644 - INFO -   cuda_available: True
2025-08-28 06:06:26,644 - INFO -   cpu_count: 4
2025-08-28 06:06:26,644 - INFO -   memory_total_gb: 11.0
2025-08-28 06:06:26,644 - INFO -   timestamp: 1756328786.6442187
2025-08-28 06:06:26,644 - INFO -   cuda_version: 11.8
2025-08-28 06:06:26,644 - INFO -   gpu_count: 1
2025-08-28 06:06:26,644 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-28 06:06:26,651 - INFO - Starting experiment: dpf_sparsity0.9
2025-08-28 06:06:26,651 - INFO - Model: resnet-20
2025-08-28 06:06:26,651 - INFO - Dataset: cifar10
2025-08-28 06:06:26,651 - INFO - Pruning: dpf (90.00%)
2025-08-28 06:06:26,840 - INFO - Model Information:
2025-08-28 06:06:26,840 - INFO -   Type: pruned
2025-08-28 06:06:26,840 - INFO -   Total parameters: 544,948
2025-08-28 06:06:26,840 - INFO -   Trainable parameters: 274,692
2025-08-28 06:06:26,840 - INFO -   Sparsity: 90.00%
2025-08-28 06:06:27,949 - INFO - Starting training...
2025-08-28 06:06:27,949 - INFO - 
Epoch: 0, lr = 0.1
2025-08-28 06:06:28,624 - INFO - Pruning info: sparsity=0.000
2025-08-28 06:06:28,624 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:29,209 - INFO - Epoch: [0][0/391] Time 1.259 (1.259) Data 0.514 (0.514) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-28 06:06:31,047 - INFO - Epoch: [0][100/391] Time 0.017 (0.031) Data 0.000 (0.007) Loss 1.6914 (1.9312) Acc@1 38.281 (26.122) Acc@5 87.500 (81.389)
2025-08-28 06:06:32,141 - INFO - Pruning info: sparsity=0.000
2025-08-28 06:06:32,141 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:32,977 - INFO - Epoch: [0][200/391] Time 0.021 (0.025) Data 0.000 (0.005) Loss 1.4822 (1.7763) Acc@1 46.875 (32.478) Acc@5 93.750 (85.494)
2025-08-28 06:06:34,833 - INFO - Epoch: [0][300/391] Time 0.015 (0.023) Data 0.000 (0.003) Loss 1.3619 (1.6653) Acc@1 49.219 (37.370) Acc@5 94.531 (87.757)
2025-08-28 06:06:35,206 - INFO - Pruning info: sparsity=0.000
2025-08-28 06:06:35,207 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:06:36,920 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 1.5608 (1.5608) Acc@1 46.875 (46.875) Acc@5 92.188 (92.188)
2025-08-28 06:06:37,879 - INFO - Epoch 0:
2025-08-28 06:06:37,879 - INFO -   Train: acc1: 40.7920 | acc5: 89.1460 | loss: 1.5844 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-28 06:06:37,879 - INFO -   Val:   acc1: 45.3100 | acc5: 92.7000 | loss: 1.5778
2025-08-28 06:06:37,879 - INFO -   LR: 0.100000
2025-08-28 06:06:37,923 - INFO - Checkpoint saved: epoch=0, metric=45.3100
2025-08-28 06:06:37,955 - INFO - 
Epoch: 1, lr = 0.1
2025-08-28 06:06:38,174 - INFO - Epoch: [1][0/391] Time 0.218 (0.218) Data 0.191 (0.191) Loss 1.4714 (1.4714) Acc@1 48.438 (48.438) Acc@5 91.406 (91.406)
2025-08-28 06:06:39,726 - INFO - Pruning info: sparsity=0.036
2025-08-28 06:06:39,726 - INFO -   Reactivation rate: 0.0088
2025-08-28 06:06:39,964 - INFO - Epoch: [1][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 1.1095 (1.1852) Acc@1 58.594 (57.240) Acc@5 96.094 (95.266)
2025-08-28 06:06:41,768 - INFO - Epoch: [1][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.9603 (1.1451) Acc@1 67.188 (58.757) Acc@5 97.656 (95.546)
2025-08-28 06:06:42,629 - INFO - Pruning info: sparsity=0.036
2025-08-28 06:06:42,629 - INFO -   Reactivation rate: 0.0063
2025-08-28 06:06:43,594 - INFO - Epoch: [1][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 1.0259 (1.1086) Acc@1 63.281 (60.112) Acc@5 94.531 (95.863)
2025-08-28 06:06:45,364 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 1.3292 (1.3292) Acc@1 56.250 (56.250) Acc@5 92.969 (92.969)
2025-08-28 06:06:46,225 - INFO - Epoch 1:
2025-08-28 06:06:46,225 - INFO -   Train: acc1: 61.2500 | acc5: 96.1260 | loss: 1.0794 | sparsity: 0.0355 | reactivation_rate: 0.0070
2025-08-28 06:06:46,226 - INFO -   Val:   acc1: 56.1200 | acc5: 93.3600 | loss: 1.3864
2025-08-28 06:06:46,226 - INFO -   LR: 0.100000
2025-08-28 06:06:46,271 - INFO - Checkpoint saved: epoch=1, metric=56.1200
2025-08-28 06:06:46,304 - INFO - 
Epoch: 2, lr = 0.1
2025-08-28 06:06:46,496 - INFO - Epoch: [2][0/391] Time 0.191 (0.191) Data 0.170 (0.170) Loss 0.9594 (0.9594) Acc@1 65.625 (65.625) Acc@5 97.656 (97.656)
2025-08-28 06:06:46,771 - INFO - Pruning info: sparsity=0.070
2025-08-28 06:06:46,771 - INFO -   Reactivation rate: 0.0135
2025-08-28 06:06:48,436 - INFO - Epoch: [2][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.8729 (0.9472) Acc@1 70.312 (66.012) Acc@5 96.094 (97.022)
2025-08-28 06:06:49,888 - INFO - Pruning info: sparsity=0.070
2025-08-28 06:06:49,888 - INFO -   Reactivation rate: 0.0078
2025-08-28 06:06:50,350 - INFO - Epoch: [2][200/391] Time 0.029 (0.020) Data 0.015 (0.003) Loss 0.7587 (0.9198) Acc@1 72.656 (67.083) Acc@5 98.438 (97.338)
2025-08-28 06:06:52,197 - INFO - Epoch: [2][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.9052 (0.9024) Acc@1 64.062 (67.997) Acc@5 99.219 (97.446)
2025-08-28 06:06:52,978 - INFO - Pruning info: sparsity=0.070
2025-08-28 06:06:52,978 - INFO -   Reactivation rate: 0.0058
2025-08-28 06:06:54,155 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 1.3623 (1.3623) Acc@1 61.719 (61.719) Acc@5 94.531 (94.531)
2025-08-28 06:06:55,040 - INFO - Epoch 2:
2025-08-28 06:06:55,041 - INFO -   Train: acc1: 68.6300 | acc5: 97.5180 | loss: 0.8859 | sparsity: 0.0701 | reactivation_rate: 0.0075
2025-08-28 06:06:55,041 - INFO -   Val:   acc1: 58.0200 | acc5: 94.9600 | loss: 1.4622
2025-08-28 06:06:55,041 - INFO -   LR: 0.100000
2025-08-28 06:06:55,084 - INFO - Checkpoint saved: epoch=2, metric=58.0200
2025-08-28 06:06:55,116 - INFO - 
Epoch: 3, lr = 0.1
2025-08-28 06:06:55,318 - INFO - Epoch: [3][0/391] Time 0.201 (0.201) Data 0.169 (0.169) Loss 0.8272 (0.8272) Acc@1 70.312 (70.312) Acc@5 96.094 (96.094)
2025-08-28 06:06:57,111 - INFO - Epoch: [3][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.8246 (0.7711) Acc@1 70.312 (73.051) Acc@5 95.312 (98.120)
2025-08-28 06:06:57,261 - INFO - Pruning info: sparsity=0.104
2025-08-28 06:06:57,261 - INFO -   Reactivation rate: 0.0090
2025-08-28 06:06:58,947 - INFO - Epoch: [3][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.7068 (0.7617) Acc@1 75.000 (73.441) Acc@5 98.438 (98.235)
2025-08-28 06:07:00,220 - INFO - Pruning info: sparsity=0.104
2025-08-28 06:07:00,221 - INFO -   Reactivation rate: 0.0062
2025-08-28 06:07:00,800 - INFO - Epoch: [3][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.7901 (0.7605) Acc@1 72.656 (73.596) Acc@5 99.219 (98.243)
2025-08-28 06:07:02,598 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.8325 (0.8325) Acc@1 71.094 (71.094) Acc@5 99.219 (99.219)
2025-08-28 06:07:03,513 - INFO - Epoch 3:
2025-08-28 06:07:03,513 - INFO -   Train: acc1: 73.6200 | acc5: 98.2540 | loss: 0.7591 | sparsity: 0.1037 | reactivation_rate: 0.0075
2025-08-28 06:07:03,513 - INFO -   Val:   acc1: 71.0700 | acc5: 98.1200 | loss: 0.8774
2025-08-28 06:07:03,513 - INFO -   LR: 0.100000
2025-08-28 06:07:03,555 - INFO - Checkpoint saved: epoch=3, metric=71.0700
2025-08-28 06:07:03,586 - INFO - 
Epoch: 4, lr = 0.1
2025-08-28 06:07:03,766 - INFO - Epoch: [4][0/391] Time 0.179 (0.179) Data 0.163 (0.163) Loss 0.6602 (0.6602) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-28 06:07:04,537 - INFO - Pruning info: sparsity=0.136
2025-08-28 06:07:04,537 - INFO -   Reactivation rate: 0.0117
2025-08-28 06:07:05,730 - INFO - Epoch: [4][100/391] Time 0.025 (0.021) Data 0.002 (0.005) Loss 0.6970 (0.7076) Acc@1 80.469 (75.526) Acc@5 97.656 (98.376)
2025-08-28 06:07:07,462 - INFO - Pruning info: sparsity=0.136
2025-08-28 06:07:07,462 - INFO -   Reactivation rate: 0.0071
2025-08-28 06:07:07,555 - INFO - Epoch: [4][200/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.7381 (0.6971) Acc@1 72.656 (75.987) Acc@5 100.000 (98.368)
2025-08-28 06:07:09,378 - INFO - Epoch: [4][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.6793 (0.6922) Acc@1 76.562 (76.194) Acc@5 97.656 (98.354)
2025-08-28 06:07:10,463 - INFO - Pruning info: sparsity=0.136
2025-08-28 06:07:10,463 - INFO -   Reactivation rate: 0.0053
2025-08-28 06:07:11,197 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 1.1713 (1.1713) Acc@1 62.500 (62.500) Acc@5 93.750 (93.750)
2025-08-28 06:07:12,026 - INFO - Epoch 4:
2025-08-28 06:07:12,026 - INFO -   Train: acc1: 76.2320 | acc5: 98.4180 | loss: 0.6895 | sparsity: 0.1365 | reactivation_rate: 0.0073
2025-08-28 06:07:12,026 - INFO -   Val:   acc1: 62.5900 | acc5: 95.7700 | loss: 1.1479
2025-08-28 06:07:12,026 - INFO -   LR: 0.100000
2025-08-28 06:07:12,033 - INFO - 
Epoch: 5, lr = 0.1
2025-08-28 06:07:12,243 - INFO - Epoch: [5][0/391] Time 0.209 (0.209) Data 0.174 (0.174) Loss 0.7321 (0.7321) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-28 06:07:14,059 - INFO - Epoch: [5][100/391] Time 0.045 (0.020) Data 0.025 (0.004) Loss 0.6595 (0.6765) Acc@1 75.000 (76.725) Acc@5 100.000 (98.538)
2025-08-28 06:07:14,487 - INFO - Pruning info: sparsity=0.168
2025-08-28 06:07:14,488 - INFO -   Reactivation rate: 0.0085
2025-08-28 06:07:15,879 - INFO - Epoch: [5][200/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.6960 (0.6580) Acc@1 76.562 (77.383) Acc@5 99.219 (98.577)
2025-08-28 06:07:17,380 - INFO - Pruning info: sparsity=0.168
2025-08-28 06:07:17,380 - INFO -   Reactivation rate: 0.0058
2025-08-28 06:07:17,650 - INFO - Epoch: [5][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.7118 (0.6538) Acc@1 75.781 (77.564) Acc@5 97.656 (98.583)
2025-08-28 06:07:19,457 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 1.5634 (1.5634) Acc@1 54.688 (54.688) Acc@5 93.750 (93.750)
2025-08-28 06:07:20,305 - INFO - Epoch 5:
2025-08-28 06:07:20,305 - INFO -   Train: acc1: 77.6520 | acc5: 98.6280 | loss: 0.6519 | sparsity: 0.1683 | reactivation_rate: 0.0073
2025-08-28 06:07:20,305 - INFO -   Val:   acc1: 56.4100 | acc5: 93.6900 | loss: 1.5249
2025-08-28 06:07:20,305 - INFO -   LR: 0.100000
2025-08-28 06:07:20,313 - INFO - 
Epoch: 6, lr = 0.1
2025-08-28 06:07:20,539 - INFO - Epoch: [6][0/391] Time 0.225 (0.225) Data 0.196 (0.196) Loss 0.4997 (0.4997) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:07:21,535 - INFO - Pruning info: sparsity=0.199
2025-08-28 06:07:21,535 - INFO -   Reactivation rate: 0.0108
2025-08-28 06:07:22,383 - INFO - Epoch: [6][100/391] Time 0.029 (0.020) Data 0.010 (0.004) Loss 0.5485 (0.6070) Acc@1 80.469 (78.945) Acc@5 99.219 (98.793)
2025-08-28 06:07:24,174 - INFO - Epoch: [6][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.6704 (0.6207) Acc@1 73.438 (78.642) Acc@5 99.219 (98.780)
2025-08-28 06:07:24,413 - INFO - Pruning info: sparsity=0.199
2025-08-28 06:07:24,413 - INFO -   Reactivation rate: 0.0067
2025-08-28 06:07:26,042 - INFO - Epoch: [6][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.5965 (0.6227) Acc@1 78.906 (78.662) Acc@5 98.438 (98.757)
2025-08-28 06:07:27,345 - INFO - Pruning info: sparsity=0.199
2025-08-28 06:07:27,345 - INFO -   Reactivation rate: 0.0050
2025-08-28 06:07:27,830 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.6409 (0.6409) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 06:07:28,684 - INFO - Epoch 6:
2025-08-28 06:07:28,684 - INFO -   Train: acc1: 78.6780 | acc5: 98.7660 | loss: 0.6209 | sparsity: 0.1992 | reactivation_rate: 0.0071
2025-08-28 06:07:28,684 - INFO -   Val:   acc1: 77.5900 | acc5: 98.1200 | loss: 0.6762
2025-08-28 06:07:28,684 - INFO -   LR: 0.100000
2025-08-28 06:07:28,730 - INFO - Checkpoint saved: epoch=6, metric=77.5900
2025-08-28 06:07:28,761 - INFO - 
Epoch: 7, lr = 0.1
2025-08-28 06:07:28,957 - INFO - Epoch: [7][0/391] Time 0.195 (0.195) Data 0.177 (0.177) Loss 0.6180 (0.6180) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:07:30,818 - INFO - Epoch: [7][100/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.7084 (0.5989) Acc@1 74.219 (79.324) Acc@5 97.656 (98.770)
2025-08-28 06:07:31,557 - INFO - Pruning info: sparsity=0.229
2025-08-28 06:07:31,557 - INFO -   Reactivation rate: 0.0075
2025-08-28 06:07:32,670 - INFO - Epoch: [7][200/391] Time 0.026 (0.019) Data 0.010 (0.003) Loss 0.5444 (0.6005) Acc@1 83.594 (79.307) Acc@5 98.438 (98.795)
2025-08-28 06:07:34,449 - INFO - Epoch: [7][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4533 (0.5980) Acc@1 84.375 (79.324) Acc@5 100.000 (98.845)
2025-08-28 06:07:34,492 - INFO - Pruning info: sparsity=0.229
2025-08-28 06:07:34,492 - INFO -   Reactivation rate: 0.0054
2025-08-28 06:07:36,263 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.8291 (0.8291) Acc@1 71.094 (71.094) Acc@5 97.656 (97.656)
2025-08-28 06:07:37,105 - INFO - Epoch 7:
2025-08-28 06:07:37,105 - INFO -   Train: acc1: 79.3720 | acc5: 98.8540 | loss: 0.5973 | sparsity: 0.2292 | reactivation_rate: 0.0069
2025-08-28 06:07:37,105 - INFO -   Val:   acc1: 69.4300 | acc5: 96.0000 | loss: 0.9958
2025-08-28 06:07:37,105 - INFO -   LR: 0.100000
2025-08-28 06:07:37,266 - INFO - 
Epoch: 8, lr = 0.1
2025-08-28 06:07:37,488 - INFO - Epoch: [8][0/391] Time 0.221 (0.221) Data 0.198 (0.198) Loss 0.5241 (0.5241) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:07:38,802 - INFO - Pruning info: sparsity=0.258
2025-08-28 06:07:38,802 - INFO -   Reactivation rate: 0.0090
2025-08-28 06:07:39,310 - INFO - Epoch: [8][100/391] Time 0.031 (0.020) Data 0.011 (0.005) Loss 0.5744 (0.5724) Acc@1 80.469 (80.152) Acc@5 99.219 (98.933)
2025-08-28 06:07:41,118 - INFO - Epoch: [8][200/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.4741 (0.5669) Acc@1 84.375 (80.201) Acc@5 99.219 (98.935)
2025-08-28 06:07:41,716 - INFO - Pruning info: sparsity=0.258
2025-08-28 06:07:41,716 - INFO -   Reactivation rate: 0.0060
2025-08-28 06:07:42,939 - INFO - Epoch: [8][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.7077 (0.5756) Acc@1 76.562 (79.981) Acc@5 99.219 (98.931)
2025-08-28 06:07:44,787 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6598 (0.6598) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:07:45,644 - INFO - Epoch 8:
2025-08-28 06:07:45,644 - INFO -   Train: acc1: 80.0680 | acc5: 98.9600 | loss: 0.5743 | sparsity: 0.2584 | reactivation_rate: 0.0067
2025-08-28 06:07:45,644 - INFO -   Val:   acc1: 76.0000 | acc5: 98.5900 | loss: 0.7327
2025-08-28 06:07:45,644 - INFO -   LR: 0.100000
2025-08-28 06:07:45,653 - INFO - 
Epoch: 9, lr = 0.1
2025-08-28 06:07:45,861 - INFO - Epoch: [9][0/391] Time 0.207 (0.207) Data 0.181 (0.181) Loss 0.5008 (0.5008) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:07:45,872 - INFO - Pruning info: sparsity=0.287
2025-08-28 06:07:45,872 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:07:47,776 - INFO - Epoch: [9][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.5096 (0.5569) Acc@1 82.812 (80.739) Acc@5 98.438 (99.033)
2025-08-28 06:07:48,964 - INFO - Pruning info: sparsity=0.287
2025-08-28 06:07:48,964 - INFO -   Reactivation rate: 0.0065
2025-08-28 06:07:49,705 - INFO - Epoch: [9][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4886 (0.5545) Acc@1 80.469 (80.912) Acc@5 99.219 (98.997)
2025-08-28 06:07:51,517 - INFO - Epoch: [9][300/391] Time 0.027 (0.019) Data 0.011 (0.003) Loss 0.7478 (0.5596) Acc@1 81.250 (80.879) Acc@5 95.312 (98.985)
2025-08-28 06:07:51,885 - INFO - Pruning info: sparsity=0.287
2025-08-28 06:07:51,885 - INFO -   Reactivation rate: 0.0049
2025-08-28 06:07:53,366 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.9143 (0.9143) Acc@1 72.656 (72.656) Acc@5 97.656 (97.656)
2025-08-28 06:07:54,223 - INFO - Epoch 9:
2025-08-28 06:07:54,224 - INFO -   Train: acc1: 80.8540 | acc5: 98.9880 | loss: 0.5586 | sparsity: 0.2867 | reactivation_rate: 0.0063
2025-08-28 06:07:54,224 - INFO -   Val:   acc1: 75.1700 | acc5: 98.4200 | loss: 0.7783
2025-08-28 06:07:54,224 - INFO -   LR: 0.100000
2025-08-28 06:07:54,232 - INFO - 
Epoch: 10, lr = 0.1
2025-08-28 06:07:54,442 - INFO - Epoch: [10][0/391] Time 0.210 (0.210) Data 0.185 (0.185) Loss 0.4930 (0.4930) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-28 06:07:56,034 - INFO - Pruning info: sparsity=0.314
2025-08-28 06:07:56,034 - INFO -   Reactivation rate: 0.0080
2025-08-28 06:07:56,229 - INFO - Epoch: [10][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4331 (0.5319) Acc@1 85.938 (81.544) Acc@5 100.000 (99.010)
2025-08-28 06:07:58,100 - INFO - Epoch: [10][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4978 (0.5365) Acc@1 85.938 (81.534) Acc@5 100.000 (99.052)
2025-08-28 06:07:59,030 - INFO - Pruning info: sparsity=0.314
2025-08-28 06:07:59,030 - INFO -   Reactivation rate: 0.0051
2025-08-28 06:07:59,979 - INFO - Epoch: [10][300/391] Time 0.026 (0.019) Data 0.000 (0.004) Loss 0.7131 (0.5432) Acc@1 77.344 (81.330) Acc@5 98.438 (99.003)
2025-08-28 06:08:01,718 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.8299 (0.8299) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 06:08:02,575 - INFO - Epoch 10:
2025-08-28 06:08:02,575 - INFO -   Train: acc1: 81.3240 | acc5: 99.0060 | loss: 0.5440 | sparsity: 0.3141 | reactivation_rate: 0.0061
2025-08-28 06:08:02,575 - INFO -   Val:   acc1: 71.4600 | acc5: 97.8300 | loss: 0.8669
2025-08-28 06:08:02,575 - INFO -   LR: 0.100000
2025-08-28 06:08:02,620 - INFO - 
Epoch: 11, lr = 0.1
2025-08-28 06:08:02,816 - INFO - Epoch: [11][0/391] Time 0.195 (0.195) Data 0.178 (0.178) Loss 0.5816 (0.5816) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 06:08:03,150 - INFO - Pruning info: sparsity=0.341
2025-08-28 06:08:03,150 - INFO -   Reactivation rate: 0.0111
2025-08-28 06:08:04,581 - INFO - Epoch: [11][100/391] Time 0.015 (0.019) Data 0.004 (0.005) Loss 0.4560 (0.5308) Acc@1 85.156 (81.428) Acc@5 99.219 (99.257)
2025-08-28 06:08:06,078 - INFO - Pruning info: sparsity=0.341
2025-08-28 06:08:06,078 - INFO -   Reactivation rate: 0.0056
2025-08-28 06:08:06,484 - INFO - Epoch: [11][200/391] Time 0.012 (0.019) Data 0.000 (0.005) Loss 0.6366 (0.5277) Acc@1 76.562 (81.740) Acc@5 98.438 (99.184)
2025-08-28 06:08:08,342 - INFO - Epoch: [11][300/391] Time 0.037 (0.019) Data 0.022 (0.005) Loss 0.6935 (0.5337) Acc@1 78.125 (81.629) Acc@5 98.438 (99.143)
2025-08-28 06:08:09,038 - INFO - Pruning info: sparsity=0.341
2025-08-28 06:08:09,042 - INFO -   Reactivation rate: 0.0042
2025-08-28 06:08:10,144 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.5139 (0.5139) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:08:11,006 - INFO - Epoch 11:
2025-08-28 06:08:11,006 - INFO -   Train: acc1: 81.6400 | acc5: 99.1300 | loss: 0.5335 | sparsity: 0.3408 | reactivation_rate: 0.0059
2025-08-28 06:08:11,006 - INFO -   Val:   acc1: 78.5500 | acc5: 98.7700 | loss: 0.6320
2025-08-28 06:08:11,006 - INFO -   LR: 0.100000
2025-08-28 06:08:11,049 - INFO - Checkpoint saved: epoch=11, metric=78.5500
2025-08-28 06:08:11,081 - INFO - 
Epoch: 12, lr = 0.1
2025-08-28 06:08:11,278 - INFO - Epoch: [12][0/391] Time 0.197 (0.197) Data 0.174 (0.174) Loss 0.5296 (0.5296) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 06:08:13,148 - INFO - Epoch: [12][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.4974 (0.5437) Acc@1 83.594 (81.095) Acc@5 99.219 (99.080)
2025-08-28 06:08:13,273 - INFO - Pruning info: sparsity=0.367
2025-08-28 06:08:13,273 - INFO -   Reactivation rate: 0.0070
2025-08-28 06:08:14,960 - INFO - Epoch: [12][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.7039 (0.5215) Acc@1 76.562 (81.988) Acc@5 100.000 (99.075)
2025-08-28 06:08:16,160 - INFO - Pruning info: sparsity=0.367
2025-08-28 06:08:16,160 - INFO -   Reactivation rate: 0.0047
2025-08-28 06:08:16,814 - INFO - Epoch: [12][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4802 (0.5279) Acc@1 82.031 (81.759) Acc@5 99.219 (99.073)
2025-08-28 06:08:18,580 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.6286 (0.6286) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 06:08:19,469 - INFO - Epoch 12:
2025-08-28 06:08:19,470 - INFO -   Train: acc1: 81.7200 | acc5: 99.0580 | loss: 0.5314 | sparsity: 0.3666 | reactivation_rate: 0.0057
2025-08-28 06:08:19,470 - INFO -   Val:   acc1: 76.1900 | acc5: 98.0000 | loss: 0.7308
2025-08-28 06:08:19,470 - INFO -   LR: 0.100000
2025-08-28 06:08:19,479 - INFO - 
Epoch: 13, lr = 0.1
2025-08-28 06:08:19,678 - INFO - Epoch: [13][0/391] Time 0.199 (0.199) Data 0.181 (0.181) Loss 0.5541 (0.5541) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:08:20,334 - INFO - Pruning info: sparsity=0.392
2025-08-28 06:08:20,334 - INFO -   Reactivation rate: 0.0082
2025-08-28 06:08:21,573 - INFO - Epoch: [13][100/391] Time 0.012 (0.021) Data 0.000 (0.005) Loss 0.3850 (0.4905) Acc@1 86.719 (83.199) Acc@5 99.219 (99.095)
2025-08-28 06:08:23,333 - INFO - Pruning info: sparsity=0.392
2025-08-28 06:08:23,333 - INFO -   Reactivation rate: 0.0051
2025-08-28 06:08:23,411 - INFO - Epoch: [13][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.3433 (0.5053) Acc@1 91.406 (82.739) Acc@5 99.219 (99.106)
2025-08-28 06:08:25,271 - INFO - Epoch: [13][300/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.4513 (0.5098) Acc@1 82.812 (82.550) Acc@5 100.000 (99.110)
2025-08-28 06:08:26,311 - INFO - Pruning info: sparsity=0.392
2025-08-28 06:08:26,312 - INFO -   Reactivation rate: 0.0040
2025-08-28 06:08:27,092 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.6760 (0.6760) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 06:08:27,975 - INFO - Epoch 13:
2025-08-28 06:08:27,975 - INFO -   Train: acc1: 82.5780 | acc5: 99.0900 | loss: 0.5143 | sparsity: 0.3916 | reactivation_rate: 0.0054
2025-08-28 06:08:27,975 - INFO -   Val:   acc1: 77.1500 | acc5: 98.7500 | loss: 0.6906
2025-08-28 06:08:27,975 - INFO -   LR: 0.100000
2025-08-28 06:08:27,983 - INFO - 
Epoch: 14, lr = 0.1
2025-08-28 06:08:28,183 - INFO - Epoch: [14][0/391] Time 0.199 (0.199) Data 0.182 (0.182) Loss 0.5236 (0.5236) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:08:29,985 - INFO - Epoch: [14][100/391] Time 0.034 (0.020) Data 0.022 (0.005) Loss 0.6349 (0.5073) Acc@1 80.469 (82.403) Acc@5 98.438 (99.196)
2025-08-28 06:08:30,481 - INFO - Pruning info: sparsity=0.416
2025-08-28 06:08:30,481 - INFO -   Reactivation rate: 0.0061
2025-08-28 06:08:31,889 - INFO - Epoch: [14][200/391] Time 0.015 (0.019) Data 0.000 (0.005) Loss 0.5866 (0.5066) Acc@1 80.469 (82.408) Acc@5 99.219 (99.160)
2025-08-28 06:08:33,434 - INFO - Pruning info: sparsity=0.416
2025-08-28 06:08:33,434 - INFO -   Reactivation rate: 0.0041
2025-08-28 06:08:33,681 - INFO - Epoch: [14][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3900 (0.5117) Acc@1 88.281 (82.197) Acc@5 100.000 (99.164)
2025-08-28 06:08:35,468 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 1.1606 (1.1606) Acc@1 65.625 (65.625) Acc@5 94.531 (94.531)
2025-08-28 06:08:36,333 - INFO - Epoch 14:
2025-08-28 06:08:36,333 - INFO -   Train: acc1: 82.2340 | acc5: 99.1480 | loss: 0.5137 | sparsity: 0.4158 | reactivation_rate: 0.0052
2025-08-28 06:08:36,333 - INFO -   Val:   acc1: 70.4400 | acc5: 96.4500 | loss: 1.0149
2025-08-28 06:08:36,334 - INFO -   LR: 0.100000
2025-08-28 06:08:36,343 - INFO - 
Epoch: 15, lr = 0.1
2025-08-28 06:08:36,552 - INFO - Epoch: [15][0/391] Time 0.207 (0.207) Data 0.186 (0.186) Loss 0.5359 (0.5359) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:08:37,681 - INFO - Pruning info: sparsity=0.439
2025-08-28 06:08:37,681 - INFO -   Reactivation rate: 0.0072
2025-08-28 06:08:38,543 - INFO - Epoch: [15][100/391] Time 0.029 (0.022) Data 0.012 (0.004) Loss 0.5156 (0.4851) Acc@1 85.156 (83.037) Acc@5 98.438 (99.180)
2025-08-28 06:08:40,374 - INFO - Epoch: [15][200/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.5297 (0.5002) Acc@1 78.906 (82.673) Acc@5 100.000 (99.149)
2025-08-28 06:08:40,617 - INFO - Pruning info: sparsity=0.439
2025-08-28 06:08:40,617 - INFO -   Reactivation rate: 0.0046
2025-08-28 06:08:42,242 - INFO - Epoch: [15][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.5112 (0.5035) Acc@1 82.031 (82.631) Acc@5 99.219 (99.182)
2025-08-28 06:08:43,590 - INFO - Pruning info: sparsity=0.439
2025-08-28 06:08:43,590 - INFO -   Reactivation rate: 0.0035
2025-08-28 06:08:44,048 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 1.3083 (1.3083) Acc@1 60.938 (60.938) Acc@5 98.438 (98.438)
2025-08-28 06:08:44,943 - INFO - Epoch 15:
2025-08-28 06:08:44,943 - INFO -   Train: acc1: 82.5860 | acc5: 99.1480 | loss: 0.5051 | sparsity: 0.4392 | reactivation_rate: 0.0050
2025-08-28 06:08:44,943 - INFO -   Val:   acc1: 66.1400 | acc5: 97.8600 | loss: 1.1949
2025-08-28 06:08:44,943 - INFO -   LR: 0.100000
2025-08-28 06:08:44,954 - INFO - 
Epoch: 16, lr = 0.1
2025-08-28 06:08:45,158 - INFO - Epoch: [16][0/391] Time 0.203 (0.203) Data 0.174 (0.174) Loss 0.5495 (0.5495) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-28 06:08:47,142 - INFO - Epoch: [16][100/391] Time 0.019 (0.022) Data 0.000 (0.004) Loss 0.5785 (0.4944) Acc@1 76.562 (82.812) Acc@5 98.438 (99.165)
2025-08-28 06:08:47,893 - INFO - Pruning info: sparsity=0.462
2025-08-28 06:08:47,893 - INFO -   Reactivation rate: 0.0052
2025-08-28 06:08:48,940 - INFO - Epoch: [16][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.6142 (0.4935) Acc@1 82.812 (83.007) Acc@5 96.094 (99.160)
2025-08-28 06:08:50,755 - INFO - Epoch: [16][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.6656 (0.4948) Acc@1 75.000 (82.841) Acc@5 97.656 (99.169)
2025-08-28 06:08:50,825 - INFO - Pruning info: sparsity=0.462
2025-08-28 06:08:50,825 - INFO -   Reactivation rate: 0.0035
2025-08-28 06:08:52,592 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.4958 (0.4958) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:08:53,462 - INFO - Epoch 16:
2025-08-28 06:08:53,462 - INFO -   Train: acc1: 82.7980 | acc5: 99.1800 | loss: 0.4949 | sparsity: 0.4619 | reactivation_rate: 0.0047
2025-08-28 06:08:53,462 - INFO -   Val:   acc1: 79.6100 | acc5: 98.9400 | loss: 0.6053
2025-08-28 06:08:53,462 - INFO -   LR: 0.100000
2025-08-28 06:08:53,506 - INFO - Checkpoint saved: epoch=16, metric=79.6100
2025-08-28 06:08:53,539 - INFO - 
Epoch: 17, lr = 0.1
2025-08-28 06:08:53,731 - INFO - Epoch: [17][0/391] Time 0.191 (0.191) Data 0.165 (0.165) Loss 0.5055 (0.5055) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:08:55,055 - INFO - Pruning info: sparsity=0.484
2025-08-28 06:08:55,055 - INFO -   Reactivation rate: 0.0063
2025-08-28 06:08:55,556 - INFO - Epoch: [17][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4361 (0.4874) Acc@1 84.375 (83.246) Acc@5 99.219 (99.281)
2025-08-28 06:08:57,460 - INFO - Epoch: [17][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5033 (0.4878) Acc@1 78.906 (83.240) Acc@5 100.000 (99.269)
2025-08-28 06:08:58,026 - INFO - Pruning info: sparsity=0.484
2025-08-28 06:08:58,026 - INFO -   Reactivation rate: 0.0042
2025-08-28 06:08:59,347 - INFO - Epoch: [17][300/391] Time 0.031 (0.019) Data 0.002 (0.003) Loss 0.5313 (0.4963) Acc@1 81.250 (82.929) Acc@5 98.438 (99.247)
2025-08-28 06:09:01,220 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5314 (0.5314) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 06:09:02,269 - INFO - Epoch 17:
2025-08-28 06:09:02,269 - INFO -   Train: acc1: 82.9480 | acc5: 99.2020 | loss: 0.4962 | sparsity: 0.4838 | reactivation_rate: 0.0046
2025-08-28 06:09:02,269 - INFO -   Val:   acc1: 78.8800 | acc5: 98.5200 | loss: 0.6179
2025-08-28 06:09:02,269 - INFO -   LR: 0.100000
2025-08-28 06:09:02,279 - INFO - 
Epoch: 18, lr = 0.1
2025-08-28 06:09:02,473 - INFO - Epoch: [18][0/391] Time 0.193 (0.193) Data 0.174 (0.174) Loss 0.4490 (0.4490) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:09:02,515 - INFO - Pruning info: sparsity=0.505
2025-08-28 06:09:02,515 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:09:04,353 - INFO - Epoch: [18][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.3955 (0.4793) Acc@1 86.719 (83.308) Acc@5 100.000 (99.196)
2025-08-28 06:09:05,488 - INFO - Pruning info: sparsity=0.505
2025-08-28 06:09:05,488 - INFO -   Reactivation rate: 0.0046
2025-08-28 06:09:06,154 - INFO - Epoch: [18][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4392 (0.4870) Acc@1 86.719 (83.151) Acc@5 99.219 (99.199)
2025-08-28 06:09:07,928 - INFO - Epoch: [18][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5794 (0.4848) Acc@1 78.906 (83.313) Acc@5 100.000 (99.214)
2025-08-28 06:09:08,363 - INFO - Pruning info: sparsity=0.505
2025-08-28 06:09:08,364 - INFO -   Reactivation rate: 0.0032
2025-08-28 06:09:09,881 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.7265 (0.7265) Acc@1 73.438 (73.438) Acc@5 96.094 (96.094)
2025-08-28 06:09:10,732 - INFO - Epoch 18:
2025-08-28 06:09:10,733 - INFO -   Train: acc1: 83.3220 | acc5: 99.2380 | loss: 0.4855 | sparsity: 0.5049 | reactivation_rate: 0.0043
2025-08-28 06:09:10,733 - INFO -   Val:   acc1: 72.3900 | acc5: 96.9600 | loss: 0.8796
2025-08-28 06:09:10,733 - INFO -   LR: 0.100000
2025-08-28 06:09:10,743 - INFO - 
Epoch: 19, lr = 0.1
2025-08-28 06:09:10,956 - INFO - Epoch: [19][0/391] Time 0.212 (0.212) Data 0.184 (0.184) Loss 0.4131 (0.4131) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:09:12,641 - INFO - Pruning info: sparsity=0.525
2025-08-28 06:09:12,641 - INFO -   Reactivation rate: 0.0054
2025-08-28 06:09:12,821 - INFO - Epoch: [19][100/391] Time 0.021 (0.021) Data 0.000 (0.005) Loss 0.4294 (0.4764) Acc@1 84.375 (83.617) Acc@5 100.000 (99.273)
2025-08-28 06:09:14,757 - INFO - Epoch: [19][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3675 (0.4860) Acc@1 85.156 (83.263) Acc@5 100.000 (99.269)
2025-08-28 06:09:15,723 - INFO - Pruning info: sparsity=0.525
2025-08-28 06:09:15,723 - INFO -   Reactivation rate: 0.0035
2025-08-28 06:09:16,650 - INFO - Epoch: [19][300/391] Time 0.035 (0.020) Data 0.000 (0.003) Loss 0.3630 (0.4852) Acc@1 89.062 (83.072) Acc@5 100.000 (99.268)
2025-08-28 06:09:18,583 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.7039 (0.7039) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-28 06:09:19,588 - INFO - Epoch 19:
2025-08-28 06:09:19,588 - INFO -   Train: acc1: 83.2140 | acc5: 99.2660 | loss: 0.4816 | sparsity: 0.5254 | reactivation_rate: 0.0041
2025-08-28 06:09:19,588 - INFO -   Val:   acc1: 71.7000 | acc5: 98.0000 | loss: 0.8625
2025-08-28 06:09:19,588 - INFO -   LR: 0.100000
2025-08-28 06:09:19,597 - INFO - 
Epoch: 20, lr = 0.1
2025-08-28 06:09:19,799 - INFO - Epoch: [20][0/391] Time 0.201 (0.201) Data 0.184 (0.184) Loss 0.4959 (0.4959) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:09:20,141 - INFO - Pruning info: sparsity=0.545
2025-08-28 06:09:20,141 - INFO -   Reactivation rate: 0.0070
2025-08-28 06:09:21,735 - INFO - Epoch: [20][100/391] Time 0.017 (0.021) Data 0.000 (0.005) Loss 0.3522 (0.4819) Acc@1 87.500 (83.230) Acc@5 99.219 (99.226)
2025-08-28 06:09:23,207 - INFO - Pruning info: sparsity=0.545
2025-08-28 06:09:23,207 - INFO -   Reactivation rate: 0.0040
2025-08-28 06:09:23,579 - INFO - Epoch: [20][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4762 (0.4814) Acc@1 84.375 (83.244) Acc@5 99.219 (99.262)
2025-08-28 06:09:25,412 - INFO - Epoch: [20][300/391] Time 0.067 (0.019) Data 0.041 (0.003) Loss 0.5099 (0.4815) Acc@1 85.938 (83.223) Acc@5 96.875 (99.255)
2025-08-28 06:09:26,150 - INFO - Pruning info: sparsity=0.545
2025-08-28 06:09:26,150 - INFO -   Reactivation rate: 0.0029
2025-08-28 06:09:27,327 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.6516 (0.6516) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 06:09:28,202 - INFO - Epoch 20:
2025-08-28 06:09:28,202 - INFO -   Train: acc1: 83.2720 | acc5: 99.2580 | loss: 0.4811 | sparsity: 0.5451 | reactivation_rate: 0.0039
2025-08-28 06:09:28,202 - INFO -   Val:   acc1: 75.9900 | acc5: 97.9100 | loss: 0.7802
2025-08-28 06:09:28,202 - INFO -   LR: 0.100000
2025-08-28 06:09:28,252 - INFO - 
Epoch: 21, lr = 0.1
2025-08-28 06:09:28,475 - INFO - Epoch: [21][0/391] Time 0.222 (0.222) Data 0.203 (0.203) Loss 0.3047 (0.3047) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:09:30,326 - INFO - Epoch: [21][100/391] Time 0.018 (0.021) Data 0.000 (0.005) Loss 0.3970 (0.4466) Acc@1 87.500 (84.599) Acc@5 99.219 (99.250)
2025-08-28 06:09:30,441 - INFO - Pruning info: sparsity=0.564
2025-08-28 06:09:30,441 - INFO -   Reactivation rate: 0.0045
2025-08-28 06:09:32,200 - INFO - Epoch: [21][200/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.5234 (0.4588) Acc@1 83.594 (84.091) Acc@5 99.219 (99.215)
2025-08-28 06:09:33,501 - INFO - Pruning info: sparsity=0.564
2025-08-28 06:09:33,501 - INFO -   Reactivation rate: 0.0031
2025-08-28 06:09:34,112 - INFO - Epoch: [21][300/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.5099 (0.4676) Acc@1 78.906 (83.833) Acc@5 99.219 (99.221)
2025-08-28 06:09:35,925 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.5182 (0.5182) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:09:36,803 - INFO - Epoch 21:
2025-08-28 06:09:36,803 - INFO -   Train: acc1: 83.6520 | acc5: 99.2320 | loss: 0.4722 | sparsity: 0.5641 | reactivation_rate: 0.0038
2025-08-28 06:09:36,803 - INFO -   Val:   acc1: 81.3900 | acc5: 98.7200 | loss: 0.5613
2025-08-28 06:09:36,804 - INFO -   LR: 0.100000
2025-08-28 06:09:36,850 - INFO - Checkpoint saved: epoch=21, metric=81.3900
2025-08-28 06:09:36,883 - INFO - 
Epoch: 22, lr = 0.1
2025-08-28 06:09:37,065 - INFO - Epoch: [22][0/391] Time 0.180 (0.180) Data 0.163 (0.163) Loss 0.4390 (0.4390) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:09:37,817 - INFO - Pruning info: sparsity=0.582
2025-08-28 06:09:37,818 - INFO -   Reactivation rate: 0.0054
2025-08-28 06:09:38,999 - INFO - Epoch: [22][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.4503 (0.4527) Acc@1 83.594 (84.421) Acc@5 99.219 (99.296)
2025-08-28 06:09:40,759 - INFO - Pruning info: sparsity=0.582
2025-08-28 06:09:40,759 - INFO -   Reactivation rate: 0.0036
2025-08-28 06:09:40,801 - INFO - Epoch: [22][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5069 (0.4554) Acc@1 81.250 (84.398) Acc@5 97.656 (99.265)
2025-08-28 06:09:42,691 - INFO - Epoch: [22][300/391] Time 0.030 (0.019) Data 0.010 (0.003) Loss 0.3358 (0.4624) Acc@1 87.500 (84.160) Acc@5 100.000 (99.255)
2025-08-28 06:09:43,719 - INFO - Pruning info: sparsity=0.582
2025-08-28 06:09:43,720 - INFO -   Reactivation rate: 0.0027
2025-08-28 06:09:44,448 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5434 (0.5434) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:09:45,313 - INFO - Epoch 22:
2025-08-28 06:09:45,313 - INFO -   Train: acc1: 84.0120 | acc5: 99.2360 | loss: 0.4662 | sparsity: 0.5824 | reactivation_rate: 0.0036
2025-08-28 06:09:45,314 - INFO -   Val:   acc1: 78.5200 | acc5: 98.5900 | loss: 0.6603
2025-08-28 06:09:45,314 - INFO -   LR: 0.100000
2025-08-28 06:09:45,323 - INFO - 
Epoch: 23, lr = 0.1
2025-08-28 06:09:45,512 - INFO - Epoch: [23][0/391] Time 0.188 (0.188) Data 0.172 (0.172) Loss 0.3843 (0.3843) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:09:47,382 - INFO - Epoch: [23][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.5124 (0.4542) Acc@1 80.469 (84.599) Acc@5 99.219 (99.281)
2025-08-28 06:09:47,849 - INFO - Pruning info: sparsity=0.600
2025-08-28 06:09:47,849 - INFO -   Reactivation rate: 0.0041
2025-08-28 06:09:49,172 - INFO - Epoch: [23][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4825 (0.4728) Acc@1 85.938 (83.936) Acc@5 98.438 (99.192)
2025-08-28 06:09:50,787 - INFO - Pruning info: sparsity=0.600
2025-08-28 06:09:50,787 - INFO -   Reactivation rate: 0.0028
2025-08-28 06:09:50,988 - INFO - Epoch: [23][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4601 (0.4667) Acc@1 84.375 (84.040) Acc@5 100.000 (99.260)
2025-08-28 06:09:52,834 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.6490 (0.6490) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:09:53,690 - INFO - Epoch 23:
2025-08-28 06:09:53,690 - INFO -   Train: acc1: 83.8840 | acc5: 99.2500 | loss: 0.4687 | sparsity: 0.6000 | reactivation_rate: 0.0034
2025-08-28 06:09:53,690 - INFO -   Val:   acc1: 78.3000 | acc5: 98.9100 | loss: 0.6578
2025-08-28 06:09:53,690 - INFO -   LR: 0.100000
2025-08-28 06:09:53,699 - INFO - 
Epoch: 24, lr = 0.1
2025-08-28 06:09:53,917 - INFO - Epoch: [24][0/391] Time 0.216 (0.216) Data 0.199 (0.199) Loss 0.4399 (0.4399) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:09:54,918 - INFO - Pruning info: sparsity=0.617
2025-08-28 06:09:54,918 - INFO -   Reactivation rate: 0.0046
2025-08-28 06:09:55,727 - INFO - Epoch: [24][100/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.3851 (0.4657) Acc@1 88.281 (84.352) Acc@5 98.438 (99.257)
2025-08-28 06:09:57,575 - INFO - Epoch: [24][200/391] Time 0.033 (0.019) Data 0.000 (0.004) Loss 0.4965 (0.4605) Acc@1 82.812 (84.309) Acc@5 98.438 (99.300)
2025-08-28 06:09:57,877 - INFO - Pruning info: sparsity=0.617
2025-08-28 06:09:57,877 - INFO -   Reactivation rate: 0.0031
2025-08-28 06:09:59,391 - INFO - Epoch: [24][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4955 (0.4598) Acc@1 82.812 (84.258) Acc@5 99.219 (99.328)
2025-08-28 06:10:00,786 - INFO - Pruning info: sparsity=0.617
2025-08-28 06:10:00,786 - INFO -   Reactivation rate: 0.0023
2025-08-28 06:10:01,201 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.7005 (0.7005) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 06:10:02,083 - INFO - Epoch 24:
2025-08-28 06:10:02,083 - INFO -   Train: acc1: 84.2020 | acc5: 99.3020 | loss: 0.4600 | sparsity: 0.6170 | reactivation_rate: 0.0032
2025-08-28 06:10:02,083 - INFO -   Val:   acc1: 76.6800 | acc5: 98.7500 | loss: 0.6779
2025-08-28 06:10:02,083 - INFO -   LR: 0.100000
2025-08-28 06:10:02,093 - INFO - 
Epoch: 25, lr = 0.1
2025-08-28 06:10:02,277 - INFO - Epoch: [25][0/391] Time 0.183 (0.183) Data 0.153 (0.153) Loss 0.3869 (0.3869) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:10:04,064 - INFO - Epoch: [25][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5238 (0.4340) Acc@1 82.031 (85.265) Acc@5 98.438 (99.420)
2025-08-28 06:10:04,939 - INFO - Pruning info: sparsity=0.633
2025-08-28 06:10:04,939 - INFO -   Reactivation rate: 0.0033
2025-08-28 06:10:05,981 - INFO - Epoch: [25][200/391] Time 0.028 (0.019) Data 0.018 (0.005) Loss 0.5578 (0.4484) Acc@1 79.688 (84.534) Acc@5 98.438 (99.413)
2025-08-28 06:10:07,835 - INFO - Epoch: [25][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4238 (0.4521) Acc@1 84.375 (84.419) Acc@5 100.000 (99.356)
2025-08-28 06:10:07,947 - INFO - Pruning info: sparsity=0.633
2025-08-28 06:10:07,947 - INFO -   Reactivation rate: 0.0025
2025-08-28 06:10:09,696 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5705 (0.5705) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-28 06:10:10,558 - INFO - Epoch 25:
2025-08-28 06:10:10,558 - INFO -   Train: acc1: 84.3440 | acc5: 99.3340 | loss: 0.4549 | sparsity: 0.6333 | reactivation_rate: 0.0030
2025-08-28 06:10:10,558 - INFO -   Val:   acc1: 79.6000 | acc5: 98.5200 | loss: 0.6203
2025-08-28 06:10:10,558 - INFO -   LR: 0.100000
2025-08-28 06:10:10,568 - INFO - 
Epoch: 26, lr = 0.1
2025-08-28 06:10:10,788 - INFO - Epoch: [26][0/391] Time 0.220 (0.220) Data 0.200 (0.200) Loss 0.3345 (0.3345) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:10:12,145 - INFO - Pruning info: sparsity=0.649
2025-08-28 06:10:12,145 - INFO -   Reactivation rate: 0.0039
2025-08-28 06:10:12,655 - INFO - Epoch: [26][100/391] Time 0.012 (0.021) Data 0.000 (0.005) Loss 0.4253 (0.4443) Acc@1 86.719 (84.878) Acc@5 99.219 (99.366)
2025-08-28 06:10:14,406 - INFO - Epoch: [26][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4855 (0.4459) Acc@1 82.031 (84.682) Acc@5 100.000 (99.366)
2025-08-28 06:10:15,020 - INFO - Pruning info: sparsity=0.649
2025-08-28 06:10:15,020 - INFO -   Reactivation rate: 0.0025
2025-08-28 06:10:16,324 - INFO - Epoch: [26][300/391] Time 0.025 (0.019) Data 0.013 (0.004) Loss 0.6511 (0.4546) Acc@1 76.562 (84.396) Acc@5 99.219 (99.351)
2025-08-28 06:10:18,103 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.4660 (0.4660) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:10:18,997 - INFO - Epoch 26:
2025-08-28 06:10:18,997 - INFO -   Train: acc1: 84.5900 | acc5: 99.3220 | loss: 0.4492 | sparsity: 0.6490 | reactivation_rate: 0.0028
2025-08-28 06:10:18,998 - INFO -   Val:   acc1: 81.3800 | acc5: 99.0900 | loss: 0.5562
2025-08-28 06:10:18,998 - INFO -   LR: 0.100000
2025-08-28 06:10:19,007 - INFO - 
Epoch: 27, lr = 0.1
2025-08-28 06:10:19,217 - INFO - Epoch: [27][0/391] Time 0.209 (0.209) Data 0.179 (0.179) Loss 0.4105 (0.4105) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-28 06:10:19,254 - INFO - Pruning info: sparsity=0.664
2025-08-28 06:10:19,255 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:10:21,095 - INFO - Epoch: [27][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.5174 (0.4356) Acc@1 80.469 (85.350) Acc@5 100.000 (99.296)
2025-08-28 06:10:22,211 - INFO - Pruning info: sparsity=0.664
2025-08-28 06:10:22,211 - INFO -   Reactivation rate: 0.0030
2025-08-28 06:10:22,912 - INFO - Epoch: [27][200/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.4318 (0.4426) Acc@1 86.719 (85.001) Acc@5 98.438 (99.324)
2025-08-28 06:10:24,771 - INFO - Epoch: [27][300/391] Time 0.031 (0.019) Data 0.000 (0.003) Loss 0.4952 (0.4452) Acc@1 83.594 (84.741) Acc@5 97.656 (99.362)
2025-08-28 06:10:25,121 - INFO - Pruning info: sparsity=0.664
2025-08-28 06:10:25,121 - INFO -   Reactivation rate: 0.0020
2025-08-28 06:10:26,504 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.5978 (0.5978) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-28 06:10:27,351 - INFO - Epoch 27:
2025-08-28 06:10:27,352 - INFO -   Train: acc1: 84.5200 | acc5: 99.3380 | loss: 0.4513 | sparsity: 0.6641 | reactivation_rate: 0.0027
2025-08-28 06:10:27,352 - INFO -   Val:   acc1: 77.6300 | acc5: 98.8200 | loss: 0.6519
2025-08-28 06:10:27,352 - INFO -   LR: 0.100000
2025-08-28 06:10:27,366 - INFO - 
Epoch: 28, lr = 0.1
2025-08-28 06:10:27,572 - INFO - Epoch: [28][0/391] Time 0.205 (0.205) Data 0.182 (0.182) Loss 0.3322 (0.3322) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:10:29,276 - INFO - Pruning info: sparsity=0.679
2025-08-28 06:10:29,276 - INFO -   Reactivation rate: 0.0035
2025-08-28 06:10:29,434 - INFO - Epoch: [28][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.4931 (0.4384) Acc@1 85.938 (84.963) Acc@5 99.219 (99.428)
2025-08-28 06:10:31,304 - INFO - Epoch: [28][200/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.4968 (0.4490) Acc@1 83.594 (84.515) Acc@5 100.000 (99.370)
2025-08-28 06:10:32,211 - INFO - Pruning info: sparsity=0.679
2025-08-28 06:10:32,211 - INFO -   Reactivation rate: 0.0024
2025-08-28 06:10:33,107 - INFO - Epoch: [28][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3529 (0.4480) Acc@1 85.938 (84.616) Acc@5 100.000 (99.346)
2025-08-28 06:10:34,868 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.5746 (0.5746) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:10:35,724 - INFO - Epoch 28:
2025-08-28 06:10:35,724 - INFO -   Train: acc1: 84.5580 | acc5: 99.3300 | loss: 0.4488 | sparsity: 0.6785 | reactivation_rate: 0.0026
2025-08-28 06:10:35,724 - INFO -   Val:   acc1: 77.9500 | acc5: 98.7100 | loss: 0.6695
2025-08-28 06:10:35,724 - INFO -   LR: 0.100000
2025-08-28 06:10:35,735 - INFO - 
Epoch: 29, lr = 0.1
2025-08-28 06:10:35,934 - INFO - Epoch: [29][0/391] Time 0.198 (0.198) Data 0.174 (0.174) Loss 0.5215 (0.5215) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-28 06:10:36,294 - INFO - Pruning info: sparsity=0.692
2025-08-28 06:10:36,294 - INFO -   Reactivation rate: 0.0039
2025-08-28 06:10:37,786 - INFO - Epoch: [29][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3879 (0.4372) Acc@1 85.156 (84.777) Acc@5 99.219 (99.366)
2025-08-28 06:10:39,248 - INFO - Pruning info: sparsity=0.692
2025-08-28 06:10:39,248 - INFO -   Reactivation rate: 0.0026
2025-08-28 06:10:39,648 - INFO - Epoch: [29][200/391] Time 0.034 (0.019) Data 0.010 (0.003) Loss 0.4427 (0.4406) Acc@1 81.250 (84.764) Acc@5 100.000 (99.386)
2025-08-28 06:10:41,428 - INFO - Epoch: [29][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4706 (0.4405) Acc@1 85.938 (84.772) Acc@5 99.219 (99.372)
2025-08-28 06:10:42,154 - INFO - Pruning info: sparsity=0.692
2025-08-28 06:10:42,154 - INFO -   Reactivation rate: 0.0018
2025-08-28 06:10:43,244 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.4917 (0.4917) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 06:10:44,096 - INFO - Epoch 29:
2025-08-28 06:10:44,096 - INFO -   Train: acc1: 84.7680 | acc5: 99.3540 | loss: 0.4409 | sparsity: 0.6924 | reactivation_rate: 0.0024
2025-08-28 06:10:44,097 - INFO -   Val:   acc1: 80.3400 | acc5: 98.6400 | loss: 0.6095
2025-08-28 06:10:44,097 - INFO -   LR: 0.100000
2025-08-28 06:10:44,107 - INFO - 
Epoch: 30, lr = 0.1
2025-08-28 06:10:44,306 - INFO - Epoch: [30][0/391] Time 0.198 (0.198) Data 0.170 (0.170) Loss 0.3183 (0.3183) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:10:46,149 - INFO - Epoch: [30][100/391] Time 0.013 (0.020) Data 0.000 (0.006) Loss 0.5522 (0.4421) Acc@1 79.688 (84.769) Acc@5 100.000 (99.466)
2025-08-28 06:10:46,347 - INFO - Pruning info: sparsity=0.706
2025-08-28 06:10:46,347 - INFO -   Reactivation rate: 0.0029
2025-08-28 06:10:48,029 - INFO - Epoch: [30][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3546 (0.4453) Acc@1 85.938 (84.670) Acc@5 98.438 (99.401)
2025-08-28 06:10:49,247 - INFO - Pruning info: sparsity=0.706
2025-08-28 06:10:49,247 - INFO -   Reactivation rate: 0.0021
2025-08-28 06:10:49,781 - INFO - Epoch: [30][300/391] Time 0.028 (0.019) Data 0.016 (0.004) Loss 0.4962 (0.4455) Acc@1 80.469 (84.692) Acc@5 100.000 (99.390)
2025-08-28 06:10:51,632 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.8281 (0.8281) Acc@1 73.438 (73.438) Acc@5 100.000 (100.000)
2025-08-28 06:10:52,503 - INFO - Epoch 30:
2025-08-28 06:10:52,503 - INFO -   Train: acc1: 84.6140 | acc5: 99.4040 | loss: 0.4478 | sparsity: 0.7056 | reactivation_rate: 0.0023
2025-08-28 06:10:52,504 - INFO -   Val:   acc1: 74.3300 | acc5: 97.6200 | loss: 0.8549
2025-08-28 06:10:52,504 - INFO -   LR: 0.100000
2025-08-28 06:10:52,547 - INFO - 
Epoch: 31, lr = 0.1
2025-08-28 06:10:52,732 - INFO - Epoch: [31][0/391] Time 0.184 (0.184) Data 0.156 (0.156) Loss 0.5731 (0.5731) Acc@1 85.156 (85.156) Acc@5 97.656 (97.656)
2025-08-28 06:10:53,437 - INFO - Pruning info: sparsity=0.718
2025-08-28 06:10:53,437 - INFO -   Reactivation rate: 0.0028
2025-08-28 06:10:54,541 - INFO - Epoch: [31][100/391] Time 0.012 (0.020) Data 0.000 (0.005) Loss 0.2855 (0.4222) Acc@1 89.062 (85.551) Acc@5 100.000 (99.482)
2025-08-28 06:10:56,347 - INFO - Pruning info: sparsity=0.718
2025-08-28 06:10:56,347 - INFO -   Reactivation rate: 0.0021
2025-08-28 06:10:56,373 - INFO - Epoch: [31][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4867 (0.4318) Acc@1 82.031 (85.246) Acc@5 99.219 (99.452)
2025-08-28 06:10:58,270 - INFO - Epoch: [31][300/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.4149 (0.4340) Acc@1 87.500 (85.081) Acc@5 99.219 (99.442)
2025-08-28 06:10:59,312 - INFO - Pruning info: sparsity=0.718
2025-08-28 06:10:59,312 - INFO -   Reactivation rate: 0.0017
2025-08-28 06:11:00,048 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.5822 (0.5822) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:11:00,965 - INFO - Epoch 31:
2025-08-28 06:11:00,966 - INFO -   Train: acc1: 85.0600 | acc5: 99.4220 | loss: 0.4364 | sparsity: 0.7183 | reactivation_rate: 0.0021
2025-08-28 06:11:00,966 - INFO -   Val:   acc1: 78.2700 | acc5: 98.7200 | loss: 0.7064
2025-08-28 06:11:00,966 - INFO -   LR: 0.100000
2025-08-28 06:11:00,976 - INFO - 
Epoch: 32, lr = 0.1
2025-08-28 06:11:01,185 - INFO - Epoch: [32][0/391] Time 0.208 (0.208) Data 0.179 (0.179) Loss 0.5658 (0.5658) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:11:03,003 - INFO - Epoch: [32][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4147 (0.4131) Acc@1 85.938 (85.883) Acc@5 98.438 (99.397)
2025-08-28 06:11:03,519 - INFO - Pruning info: sparsity=0.730
2025-08-28 06:11:03,519 - INFO -   Reactivation rate: 0.0023
2025-08-28 06:11:04,875 - INFO - Epoch: [32][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4515 (0.4254) Acc@1 85.156 (85.393) Acc@5 97.656 (99.398)
2025-08-28 06:11:06,479 - INFO - Pruning info: sparsity=0.730
2025-08-28 06:11:06,479 - INFO -   Reactivation rate: 0.0017
2025-08-28 06:11:06,705 - INFO - Epoch: [32][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3640 (0.4302) Acc@1 87.500 (85.268) Acc@5 99.219 (99.367)
2025-08-28 06:11:08,606 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.5425 (0.5425) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:11:09,455 - INFO - Epoch 32:
2025-08-28 06:11:09,455 - INFO -   Train: acc1: 85.1220 | acc5: 99.3840 | loss: 0.4330 | sparsity: 0.7304 | reactivation_rate: 0.0020
2025-08-28 06:11:09,455 - INFO -   Val:   acc1: 82.4700 | acc5: 99.0600 | loss: 0.5321
2025-08-28 06:11:09,455 - INFO -   LR: 0.100000
2025-08-28 06:11:09,498 - INFO - Checkpoint saved: epoch=32, metric=82.4700
2025-08-28 06:11:09,529 - INFO - 
Epoch: 33, lr = 0.1
2025-08-28 06:11:09,686 - INFO - Epoch: [33][0/391] Time 0.156 (0.156) Data 0.140 (0.140) Loss 0.3109 (0.3109) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:11:10,730 - INFO - Pruning info: sparsity=0.742
2025-08-28 06:11:10,730 - INFO -   Reactivation rate: 0.0026
2025-08-28 06:11:11,559 - INFO - Epoch: [33][100/391] Time 0.024 (0.020) Data 0.001 (0.004) Loss 0.4183 (0.4367) Acc@1 85.938 (85.272) Acc@5 99.219 (99.350)
2025-08-28 06:11:13,373 - INFO - Epoch: [33][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.5401 (0.4252) Acc@1 78.906 (85.479) Acc@5 97.656 (99.417)
2025-08-28 06:11:13,678 - INFO - Pruning info: sparsity=0.742
2025-08-28 06:11:13,679 - INFO -   Reactivation rate: 0.0018
2025-08-28 06:11:15,241 - INFO - Epoch: [33][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4199 (0.4289) Acc@1 85.938 (85.372) Acc@5 97.656 (99.395)
2025-08-28 06:11:16,607 - INFO - Pruning info: sparsity=0.742
2025-08-28 06:11:16,608 - INFO -   Reactivation rate: 0.0015
2025-08-28 06:11:17,050 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.4581 (0.4581) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:11:17,973 - INFO - Epoch 33:
2025-08-28 06:11:17,973 - INFO -   Train: acc1: 85.1460 | acc5: 99.3700 | loss: 0.4334 | sparsity: 0.7419 | reactivation_rate: 0.0019
2025-08-28 06:11:17,973 - INFO -   Val:   acc1: 80.4700 | acc5: 99.1500 | loss: 0.5869
2025-08-28 06:11:17,973 - INFO -   LR: 0.100000
2025-08-28 06:11:17,983 - INFO - 
Epoch: 34, lr = 0.1
2025-08-28 06:11:18,221 - INFO - Epoch: [34][0/391] Time 0.237 (0.237) Data 0.181 (0.181) Loss 0.5063 (0.5063) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 06:11:20,081 - INFO - Epoch: [34][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.4852 (0.4252) Acc@1 83.594 (85.326) Acc@5 98.438 (99.343)
2025-08-28 06:11:21,037 - INFO - Pruning info: sparsity=0.753
2025-08-28 06:11:21,037 - INFO -   Reactivation rate: 0.0020
2025-08-28 06:11:21,998 - INFO - Epoch: [34][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.3527 (0.4223) Acc@1 88.281 (85.094) Acc@5 100.000 (99.398)
2025-08-28 06:11:23,822 - INFO - Epoch: [34][300/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.6131 (0.4270) Acc@1 77.344 (85.052) Acc@5 98.438 (99.387)
2025-08-28 06:11:23,920 - INFO - Pruning info: sparsity=0.753
2025-08-28 06:11:23,920 - INFO -   Reactivation rate: 0.0015
2025-08-28 06:11:25,637 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.6924 (0.6924) Acc@1 75.781 (75.781) Acc@5 99.219 (99.219)
2025-08-28 06:11:26,548 - INFO - Epoch 34:
2025-08-28 06:11:26,548 - INFO -   Train: acc1: 84.8140 | acc5: 99.3780 | loss: 0.4343 | sparsity: 0.7530 | reactivation_rate: 0.0018
2025-08-28 06:11:26,548 - INFO -   Val:   acc1: 74.7500 | acc5: 98.4600 | loss: 0.8007
2025-08-28 06:11:26,548 - INFO -   LR: 0.100000
2025-08-28 06:11:26,560 - INFO - 
Epoch: 35, lr = 0.1
2025-08-28 06:11:26,762 - INFO - Epoch: [35][0/391] Time 0.200 (0.200) Data 0.178 (0.178) Loss 0.3581 (0.3581) Acc@1 88.281 (88.281) Acc@5 96.875 (96.875)
2025-08-28 06:11:28,278 - INFO - Pruning info: sparsity=0.763
2025-08-28 06:11:28,278 - INFO -   Reactivation rate: 0.0022
2025-08-28 06:11:28,708 - INFO - Epoch: [35][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.4880 (0.4226) Acc@1 86.719 (85.891) Acc@5 98.438 (99.281)
2025-08-28 06:11:30,613 - INFO - Epoch: [35][200/391] Time 0.018 (0.020) Data 0.003 (0.003) Loss 0.4348 (0.4217) Acc@1 87.500 (85.654) Acc@5 99.219 (99.320)
2025-08-28 06:11:31,208 - INFO - Pruning info: sparsity=0.763
2025-08-28 06:11:31,208 - INFO -   Reactivation rate: 0.0015
2025-08-28 06:11:32,437 - INFO - Epoch: [35][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3151 (0.4272) Acc@1 90.625 (85.538) Acc@5 100.000 (99.328)
2025-08-28 06:11:34,224 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.8237 (0.8237) Acc@1 71.094 (71.094) Acc@5 97.656 (97.656)
2025-08-28 06:11:35,081 - INFO - Epoch 35:
2025-08-28 06:11:35,081 - INFO -   Train: acc1: 85.4280 | acc5: 99.3580 | loss: 0.4284 | sparsity: 0.7635 | reactivation_rate: 0.0016
2025-08-28 06:11:35,081 - INFO -   Val:   acc1: 76.8000 | acc5: 98.4500 | loss: 0.7686
2025-08-28 06:11:35,081 - INFO -   LR: 0.100000
2025-08-28 06:11:35,092 - INFO - 
Epoch: 36, lr = 0.1
2025-08-28 06:11:35,304 - INFO - Epoch: [36][0/391] Time 0.211 (0.211) Data 0.190 (0.190) Loss 0.4510 (0.4510) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:11:35,345 - INFO - Pruning info: sparsity=0.773
2025-08-28 06:11:35,345 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:11:37,122 - INFO - Epoch: [36][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.4159 (0.4268) Acc@1 82.812 (85.265) Acc@5 100.000 (99.343)
2025-08-28 06:11:38,324 - INFO - Pruning info: sparsity=0.773
2025-08-28 06:11:38,324 - INFO -   Reactivation rate: 0.0017
2025-08-28 06:11:39,000 - INFO - Epoch: [36][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3709 (0.4218) Acc@1 88.281 (85.421) Acc@5 100.000 (99.370)
2025-08-28 06:11:40,908 - INFO - Epoch: [36][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4370 (0.4257) Acc@1 81.250 (85.309) Acc@5 99.219 (99.374)
2025-08-28 06:11:41,283 - INFO - Pruning info: sparsity=0.773
2025-08-28 06:11:41,283 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:11:42,671 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.6331 (0.6331) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-28 06:11:43,588 - INFO - Epoch 36:
2025-08-28 06:11:43,588 - INFO -   Train: acc1: 85.2500 | acc5: 99.3900 | loss: 0.4284 | sparsity: 0.7735 | reactivation_rate: 0.0016
2025-08-28 06:11:43,588 - INFO -   Val:   acc1: 77.2700 | acc5: 98.9800 | loss: 0.6720
2025-08-28 06:11:43,588 - INFO -   LR: 0.100000
2025-08-28 06:11:43,598 - INFO - 
Epoch: 37, lr = 0.1
2025-08-28 06:11:43,818 - INFO - Epoch: [37][0/391] Time 0.219 (0.219) Data 0.196 (0.196) Loss 0.3938 (0.3938) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:11:45,482 - INFO - Pruning info: sparsity=0.783
2025-08-28 06:11:45,482 - INFO -   Reactivation rate: 0.0019
2025-08-28 06:11:45,610 - INFO - Epoch: [37][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4230 (0.4222) Acc@1 86.719 (85.535) Acc@5 100.000 (99.381)
2025-08-28 06:11:47,478 - INFO - Epoch: [37][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3886 (0.4329) Acc@1 88.281 (85.012) Acc@5 99.219 (99.374)
2025-08-28 06:11:48,411 - INFO - Pruning info: sparsity=0.783
2025-08-28 06:11:48,414 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:11:49,280 - INFO - Epoch: [37][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.6498 (0.4264) Acc@1 79.688 (85.291) Acc@5 98.438 (99.403)
2025-08-28 06:11:51,078 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.5109 (0.5109) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:11:51,943 - INFO - Epoch 37:
2025-08-28 06:11:51,944 - INFO -   Train: acc1: 85.2200 | acc5: 99.3840 | loss: 0.4292 | sparsity: 0.7829 | reactivation_rate: 0.0015
2025-08-28 06:11:51,944 - INFO -   Val:   acc1: 79.8300 | acc5: 99.0200 | loss: 0.6127
2025-08-28 06:11:51,944 - INFO -   LR: 0.100000
2025-08-28 06:11:51,954 - INFO - 
Epoch: 38, lr = 0.1
2025-08-28 06:11:52,146 - INFO - Epoch: [38][0/391] Time 0.191 (0.191) Data 0.161 (0.161) Loss 0.3823 (0.3823) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:11:52,504 - INFO - Pruning info: sparsity=0.792
2025-08-28 06:11:52,504 - INFO -   Reactivation rate: 0.0021
2025-08-28 06:11:54,019 - INFO - Epoch: [38][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.4578 (0.4276) Acc@1 85.156 (85.164) Acc@5 99.219 (99.466)
2025-08-28 06:11:55,492 - INFO - Pruning info: sparsity=0.792
2025-08-28 06:11:55,492 - INFO -   Reactivation rate: 0.0014
2025-08-28 06:11:55,851 - INFO - Epoch: [38][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.3511 (0.4231) Acc@1 88.281 (85.436) Acc@5 99.219 (99.429)
2025-08-28 06:11:57,693 - INFO - Epoch: [38][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4556 (0.4303) Acc@1 84.375 (85.195) Acc@5 100.000 (99.395)
2025-08-28 06:11:58,413 - INFO - Pruning info: sparsity=0.792
2025-08-28 06:11:58,413 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:11:59,493 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.7674 (0.7674) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-28 06:12:00,386 - INFO - Epoch 38:
2025-08-28 06:12:00,386 - INFO -   Train: acc1: 85.3140 | acc5: 99.4040 | loss: 0.4284 | sparsity: 0.7919 | reactivation_rate: 0.0014
2025-08-28 06:12:00,386 - INFO -   Val:   acc1: 72.2600 | acc5: 98.4800 | loss: 0.9667
2025-08-28 06:12:00,386 - INFO -   LR: 0.100000
2025-08-28 06:12:00,396 - INFO - 
Epoch: 39, lr = 0.1
2025-08-28 06:12:00,599 - INFO - Epoch: [39][0/391] Time 0.202 (0.202) Data 0.182 (0.182) Loss 0.3276 (0.3276) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:12:02,478 - INFO - Epoch: [39][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.4337 (0.4144) Acc@1 84.375 (85.883) Acc@5 98.438 (99.459)
2025-08-28 06:12:02,702 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:12:02,702 - INFO -   Reactivation rate: 0.0016
2025-08-28 06:12:04,364 - INFO - Epoch: [39][200/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.5362 (0.4223) Acc@1 84.375 (85.525) Acc@5 98.438 (99.436)
2025-08-28 06:12:05,651 - INFO - Pruning info: sparsity=0.800
2025-08-28 06:12:05,651 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:12:06,191 - INFO - Epoch: [39][300/391] Time 0.020 (0.019) Data 0.008 (0.003) Loss 0.4785 (0.4216) Acc@1 84.375 (85.496) Acc@5 97.656 (99.460)
2025-08-28 06:12:08,027 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.5123 (0.5123) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:12:08,893 - INFO - Epoch 39:
2025-08-28 06:12:08,894 - INFO -   Train: acc1: 85.3540 | acc5: 99.4300 | loss: 0.4272 | sparsity: 0.8005 | reactivation_rate: 0.0013
2025-08-28 06:12:08,894 - INFO -   Val:   acc1: 81.5300 | acc5: 99.0800 | loss: 0.5468
2025-08-28 06:12:08,894 - INFO -   LR: 0.100000
2025-08-28 06:12:08,905 - INFO - 
Epoch: 40, lr = 0.1
2025-08-28 06:12:09,112 - INFO - Epoch: [40][0/391] Time 0.206 (0.206) Data 0.172 (0.172) Loss 0.4926 (0.4926) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 06:12:09,846 - INFO - Pruning info: sparsity=0.809
2025-08-28 06:12:09,847 - INFO -   Reactivation rate: 0.0018
2025-08-28 06:12:11,004 - INFO - Epoch: [40][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.3680 (0.4129) Acc@1 86.719 (85.497) Acc@5 100.000 (99.505)
2025-08-28 06:12:12,913 - INFO - Pruning info: sparsity=0.809
2025-08-28 06:12:12,913 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:12:12,934 - INFO - Epoch: [40][200/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.4388 (0.4106) Acc@1 87.500 (85.677) Acc@5 99.219 (99.468)
2025-08-28 06:12:14,922 - INFO - Epoch: [40][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5004 (0.4176) Acc@1 82.031 (85.517) Acc@5 100.000 (99.447)
2025-08-28 06:12:16,076 - INFO - Pruning info: sparsity=0.809
2025-08-28 06:12:16,076 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:12:16,874 - INFO - Test: [0/79] Time 0.168 (0.168) Loss 0.5177 (0.5177) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-28 06:12:17,731 - INFO - Epoch 40:
2025-08-28 06:12:17,731 - INFO -   Train: acc1: 85.5080 | acc5: 99.4280 | loss: 0.4199 | sparsity: 0.8085 | reactivation_rate: 0.0012
2025-08-28 06:12:17,731 - INFO -   Val:   acc1: 82.3300 | acc5: 99.1400 | loss: 0.5202
2025-08-28 06:12:17,731 - INFO -   LR: 0.100000
2025-08-28 06:12:17,778 - INFO - 
Epoch: 41, lr = 0.1
2025-08-28 06:12:17,968 - INFO - Epoch: [41][0/391] Time 0.190 (0.190) Data 0.162 (0.162) Loss 0.3539 (0.3539) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 06:12:19,942 - INFO - Epoch: [41][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.4788 (0.4146) Acc@1 86.719 (85.760) Acc@5 100.000 (99.451)
2025-08-28 06:12:20,428 - INFO - Pruning info: sparsity=0.816
2025-08-28 06:12:20,428 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:12:21,834 - INFO - Epoch: [41][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3498 (0.4202) Acc@1 89.062 (85.607) Acc@5 100.000 (99.436)
2025-08-28 06:12:23,580 - INFO - Pruning info: sparsity=0.816
2025-08-28 06:12:23,581 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:12:23,804 - INFO - Epoch: [41][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3920 (0.4220) Acc@1 84.375 (85.520) Acc@5 100.000 (99.406)
2025-08-28 06:12:25,715 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.5833 (0.5833) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:12:26,601 - INFO - Epoch 41:
2025-08-28 06:12:26,602 - INFO -   Train: acc1: 85.3320 | acc5: 99.4180 | loss: 0.4277 | sparsity: 0.8162 | reactivation_rate: 0.0012
2025-08-28 06:12:26,602 - INFO -   Val:   acc1: 80.0400 | acc5: 98.3400 | loss: 0.6162
2025-08-28 06:12:26,602 - INFO -   LR: 0.100000
2025-08-28 06:12:26,612 - INFO - 
Epoch: 42, lr = 0.1
2025-08-28 06:12:26,809 - INFO - Epoch: [42][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.4193 (0.4193) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:12:27,922 - INFO - Pruning info: sparsity=0.823
2025-08-28 06:12:27,922 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:12:28,708 - INFO - Epoch: [42][100/391] Time 0.018 (0.021) Data 0.008 (0.004) Loss 0.6519 (0.4051) Acc@1 76.562 (86.038) Acc@5 100.000 (99.528)
2025-08-28 06:12:30,713 - INFO - Epoch: [42][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.6016 (0.4143) Acc@1 78.125 (85.673) Acc@5 99.219 (99.522)
2025-08-28 06:12:31,083 - INFO - Pruning info: sparsity=0.823
2025-08-28 06:12:31,083 - INFO -   Reactivation rate: 0.0011
2025-08-28 06:12:32,731 - INFO - Epoch: [42][300/391] Time 0.015 (0.020) Data 0.004 (0.002) Loss 0.3020 (0.4223) Acc@1 90.625 (85.444) Acc@5 100.000 (99.476)
2025-08-28 06:12:34,196 - INFO - Pruning info: sparsity=0.823
2025-08-28 06:12:34,197 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:12:34,609 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.5564 (0.5564) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:12:35,441 - INFO - Epoch 42:
2025-08-28 06:12:35,441 - INFO -   Train: acc1: 85.2880 | acc5: 99.4420 | loss: 0.4264 | sparsity: 0.8233 | reactivation_rate: 0.0011
2025-08-28 06:12:35,441 - INFO -   Val:   acc1: 79.9500 | acc5: 99.2000 | loss: 0.5937
2025-08-28 06:12:35,441 - INFO -   LR: 0.100000
2025-08-28 06:12:35,453 - INFO - 
Epoch: 43, lr = 0.1
2025-08-28 06:12:35,619 - INFO - Epoch: [43][0/391] Time 0.165 (0.165) Data 0.140 (0.140) Loss 0.2828 (0.2828) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:12:37,594 - INFO - Epoch: [43][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4261 (0.4295) Acc@1 85.156 (85.381) Acc@5 99.219 (99.435)
2025-08-28 06:12:38,489 - INFO - Pruning info: sparsity=0.830
2025-08-28 06:12:38,490 - INFO -   Reactivation rate: 0.0011
2025-08-28 06:12:39,607 - INFO - Epoch: [43][200/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.3420 (0.4146) Acc@1 89.844 (85.751) Acc@5 100.000 (99.475)
2025-08-28 06:12:41,462 - INFO - Epoch: [43][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.2880 (0.4170) Acc@1 89.844 (85.688) Acc@5 100.000 (99.478)
2025-08-28 06:12:41,594 - INFO - Pruning info: sparsity=0.830
2025-08-28 06:12:41,595 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:12:43,485 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.6992 (0.6992) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:12:44,343 - INFO - Epoch 43:
2025-08-28 06:12:44,343 - INFO -   Train: acc1: 85.6140 | acc5: 99.4700 | loss: 0.4197 | sparsity: 0.8301 | reactivation_rate: 0.0010
2025-08-28 06:12:44,343 - INFO -   Val:   acc1: 81.2500 | acc5: 98.9000 | loss: 0.5811
2025-08-28 06:12:44,343 - INFO -   LR: 0.100000
2025-08-28 06:12:44,353 - INFO - 
Epoch: 44, lr = 0.1
2025-08-28 06:12:44,555 - INFO - Epoch: [44][0/391] Time 0.200 (0.200) Data 0.179 (0.179) Loss 0.3715 (0.3715) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:12:45,955 - INFO - Pruning info: sparsity=0.836
2025-08-28 06:12:45,955 - INFO -   Reactivation rate: 0.0013
2025-08-28 06:12:46,392 - INFO - Epoch: [44][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.3545 (0.4166) Acc@1 89.844 (85.705) Acc@5 99.219 (99.404)
2025-08-28 06:12:48,418 - INFO - Epoch: [44][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4179 (0.4182) Acc@1 83.594 (85.708) Acc@5 99.219 (99.398)
2025-08-28 06:12:49,150 - INFO - Pruning info: sparsity=0.836
2025-08-28 06:12:49,150 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:12:50,351 - INFO - Epoch: [44][300/391] Time 0.053 (0.020) Data 0.000 (0.003) Loss 0.3480 (0.4190) Acc@1 88.281 (85.769) Acc@5 100.000 (99.403)
2025-08-28 06:12:52,144 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.6882 (0.6882) Acc@1 83.594 (83.594) Acc@5 97.656 (97.656)
2025-08-28 06:12:53,009 - INFO - Epoch 44:
2025-08-28 06:12:53,009 - INFO -   Train: acc1: 85.6220 | acc5: 99.4300 | loss: 0.4205 | sparsity: 0.8364 | reactivation_rate: 0.0010
2025-08-28 06:12:53,009 - INFO -   Val:   acc1: 80.2200 | acc5: 98.8600 | loss: 0.6061
2025-08-28 06:12:53,009 - INFO -   LR: 0.100000
2025-08-28 06:12:53,019 - INFO - 
Epoch: 45, lr = 0.1
2025-08-28 06:12:53,212 - INFO - Epoch: [45][0/391] Time 0.192 (0.192) Data 0.168 (0.168) Loss 0.3162 (0.3162) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 06:12:53,313 - INFO - Pruning info: sparsity=0.842
2025-08-28 06:12:53,313 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:12:55,041 - INFO - Epoch: [45][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.6862 (0.4168) Acc@1 82.031 (85.968) Acc@5 99.219 (99.296)
2025-08-28 06:12:56,182 - INFO - Pruning info: sparsity=0.842
2025-08-28 06:12:56,182 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:12:56,902 - INFO - Epoch: [45][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4130 (0.4274) Acc@1 85.156 (85.424) Acc@5 99.219 (99.308)
2025-08-28 06:12:58,924 - INFO - Epoch: [45][300/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3614 (0.4205) Acc@1 87.500 (85.600) Acc@5 99.219 (99.364)
2025-08-28 06:12:59,406 - INFO - Pruning info: sparsity=0.842
2025-08-28 06:12:59,406 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:13:00,825 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.6674 (0.6674) Acc@1 78.125 (78.125) Acc@5 96.875 (96.875)
2025-08-28 06:13:01,687 - INFO - Epoch 45:
2025-08-28 06:13:01,687 - INFO -   Train: acc1: 85.4820 | acc5: 99.3680 | loss: 0.4215 | sparsity: 0.8424 | reactivation_rate: 0.0009
2025-08-28 06:13:01,687 - INFO -   Val:   acc1: 74.8700 | acc5: 95.7600 | loss: 0.8461
2025-08-28 06:13:01,687 - INFO -   LR: 0.100000
2025-08-28 06:13:01,700 - INFO - 
Epoch: 46, lr = 0.1
2025-08-28 06:13:01,914 - INFO - Epoch: [46][0/391] Time 0.213 (0.213) Data 0.194 (0.194) Loss 0.4034 (0.4034) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:13:03,611 - INFO - Pruning info: sparsity=0.848
2025-08-28 06:13:03,611 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:13:03,753 - INFO - Epoch: [46][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.3788 (0.3992) Acc@1 82.812 (86.402) Acc@5 100.000 (99.544)
2025-08-28 06:13:05,791 - INFO - Epoch: [46][200/391] Time 0.033 (0.020) Data 0.013 (0.003) Loss 0.4281 (0.4096) Acc@1 82.812 (85.856) Acc@5 99.219 (99.487)
2025-08-28 06:13:06,852 - INFO - Pruning info: sparsity=0.848
2025-08-28 06:13:06,852 - INFO -   Reactivation rate: 0.0009
2025-08-28 06:13:07,786 - INFO - Epoch: [46][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3953 (0.4130) Acc@1 86.719 (85.893) Acc@5 100.000 (99.445)
2025-08-28 06:13:09,661 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.8895 (0.8895) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-28 06:13:10,493 - INFO - Epoch 46:
2025-08-28 06:13:10,493 - INFO -   Train: acc1: 85.5620 | acc5: 99.4260 | loss: 0.4200 | sparsity: 0.8480 | reactivation_rate: 0.0009
2025-08-28 06:13:10,493 - INFO -   Val:   acc1: 75.4900 | acc5: 98.6400 | loss: 0.8468
2025-08-28 06:13:10,493 - INFO -   LR: 0.100000
2025-08-28 06:13:10,506 - INFO - 
Epoch: 47, lr = 0.1
2025-08-28 06:13:10,685 - INFO - Epoch: [47][0/391] Time 0.178 (0.178) Data 0.158 (0.158) Loss 0.4440 (0.4440) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:13:11,129 - INFO - Pruning info: sparsity=0.853
2025-08-28 06:13:11,129 - INFO -   Reactivation rate: 0.0012
2025-08-28 06:13:12,585 - INFO - Epoch: [47][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.4386 (0.4083) Acc@1 89.844 (85.953) Acc@5 99.219 (99.582)
2025-08-28 06:13:14,140 - INFO - Pruning info: sparsity=0.853
2025-08-28 06:13:14,141 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:13:14,476 - INFO - Epoch: [47][200/391] Time 0.027 (0.020) Data 0.001 (0.003) Loss 0.5479 (0.4156) Acc@1 79.688 (85.708) Acc@5 100.000 (99.518)
2025-08-28 06:13:16,395 - INFO - Epoch: [47][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.4091 (0.4197) Acc@1 80.469 (85.613) Acc@5 100.000 (99.478)
2025-08-28 06:13:17,235 - INFO - Pruning info: sparsity=0.853
2025-08-28 06:13:17,236 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:13:18,323 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.7207 (0.7207) Acc@1 73.438 (73.438) Acc@5 99.219 (99.219)
2025-08-28 06:13:19,216 - INFO - Epoch 47:
2025-08-28 06:13:19,216 - INFO -   Train: acc1: 85.4440 | acc5: 99.4440 | loss: 0.4238 | sparsity: 0.8532 | reactivation_rate: 0.0008
2025-08-28 06:13:19,216 - INFO -   Val:   acc1: 74.5200 | acc5: 98.4100 | loss: 0.7862
2025-08-28 06:13:19,216 - INFO -   LR: 0.100000
2025-08-28 06:13:19,228 - INFO - 
Epoch: 48, lr = 0.1
2025-08-28 06:13:19,425 - INFO - Epoch: [48][0/391] Time 0.196 (0.196) Data 0.153 (0.153) Loss 0.4754 (0.4754) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 06:13:21,363 - INFO - Epoch: [48][100/391] Time 0.026 (0.021) Data 0.003 (0.003) Loss 0.4012 (0.4032) Acc@1 88.281 (86.200) Acc@5 100.000 (99.528)
2025-08-28 06:13:21,585 - INFO - Pruning info: sparsity=0.858
2025-08-28 06:13:21,585 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:13:23,304 - INFO - Epoch: [48][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4061 (0.4030) Acc@1 85.938 (85.961) Acc@5 99.219 (99.510)
2025-08-28 06:13:24,768 - INFO - Pruning info: sparsity=0.858
2025-08-28 06:13:24,768 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:13:25,278 - INFO - Epoch: [48][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4412 (0.4102) Acc@1 85.156 (85.818) Acc@5 99.219 (99.502)
2025-08-28 06:13:27,136 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.4443 (0.4443) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 06:13:28,011 - INFO - Epoch 48:
2025-08-28 06:13:28,011 - INFO -   Train: acc1: 85.6000 | acc5: 99.4860 | loss: 0.4159 | sparsity: 0.8580 | reactivation_rate: 0.0007
2025-08-28 06:13:28,011 - INFO -   Val:   acc1: 81.7200 | acc5: 99.0300 | loss: 0.5376
2025-08-28 06:13:28,011 - INFO -   LR: 0.100000
2025-08-28 06:13:28,022 - INFO - 
Epoch: 49, lr = 0.1
2025-08-28 06:13:28,233 - INFO - Epoch: [49][0/391] Time 0.211 (0.211) Data 0.185 (0.185) Loss 0.5399 (0.5399) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:13:28,970 - INFO - Pruning info: sparsity=0.863
2025-08-28 06:13:28,970 - INFO -   Reactivation rate: 0.0010
2025-08-28 06:13:30,069 - INFO - Epoch: [49][100/391] Time 0.028 (0.020) Data 0.000 (0.004) Loss 0.5019 (0.4122) Acc@1 82.031 (85.907) Acc@5 98.438 (99.513)
2025-08-28 06:13:31,845 - INFO - Epoch: [49][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3605 (0.4129) Acc@1 89.844 (85.743) Acc@5 100.000 (99.448)
2025-08-28 06:13:31,852 - INFO - Pruning info: sparsity=0.863
2025-08-28 06:13:31,852 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:13:33,675 - INFO - Epoch: [49][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4092 (0.4208) Acc@1 85.156 (85.424) Acc@5 100.000 (99.426)
2025-08-28 06:13:34,882 - INFO - Pruning info: sparsity=0.863
2025-08-28 06:13:34,882 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:13:35,635 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.5867 (0.5867) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-28 06:13:36,490 - INFO - Epoch 49:
2025-08-28 06:13:36,490 - INFO -   Train: acc1: 85.4380 | acc5: 99.4320 | loss: 0.4213 | sparsity: 0.8625 | reactivation_rate: 0.0007
2025-08-28 06:13:36,490 - INFO -   Val:   acc1: 80.1700 | acc5: 99.0200 | loss: 0.6219
2025-08-28 06:13:36,490 - INFO -   LR: 0.100000
2025-08-28 06:13:36,502 - INFO - 
Epoch: 50, lr = 0.1
2025-08-28 06:13:36,720 - INFO - Epoch: [50][0/391] Time 0.216 (0.216) Data 0.188 (0.188) Loss 0.2572 (0.2572) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:13:38,625 - INFO - Epoch: [50][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.5918 (0.4118) Acc@1 77.344 (85.651) Acc@5 100.000 (99.489)
2025-08-28 06:13:39,138 - INFO - Pruning info: sparsity=0.867
2025-08-28 06:13:39,138 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:13:40,480 - INFO - Epoch: [50][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2754 (0.4193) Acc@1 89.844 (85.288) Acc@5 100.000 (99.506)
2025-08-28 06:13:42,202 - INFO - Pruning info: sparsity=0.867
2025-08-28 06:13:42,202 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:13:42,348 - INFO - Epoch: [50][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.3750 (0.4218) Acc@1 85.156 (85.177) Acc@5 99.219 (99.473)
2025-08-28 06:13:44,249 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.5759 (0.5759) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:13:45,126 - INFO - Epoch 50:
2025-08-28 06:13:45,126 - INFO -   Train: acc1: 85.2000 | acc5: 99.4460 | loss: 0.4232 | sparsity: 0.8667 | reactivation_rate: 0.0006
2025-08-28 06:13:45,126 - INFO -   Val:   acc1: 81.6100 | acc5: 99.2500 | loss: 0.5477
2025-08-28 06:13:45,126 - INFO -   LR: 0.100000
2025-08-28 06:13:45,171 - INFO - 
Epoch: 51, lr = 0.1
2025-08-28 06:13:45,364 - INFO - Epoch: [51][0/391] Time 0.192 (0.192) Data 0.171 (0.171) Loss 0.4374 (0.4374) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:13:46,452 - INFO - Pruning info: sparsity=0.871
2025-08-28 06:13:46,452 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:13:47,304 - INFO - Epoch: [51][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.4472 (0.4044) Acc@1 84.375 (86.115) Acc@5 100.000 (99.520)
2025-08-28 06:13:49,263 - INFO - Epoch: [51][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4670 (0.4123) Acc@1 84.375 (85.801) Acc@5 98.438 (99.491)
2025-08-28 06:13:49,635 - INFO - Pruning info: sparsity=0.871
2025-08-28 06:13:49,635 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:13:51,284 - INFO - Epoch: [51][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.3303 (0.4181) Acc@1 91.406 (85.577) Acc@5 100.000 (99.463)
2025-08-28 06:13:52,760 - INFO - Pruning info: sparsity=0.871
2025-08-28 06:13:52,760 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:13:53,127 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.7794 (0.7794) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-28 06:13:54,010 - INFO - Epoch 51:
2025-08-28 06:13:54,010 - INFO -   Train: acc1: 85.5540 | acc5: 99.4340 | loss: 0.4211 | sparsity: 0.8705 | reactivation_rate: 0.0006
2025-08-28 06:13:54,010 - INFO -   Val:   acc1: 78.2800 | acc5: 98.6900 | loss: 0.7116
2025-08-28 06:13:54,010 - INFO -   LR: 0.100000
2025-08-28 06:13:54,024 - INFO - 
Epoch: 52, lr = 0.1
2025-08-28 06:13:54,232 - INFO - Epoch: [52][0/391] Time 0.208 (0.208) Data 0.175 (0.175) Loss 0.4253 (0.4253) Acc@1 85.938 (85.938) Acc@5 97.656 (97.656)
2025-08-28 06:13:56,278 - INFO - Epoch: [52][100/391] Time 0.030 (0.022) Data 0.000 (0.004) Loss 0.3565 (0.3984) Acc@1 85.938 (86.231) Acc@5 100.000 (99.459)
2025-08-28 06:13:57,234 - INFO - Pruning info: sparsity=0.874
2025-08-28 06:13:57,234 - INFO -   Reactivation rate: 0.0007
2025-08-28 06:13:58,316 - INFO - Epoch: [52][200/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.4226 (0.4167) Acc@1 84.375 (85.537) Acc@5 99.219 (99.405)
2025-08-28 06:14:00,241 - INFO - Epoch: [52][300/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.3126 (0.4202) Acc@1 87.500 (85.473) Acc@5 100.000 (99.424)
2025-08-28 06:14:00,387 - INFO - Pruning info: sparsity=0.874
2025-08-28 06:14:00,387 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:14:02,125 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.7644 (0.7644) Acc@1 72.656 (72.656) Acc@5 100.000 (100.000)
2025-08-28 06:14:02,987 - INFO - Epoch 52:
2025-08-28 06:14:02,987 - INFO -   Train: acc1: 85.3400 | acc5: 99.4080 | loss: 0.4252 | sparsity: 0.8740 | reactivation_rate: 0.0006
2025-08-28 06:14:02,987 - INFO -   Val:   acc1: 75.5600 | acc5: 98.4600 | loss: 0.7867
2025-08-28 06:14:02,987 - INFO -   LR: 0.100000
2025-08-28 06:14:03,001 - INFO - 
Epoch: 53, lr = 0.1
2025-08-28 06:14:03,205 - INFO - Epoch: [53][0/391] Time 0.203 (0.203) Data 0.171 (0.171) Loss 0.4377 (0.4377) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:14:04,655 - INFO - Pruning info: sparsity=0.877
2025-08-28 06:14:04,655 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:14:05,145 - INFO - Epoch: [53][100/391] Time 0.027 (0.021) Data 0.000 (0.003) Loss 0.4540 (0.4094) Acc@1 82.812 (86.077) Acc@5 99.219 (99.420)
2025-08-28 06:14:07,125 - INFO - Epoch: [53][200/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.4796 (0.4172) Acc@1 80.469 (85.654) Acc@5 100.000 (99.413)
2025-08-28 06:14:07,802 - INFO - Pruning info: sparsity=0.877
2025-08-28 06:14:07,802 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:14:08,983 - INFO - Epoch: [53][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.3135 (0.4201) Acc@1 89.844 (85.501) Acc@5 100.000 (99.395)
2025-08-28 06:14:10,889 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.5554 (0.5554) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:14:11,777 - INFO - Epoch 53:
2025-08-28 06:14:11,777 - INFO -   Train: acc1: 85.3440 | acc5: 99.3980 | loss: 0.4244 | sparsity: 0.8773 | reactivation_rate: 0.0005
2025-08-28 06:14:11,777 - INFO -   Val:   acc1: 80.1000 | acc5: 98.8500 | loss: 0.6086
2025-08-28 06:14:11,777 - INFO -   LR: 0.100000
2025-08-28 06:14:11,790 - INFO - 
Epoch: 54, lr = 0.1
2025-08-28 06:14:12,015 - INFO - Epoch: [54][0/391] Time 0.224 (0.224) Data 0.192 (0.192) Loss 0.3426 (0.3426) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:14:12,105 - INFO - Pruning info: sparsity=0.880
2025-08-28 06:14:12,105 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:14:13,945 - INFO - Epoch: [54][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.3093 (0.4173) Acc@1 91.406 (85.752) Acc@5 99.219 (99.381)
2025-08-28 06:14:15,145 - INFO - Pruning info: sparsity=0.880
2025-08-28 06:14:15,145 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:14:15,832 - INFO - Epoch: [54][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.4593 (0.4175) Acc@1 78.125 (85.623) Acc@5 100.000 (99.425)
2025-08-28 06:14:17,729 - INFO - Epoch: [54][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4264 (0.4134) Acc@1 83.594 (85.764) Acc@5 98.438 (99.460)
2025-08-28 06:14:18,250 - INFO - Pruning info: sparsity=0.880
2025-08-28 06:14:18,251 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:14:19,671 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.4983 (0.4983) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:14:20,518 - INFO - Epoch 54:
2025-08-28 06:14:20,518 - INFO -   Train: acc1: 85.5300 | acc5: 99.4620 | loss: 0.4183 | sparsity: 0.8802 | reactivation_rate: 0.0005
2025-08-28 06:14:20,518 - INFO -   Val:   acc1: 81.1900 | acc5: 99.1400 | loss: 0.5703
2025-08-28 06:14:20,518 - INFO -   LR: 0.100000
2025-08-28 06:14:20,531 - INFO - 
Epoch: 55, lr = 0.1
2025-08-28 06:14:20,743 - INFO - Epoch: [55][0/391] Time 0.210 (0.210) Data 0.191 (0.191) Loss 0.2934 (0.2934) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:14:22,582 - INFO - Pruning info: sparsity=0.883
2025-08-28 06:14:22,583 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:14:22,688 - INFO - Epoch: [55][100/391] Time 0.021 (0.021) Data 0.001 (0.003) Loss 0.4947 (0.4186) Acc@1 81.250 (85.868) Acc@5 99.219 (99.381)
2025-08-28 06:14:24,654 - INFO - Epoch: [55][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.5256 (0.4214) Acc@1 78.906 (85.650) Acc@5 99.219 (99.429)
2025-08-28 06:14:25,648 - INFO - Pruning info: sparsity=0.883
2025-08-28 06:14:25,649 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:14:26,502 - INFO - Epoch: [55][300/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.3714 (0.4195) Acc@1 86.719 (85.642) Acc@5 99.219 (99.437)
2025-08-28 06:14:28,332 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5069 (0.5069) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:14:29,168 - INFO - Epoch 55:
2025-08-28 06:14:29,168 - INFO -   Train: acc1: 85.4980 | acc5: 99.4100 | loss: 0.4232 | sparsity: 0.8829 | reactivation_rate: 0.0005
2025-08-28 06:14:29,168 - INFO -   Val:   acc1: 80.6200 | acc5: 99.1000 | loss: 0.5815
2025-08-28 06:14:29,168 - INFO -   LR: 0.100000
2025-08-28 06:14:29,180 - INFO - 
Epoch: 56, lr = 0.1
2025-08-28 06:14:29,381 - INFO - Epoch: [56][0/391] Time 0.199 (0.199) Data 0.182 (0.182) Loss 0.3831 (0.3831) Acc@1 89.062 (89.062) Acc@5 98.438 (98.438)
2025-08-28 06:14:29,831 - INFO - Pruning info: sparsity=0.885
2025-08-28 06:14:29,831 - INFO -   Reactivation rate: 0.0008
2025-08-28 06:14:31,268 - INFO - Epoch: [56][100/391] Time 0.015 (0.021) Data 0.003 (0.003) Loss 0.3516 (0.4093) Acc@1 86.719 (85.806) Acc@5 99.219 (99.497)
2025-08-28 06:14:32,801 - INFO - Pruning info: sparsity=0.885
2025-08-28 06:14:32,801 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:14:33,099 - INFO - Epoch: [56][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4561 (0.4188) Acc@1 85.156 (85.607) Acc@5 99.219 (99.440)
2025-08-28 06:14:34,948 - INFO - Epoch: [56][300/391] Time 0.031 (0.019) Data 0.002 (0.003) Loss 0.3976 (0.4202) Acc@1 85.156 (85.610) Acc@5 99.219 (99.460)
2025-08-28 06:14:35,769 - INFO - Pruning info: sparsity=0.885
2025-08-28 06:14:35,769 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:14:36,825 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.6492 (0.6492) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 06:14:37,653 - INFO - Epoch 56:
2025-08-28 06:14:37,653 - INFO -   Train: acc1: 85.4600 | acc5: 99.4160 | loss: 0.4224 | sparsity: 0.8854 | reactivation_rate: 0.0004
2025-08-28 06:14:37,653 - INFO -   Val:   acc1: 77.9100 | acc5: 98.8600 | loss: 0.6773
2025-08-28 06:14:37,653 - INFO -   LR: 0.100000
2025-08-28 06:14:37,666 - INFO - 
Epoch: 57, lr = 0.1
2025-08-28 06:14:37,840 - INFO - Epoch: [57][0/391] Time 0.172 (0.172) Data 0.149 (0.149) Loss 0.2973 (0.2973) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:14:39,789 - INFO - Epoch: [57][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4218 (0.4181) Acc@1 85.938 (85.497) Acc@5 99.219 (99.389)
2025-08-28 06:14:40,025 - INFO - Pruning info: sparsity=0.888
2025-08-28 06:14:40,025 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:14:41,785 - INFO - Epoch: [57][200/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.4825 (0.4267) Acc@1 82.812 (85.086) Acc@5 100.000 (99.421)
2025-08-28 06:14:43,141 - INFO - Pruning info: sparsity=0.888
2025-08-28 06:14:43,141 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:14:43,707 - INFO - Epoch: [57][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4351 (0.4237) Acc@1 85.156 (85.299) Acc@5 100.000 (99.434)
2025-08-28 06:14:45,611 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.4257 (0.4257) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-28 06:14:46,463 - INFO - Epoch 57:
2025-08-28 06:14:46,463 - INFO -   Train: acc1: 85.3880 | acc5: 99.4080 | loss: 0.4241 | sparsity: 0.8876 | reactivation_rate: 0.0004
2025-08-28 06:14:46,464 - INFO -   Val:   acc1: 82.8400 | acc5: 99.3000 | loss: 0.5125
2025-08-28 06:14:46,464 - INFO -   LR: 0.100000
2025-08-28 06:14:46,513 - INFO - Checkpoint saved: epoch=57, metric=82.8400
2025-08-28 06:14:46,545 - INFO - 
Epoch: 58, lr = 0.1
2025-08-28 06:14:46,720 - INFO - Epoch: [58][0/391] Time 0.174 (0.174) Data 0.147 (0.147) Loss 0.4184 (0.4184) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-28 06:14:47,527 - INFO - Pruning info: sparsity=0.890
2025-08-28 06:14:47,527 - INFO -   Reactivation rate: 0.0006
2025-08-28 06:14:48,588 - INFO - Epoch: [58][100/391] Time 0.018 (0.020) Data 0.002 (0.003) Loss 0.3465 (0.4231) Acc@1 89.844 (85.381) Acc@5 98.438 (99.366)
2025-08-28 06:14:50,496 - INFO - Epoch: [58][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.4995 (0.4245) Acc@1 83.594 (85.339) Acc@5 99.219 (99.378)
2025-08-28 06:14:50,515 - INFO - Pruning info: sparsity=0.890
2025-08-28 06:14:50,515 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:14:52,311 - INFO - Epoch: [58][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4042 (0.4285) Acc@1 89.062 (85.252) Acc@5 100.000 (99.356)
2025-08-28 06:14:53,585 - INFO - Pruning info: sparsity=0.890
2025-08-28 06:14:53,585 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:14:54,310 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.4507 (0.4507) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:14:55,198 - INFO - Epoch 58:
2025-08-28 06:14:55,198 - INFO -   Train: acc1: 85.3840 | acc5: 99.3980 | loss: 0.4258 | sparsity: 0.8895 | reactivation_rate: 0.0004
2025-08-28 06:14:55,198 - INFO -   Val:   acc1: 82.8500 | acc5: 99.1700 | loss: 0.5019
2025-08-28 06:14:55,198 - INFO -   LR: 0.100000
2025-08-28 06:14:55,244 - INFO - Checkpoint saved: epoch=58, metric=82.8500
2025-08-28 06:14:55,278 - INFO - 
Epoch: 59, lr = 0.1
2025-08-28 06:14:55,453 - INFO - Epoch: [59][0/391] Time 0.174 (0.174) Data 0.157 (0.157) Loss 0.4724 (0.4724) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:14:57,341 - INFO - Epoch: [59][100/391] Time 0.015 (0.020) Data 0.004 (0.003) Loss 0.4410 (0.4109) Acc@1 85.938 (85.767) Acc@5 99.219 (99.482)
2025-08-28 06:14:57,943 - INFO - Pruning info: sparsity=0.891
2025-08-28 06:14:57,943 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:14:59,178 - INFO - Epoch: [59][200/391] Time 0.027 (0.019) Data 0.000 (0.002) Loss 0.5031 (0.4204) Acc@1 82.812 (85.370) Acc@5 97.656 (99.440)
2025-08-28 06:15:00,875 - INFO - Pruning info: sparsity=0.891
2025-08-28 06:15:00,875 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:15:01,053 - INFO - Epoch: [59][300/391] Time 0.015 (0.019) Data 0.000 (0.002) Loss 0.3840 (0.4290) Acc@1 85.156 (85.125) Acc@5 100.000 (99.395)
2025-08-28 06:15:02,880 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.6565 (0.6565) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 06:15:03,747 - INFO - Epoch 59:
2025-08-28 06:15:03,747 - INFO -   Train: acc1: 85.2140 | acc5: 99.4240 | loss: 0.4269 | sparsity: 0.8913 | reactivation_rate: 0.0004
2025-08-28 06:15:03,747 - INFO -   Val:   acc1: 75.0700 | acc5: 98.4700 | loss: 0.8218
2025-08-28 06:15:03,747 - INFO -   LR: 0.100000
2025-08-28 06:15:03,759 - INFO - 
Epoch: 60, lr = 0.1
2025-08-28 06:15:03,968 - INFO - Epoch: [60][0/391] Time 0.208 (0.208) Data 0.173 (0.173) Loss 0.3492 (0.3492) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:15:05,102 - INFO - Pruning info: sparsity=0.893
2025-08-28 06:15:05,102 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:15:05,869 - INFO - Epoch: [60][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4464 (0.4203) Acc@1 84.375 (85.234) Acc@5 99.219 (99.505)
2025-08-28 06:15:07,835 - INFO - Epoch: [60][200/391] Time 0.035 (0.020) Data 0.008 (0.003) Loss 0.4107 (0.4268) Acc@1 83.594 (84.958) Acc@5 100.000 (99.429)
2025-08-28 06:15:08,216 - INFO - Pruning info: sparsity=0.893
2025-08-28 06:15:08,216 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:15:09,778 - INFO - Epoch: [60][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.4212 (0.4244) Acc@1 85.938 (85.159) Acc@5 99.219 (99.403)
2025-08-28 06:15:11,256 - INFO - Pruning info: sparsity=0.893
2025-08-28 06:15:11,256 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:15:11,618 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.7727 (0.7727) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-28 06:15:12,465 - INFO - Epoch 60:
2025-08-28 06:15:12,466 - INFO -   Train: acc1: 85.2460 | acc5: 99.4380 | loss: 0.4233 | sparsity: 0.8928 | reactivation_rate: 0.0003
2025-08-28 06:15:12,466 - INFO -   Val:   acc1: 77.5600 | acc5: 97.7000 | loss: 0.7461
2025-08-28 06:15:12,466 - INFO -   LR: 0.100000
2025-08-28 06:15:12,515 - INFO - 
Epoch: 61, lr = 0.1
2025-08-28 06:15:12,705 - INFO - Epoch: [61][0/391] Time 0.190 (0.190) Data 0.172 (0.172) Loss 0.4411 (0.4411) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:15:14,668 - INFO - Epoch: [61][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.4076 (0.3967) Acc@1 87.500 (86.471) Acc@5 99.219 (99.466)
2025-08-28 06:15:15,594 - INFO - Pruning info: sparsity=0.894
2025-08-28 06:15:15,594 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:15:16,604 - INFO - Epoch: [61][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4262 (0.4154) Acc@1 86.719 (85.685) Acc@5 100.000 (99.421)
2025-08-28 06:15:18,528 - INFO - Epoch: [61][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5542 (0.4217) Acc@1 78.906 (85.387) Acc@5 99.219 (99.408)
2025-08-28 06:15:18,695 - INFO - Pruning info: sparsity=0.894
2025-08-28 06:15:18,695 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:15:20,543 - INFO - Test: [0/79] Time 0.176 (0.176) Loss 0.4875 (0.4875) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:15:21,405 - INFO - Epoch 61:
2025-08-28 06:15:21,406 - INFO -   Train: acc1: 85.2060 | acc5: 99.3880 | loss: 0.4282 | sparsity: 0.8941 | reactivation_rate: 0.0003
2025-08-28 06:15:21,406 - INFO -   Val:   acc1: 81.6000 | acc5: 99.2300 | loss: 0.5463
2025-08-28 06:15:21,406 - INFO -   LR: 0.100000
2025-08-28 06:15:21,419 - INFO - 
Epoch: 62, lr = 0.1
2025-08-28 06:15:21,638 - INFO - Epoch: [62][0/391] Time 0.218 (0.218) Data 0.185 (0.185) Loss 0.3677 (0.3677) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:15:23,055 - INFO - Pruning info: sparsity=0.895
2025-08-28 06:15:23,055 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:15:23,512 - INFO - Epoch: [62][100/391] Time 0.025 (0.021) Data 0.003 (0.004) Loss 0.4759 (0.4077) Acc@1 84.375 (85.829) Acc@5 100.000 (99.513)
2025-08-28 06:15:25,445 - INFO - Epoch: [62][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3613 (0.4074) Acc@1 91.406 (86.101) Acc@5 100.000 (99.499)
2025-08-28 06:15:26,186 - INFO - Pruning info: sparsity=0.895
2025-08-28 06:15:26,186 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:15:27,440 - INFO - Epoch: [62][300/391] Time 0.017 (0.020) Data 0.001 (0.002) Loss 0.4078 (0.4165) Acc@1 86.719 (85.795) Acc@5 100.000 (99.452)
2025-08-28 06:15:29,330 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.4603 (0.4603) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 06:15:30,202 - INFO - Epoch 62:
2025-08-28 06:15:30,202 - INFO -   Train: acc1: 85.5960 | acc5: 99.4440 | loss: 0.4212 | sparsity: 0.8953 | reactivation_rate: 0.0003
2025-08-28 06:15:30,202 - INFO -   Val:   acc1: 83.1500 | acc5: 98.7700 | loss: 0.5182
2025-08-28 06:15:30,202 - INFO -   LR: 0.100000
2025-08-28 06:15:30,249 - INFO - Checkpoint saved: epoch=62, metric=83.1500
2025-08-28 06:15:30,283 - INFO - 
Epoch: 63, lr = 0.1
2025-08-28 06:15:30,463 - INFO - Epoch: [63][0/391] Time 0.179 (0.179) Data 0.157 (0.157) Loss 0.3210 (0.3210) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:15:30,615 - INFO - Pruning info: sparsity=0.896
2025-08-28 06:15:30,615 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:15:32,398 - INFO - Epoch: [63][100/391] Time 0.018 (0.021) Data 0.001 (0.003) Loss 0.4959 (0.3971) Acc@1 82.812 (86.270) Acc@5 99.219 (99.489)
2025-08-28 06:15:33,601 - INFO - Pruning info: sparsity=0.896
2025-08-28 06:15:33,601 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:15:34,243 - INFO - Epoch: [63][200/391] Time 0.032 (0.020) Data 0.013 (0.003) Loss 0.4839 (0.4081) Acc@1 83.594 (85.798) Acc@5 100.000 (99.502)
2025-08-28 06:15:36,205 - INFO - Epoch: [63][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.3502 (0.4186) Acc@1 89.062 (85.514) Acc@5 100.000 (99.468)
2025-08-28 06:15:36,699 - INFO - Pruning info: sparsity=0.896
2025-08-28 06:15:36,699 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:15:38,090 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.5863 (0.5863) Acc@1 83.594 (83.594) Acc@5 97.656 (97.656)
2025-08-28 06:15:38,939 - INFO - Epoch 63:
2025-08-28 06:15:38,939 - INFO -   Train: acc1: 85.4560 | acc5: 99.4520 | loss: 0.4214 | sparsity: 0.8963 | reactivation_rate: 0.0003
2025-08-28 06:15:38,939 - INFO -   Val:   acc1: 80.5200 | acc5: 98.6500 | loss: 0.5912
2025-08-28 06:15:38,939 - INFO -   LR: 0.100000
2025-08-28 06:15:38,952 - INFO - 
Epoch: 64, lr = 0.1
2025-08-28 06:15:39,166 - INFO - Epoch: [64][0/391] Time 0.213 (0.213) Data 0.180 (0.180) Loss 0.2812 (0.2812) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:15:40,977 - INFO - Pruning info: sparsity=0.897
2025-08-28 06:15:40,977 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:15:41,058 - INFO - Epoch: [64][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4300 (0.4233) Acc@1 84.375 (85.620) Acc@5 100.000 (99.412)
2025-08-28 06:15:42,964 - INFO - Epoch: [64][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.4338 (0.4287) Acc@1 85.938 (85.257) Acc@5 100.000 (99.378)
2025-08-28 06:15:44,015 - INFO - Pruning info: sparsity=0.897
2025-08-28 06:15:44,015 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:15:44,783 - INFO - Epoch: [64][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.5316 (0.4278) Acc@1 80.469 (85.133) Acc@5 98.438 (99.426)
2025-08-28 06:15:46,681 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.7339 (0.7339) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 06:15:47,530 - INFO - Epoch 64:
2025-08-28 06:15:47,530 - INFO -   Train: acc1: 85.2640 | acc5: 99.3840 | loss: 0.4255 | sparsity: 0.8972 | reactivation_rate: 0.0003
2025-08-28 06:15:47,530 - INFO -   Val:   acc1: 76.8500 | acc5: 98.6800 | loss: 0.7255
2025-08-28 06:15:47,530 - INFO -   LR: 0.100000
2025-08-28 06:15:47,543 - INFO - 
Epoch: 65, lr = 0.1
2025-08-28 06:15:47,742 - INFO - Epoch: [65][0/391] Time 0.198 (0.198) Data 0.170 (0.170) Loss 0.3311 (0.3311) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:15:48,217 - INFO - Pruning info: sparsity=0.898
2025-08-28 06:15:48,217 - INFO -   Reactivation rate: 0.0005
2025-08-28 06:15:49,709 - INFO - Epoch: [65][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4353 (0.4255) Acc@1 80.469 (85.489) Acc@5 99.219 (99.404)
2025-08-28 06:15:51,384 - INFO - Pruning info: sparsity=0.898
2025-08-28 06:15:51,384 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:15:51,669 - INFO - Epoch: [65][200/391] Time 0.014 (0.021) Data 0.000 (0.002) Loss 0.4789 (0.4254) Acc@1 81.250 (85.362) Acc@5 100.000 (99.390)
2025-08-28 06:15:53,698 - INFO - Epoch: [65][300/391] Time 0.019 (0.020) Data 0.002 (0.002) Loss 0.3943 (0.4264) Acc@1 86.719 (85.408) Acc@5 98.438 (99.400)
2025-08-28 06:15:54,538 - INFO - Pruning info: sparsity=0.898
2025-08-28 06:15:54,538 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:15:55,572 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.6948 (0.6948) Acc@1 75.781 (75.781) Acc@5 100.000 (100.000)
2025-08-28 06:15:56,438 - INFO - Epoch 65:
2025-08-28 06:15:56,439 - INFO -   Train: acc1: 85.3240 | acc5: 99.4060 | loss: 0.4296 | sparsity: 0.8979 | reactivation_rate: 0.0002
2025-08-28 06:15:56,439 - INFO -   Val:   acc1: 75.9900 | acc5: 99.0900 | loss: 0.6947
2025-08-28 06:15:56,439 - INFO -   LR: 0.100000
2025-08-28 06:15:56,451 - INFO - 
Epoch: 66, lr = 0.1
2025-08-28 06:15:56,641 - INFO - Epoch: [66][0/391] Time 0.189 (0.189) Data 0.161 (0.161) Loss 0.3816 (0.3816) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:15:58,598 - INFO - Epoch: [66][100/391] Time 0.022 (0.021) Data 0.007 (0.003) Loss 0.2694 (0.3987) Acc@1 92.188 (86.200) Acc@5 100.000 (99.528)
2025-08-28 06:15:58,830 - INFO - Pruning info: sparsity=0.898
2025-08-28 06:15:58,831 - INFO -   Reactivation rate: 0.0003
2025-08-28 06:16:00,454 - INFO - Epoch: [66][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.6071 (0.4125) Acc@1 78.125 (85.798) Acc@5 98.438 (99.440)
2025-08-28 06:16:01,865 - INFO - Pruning info: sparsity=0.898
2025-08-28 06:16:01,865 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:16:02,380 - INFO - Epoch: [66][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.5149 (0.4248) Acc@1 82.812 (85.338) Acc@5 98.438 (99.419)
2025-08-28 06:16:04,215 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.4424 (0.4424) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:16:05,060 - INFO - Epoch 66:
2025-08-28 06:16:05,060 - INFO -   Train: acc1: 85.3340 | acc5: 99.4340 | loss: 0.4246 | sparsity: 0.8984 | reactivation_rate: 0.0002
2025-08-28 06:16:05,060 - INFO -   Val:   acc1: 79.8800 | acc5: 99.1500 | loss: 0.5856
2025-08-28 06:16:05,060 - INFO -   LR: 0.100000
2025-08-28 06:16:05,081 - INFO - 
Epoch: 67, lr = 0.1
2025-08-28 06:16:05,280 - INFO - Epoch: [67][0/391] Time 0.198 (0.198) Data 0.177 (0.177) Loss 0.3827 (0.3827) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:16:06,175 - INFO - Pruning info: sparsity=0.899
2025-08-28 06:16:06,175 - INFO -   Reactivation rate: 0.0004
2025-08-28 06:16:07,328 - INFO - Epoch: [67][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.4673 (0.4124) Acc@1 84.375 (85.705) Acc@5 99.219 (99.520)
2025-08-28 06:16:09,295 - INFO - Epoch: [67][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.3920 (0.4247) Acc@1 84.375 (85.292) Acc@5 100.000 (99.475)
2025-08-28 06:16:09,373 - INFO - Pruning info: sparsity=0.899
2025-08-28 06:16:09,373 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:16:11,348 - INFO - Epoch: [67][300/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.3969 (0.4177) Acc@1 87.500 (85.556) Acc@5 97.656 (99.489)
2025-08-28 06:16:12,570 - INFO - Pruning info: sparsity=0.899
2025-08-28 06:16:12,570 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:13,244 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.8869 (0.8869) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-28 06:16:14,123 - INFO - Epoch 67:
2025-08-28 06:16:14,123 - INFO -   Train: acc1: 85.3340 | acc5: 99.4220 | loss: 0.4237 | sparsity: 0.8989 | reactivation_rate: 0.0002
2025-08-28 06:16:14,123 - INFO -   Val:   acc1: 75.2800 | acc5: 98.6100 | loss: 0.8437
2025-08-28 06:16:14,123 - INFO -   LR: 0.100000
2025-08-28 06:16:14,136 - INFO - 
Epoch: 68, lr = 0.1
2025-08-28 06:16:14,342 - INFO - Epoch: [68][0/391] Time 0.206 (0.206) Data 0.175 (0.175) Loss 0.4009 (0.4009) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:16:16,279 - INFO - Epoch: [68][100/391] Time 0.037 (0.021) Data 0.000 (0.004) Loss 0.4667 (0.4152) Acc@1 86.719 (85.713) Acc@5 99.219 (99.474)
2025-08-28 06:16:16,889 - INFO - Pruning info: sparsity=0.899
2025-08-28 06:16:16,889 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:16:18,184 - INFO - Epoch: [68][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4743 (0.4216) Acc@1 83.594 (85.545) Acc@5 100.000 (99.436)
2025-08-28 06:16:19,931 - INFO - Pruning info: sparsity=0.899
2025-08-28 06:16:19,931 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:20,126 - INFO - Epoch: [68][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.5323 (0.4225) Acc@1 83.594 (85.465) Acc@5 98.438 (99.424)
2025-08-28 06:16:22,160 - INFO - Test: [0/79] Time 0.170 (0.170) Loss 0.8042 (0.8042) Acc@1 72.656 (72.656) Acc@5 96.094 (96.094)
2025-08-28 06:16:22,997 - INFO - Epoch 68:
2025-08-28 06:16:22,997 - INFO -   Train: acc1: 85.4320 | acc5: 99.4000 | loss: 0.4219 | sparsity: 0.8993 | reactivation_rate: 0.0002
2025-08-28 06:16:22,997 - INFO -   Val:   acc1: 74.8300 | acc5: 97.6600 | loss: 0.8284
2025-08-28 06:16:22,997 - INFO -   LR: 0.100000
2025-08-28 06:16:23,008 - INFO - 
Epoch: 69, lr = 0.1
2025-08-28 06:16:23,202 - INFO - Epoch: [69][0/391] Time 0.193 (0.193) Data 0.167 (0.167) Loss 0.5015 (0.5015) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-28 06:16:24,294 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:24,294 - INFO -   Reactivation rate: 0.0002
2025-08-28 06:16:25,069 - INFO - Epoch: [69][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.4368 (0.4277) Acc@1 85.156 (85.458) Acc@5 100.000 (99.412)
2025-08-28 06:16:26,902 - INFO - Epoch: [69][200/391] Time 0.043 (0.019) Data 0.032 (0.002) Loss 0.4009 (0.4267) Acc@1 85.156 (85.354) Acc@5 100.000 (99.370)
2025-08-28 06:16:27,269 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:27,269 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:28,706 - INFO - Epoch: [69][300/391] Time 0.038 (0.019) Data 0.017 (0.002) Loss 0.4288 (0.4314) Acc@1 85.156 (85.177) Acc@5 100.000 (99.374)
2025-08-28 06:16:30,172 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:30,172 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:30,550 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.9104 (0.9104) Acc@1 76.562 (76.562) Acc@5 97.656 (97.656)
2025-08-28 06:16:31,408 - INFO - Epoch 69:
2025-08-28 06:16:31,408 - INFO -   Train: acc1: 85.1120 | acc5: 99.3740 | loss: 0.4326 | sparsity: 0.8995 | reactivation_rate: 0.0002
2025-08-28 06:16:31,408 - INFO -   Val:   acc1: 72.6100 | acc5: 98.6500 | loss: 0.9502
2025-08-28 06:16:31,408 - INFO -   LR: 0.100000
2025-08-28 06:16:31,422 - INFO - 
Epoch: 70, lr = 0.1
2025-08-28 06:16:31,614 - INFO - Epoch: [70][0/391] Time 0.191 (0.191) Data 0.157 (0.157) Loss 0.5086 (0.5086) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:16:33,498 - INFO - Epoch: [70][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4561 (0.4140) Acc@1 83.594 (85.528) Acc@5 100.000 (99.482)
2025-08-28 06:16:34,394 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:34,395 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:35,457 - INFO - Epoch: [70][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.3927 (0.4219) Acc@1 85.156 (85.339) Acc@5 100.000 (99.394)
2025-08-28 06:16:37,230 - INFO - Epoch: [70][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2424 (0.4220) Acc@1 92.188 (85.356) Acc@5 100.000 (99.398)
2025-08-28 06:16:37,376 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:37,376 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:39,042 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.5726 (0.5726) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-28 06:16:39,911 - INFO - Epoch 70:
2025-08-28 06:16:39,911 - INFO -   Train: acc1: 85.3200 | acc5: 99.4020 | loss: 0.4224 | sparsity: 0.8997 | reactivation_rate: 0.0001
2025-08-28 06:16:39,911 - INFO -   Val:   acc1: 79.0100 | acc5: 98.5300 | loss: 0.6798
2025-08-28 06:16:39,911 - INFO -   LR: 0.100000
2025-08-28 06:16:39,961 - INFO - 
Epoch: 71, lr = 0.1
2025-08-28 06:16:40,170 - INFO - Epoch: [71][0/391] Time 0.208 (0.208) Data 0.170 (0.170) Loss 0.2770 (0.2770) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:16:41,643 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:41,644 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:42,090 - INFO - Epoch: [71][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.4300 (0.4119) Acc@1 82.031 (85.767) Acc@5 100.000 (99.451)
2025-08-28 06:16:43,978 - INFO - Epoch: [71][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.4277 (0.4168) Acc@1 87.500 (85.545) Acc@5 98.438 (99.464)
2025-08-28 06:16:44,669 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:44,670 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:45,887 - INFO - Epoch: [71][300/391] Time 0.023 (0.020) Data 0.001 (0.003) Loss 0.3467 (0.4235) Acc@1 86.719 (85.335) Acc@5 98.438 (99.429)
2025-08-28 06:16:47,819 - INFO - Test: [0/79] Time 0.176 (0.176) Loss 0.5278 (0.5278) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:16:48,700 - INFO - Epoch 71:
2025-08-28 06:16:48,700 - INFO -   Train: acc1: 85.2920 | acc5: 99.4060 | loss: 0.4255 | sparsity: 0.8999 | reactivation_rate: 0.0001
2025-08-28 06:16:48,700 - INFO -   Val:   acc1: 79.2100 | acc5: 98.6200 | loss: 0.6216
2025-08-28 06:16:48,700 - INFO -   LR: 0.100000
2025-08-28 06:16:48,713 - INFO - 
Epoch: 72, lr = 0.1
2025-08-28 06:16:48,906 - INFO - Epoch: [72][0/391] Time 0.192 (0.192) Data 0.155 (0.155) Loss 0.4385 (0.4385) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:16:49,047 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:49,047 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:50,919 - INFO - Epoch: [72][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.3133 (0.4106) Acc@1 88.281 (85.667) Acc@5 100.000 (99.505)
2025-08-28 06:16:52,228 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:52,228 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:52,895 - INFO - Epoch: [72][200/391] Time 0.032 (0.021) Data 0.000 (0.003) Loss 0.4333 (0.4224) Acc@1 85.156 (85.183) Acc@5 100.000 (99.452)
2025-08-28 06:16:54,802 - INFO - Epoch: [72][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.5748 (0.4254) Acc@1 82.031 (85.143) Acc@5 98.438 (99.445)
2025-08-28 06:16:55,332 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:55,332 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:56,721 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5494 (0.5494) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 06:16:57,577 - INFO - Epoch 72:
2025-08-28 06:16:57,577 - INFO -   Train: acc1: 85.1020 | acc5: 99.4520 | loss: 0.4268 | sparsity: 0.8999 | reactivation_rate: 0.0001
2025-08-28 06:16:57,577 - INFO -   Val:   acc1: 81.4300 | acc5: 99.1800 | loss: 0.5761
2025-08-28 06:16:57,577 - INFO -   LR: 0.100000
2025-08-28 06:16:57,588 - INFO - 
Epoch: 73, lr = 0.1
2025-08-28 06:16:57,796 - INFO - Epoch: [73][0/391] Time 0.206 (0.206) Data 0.174 (0.174) Loss 0.3948 (0.3948) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:16:59,519 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:16:59,519 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:16:59,614 - INFO - Epoch: [73][100/391] Time 0.032 (0.020) Data 0.009 (0.004) Loss 0.3617 (0.4205) Acc@1 90.625 (85.357) Acc@5 100.000 (99.513)
2025-08-28 06:17:01,415 - INFO - Epoch: [73][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.4377 (0.4249) Acc@1 82.812 (85.253) Acc@5 99.219 (99.471)
2025-08-28 06:17:02,481 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:02,481 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:17:03,246 - INFO - Epoch: [73][300/391] Time 0.025 (0.019) Data 0.006 (0.003) Loss 0.3400 (0.4258) Acc@1 88.281 (85.286) Acc@5 99.219 (99.473)
2025-08-28 06:17:05,178 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.7241 (0.7241) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 06:17:06,054 - INFO - Epoch 73:
2025-08-28 06:17:06,054 - INFO -   Train: acc1: 85.2900 | acc5: 99.4340 | loss: 0.4257 | sparsity: 0.9000 | reactivation_rate: 0.0001
2025-08-28 06:17:06,054 - INFO -   Val:   acc1: 76.0100 | acc5: 97.9000 | loss: 0.7874
2025-08-28 06:17:06,054 - INFO -   LR: 0.100000
2025-08-28 06:17:06,068 - INFO - 
Epoch: 74, lr = 0.1
2025-08-28 06:17:06,297 - INFO - Epoch: [74][0/391] Time 0.229 (0.229) Data 0.205 (0.205) Loss 0.4951 (0.4951) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:17:06,823 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:06,823 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:17:08,215 - INFO - Epoch: [74][100/391] Time 0.012 (0.021) Data 0.001 (0.003) Loss 0.3533 (0.4262) Acc@1 88.281 (85.272) Acc@5 100.000 (99.335)
2025-08-28 06:17:09,939 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:09,939 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:17:10,233 - INFO - Epoch: [74][200/391] Time 0.029 (0.021) Data 0.000 (0.003) Loss 0.4441 (0.4220) Acc@1 83.594 (85.405) Acc@5 99.219 (99.390)
2025-08-28 06:17:12,159 - INFO - Epoch: [74][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3774 (0.4226) Acc@1 89.062 (85.382) Acc@5 98.438 (99.406)
2025-08-28 06:17:13,082 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:13,082 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:17:14,053 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.6000 (0.6000) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:17:14,900 - INFO - Epoch 74:
2025-08-28 06:17:14,900 - INFO -   Train: acc1: 85.3360 | acc5: 99.3960 | loss: 0.4255 | sparsity: 0.9000 | reactivation_rate: 0.0001
2025-08-28 06:17:14,900 - INFO -   Val:   acc1: 79.2500 | acc5: 98.8100 | loss: 0.6388
2025-08-28 06:17:14,900 - INFO -   LR: 0.100000
2025-08-28 06:17:14,914 - INFO - 
Epoch: 75, lr = 0.1
2025-08-28 06:17:15,113 - INFO - Epoch: [75][0/391] Time 0.199 (0.199) Data 0.176 (0.176) Loss 0.3639 (0.3639) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:17:16,934 - INFO - Epoch: [75][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4832 (0.4135) Acc@1 82.812 (85.690) Acc@5 97.656 (99.420)
2025-08-28 06:17:17,214 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:17,214 - INFO -   Reactivation rate: 0.0001
2025-08-28 06:17:18,850 - INFO - Epoch: [75][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2488 (0.4160) Acc@1 95.312 (85.599) Acc@5 99.219 (99.483)
2025-08-28 06:17:20,217 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:20,217 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:20,701 - INFO - Epoch: [75][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.6435 (0.4226) Acc@1 78.125 (85.398) Acc@5 99.219 (99.445)
2025-08-28 06:17:22,685 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.5414 (0.5414) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:17:23,571 - INFO - Epoch 75:
2025-08-28 06:17:23,571 - INFO -   Train: acc1: 85.3860 | acc5: 99.4380 | loss: 0.4236 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:17:23,571 - INFO -   Val:   acc1: 80.0500 | acc5: 98.9700 | loss: 0.5954
2025-08-28 06:17:23,571 - INFO -   LR: 0.100000
2025-08-28 06:17:23,582 - INFO - 
Epoch: 76, lr = 0.1
2025-08-28 06:17:23,779 - INFO - Epoch: [76][0/391] Time 0.196 (0.196) Data 0.179 (0.179) Loss 0.4427 (0.4427) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 06:17:24,558 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:24,559 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:25,723 - INFO - Epoch: [76][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.4447 (0.4204) Acc@1 83.594 (85.357) Acc@5 100.000 (99.466)
2025-08-28 06:17:27,644 - INFO - Epoch: [76][200/391] Time 0.030 (0.020) Data 0.000 (0.003) Loss 0.3437 (0.4204) Acc@1 89.844 (85.366) Acc@5 99.219 (99.479)
2025-08-28 06:17:27,703 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:27,703 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:29,420 - INFO - Epoch: [76][300/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.4497 (0.4226) Acc@1 87.500 (85.343) Acc@5 100.000 (99.442)
2025-08-28 06:17:30,656 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:30,656 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:31,288 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.6764 (0.6764) Acc@1 72.656 (72.656) Acc@5 99.219 (99.219)
2025-08-28 06:17:32,218 - INFO - Epoch 76:
2025-08-28 06:17:32,218 - INFO -   Train: acc1: 85.3600 | acc5: 99.4320 | loss: 0.4243 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:17:32,218 - INFO -   Val:   acc1: 75.5500 | acc5: 98.9400 | loss: 0.8008
2025-08-28 06:17:32,218 - INFO -   LR: 0.100000
2025-08-28 06:17:32,230 - INFO - 
Epoch: 77, lr = 0.1
2025-08-28 06:17:32,428 - INFO - Epoch: [77][0/391] Time 0.197 (0.197) Data 0.172 (0.172) Loss 0.3129 (0.3129) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:17:34,341 - INFO - Epoch: [77][100/391] Time 0.030 (0.021) Data 0.005 (0.003) Loss 0.4633 (0.4205) Acc@1 81.250 (85.504) Acc@5 100.000 (99.505)
2025-08-28 06:17:35,028 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:35,028 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:36,311 - INFO - Epoch: [77][200/391] Time 0.023 (0.020) Data 0.002 (0.003) Loss 0.4308 (0.4302) Acc@1 85.156 (85.156) Acc@5 99.219 (99.456)
2025-08-28 06:17:38,065 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:38,065 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:38,222 - INFO - Epoch: [77][300/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.4208 (0.4264) Acc@1 85.156 (85.372) Acc@5 100.000 (99.421)
2025-08-28 06:17:40,159 - INFO - Test: [0/79] Time 0.164 (0.164) Loss 0.4931 (0.4931) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-28 06:17:41,034 - INFO - Epoch 77:
2025-08-28 06:17:41,034 - INFO -   Train: acc1: 85.2520 | acc5: 99.4220 | loss: 0.4308 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:17:41,034 - INFO -   Val:   acc1: 80.4700 | acc5: 99.0200 | loss: 0.5885
2025-08-28 06:17:41,034 - INFO -   LR: 0.100000
2025-08-28 06:17:41,047 - INFO - 
Epoch: 78, lr = 0.1
2025-08-28 06:17:41,235 - INFO - Epoch: [78][0/391] Time 0.187 (0.187) Data 0.170 (0.170) Loss 0.4196 (0.4196) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:17:42,394 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:42,395 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:43,168 - INFO - Epoch: [78][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.3482 (0.4030) Acc@1 89.062 (86.317) Acc@5 99.219 (99.459)
2025-08-28 06:17:45,042 - INFO - Epoch: [78][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4410 (0.4196) Acc@1 85.156 (85.514) Acc@5 99.219 (99.429)
2025-08-28 06:17:45,485 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:45,485 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:46,960 - INFO - Epoch: [78][300/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.5669 (0.4255) Acc@1 82.812 (85.289) Acc@5 99.219 (99.439)
2025-08-28 06:17:48,496 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:48,496 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:48,842 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.5301 (0.5301) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:17:49,703 - INFO - Epoch 78:
2025-08-28 06:17:49,704 - INFO -   Train: acc1: 85.2320 | acc5: 99.4360 | loss: 0.4267 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:17:49,704 - INFO -   Val:   acc1: 81.3200 | acc5: 98.9700 | loss: 0.5575
2025-08-28 06:17:49,704 - INFO -   LR: 0.100000
2025-08-28 06:17:49,716 - INFO - 
Epoch: 79, lr = 0.1
2025-08-28 06:17:49,890 - INFO - Epoch: [79][0/391] Time 0.173 (0.173) Data 0.152 (0.152) Loss 0.5096 (0.5096) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-28 06:17:51,807 - INFO - Epoch: [79][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.4464 (0.4244) Acc@1 85.938 (85.566) Acc@5 97.656 (99.435)
2025-08-28 06:17:52,767 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:52,767 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:53,709 - INFO - Epoch: [79][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.4218 (0.4192) Acc@1 85.938 (85.611) Acc@5 99.219 (99.495)
2025-08-28 06:17:55,693 - INFO - Epoch: [79][300/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.4914 (0.4212) Acc@1 86.719 (85.636) Acc@5 99.219 (99.468)
2025-08-28 06:17:55,900 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:17:55,901 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:17:57,658 - INFO - Test: [0/79] Time 0.177 (0.177) Loss 0.7186 (0.7186) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 06:17:58,525 - INFO - Epoch 79:
2025-08-28 06:17:58,525 - INFO -   Train: acc1: 85.3880 | acc5: 99.4460 | loss: 0.4278 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:17:58,525 - INFO -   Val:   acc1: 78.4500 | acc5: 98.6800 | loss: 0.6824
2025-08-28 06:17:58,526 - INFO -   LR: 0.100000
2025-08-28 06:17:58,541 - INFO - 
Epoch: 80, lr = 0.1
2025-08-28 06:17:58,777 - INFO - Epoch: [80][0/391] Time 0.235 (0.235) Data 0.189 (0.189) Loss 0.4032 (0.4032) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:18:00,374 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:00,375 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:00,769 - INFO - Epoch: [80][100/391] Time 0.029 (0.022) Data 0.000 (0.003) Loss 0.5658 (0.4086) Acc@1 78.125 (85.729) Acc@5 99.219 (99.350)
2025-08-28 06:18:02,851 - INFO - Epoch: [80][200/391] Time 0.037 (0.021) Data 0.017 (0.003) Loss 0.3834 (0.4204) Acc@1 85.938 (85.491) Acc@5 100.000 (99.355)
2025-08-28 06:18:03,576 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:03,576 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:04,800 - INFO - Epoch: [80][300/391] Time 0.018 (0.021) Data 0.000 (0.002) Loss 0.3925 (0.4208) Acc@1 86.719 (85.530) Acc@5 100.000 (99.390)
2025-08-28 06:18:06,794 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.5466 (0.5466) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:18:07,625 - INFO - Epoch 80:
2025-08-28 06:18:07,625 - INFO -   Train: acc1: 85.3760 | acc5: 99.3940 | loss: 0.4247 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:18:07,625 - INFO -   Val:   acc1: 80.2000 | acc5: 99.2500 | loss: 0.5728
2025-08-28 06:18:07,625 - INFO -   LR: 0.100000
2025-08-28 06:18:07,674 - INFO - 
Epoch: 81, lr = 0.1
2025-08-28 06:18:07,878 - INFO - Epoch: [81][0/391] Time 0.203 (0.203) Data 0.173 (0.173) Loss 0.4051 (0.4051) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:18:08,046 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:08,046 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:09,830 - INFO - Epoch: [81][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.3446 (0.4152) Acc@1 85.156 (85.821) Acc@5 100.000 (99.404)
2025-08-28 06:18:11,076 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:11,076 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:11,696 - INFO - Epoch: [81][200/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3938 (0.4213) Acc@1 85.938 (85.448) Acc@5 100.000 (99.382)
2025-08-28 06:18:13,596 - INFO - Epoch: [81][300/391] Time 0.021 (0.020) Data 0.002 (0.002) Loss 0.4215 (0.4218) Acc@1 85.938 (85.481) Acc@5 100.000 (99.408)
2025-08-28 06:18:14,163 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:14,163 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:15,529 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.8795 (0.8795) Acc@1 72.656 (72.656) Acc@5 96.875 (96.875)
2025-08-28 06:18:16,403 - INFO - Epoch 81:
2025-08-28 06:18:16,404 - INFO -   Train: acc1: 85.3260 | acc5: 99.3940 | loss: 0.4265 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:18:16,404 - INFO -   Val:   acc1: 77.2100 | acc5: 98.1000 | loss: 0.7455
2025-08-28 06:18:16,404 - INFO -   LR: 0.100000
2025-08-28 06:18:16,416 - INFO - 
Epoch: 82, lr = 0.1
2025-08-28 06:18:16,602 - INFO - Epoch: [82][0/391] Time 0.185 (0.185) Data 0.165 (0.165) Loss 0.5173 (0.5173) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-28 06:18:18,372 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:18,372 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:18,421 - INFO - Epoch: [82][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.3751 (0.4221) Acc@1 85.938 (85.342) Acc@5 99.219 (99.420)
2025-08-28 06:18:20,338 - INFO - Epoch: [82][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4571 (0.4276) Acc@1 83.594 (85.199) Acc@5 100.000 (99.433)
2025-08-28 06:18:21,388 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:21,388 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:22,199 - INFO - Epoch: [82][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4554 (0.4266) Acc@1 83.594 (85.250) Acc@5 100.000 (99.403)
2025-08-28 06:18:24,105 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.6601 (0.6601) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-28 06:18:24,992 - INFO - Epoch 82:
2025-08-28 06:18:24,992 - INFO -   Train: acc1: 85.2400 | acc5: 99.4060 | loss: 0.4261 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:18:24,992 - INFO -   Val:   acc1: 75.8400 | acc5: 98.5100 | loss: 0.7376
2025-08-28 06:18:24,992 - INFO -   LR: 0.100000
2025-08-28 06:18:25,006 - INFO - 
Epoch: 83, lr = 0.1
2025-08-28 06:18:25,214 - INFO - Epoch: [83][0/391] Time 0.207 (0.207) Data 0.190 (0.190) Loss 0.5246 (0.5246) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-28 06:18:25,656 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:25,656 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:27,172 - INFO - Epoch: [83][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.3315 (0.4159) Acc@1 89.844 (85.945) Acc@5 100.000 (99.459)
2025-08-28 06:18:28,906 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:28,906 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:29,141 - INFO - Epoch: [83][200/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.3978 (0.4147) Acc@1 86.719 (85.794) Acc@5 99.219 (99.425)
2025-08-28 06:18:31,014 - INFO - Epoch: [83][300/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5601 (0.4222) Acc@1 81.250 (85.566) Acc@5 98.438 (99.406)
2025-08-28 06:18:31,894 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:31,895 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:32,844 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.5605 (0.5605) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:18:33,699 - INFO - Epoch 83:
2025-08-28 06:18:33,699 - INFO -   Train: acc1: 85.4200 | acc5: 99.3960 | loss: 0.4245 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:18:33,699 - INFO -   Val:   acc1: 79.8300 | acc5: 98.9000 | loss: 0.5998
2025-08-28 06:18:33,699 - INFO -   LR: 0.100000
2025-08-28 06:18:33,715 - INFO - 
Epoch: 84, lr = 0.1
2025-08-28 06:18:33,899 - INFO - Epoch: [84][0/391] Time 0.183 (0.183) Data 0.165 (0.165) Loss 0.4293 (0.4293) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:18:35,895 - INFO - Epoch: [84][100/391] Time 0.030 (0.022) Data 0.000 (0.003) Loss 0.4335 (0.4232) Acc@1 85.156 (85.388) Acc@5 99.219 (99.451)
2025-08-28 06:18:36,198 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:36,198 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:37,858 - INFO - Epoch: [84][200/391] Time 0.018 (0.021) Data 0.001 (0.003) Loss 0.5356 (0.4147) Acc@1 85.156 (85.599) Acc@5 100.000 (99.506)
2025-08-28 06:18:39,389 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:39,389 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:39,928 - INFO - Epoch: [84][300/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.3230 (0.4177) Acc@1 89.062 (85.504) Acc@5 100.000 (99.483)
2025-08-28 06:18:41,880 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.6174 (0.6174) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 06:18:42,719 - INFO - Epoch 84:
2025-08-28 06:18:42,719 - INFO -   Train: acc1: 85.2620 | acc5: 99.4460 | loss: 0.4246 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:18:42,719 - INFO -   Val:   acc1: 75.7100 | acc5: 98.3800 | loss: 0.7385
2025-08-28 06:18:42,719 - INFO -   LR: 0.100000
2025-08-28 06:18:42,735 - INFO - 
Epoch: 85, lr = 0.1
2025-08-28 06:18:42,942 - INFO - Epoch: [85][0/391] Time 0.206 (0.206) Data 0.175 (0.175) Loss 0.5261 (0.5261) Acc@1 81.250 (81.250) Acc@5 99.219 (99.219)
2025-08-28 06:18:43,789 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:43,789 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:44,848 - INFO - Epoch: [85][100/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.5123 (0.4231) Acc@1 83.594 (85.543) Acc@5 98.438 (99.482)
2025-08-28 06:18:46,825 - INFO - Epoch: [85][200/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.4438 (0.4181) Acc@1 85.938 (85.541) Acc@5 99.219 (99.483)
2025-08-28 06:18:46,913 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:46,913 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:48,891 - INFO - Epoch: [85][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4295 (0.4177) Acc@1 85.938 (85.652) Acc@5 99.219 (99.463)
2025-08-28 06:18:50,064 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:50,066 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:50,736 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.5532 (0.5532) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-28 06:18:51,598 - INFO - Epoch 85:
2025-08-28 06:18:51,599 - INFO -   Train: acc1: 85.4860 | acc5: 99.4400 | loss: 0.4226 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:18:51,599 - INFO -   Val:   acc1: 77.8100 | acc5: 98.6800 | loss: 0.6800
2025-08-28 06:18:51,599 - INFO -   LR: 0.100000
2025-08-28 06:18:51,615 - INFO - 
Epoch: 86, lr = 0.1
2025-08-28 06:18:51,824 - INFO - Epoch: [86][0/391] Time 0.208 (0.208) Data 0.178 (0.178) Loss 0.2799 (0.2799) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:18:53,886 - INFO - Epoch: [86][100/391] Time 0.024 (0.022) Data 0.000 (0.004) Loss 0.3358 (0.4228) Acc@1 87.500 (85.551) Acc@5 100.000 (99.443)
2025-08-28 06:18:54,579 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:54,579 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:55,815 - INFO - Epoch: [86][200/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.3882 (0.4246) Acc@1 84.375 (85.386) Acc@5 99.219 (99.471)
2025-08-28 06:18:57,662 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:18:57,663 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:18:57,798 - INFO - Epoch: [86][300/391] Time 0.033 (0.021) Data 0.011 (0.002) Loss 0.4090 (0.4289) Acc@1 85.156 (85.187) Acc@5 100.000 (99.450)
2025-08-28 06:18:59,657 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.5708 (0.5708) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-28 06:19:00,529 - INFO - Epoch 86:
2025-08-28 06:19:00,529 - INFO -   Train: acc1: 85.3660 | acc5: 99.4340 | loss: 0.4259 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:00,529 - INFO -   Val:   acc1: 80.9200 | acc5: 99.0200 | loss: 0.5729
2025-08-28 06:19:00,529 - INFO -   LR: 0.100000
2025-08-28 06:19:00,545 - INFO - 
Epoch: 87, lr = 0.1
2025-08-28 06:19:00,763 - INFO - Epoch: [87][0/391] Time 0.218 (0.218) Data 0.185 (0.185) Loss 0.4230 (0.4230) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-28 06:19:02,017 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:02,017 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:02,686 - INFO - Epoch: [87][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.2990 (0.4226) Acc@1 89.062 (85.798) Acc@5 100.000 (99.459)
2025-08-28 06:19:04,508 - INFO - Epoch: [87][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.3849 (0.4244) Acc@1 89.062 (85.557) Acc@5 99.219 (99.433)
2025-08-28 06:19:04,894 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:04,895 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:06,434 - INFO - Epoch: [87][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.5409 (0.4256) Acc@1 80.469 (85.408) Acc@5 99.219 (99.411)
2025-08-28 06:19:07,990 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:07,990 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:08,295 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.5294 (0.5294) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:19:09,194 - INFO - Epoch 87:
2025-08-28 06:19:09,194 - INFO -   Train: acc1: 85.3920 | acc5: 99.4340 | loss: 0.4237 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:09,194 - INFO -   Val:   acc1: 79.5800 | acc5: 98.9300 | loss: 0.6302
2025-08-28 06:19:09,194 - INFO -   LR: 0.100000
2025-08-28 06:19:09,208 - INFO - 
Epoch: 88, lr = 0.1
2025-08-28 06:19:09,432 - INFO - Epoch: [88][0/391] Time 0.222 (0.222) Data 0.190 (0.190) Loss 0.3350 (0.3350) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:19:11,328 - INFO - Epoch: [88][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.3982 (0.4201) Acc@1 88.281 (85.450) Acc@5 100.000 (99.459)
2025-08-28 06:19:12,323 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:12,324 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:13,309 - INFO - Epoch: [88][200/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.4462 (0.4168) Acc@1 88.281 (85.798) Acc@5 100.000 (99.405)
2025-08-28 06:19:15,253 - INFO - Epoch: [88][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.5261 (0.4222) Acc@1 79.688 (85.597) Acc@5 100.000 (99.395)
2025-08-28 06:19:15,490 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:15,490 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:17,095 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.5352 (0.5352) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:19:17,942 - INFO - Epoch 88:
2025-08-28 06:19:17,942 - INFO -   Train: acc1: 85.5720 | acc5: 99.4020 | loss: 0.4234 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:17,942 - INFO -   Val:   acc1: 78.4400 | acc5: 99.0200 | loss: 0.6341
2025-08-28 06:19:17,942 - INFO -   LR: 0.100000
2025-08-28 06:19:17,956 - INFO - 
Epoch: 89, lr = 0.1
2025-08-28 06:19:18,159 - INFO - Epoch: [89][0/391] Time 0.201 (0.201) Data 0.181 (0.181) Loss 0.3879 (0.3879) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-28 06:19:19,602 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:19,602 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:20,007 - INFO - Epoch: [89][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.4793 (0.4128) Acc@1 82.812 (85.837) Acc@5 99.219 (99.428)
2025-08-28 06:19:21,953 - INFO - Epoch: [89][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.3890 (0.4189) Acc@1 85.938 (85.592) Acc@5 99.219 (99.448)
2025-08-28 06:19:22,823 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:22,823 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:23,973 - INFO - Epoch: [89][300/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.6236 (0.4250) Acc@1 79.688 (85.431) Acc@5 99.219 (99.408)
2025-08-28 06:19:25,875 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5208 (0.5208) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-28 06:19:26,786 - INFO - Epoch 89:
2025-08-28 06:19:26,787 - INFO -   Train: acc1: 85.3600 | acc5: 99.4000 | loss: 0.4257 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:26,787 - INFO -   Val:   acc1: 79.0200 | acc5: 99.0300 | loss: 0.6243
2025-08-28 06:19:26,787 - INFO -   LR: 0.100000
2025-08-28 06:19:26,802 - INFO - 
Epoch: 90, lr = 0.1
2025-08-28 06:19:27,012 - INFO - Epoch: [90][0/391] Time 0.209 (0.209) Data 0.175 (0.175) Loss 0.4159 (0.4159) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:19:27,225 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:27,225 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:29,016 - INFO - Epoch: [90][100/391] Time 0.015 (0.022) Data 0.000 (0.003) Loss 0.4836 (0.4104) Acc@1 82.812 (85.798) Acc@5 99.219 (99.474)
2025-08-28 06:19:30,326 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:30,326 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:30,902 - INFO - Epoch: [90][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4388 (0.4177) Acc@1 85.938 (85.592) Acc@5 99.219 (99.475)
2025-08-28 06:19:32,898 - INFO - Epoch: [90][300/391] Time 0.032 (0.020) Data 0.007 (0.002) Loss 0.5319 (0.4190) Acc@1 82.812 (85.538) Acc@5 98.438 (99.463)
2025-08-28 06:19:33,477 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:33,477 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:34,784 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.5135 (0.5135) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-28 06:19:35,627 - INFO - Epoch 90:
2025-08-28 06:19:35,627 - INFO -   Train: acc1: 85.3340 | acc5: 99.4440 | loss: 0.4234 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:35,627 - INFO -   Val:   acc1: 79.3000 | acc5: 99.0200 | loss: 0.6461
2025-08-28 06:19:35,627 - INFO -   LR: 0.100000
2025-08-28 06:19:35,676 - INFO - 
Epoch: 91, lr = 0.1
2025-08-28 06:19:35,881 - INFO - Epoch: [91][0/391] Time 0.204 (0.204) Data 0.176 (0.176) Loss 0.3832 (0.3832) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-28 06:19:37,838 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:37,838 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:37,878 - INFO - Epoch: [91][100/391] Time 0.020 (0.022) Data 0.000 (0.005) Loss 0.4963 (0.4038) Acc@1 83.594 (86.061) Acc@5 99.219 (99.505)
2025-08-28 06:19:39,847 - INFO - Epoch: [91][200/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.4944 (0.4188) Acc@1 83.594 (85.689) Acc@5 99.219 (99.405)
2025-08-28 06:19:41,039 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:41,039 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:41,830 - INFO - Epoch: [91][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.4220 (0.4214) Acc@1 85.156 (85.621) Acc@5 99.219 (99.372)
2025-08-28 06:19:43,724 - INFO - Test: [0/79] Time 0.178 (0.178) Loss 0.4552 (0.4552) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-28 06:19:44,881 - INFO - Epoch 91:
2025-08-28 06:19:44,881 - INFO -   Train: acc1: 85.4240 | acc5: 99.4060 | loss: 0.4263 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:44,882 - INFO -   Val:   acc1: 80.2100 | acc5: 99.0700 | loss: 0.5923
2025-08-28 06:19:44,882 - INFO -   LR: 0.100000
2025-08-28 06:19:44,897 - INFO - 
Epoch: 92, lr = 0.1
2025-08-28 06:19:45,081 - INFO - Epoch: [92][0/391] Time 0.183 (0.183) Data 0.166 (0.166) Loss 0.3842 (0.3842) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:19:45,651 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:45,651 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:47,135 - INFO - Epoch: [92][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.4487 (0.4162) Acc@1 83.594 (85.922) Acc@5 100.000 (99.366)
2025-08-28 06:19:48,879 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:48,879 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:49,115 - INFO - Epoch: [92][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.2897 (0.4173) Acc@1 89.844 (85.751) Acc@5 100.000 (99.413)
2025-08-28 06:19:51,013 - INFO - Epoch: [92][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2850 (0.4208) Acc@1 92.969 (85.501) Acc@5 99.219 (99.426)
2025-08-28 06:19:51,913 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:51,913 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:52,898 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.6694 (0.6694) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-28 06:19:53,760 - INFO - Epoch 92:
2025-08-28 06:19:53,760 - INFO -   Train: acc1: 85.4240 | acc5: 99.3980 | loss: 0.4236 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:19:53,760 - INFO -   Val:   acc1: 76.7000 | acc5: 98.8700 | loss: 0.7512
2025-08-28 06:19:53,760 - INFO -   LR: 0.100000
2025-08-28 06:19:53,775 - INFO - 
Epoch: 93, lr = 0.1
2025-08-28 06:19:53,973 - INFO - Epoch: [93][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.4445 (0.4445) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:19:55,908 - INFO - Epoch: [93][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3130 (0.4363) Acc@1 90.625 (84.777) Acc@5 100.000 (99.397)
2025-08-28 06:19:56,222 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:56,222 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:57,941 - INFO - Epoch: [93][200/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.3372 (0.4261) Acc@1 87.500 (85.296) Acc@5 100.000 (99.421)
2025-08-28 06:19:59,453 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:19:59,453 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:19:59,940 - INFO - Epoch: [93][300/391] Time 0.025 (0.020) Data 0.000 (0.002) Loss 0.4564 (0.4226) Acc@1 85.938 (85.372) Acc@5 97.656 (99.445)
2025-08-28 06:20:01,880 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.5104 (0.5104) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-28 06:20:02,729 - INFO - Epoch 93:
2025-08-28 06:20:02,729 - INFO -   Train: acc1: 85.2000 | acc5: 99.4160 | loss: 0.4265 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:02,729 - INFO -   Val:   acc1: 77.7300 | acc5: 98.6200 | loss: 0.7143
2025-08-28 06:20:02,729 - INFO -   LR: 0.100000
2025-08-28 06:20:02,745 - INFO - 
Epoch: 94, lr = 0.1
2025-08-28 06:20:02,946 - INFO - Epoch: [94][0/391] Time 0.200 (0.200) Data 0.173 (0.173) Loss 0.4117 (0.4117) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-28 06:20:03,835 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:03,835 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:04,843 - INFO - Epoch: [94][100/391] Time 0.011 (0.021) Data 0.000 (0.004) Loss 0.3600 (0.4245) Acc@1 85.938 (85.187) Acc@5 100.000 (99.381)
2025-08-28 06:20:06,734 - INFO - Epoch: [94][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.5102 (0.4229) Acc@1 82.031 (85.351) Acc@5 100.000 (99.394)
2025-08-28 06:20:06,861 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:06,861 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:08,682 - INFO - Epoch: [94][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.5119 (0.4237) Acc@1 85.156 (85.341) Acc@5 98.438 (99.380)
2025-08-28 06:20:09,872 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:09,872 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:10,474 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.6940 (0.6940) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 06:20:11,348 - INFO - Epoch 94:
2025-08-28 06:20:11,348 - INFO -   Train: acc1: 85.2660 | acc5: 99.3600 | loss: 0.4263 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:11,348 - INFO -   Val:   acc1: 76.5800 | acc5: 98.7800 | loss: 0.7132
2025-08-28 06:20:11,348 - INFO -   LR: 0.100000
2025-08-28 06:20:11,361 - INFO - 
Epoch: 95, lr = 0.1
2025-08-28 06:20:11,541 - INFO - Epoch: [95][0/391] Time 0.179 (0.179) Data 0.156 (0.156) Loss 0.3901 (0.3901) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:20:13,427 - INFO - Epoch: [95][100/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.4541 (0.4206) Acc@1 85.156 (85.195) Acc@5 99.219 (99.489)
2025-08-28 06:20:14,119 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:14,119 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:15,325 - INFO - Epoch: [95][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.5240 (0.4267) Acc@1 83.594 (85.121) Acc@5 98.438 (99.456)
2025-08-28 06:20:17,039 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:17,040 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:17,185 - INFO - Epoch: [95][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.3169 (0.4291) Acc@1 91.406 (85.060) Acc@5 100.000 (99.421)
2025-08-28 06:20:19,194 - INFO - Test: [0/79] Time 0.174 (0.174) Loss 0.7645 (0.7645) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-28 06:20:20,059 - INFO - Epoch 95:
2025-08-28 06:20:20,060 - INFO -   Train: acc1: 85.1980 | acc5: 99.4380 | loss: 0.4245 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:20,060 - INFO -   Val:   acc1: 75.4700 | acc5: 98.9500 | loss: 0.8294
2025-08-28 06:20:20,060 - INFO -   LR: 0.100000
2025-08-28 06:20:20,074 - INFO - 
Epoch: 96, lr = 0.1
2025-08-28 06:20:20,291 - INFO - Epoch: [96][0/391] Time 0.215 (0.215) Data 0.176 (0.176) Loss 0.5584 (0.5584) Acc@1 78.906 (78.906) Acc@5 98.438 (98.438)
2025-08-28 06:20:21,616 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:21,616 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:22,283 - INFO - Epoch: [96][100/391] Time 0.012 (0.022) Data 0.000 (0.004) Loss 0.4001 (0.4247) Acc@1 87.500 (84.855) Acc@5 99.219 (99.459)
2025-08-28 06:20:24,177 - INFO - Epoch: [96][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.5365 (0.4323) Acc@1 82.031 (84.900) Acc@5 98.438 (99.429)
2025-08-28 06:20:24,564 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:24,564 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:26,024 - INFO - Epoch: [96][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.4198 (0.4334) Acc@1 87.500 (84.904) Acc@5 99.219 (99.439)
2025-08-28 06:20:27,561 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:27,561 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:27,832 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.5242 (0.5242) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-28 06:20:28,689 - INFO - Epoch 96:
2025-08-28 06:20:28,689 - INFO -   Train: acc1: 85.0120 | acc5: 99.4380 | loss: 0.4302 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:28,689 - INFO -   Val:   acc1: 79.9000 | acc5: 99.0500 | loss: 0.6371
2025-08-28 06:20:28,689 - INFO -   LR: 0.100000
2025-08-28 06:20:28,705 - INFO - 
Epoch: 97, lr = 0.1
2025-08-28 06:20:28,914 - INFO - Epoch: [97][0/391] Time 0.209 (0.209) Data 0.175 (0.175) Loss 0.4157 (0.4157) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:20:30,866 - INFO - Epoch: [97][100/391] Time 0.025 (0.021) Data 0.000 (0.004) Loss 0.4005 (0.4130) Acc@1 85.938 (85.528) Acc@5 98.438 (99.513)
2025-08-28 06:20:31,901 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:31,901 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:32,797 - INFO - Epoch: [97][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.4239 (0.4224) Acc@1 85.938 (85.533) Acc@5 99.219 (99.436)
2025-08-28 06:20:34,869 - INFO - Epoch: [97][300/391] Time 0.034 (0.020) Data 0.000 (0.003) Loss 0.3680 (0.4236) Acc@1 89.062 (85.450) Acc@5 100.000 (99.403)
2025-08-28 06:20:35,046 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:35,047 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:36,666 - INFO - Test: [0/79] Time 0.165 (0.165) Loss 0.8229 (0.8229) Acc@1 74.219 (74.219) Acc@5 99.219 (99.219)
2025-08-28 06:20:37,529 - INFO - Epoch 97:
2025-08-28 06:20:37,530 - INFO -   Train: acc1: 85.4460 | acc5: 99.3960 | loss: 0.4243 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:37,530 - INFO -   Val:   acc1: 74.9600 | acc5: 98.2900 | loss: 0.8219
2025-08-28 06:20:37,530 - INFO -   LR: 0.100000
2025-08-28 06:20:37,546 - INFO - 
Epoch: 98, lr = 0.1
2025-08-28 06:20:37,763 - INFO - Epoch: [98][0/391] Time 0.216 (0.216) Data 0.187 (0.187) Loss 0.4848 (0.4848) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-28 06:20:39,331 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:39,332 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:39,693 - INFO - Epoch: [98][100/391] Time 0.023 (0.021) Data 0.000 (0.003) Loss 0.3498 (0.4182) Acc@1 88.281 (85.203) Acc@5 99.219 (99.389)
2025-08-28 06:20:41,669 - INFO - Epoch: [98][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.4745 (0.4196) Acc@1 82.812 (85.331) Acc@5 99.219 (99.355)
2025-08-28 06:20:42,429 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:42,429 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:43,502 - INFO - Epoch: [98][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3752 (0.4221) Acc@1 86.719 (85.359) Acc@5 100.000 (99.419)
2025-08-28 06:20:45,271 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.4375 (0.4375) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-28 06:20:46,138 - INFO - Epoch 98:
2025-08-28 06:20:46,138 - INFO -   Train: acc1: 85.3720 | acc5: 99.4280 | loss: 0.4247 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:46,138 - INFO -   Val:   acc1: 82.1200 | acc5: 99.1400 | loss: 0.5266
2025-08-28 06:20:46,138 - INFO -   LR: 0.100000
2025-08-28 06:20:46,152 - INFO - 
Epoch: 99, lr = 0.1
2025-08-28 06:20:46,353 - INFO - Epoch: [99][0/391] Time 0.199 (0.199) Data 0.170 (0.170) Loss 0.3850 (0.3850) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:20:46,575 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:46,575 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:48,296 - INFO - Epoch: [99][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.4155 (0.4320) Acc@1 88.281 (85.040) Acc@5 98.438 (99.459)
2025-08-28 06:20:49,612 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:49,612 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:50,169 - INFO - Epoch: [99][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.3091 (0.4305) Acc@1 89.844 (85.040) Acc@5 100.000 (99.448)
2025-08-28 06:20:52,132 - INFO - Epoch: [99][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3825 (0.4281) Acc@1 89.062 (85.343) Acc@5 99.219 (99.426)
2025-08-28 06:20:52,742 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:52,743 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:54,076 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.5112 (0.5112) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-28 06:20:54,933 - INFO - Epoch 99:
2025-08-28 06:20:54,933 - INFO -   Train: acc1: 85.4020 | acc5: 99.4500 | loss: 0.4257 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:20:54,933 - INFO -   Val:   acc1: 80.9200 | acc5: 98.7900 | loss: 0.5913
2025-08-28 06:20:54,933 - INFO -   LR: 0.010000
2025-08-28 06:20:54,949 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-28 06:20:55,143 - INFO - Epoch: [100][0/391] Time 0.193 (0.193) Data 0.176 (0.176) Loss 0.3553 (0.3553) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:20:57,022 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:20:57,022 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:20:57,045 - INFO - Epoch: [100][100/391] Time 0.028 (0.021) Data 0.000 (0.003) Loss 0.2765 (0.3440) Acc@1 89.844 (88.111) Acc@5 100.000 (99.714)
2025-08-28 06:20:58,982 - INFO - Epoch: [100][200/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.3312 (0.3305) Acc@1 88.281 (88.806) Acc@5 100.000 (99.708)
2025-08-28 06:21:00,062 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:00,062 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:00,806 - INFO - Epoch: [100][300/391] Time 0.029 (0.019) Data 0.000 (0.002) Loss 0.2459 (0.3200) Acc@1 93.750 (89.229) Acc@5 99.219 (99.720)
2025-08-28 06:21:02,639 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2799 (0.2799) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 06:21:03,498 - INFO - Epoch 100:
2025-08-28 06:21:03,499 - INFO -   Train: acc1: 89.4300 | acc5: 99.7040 | loss: 0.3137 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:03,499 - INFO -   Val:   acc1: 88.6100 | acc5: 99.6300 | loss: 0.3374
2025-08-28 06:21:03,499 - INFO -   LR: 0.010000
2025-08-28 06:21:03,549 - INFO - Checkpoint saved: epoch=100, metric=88.6100
2025-08-28 06:21:03,581 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-28 06:21:03,796 - INFO - Epoch: [101][0/391] Time 0.213 (0.213) Data 0.185 (0.185) Loss 0.3555 (0.3555) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 06:21:04,413 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:04,413 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:05,847 - INFO - Epoch: [101][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.1817 (0.2772) Acc@1 95.312 (90.679) Acc@5 100.000 (99.729)
2025-08-28 06:21:07,576 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:07,576 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:07,813 - INFO - Epoch: [101][200/391] Time 0.016 (0.021) Data 0.004 (0.002) Loss 0.3041 (0.2782) Acc@1 92.188 (90.590) Acc@5 99.219 (99.712)
2025-08-28 06:21:09,687 - INFO - Epoch: [101][300/391] Time 0.024 (0.020) Data 0.013 (0.002) Loss 0.3166 (0.2797) Acc@1 88.281 (90.438) Acc@5 100.000 (99.725)
2025-08-28 06:21:10,531 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:10,531 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:11,540 - INFO - Test: [0/79] Time 0.170 (0.170) Loss 0.2808 (0.2808) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:21:12,418 - INFO - Epoch 101:
2025-08-28 06:21:12,418 - INFO -   Train: acc1: 90.4040 | acc5: 99.7020 | loss: 0.2809 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:12,418 - INFO -   Val:   acc1: 88.7300 | acc5: 99.6400 | loss: 0.3289
2025-08-28 06:21:12,418 - INFO -   LR: 0.010000
2025-08-28 06:21:12,469 - INFO - Checkpoint saved: epoch=101, metric=88.7300
2025-08-28 06:21:12,501 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-28 06:21:12,701 - INFO - Epoch: [102][0/391] Time 0.199 (0.199) Data 0.183 (0.183) Loss 0.2637 (0.2637) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:21:14,636 - INFO - Epoch: [102][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.3076 (0.2739) Acc@1 92.188 (90.934) Acc@5 100.000 (99.706)
2025-08-28 06:21:14,931 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:14,931 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:16,563 - INFO - Epoch: [102][200/391] Time 0.027 (0.020) Data 0.013 (0.003) Loss 0.2189 (0.2705) Acc@1 92.969 (90.847) Acc@5 100.000 (99.740)
2025-08-28 06:21:18,081 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:18,081 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:18,506 - INFO - Epoch: [102][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.2693 (0.2699) Acc@1 92.969 (90.882) Acc@5 100.000 (99.735)
2025-08-28 06:21:20,390 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.2842 (0.2842) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:21:21,251 - INFO - Epoch 102:
2025-08-28 06:21:21,251 - INFO -   Train: acc1: 90.9040 | acc5: 99.7440 | loss: 0.2683 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:21,251 - INFO -   Val:   acc1: 88.7600 | acc5: 99.6300 | loss: 0.3296
2025-08-28 06:21:21,251 - INFO -   LR: 0.010000
2025-08-28 06:21:21,303 - INFO - Checkpoint saved: epoch=102, metric=88.7600
2025-08-28 06:21:21,336 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-28 06:21:21,538 - INFO - Epoch: [103][0/391] Time 0.201 (0.201) Data 0.182 (0.182) Loss 0.2932 (0.2932) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:21:22,471 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:22,471 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:23,543 - INFO - Epoch: [103][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.3251 (0.2608) Acc@1 87.500 (90.934) Acc@5 99.219 (99.745)
2025-08-28 06:21:25,542 - INFO - Epoch: [103][200/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.2903 (0.2583) Acc@1 92.969 (91.138) Acc@5 100.000 (99.751)
2025-08-28 06:21:25,625 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:25,625 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:27,455 - INFO - Epoch: [103][300/391] Time 0.033 (0.020) Data 0.019 (0.002) Loss 0.3981 (0.2598) Acc@1 90.625 (91.095) Acc@5 99.219 (99.743)
2025-08-28 06:21:28,755 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:28,756 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:29,376 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.2945 (0.2945) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:21:30,213 - INFO - Epoch 103:
2025-08-28 06:21:30,213 - INFO -   Train: acc1: 91.0720 | acc5: 99.7500 | loss: 0.2609 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:30,213 - INFO -   Val:   acc1: 88.8600 | acc5: 99.5800 | loss: 0.3258
2025-08-28 06:21:30,213 - INFO -   LR: 0.010000
2025-08-28 06:21:30,263 - INFO - Checkpoint saved: epoch=103, metric=88.8600
2025-08-28 06:21:30,294 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-28 06:21:30,491 - INFO - Epoch: [104][0/391] Time 0.196 (0.196) Data 0.166 (0.166) Loss 0.2436 (0.2436) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:21:32,395 - INFO - Epoch: [104][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2812 (0.2558) Acc@1 91.406 (91.282) Acc@5 100.000 (99.814)
2025-08-28 06:21:33,129 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:33,130 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:34,360 - INFO - Epoch: [104][200/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.2674 (0.2587) Acc@1 90.625 (91.123) Acc@5 100.000 (99.771)
2025-08-28 06:21:36,196 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:36,196 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:36,294 - INFO - Epoch: [104][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.1688 (0.2583) Acc@1 96.094 (91.209) Acc@5 100.000 (99.761)
2025-08-28 06:21:38,059 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2752 (0.2752) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:21:38,915 - INFO - Epoch 104:
2025-08-28 06:21:38,916 - INFO -   Train: acc1: 91.0760 | acc5: 99.7800 | loss: 0.2606 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:38,916 - INFO -   Val:   acc1: 88.6900 | acc5: 99.6200 | loss: 0.3274
2025-08-28 06:21:38,916 - INFO -   LR: 0.010000
2025-08-28 06:21:38,932 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-28 06:21:39,146 - INFO - Epoch: [105][0/391] Time 0.213 (0.213) Data 0.177 (0.177) Loss 0.1974 (0.1974) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:21:40,417 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:40,417 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:41,143 - INFO - Epoch: [105][100/391] Time 0.017 (0.022) Data 0.000 (0.004) Loss 0.2784 (0.2490) Acc@1 89.062 (91.414) Acc@5 100.000 (99.814)
2025-08-28 06:21:43,099 - INFO - Epoch: [105][200/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.2048 (0.2515) Acc@1 92.969 (91.352) Acc@5 99.219 (99.802)
2025-08-28 06:21:43,587 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:43,587 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:45,111 - INFO - Epoch: [105][300/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.2834 (0.2539) Acc@1 89.844 (91.315) Acc@5 99.219 (99.798)
2025-08-28 06:21:46,805 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:46,805 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:47,072 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.2623 (0.2623) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:21:47,939 - INFO - Epoch 105:
2025-08-28 06:21:47,940 - INFO -   Train: acc1: 91.3220 | acc5: 99.7860 | loss: 0.2530 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:47,940 - INFO -   Val:   acc1: 88.7200 | acc5: 99.6500 | loss: 0.3277
2025-08-28 06:21:47,940 - INFO -   LR: 0.010000
2025-08-28 06:21:47,957 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-28 06:21:48,141 - INFO - Epoch: [106][0/391] Time 0.183 (0.183) Data 0.166 (0.166) Loss 0.1954 (0.1954) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:21:50,034 - INFO - Epoch: [106][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1704 (0.2449) Acc@1 93.750 (91.522) Acc@5 100.000 (99.737)
2025-08-28 06:21:51,115 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:51,115 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:52,057 - INFO - Epoch: [106][200/391] Time 0.021 (0.020) Data 0.005 (0.002) Loss 0.2487 (0.2432) Acc@1 91.406 (91.569) Acc@5 100.000 (99.782)
2025-08-28 06:21:53,931 - INFO - Epoch: [106][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3928 (0.2463) Acc@1 87.500 (91.435) Acc@5 100.000 (99.769)
2025-08-28 06:21:54,203 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:54,203 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:55,802 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.2443 (0.2443) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:21:56,660 - INFO - Epoch 106:
2025-08-28 06:21:56,660 - INFO -   Train: acc1: 91.3720 | acc5: 99.7680 | loss: 0.2505 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:21:56,660 - INFO -   Val:   acc1: 88.7700 | acc5: 99.6200 | loss: 0.3225
2025-08-28 06:21:56,660 - INFO -   LR: 0.010000
2025-08-28 06:21:56,675 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-28 06:21:56,886 - INFO - Epoch: [107][0/391] Time 0.210 (0.210) Data 0.191 (0.191) Loss 0.2268 (0.2268) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:21:58,454 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:21:58,454 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:21:58,796 - INFO - Epoch: [107][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.2070 (0.2472) Acc@1 89.844 (91.607) Acc@5 100.000 (99.799)
2025-08-28 06:22:00,765 - INFO - Epoch: [107][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.3397 (0.2465) Acc@1 89.062 (91.554) Acc@5 100.000 (99.794)
2025-08-28 06:22:01,556 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:01,556 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:02,690 - INFO - Epoch: [107][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2951 (0.2472) Acc@1 90.625 (91.559) Acc@5 99.219 (99.800)
2025-08-28 06:22:04,547 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2558 (0.2558) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:22:05,406 - INFO - Epoch 107:
2025-08-28 06:22:05,406 - INFO -   Train: acc1: 91.4140 | acc5: 99.7940 | loss: 0.2499 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:05,407 - INFO -   Val:   acc1: 88.8400 | acc5: 99.6200 | loss: 0.3249
2025-08-28 06:22:05,407 - INFO -   LR: 0.010000
2025-08-28 06:22:05,423 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-28 06:22:05,632 - INFO - Epoch: [108][0/391] Time 0.209 (0.209) Data 0.182 (0.182) Loss 0.1399 (0.1399) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:22:05,869 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:05,870 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:07,636 - INFO - Epoch: [108][100/391] Time 0.012 (0.022) Data 0.000 (0.004) Loss 0.2306 (0.2428) Acc@1 90.625 (91.723) Acc@5 100.000 (99.791)
2025-08-28 06:22:08,979 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:08,979 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:09,550 - INFO - Epoch: [108][200/391] Time 0.020 (0.021) Data 0.000 (0.002) Loss 0.2587 (0.2471) Acc@1 90.625 (91.523) Acc@5 99.219 (99.763)
2025-08-28 06:22:11,353 - INFO - Epoch: [108][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.2495 (0.2471) Acc@1 92.969 (91.435) Acc@5 100.000 (99.785)
2025-08-28 06:22:11,985 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:11,985 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:13,255 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2792 (0.2792) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:22:14,116 - INFO - Epoch 108:
2025-08-28 06:22:14,116 - INFO -   Train: acc1: 91.4580 | acc5: 99.7960 | loss: 0.2472 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:14,116 - INFO -   Val:   acc1: 88.6200 | acc5: 99.6400 | loss: 0.3301
2025-08-28 06:22:14,116 - INFO -   LR: 0.010000
2025-08-28 06:22:14,132 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-28 06:22:14,337 - INFO - Epoch: [109][0/391] Time 0.204 (0.204) Data 0.180 (0.180) Loss 0.2178 (0.2178) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:22:16,286 - INFO - Epoch: [109][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.3146 (0.2413) Acc@1 87.500 (91.669) Acc@5 99.219 (99.752)
2025-08-28 06:22:16,292 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:16,292 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:18,201 - INFO - Epoch: [109][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.2509 (0.2395) Acc@1 90.625 (91.752) Acc@5 99.219 (99.771)
2025-08-28 06:22:19,371 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:19,371 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:20,165 - INFO - Epoch: [109][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.2861 (0.2417) Acc@1 89.062 (91.681) Acc@5 100.000 (99.798)
2025-08-28 06:22:21,949 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2364 (0.2364) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:22:22,809 - INFO - Epoch 109:
2025-08-28 06:22:22,809 - INFO -   Train: acc1: 91.6060 | acc5: 99.7840 | loss: 0.2451 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:22,810 - INFO -   Val:   acc1: 88.8600 | acc5: 99.6700 | loss: 0.3314
2025-08-28 06:22:22,810 - INFO -   LR: 0.010000
2025-08-28 06:22:22,825 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-28 06:22:23,023 - INFO - Epoch: [110][0/391] Time 0.197 (0.197) Data 0.180 (0.180) Loss 0.2016 (0.2016) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:22:23,665 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:23,665 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:25,027 - INFO - Epoch: [110][100/391] Time 0.014 (0.022) Data 0.000 (0.004) Loss 0.2557 (0.2409) Acc@1 90.625 (91.692) Acc@5 100.000 (99.783)
2025-08-28 06:22:26,675 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:26,675 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:26,897 - INFO - Epoch: [110][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1711 (0.2413) Acc@1 95.312 (91.838) Acc@5 100.000 (99.802)
2025-08-28 06:22:28,759 - INFO - Epoch: [110][300/391] Time 0.023 (0.020) Data 0.000 (0.003) Loss 0.2698 (0.2428) Acc@1 92.188 (91.775) Acc@5 100.000 (99.777)
2025-08-28 06:22:29,729 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:29,729 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:30,650 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2670 (0.2670) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-28 06:22:31,507 - INFO - Epoch 110:
2025-08-28 06:22:31,508 - INFO -   Train: acc1: 91.6940 | acc5: 99.7740 | loss: 0.2433 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:31,508 - INFO -   Val:   acc1: 88.7400 | acc5: 99.6200 | loss: 0.3355
2025-08-28 06:22:31,508 - INFO -   LR: 0.010000
2025-08-28 06:22:31,558 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-28 06:22:31,793 - INFO - Epoch: [111][0/391] Time 0.234 (0.234) Data 0.213 (0.213) Loss 0.1898 (0.1898) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:22:33,623 - INFO - Epoch: [111][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.2674 (0.2312) Acc@1 90.625 (92.164) Acc@5 100.000 (99.845)
2025-08-28 06:22:33,997 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:33,997 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:35,589 - INFO - Epoch: [111][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2169 (0.2394) Acc@1 92.969 (91.896) Acc@5 100.000 (99.845)
2025-08-28 06:22:37,138 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:37,138 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:37,573 - INFO - Epoch: [111][300/391] Time 0.041 (0.020) Data 0.025 (0.003) Loss 0.2710 (0.2436) Acc@1 91.406 (91.642) Acc@5 99.219 (99.785)
2025-08-28 06:22:39,360 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2753 (0.2753) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:22:40,209 - INFO - Epoch 111:
2025-08-28 06:22:40,209 - INFO -   Train: acc1: 91.6640 | acc5: 99.7940 | loss: 0.2422 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:40,209 - INFO -   Val:   acc1: 88.8100 | acc5: 99.6600 | loss: 0.3378
2025-08-28 06:22:40,209 - INFO -   LR: 0.010000
2025-08-28 06:22:40,223 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-28 06:22:40,416 - INFO - Epoch: [112][0/391] Time 0.193 (0.193) Data 0.154 (0.154) Loss 0.1761 (0.1761) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:22:41,355 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:41,356 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:42,421 - INFO - Epoch: [112][100/391] Time 0.018 (0.022) Data 0.000 (0.004) Loss 0.2908 (0.2341) Acc@1 90.625 (91.963) Acc@5 100.000 (99.838)
2025-08-28 06:22:44,336 - INFO - Epoch: [112][200/391] Time 0.026 (0.020) Data 0.012 (0.003) Loss 0.2423 (0.2376) Acc@1 93.750 (91.908) Acc@5 100.000 (99.845)
2025-08-28 06:22:44,497 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:44,497 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:46,188 - INFO - Epoch: [112][300/391] Time 0.021 (0.020) Data 0.002 (0.002) Loss 0.1226 (0.2361) Acc@1 96.875 (91.972) Acc@5 100.000 (99.834)
2025-08-28 06:22:47,491 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:47,492 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:48,051 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2839 (0.2839) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:22:48,915 - INFO - Epoch 112:
2025-08-28 06:22:48,915 - INFO -   Train: acc1: 91.8000 | acc5: 99.8080 | loss: 0.2411 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:48,915 - INFO -   Val:   acc1: 88.6700 | acc5: 99.6400 | loss: 0.3362
2025-08-28 06:22:48,915 - INFO -   LR: 0.010000
2025-08-28 06:22:48,929 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-28 06:22:49,136 - INFO - Epoch: [113][0/391] Time 0.206 (0.206) Data 0.179 (0.179) Loss 0.2361 (0.2361) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:22:51,133 - INFO - Epoch: [113][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.1937 (0.2368) Acc@1 93.750 (92.025) Acc@5 100.000 (99.783)
2025-08-28 06:22:51,755 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:51,756 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:52,933 - INFO - Epoch: [113][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2330 (0.2364) Acc@1 92.969 (91.989) Acc@5 100.000 (99.794)
2025-08-28 06:22:54,850 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:54,850 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:54,917 - INFO - Epoch: [113][300/391] Time 0.017 (0.020) Data 0.006 (0.002) Loss 0.2712 (0.2367) Acc@1 88.281 (91.936) Acc@5 100.000 (99.798)
2025-08-28 06:22:56,908 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3105 (0.3105) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:22:57,747 - INFO - Epoch 113:
2025-08-28 06:22:57,748 - INFO -   Train: acc1: 91.7340 | acc5: 99.8000 | loss: 0.2399 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:22:57,748 - INFO -   Val:   acc1: 88.5200 | acc5: 99.5900 | loss: 0.3441
2025-08-28 06:22:57,748 - INFO -   LR: 0.010000
2025-08-28 06:22:57,762 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-28 06:22:57,961 - INFO - Epoch: [114][0/391] Time 0.198 (0.198) Data 0.179 (0.179) Loss 0.1394 (0.1394) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:22:59,199 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:22:59,200 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:22:59,911 - INFO - Epoch: [114][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.3006 (0.2346) Acc@1 91.406 (91.685) Acc@5 99.219 (99.830)
2025-08-28 06:23:01,851 - INFO - Epoch: [114][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2295 (0.2376) Acc@1 93.750 (91.783) Acc@5 100.000 (99.825)
2025-08-28 06:23:02,345 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:02,345 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:03,737 - INFO - Epoch: [114][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1657 (0.2393) Acc@1 95.312 (91.759) Acc@5 100.000 (99.821)
2025-08-28 06:23:05,338 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:05,338 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:05,586 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.3015 (0.3015) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:23:06,440 - INFO - Epoch 114:
2025-08-28 06:23:06,441 - INFO -   Train: acc1: 91.6960 | acc5: 99.8120 | loss: 0.2425 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:06,441 - INFO -   Val:   acc1: 88.2100 | acc5: 99.7000 | loss: 0.3480
2025-08-28 06:23:06,441 - INFO -   LR: 0.010000
2025-08-28 06:23:06,459 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-28 06:23:06,640 - INFO - Epoch: [115][0/391] Time 0.181 (0.181) Data 0.151 (0.151) Loss 0.3278 (0.3278) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:23:08,643 - INFO - Epoch: [115][100/391] Time 0.029 (0.022) Data 0.015 (0.004) Loss 0.3181 (0.2295) Acc@1 89.844 (92.157) Acc@5 99.219 (99.752)
2025-08-28 06:23:09,596 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:09,596 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:10,573 - INFO - Epoch: [115][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2366 (0.2306) Acc@1 90.625 (92.133) Acc@5 100.000 (99.782)
2025-08-28 06:23:12,521 - INFO - Epoch: [115][300/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2749 (0.2361) Acc@1 90.625 (91.847) Acc@5 99.219 (99.790)
2025-08-28 06:23:12,813 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:12,813 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:14,447 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2653 (0.2653) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:23:15,331 - INFO - Epoch 115:
2025-08-28 06:23:15,331 - INFO -   Train: acc1: 91.7720 | acc5: 99.7980 | loss: 0.2391 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:15,331 - INFO -   Val:   acc1: 88.1600 | acc5: 99.6400 | loss: 0.3427
2025-08-28 06:23:15,331 - INFO -   LR: 0.010000
2025-08-28 06:23:15,347 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-28 06:23:15,554 - INFO - Epoch: [116][0/391] Time 0.207 (0.207) Data 0.179 (0.179) Loss 0.3244 (0.3244) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:23:17,157 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:17,157 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:17,467 - INFO - Epoch: [116][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2525 (0.2397) Acc@1 89.062 (91.731) Acc@5 99.219 (99.884)
2025-08-28 06:23:19,484 - INFO - Epoch: [116][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.2457 (0.2398) Acc@1 92.188 (91.706) Acc@5 100.000 (99.813)
2025-08-28 06:23:20,307 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:20,308 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:21,367 - INFO - Epoch: [116][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2299 (0.2396) Acc@1 89.844 (91.687) Acc@5 100.000 (99.818)
2025-08-28 06:23:23,378 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.2829 (0.2829) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-28 06:23:24,227 - INFO - Epoch 116:
2025-08-28 06:23:24,227 - INFO -   Train: acc1: 91.6180 | acc5: 99.8300 | loss: 0.2412 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:24,227 - INFO -   Val:   acc1: 88.8400 | acc5: 99.5500 | loss: 0.3331
2025-08-28 06:23:24,227 - INFO -   LR: 0.010000
2025-08-28 06:23:24,242 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-28 06:23:24,452 - INFO - Epoch: [117][0/391] Time 0.209 (0.209) Data 0.187 (0.187) Loss 0.2385 (0.2385) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:23:24,720 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:24,720 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:26,397 - INFO - Epoch: [117][100/391] Time 0.024 (0.021) Data 0.000 (0.004) Loss 0.2211 (0.2401) Acc@1 93.750 (91.723) Acc@5 100.000 (99.783)
2025-08-28 06:23:27,772 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:27,773 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:28,304 - INFO - Epoch: [117][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3067 (0.2392) Acc@1 89.844 (91.748) Acc@5 99.219 (99.817)
2025-08-28 06:23:30,244 - INFO - Epoch: [117][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3912 (0.2410) Acc@1 86.719 (91.705) Acc@5 99.219 (99.805)
2025-08-28 06:23:30,882 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:30,882 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:32,151 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3013 (0.3013) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:23:33,032 - INFO - Epoch 117:
2025-08-28 06:23:33,032 - INFO -   Train: acc1: 91.7140 | acc5: 99.8100 | loss: 0.2420 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:33,032 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6300 | loss: 0.3333
2025-08-28 06:23:33,032 - INFO -   LR: 0.010000
2025-08-28 06:23:33,046 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-28 06:23:33,266 - INFO - Epoch: [118][0/391] Time 0.219 (0.219) Data 0.194 (0.194) Loss 0.2077 (0.2077) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:23:35,237 - INFO - Epoch: [118][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.2774 (0.2420) Acc@1 90.625 (91.762) Acc@5 100.000 (99.776)
2025-08-28 06:23:35,275 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:35,275 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:37,147 - INFO - Epoch: [118][200/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2415 (0.2434) Acc@1 90.625 (91.597) Acc@5 100.000 (99.786)
2025-08-28 06:23:38,255 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:38,256 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:39,035 - INFO - Epoch: [118][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2727 (0.2403) Acc@1 88.281 (91.653) Acc@5 100.000 (99.803)
2025-08-28 06:23:40,823 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2256 (0.2256) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:23:41,682 - INFO - Epoch 118:
2025-08-28 06:23:41,683 - INFO -   Train: acc1: 91.6480 | acc5: 99.7860 | loss: 0.2414 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:41,683 - INFO -   Val:   acc1: 88.5600 | acc5: 99.5900 | loss: 0.3375
2025-08-28 06:23:41,683 - INFO -   LR: 0.010000
2025-08-28 06:23:41,699 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-28 06:23:41,922 - INFO - Epoch: [119][0/391] Time 0.223 (0.223) Data 0.197 (0.197) Loss 0.2201 (0.2201) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:23:42,467 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:42,468 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:43,822 - INFO - Epoch: [119][100/391] Time 0.034 (0.021) Data 0.020 (0.004) Loss 0.1739 (0.2335) Acc@1 95.312 (92.110) Acc@5 100.000 (99.822)
2025-08-28 06:23:45,461 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:45,461 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:45,636 - INFO - Epoch: [119][200/391] Time 0.024 (0.020) Data 0.010 (0.003) Loss 0.2900 (0.2368) Acc@1 90.625 (91.857) Acc@5 99.219 (99.802)
2025-08-28 06:23:47,540 - INFO - Epoch: [119][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2126 (0.2367) Acc@1 92.969 (91.819) Acc@5 100.000 (99.803)
2025-08-28 06:23:48,512 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:48,512 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:49,461 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3207 (0.3207) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:23:50,345 - INFO - Epoch 119:
2025-08-28 06:23:50,346 - INFO -   Train: acc1: 91.6880 | acc5: 99.7980 | loss: 0.2405 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:50,346 - INFO -   Val:   acc1: 88.2500 | acc5: 99.5600 | loss: 0.3557
2025-08-28 06:23:50,346 - INFO -   LR: 0.010000
2025-08-28 06:23:50,360 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-28 06:23:50,552 - INFO - Epoch: [120][0/391] Time 0.191 (0.191) Data 0.167 (0.167) Loss 0.2127 (0.2127) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:23:52,496 - INFO - Epoch: [120][100/391] Time 0.022 (0.021) Data 0.000 (0.005) Loss 0.2633 (0.2380) Acc@1 90.625 (91.816) Acc@5 100.000 (99.807)
2025-08-28 06:23:52,831 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:52,831 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:54,369 - INFO - Epoch: [120][200/391] Time 0.032 (0.020) Data 0.000 (0.004) Loss 0.1627 (0.2413) Acc@1 96.094 (91.694) Acc@5 100.000 (99.821)
2025-08-28 06:23:55,813 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:23:55,813 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:23:56,216 - INFO - Epoch: [120][300/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.2645 (0.2413) Acc@1 90.625 (91.705) Acc@5 100.000 (99.811)
2025-08-28 06:23:58,014 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.3337 (0.3337) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:23:58,893 - INFO - Epoch 120:
2025-08-28 06:23:58,893 - INFO -   Train: acc1: 91.5620 | acc5: 99.8180 | loss: 0.2429 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:23:58,893 - INFO -   Val:   acc1: 87.7800 | acc5: 99.5500 | loss: 0.3657
2025-08-28 06:23:58,893 - INFO -   LR: 0.010000
2025-08-28 06:23:58,941 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-28 06:23:59,113 - INFO - Epoch: [121][0/391] Time 0.171 (0.171) Data 0.146 (0.146) Loss 0.2389 (0.2389) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:24:00,092 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:00,093 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:01,067 - INFO - Epoch: [121][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1756 (0.2296) Acc@1 93.750 (92.017) Acc@5 100.000 (99.783)
2025-08-28 06:24:03,042 - INFO - Epoch: [121][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2542 (0.2361) Acc@1 90.625 (91.702) Acc@5 100.000 (99.798)
2025-08-28 06:24:03,210 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:03,210 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:04,861 - INFO - Epoch: [121][300/391] Time 0.021 (0.020) Data 0.002 (0.002) Loss 0.4543 (0.2422) Acc@1 89.062 (91.578) Acc@5 99.219 (99.779)
2025-08-28 06:24:06,264 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:06,264 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:06,787 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2877 (0.2877) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:24:07,660 - INFO - Epoch 121:
2025-08-28 06:24:07,661 - INFO -   Train: acc1: 91.6080 | acc5: 99.7940 | loss: 0.2430 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:24:07,661 - INFO -   Val:   acc1: 88.4200 | acc5: 99.5700 | loss: 0.3418
2025-08-28 06:24:07,661 - INFO -   LR: 0.010000
2025-08-28 06:24:07,675 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-28 06:24:07,879 - INFO - Epoch: [122][0/391] Time 0.202 (0.202) Data 0.180 (0.180) Loss 0.1898 (0.1898) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:24:09,786 - INFO - Epoch: [122][100/391] Time 0.021 (0.021) Data 0.000 (0.003) Loss 0.2900 (0.2346) Acc@1 89.062 (91.754) Acc@5 100.000 (99.791)
2025-08-28 06:24:10,462 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:10,462 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:11,682 - INFO - Epoch: [122][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2483 (0.2409) Acc@1 93.750 (91.562) Acc@5 99.219 (99.802)
2025-08-28 06:24:13,513 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:13,514 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:13,560 - INFO - Epoch: [122][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2368 (0.2399) Acc@1 92.969 (91.598) Acc@5 100.000 (99.769)
2025-08-28 06:24:15,388 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.2793 (0.2793) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:24:16,274 - INFO - Epoch 122:
2025-08-28 06:24:16,274 - INFO -   Train: acc1: 91.4820 | acc5: 99.7560 | loss: 0.2426 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:24:16,274 - INFO -   Val:   acc1: 88.2700 | acc5: 99.6000 | loss: 0.3490
2025-08-28 06:24:16,274 - INFO -   LR: 0.010000
2025-08-28 06:24:16,288 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-28 06:24:16,501 - INFO - Epoch: [123][0/391] Time 0.212 (0.212) Data 0.179 (0.179) Loss 0.2232 (0.2232) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 06:24:17,874 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:17,874 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:18,549 - INFO - Epoch: [123][100/391] Time 0.019 (0.022) Data 0.000 (0.004) Loss 0.2567 (0.2472) Acc@1 92.188 (91.468) Acc@5 100.000 (99.768)
2025-08-28 06:24:20,513 - INFO - Epoch: [123][200/391] Time 0.029 (0.021) Data 0.013 (0.003) Loss 0.2968 (0.2402) Acc@1 87.500 (91.702) Acc@5 100.000 (99.794)
2025-08-28 06:24:21,020 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:21,020 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:22,410 - INFO - Epoch: [123][300/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.2462 (0.2414) Acc@1 92.188 (91.655) Acc@5 99.219 (99.798)
2025-08-28 06:24:24,051 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:24,051 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:24,278 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3168 (0.3168) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:24:25,149 - INFO - Epoch 123:
2025-08-28 06:24:25,149 - INFO -   Train: acc1: 91.6160 | acc5: 99.7940 | loss: 0.2428 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:24:25,149 - INFO -   Val:   acc1: 87.8600 | acc5: 99.4900 | loss: 0.3750
2025-08-28 06:24:25,150 - INFO -   LR: 0.010000
2025-08-28 06:24:25,164 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-28 06:24:25,370 - INFO - Epoch: [124][0/391] Time 0.205 (0.205) Data 0.180 (0.180) Loss 0.2513 (0.2513) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:24:27,305 - INFO - Epoch: [124][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.3747 (0.2351) Acc@1 85.938 (91.963) Acc@5 100.000 (99.799)
2025-08-28 06:24:28,367 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:28,367 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:29,180 - INFO - Epoch: [124][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2170 (0.2400) Acc@1 92.969 (91.717) Acc@5 100.000 (99.810)
2025-08-28 06:24:31,012 - INFO - Epoch: [124][300/391] Time 0.025 (0.019) Data 0.000 (0.002) Loss 0.1838 (0.2440) Acc@1 92.969 (91.601) Acc@5 100.000 (99.787)
2025-08-28 06:24:31,260 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:31,261 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:32,866 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2751 (0.2751) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:24:33,735 - INFO - Epoch 124:
2025-08-28 06:24:33,736 - INFO -   Train: acc1: 91.4720 | acc5: 99.7900 | loss: 0.2460 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:24:33,736 - INFO -   Val:   acc1: 87.8800 | acc5: 99.5100 | loss: 0.3528
2025-08-28 06:24:33,736 - INFO -   LR: 0.010000
2025-08-28 06:24:33,752 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-28 06:24:33,925 - INFO - Epoch: [125][0/391] Time 0.171 (0.171) Data 0.154 (0.154) Loss 0.2509 (0.2509) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:24:35,625 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:35,625 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:35,950 - INFO - Epoch: [125][100/391] Time 0.017 (0.022) Data 0.000 (0.004) Loss 0.1606 (0.2358) Acc@1 95.312 (91.808) Acc@5 100.000 (99.783)
2025-08-28 06:24:37,855 - INFO - Epoch: [125][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1519 (0.2391) Acc@1 96.094 (91.783) Acc@5 100.000 (99.817)
2025-08-28 06:24:38,685 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:38,685 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:39,713 - INFO - Epoch: [125][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1428 (0.2388) Acc@1 96.875 (91.884) Acc@5 100.000 (99.805)
2025-08-28 06:24:41,549 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.2854 (0.2854) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:24:42,428 - INFO - Epoch 125:
2025-08-28 06:24:42,429 - INFO -   Train: acc1: 91.7480 | acc5: 99.8040 | loss: 0.2412 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:24:42,429 - INFO -   Val:   acc1: 87.9900 | acc5: 99.5700 | loss: 0.3562
2025-08-28 06:24:42,429 - INFO -   LR: 0.010000
2025-08-28 06:24:42,446 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-28 06:24:42,637 - INFO - Epoch: [126][0/391] Time 0.190 (0.190) Data 0.166 (0.166) Loss 0.3484 (0.3484) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-28 06:24:42,894 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:42,895 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:44,608 - INFO - Epoch: [126][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2581 (0.2390) Acc@1 89.062 (91.662) Acc@5 100.000 (99.853)
2025-08-28 06:24:46,003 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:46,003 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:46,503 - INFO - Epoch: [126][200/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2691 (0.2396) Acc@1 92.188 (91.667) Acc@5 100.000 (99.833)
2025-08-28 06:24:48,426 - INFO - Epoch: [126][300/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2745 (0.2401) Acc@1 92.188 (91.718) Acc@5 99.219 (99.834)
2025-08-28 06:24:48,994 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:48,994 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:50,292 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.3493 (0.3493) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-28 06:24:51,144 - INFO - Epoch 126:
2025-08-28 06:24:51,144 - INFO -   Train: acc1: 91.5760 | acc5: 99.8180 | loss: 0.2427 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:24:51,144 - INFO -   Val:   acc1: 87.7300 | acc5: 99.5600 | loss: 0.3606
2025-08-28 06:24:51,144 - INFO -   LR: 0.010000
2025-08-28 06:24:51,161 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-28 06:24:51,365 - INFO - Epoch: [127][0/391] Time 0.202 (0.202) Data 0.183 (0.183) Loss 0.2022 (0.2022) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:24:53,346 - INFO - Epoch: [127][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.3243 (0.2412) Acc@1 91.406 (91.754) Acc@5 100.000 (99.838)
2025-08-28 06:24:53,394 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:53,394 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:55,334 - INFO - Epoch: [127][200/391] Time 0.028 (0.021) Data 0.011 (0.002) Loss 0.3016 (0.2429) Acc@1 91.406 (91.535) Acc@5 100.000 (99.848)
2025-08-28 06:24:56,569 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:24:56,569 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:24:57,295 - INFO - Epoch: [127][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3031 (0.2432) Acc@1 91.406 (91.518) Acc@5 100.000 (99.836)
2025-08-28 06:24:59,163 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.2796 (0.2796) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:25:00,044 - INFO - Epoch 127:
2025-08-28 06:25:00,044 - INFO -   Train: acc1: 91.4740 | acc5: 99.8100 | loss: 0.2454 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:00,044 - INFO -   Val:   acc1: 88.2000 | acc5: 99.4500 | loss: 0.3580
2025-08-28 06:25:00,044 - INFO -   LR: 0.010000
2025-08-28 06:25:00,062 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-28 06:25:00,296 - INFO - Epoch: [128][0/391] Time 0.233 (0.233) Data 0.207 (0.207) Loss 0.3068 (0.3068) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:25:00,931 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:00,931 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:02,264 - INFO - Epoch: [128][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.2340 (0.2426) Acc@1 92.188 (91.399) Acc@5 100.000 (99.807)
2025-08-28 06:25:03,958 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:03,958 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:04,127 - INFO - Epoch: [128][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1744 (0.2408) Acc@1 95.312 (91.531) Acc@5 100.000 (99.790)
2025-08-28 06:25:05,972 - INFO - Epoch: [128][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1674 (0.2473) Acc@1 94.531 (91.354) Acc@5 100.000 (99.772)
2025-08-28 06:25:06,948 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:06,948 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:07,804 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.3098 (0.3098) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:25:08,642 - INFO - Epoch 128:
2025-08-28 06:25:08,642 - INFO -   Train: acc1: 91.4080 | acc5: 99.7660 | loss: 0.2470 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:08,642 - INFO -   Val:   acc1: 87.7700 | acc5: 99.5300 | loss: 0.3707
2025-08-28 06:25:08,642 - INFO -   LR: 0.010000
2025-08-28 06:25:08,657 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-28 06:25:08,873 - INFO - Epoch: [129][0/391] Time 0.215 (0.215) Data 0.196 (0.196) Loss 0.1889 (0.1889) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:25:10,776 - INFO - Epoch: [129][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.2055 (0.2414) Acc@1 92.188 (91.669) Acc@5 100.000 (99.814)
2025-08-28 06:25:11,177 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:11,177 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:12,661 - INFO - Epoch: [129][200/391] Time 0.023 (0.020) Data 0.007 (0.002) Loss 0.2222 (0.2428) Acc@1 89.844 (91.655) Acc@5 100.000 (99.782)
2025-08-28 06:25:14,100 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:14,100 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:14,430 - INFO - Epoch: [129][300/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.2277 (0.2433) Acc@1 91.406 (91.640) Acc@5 100.000 (99.787)
2025-08-28 06:25:16,289 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2920 (0.2920) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:25:17,147 - INFO - Epoch 129:
2025-08-28 06:25:17,147 - INFO -   Train: acc1: 91.4400 | acc5: 99.7880 | loss: 0.2480 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:17,147 - INFO -   Val:   acc1: 87.9400 | acc5: 99.6000 | loss: 0.3679
2025-08-28 06:25:17,147 - INFO -   LR: 0.010000
2025-08-28 06:25:17,164 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-28 06:25:17,320 - INFO - Epoch: [130][0/391] Time 0.155 (0.155) Data 0.137 (0.137) Loss 0.2575 (0.2575) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:25:18,377 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:18,378 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:19,378 - INFO - Epoch: [130][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.2009 (0.2419) Acc@1 92.969 (91.723) Acc@5 99.219 (99.783)
2025-08-28 06:25:21,334 - INFO - Epoch: [130][200/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.2003 (0.2443) Acc@1 92.969 (91.651) Acc@5 99.219 (99.798)
2025-08-28 06:25:21,481 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:21,482 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:23,240 - INFO - Epoch: [130][300/391] Time 0.032 (0.020) Data 0.020 (0.002) Loss 0.2630 (0.2481) Acc@1 90.625 (91.474) Acc@5 100.000 (99.779)
2025-08-28 06:25:24,510 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:24,511 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:25,044 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2934 (0.2934) Acc@1 91.406 (91.406) Acc@5 98.438 (98.438)
2025-08-28 06:25:25,881 - INFO - Epoch 130:
2025-08-28 06:25:25,881 - INFO -   Train: acc1: 91.4900 | acc5: 99.7840 | loss: 0.2470 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:25,881 - INFO -   Val:   acc1: 88.8100 | acc5: 99.6100 | loss: 0.3346
2025-08-28 06:25:25,881 - INFO -   LR: 0.010000
2025-08-28 06:25:25,931 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-28 06:25:26,125 - INFO - Epoch: [131][0/391] Time 0.193 (0.193) Data 0.175 (0.175) Loss 0.1405 (0.1405) Acc@1 96.094 (96.094) Acc@5 99.219 (99.219)
2025-08-28 06:25:28,070 - INFO - Epoch: [131][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.2395 (0.2461) Acc@1 92.188 (91.460) Acc@5 99.219 (99.776)
2025-08-28 06:25:28,867 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:28,867 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:30,057 - INFO - Epoch: [131][200/391] Time 0.021 (0.021) Data 0.000 (0.002) Loss 0.1986 (0.2462) Acc@1 92.969 (91.507) Acc@5 100.000 (99.775)
2025-08-28 06:25:31,954 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:31,954 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:31,982 - INFO - Epoch: [131][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.3610 (0.2452) Acc@1 88.281 (91.562) Acc@5 100.000 (99.769)
2025-08-28 06:25:33,845 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2833 (0.2833) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:25:34,711 - INFO - Epoch 131:
2025-08-28 06:25:34,711 - INFO -   Train: acc1: 91.4280 | acc5: 99.7700 | loss: 0.2474 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:34,711 - INFO -   Val:   acc1: 87.9000 | acc5: 99.4700 | loss: 0.3639
2025-08-28 06:25:34,711 - INFO -   LR: 0.010000
2025-08-28 06:25:34,728 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-28 06:25:34,935 - INFO - Epoch: [132][0/391] Time 0.205 (0.205) Data 0.174 (0.174) Loss 0.2952 (0.2952) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:25:36,314 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:36,315 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:36,938 - INFO - Epoch: [132][100/391] Time 0.033 (0.022) Data 0.000 (0.004) Loss 0.1827 (0.2463) Acc@1 93.750 (91.321) Acc@5 99.219 (99.876)
2025-08-28 06:25:38,892 - INFO - Epoch: [132][200/391] Time 0.013 (0.021) Data 0.000 (0.003) Loss 0.1647 (0.2404) Acc@1 94.531 (91.674) Acc@5 100.000 (99.864)
2025-08-28 06:25:39,342 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:39,342 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:40,771 - INFO - Epoch: [132][300/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3128 (0.2421) Acc@1 89.062 (91.655) Acc@5 98.438 (99.849)
2025-08-28 06:25:42,375 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:42,376 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:42,602 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2597 (0.2597) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 06:25:43,450 - INFO - Epoch 132:
2025-08-28 06:25:43,450 - INFO -   Train: acc1: 91.4360 | acc5: 99.8320 | loss: 0.2464 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:43,450 - INFO -   Val:   acc1: 87.6700 | acc5: 99.5300 | loss: 0.3656
2025-08-28 06:25:43,450 - INFO -   LR: 0.010000
2025-08-28 06:25:43,469 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-28 06:25:43,657 - INFO - Epoch: [133][0/391] Time 0.187 (0.187) Data 0.162 (0.162) Loss 0.1988 (0.1988) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:25:45,689 - INFO - Epoch: [133][100/391] Time 0.017 (0.022) Data 0.000 (0.004) Loss 0.2706 (0.2426) Acc@1 89.062 (91.453) Acc@5 99.219 (99.799)
2025-08-28 06:25:46,763 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:46,763 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:47,667 - INFO - Epoch: [133][200/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.2739 (0.2465) Acc@1 90.625 (91.426) Acc@5 100.000 (99.798)
2025-08-28 06:25:49,470 - INFO - Epoch: [133][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.2599 (0.2474) Acc@1 90.625 (91.458) Acc@5 100.000 (99.772)
2025-08-28 06:25:49,818 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:49,818 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:51,400 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2856 (0.2856) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:25:52,252 - INFO - Epoch 133:
2025-08-28 06:25:52,252 - INFO -   Train: acc1: 91.3260 | acc5: 99.7740 | loss: 0.2507 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:25:52,252 - INFO -   Val:   acc1: 88.0700 | acc5: 99.6000 | loss: 0.3532
2025-08-28 06:25:52,252 - INFO -   LR: 0.010000
2025-08-28 06:25:52,267 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-28 06:25:52,471 - INFO - Epoch: [134][0/391] Time 0.204 (0.204) Data 0.185 (0.185) Loss 0.2466 (0.2466) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:25:54,067 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:54,068 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:54,326 - INFO - Epoch: [134][100/391] Time 0.024 (0.020) Data 0.012 (0.003) Loss 0.1455 (0.2424) Acc@1 94.531 (91.677) Acc@5 100.000 (99.791)
2025-08-28 06:25:56,287 - INFO - Epoch: [134][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2894 (0.2428) Acc@1 89.062 (91.639) Acc@5 99.219 (99.794)
2025-08-28 06:25:57,202 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:25:57,202 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:25:58,257 - INFO - Epoch: [134][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.3033 (0.2478) Acc@1 90.625 (91.443) Acc@5 100.000 (99.792)
2025-08-28 06:26:00,167 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2395 (0.2395) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:26:01,024 - INFO - Epoch 134:
2025-08-28 06:26:01,024 - INFO -   Train: acc1: 91.4100 | acc5: 99.7920 | loss: 0.2496 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:01,025 - INFO -   Val:   acc1: 86.9500 | acc5: 99.5700 | loss: 0.3853
2025-08-28 06:26:01,025 - INFO -   LR: 0.010000
2025-08-28 06:26:01,042 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-28 06:26:01,218 - INFO - Epoch: [135][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.3352 (0.3352) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:26:01,559 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:01,559 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:03,218 - INFO - Epoch: [135][100/391] Time 0.013 (0.022) Data 0.000 (0.003) Loss 0.3201 (0.2458) Acc@1 87.500 (91.615) Acc@5 100.000 (99.799)
2025-08-28 06:26:04,668 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:04,668 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:05,111 - INFO - Epoch: [135][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.2903 (0.2480) Acc@1 91.406 (91.519) Acc@5 99.219 (99.802)
2025-08-28 06:26:07,125 - INFO - Epoch: [135][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.3250 (0.2496) Acc@1 85.156 (91.474) Acc@5 100.000 (99.795)
2025-08-28 06:26:07,819 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:07,819 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:09,060 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.2503 (0.2503) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:26:09,900 - INFO - Epoch 135:
2025-08-28 06:26:09,901 - INFO -   Train: acc1: 91.4140 | acc5: 99.7780 | loss: 0.2506 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:09,901 - INFO -   Val:   acc1: 87.9800 | acc5: 99.5600 | loss: 0.3527
2025-08-28 06:26:09,901 - INFO -   LR: 0.010000
2025-08-28 06:26:09,918 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-28 06:26:10,114 - INFO - Epoch: [136][0/391] Time 0.194 (0.194) Data 0.177 (0.177) Loss 0.1877 (0.1877) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:26:12,115 - INFO - Epoch: [136][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.2176 (0.2552) Acc@1 94.531 (91.252) Acc@5 100.000 (99.714)
2025-08-28 06:26:12,181 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:12,181 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:14,096 - INFO - Epoch: [136][200/391] Time 0.025 (0.021) Data 0.000 (0.003) Loss 0.3446 (0.2519) Acc@1 89.062 (91.262) Acc@5 99.219 (99.775)
2025-08-28 06:26:15,327 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:15,327 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:16,047 - INFO - Epoch: [136][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2973 (0.2510) Acc@1 89.844 (91.292) Acc@5 100.000 (99.792)
2025-08-28 06:26:17,926 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.2902 (0.2902) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:26:18,770 - INFO - Epoch 136:
2025-08-28 06:26:18,771 - INFO -   Train: acc1: 91.2500 | acc5: 99.7940 | loss: 0.2519 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:18,771 - INFO -   Val:   acc1: 87.8400 | acc5: 99.5500 | loss: 0.3557
2025-08-28 06:26:18,771 - INFO -   LR: 0.010000
2025-08-28 06:26:18,788 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-28 06:26:19,000 - INFO - Epoch: [137][0/391] Time 0.211 (0.211) Data 0.189 (0.189) Loss 0.2458 (0.2458) Acc@1 92.188 (92.188) Acc@5 98.438 (98.438)
2025-08-28 06:26:19,630 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:19,631 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:20,913 - INFO - Epoch: [137][100/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.1870 (0.2411) Acc@1 92.969 (91.476) Acc@5 100.000 (99.868)
2025-08-28 06:26:22,721 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:22,721 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:22,862 - INFO - Epoch: [137][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2248 (0.2483) Acc@1 92.188 (91.356) Acc@5 99.219 (99.794)
2025-08-28 06:26:24,736 - INFO - Epoch: [137][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.3852 (0.2484) Acc@1 86.719 (91.336) Acc@5 100.000 (99.785)
2025-08-28 06:26:25,791 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:25,791 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:26,722 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2721 (0.2721) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:26:27,620 - INFO - Epoch 137:
2025-08-28 06:26:27,620 - INFO -   Train: acc1: 91.2580 | acc5: 99.7820 | loss: 0.2510 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:27,620 - INFO -   Val:   acc1: 88.1000 | acc5: 99.6000 | loss: 0.3486
2025-08-28 06:26:27,620 - INFO -   LR: 0.010000
2025-08-28 06:26:27,640 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-28 06:26:27,825 - INFO - Epoch: [138][0/391] Time 0.184 (0.184) Data 0.163 (0.163) Loss 0.2154 (0.2154) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 06:26:29,871 - INFO - Epoch: [138][100/391] Time 0.018 (0.022) Data 0.000 (0.005) Loss 0.2403 (0.2441) Acc@1 92.188 (91.692) Acc@5 100.000 (99.822)
2025-08-28 06:26:30,314 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:30,314 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:31,728 - INFO - Epoch: [138][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2042 (0.2443) Acc@1 92.969 (91.698) Acc@5 100.000 (99.778)
2025-08-28 06:26:33,313 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:33,314 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:33,662 - INFO - Epoch: [138][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.2050 (0.2485) Acc@1 92.969 (91.450) Acc@5 100.000 (99.772)
2025-08-28 06:26:35,602 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.3706 (0.3706) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:26:36,521 - INFO - Epoch 138:
2025-08-28 06:26:36,522 - INFO -   Train: acc1: 91.3440 | acc5: 99.7680 | loss: 0.2504 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:36,522 - INFO -   Val:   acc1: 86.4300 | acc5: 99.5700 | loss: 0.4116
2025-08-28 06:26:36,522 - INFO -   LR: 0.010000
2025-08-28 06:26:36,539 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-28 06:26:36,738 - INFO - Epoch: [139][0/391] Time 0.198 (0.198) Data 0.179 (0.179) Loss 0.3734 (0.3734) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-28 06:26:37,777 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:37,777 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:38,768 - INFO - Epoch: [139][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.3070 (0.2397) Acc@1 88.281 (91.515) Acc@5 100.000 (99.799)
2025-08-28 06:26:40,620 - INFO - Epoch: [139][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2697 (0.2468) Acc@1 91.406 (91.313) Acc@5 100.000 (99.810)
2025-08-28 06:26:40,813 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:40,813 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:42,518 - INFO - Epoch: [139][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.3795 (0.2500) Acc@1 87.500 (91.219) Acc@5 100.000 (99.813)
2025-08-28 06:26:43,781 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:43,781 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:44,346 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.2820 (0.2820) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:26:45,240 - INFO - Epoch 139:
2025-08-28 06:26:45,240 - INFO -   Train: acc1: 91.1540 | acc5: 99.7920 | loss: 0.2523 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:45,240 - INFO -   Val:   acc1: 87.1700 | acc5: 99.5700 | loss: 0.3820
2025-08-28 06:26:45,240 - INFO -   LR: 0.010000
2025-08-28 06:26:45,257 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-28 06:26:45,437 - INFO - Epoch: [140][0/391] Time 0.178 (0.178) Data 0.154 (0.154) Loss 0.2405 (0.2405) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:26:47,415 - INFO - Epoch: [140][100/391] Time 0.035 (0.021) Data 0.014 (0.004) Loss 0.2542 (0.2486) Acc@1 87.500 (91.120) Acc@5 100.000 (99.876)
2025-08-28 06:26:48,188 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:48,189 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:49,294 - INFO - Epoch: [140][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2660 (0.2556) Acc@1 91.406 (91.025) Acc@5 100.000 (99.833)
2025-08-28 06:26:51,110 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:51,110 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:51,124 - INFO - Epoch: [140][300/391] Time 0.020 (0.019) Data 0.001 (0.002) Loss 0.2429 (0.2524) Acc@1 89.844 (91.225) Acc@5 100.000 (99.808)
2025-08-28 06:26:52,951 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.2929 (0.2929) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:26:53,799 - INFO - Epoch 140:
2025-08-28 06:26:53,799 - INFO -   Train: acc1: 91.2340 | acc5: 99.7920 | loss: 0.2528 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:26:53,799 - INFO -   Val:   acc1: 87.1600 | acc5: 99.5100 | loss: 0.3936
2025-08-28 06:26:53,799 - INFO -   LR: 0.010000
2025-08-28 06:26:53,854 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-28 06:26:54,055 - INFO - Epoch: [141][0/391] Time 0.200 (0.200) Data 0.172 (0.172) Loss 0.3379 (0.3379) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:26:55,325 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:55,326 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:55,916 - INFO - Epoch: [141][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1677 (0.2449) Acc@1 94.531 (91.491) Acc@5 100.000 (99.752)
2025-08-28 06:26:57,801 - INFO - Epoch: [141][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1967 (0.2476) Acc@1 94.531 (91.453) Acc@5 100.000 (99.747)
2025-08-28 06:26:58,327 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:26:58,327 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:26:59,680 - INFO - Epoch: [141][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.2254 (0.2536) Acc@1 91.406 (91.279) Acc@5 100.000 (99.756)
2025-08-28 06:27:01,419 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:01,420 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:01,636 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.3049 (0.3049) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:27:02,509 - INFO - Epoch 141:
2025-08-28 06:27:02,509 - INFO -   Train: acc1: 91.2320 | acc5: 99.7640 | loss: 0.2544 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:02,509 - INFO -   Val:   acc1: 87.5600 | acc5: 99.6000 | loss: 0.3630
2025-08-28 06:27:02,510 - INFO -   LR: 0.010000
2025-08-28 06:27:02,528 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-28 06:27:02,729 - INFO - Epoch: [142][0/391] Time 0.199 (0.199) Data 0.182 (0.182) Loss 0.1581 (0.1581) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:27:04,643 - INFO - Epoch: [142][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.2583 (0.2542) Acc@1 89.844 (91.019) Acc@5 100.000 (99.876)
2025-08-28 06:27:05,675 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:05,675 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:06,481 - INFO - Epoch: [142][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2576 (0.2513) Acc@1 89.844 (91.088) Acc@5 100.000 (99.829)
2025-08-28 06:27:08,333 - INFO - Epoch: [142][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3378 (0.2524) Acc@1 87.500 (91.113) Acc@5 100.000 (99.824)
2025-08-28 06:27:08,690 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:08,690 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:10,198 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2846 (0.2846) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-28 06:27:11,076 - INFO - Epoch 142:
2025-08-28 06:27:11,076 - INFO -   Train: acc1: 91.1240 | acc5: 99.8080 | loss: 0.2531 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:11,076 - INFO -   Val:   acc1: 88.3100 | acc5: 99.6000 | loss: 0.3480
2025-08-28 06:27:11,076 - INFO -   LR: 0.010000
2025-08-28 06:27:11,093 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-28 06:27:11,306 - INFO - Epoch: [143][0/391] Time 0.212 (0.212) Data 0.193 (0.193) Loss 0.2847 (0.2847) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:27:12,938 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:12,939 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:13,202 - INFO - Epoch: [143][100/391] Time 0.021 (0.021) Data 0.008 (0.005) Loss 0.2241 (0.2445) Acc@1 92.188 (91.708) Acc@5 100.000 (99.822)
2025-08-28 06:27:15,084 - INFO - Epoch: [143][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1859 (0.2492) Acc@1 93.750 (91.441) Acc@5 100.000 (99.817)
2025-08-28 06:27:15,966 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:15,966 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:16,986 - INFO - Epoch: [143][300/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.2213 (0.2503) Acc@1 92.969 (91.391) Acc@5 100.000 (99.798)
2025-08-28 06:27:18,918 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.3288 (0.3288) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:27:19,783 - INFO - Epoch 143:
2025-08-28 06:27:19,783 - INFO -   Train: acc1: 91.3180 | acc5: 99.7900 | loss: 0.2521 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:19,784 - INFO -   Val:   acc1: 87.4000 | acc5: 99.4800 | loss: 0.3789
2025-08-28 06:27:19,784 - INFO -   LR: 0.010000
2025-08-28 06:27:19,799 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-28 06:27:20,050 - INFO - Epoch: [144][0/391] Time 0.250 (0.250) Data 0.207 (0.207) Loss 0.3248 (0.3248) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:27:20,294 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:20,295 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:21,863 - INFO - Epoch: [144][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2507 (0.2577) Acc@1 89.062 (91.306) Acc@5 100.000 (99.776)
2025-08-28 06:27:23,293 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:23,293 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:23,722 - INFO - Epoch: [144][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2596 (0.2600) Acc@1 92.969 (91.099) Acc@5 100.000 (99.790)
2025-08-28 06:27:25,539 - INFO - Epoch: [144][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.2311 (0.2568) Acc@1 91.406 (91.157) Acc@5 100.000 (99.800)
2025-08-28 06:27:26,226 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:26,226 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:27,372 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2687 (0.2687) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-28 06:27:28,224 - INFO - Epoch 144:
2025-08-28 06:27:28,224 - INFO -   Train: acc1: 91.2080 | acc5: 99.7900 | loss: 0.2557 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:28,224 - INFO -   Val:   acc1: 88.3500 | acc5: 99.6400 | loss: 0.3412
2025-08-28 06:27:28,224 - INFO -   LR: 0.010000
2025-08-28 06:27:28,240 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-28 06:27:28,452 - INFO - Epoch: [145][0/391] Time 0.211 (0.211) Data 0.185 (0.185) Loss 0.2402 (0.2402) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:27:30,274 - INFO - Epoch: [145][100/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2348 (0.2409) Acc@1 91.406 (91.747) Acc@5 99.219 (99.752)
2025-08-28 06:27:30,378 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:30,378 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:32,199 - INFO - Epoch: [145][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.1854 (0.2466) Acc@1 92.969 (91.461) Acc@5 100.000 (99.782)
2025-08-28 06:27:33,386 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:33,387 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:34,029 - INFO - Epoch: [145][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2314 (0.2514) Acc@1 93.750 (91.206) Acc@5 100.000 (99.777)
2025-08-28 06:27:35,865 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2871 (0.2871) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-28 06:27:36,734 - INFO - Epoch 145:
2025-08-28 06:27:36,734 - INFO -   Train: acc1: 91.1560 | acc5: 99.7980 | loss: 0.2540 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:36,734 - INFO -   Val:   acc1: 88.1100 | acc5: 99.5700 | loss: 0.3621
2025-08-28 06:27:36,735 - INFO -   LR: 0.010000
2025-08-28 06:27:36,753 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-28 06:27:36,945 - INFO - Epoch: [146][0/391] Time 0.190 (0.190) Data 0.163 (0.163) Loss 0.3931 (0.3931) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-28 06:27:37,573 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:37,573 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:38,757 - INFO - Epoch: [146][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1985 (0.2403) Acc@1 92.188 (91.662) Acc@5 100.000 (99.783)
2025-08-28 06:27:40,527 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:40,527 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:40,641 - INFO - Epoch: [146][200/391] Time 0.035 (0.019) Data 0.023 (0.003) Loss 0.2200 (0.2492) Acc@1 91.406 (91.348) Acc@5 99.219 (99.775)
2025-08-28 06:27:42,388 - INFO - Epoch: [146][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.2161 (0.2483) Acc@1 93.750 (91.328) Acc@5 100.000 (99.790)
2025-08-28 06:27:43,390 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:43,390 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:44,232 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.3320 (0.3320) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:27:45,081 - INFO - Epoch 146:
2025-08-28 06:27:45,082 - INFO -   Train: acc1: 91.2320 | acc5: 99.7980 | loss: 0.2508 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:45,082 - INFO -   Val:   acc1: 87.4800 | acc5: 99.5500 | loss: 0.3796
2025-08-28 06:27:45,082 - INFO -   LR: 0.010000
2025-08-28 06:27:45,098 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-28 06:27:45,296 - INFO - Epoch: [147][0/391] Time 0.197 (0.197) Data 0.175 (0.175) Loss 0.3131 (0.3131) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:27:47,138 - INFO - Epoch: [147][100/391] Time 0.035 (0.020) Data 0.020 (0.003) Loss 0.2756 (0.2569) Acc@1 87.500 (91.383) Acc@5 100.000 (99.760)
2025-08-28 06:27:47,571 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:47,572 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:48,956 - INFO - Epoch: [147][200/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.3006 (0.2559) Acc@1 91.406 (91.278) Acc@5 99.219 (99.771)
2025-08-28 06:27:50,445 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:50,445 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:50,806 - INFO - Epoch: [147][300/391] Time 0.014 (0.019) Data 0.002 (0.002) Loss 0.3069 (0.2570) Acc@1 93.750 (91.183) Acc@5 100.000 (99.790)
2025-08-28 06:27:52,600 - INFO - Test: [0/79] Time 0.156 (0.156) Loss 0.3180 (0.3180) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-28 06:27:53,434 - INFO - Epoch 147:
2025-08-28 06:27:53,434 - INFO -   Train: acc1: 91.2640 | acc5: 99.7880 | loss: 0.2564 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:27:53,434 - INFO -   Val:   acc1: 88.1100 | acc5: 99.6600 | loss: 0.3500
2025-08-28 06:27:53,434 - INFO -   LR: 0.010000
2025-08-28 06:27:53,454 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-28 06:27:53,647 - INFO - Epoch: [148][0/391] Time 0.191 (0.191) Data 0.171 (0.171) Loss 0.2647 (0.2647) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:27:54,602 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:54,602 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:55,578 - INFO - Epoch: [148][100/391] Time 0.035 (0.021) Data 0.000 (0.004) Loss 0.3557 (0.2545) Acc@1 86.719 (91.197) Acc@5 100.000 (99.776)
2025-08-28 06:27:57,387 - INFO - Epoch: [148][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2583 (0.2502) Acc@1 92.188 (91.305) Acc@5 100.000 (99.767)
2025-08-28 06:27:57,637 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:27:57,637 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:27:59,401 - INFO - Epoch: [148][300/391] Time 0.033 (0.020) Data 0.013 (0.003) Loss 0.2435 (0.2539) Acc@1 92.188 (91.116) Acc@5 99.219 (99.756)
2025-08-28 06:28:00,669 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:00,669 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:01,179 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3169 (0.3169) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:28:02,059 - INFO - Epoch 148:
2025-08-28 06:28:02,060 - INFO -   Train: acc1: 91.0500 | acc5: 99.7680 | loss: 0.2559 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:02,060 - INFO -   Val:   acc1: 88.0100 | acc5: 99.5800 | loss: 0.3607
2025-08-28 06:28:02,060 - INFO -   LR: 0.010000
2025-08-28 06:28:02,077 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-28 06:28:02,271 - INFO - Epoch: [149][0/391] Time 0.192 (0.192) Data 0.177 (0.177) Loss 0.3146 (0.3146) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:28:04,223 - INFO - Epoch: [149][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.2729 (0.2459) Acc@1 92.188 (91.600) Acc@5 100.000 (99.799)
2025-08-28 06:28:04,984 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:04,984 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:06,051 - INFO - Epoch: [149][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3142 (0.2553) Acc@1 88.281 (91.185) Acc@5 100.000 (99.771)
2025-08-28 06:28:07,863 - INFO - Epoch: [149][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.2619 (0.2543) Acc@1 91.406 (91.201) Acc@5 99.219 (99.769)
2025-08-28 06:28:07,868 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:07,868 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:09,705 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.3375 (0.3375) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-28 06:28:10,591 - INFO - Epoch 149:
2025-08-28 06:28:10,592 - INFO -   Train: acc1: 91.2200 | acc5: 99.7820 | loss: 0.2538 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:10,592 - INFO -   Val:   acc1: 87.8400 | acc5: 99.5800 | loss: 0.3647
2025-08-28 06:28:10,592 - INFO -   LR: 0.001000
2025-08-28 06:28:10,613 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-28 06:28:10,799 - INFO - Epoch: [150][0/391] Time 0.185 (0.185) Data 0.167 (0.167) Loss 0.3336 (0.3336) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-28 06:28:12,168 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:12,169 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:12,742 - INFO - Epoch: [150][100/391] Time 0.023 (0.021) Data 0.000 (0.004) Loss 0.2222 (0.2294) Acc@1 91.406 (92.350) Acc@5 100.000 (99.861)
2025-08-28 06:28:14,576 - INFO - Epoch: [150][200/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.2094 (0.2256) Acc@1 92.969 (92.428) Acc@5 100.000 (99.845)
2025-08-28 06:28:15,195 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:15,195 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:16,449 - INFO - Epoch: [150][300/391] Time 0.019 (0.019) Data 0.001 (0.003) Loss 0.2785 (0.2268) Acc@1 90.625 (92.294) Acc@5 100.000 (99.842)
2025-08-28 06:28:17,994 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:17,994 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:18,201 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2941 (0.2941) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:28:19,038 - INFO - Epoch 150:
2025-08-28 06:28:19,038 - INFO -   Train: acc1: 92.3920 | acc5: 99.8240 | loss: 0.2238 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:19,038 - INFO -   Val:   acc1: 89.4800 | acc5: 99.6400 | loss: 0.3134
2025-08-28 06:28:19,038 - INFO -   LR: 0.001000
2025-08-28 06:28:19,088 - INFO - Checkpoint saved: epoch=150, metric=89.4800
2025-08-28 06:28:19,119 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-28 06:28:19,339 - INFO - Epoch: [151][0/391] Time 0.220 (0.220) Data 0.192 (0.192) Loss 0.2238 (0.2238) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:28:21,292 - INFO - Epoch: [151][100/391] Time 0.017 (0.021) Data 0.000 (0.005) Loss 0.1388 (0.2033) Acc@1 96.094 (93.224) Acc@5 100.000 (99.838)
2025-08-28 06:28:22,324 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:22,324 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:23,076 - INFO - Epoch: [151][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3109 (0.2089) Acc@1 89.844 (92.914) Acc@5 99.219 (99.868)
2025-08-28 06:28:24,962 - INFO - Epoch: [151][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2225 (0.2091) Acc@1 89.062 (92.888) Acc@5 100.000 (99.844)
2025-08-28 06:28:25,313 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:25,313 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:26,825 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.2783 (0.2783) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:28:27,654 - INFO - Epoch 151:
2025-08-28 06:28:27,655 - INFO -   Train: acc1: 92.8380 | acc5: 99.8420 | loss: 0.2104 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:27,655 - INFO -   Val:   acc1: 89.5900 | acc5: 99.6500 | loss: 0.3095
2025-08-28 06:28:27,655 - INFO -   LR: 0.001000
2025-08-28 06:28:27,848 - INFO - Checkpoint saved: epoch=151, metric=89.5900
2025-08-28 06:28:27,879 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-28 06:28:28,090 - INFO - Epoch: [152][0/391] Time 0.209 (0.209) Data 0.190 (0.190) Loss 0.3182 (0.3182) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:28:29,646 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:29,646 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:29,886 - INFO - Epoch: [152][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2401 (0.2134) Acc@1 92.969 (92.683) Acc@5 100.000 (99.845)
2025-08-28 06:28:31,732 - INFO - Epoch: [152][200/391] Time 0.028 (0.019) Data 0.000 (0.004) Loss 0.1713 (0.2120) Acc@1 95.312 (92.716) Acc@5 100.000 (99.848)
2025-08-28 06:28:32,602 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:32,603 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:33,569 - INFO - Epoch: [152][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1551 (0.2101) Acc@1 96.875 (92.881) Acc@5 100.000 (99.844)
2025-08-28 06:28:35,361 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2702 (0.2702) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:28:36,204 - INFO - Epoch 152:
2025-08-28 06:28:36,204 - INFO -   Train: acc1: 92.7960 | acc5: 99.8460 | loss: 0.2112 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:36,205 - INFO -   Val:   acc1: 89.4600 | acc5: 99.6500 | loss: 0.3121
2025-08-28 06:28:36,205 - INFO -   LR: 0.001000
2025-08-28 06:28:36,223 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-28 06:28:36,424 - INFO - Epoch: [153][0/391] Time 0.200 (0.200) Data 0.179 (0.179) Loss 0.2648 (0.2648) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-28 06:28:36,691 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:36,691 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:38,190 - INFO - Epoch: [153][100/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.1865 (0.2014) Acc@1 92.188 (93.108) Acc@5 100.000 (99.807)
2025-08-28 06:28:39,593 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:39,593 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:40,038 - INFO - Epoch: [153][200/391] Time 0.035 (0.019) Data 0.020 (0.003) Loss 0.1584 (0.2021) Acc@1 94.531 (93.148) Acc@5 100.000 (99.848)
2025-08-28 06:28:41,801 - INFO - Epoch: [153][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1694 (0.2023) Acc@1 94.531 (93.096) Acc@5 100.000 (99.829)
2025-08-28 06:28:42,456 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:42,456 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:43,636 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.2838 (0.2838) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:28:44,508 - INFO - Epoch 153:
2025-08-28 06:28:44,508 - INFO -   Train: acc1: 93.0760 | acc5: 99.8240 | loss: 0.2030 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:44,508 - INFO -   Val:   acc1: 89.4000 | acc5: 99.6900 | loss: 0.3120
2025-08-28 06:28:44,508 - INFO -   LR: 0.001000
2025-08-28 06:28:44,527 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-28 06:28:44,696 - INFO - Epoch: [154][0/391] Time 0.168 (0.168) Data 0.151 (0.151) Loss 0.2290 (0.2290) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:28:46,651 - INFO - Epoch: [154][100/391] Time 0.018 (0.021) Data 0.000 (0.003) Loss 0.2649 (0.2014) Acc@1 91.406 (93.162) Acc@5 100.000 (99.845)
2025-08-28 06:28:46,758 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:46,758 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:48,489 - INFO - Epoch: [154][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.2582 (0.2038) Acc@1 92.188 (92.984) Acc@5 100.000 (99.829)
2025-08-28 06:28:49,660 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:49,660 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:50,338 - INFO - Epoch: [154][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.2086 (0.2018) Acc@1 92.969 (93.145) Acc@5 100.000 (99.849)
2025-08-28 06:28:52,231 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2910 (0.2910) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:28:53,073 - INFO - Epoch 154:
2025-08-28 06:28:53,073 - INFO -   Train: acc1: 93.0940 | acc5: 99.8420 | loss: 0.2033 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:28:53,073 - INFO -   Val:   acc1: 89.4600 | acc5: 99.7100 | loss: 0.3090
2025-08-28 06:28:53,074 - INFO -   LR: 0.001000
2025-08-28 06:28:53,090 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-28 06:28:53,288 - INFO - Epoch: [155][0/391] Time 0.198 (0.198) Data 0.173 (0.173) Loss 0.2028 (0.2028) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:28:53,866 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:53,866 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:55,159 - INFO - Epoch: [155][100/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.1956 (0.2056) Acc@1 93.750 (92.884) Acc@5 100.000 (99.868)
2025-08-28 06:28:56,846 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:56,846 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:28:56,978 - INFO - Epoch: [155][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2460 (0.1999) Acc@1 90.625 (93.008) Acc@5 99.219 (99.860)
2025-08-28 06:28:58,802 - INFO - Epoch: [155][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2018 (0.1987) Acc@1 92.188 (93.099) Acc@5 100.000 (99.855)
2025-08-28 06:28:59,807 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:28:59,807 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:00,642 - INFO - Test: [0/79] Time 0.167 (0.167) Loss 0.2791 (0.2791) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:29:01,492 - INFO - Epoch 155:
2025-08-28 06:29:01,492 - INFO -   Train: acc1: 93.0740 | acc5: 99.8560 | loss: 0.2010 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:01,492 - INFO -   Val:   acc1: 89.5200 | acc5: 99.6600 | loss: 0.3086
2025-08-28 06:29:01,492 - INFO -   LR: 0.001000
2025-08-28 06:29:01,511 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-28 06:29:01,721 - INFO - Epoch: [156][0/391] Time 0.209 (0.209) Data 0.174 (0.174) Loss 0.2183 (0.2183) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:29:03,586 - INFO - Epoch: [156][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2011 (0.1984) Acc@1 95.312 (93.301) Acc@5 100.000 (99.868)
2025-08-28 06:29:03,992 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:03,992 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:05,445 - INFO - Epoch: [156][200/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2080 (0.1943) Acc@1 91.406 (93.458) Acc@5 100.000 (99.852)
2025-08-28 06:29:07,043 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:07,043 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:07,361 - INFO - Epoch: [156][300/391] Time 0.020 (0.019) Data 0.000 (0.002) Loss 0.2209 (0.1984) Acc@1 93.750 (93.285) Acc@5 100.000 (99.855)
2025-08-28 06:29:09,150 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.2751 (0.2751) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:29:09,993 - INFO - Epoch 156:
2025-08-28 06:29:09,993 - INFO -   Train: acc1: 93.3120 | acc5: 99.8540 | loss: 0.1982 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:09,993 - INFO -   Val:   acc1: 89.5400 | acc5: 99.7100 | loss: 0.3092
2025-08-28 06:29:09,993 - INFO -   LR: 0.001000
2025-08-28 06:29:10,011 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-28 06:29:10,201 - INFO - Epoch: [157][0/391] Time 0.188 (0.188) Data 0.161 (0.161) Loss 0.2044 (0.2044) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:29:11,272 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:11,272 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:12,175 - INFO - Epoch: [157][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1917 (0.1952) Acc@1 92.188 (93.441) Acc@5 100.000 (99.868)
2025-08-28 06:29:13,995 - INFO - Epoch: [157][200/391] Time 0.024 (0.020) Data 0.000 (0.002) Loss 0.1725 (0.2007) Acc@1 93.750 (93.221) Acc@5 100.000 (99.880)
2025-08-28 06:29:14,171 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:14,172 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:15,845 - INFO - Epoch: [157][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.1959 (0.2006) Acc@1 92.969 (93.205) Acc@5 100.000 (99.873)
2025-08-28 06:29:17,181 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:17,182 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:17,668 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2893 (0.2893) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:29:18,522 - INFO - Epoch 157:
2025-08-28 06:29:18,522 - INFO -   Train: acc1: 93.2520 | acc5: 99.8580 | loss: 0.1989 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:18,522 - INFO -   Val:   acc1: 89.4400 | acc5: 99.6700 | loss: 0.3097
2025-08-28 06:29:18,522 - INFO -   LR: 0.001000
2025-08-28 06:29:18,540 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-28 06:29:18,753 - INFO - Epoch: [158][0/391] Time 0.212 (0.212) Data 0.183 (0.183) Loss 0.1848 (0.1848) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:29:20,619 - INFO - Epoch: [158][100/391] Time 0.021 (0.021) Data 0.000 (0.005) Loss 0.1993 (0.2063) Acc@1 93.750 (92.946) Acc@5 100.000 (99.868)
2025-08-28 06:29:21,321 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:21,321 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:22,394 - INFO - Epoch: [158][200/391] Time 0.027 (0.019) Data 0.013 (0.003) Loss 0.1613 (0.2019) Acc@1 95.312 (93.198) Acc@5 100.000 (99.887)
2025-08-28 06:29:24,216 - INFO - Epoch: [158][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1507 (0.1986) Acc@1 94.531 (93.257) Acc@5 100.000 (99.891)
2025-08-28 06:29:24,237 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:24,237 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:26,054 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2777 (0.2777) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:29:26,878 - INFO - Epoch 158:
2025-08-28 06:29:26,878 - INFO -   Train: acc1: 93.1540 | acc5: 99.8820 | loss: 0.1996 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:26,878 - INFO -   Val:   acc1: 89.5400 | acc5: 99.7000 | loss: 0.3106
2025-08-28 06:29:26,878 - INFO -   LR: 0.001000
2025-08-28 06:29:26,897 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-28 06:29:27,101 - INFO - Epoch: [159][0/391] Time 0.202 (0.202) Data 0.175 (0.175) Loss 0.1971 (0.1971) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 06:29:28,460 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:28,460 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:29,005 - INFO - Epoch: [159][100/391] Time 0.011 (0.021) Data 0.000 (0.003) Loss 0.1775 (0.1929) Acc@1 94.531 (93.270) Acc@5 100.000 (99.814)
2025-08-28 06:29:30,930 - INFO - Epoch: [159][200/391] Time 0.029 (0.020) Data 0.000 (0.002) Loss 0.1506 (0.1925) Acc@1 94.531 (93.404) Acc@5 100.000 (99.848)
2025-08-28 06:29:31,459 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:31,460 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:32,869 - INFO - Epoch: [159][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2974 (0.1939) Acc@1 87.500 (93.371) Acc@5 100.000 (99.860)
2025-08-28 06:29:34,793 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2874 (0.2874) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:29:35,673 - INFO - Epoch 159:
2025-08-28 06:29:35,673 - INFO -   Train: acc1: 93.2660 | acc5: 99.8660 | loss: 0.1963 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:35,673 - INFO -   Val:   acc1: 89.6800 | acc5: 99.6900 | loss: 0.3083
2025-08-28 06:29:35,673 - INFO -   LR: 0.001000
2025-08-28 06:29:35,727 - INFO - Checkpoint saved: epoch=159, metric=89.6800
2025-08-28 06:29:35,760 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-28 06:29:35,930 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:35,930 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:35,951 - INFO - Epoch: [160][0/391] Time 0.191 (0.191) Data 0.163 (0.163) Loss 0.1931 (0.1931) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:29:37,867 - INFO - Epoch: [160][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.1074 (0.1915) Acc@1 96.875 (93.301) Acc@5 100.000 (99.853)
2025-08-28 06:29:39,005 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:39,005 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:39,777 - INFO - Epoch: [160][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.1852 (0.1980) Acc@1 93.750 (93.237) Acc@5 100.000 (99.841)
2025-08-28 06:29:41,676 - INFO - Epoch: [160][300/391] Time 0.013 (0.020) Data 0.000 (0.002) Loss 0.2208 (0.1977) Acc@1 92.969 (93.330) Acc@5 100.000 (99.852)
2025-08-28 06:29:42,091 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:42,091 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:43,575 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2795 (0.2795) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:29:44,425 - INFO - Epoch 160:
2025-08-28 06:29:44,425 - INFO -   Train: acc1: 93.3260 | acc5: 99.8520 | loss: 0.1972 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:44,425 - INFO -   Val:   acc1: 89.4100 | acc5: 99.6700 | loss: 0.3144
2025-08-28 06:29:44,425 - INFO -   LR: 0.001000
2025-08-28 06:29:44,477 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-28 06:29:44,680 - INFO - Epoch: [161][0/391] Time 0.202 (0.202) Data 0.174 (0.174) Loss 0.2832 (0.2832) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:29:46,408 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:46,408 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:46,606 - INFO - Epoch: [161][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.2201 (0.1939) Acc@1 92.188 (93.719) Acc@5 100.000 (99.853)
2025-08-28 06:29:48,492 - INFO - Epoch: [161][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.1107 (0.1925) Acc@1 98.438 (93.563) Acc@5 100.000 (99.883)
2025-08-28 06:29:49,385 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:49,386 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:50,466 - INFO - Epoch: [161][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1917 (0.1947) Acc@1 94.531 (93.426) Acc@5 100.000 (99.868)
2025-08-28 06:29:52,338 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.2778 (0.2778) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:29:53,213 - INFO - Epoch 161:
2025-08-28 06:29:53,213 - INFO -   Train: acc1: 93.4140 | acc5: 99.8500 | loss: 0.1954 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:29:53,214 - INFO -   Val:   acc1: 89.6700 | acc5: 99.6700 | loss: 0.3104
2025-08-28 06:29:53,214 - INFO -   LR: 0.001000
2025-08-28 06:29:53,233 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-28 06:29:53,430 - INFO - Epoch: [162][0/391] Time 0.195 (0.195) Data 0.176 (0.176) Loss 0.1654 (0.1654) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:29:53,735 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:53,735 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:55,277 - INFO - Epoch: [162][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1905 (0.1817) Acc@1 94.531 (93.974) Acc@5 100.000 (99.915)
2025-08-28 06:29:56,792 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:56,792 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:29:57,204 - INFO - Epoch: [162][200/391] Time 0.024 (0.020) Data 0.000 (0.003) Loss 0.1182 (0.1882) Acc@1 95.312 (93.567) Acc@5 100.000 (99.887)
2025-08-28 06:29:59,188 - INFO - Epoch: [162][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.2114 (0.1929) Acc@1 93.750 (93.439) Acc@5 99.219 (99.873)
2025-08-28 06:29:59,869 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:29:59,870 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:00,996 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.2646 (0.2646) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:30:01,881 - INFO - Epoch 162:
2025-08-28 06:30:01,881 - INFO -   Train: acc1: 93.4400 | acc5: 99.8560 | loss: 0.1942 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:01,881 - INFO -   Val:   acc1: 89.6000 | acc5: 99.6700 | loss: 0.3106
2025-08-28 06:30:01,881 - INFO -   LR: 0.001000
2025-08-28 06:30:01,899 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-28 06:30:02,117 - INFO - Epoch: [163][0/391] Time 0.217 (0.217) Data 0.180 (0.180) Loss 0.2343 (0.2343) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:30:03,987 - INFO - Epoch: [163][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.1745 (0.1873) Acc@1 93.750 (93.820) Acc@5 100.000 (99.861)
2025-08-28 06:30:04,125 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:04,125 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:05,889 - INFO - Epoch: [163][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1459 (0.1887) Acc@1 95.312 (93.696) Acc@5 100.000 (99.864)
2025-08-28 06:30:07,177 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:07,178 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:07,833 - INFO - Epoch: [163][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1621 (0.1921) Acc@1 95.312 (93.532) Acc@5 100.000 (99.865)
2025-08-28 06:30:09,757 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2589 (0.2589) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:30:10,633 - INFO - Epoch 163:
2025-08-28 06:30:10,633 - INFO -   Train: acc1: 93.5340 | acc5: 99.8620 | loss: 0.1920 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:10,633 - INFO -   Val:   acc1: 89.5600 | acc5: 99.6800 | loss: 0.3107
2025-08-28 06:30:10,633 - INFO -   LR: 0.001000
2025-08-28 06:30:10,650 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-28 06:30:10,857 - INFO - Epoch: [164][0/391] Time 0.206 (0.206) Data 0.176 (0.176) Loss 0.2674 (0.2674) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:30:11,546 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:11,546 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:12,803 - INFO - Epoch: [164][100/391] Time 0.027 (0.021) Data 0.000 (0.004) Loss 0.2200 (0.1902) Acc@1 92.969 (93.410) Acc@5 100.000 (99.845)
2025-08-28 06:30:14,559 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:14,559 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:14,641 - INFO - Epoch: [164][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1807 (0.1936) Acc@1 94.531 (93.252) Acc@5 100.000 (99.837)
2025-08-28 06:30:16,549 - INFO - Epoch: [164][300/391] Time 0.029 (0.020) Data 0.012 (0.003) Loss 0.1486 (0.1912) Acc@1 95.312 (93.420) Acc@5 100.000 (99.847)
2025-08-28 06:30:17,604 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:17,604 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:18,384 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2737 (0.2737) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:30:19,241 - INFO - Epoch 164:
2025-08-28 06:30:19,241 - INFO -   Train: acc1: 93.3780 | acc5: 99.8480 | loss: 0.1926 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:19,241 - INFO -   Val:   acc1: 89.5700 | acc5: 99.6600 | loss: 0.3120
2025-08-28 06:30:19,241 - INFO -   LR: 0.001000
2025-08-28 06:30:19,260 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-28 06:30:19,450 - INFO - Epoch: [165][0/391] Time 0.189 (0.189) Data 0.159 (0.159) Loss 0.2629 (0.2629) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-28 06:30:21,509 - INFO - Epoch: [165][100/391] Time 0.033 (0.022) Data 0.013 (0.003) Loss 0.1180 (0.1932) Acc@1 98.438 (93.363) Acc@5 100.000 (99.822)
2025-08-28 06:30:21,948 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:21,949 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:23,388 - INFO - Epoch: [165][200/391] Time 0.019 (0.021) Data 0.000 (0.002) Loss 0.1798 (0.1899) Acc@1 92.188 (93.486) Acc@5 100.000 (99.860)
2025-08-28 06:30:25,023 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:25,024 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:25,354 - INFO - Epoch: [165][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1885 (0.1922) Acc@1 93.750 (93.454) Acc@5 100.000 (99.860)
2025-08-28 06:30:27,317 - INFO - Test: [0/79] Time 0.175 (0.175) Loss 0.2822 (0.2822) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:30:28,208 - INFO - Epoch 165:
2025-08-28 06:30:28,209 - INFO -   Train: acc1: 93.3760 | acc5: 99.8640 | loss: 0.1937 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:28,209 - INFO -   Val:   acc1: 89.6300 | acc5: 99.6500 | loss: 0.3122
2025-08-28 06:30:28,209 - INFO -   LR: 0.001000
2025-08-28 06:30:28,226 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-28 06:30:28,437 - INFO - Epoch: [166][0/391] Time 0.210 (0.210) Data 0.190 (0.190) Loss 0.2436 (0.2436) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:30:29,520 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:29,521 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:30,358 - INFO - Epoch: [166][100/391] Time 0.015 (0.021) Data 0.000 (0.004) Loss 0.1096 (0.1912) Acc@1 96.875 (93.502) Acc@5 100.000 (99.907)
2025-08-28 06:30:32,253 - INFO - Epoch: [166][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.2089 (0.1927) Acc@1 92.188 (93.579) Acc@5 100.000 (99.880)
2025-08-28 06:30:32,531 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:32,531 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:34,169 - INFO - Epoch: [166][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1127 (0.1919) Acc@1 98.438 (93.566) Acc@5 100.000 (99.873)
2025-08-28 06:30:35,560 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:35,560 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:36,055 - INFO - Test: [0/79] Time 0.171 (0.171) Loss 0.2573 (0.2573) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:30:36,884 - INFO - Epoch 166:
2025-08-28 06:30:36,884 - INFO -   Train: acc1: 93.5320 | acc5: 99.8600 | loss: 0.1927 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:36,884 - INFO -   Val:   acc1: 89.5400 | acc5: 99.6700 | loss: 0.3159
2025-08-28 06:30:36,884 - INFO -   LR: 0.001000
2025-08-28 06:30:36,903 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-28 06:30:37,129 - INFO - Epoch: [167][0/391] Time 0.225 (0.225) Data 0.189 (0.189) Loss 0.2002 (0.2002) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:30:38,934 - INFO - Epoch: [167][100/391] Time 0.020 (0.020) Data 0.000 (0.005) Loss 0.2081 (0.1919) Acc@1 92.188 (93.673) Acc@5 100.000 (99.884)
2025-08-28 06:30:39,754 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:39,754 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:40,854 - INFO - Epoch: [167][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.1881 (0.1918) Acc@1 93.750 (93.649) Acc@5 100.000 (99.891)
2025-08-28 06:30:42,735 - INFO - Epoch: [167][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.1424 (0.1913) Acc@1 93.750 (93.646) Acc@5 100.000 (99.883)
2025-08-28 06:30:42,784 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:42,785 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:44,659 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.2610 (0.2610) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:30:45,523 - INFO - Epoch 167:
2025-08-28 06:30:45,524 - INFO -   Train: acc1: 93.5860 | acc5: 99.8740 | loss: 0.1915 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:45,524 - INFO -   Val:   acc1: 89.5400 | acc5: 99.6900 | loss: 0.3124
2025-08-28 06:30:45,524 - INFO -   LR: 0.001000
2025-08-28 06:30:45,541 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-28 06:30:45,756 - INFO - Epoch: [168][0/391] Time 0.214 (0.214) Data 0.195 (0.195) Loss 0.2341 (0.2341) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-28 06:30:47,071 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:47,071 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:47,677 - INFO - Epoch: [168][100/391] Time 0.032 (0.021) Data 0.013 (0.004) Loss 0.1702 (0.1890) Acc@1 92.969 (93.510) Acc@5 100.000 (99.853)
2025-08-28 06:30:49,753 - INFO - Epoch: [168][200/391] Time 0.022 (0.021) Data 0.000 (0.003) Loss 0.1733 (0.1938) Acc@1 92.969 (93.408) Acc@5 100.000 (99.864)
2025-08-28 06:30:50,373 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:50,374 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:51,601 - INFO - Epoch: [168][300/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.2440 (0.1935) Acc@1 92.188 (93.452) Acc@5 100.000 (99.870)
2025-08-28 06:30:53,441 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2603 (0.2603) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:30:54,336 - INFO - Epoch 168:
2025-08-28 06:30:54,336 - INFO -   Train: acc1: 93.3940 | acc5: 99.8640 | loss: 0.1937 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:30:54,336 - INFO -   Val:   acc1: 89.5000 | acc5: 99.6700 | loss: 0.3148
2025-08-28 06:30:54,336 - INFO -   LR: 0.001000
2025-08-28 06:30:54,355 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-28 06:30:54,574 - INFO - Epoch: [169][0/391] Time 0.218 (0.218) Data 0.195 (0.195) Loss 0.2010 (0.2010) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:30:54,581 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:54,581 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:56,511 - INFO - Epoch: [169][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.1610 (0.1859) Acc@1 95.312 (93.595) Acc@5 100.000 (99.876)
2025-08-28 06:30:57,654 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:30:57,654 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:30:58,398 - INFO - Epoch: [169][200/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1560 (0.1887) Acc@1 96.094 (93.466) Acc@5 100.000 (99.891)
2025-08-28 06:31:00,313 - INFO - Epoch: [169][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.2530 (0.1890) Acc@1 88.281 (93.444) Acc@5 100.000 (99.878)
2025-08-28 06:31:00,763 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:00,764 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:02,372 - INFO - Test: [0/79] Time 0.177 (0.177) Loss 0.2714 (0.2714) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:31:03,247 - INFO - Epoch 169:
2025-08-28 06:31:03,247 - INFO -   Train: acc1: 93.5280 | acc5: 99.8720 | loss: 0.1890 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:03,247 - INFO -   Val:   acc1: 89.6700 | acc5: 99.6600 | loss: 0.3130
2025-08-28 06:31:03,247 - INFO -   LR: 0.001000
2025-08-28 06:31:03,265 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-28 06:31:03,467 - INFO - Epoch: [170][0/391] Time 0.201 (0.201) Data 0.176 (0.176) Loss 0.2376 (0.2376) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:31:05,194 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:05,194 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:05,409 - INFO - Epoch: [170][100/391] Time 0.028 (0.021) Data 0.011 (0.003) Loss 0.2092 (0.1968) Acc@1 92.188 (93.232) Acc@5 99.219 (99.876)
2025-08-28 06:31:07,382 - INFO - Epoch: [170][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1445 (0.1921) Acc@1 94.531 (93.482) Acc@5 100.000 (99.860)
2025-08-28 06:31:08,313 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:08,313 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:09,248 - INFO - Epoch: [170][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1463 (0.1901) Acc@1 95.312 (93.550) Acc@5 100.000 (99.868)
2025-08-28 06:31:11,106 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2695 (0.2695) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:31:11,947 - INFO - Epoch 170:
2025-08-28 06:31:11,947 - INFO -   Train: acc1: 93.6180 | acc5: 99.8560 | loss: 0.1895 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:11,947 - INFO -   Val:   acc1: 89.6700 | acc5: 99.6600 | loss: 0.3122
2025-08-28 06:31:11,947 - INFO -   LR: 0.001000
2025-08-28 06:31:12,000 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-28 06:31:12,213 - INFO - Epoch: [171][0/391] Time 0.212 (0.212) Data 0.189 (0.189) Loss 0.1558 (0.1558) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:31:12,573 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:12,573 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:14,217 - INFO - Epoch: [171][100/391] Time 0.025 (0.022) Data 0.000 (0.003) Loss 0.2686 (0.1812) Acc@1 92.969 (93.680) Acc@5 100.000 (99.915)
2025-08-28 06:31:15,645 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:15,645 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:16,079 - INFO - Epoch: [171][200/391] Time 0.021 (0.020) Data 0.002 (0.002) Loss 0.3087 (0.1878) Acc@1 91.406 (93.544) Acc@5 99.219 (99.883)
2025-08-28 06:31:18,099 - INFO - Epoch: [171][300/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.1362 (0.1892) Acc@1 95.312 (93.477) Acc@5 100.000 (99.888)
2025-08-28 06:31:18,860 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:18,860 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:19,980 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2716 (0.2716) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:31:20,828 - INFO - Epoch 171:
2025-08-28 06:31:20,829 - INFO -   Train: acc1: 93.4540 | acc5: 99.8840 | loss: 0.1900 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:20,829 - INFO -   Val:   acc1: 89.5700 | acc5: 99.6600 | loss: 0.3157
2025-08-28 06:31:20,829 - INFO -   LR: 0.001000
2025-08-28 06:31:20,846 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-28 06:31:21,058 - INFO - Epoch: [172][0/391] Time 0.210 (0.210) Data 0.174 (0.174) Loss 0.2197 (0.2197) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:31:22,965 - INFO - Epoch: [172][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2117 (0.1829) Acc@1 93.750 (93.974) Acc@5 100.000 (99.861)
2025-08-28 06:31:23,101 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:23,101 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:24,989 - INFO - Epoch: [172][200/391] Time 0.022 (0.021) Data 0.000 (0.002) Loss 0.1132 (0.1822) Acc@1 96.875 (93.937) Acc@5 100.000 (99.841)
2025-08-28 06:31:26,314 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:26,314 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:26,969 - INFO - Epoch: [172][300/391] Time 0.020 (0.020) Data 0.000 (0.002) Loss 0.1319 (0.1867) Acc@1 96.875 (93.833) Acc@5 100.000 (99.847)
2025-08-28 06:31:28,727 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2608 (0.2608) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:31:29,579 - INFO - Epoch 172:
2025-08-28 06:31:29,579 - INFO -   Train: acc1: 93.7360 | acc5: 99.8580 | loss: 0.1872 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:29,579 - INFO -   Val:   acc1: 89.5300 | acc5: 99.6500 | loss: 0.3152
2025-08-28 06:31:29,579 - INFO -   LR: 0.001000
2025-08-28 06:31:29,599 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-28 06:31:29,813 - INFO - Epoch: [173][0/391] Time 0.213 (0.213) Data 0.187 (0.187) Loss 0.1954 (0.1954) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:31:30,558 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:30,558 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:31,807 - INFO - Epoch: [173][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.2391 (0.1859) Acc@1 92.188 (93.642) Acc@5 100.000 (99.861)
2025-08-28 06:31:33,725 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:33,725 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:33,808 - INFO - Epoch: [173][200/391] Time 0.032 (0.021) Data 0.013 (0.003) Loss 0.2143 (0.1886) Acc@1 92.188 (93.470) Acc@5 100.000 (99.860)
2025-08-28 06:31:35,827 - INFO - Epoch: [173][300/391] Time 0.024 (0.021) Data 0.000 (0.003) Loss 0.1849 (0.1910) Acc@1 95.312 (93.431) Acc@5 100.000 (99.857)
2025-08-28 06:31:37,012 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:37,012 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:37,849 - INFO - Test: [0/79] Time 0.166 (0.166) Loss 0.2774 (0.2774) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:31:38,708 - INFO - Epoch 173:
2025-08-28 06:31:38,709 - INFO -   Train: acc1: 93.3540 | acc5: 99.8560 | loss: 0.1933 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:38,709 - INFO -   Val:   acc1: 89.4700 | acc5: 99.6500 | loss: 0.3165
2025-08-28 06:31:38,709 - INFO -   LR: 0.001000
2025-08-28 06:31:38,726 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-28 06:31:38,923 - INFO - Epoch: [174][0/391] Time 0.196 (0.196) Data 0.171 (0.171) Loss 0.1406 (0.1406) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:31:40,856 - INFO - Epoch: [174][100/391] Time 0.012 (0.021) Data 0.000 (0.005) Loss 0.2099 (0.1909) Acc@1 92.969 (93.533) Acc@5 100.000 (99.899)
2025-08-28 06:31:41,361 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:41,362 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:42,790 - INFO - Epoch: [174][200/391] Time 0.021 (0.020) Data 0.000 (0.004) Loss 0.1742 (0.1891) Acc@1 96.094 (93.661) Acc@5 100.000 (99.891)
2025-08-28 06:31:44,407 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:44,407 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:44,673 - INFO - Epoch: [174][300/391] Time 0.049 (0.020) Data 0.033 (0.003) Loss 0.1033 (0.1886) Acc@1 96.875 (93.620) Acc@5 100.000 (99.875)
2025-08-28 06:31:46,564 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2610 (0.2610) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:31:47,409 - INFO - Epoch 174:
2025-08-28 06:31:47,409 - INFO -   Train: acc1: 93.5800 | acc5: 99.8640 | loss: 0.1896 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:47,409 - INFO -   Val:   acc1: 89.5100 | acc5: 99.6600 | loss: 0.3164
2025-08-28 06:31:47,409 - INFO -   LR: 0.001000
2025-08-28 06:31:47,430 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-28 06:31:47,620 - INFO - Epoch: [175][0/391] Time 0.190 (0.190) Data 0.164 (0.164) Loss 0.2257 (0.2257) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:31:48,721 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:48,722 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:49,637 - INFO - Epoch: [175][100/391] Time 0.019 (0.022) Data 0.000 (0.003) Loss 0.1349 (0.1863) Acc@1 96.875 (93.704) Acc@5 100.000 (99.868)
2025-08-28 06:31:51,663 - INFO - Epoch: [175][200/391] Time 0.017 (0.021) Data 0.000 (0.002) Loss 0.1570 (0.1873) Acc@1 93.750 (93.606) Acc@5 100.000 (99.880)
2025-08-28 06:31:51,969 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:51,969 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:53,618 - INFO - Epoch: [175][300/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 0.2628 (0.1886) Acc@1 92.188 (93.566) Acc@5 100.000 (99.865)
2025-08-28 06:31:55,127 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:55,128 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:31:55,560 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.2604 (0.2604) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:31:56,447 - INFO - Epoch 175:
2025-08-28 06:31:56,447 - INFO -   Train: acc1: 93.5880 | acc5: 99.8640 | loss: 0.1882 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:31:56,448 - INFO -   Val:   acc1: 89.5100 | acc5: 99.7000 | loss: 0.3157
2025-08-28 06:31:56,448 - INFO -   LR: 0.001000
2025-08-28 06:31:56,496 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-28 06:31:56,698 - INFO - Epoch: [176][0/391] Time 0.201 (0.201) Data 0.168 (0.168) Loss 0.2034 (0.2034) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:31:58,752 - INFO - Epoch: [176][100/391] Time 0.027 (0.022) Data 0.009 (0.003) Loss 0.1965 (0.1862) Acc@1 92.969 (93.773) Acc@5 100.000 (99.868)
2025-08-28 06:31:59,510 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:31:59,510 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:00,605 - INFO - Epoch: [176][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1955 (0.1868) Acc@1 94.531 (93.653) Acc@5 99.219 (99.887)
2025-08-28 06:32:02,388 - INFO - Epoch: [176][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.2231 (0.1887) Acc@1 92.969 (93.563) Acc@5 100.000 (99.870)
2025-08-28 06:32:02,463 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:02,463 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:04,380 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2796 (0.2796) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:32:05,265 - INFO - Epoch 176:
2025-08-28 06:32:05,265 - INFO -   Train: acc1: 93.5840 | acc5: 99.8620 | loss: 0.1880 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:05,265 - INFO -   Val:   acc1: 89.4200 | acc5: 99.6900 | loss: 0.3158
2025-08-28 06:32:05,265 - INFO -   LR: 0.001000
2025-08-28 06:32:05,284 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-28 06:32:05,483 - INFO - Epoch: [177][0/391] Time 0.199 (0.199) Data 0.164 (0.164) Loss 0.1355 (0.1355) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:32:06,925 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:06,925 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:07,442 - INFO - Epoch: [177][100/391] Time 0.012 (0.021) Data 0.000 (0.004) Loss 0.1531 (0.1845) Acc@1 92.969 (93.557) Acc@5 100.000 (99.884)
2025-08-28 06:32:09,429 - INFO - Epoch: [177][200/391] Time 0.014 (0.021) Data 0.000 (0.003) Loss 0.1289 (0.1840) Acc@1 98.438 (93.630) Acc@5 100.000 (99.887)
2025-08-28 06:32:10,072 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:10,072 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:11,390 - INFO - Epoch: [177][300/391] Time 0.027 (0.020) Data 0.013 (0.003) Loss 0.2203 (0.1869) Acc@1 92.969 (93.485) Acc@5 100.000 (99.875)
2025-08-28 06:32:13,230 - INFO - Test: [0/79] Time 0.155 (0.155) Loss 0.2673 (0.2673) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:32:14,074 - INFO - Epoch 177:
2025-08-28 06:32:14,075 - INFO -   Train: acc1: 93.4740 | acc5: 99.8800 | loss: 0.1880 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:14,075 - INFO -   Val:   acc1: 89.6000 | acc5: 99.6700 | loss: 0.3143
2025-08-28 06:32:14,075 - INFO -   LR: 0.001000
2025-08-28 06:32:14,094 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-28 06:32:14,291 - INFO - Epoch: [178][0/391] Time 0.196 (0.196) Data 0.173 (0.173) Loss 0.1272 (0.1272) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:32:14,326 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:14,326 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:16,234 - INFO - Epoch: [178][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.1252 (0.1925) Acc@1 96.875 (93.332) Acc@5 100.000 (99.899)
2025-08-28 06:32:17,352 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:17,352 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:18,086 - INFO - Epoch: [178][200/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.2439 (0.1941) Acc@1 91.406 (93.206) Acc@5 99.219 (99.876)
2025-08-28 06:32:20,066 - INFO - Epoch: [178][300/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.2233 (0.1911) Acc@1 92.969 (93.436) Acc@5 99.219 (99.870)
2025-08-28 06:32:20,419 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:20,420 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:21,940 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2795 (0.2795) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:32:22,792 - INFO - Epoch 178:
2025-08-28 06:32:22,792 - INFO -   Train: acc1: 93.4560 | acc5: 99.8660 | loss: 0.1901 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:22,792 - INFO -   Val:   acc1: 89.4600 | acc5: 99.6700 | loss: 0.3158
2025-08-28 06:32:22,792 - INFO -   LR: 0.001000
2025-08-28 06:32:22,814 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-28 06:32:23,029 - INFO - Epoch: [179][0/391] Time 0.214 (0.214) Data 0.188 (0.188) Loss 0.1629 (0.1629) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-28 06:32:24,848 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:24,848 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:25,036 - INFO - Epoch: [179][100/391] Time 0.016 (0.022) Data 0.000 (0.004) Loss 0.1763 (0.1854) Acc@1 93.750 (93.464) Acc@5 100.000 (99.868)
2025-08-28 06:32:26,909 - INFO - Epoch: [179][200/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1935 (0.1861) Acc@1 93.750 (93.552) Acc@5 100.000 (99.876)
2025-08-28 06:32:27,854 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:27,854 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:28,903 - INFO - Epoch: [179][300/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.1871 (0.1878) Acc@1 94.531 (93.558) Acc@5 100.000 (99.873)
2025-08-28 06:32:30,915 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2629 (0.2629) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:32:31,797 - INFO - Epoch 179:
2025-08-28 06:32:31,797 - INFO -   Train: acc1: 93.5040 | acc5: 99.8760 | loss: 0.1874 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:31,798 - INFO -   Val:   acc1: 89.5800 | acc5: 99.6700 | loss: 0.3143
2025-08-28 06:32:31,798 - INFO -   LR: 0.001000
2025-08-28 06:32:31,818 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-28 06:32:32,023 - INFO - Epoch: [180][0/391] Time 0.204 (0.204) Data 0.170 (0.170) Loss 0.2173 (0.2173) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:32:32,386 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:32,386 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:33,887 - INFO - Epoch: [180][100/391] Time 0.034 (0.020) Data 0.004 (0.003) Loss 0.1986 (0.1852) Acc@1 94.531 (93.472) Acc@5 100.000 (99.884)
2025-08-28 06:32:35,330 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:35,330 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:35,704 - INFO - Epoch: [180][200/391] Time 0.016 (0.019) Data 0.001 (0.003) Loss 0.1695 (0.1883) Acc@1 93.750 (93.490) Acc@5 100.000 (99.852)
2025-08-28 06:32:37,618 - INFO - Epoch: [180][300/391] Time 0.012 (0.019) Data 0.001 (0.003) Loss 0.2370 (0.1897) Acc@1 93.750 (93.459) Acc@5 100.000 (99.849)
2025-08-28 06:32:38,306 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:38,306 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:39,343 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.2765 (0.2765) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:32:40,207 - INFO - Epoch 180:
2025-08-28 06:32:40,207 - INFO -   Train: acc1: 93.5000 | acc5: 99.8560 | loss: 0.1888 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:40,207 - INFO -   Val:   acc1: 89.6200 | acc5: 99.6800 | loss: 0.3105
2025-08-28 06:32:40,207 - INFO -   LR: 0.001000
2025-08-28 06:32:40,262 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-28 06:32:40,461 - INFO - Epoch: [181][0/391] Time 0.198 (0.198) Data 0.181 (0.181) Loss 0.1907 (0.1907) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:32:42,404 - INFO - Epoch: [181][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.1486 (0.1837) Acc@1 94.531 (93.688) Acc@5 100.000 (99.868)
2025-08-28 06:32:42,571 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:42,571 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:44,299 - INFO - Epoch: [181][200/391] Time 0.022 (0.020) Data 0.000 (0.002) Loss 0.1713 (0.1823) Acc@1 94.531 (93.762) Acc@5 99.219 (99.868)
2025-08-28 06:32:45,641 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:45,641 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:46,270 - INFO - Epoch: [181][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.2023 (0.1848) Acc@1 94.531 (93.625) Acc@5 99.219 (99.873)
2025-08-28 06:32:48,232 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.2729 (0.2729) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-28 06:32:49,071 - INFO - Epoch 181:
2025-08-28 06:32:49,071 - INFO -   Train: acc1: 93.5660 | acc5: 99.8760 | loss: 0.1858 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:49,071 - INFO -   Val:   acc1: 89.6400 | acc5: 99.6700 | loss: 0.3153
2025-08-28 06:32:49,071 - INFO -   LR: 0.001000
2025-08-28 06:32:49,090 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-28 06:32:49,283 - INFO - Epoch: [182][0/391] Time 0.192 (0.192) Data 0.171 (0.171) Loss 0.2022 (0.2022) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:32:49,930 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:49,931 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:51,199 - INFO - Epoch: [182][100/391] Time 0.022 (0.021) Data 0.000 (0.004) Loss 0.1285 (0.1825) Acc@1 96.094 (93.765) Acc@5 100.000 (99.915)
2025-08-28 06:32:53,064 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:53,064 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:53,127 - INFO - Epoch: [182][200/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.2064 (0.1815) Acc@1 92.969 (93.820) Acc@5 100.000 (99.899)
2025-08-28 06:32:55,076 - INFO - Epoch: [182][300/391] Time 0.027 (0.020) Data 0.006 (0.002) Loss 0.1557 (0.1839) Acc@1 92.969 (93.817) Acc@5 100.000 (99.878)
2025-08-28 06:32:56,166 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:32:56,167 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:32:56,887 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2735 (0.2735) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:32:57,759 - INFO - Epoch 182:
2025-08-28 06:32:57,759 - INFO -   Train: acc1: 93.7540 | acc5: 99.8820 | loss: 0.1839 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:32:57,759 - INFO -   Val:   acc1: 89.4000 | acc5: 99.6700 | loss: 0.3210
2025-08-28 06:32:57,759 - INFO -   LR: 0.001000
2025-08-28 06:32:57,779 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-28 06:32:57,976 - INFO - Epoch: [183][0/391] Time 0.196 (0.196) Data 0.171 (0.171) Loss 0.1739 (0.1739) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:33:00,037 - INFO - Epoch: [183][100/391] Time 0.024 (0.022) Data 0.007 (0.004) Loss 0.1885 (0.1884) Acc@1 92.188 (93.742) Acc@5 100.000 (99.868)
2025-08-28 06:33:00,528 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:00,528 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:02,043 - INFO - Epoch: [183][200/391] Time 0.030 (0.021) Data 0.000 (0.002) Loss 0.1379 (0.1865) Acc@1 96.094 (93.610) Acc@5 100.000 (99.883)
2025-08-28 06:33:03,842 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:03,842 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:04,092 - INFO - Epoch: [183][300/391] Time 0.013 (0.021) Data 0.000 (0.002) Loss 0.1910 (0.1889) Acc@1 92.969 (93.527) Acc@5 100.000 (99.886)
2025-08-28 06:33:05,991 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.2718 (0.2718) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:33:06,903 - INFO - Epoch 183:
2025-08-28 06:33:06,904 - INFO -   Train: acc1: 93.5700 | acc5: 99.8800 | loss: 0.1880 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:06,904 - INFO -   Val:   acc1: 89.6400 | acc5: 99.6500 | loss: 0.3158
2025-08-28 06:33:06,904 - INFO -   LR: 0.001000
2025-08-28 06:33:06,922 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-28 06:33:07,138 - INFO - Epoch: [184][0/391] Time 0.215 (0.215) Data 0.191 (0.191) Loss 0.1796 (0.1796) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:33:08,216 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:08,216 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:08,997 - INFO - Epoch: [184][100/391] Time 0.035 (0.021) Data 0.020 (0.004) Loss 0.2203 (0.1875) Acc@1 92.188 (93.448) Acc@5 100.000 (99.923)
2025-08-28 06:33:10,986 - INFO - Epoch: [184][200/391] Time 0.028 (0.020) Data 0.000 (0.002) Loss 0.1531 (0.1887) Acc@1 95.312 (93.486) Acc@5 100.000 (99.903)
2025-08-28 06:33:11,275 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:11,275 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:12,884 - INFO - Epoch: [184][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.2307 (0.1847) Acc@1 92.969 (93.698) Acc@5 100.000 (99.901)
2025-08-28 06:33:14,331 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:14,331 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:14,732 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 0.2552 (0.2552) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:33:15,604 - INFO - Epoch 184:
2025-08-28 06:33:15,604 - INFO -   Train: acc1: 93.6160 | acc5: 99.8900 | loss: 0.1864 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:15,604 - INFO -   Val:   acc1: 89.7300 | acc5: 99.6600 | loss: 0.3147
2025-08-28 06:33:15,604 - INFO -   LR: 0.001000
2025-08-28 06:33:15,661 - INFO - Checkpoint saved: epoch=184, metric=89.7300
2025-08-28 06:33:15,691 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-28 06:33:15,903 - INFO - Epoch: [185][0/391] Time 0.211 (0.211) Data 0.186 (0.186) Loss 0.2833 (0.2833) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-28 06:33:17,945 - INFO - Epoch: [185][100/391] Time 0.030 (0.022) Data 0.009 (0.004) Loss 0.1758 (0.1864) Acc@1 94.531 (93.680) Acc@5 100.000 (99.868)
2025-08-28 06:33:18,793 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:18,794 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:19,900 - INFO - Epoch: [185][200/391] Time 0.019 (0.021) Data 0.004 (0.003) Loss 0.2057 (0.1822) Acc@1 89.844 (93.719) Acc@5 100.000 (99.876)
2025-08-28 06:33:21,817 - INFO - Epoch: [185][300/391] Time 0.024 (0.020) Data 0.007 (0.003) Loss 0.2828 (0.1831) Acc@1 91.406 (93.721) Acc@5 99.219 (99.868)
2025-08-28 06:33:21,910 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:21,910 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:23,678 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.2602 (0.2602) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:33:24,525 - INFO - Epoch 185:
2025-08-28 06:33:24,525 - INFO -   Train: acc1: 93.6560 | acc5: 99.8700 | loss: 0.1843 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:24,525 - INFO -   Val:   acc1: 89.7200 | acc5: 99.6800 | loss: 0.3169
2025-08-28 06:33:24,525 - INFO -   LR: 0.001000
2025-08-28 06:33:24,544 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-28 06:33:24,753 - INFO - Epoch: [186][0/391] Time 0.208 (0.208) Data 0.183 (0.183) Loss 0.1814 (0.1814) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:33:26,208 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:26,208 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:26,667 - INFO - Epoch: [186][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.1923 (0.1854) Acc@1 92.969 (93.386) Acc@5 100.000 (99.907)
2025-08-28 06:33:28,610 - INFO - Epoch: [186][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2446 (0.1839) Acc@1 91.406 (93.633) Acc@5 99.219 (99.899)
2025-08-28 06:33:29,250 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:29,250 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:30,522 - INFO - Epoch: [186][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1557 (0.1847) Acc@1 94.531 (93.657) Acc@5 99.219 (99.888)
2025-08-28 06:33:32,391 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.2636 (0.2636) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:33:33,236 - INFO - Epoch 186:
2025-08-28 06:33:33,236 - INFO -   Train: acc1: 93.5500 | acc5: 99.8940 | loss: 0.1868 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:33,236 - INFO -   Val:   acc1: 89.6200 | acc5: 99.6800 | loss: 0.3173
2025-08-28 06:33:33,236 - INFO -   LR: 0.001000
2025-08-28 06:33:33,256 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-28 06:33:33,439 - INFO - Epoch: [187][0/391] Time 0.181 (0.181) Data 0.165 (0.165) Loss 0.1978 (0.1978) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:33:33,507 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:33,508 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:35,359 - INFO - Epoch: [187][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2508 (0.1809) Acc@1 92.969 (93.881) Acc@5 100.000 (99.853)
2025-08-28 06:33:36,535 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:36,535 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:37,315 - INFO - Epoch: [187][200/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2175 (0.1816) Acc@1 90.625 (93.855) Acc@5 100.000 (99.868)
2025-08-28 06:33:39,274 - INFO - Epoch: [187][300/391] Time 0.023 (0.020) Data 0.000 (0.002) Loss 0.1848 (0.1826) Acc@1 92.969 (93.877) Acc@5 100.000 (99.881)
2025-08-28 06:33:39,735 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:39,736 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:41,295 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.2840 (0.2840) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:33:42,270 - INFO - Epoch 187:
2025-08-28 06:33:42,271 - INFO -   Train: acc1: 93.7080 | acc5: 99.8760 | loss: 0.1859 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:42,271 - INFO -   Val:   acc1: 89.8000 | acc5: 99.6900 | loss: 0.3157
2025-08-28 06:33:42,271 - INFO -   LR: 0.001000
2025-08-28 06:33:42,325 - INFO - Checkpoint saved: epoch=187, metric=89.8000
2025-08-28 06:33:42,355 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-28 06:33:42,554 - INFO - Epoch: [188][0/391] Time 0.198 (0.198) Data 0.166 (0.166) Loss 0.1388 (0.1388) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:33:44,342 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:44,342 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:44,519 - INFO - Epoch: [188][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.1456 (0.1868) Acc@1 95.312 (93.727) Acc@5 100.000 (99.868)
2025-08-28 06:33:46,328 - INFO - Epoch: [188][200/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.1549 (0.1841) Acc@1 94.531 (93.719) Acc@5 100.000 (99.887)
2025-08-28 06:33:47,337 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:47,337 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:48,232 - INFO - Epoch: [188][300/391] Time 0.040 (0.020) Data 0.007 (0.003) Loss 0.1821 (0.1825) Acc@1 91.406 (93.792) Acc@5 100.000 (99.886)
2025-08-28 06:33:50,096 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.2577 (0.2577) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-28 06:33:50,949 - INFO - Epoch 188:
2025-08-28 06:33:50,950 - INFO -   Train: acc1: 93.7360 | acc5: 99.8860 | loss: 0.1836 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:50,950 - INFO -   Val:   acc1: 89.5500 | acc5: 99.6700 | loss: 0.3164
2025-08-28 06:33:50,950 - INFO -   LR: 0.001000
2025-08-28 06:33:50,968 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-28 06:33:51,180 - INFO - Epoch: [189][0/391] Time 0.211 (0.211) Data 0.195 (0.195) Loss 0.1508 (0.1508) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:33:51,584 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:51,585 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:53,050 - INFO - Epoch: [189][100/391] Time 0.032 (0.021) Data 0.000 (0.003) Loss 0.2270 (0.1857) Acc@1 87.500 (93.735) Acc@5 100.000 (99.868)
2025-08-28 06:33:54,611 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:54,611 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:54,971 - INFO - Epoch: [189][200/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.1879 (0.1845) Acc@1 92.969 (93.672) Acc@5 100.000 (99.883)
2025-08-28 06:33:57,010 - INFO - Epoch: [189][300/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.1238 (0.1831) Acc@1 96.875 (93.724) Acc@5 100.000 (99.883)
2025-08-28 06:33:57,827 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:33:57,828 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:33:59,077 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.2725 (0.2725) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:33:59,971 - INFO - Epoch 189:
2025-08-28 06:33:59,971 - INFO -   Train: acc1: 93.7660 | acc5: 99.8840 | loss: 0.1830 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:33:59,971 - INFO -   Val:   acc1: 89.8200 | acc5: 99.7100 | loss: 0.3174
2025-08-28 06:33:59,971 - INFO -   LR: 0.001000
2025-08-28 06:34:00,024 - INFO - Checkpoint saved: epoch=189, metric=89.8200
2025-08-28 06:34:00,057 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-28 06:34:00,257 - INFO - Epoch: [190][0/391] Time 0.199 (0.199) Data 0.183 (0.183) Loss 0.1557 (0.1557) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:34:02,254 - INFO - Epoch: [190][100/391] Time 0.017 (0.022) Data 0.000 (0.003) Loss 0.2546 (0.1874) Acc@1 91.406 (93.781) Acc@5 99.219 (99.876)
2025-08-28 06:34:02,441 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:02,441 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:04,118 - INFO - Epoch: [190][200/391] Time 0.014 (0.020) Data 0.000 (0.002) Loss 0.2023 (0.1855) Acc@1 92.188 (93.836) Acc@5 100.000 (99.860)
2025-08-28 06:34:05,400 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:05,400 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:05,992 - INFO - Epoch: [190][300/391] Time 0.019 (0.020) Data 0.000 (0.002) Loss 0.1795 (0.1840) Acc@1 94.531 (93.823) Acc@5 100.000 (99.873)
2025-08-28 06:34:07,862 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2673 (0.2673) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:34:08,707 - INFO - Epoch 190:
2025-08-28 06:34:08,707 - INFO -   Train: acc1: 93.7620 | acc5: 99.8760 | loss: 0.1843 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:34:08,708 - INFO -   Val:   acc1: 89.6100 | acc5: 99.6800 | loss: 0.3178
2025-08-28 06:34:08,708 - INFO -   LR: 0.001000
2025-08-28 06:34:08,762 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-28 06:34:08,981 - INFO - Epoch: [191][0/391] Time 0.218 (0.218) Data 0.194 (0.194) Loss 0.2271 (0.2271) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-28 06:34:09,736 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:09,736 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:10,970 - INFO - Epoch: [191][100/391] Time 0.019 (0.022) Data 0.000 (0.004) Loss 0.1606 (0.1843) Acc@1 93.750 (93.874) Acc@5 100.000 (99.884)
2025-08-28 06:34:12,884 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:12,884 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:12,928 - INFO - Epoch: [191][200/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.2175 (0.1837) Acc@1 90.625 (93.746) Acc@5 100.000 (99.880)
2025-08-28 06:34:14,903 - INFO - Epoch: [191][300/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.2019 (0.1812) Acc@1 92.188 (93.908) Acc@5 100.000 (99.886)
2025-08-28 06:34:15,988 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:15,988 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:16,769 - INFO - Test: [0/79] Time 0.162 (0.162) Loss 0.2615 (0.2615) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:34:17,627 - INFO - Epoch 191:
2025-08-28 06:34:17,627 - INFO -   Train: acc1: 93.8080 | acc5: 99.8920 | loss: 0.1835 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:34:17,627 - INFO -   Val:   acc1: 89.5300 | acc5: 99.6400 | loss: 0.3190
2025-08-28 06:34:17,627 - INFO -   LR: 0.001000
2025-08-28 06:34:17,648 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-28 06:34:17,853 - INFO - Epoch: [192][0/391] Time 0.204 (0.204) Data 0.158 (0.158) Loss 0.1710 (0.1710) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:34:19,835 - INFO - Epoch: [192][100/391] Time 0.015 (0.022) Data 0.000 (0.003) Loss 0.1550 (0.1852) Acc@1 93.750 (93.510) Acc@5 100.000 (99.907)
2025-08-28 06:34:20,355 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:20,355 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:21,707 - INFO - Epoch: [192][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.2151 (0.1836) Acc@1 92.188 (93.692) Acc@5 100.000 (99.911)
2025-08-28 06:34:23,451 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:23,451 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:23,645 - INFO - Epoch: [192][300/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.1356 (0.1843) Acc@1 97.656 (93.670) Acc@5 100.000 (99.904)
2025-08-28 06:34:25,592 - INFO - Test: [0/79] Time 0.168 (0.168) Loss 0.2635 (0.2635) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:34:26,465 - INFO - Epoch 192:
2025-08-28 06:34:26,465 - INFO -   Train: acc1: 93.5920 | acc5: 99.8920 | loss: 0.1865 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:34:26,465 - INFO -   Val:   acc1: 89.3900 | acc5: 99.7000 | loss: 0.3202
2025-08-28 06:34:26,465 - INFO -   LR: 0.001000
2025-08-28 06:34:26,487 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-28 06:34:26,682 - INFO - Epoch: [193][0/391] Time 0.194 (0.194) Data 0.160 (0.160) Loss 0.2807 (0.2807) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:34:27,822 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:27,822 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:28,631 - INFO - Epoch: [193][100/391] Time 0.012 (0.021) Data 0.000 (0.003) Loss 0.2074 (0.1777) Acc@1 92.188 (94.044) Acc@5 100.000 (99.923)
2025-08-28 06:34:30,605 - INFO - Epoch: [193][200/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.2083 (0.1811) Acc@1 91.406 (93.797) Acc@5 100.000 (99.887)
2025-08-28 06:34:30,963 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:30,963 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:32,663 - INFO - Epoch: [193][300/391] Time 0.012 (0.020) Data 0.000 (0.002) Loss 0.2505 (0.1806) Acc@1 89.844 (93.854) Acc@5 100.000 (99.888)
2025-08-28 06:34:34,112 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:34,112 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:34,527 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.2577 (0.2577) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:34:35,399 - INFO - Epoch 193:
2025-08-28 06:34:35,400 - INFO -   Train: acc1: 93.7540 | acc5: 99.8700 | loss: 0.1823 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:34:35,400 - INFO -   Val:   acc1: 89.7200 | acc5: 99.7200 | loss: 0.3166
2025-08-28 06:34:35,400 - INFO -   LR: 0.001000
2025-08-28 06:34:35,421 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-28 06:34:35,643 - INFO - Epoch: [194][0/391] Time 0.221 (0.221) Data 0.197 (0.197) Loss 0.1707 (0.1707) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-28 06:34:37,689 - INFO - Epoch: [194][100/391] Time 0.014 (0.022) Data 0.000 (0.003) Loss 0.1315 (0.1826) Acc@1 96.875 (93.657) Acc@5 100.000 (99.899)
2025-08-28 06:34:38,551 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:38,552 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:39,592 - INFO - Epoch: [194][200/391] Time 0.014 (0.021) Data 0.002 (0.003) Loss 0.1202 (0.1828) Acc@1 96.875 (93.637) Acc@5 100.000 (99.895)
2025-08-28 06:34:41,550 - INFO - Epoch: [194][300/391] Time 0.016 (0.020) Data 0.000 (0.002) Loss 0.1613 (0.1830) Acc@1 94.531 (93.714) Acc@5 100.000 (99.883)
2025-08-28 06:34:41,654 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:41,655 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:43,484 - INFO - Test: [0/79] Time 0.159 (0.159) Loss 0.2790 (0.2790) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:34:44,363 - INFO - Epoch 194:
2025-08-28 06:34:44,363 - INFO -   Train: acc1: 93.6980 | acc5: 99.8920 | loss: 0.1838 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:34:44,363 - INFO -   Val:   acc1: 89.3800 | acc5: 99.7200 | loss: 0.3220
2025-08-28 06:34:44,363 - INFO -   LR: 0.001000
2025-08-28 06:34:44,383 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-28 06:34:44,579 - INFO - Epoch: [195][0/391] Time 0.196 (0.196) Data 0.173 (0.173) Loss 0.1572 (0.1572) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-28 06:34:45,986 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:45,986 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:46,454 - INFO - Epoch: [195][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.0972 (0.1803) Acc@1 97.656 (93.982) Acc@5 100.000 (99.853)
2025-08-28 06:34:48,290 - INFO - Epoch: [195][200/391] Time 0.044 (0.019) Data 0.012 (0.004) Loss 0.2797 (0.1809) Acc@1 89.844 (93.882) Acc@5 100.000 (99.852)
2025-08-28 06:34:48,908 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:48,909 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:50,068 - INFO - Epoch: [195][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1054 (0.1836) Acc@1 98.438 (93.760) Acc@5 100.000 (99.870)
2025-08-28 06:34:51,951 - INFO - Test: [0/79] Time 0.163 (0.163) Loss 0.2638 (0.2638) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:34:52,836 - INFO - Epoch 195:
2025-08-28 06:34:52,836 - INFO -   Train: acc1: 93.7920 | acc5: 99.8760 | loss: 0.1828 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:34:52,836 - INFO -   Val:   acc1: 89.3600 | acc5: 99.6800 | loss: 0.3209
2025-08-28 06:34:52,836 - INFO -   LR: 0.001000
2025-08-28 06:34:52,855 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-28 06:34:53,044 - INFO - Epoch: [196][0/391] Time 0.188 (0.188) Data 0.162 (0.162) Loss 0.2369 (0.2369) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-28 06:34:53,133 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:53,134 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:54,912 - INFO - Epoch: [196][100/391] Time 0.033 (0.020) Data 0.001 (0.004) Loss 0.2010 (0.1847) Acc@1 94.531 (93.603) Acc@5 99.219 (99.845)
2025-08-28 06:34:56,223 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:56,223 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:34:56,871 - INFO - Epoch: [196][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1371 (0.1831) Acc@1 96.094 (93.637) Acc@5 100.000 (99.872)
2025-08-28 06:34:58,722 - INFO - Epoch: [196][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1514 (0.1837) Acc@1 93.750 (93.628) Acc@5 100.000 (99.878)
2025-08-28 06:34:59,220 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:34:59,220 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:00,783 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.2596 (0.2596) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-28 06:35:01,686 - INFO - Epoch 196:
2025-08-28 06:35:01,686 - INFO -   Train: acc1: 93.5140 | acc5: 99.8720 | loss: 0.1865 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:35:01,686 - INFO -   Val:   acc1: 89.6500 | acc5: 99.6600 | loss: 0.3211
2025-08-28 06:35:01,686 - INFO -   LR: 0.001000
2025-08-28 06:35:01,708 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-28 06:35:01,942 - INFO - Epoch: [197][0/391] Time 0.233 (0.233) Data 0.205 (0.205) Loss 0.1277 (0.1277) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-28 06:35:03,776 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:03,776 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:03,885 - INFO - Epoch: [197][100/391] Time 0.012 (0.022) Data 0.000 (0.003) Loss 0.2723 (0.1890) Acc@1 92.188 (93.595) Acc@5 99.219 (99.845)
2025-08-28 06:35:05,776 - INFO - Epoch: [197][200/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.2297 (0.1867) Acc@1 92.969 (93.622) Acc@5 100.000 (99.872)
2025-08-28 06:35:06,769 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:06,770 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:07,814 - INFO - Epoch: [197][300/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.1877 (0.1832) Acc@1 91.406 (93.683) Acc@5 100.000 (99.891)
2025-08-28 06:35:09,745 - INFO - Test: [0/79] Time 0.161 (0.161) Loss 0.2557 (0.2557) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-28 06:35:10,618 - INFO - Epoch 197:
2025-08-28 06:35:10,618 - INFO -   Train: acc1: 93.7620 | acc5: 99.8920 | loss: 0.1823 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:35:10,618 - INFO -   Val:   acc1: 89.5400 | acc5: 99.6800 | loss: 0.3193
2025-08-28 06:35:10,618 - INFO -   LR: 0.001000
2025-08-28 06:35:10,638 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-28 06:35:10,846 - INFO - Epoch: [198][0/391] Time 0.208 (0.208) Data 0.188 (0.188) Loss 0.1362 (0.1362) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-28 06:35:11,270 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:11,270 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:12,724 - INFO - Epoch: [198][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.1421 (0.1806) Acc@1 96.094 (93.773) Acc@5 100.000 (99.884)
2025-08-28 06:35:14,267 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:14,267 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:14,603 - INFO - Epoch: [198][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2362 (0.1887) Acc@1 92.969 (93.466) Acc@5 100.000 (99.880)
2025-08-28 06:35:16,488 - INFO - Epoch: [198][300/391] Time 0.023 (0.019) Data 0.007 (0.002) Loss 0.1604 (0.1853) Acc@1 93.750 (93.657) Acc@5 100.000 (99.881)
2025-08-28 06:35:17,374 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:17,374 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:18,511 - INFO - Test: [0/79] Time 0.174 (0.174) Loss 0.2607 (0.2607) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-28 06:35:19,380 - INFO - Epoch 198:
2025-08-28 06:35:19,381 - INFO -   Train: acc1: 93.6660 | acc5: 99.8860 | loss: 0.1843 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:35:19,381 - INFO -   Val:   acc1: 89.5200 | acc5: 99.6600 | loss: 0.3190
2025-08-28 06:35:19,381 - INFO -   LR: 0.001000
2025-08-28 06:35:19,400 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-28 06:35:19,614 - INFO - Epoch: [199][0/391] Time 0.213 (0.213) Data 0.174 (0.174) Loss 0.1103 (0.1103) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-28 06:35:21,499 - INFO - Epoch: [199][100/391] Time 0.023 (0.021) Data 0.000 (0.003) Loss 0.1752 (0.1747) Acc@1 92.969 (94.021) Acc@5 100.000 (99.899)
2025-08-28 06:35:21,680 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:21,680 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:23,362 - INFO - Epoch: [199][200/391] Time 0.020 (0.020) Data 0.000 (0.003) Loss 0.1550 (0.1760) Acc@1 95.312 (94.014) Acc@5 100.000 (99.926)
2025-08-28 06:35:24,729 - INFO - Pruning info: sparsity=0.900
2025-08-28 06:35:24,729 - INFO -   Reactivation rate: 0.0000
2025-08-28 06:35:25,321 - INFO - Epoch: [199][300/391] Time 0.019 (0.020) Data 0.000 (0.003) Loss 0.2247 (0.1808) Acc@1 92.969 (93.872) Acc@5 99.219 (99.909)
2025-08-28 06:35:27,160 - INFO - Test: [0/79] Time 0.152 (0.152) Loss 0.2564 (0.2564) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-28 06:35:28,027 - INFO - Epoch 199:
2025-08-28 06:35:28,027 - INFO -   Train: acc1: 93.7460 | acc5: 99.8940 | loss: 0.1838 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-28 06:35:28,027 - INFO -   Val:   acc1: 89.5800 | acc5: 99.6900 | loss: 0.3168
2025-08-28 06:35:28,027 - INFO -   LR: 0.001000
2025-08-28 06:35:28,046 - INFO - training time: 00h 29m 00.10s
2025-08-28 06:35:28,046 - INFO - 
Training completed!
2025-08-28 06:35:28,046 - INFO - Best accuracy: 89.8200
2025-08-28 06:35:28,046 - INFO - Total training time: 0.48 hours
2025-08-28 06:35:28,046 - INFO - total_experiment time: 00h 29m 01.45s
2025-08-28 06:35:28,047 - INFO - Experiment completed successfully
2025-08-28 06:35:28,048 - INFO - Total time: 0.48 hours
