2025-08-27 16:57:40,910 - INFO - Starting experiment: dpf_sparsity0.9_seed42
2025-08-27 16:57:40,910 - INFO - Save directory: ./runs/dpf/sparsity0.9/seed42
2025-08-27 16:57:40,910 - INFO - Hyperparameters:
2025-08-27 16:57:40,910 - INFO -   name: dpf_sparsity0.9_seed42
2025-08-27 16:57:40,910 - INFO -   description: DPF pruning 90% (seed=42)
2025-08-27 16:57:40,910 - INFO -   save_dir: ./runs
2025-08-27 16:57:40,910 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 16:57:40,910 - INFO -   model: {'arch': 'resnet', 'layers': 18, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 16:57:40,910 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 16:57:40,910 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.9, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 16:57:40,911 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 16:57:40,911 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 16:57:40,945 - INFO - System Information:
2025-08-27 16:57:40,945 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 16:57:40,945 - INFO -   python_version: 3.9.18
2025-08-27 16:57:40,946 - INFO -   pytorch_version: 2.1.0
2025-08-27 16:57:40,946 - INFO -   cuda_available: True
2025-08-27 16:57:40,946 - INFO -   cpu_count: 4
2025-08-27 16:57:40,946 - INFO -   memory_total_gb: 11.0
2025-08-27 16:57:40,946 - INFO -   timestamp: 1756281460.945508
2025-08-27 16:57:40,946 - INFO -   cuda_version: 11.8
2025-08-27 16:57:40,946 - INFO -   gpu_count: 1
2025-08-27 16:57:40,946 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 16:57:40,953 - INFO - Starting experiment: dpf_sparsity0.9_seed42
2025-08-27 16:57:40,953 - INFO - Model: resnet-18
2025-08-27 16:57:40,953 - INFO - Dataset: cifar10
2025-08-27 16:57:40,953 - INFO - Pruning: dpf (90.00%)
2025-08-27 18:17:59,360 - INFO - Starting experiment: dpf_sparsity0.9_seed42
2025-08-27 18:17:59,361 - INFO - Save directory: ./runs/dpf/sparsity0.9/seed42
2025-08-27 18:17:59,361 - INFO - Hyperparameters:
2025-08-27 18:17:59,361 - INFO -   name: dpf_sparsity0.9_seed42
2025-08-27 18:17:59,361 - INFO -   description: DPF pruning 90% (seed=42)
2025-08-27 18:17:59,361 - INFO -   save_dir: ./runs
2025-08-27 18:17:59,361 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 18:17:59,361 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 18:17:59,361 - INFO -   training: {'epochs': 5, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 18:17:59,361 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.9, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 18:17:59,361 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 18:17:59,361 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 18:17:59,420 - INFO - System Information:
2025-08-27 18:17:59,421 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 18:17:59,421 - INFO -   python_version: 3.9.18
2025-08-27 18:17:59,421 - INFO -   pytorch_version: 2.1.0
2025-08-27 18:17:59,421 - INFO -   cuda_available: True
2025-08-27 18:17:59,421 - INFO -   cpu_count: 4
2025-08-27 18:17:59,421 - INFO -   memory_total_gb: 11.0
2025-08-27 18:17:59,421 - INFO -   timestamp: 1756286279.4203806
2025-08-27 18:17:59,421 - INFO -   cuda_version: 11.8
2025-08-27 18:17:59,421 - INFO -   gpu_count: 1
2025-08-27 18:17:59,421 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 18:17:59,426 - INFO - Starting experiment: dpf_sparsity0.9_seed42
2025-08-27 18:17:59,427 - INFO - Model: resnet-20
2025-08-27 18:17:59,427 - INFO - Dataset: cifar10
2025-08-27 18:17:59,427 - INFO - Pruning: dpf (90.00%)
2025-08-27 18:17:59,607 - INFO - Model Information:
2025-08-27 18:17:59,607 - INFO -   Type: pruned
2025-08-27 18:17:59,607 - INFO -   Total parameters: 544,948
2025-08-27 18:17:59,607 - INFO -   Trainable parameters: 274,692
2025-08-27 18:17:59,607 - INFO -   Sparsity: 90.00%
2025-08-27 18:18:00,958 - INFO - Starting training...
2025-08-27 18:18:00,958 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 18:18:01,681 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:18:01,681 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:18:02,202 - INFO - Epoch: [0][0/391] Time 1.243 (1.243) Data 0.594 (0.594) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 18:18:04,066 - INFO - Epoch: [0][100/391] Time 0.015 (0.031) Data 0.000 (0.008) Loss 1.6914 (1.9312) Acc@1 38.281 (26.122) Acc@5 87.500 (81.389)
2025-08-27 18:18:05,243 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:18:05,244 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:18:06,001 - INFO - Epoch: [0][200/391] Time 0.014 (0.025) Data 0.000 (0.005) Loss 1.4822 (1.7763) Acc@1 46.875 (32.478) Acc@5 93.750 (85.494)
2025-08-27 18:18:07,858 - INFO - Epoch: [0][300/391] Time 0.013 (0.023) Data 0.000 (0.004) Loss 1.3619 (1.6653) Acc@1 49.219 (37.370) Acc@5 94.531 (87.757)
2025-08-27 18:18:08,247 - INFO - Pruning info: sparsity=0.000
2025-08-27 18:18:08,248 - INFO -   Reactivation rate: 0.0000
2025-08-27 18:18:10,010 - INFO - Test: [0/79] Time 0.165 (0.165) Loss 1.5608 (1.5608) Acc@1 46.875 (46.875) Acc@5 92.188 (92.188)
2025-08-27 18:18:10,964 - INFO - Epoch 0:
2025-08-27 18:18:10,964 - INFO -   Train: acc1: 40.7920 | acc5: 89.1460 | loss: 1.5844 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 18:18:10,964 - INFO -   Val:   acc1: 45.3100 | acc5: 92.7000 | loss: 1.5778
2025-08-27 18:18:10,964 - INFO -   LR: 0.100000
2025-08-27 18:18:11,008 - INFO - Checkpoint saved: epoch=0, metric=45.3100
2025-08-27 18:18:11,038 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 18:18:11,226 - INFO - Epoch: [1][0/391] Time 0.187 (0.187) Data 0.166 (0.166) Loss 1.4714 (1.4714) Acc@1 48.438 (48.438) Acc@5 91.406 (91.406)
2025-08-27 18:18:13,007 - INFO - Pruning info: sparsity=0.036
2025-08-27 18:18:13,008 - INFO -   Reactivation rate: 0.0087
2025-08-27 18:18:13,214 - INFO - Epoch: [1][100/391] Time 0.012 (0.022) Data 0.000 (0.003) Loss 1.1020 (1.1866) Acc@1 58.594 (56.923) Acc@5 96.094 (95.320)
2025-08-27 18:18:15,313 - INFO - Epoch: [1][200/391] Time 0.035 (0.021) Data 0.000 (0.002) Loss 0.9925 (1.1420) Acc@1 65.625 (58.784) Acc@5 97.656 (95.620)
2025-08-27 18:18:16,291 - INFO - Pruning info: sparsity=0.036
2025-08-27 18:18:16,291 - INFO -   Reactivation rate: 0.0061
2025-08-27 18:18:17,249 - INFO - Epoch: [1][300/391] Time 0.012 (0.021) Data 0.000 (0.002) Loss 1.0190 (1.1064) Acc@1 64.844 (60.208) Acc@5 93.750 (95.868)
2025-08-27 18:18:19,116 - INFO - Test: [0/79] Time 0.154 (0.154) Loss 1.2695 (1.2695) Acc@1 55.469 (55.469) Acc@5 94.531 (94.531)
2025-08-27 18:18:19,955 - INFO - Epoch 1:
2025-08-27 18:18:19,955 - INFO -   Train: acc1: 61.3640 | acc5: 96.0920 | loss: 1.0782 | sparsity: 0.0355 | reactivation_rate: 0.0070
2025-08-27 18:18:19,955 - INFO -   Val:   acc1: 57.3100 | acc5: 95.0900 | loss: 1.3660
2025-08-27 18:18:19,955 - INFO -   LR: 0.100000
2025-08-27 18:18:20,002 - INFO - Checkpoint saved: epoch=1, metric=57.3100
2025-08-27 18:18:20,034 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 18:18:20,224 - INFO - Epoch: [2][0/391] Time 0.189 (0.189) Data 0.169 (0.169) Loss 0.9164 (0.9164) Acc@1 67.188 (67.188) Acc@5 97.656 (97.656)
2025-08-27 18:18:20,573 - INFO - Pruning info: sparsity=0.070
2025-08-27 18:18:20,574 - INFO -   Reactivation rate: 0.0134
2025-08-27 18:18:22,149 - INFO - Epoch: [2][100/391] Time 0.018 (0.021) Data 0.001 (0.003) Loss 0.8811 (0.9380) Acc@1 70.312 (66.808) Acc@5 96.875 (97.099)
2025-08-27 18:18:23,653 - INFO - Pruning info: sparsity=0.070
2025-08-27 18:18:23,653 - INFO -   Reactivation rate: 0.0075
2025-08-27 18:18:24,082 - INFO - Epoch: [2][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.7811 (0.9106) Acc@1 69.531 (67.685) Acc@5 97.656 (97.221)
2025-08-27 18:18:26,132 - INFO - Epoch: [2][300/391] Time 0.017 (0.020) Data 0.000 (0.002) Loss 0.9053 (0.8983) Acc@1 67.188 (68.270) Acc@5 98.438 (97.303)
2025-08-27 18:18:26,890 - INFO - Pruning info: sparsity=0.070
2025-08-27 18:18:26,890 - INFO -   Reactivation rate: 0.0058
2025-08-27 18:18:28,091 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 1.1413 (1.1413) Acc@1 68.750 (68.750) Acc@5 97.656 (97.656)
2025-08-27 18:18:28,941 - INFO - Epoch 2:
2025-08-27 18:18:28,941 - INFO -   Train: acc1: 68.8240 | acc5: 97.4080 | loss: 0.8826 | sparsity: 0.0701 | reactivation_rate: 0.0075
2025-08-27 18:18:28,941 - INFO -   Val:   acc1: 65.0700 | acc5: 96.7400 | loss: 1.1247
2025-08-27 18:18:28,941 - INFO -   LR: 0.100000
2025-08-27 18:18:28,986 - INFO - Checkpoint saved: epoch=2, metric=65.0700
2025-08-27 18:18:29,019 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 18:18:29,209 - INFO - Epoch: [3][0/391] Time 0.189 (0.189) Data 0.168 (0.168) Loss 0.8380 (0.8380) Acc@1 69.531 (69.531) Acc@5 96.875 (96.875)
2025-08-27 18:18:31,204 - INFO - Epoch: [3][100/391] Time 0.021 (0.022) Data 0.000 (0.003) Loss 0.7856 (0.7629) Acc@1 72.656 (73.345) Acc@5 98.438 (98.329)
2025-08-27 18:18:31,330 - INFO - Pruning info: sparsity=0.104
2025-08-27 18:18:31,330 - INFO -   Reactivation rate: 0.0091
2025-08-27 18:18:33,084 - INFO - Epoch: [3][200/391] Time 0.018 (0.020) Data 0.000 (0.002) Loss 0.6912 (0.7586) Acc@1 73.438 (73.768) Acc@5 98.438 (98.305)
2025-08-27 18:18:34,364 - INFO - Pruning info: sparsity=0.104
2025-08-27 18:18:34,364 - INFO -   Reactivation rate: 0.0065
2025-08-27 18:18:35,024 - INFO - Epoch: [3][300/391] Time 0.023 (0.020) Data 0.001 (0.002) Loss 0.7305 (0.7553) Acc@1 74.219 (73.809) Acc@5 98.438 (98.316)
2025-08-27 18:18:36,821 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.7428 (0.7428) Acc@1 70.312 (70.312) Acc@5 100.000 (100.000)
2025-08-27 18:18:37,705 - INFO - Epoch 3:
2025-08-27 18:18:37,706 - INFO -   Train: acc1: 73.8420 | acc5: 98.3400 | loss: 0.7547 | sparsity: 0.1037 | reactivation_rate: 0.0076
2025-08-27 18:18:37,706 - INFO -   Val:   acc1: 73.0500 | acc5: 98.3100 | loss: 0.7937
2025-08-27 18:18:37,706 - INFO -   LR: 0.100000
2025-08-27 18:18:37,749 - INFO - Checkpoint saved: epoch=3, metric=73.0500
2025-08-27 18:18:37,779 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 18:18:37,970 - INFO - Epoch: [4][0/391] Time 0.189 (0.189) Data 0.168 (0.168) Loss 0.6331 (0.6331) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 18:18:38,662 - INFO - Pruning info: sparsity=0.136
2025-08-27 18:18:38,662 - INFO -   Reactivation rate: 0.0115
2025-08-27 18:18:39,965 - INFO - Epoch: [4][100/391] Time 0.020 (0.022) Data 0.000 (0.003) Loss 0.6937 (0.7033) Acc@1 79.688 (75.379) Acc@5 96.875 (98.515)
2025-08-27 18:18:41,803 - INFO - Pruning info: sparsity=0.136
2025-08-27 18:18:41,803 - INFO -   Reactivation rate: 0.0073
2025-08-27 18:18:41,891 - INFO - Epoch: [4][200/391] Time 0.011 (0.020) Data 0.000 (0.002) Loss 0.7800 (0.6934) Acc@1 71.094 (75.972) Acc@5 100.000 (98.441)
2025-08-27 18:18:43,838 - INFO - Epoch: [4][300/391] Time 0.015 (0.020) Data 0.000 (0.002) Loss 0.7148 (0.6921) Acc@1 76.562 (76.150) Acc@5 98.438 (98.466)
2025-08-27 18:18:44,811 - INFO - Pruning info: sparsity=0.136
2025-08-27 18:18:44,812 - INFO -   Reactivation rate: 0.0055
2025-08-27 18:18:45,647 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 1.0979 (1.0979) Acc@1 64.062 (64.062) Acc@5 98.438 (98.438)
2025-08-27 18:18:46,517 - INFO - Epoch 4:
2025-08-27 18:18:46,518 - INFO -   Train: acc1: 76.2180 | acc5: 98.4980 | loss: 0.6877 | sparsity: 0.1365 | reactivation_rate: 0.0073
2025-08-27 18:18:46,518 - INFO -   Val:   acc1: 65.2200 | acc5: 96.6500 | loss: 1.0753
2025-08-27 18:18:46,518 - INFO -   LR: 0.100000
2025-08-27 18:18:46,526 - INFO - training time: 00h 00m 45.57s
2025-08-27 18:18:46,526 - INFO - 
Training completed!
2025-08-27 18:18:46,527 - INFO - Best accuracy: 73.0500
2025-08-27 18:18:46,527 - INFO - Total training time: 0.01 hours
2025-08-27 18:18:46,527 - INFO - total_experiment time: 00h 00m 47.17s
2025-08-27 18:18:46,527 - INFO - Experiment completed successfully
2025-08-27 18:18:46,528 - INFO - Total time: 0.01 hours
2025-08-27 22:44:19,688 - INFO - Starting experiment: dpf_sparsity0.9_seed42
2025-08-27 22:44:19,688 - INFO - Save directory: ./runs/dpf/sparsity0.9/seed42
2025-08-27 22:44:19,688 - INFO - Hyperparameters:
2025-08-27 22:44:19,688 - INFO -   name: dpf_sparsity0.9_seed42
2025-08-27 22:44:19,688 - INFO -   description: DPF pruning 90% (seed=42)
2025-08-27 22:44:19,688 - INFO -   save_dir: ./runs
2025-08-27 22:44:19,688 - INFO -   data: {'dataset': 'cifar10', 'datapath': '~/Datasets/CIFAR', 'batch_size': 128, 'workers': 4}
2025-08-27 22:44:19,688 - INFO -   model: {'arch': 'resnet', 'layers': 20, 'width_mult': 1.0, 'depth_mult': 1.0, 'model_mult': 0}
2025-08-27 22:44:19,688 - INFO -   training: {'epochs': 200, 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005, 'nesterov': False, 'scheduler': 'multistep', 'milestones': [100, 150], 'gamma': 0.1, 'step_size': 30, 'warmup_lr': 0.1, 'warmup_lr_epoch': 0, 'warmup_loss_epoch': 70}
2025-08-27 22:44:19,688 - INFO -   pruning: {'enabled': True, 'method': 'dpf', 'sparsity': 0.9, 'prune_freq': 16, 'target_epoch': 75, 'prune_type': 'unstructured', 'importance_method': 'L1'}
2025-08-27 22:44:19,688 - INFO -   mia: {'enabled': False, 'attack_type': 'lira', 'num_shadow_models': 64, 'shadow_epochs': 200, 'recalibrate': False}
2025-08-27 22:44:19,688 - INFO -   system: {'gpu': 0, 'seed': 42, 'deterministic': True, 'benchmark': True, 'print_freq': 100, 'save_freq': 10}
2025-08-27 22:44:19,755 - INFO - System Information:
2025-08-27 22:44:19,755 - INFO -   platform: Linux-5.14.0-503.40.1.el9_5.x86_64-x86_64-with-glibc2.35
2025-08-27 22:44:19,755 - INFO -   python_version: 3.9.18
2025-08-27 22:44:19,755 - INFO -   pytorch_version: 2.1.0
2025-08-27 22:44:19,755 - INFO -   cuda_available: True
2025-08-27 22:44:19,755 - INFO -   cpu_count: 4
2025-08-27 22:44:19,755 - INFO -   memory_total_gb: 11.0
2025-08-27 22:44:19,755 - INFO -   timestamp: 1756302259.755119
2025-08-27 22:44:19,755 - INFO -   cuda_version: 11.8
2025-08-27 22:44:19,755 - INFO -   gpu_count: 1
2025-08-27 22:44:19,755 - INFO -   gpu_names: ['NVIDIA GeForce RTX 3090']
2025-08-27 22:44:19,761 - INFO - Starting experiment: dpf_sparsity0.9_seed42
2025-08-27 22:44:19,761 - INFO - Model: resnet-20
2025-08-27 22:44:19,761 - INFO - Dataset: cifar10
2025-08-27 22:44:19,761 - INFO - Pruning: dpf (90.00%)
2025-08-27 22:44:19,892 - INFO - Model Information:
2025-08-27 22:44:19,892 - INFO -   Type: pruned
2025-08-27 22:44:19,892 - INFO -   Total parameters: 544,948
2025-08-27 22:44:19,892 - INFO -   Trainable parameters: 274,692
2025-08-27 22:44:19,892 - INFO -   Sparsity: 90.00%
2025-08-27 22:44:20,903 - INFO - Starting training...
2025-08-27 22:44:20,904 - INFO - 
Epoch: 0, lr = 0.1
2025-08-27 22:44:21,514 - INFO - Pruning info: sparsity=0.000
2025-08-27 22:44:21,514 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:22,031 - INFO - Epoch: [0][0/391] Time 1.127 (1.127) Data 0.471 (0.471) Loss 2.4983 (2.4983) Acc@1 9.375 (9.375) Acc@5 51.562 (51.562)
2025-08-27 22:44:23,839 - INFO - Epoch: [0][100/391] Time 0.012 (0.029) Data 0.000 (0.007) Loss 1.6962 (1.9329) Acc@1 30.469 (25.920) Acc@5 88.281 (81.482)
2025-08-27 22:44:24,954 - INFO - Pruning info: sparsity=0.000
2025-08-27 22:44:24,954 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:25,685 - INFO - Epoch: [0][200/391] Time 0.021 (0.024) Data 0.000 (0.004) Loss 1.5576 (1.7913) Acc@1 40.625 (31.440) Acc@5 92.969 (85.611)
2025-08-27 22:44:27,528 - INFO - Epoch: [0][300/391] Time 0.027 (0.022) Data 0.002 (0.004) Loss 1.3448 (1.6991) Acc@1 46.094 (35.655) Acc@5 92.969 (87.622)
2025-08-27 22:44:27,886 - INFO - Pruning info: sparsity=0.000
2025-08-27 22:44:27,886 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:44:29,433 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 1.4702 (1.4702) Acc@1 50.781 (50.781) Acc@5 94.531 (94.531)
2025-08-27 22:44:30,364 - INFO - Epoch 0:
2025-08-27 22:44:30,364 - INFO -   Train: acc1: 38.7660 | acc5: 88.8760 | loss: 1.6279 | sparsity: 0.0000 | reactivation_rate: 0.0000
2025-08-27 22:44:30,364 - INFO -   Val:   acc1: 46.7900 | acc5: 93.1200 | loss: 1.5221
2025-08-27 22:44:30,364 - INFO -   LR: 0.100000
2025-08-27 22:44:30,411 - INFO - Checkpoint saved: epoch=0, metric=46.7900
2025-08-27 22:44:30,453 - INFO - 
Epoch: 1, lr = 0.1
2025-08-27 22:44:30,617 - INFO - Epoch: [1][0/391] Time 0.163 (0.163) Data 0.133 (0.133) Loss 1.4714 (1.4714) Acc@1 45.312 (45.312) Acc@5 92.188 (92.188)
2025-08-27 22:44:32,254 - INFO - Pruning info: sparsity=0.036
2025-08-27 22:44:32,254 - INFO -   Reactivation rate: 0.0092
2025-08-27 22:44:32,425 - INFO - Epoch: [1][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 1.1050 (1.2205) Acc@1 61.719 (56.575) Acc@5 95.312 (94.887)
2025-08-27 22:44:34,181 - INFO - Epoch: [1][200/391] Time 0.018 (0.019) Data 0.006 (0.003) Loss 0.9399 (1.1741) Acc@1 64.062 (57.968) Acc@5 97.656 (95.281)
2025-08-27 22:44:35,052 - INFO - Pruning info: sparsity=0.036
2025-08-27 22:44:35,052 - INFO -   Reactivation rate: 0.0062
2025-08-27 22:44:36,012 - INFO - Epoch: [1][300/391] Time 0.023 (0.018) Data 0.007 (0.003) Loss 1.0042 (1.1328) Acc@1 64.844 (59.442) Acc@5 95.312 (95.647)
2025-08-27 22:44:37,650 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 1.1982 (1.1982) Acc@1 53.125 (53.125) Acc@5 94.531 (94.531)
2025-08-27 22:44:38,501 - INFO - Epoch 1:
2025-08-27 22:44:38,501 - INFO -   Train: acc1: 60.3640 | acc5: 95.9240 | loss: 1.1040 | sparsity: 0.0355 | reactivation_rate: 0.0070
2025-08-27 22:44:38,501 - INFO -   Val:   acc1: 58.8600 | acc5: 94.9900 | loss: 1.2343
2025-08-27 22:44:38,501 - INFO -   LR: 0.100000
2025-08-27 22:44:38,543 - INFO - Checkpoint saved: epoch=1, metric=58.8600
2025-08-27 22:44:38,575 - INFO - 
Epoch: 2, lr = 0.1
2025-08-27 22:44:38,756 - INFO - Epoch: [2][0/391] Time 0.180 (0.180) Data 0.144 (0.144) Loss 0.9213 (0.9213) Acc@1 70.312 (70.312) Acc@5 96.094 (96.094)
2025-08-27 22:44:39,092 - INFO - Pruning info: sparsity=0.070
2025-08-27 22:44:39,092 - INFO -   Reactivation rate: 0.0128
2025-08-27 22:44:40,565 - INFO - Epoch: [2][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.9196 (0.9697) Acc@1 67.188 (65.710) Acc@5 95.312 (96.914)
2025-08-27 22:44:41,937 - INFO - Pruning info: sparsity=0.070
2025-08-27 22:44:41,937 - INFO -   Reactivation rate: 0.0072
2025-08-27 22:44:42,309 - INFO - Epoch: [2][200/391] Time 0.014 (0.019) Data 0.004 (0.003) Loss 0.8970 (0.9385) Acc@1 69.531 (66.706) Acc@5 97.656 (97.252)
2025-08-27 22:44:44,055 - INFO - Epoch: [2][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.7761 (0.9218) Acc@1 74.219 (67.439) Acc@5 100.000 (97.371)
2025-08-27 22:44:44,715 - INFO - Pruning info: sparsity=0.070
2025-08-27 22:44:44,715 - INFO -   Reactivation rate: 0.0059
2025-08-27 22:44:45,788 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 1.1557 (1.1557) Acc@1 62.500 (62.500) Acc@5 95.312 (95.312)
2025-08-27 22:44:46,624 - INFO - Epoch 2:
2025-08-27 22:44:46,625 - INFO -   Train: acc1: 68.0440 | acc5: 97.4600 | loss: 0.9043 | sparsity: 0.0701 | reactivation_rate: 0.0074
2025-08-27 22:44:46,625 - INFO -   Val:   acc1: 59.6700 | acc5: 95.8400 | loss: 1.2475
2025-08-27 22:44:46,625 - INFO -   LR: 0.100000
2025-08-27 22:44:46,669 - INFO - Checkpoint saved: epoch=2, metric=59.6700
2025-08-27 22:44:46,702 - INFO - 
Epoch: 3, lr = 0.1
2025-08-27 22:44:46,856 - INFO - Epoch: [3][0/391] Time 0.152 (0.152) Data 0.135 (0.135) Loss 0.9140 (0.9140) Acc@1 70.312 (70.312) Acc@5 96.094 (96.094)
2025-08-27 22:44:48,582 - INFO - Epoch: [3][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.8124 (0.7877) Acc@1 67.188 (72.277) Acc@5 96.875 (97.912)
2025-08-27 22:44:48,703 - INFO - Pruning info: sparsity=0.104
2025-08-27 22:44:48,703 - INFO -   Reactivation rate: 0.0089
2025-08-27 22:44:50,345 - INFO - Epoch: [3][200/391] Time 0.016 (0.018) Data 0.002 (0.003) Loss 0.7393 (0.7820) Acc@1 72.656 (72.664) Acc@5 99.219 (98.049)
2025-08-27 22:44:51,504 - INFO - Pruning info: sparsity=0.104
2025-08-27 22:44:51,504 - INFO -   Reactivation rate: 0.0065
2025-08-27 22:44:52,087 - INFO - Epoch: [3][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.7781 (0.7742) Acc@1 74.219 (72.900) Acc@5 96.875 (98.147)
2025-08-27 22:44:53,751 - INFO - Test: [0/79] Time 0.105 (0.105) Loss 0.9899 (0.9899) Acc@1 64.844 (64.844) Acc@5 99.219 (99.219)
2025-08-27 22:44:54,632 - INFO - Epoch 3:
2025-08-27 22:44:54,632 - INFO -   Train: acc1: 72.9500 | acc5: 98.1500 | loss: 0.7738 | sparsity: 0.1037 | reactivation_rate: 0.0076
2025-08-27 22:44:54,632 - INFO -   Val:   acc1: 65.1400 | acc5: 96.5100 | loss: 1.0415
2025-08-27 22:44:54,632 - INFO -   LR: 0.100000
2025-08-27 22:44:54,675 - INFO - Checkpoint saved: epoch=3, metric=65.1400
2025-08-27 22:44:54,704 - INFO - 
Epoch: 4, lr = 0.1
2025-08-27 22:44:54,884 - INFO - Epoch: [4][0/391] Time 0.179 (0.179) Data 0.156 (0.156) Loss 0.7395 (0.7395) Acc@1 69.531 (69.531) Acc@5 99.219 (99.219)
2025-08-27 22:44:55,470 - INFO - Pruning info: sparsity=0.136
2025-08-27 22:44:55,470 - INFO -   Reactivation rate: 0.0111
2025-08-27 22:44:56,624 - INFO - Epoch: [4][100/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.6794 (0.7255) Acc@1 81.250 (74.667) Acc@5 98.438 (98.499)
2025-08-27 22:44:58,305 - INFO - Pruning info: sparsity=0.136
2025-08-27 22:44:58,305 - INFO -   Reactivation rate: 0.0069
2025-08-27 22:44:58,374 - INFO - Epoch: [4][200/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.7593 (0.7112) Acc@1 64.062 (75.225) Acc@5 100.000 (98.480)
2025-08-27 22:45:00,134 - INFO - Epoch: [4][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.6483 (0.7030) Acc@1 75.781 (75.641) Acc@5 99.219 (98.425)
2025-08-27 22:45:01,112 - INFO - Pruning info: sparsity=0.136
2025-08-27 22:45:01,112 - INFO -   Reactivation rate: 0.0054
2025-08-27 22:45:01,857 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 1.0523 (1.0523) Acc@1 70.312 (70.312) Acc@5 96.094 (96.094)
2025-08-27 22:45:02,666 - INFO - Epoch 4:
2025-08-27 22:45:02,666 - INFO -   Train: acc1: 75.7840 | acc5: 98.4540 | loss: 0.6988 | sparsity: 0.1365 | reactivation_rate: 0.0073
2025-08-27 22:45:02,666 - INFO -   Val:   acc1: 66.7200 | acc5: 97.3500 | loss: 1.0551
2025-08-27 22:45:02,666 - INFO -   LR: 0.100000
2025-08-27 22:45:02,709 - INFO - Checkpoint saved: epoch=4, metric=66.7200
2025-08-27 22:45:02,740 - INFO - 
Epoch: 5, lr = 0.1
2025-08-27 22:45:02,917 - INFO - Epoch: [5][0/391] Time 0.176 (0.176) Data 0.151 (0.151) Loss 0.7116 (0.7116) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:45:04,718 - INFO - Epoch: [5][100/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.5922 (0.6833) Acc@1 78.906 (76.067) Acc@5 100.000 (98.670)
2025-08-27 22:45:05,178 - INFO - Pruning info: sparsity=0.168
2025-08-27 22:45:05,179 - INFO -   Reactivation rate: 0.0087
2025-08-27 22:45:06,563 - INFO - Epoch: [5][200/391] Time 0.027 (0.019) Data 0.000 (0.003) Loss 0.6870 (0.6681) Acc@1 78.906 (76.780) Acc@5 98.438 (98.644)
2025-08-27 22:45:08,105 - INFO - Pruning info: sparsity=0.168
2025-08-27 22:45:08,106 - INFO -   Reactivation rate: 0.0060
2025-08-27 22:45:08,372 - INFO - Epoch: [5][300/391] Time 0.020 (0.019) Data 0.010 (0.003) Loss 0.8229 (0.6664) Acc@1 68.750 (76.884) Acc@5 97.656 (98.606)
2025-08-27 22:45:10,158 - INFO - Test: [0/79] Time 0.104 (0.104) Loss 0.9520 (0.9520) Acc@1 67.969 (67.969) Acc@5 97.656 (97.656)
2025-08-27 22:45:11,042 - INFO - Epoch 5:
2025-08-27 22:45:11,042 - INFO -   Train: acc1: 77.0900 | acc5: 98.6280 | loss: 0.6638 | sparsity: 0.1683 | reactivation_rate: 0.0073
2025-08-27 22:45:11,042 - INFO -   Val:   acc1: 68.6600 | acc5: 96.3900 | loss: 1.0084
2025-08-27 22:45:11,042 - INFO -   LR: 0.100000
2025-08-27 22:45:11,089 - INFO - Checkpoint saved: epoch=5, metric=68.6600
2025-08-27 22:45:11,121 - INFO - 
Epoch: 6, lr = 0.1
2025-08-27 22:45:11,297 - INFO - Epoch: [6][0/391] Time 0.175 (0.175) Data 0.155 (0.155) Loss 0.5367 (0.5367) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:45:12,244 - INFO - Pruning info: sparsity=0.199
2025-08-27 22:45:12,244 - INFO -   Reactivation rate: 0.0107
2025-08-27 22:45:13,116 - INFO - Epoch: [6][100/391] Time 0.025 (0.020) Data 0.000 (0.004) Loss 0.6569 (0.6300) Acc@1 78.125 (77.993) Acc@5 98.438 (98.685)
2025-08-27 22:45:14,955 - INFO - Epoch: [6][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.5907 (0.6324) Acc@1 78.125 (77.973) Acc@5 99.219 (98.698)
2025-08-27 22:45:15,204 - INFO - Pruning info: sparsity=0.199
2025-08-27 22:45:15,205 - INFO -   Reactivation rate: 0.0065
2025-08-27 22:45:16,799 - INFO - Epoch: [6][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.7882 (0.6334) Acc@1 75.000 (78.109) Acc@5 99.219 (98.718)
2025-08-27 22:45:18,100 - INFO - Pruning info: sparsity=0.199
2025-08-27 22:45:18,100 - INFO -   Reactivation rate: 0.0049
2025-08-27 22:45:18,553 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.8338 (0.8338) Acc@1 69.531 (69.531) Acc@5 98.438 (98.438)
2025-08-27 22:45:19,388 - INFO - Epoch 6:
2025-08-27 22:45:19,388 - INFO -   Train: acc1: 78.1860 | acc5: 98.7580 | loss: 0.6310 | sparsity: 0.1992 | reactivation_rate: 0.0070
2025-08-27 22:45:19,388 - INFO -   Val:   acc1: 67.1200 | acc5: 97.0500 | loss: 0.9938
2025-08-27 22:45:19,388 - INFO -   LR: 0.100000
2025-08-27 22:45:19,396 - INFO - 
Epoch: 7, lr = 0.1
2025-08-27 22:45:19,557 - INFO - Epoch: [7][0/391] Time 0.159 (0.159) Data 0.137 (0.137) Loss 0.6244 (0.6244) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 22:45:21,378 - INFO - Epoch: [7][100/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.6271 (0.6026) Acc@1 78.906 (79.571) Acc@5 99.219 (98.677)
2025-08-27 22:45:22,130 - INFO - Pruning info: sparsity=0.229
2025-08-27 22:45:22,130 - INFO -   Reactivation rate: 0.0079
2025-08-27 22:45:23,241 - INFO - Epoch: [7][200/391] Time 0.016 (0.019) Data 0.006 (0.003) Loss 0.5760 (0.6044) Acc@1 79.688 (79.268) Acc@5 99.219 (98.717)
2025-08-27 22:45:25,034 - INFO - Epoch: [7][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.6199 (0.6024) Acc@1 75.781 (79.179) Acc@5 96.875 (98.783)
2025-08-27 22:45:25,082 - INFO - Pruning info: sparsity=0.229
2025-08-27 22:45:25,083 - INFO -   Reactivation rate: 0.0055
2025-08-27 22:45:26,836 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 1.1582 (1.1582) Acc@1 70.312 (70.312) Acc@5 92.188 (92.188)
2025-08-27 22:45:27,671 - INFO - Epoch 7:
2025-08-27 22:45:27,672 - INFO -   Train: acc1: 79.0940 | acc5: 98.7900 | loss: 0.6047 | sparsity: 0.2292 | reactivation_rate: 0.0069
2025-08-27 22:45:27,672 - INFO -   Val:   acc1: 63.6100 | acc5: 94.2600 | loss: 1.3479
2025-08-27 22:45:27,672 - INFO -   LR: 0.100000
2025-08-27 22:45:27,680 - INFO - 
Epoch: 8, lr = 0.1
2025-08-27 22:45:27,872 - INFO - Epoch: [8][0/391] Time 0.191 (0.191) Data 0.162 (0.162) Loss 0.4745 (0.4745) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:45:29,308 - INFO - Pruning info: sparsity=0.258
2025-08-27 22:45:29,309 - INFO -   Reactivation rate: 0.0095
2025-08-27 22:45:29,795 - INFO - Epoch: [8][100/391] Time 0.024 (0.021) Data 0.011 (0.004) Loss 0.4938 (0.5821) Acc@1 79.688 (80.043) Acc@5 99.219 (98.933)
2025-08-27 22:45:31,600 - INFO - Epoch: [8][200/391] Time 0.049 (0.019) Data 0.018 (0.004) Loss 0.5066 (0.5774) Acc@1 80.469 (80.224) Acc@5 100.000 (98.927)
2025-08-27 22:45:32,150 - INFO - Pruning info: sparsity=0.258
2025-08-27 22:45:32,150 - INFO -   Reactivation rate: 0.0059
2025-08-27 22:45:33,394 - INFO - Epoch: [8][300/391] Time 0.035 (0.019) Data 0.025 (0.004) Loss 0.6024 (0.5875) Acc@1 80.469 (79.965) Acc@5 99.219 (98.887)
2025-08-27 22:45:35,194 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6825 (0.6825) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 22:45:36,048 - INFO - Epoch 8:
2025-08-27 22:45:36,049 - INFO -   Train: acc1: 80.0420 | acc5: 98.9140 | loss: 0.5829 | sparsity: 0.2584 | reactivation_rate: 0.0067
2025-08-27 22:45:36,049 - INFO -   Val:   acc1: 76.1400 | acc5: 98.3600 | loss: 0.6914
2025-08-27 22:45:36,049 - INFO -   LR: 0.100000
2025-08-27 22:45:36,091 - INFO - Checkpoint saved: epoch=8, metric=76.1400
2025-08-27 22:45:36,124 - INFO - 
Epoch: 9, lr = 0.1
2025-08-27 22:45:36,300 - INFO - Epoch: [9][0/391] Time 0.176 (0.176) Data 0.157 (0.157) Loss 0.4847 (0.4847) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 22:45:36,306 - INFO - Pruning info: sparsity=0.287
2025-08-27 22:45:36,306 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:45:38,094 - INFO - Epoch: [9][100/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.5944 (0.5460) Acc@1 82.812 (81.320) Acc@5 96.875 (98.940)
2025-08-27 22:45:39,193 - INFO - Pruning info: sparsity=0.287
2025-08-27 22:45:39,193 - INFO -   Reactivation rate: 0.0066
2025-08-27 22:45:39,912 - INFO - Epoch: [9][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4957 (0.5561) Acc@1 84.375 (80.943) Acc@5 98.438 (98.935)
2025-08-27 22:45:41,716 - INFO - Epoch: [9][300/391] Time 0.043 (0.019) Data 0.026 (0.004) Loss 0.6313 (0.5628) Acc@1 77.344 (80.687) Acc@5 96.094 (98.912)
2025-08-27 22:45:42,094 - INFO - Pruning info: sparsity=0.287
2025-08-27 22:45:42,095 - INFO -   Reactivation rate: 0.0050
2025-08-27 22:45:43,481 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.7554 (0.7554) Acc@1 78.125 (78.125) Acc@5 97.656 (97.656)
2025-08-27 22:45:44,312 - INFO - Epoch 9:
2025-08-27 22:45:44,312 - INFO -   Train: acc1: 80.6460 | acc5: 98.9720 | loss: 0.5616 | sparsity: 0.2867 | reactivation_rate: 0.0064
2025-08-27 22:45:44,312 - INFO -   Val:   acc1: 74.1200 | acc5: 97.6800 | loss: 0.7802
2025-08-27 22:45:44,312 - INFO -   LR: 0.100000
2025-08-27 22:45:44,325 - INFO - 
Epoch: 10, lr = 0.1
2025-08-27 22:45:44,498 - INFO - Epoch: [10][0/391] Time 0.172 (0.172) Data 0.138 (0.138) Loss 0.5520 (0.5520) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 22:45:46,094 - INFO - Pruning info: sparsity=0.314
2025-08-27 22:45:46,094 - INFO -   Reactivation rate: 0.0081
2025-08-27 22:45:46,271 - INFO - Epoch: [10][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3869 (0.5301) Acc@1 85.938 (81.459) Acc@5 100.000 (99.126)
2025-08-27 22:45:48,100 - INFO - Epoch: [10][200/391] Time 0.047 (0.019) Data 0.035 (0.003) Loss 0.5161 (0.5397) Acc@1 85.156 (81.153) Acc@5 97.656 (99.110)
2025-08-27 22:45:49,055 - INFO - Pruning info: sparsity=0.314
2025-08-27 22:45:49,057 - INFO -   Reactivation rate: 0.0052
2025-08-27 22:45:50,025 - INFO - Epoch: [10][300/391] Time 0.023 (0.019) Data 0.002 (0.002) Loss 0.6939 (0.5479) Acc@1 75.000 (81.050) Acc@5 96.094 (99.040)
2025-08-27 22:45:51,801 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.7561 (0.7561) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 22:45:52,631 - INFO - Epoch 10:
2025-08-27 22:45:52,632 - INFO -   Train: acc1: 81.1100 | acc5: 99.0320 | loss: 0.5482 | sparsity: 0.3141 | reactivation_rate: 0.0061
2025-08-27 22:45:52,632 - INFO -   Val:   acc1: 73.5700 | acc5: 98.3000 | loss: 0.8606
2025-08-27 22:45:52,632 - INFO -   LR: 0.100000
2025-08-27 22:45:52,676 - INFO - 
Epoch: 11, lr = 0.1
2025-08-27 22:45:52,837 - INFO - Epoch: [11][0/391] Time 0.161 (0.161) Data 0.141 (0.141) Loss 0.5569 (0.5569) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 22:45:53,212 - INFO - Pruning info: sparsity=0.341
2025-08-27 22:45:53,213 - INFO -   Reactivation rate: 0.0115
2025-08-27 22:45:54,767 - INFO - Epoch: [11][100/391] Time 0.016 (0.021) Data 0.000 (0.004) Loss 0.5603 (0.5451) Acc@1 84.375 (81.149) Acc@5 100.000 (99.087)
2025-08-27 22:45:56,197 - INFO - Pruning info: sparsity=0.341
2025-08-27 22:45:56,197 - INFO -   Reactivation rate: 0.0059
2025-08-27 22:45:56,572 - INFO - Epoch: [11][200/391] Time 0.030 (0.019) Data 0.012 (0.004) Loss 0.5776 (0.5387) Acc@1 80.469 (81.534) Acc@5 97.656 (99.106)
2025-08-27 22:45:58,388 - INFO - Epoch: [11][300/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.6201 (0.5436) Acc@1 77.344 (81.338) Acc@5 97.656 (99.040)
2025-08-27 22:45:59,108 - INFO - Pruning info: sparsity=0.341
2025-08-27 22:45:59,108 - INFO -   Reactivation rate: 0.0042
2025-08-27 22:46:00,196 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.9927 (0.9927) Acc@1 71.094 (71.094) Acc@5 97.656 (97.656)
2025-08-27 22:46:01,029 - INFO - Epoch 11:
2025-08-27 22:46:01,029 - INFO -   Train: acc1: 81.3360 | acc5: 99.0580 | loss: 0.5423 | sparsity: 0.3408 | reactivation_rate: 0.0059
2025-08-27 22:46:01,029 - INFO -   Val:   acc1: 66.8900 | acc5: 95.7800 | loss: 1.1347
2025-08-27 22:46:01,029 - INFO -   LR: 0.100000
2025-08-27 22:46:01,039 - INFO - 
Epoch: 12, lr = 0.1
2025-08-27 22:46:01,218 - INFO - Epoch: [12][0/391] Time 0.178 (0.178) Data 0.140 (0.140) Loss 0.4581 (0.4581) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:46:02,970 - INFO - Epoch: [12][100/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.5395 (0.5395) Acc@1 78.125 (81.412) Acc@5 99.219 (99.103)
2025-08-27 22:46:03,124 - INFO - Pruning info: sparsity=0.367
2025-08-27 22:46:03,124 - INFO -   Reactivation rate: 0.0068
2025-08-27 22:46:04,824 - INFO - Epoch: [12][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.7538 (0.5271) Acc@1 71.875 (81.771) Acc@5 98.438 (99.048)
2025-08-27 22:46:06,008 - INFO - Pruning info: sparsity=0.367
2025-08-27 22:46:06,009 - INFO -   Reactivation rate: 0.0049
2025-08-27 22:46:06,571 - INFO - Epoch: [12][300/391] Time 0.019 (0.018) Data 0.004 (0.003) Loss 0.6118 (0.5306) Acc@1 79.688 (81.756) Acc@5 99.219 (99.066)
2025-08-27 22:46:08,370 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.7104 (0.7104) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-27 22:46:09,221 - INFO - Epoch 12:
2025-08-27 22:46:09,221 - INFO -   Train: acc1: 81.7460 | acc5: 99.0380 | loss: 0.5306 | sparsity: 0.3666 | reactivation_rate: 0.0057
2025-08-27 22:46:09,221 - INFO -   Val:   acc1: 73.4500 | acc5: 97.8500 | loss: 0.8235
2025-08-27 22:46:09,221 - INFO -   LR: 0.100000
2025-08-27 22:46:09,230 - INFO - 
Epoch: 13, lr = 0.1
2025-08-27 22:46:09,409 - INFO - Epoch: [13][0/391] Time 0.178 (0.178) Data 0.158 (0.158) Loss 0.5602 (0.5602) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 22:46:10,071 - INFO - Pruning info: sparsity=0.392
2025-08-27 22:46:10,071 - INFO -   Reactivation rate: 0.0086
2025-08-27 22:46:11,181 - INFO - Epoch: [13][100/391] Time 0.019 (0.019) Data 0.004 (0.006) Loss 0.5453 (0.5045) Acc@1 85.156 (82.743) Acc@5 100.000 (99.281)
2025-08-27 22:46:12,916 - INFO - Pruning info: sparsity=0.392
2025-08-27 22:46:12,916 - INFO -   Reactivation rate: 0.0053
2025-08-27 22:46:12,980 - INFO - Epoch: [13][200/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.3378 (0.5113) Acc@1 88.281 (82.424) Acc@5 100.000 (99.195)
2025-08-27 22:46:14,784 - INFO - Epoch: [13][300/391] Time 0.012 (0.018) Data 0.000 (0.004) Loss 0.5223 (0.5201) Acc@1 79.688 (82.153) Acc@5 99.219 (99.175)
2025-08-27 22:46:15,789 - INFO - Pruning info: sparsity=0.392
2025-08-27 22:46:15,789 - INFO -   Reactivation rate: 0.0038
2025-08-27 22:46:16,523 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5845 (0.5845) Acc@1 81.250 (81.250) Acc@5 98.438 (98.438)
2025-08-27 22:46:17,382 - INFO - Epoch 13:
2025-08-27 22:46:17,383 - INFO -   Train: acc1: 82.0460 | acc5: 99.1620 | loss: 0.5236 | sparsity: 0.3916 | reactivation_rate: 0.0054
2025-08-27 22:46:17,383 - INFO -   Val:   acc1: 77.6500 | acc5: 98.6000 | loss: 0.6568
2025-08-27 22:46:17,383 - INFO -   LR: 0.100000
2025-08-27 22:46:17,430 - INFO - Checkpoint saved: epoch=13, metric=77.6500
2025-08-27 22:46:17,462 - INFO - 
Epoch: 14, lr = 0.1
2025-08-27 22:46:17,631 - INFO - Epoch: [14][0/391] Time 0.168 (0.168) Data 0.143 (0.143) Loss 0.4862 (0.4862) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 22:46:19,440 - INFO - Epoch: [14][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.6328 (0.5025) Acc@1 79.688 (82.580) Acc@5 98.438 (99.080)
2025-08-27 22:46:19,849 - INFO - Pruning info: sparsity=0.416
2025-08-27 22:46:19,849 - INFO -   Reactivation rate: 0.0059
2025-08-27 22:46:21,224 - INFO - Epoch: [14][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.5411 (0.5092) Acc@1 82.812 (82.408) Acc@5 99.219 (99.094)
2025-08-27 22:46:22,807 - INFO - Pruning info: sparsity=0.416
2025-08-27 22:46:22,808 - INFO -   Reactivation rate: 0.0042
2025-08-27 22:46:23,061 - INFO - Epoch: [14][300/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.4113 (0.5131) Acc@1 85.938 (82.241) Acc@5 100.000 (99.097)
2025-08-27 22:46:24,854 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.6094 (0.6094) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 22:46:25,703 - INFO - Epoch 14:
2025-08-27 22:46:25,703 - INFO -   Train: acc1: 82.3280 | acc5: 99.0920 | loss: 0.5119 | sparsity: 0.4158 | reactivation_rate: 0.0051
2025-08-27 22:46:25,703 - INFO -   Val:   acc1: 78.4600 | acc5: 98.6600 | loss: 0.6482
2025-08-27 22:46:25,703 - INFO -   LR: 0.100000
2025-08-27 22:46:25,750 - INFO - Checkpoint saved: epoch=14, metric=78.4600
2025-08-27 22:46:25,782 - INFO - 
Epoch: 15, lr = 0.1
2025-08-27 22:46:25,958 - INFO - Epoch: [15][0/391] Time 0.175 (0.175) Data 0.144 (0.144) Loss 0.4123 (0.4123) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 22:46:26,924 - INFO - Pruning info: sparsity=0.439
2025-08-27 22:46:26,924 - INFO -   Reactivation rate: 0.0078
2025-08-27 22:46:27,750 - INFO - Epoch: [15][100/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4719 (0.4912) Acc@1 83.594 (83.083) Acc@5 100.000 (99.281)
2025-08-27 22:46:29,562 - INFO - Epoch: [15][200/391] Time 0.020 (0.019) Data 0.007 (0.003) Loss 0.6097 (0.5064) Acc@1 78.125 (82.661) Acc@5 100.000 (99.199)
2025-08-27 22:46:29,823 - INFO - Pruning info: sparsity=0.439
2025-08-27 22:46:29,824 - INFO -   Reactivation rate: 0.0047
2025-08-27 22:46:31,345 - INFO - Epoch: [15][300/391] Time 0.025 (0.018) Data 0.003 (0.002) Loss 0.5008 (0.5050) Acc@1 81.250 (82.623) Acc@5 99.219 (99.188)
2025-08-27 22:46:32,638 - INFO - Pruning info: sparsity=0.439
2025-08-27 22:46:32,638 - INFO -   Reactivation rate: 0.0037
2025-08-27 22:46:33,036 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.7215 (0.7215) Acc@1 74.219 (74.219) Acc@5 100.000 (100.000)
2025-08-27 22:46:33,866 - INFO - Epoch 15:
2025-08-27 22:46:33,866 - INFO -   Train: acc1: 82.5000 | acc5: 99.1500 | loss: 0.5087 | sparsity: 0.4392 | reactivation_rate: 0.0050
2025-08-27 22:46:33,866 - INFO -   Val:   acc1: 76.4100 | acc5: 98.8000 | loss: 0.6953
2025-08-27 22:46:33,866 - INFO -   LR: 0.100000
2025-08-27 22:46:33,874 - INFO - 
Epoch: 16, lr = 0.1
2025-08-27 22:46:34,051 - INFO - Epoch: [16][0/391] Time 0.176 (0.176) Data 0.151 (0.151) Loss 0.4905 (0.4905) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 22:46:35,799 - INFO - Epoch: [16][100/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.5115 (0.4795) Acc@1 82.812 (83.385) Acc@5 98.438 (99.257)
2025-08-27 22:46:36,549 - INFO - Pruning info: sparsity=0.462
2025-08-27 22:46:36,549 - INFO -   Reactivation rate: 0.0051
2025-08-27 22:46:37,564 - INFO - Epoch: [16][200/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.4508 (0.4902) Acc@1 82.812 (82.999) Acc@5 100.000 (99.254)
2025-08-27 22:46:39,388 - INFO - Epoch: [16][300/391] Time 0.025 (0.018) Data 0.013 (0.003) Loss 0.6311 (0.4930) Acc@1 76.562 (82.875) Acc@5 100.000 (99.198)
2025-08-27 22:46:39,448 - INFO - Pruning info: sparsity=0.462
2025-08-27 22:46:39,448 - INFO -   Reactivation rate: 0.0038
2025-08-27 22:46:41,094 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.5643 (0.5643) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 22:46:41,923 - INFO - Epoch 16:
2025-08-27 22:46:41,923 - INFO -   Train: acc1: 82.9160 | acc5: 99.2180 | loss: 0.4928 | sparsity: 0.4619 | reactivation_rate: 0.0048
2025-08-27 22:46:41,923 - INFO -   Val:   acc1: 78.7800 | acc5: 98.6900 | loss: 0.6355
2025-08-27 22:46:41,923 - INFO -   LR: 0.100000
2025-08-27 22:46:41,966 - INFO - Checkpoint saved: epoch=16, metric=78.7800
2025-08-27 22:46:41,998 - INFO - 
Epoch: 17, lr = 0.1
2025-08-27 22:46:42,180 - INFO - Epoch: [17][0/391] Time 0.181 (0.181) Data 0.165 (0.165) Loss 0.4505 (0.4505) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:46:43,408 - INFO - Pruning info: sparsity=0.484
2025-08-27 22:46:43,408 - INFO -   Reactivation rate: 0.0062
2025-08-27 22:46:43,874 - INFO - Epoch: [17][100/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4379 (0.4794) Acc@1 82.812 (83.331) Acc@5 99.219 (99.335)
2025-08-27 22:46:45,633 - INFO - Epoch: [17][200/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.3732 (0.4823) Acc@1 85.938 (83.283) Acc@5 100.000 (99.250)
2025-08-27 22:46:46,212 - INFO - Pruning info: sparsity=0.484
2025-08-27 22:46:46,212 - INFO -   Reactivation rate: 0.0040
2025-08-27 22:46:47,490 - INFO - Epoch: [17][300/391] Time 0.016 (0.018) Data 0.005 (0.003) Loss 0.5084 (0.4918) Acc@1 82.812 (83.124) Acc@5 100.000 (99.232)
2025-08-27 22:46:49,224 - INFO - Test: [0/79] Time 0.153 (0.153) Loss 0.6198 (0.6198) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-27 22:46:50,108 - INFO - Epoch 17:
2025-08-27 22:46:50,109 - INFO -   Train: acc1: 83.0920 | acc5: 99.2380 | loss: 0.4925 | sparsity: 0.4838 | reactivation_rate: 0.0046
2025-08-27 22:46:50,109 - INFO -   Val:   acc1: 77.2700 | acc5: 98.7700 | loss: 0.7079
2025-08-27 22:46:50,109 - INFO -   LR: 0.100000
2025-08-27 22:46:50,116 - INFO - 
Epoch: 18, lr = 0.1
2025-08-27 22:46:50,297 - INFO - Epoch: [18][0/391] Time 0.180 (0.180) Data 0.162 (0.162) Loss 0.4222 (0.4222) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:46:50,319 - INFO - Pruning info: sparsity=0.505
2025-08-27 22:46:50,320 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:46:52,057 - INFO - Epoch: [18][100/391] Time 0.021 (0.019) Data 0.010 (0.003) Loss 0.4499 (0.4664) Acc@1 85.156 (84.143) Acc@5 98.438 (99.281)
2025-08-27 22:46:53,114 - INFO - Pruning info: sparsity=0.505
2025-08-27 22:46:53,115 - INFO -   Reactivation rate: 0.0045
2025-08-27 22:46:53,842 - INFO - Epoch: [18][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4119 (0.4786) Acc@1 83.594 (83.699) Acc@5 98.438 (99.180)
2025-08-27 22:46:55,583 - INFO - Epoch: [18][300/391] Time 0.017 (0.018) Data 0.000 (0.003) Loss 0.5655 (0.4822) Acc@1 78.125 (83.537) Acc@5 99.219 (99.182)
2025-08-27 22:46:55,922 - INFO - Pruning info: sparsity=0.505
2025-08-27 22:46:55,922 - INFO -   Reactivation rate: 0.0032
2025-08-27 22:46:57,266 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.6856 (0.6856) Acc@1 75.000 (75.000) Acc@5 97.656 (97.656)
2025-08-27 22:46:58,102 - INFO - Epoch 18:
2025-08-27 22:46:58,102 - INFO -   Train: acc1: 83.5560 | acc5: 99.2200 | loss: 0.4816 | sparsity: 0.5049 | reactivation_rate: 0.0043
2025-08-27 22:46:58,102 - INFO -   Val:   acc1: 74.5800 | acc5: 97.8900 | loss: 0.8151
2025-08-27 22:46:58,102 - INFO -   LR: 0.100000
2025-08-27 22:46:58,113 - INFO - 
Epoch: 19, lr = 0.1
2025-08-27 22:46:58,294 - INFO - Epoch: [19][0/391] Time 0.180 (0.180) Data 0.153 (0.153) Loss 0.3640 (0.3640) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:46:59,849 - INFO - Pruning info: sparsity=0.525
2025-08-27 22:46:59,849 - INFO -   Reactivation rate: 0.0055
2025-08-27 22:47:00,036 - INFO - Epoch: [19][100/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.3672 (0.4751) Acc@1 86.719 (83.694) Acc@5 99.219 (99.219)
2025-08-27 22:47:01,814 - INFO - Epoch: [19][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3540 (0.4827) Acc@1 85.938 (83.294) Acc@5 100.000 (99.234)
2025-08-27 22:47:02,736 - INFO - Pruning info: sparsity=0.525
2025-08-27 22:47:02,736 - INFO -   Reactivation rate: 0.0036
2025-08-27 22:47:03,628 - INFO - Epoch: [19][300/391] Time 0.015 (0.018) Data 0.000 (0.002) Loss 0.4099 (0.4873) Acc@1 89.062 (83.160) Acc@5 100.000 (99.219)
2025-08-27 22:47:05,449 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.6600 (0.6600) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 22:47:06,281 - INFO - Epoch 19:
2025-08-27 22:47:06,281 - INFO -   Train: acc1: 83.4080 | acc5: 99.2160 | loss: 0.4823 | sparsity: 0.5254 | reactivation_rate: 0.0042
2025-08-27 22:47:06,281 - INFO -   Val:   acc1: 76.6900 | acc5: 98.7600 | loss: 0.7159
2025-08-27 22:47:06,281 - INFO -   LR: 0.100000
2025-08-27 22:47:06,291 - INFO - 
Epoch: 20, lr = 0.1
2025-08-27 22:47:06,463 - INFO - Epoch: [20][0/391] Time 0.171 (0.171) Data 0.150 (0.150) Loss 0.4166 (0.4166) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:47:06,825 - INFO - Pruning info: sparsity=0.545
2025-08-27 22:47:06,825 - INFO -   Reactivation rate: 0.0071
2025-08-27 22:47:08,267 - INFO - Epoch: [20][100/391] Time 0.029 (0.020) Data 0.000 (0.003) Loss 0.3462 (0.4677) Acc@1 89.844 (83.934) Acc@5 99.219 (99.157)
2025-08-27 22:47:09,689 - INFO - Pruning info: sparsity=0.545
2025-08-27 22:47:09,689 - INFO -   Reactivation rate: 0.0041
2025-08-27 22:47:10,114 - INFO - Epoch: [20][200/391] Time 0.024 (0.019) Data 0.004 (0.003) Loss 0.3904 (0.4742) Acc@1 89.062 (83.773) Acc@5 100.000 (99.157)
2025-08-27 22:47:11,931 - INFO - Epoch: [20][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.6981 (0.4752) Acc@1 77.344 (83.703) Acc@5 97.656 (99.190)
2025-08-27 22:47:12,663 - INFO - Pruning info: sparsity=0.545
2025-08-27 22:47:12,663 - INFO -   Reactivation rate: 0.0029
2025-08-27 22:47:13,657 - INFO - Test: [0/79] Time 0.118 (0.118) Loss 0.7061 (0.7061) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 22:47:14,507 - INFO - Epoch 20:
2025-08-27 22:47:14,507 - INFO -   Train: acc1: 83.5280 | acc5: 99.1820 | loss: 0.4787 | sparsity: 0.5451 | reactivation_rate: 0.0039
2025-08-27 22:47:14,507 - INFO -   Val:   acc1: 75.8500 | acc5: 98.3600 | loss: 0.7545
2025-08-27 22:47:14,507 - INFO -   LR: 0.100000
2025-08-27 22:47:14,550 - INFO - 
Epoch: 21, lr = 0.1
2025-08-27 22:47:14,728 - INFO - Epoch: [21][0/391] Time 0.177 (0.177) Data 0.146 (0.146) Loss 0.4579 (0.4579) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:47:16,519 - INFO - Epoch: [21][100/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.4500 (0.4589) Acc@1 83.594 (84.375) Acc@5 100.000 (99.203)
2025-08-27 22:47:16,689 - INFO - Pruning info: sparsity=0.564
2025-08-27 22:47:16,689 - INFO -   Reactivation rate: 0.0047
2025-08-27 22:47:18,437 - INFO - Epoch: [21][200/391] Time 0.036 (0.019) Data 0.023 (0.003) Loss 0.4160 (0.4603) Acc@1 86.719 (84.262) Acc@5 99.219 (99.246)
2025-08-27 22:47:19,657 - INFO - Pruning info: sparsity=0.564
2025-08-27 22:47:19,657 - INFO -   Reactivation rate: 0.0033
2025-08-27 22:47:20,215 - INFO - Epoch: [21][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4559 (0.4658) Acc@1 84.375 (83.988) Acc@5 99.219 (99.255)
2025-08-27 22:47:22,004 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.7868 (0.7868) Acc@1 75.781 (75.781) Acc@5 97.656 (97.656)
2025-08-27 22:47:22,859 - INFO - Epoch 21:
2025-08-27 22:47:22,859 - INFO -   Train: acc1: 83.7420 | acc5: 99.2600 | loss: 0.4728 | sparsity: 0.5641 | reactivation_rate: 0.0038
2025-08-27 22:47:22,859 - INFO -   Val:   acc1: 72.7700 | acc5: 97.3100 | loss: 0.8852
2025-08-27 22:47:22,859 - INFO -   LR: 0.100000
2025-08-27 22:47:22,868 - INFO - 
Epoch: 22, lr = 0.1
2025-08-27 22:47:23,073 - INFO - Epoch: [22][0/391] Time 0.204 (0.204) Data 0.158 (0.158) Loss 0.4166 (0.4166) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:47:23,710 - INFO - Pruning info: sparsity=0.582
2025-08-27 22:47:23,711 - INFO -   Reactivation rate: 0.0053
2025-08-27 22:47:24,841 - INFO - Epoch: [22][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.4878 (0.4598) Acc@1 81.250 (84.352) Acc@5 99.219 (99.273)
2025-08-27 22:47:26,653 - INFO - Pruning info: sparsity=0.582
2025-08-27 22:47:26,666 - INFO -   Reactivation rate: 0.0034
2025-08-27 22:47:26,715 - INFO - Epoch: [22][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4835 (0.4617) Acc@1 81.250 (84.251) Acc@5 96.875 (99.273)
2025-08-27 22:47:28,563 - INFO - Epoch: [22][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.4054 (0.4590) Acc@1 84.375 (84.227) Acc@5 100.000 (99.284)
2025-08-27 22:47:29,590 - INFO - Pruning info: sparsity=0.582
2025-08-27 22:47:29,590 - INFO -   Reactivation rate: 0.0027
2025-08-27 22:47:30,342 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5468 (0.5468) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:47:31,211 - INFO - Epoch 22:
2025-08-27 22:47:31,211 - INFO -   Train: acc1: 84.1540 | acc5: 99.2880 | loss: 0.4619 | sparsity: 0.5824 | reactivation_rate: 0.0036
2025-08-27 22:47:31,211 - INFO -   Val:   acc1: 78.9100 | acc5: 98.4700 | loss: 0.6605
2025-08-27 22:47:31,211 - INFO -   LR: 0.100000
2025-08-27 22:47:31,256 - INFO - Checkpoint saved: epoch=22, metric=78.9100
2025-08-27 22:47:31,290 - INFO - 
Epoch: 23, lr = 0.1
2025-08-27 22:47:31,496 - INFO - Epoch: [23][0/391] Time 0.205 (0.205) Data 0.172 (0.172) Loss 0.4832 (0.4832) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:47:33,409 - INFO - Epoch: [23][100/391] Time 0.019 (0.021) Data 0.000 (0.004) Loss 0.4333 (0.4545) Acc@1 82.031 (84.406) Acc@5 100.000 (99.281)
2025-08-27 22:47:33,829 - INFO - Pruning info: sparsity=0.600
2025-08-27 22:47:33,830 - INFO -   Reactivation rate: 0.0040
2025-08-27 22:47:35,237 - INFO - Epoch: [23][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4633 (0.4645) Acc@1 85.156 (84.045) Acc@5 99.219 (99.262)
2025-08-27 22:47:36,748 - INFO - Pruning info: sparsity=0.600
2025-08-27 22:47:36,748 - INFO -   Reactivation rate: 0.0027
2025-08-27 22:47:36,994 - INFO - Epoch: [23][300/391] Time 0.033 (0.019) Data 0.020 (0.003) Loss 0.5549 (0.4603) Acc@1 80.469 (84.183) Acc@5 99.219 (99.307)
2025-08-27 22:47:38,721 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.6566 (0.6566) Acc@1 80.469 (80.469) Acc@5 98.438 (98.438)
2025-08-27 22:47:39,581 - INFO - Epoch 23:
2025-08-27 22:47:39,582 - INFO -   Train: acc1: 84.0960 | acc5: 99.2720 | loss: 0.4631 | sparsity: 0.6000 | reactivation_rate: 0.0034
2025-08-27 22:47:39,582 - INFO -   Val:   acc1: 76.7400 | acc5: 98.0600 | loss: 0.7222
2025-08-27 22:47:39,582 - INFO -   LR: 0.100000
2025-08-27 22:47:39,593 - INFO - 
Epoch: 24, lr = 0.1
2025-08-27 22:47:39,765 - INFO - Epoch: [24][0/391] Time 0.171 (0.171) Data 0.150 (0.150) Loss 0.4803 (0.4803) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:47:40,764 - INFO - Pruning info: sparsity=0.617
2025-08-27 22:47:40,764 - INFO -   Reactivation rate: 0.0045
2025-08-27 22:47:41,580 - INFO - Epoch: [24][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4520 (0.4750) Acc@1 83.594 (83.571) Acc@5 99.219 (99.412)
2025-08-27 22:47:43,374 - INFO - Epoch: [24][200/391] Time 0.028 (0.019) Data 0.003 (0.003) Loss 0.4810 (0.4648) Acc@1 86.719 (83.881) Acc@5 100.000 (99.359)
2025-08-27 22:47:43,622 - INFO - Pruning info: sparsity=0.617
2025-08-27 22:47:43,622 - INFO -   Reactivation rate: 0.0030
2025-08-27 22:47:45,278 - INFO - Epoch: [24][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4362 (0.4646) Acc@1 85.938 (83.882) Acc@5 99.219 (99.372)
2025-08-27 22:47:46,684 - INFO - Pruning info: sparsity=0.617
2025-08-27 22:47:46,684 - INFO -   Reactivation rate: 0.0024
2025-08-27 22:47:47,056 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6211 (0.6211) Acc@1 75.000 (75.000) Acc@5 99.219 (99.219)
2025-08-27 22:47:47,905 - INFO - Epoch 24:
2025-08-27 22:47:47,905 - INFO -   Train: acc1: 83.9380 | acc5: 99.3360 | loss: 0.4636 | sparsity: 0.6170 | reactivation_rate: 0.0032
2025-08-27 22:47:47,905 - INFO -   Val:   acc1: 78.6200 | acc5: 98.8100 | loss: 0.6455
2025-08-27 22:47:47,906 - INFO -   LR: 0.100000
2025-08-27 22:47:47,916 - INFO - 
Epoch: 25, lr = 0.1
2025-08-27 22:47:48,083 - INFO - Epoch: [25][0/391] Time 0.166 (0.166) Data 0.141 (0.141) Loss 0.4649 (0.4649) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:47:49,916 - INFO - Epoch: [25][100/391] Time 0.019 (0.020) Data 0.008 (0.003) Loss 0.4532 (0.4391) Acc@1 82.812 (85.056) Acc@5 99.219 (99.281)
2025-08-27 22:47:50,681 - INFO - Pruning info: sparsity=0.633
2025-08-27 22:47:50,681 - INFO -   Reactivation rate: 0.0033
2025-08-27 22:47:51,638 - INFO - Epoch: [25][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.5675 (0.4497) Acc@1 81.250 (84.600) Acc@5 97.656 (99.331)
2025-08-27 22:47:53,475 - INFO - Epoch: [25][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4002 (0.4528) Acc@1 87.500 (84.564) Acc@5 100.000 (99.297)
2025-08-27 22:47:53,526 - INFO - Pruning info: sparsity=0.633
2025-08-27 22:47:53,527 - INFO -   Reactivation rate: 0.0023
2025-08-27 22:47:55,237 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7937 (0.7937) Acc@1 72.656 (72.656) Acc@5 100.000 (100.000)
2025-08-27 22:47:56,074 - INFO - Epoch 25:
2025-08-27 22:47:56,074 - INFO -   Train: acc1: 84.4280 | acc5: 99.3120 | loss: 0.4547 | sparsity: 0.6333 | reactivation_rate: 0.0030
2025-08-27 22:47:56,074 - INFO -   Val:   acc1: 72.3300 | acc5: 98.0900 | loss: 0.8483
2025-08-27 22:47:56,074 - INFO -   LR: 0.100000
2025-08-27 22:47:56,085 - INFO - 
Epoch: 26, lr = 0.1
2025-08-27 22:47:56,271 - INFO - Epoch: [26][0/391] Time 0.184 (0.184) Data 0.154 (0.154) Loss 0.3858 (0.3858) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:47:57,571 - INFO - Pruning info: sparsity=0.649
2025-08-27 22:47:57,571 - INFO -   Reactivation rate: 0.0037
2025-08-27 22:47:58,078 - INFO - Epoch: [26][100/391] Time 0.016 (0.020) Data 0.000 (0.003) Loss 0.4794 (0.4473) Acc@1 83.594 (84.715) Acc@5 99.219 (99.335)
2025-08-27 22:47:59,860 - INFO - Epoch: [26][200/391] Time 0.017 (0.019) Data 0.001 (0.003) Loss 0.4466 (0.4418) Acc@1 81.250 (84.896) Acc@5 100.000 (99.331)
2025-08-27 22:48:00,482 - INFO - Pruning info: sparsity=0.649
2025-08-27 22:48:00,482 - INFO -   Reactivation rate: 0.0027
2025-08-27 22:48:01,676 - INFO - Epoch: [26][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.5366 (0.4527) Acc@1 83.594 (84.378) Acc@5 99.219 (99.317)
2025-08-27 22:48:03,452 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.7663 (0.7663) Acc@1 73.438 (73.438) Acc@5 96.094 (96.094)
2025-08-27 22:48:04,294 - INFO - Epoch 26:
2025-08-27 22:48:04,294 - INFO -   Train: acc1: 84.5980 | acc5: 99.3120 | loss: 0.4461 | sparsity: 0.6490 | reactivation_rate: 0.0028
2025-08-27 22:48:04,294 - INFO -   Val:   acc1: 74.5700 | acc5: 97.4800 | loss: 0.8819
2025-08-27 22:48:04,294 - INFO -   LR: 0.100000
2025-08-27 22:48:04,306 - INFO - 
Epoch: 27, lr = 0.1
2025-08-27 22:48:04,477 - INFO - Epoch: [27][0/391] Time 0.171 (0.171) Data 0.153 (0.153) Loss 0.4459 (0.4459) Acc@1 82.812 (82.812) Acc@5 97.656 (97.656)
2025-08-27 22:48:04,537 - INFO - Pruning info: sparsity=0.664
2025-08-27 22:48:04,537 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:48:06,366 - INFO - Epoch: [27][100/391] Time 0.027 (0.020) Data 0.000 (0.003) Loss 0.5620 (0.4345) Acc@1 79.688 (85.272) Acc@5 100.000 (99.257)
2025-08-27 22:48:07,569 - INFO - Pruning info: sparsity=0.664
2025-08-27 22:48:07,570 - INFO -   Reactivation rate: 0.0030
2025-08-27 22:48:08,226 - INFO - Epoch: [27][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4501 (0.4410) Acc@1 83.594 (84.954) Acc@5 97.656 (99.312)
2025-08-27 22:48:10,056 - INFO - Epoch: [27][300/391] Time 0.018 (0.019) Data 0.005 (0.003) Loss 0.5122 (0.4450) Acc@1 82.812 (84.829) Acc@5 97.656 (99.304)
2025-08-27 22:48:10,507 - INFO - Pruning info: sparsity=0.664
2025-08-27 22:48:10,507 - INFO -   Reactivation rate: 0.0021
2025-08-27 22:48:11,892 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.6105 (0.6105) Acc@1 79.688 (79.688) Acc@5 98.438 (98.438)
2025-08-27 22:48:12,721 - INFO - Epoch 27:
2025-08-27 22:48:12,722 - INFO -   Train: acc1: 84.7000 | acc5: 99.2900 | loss: 0.4480 | sparsity: 0.6641 | reactivation_rate: 0.0027
2025-08-27 22:48:12,722 - INFO -   Val:   acc1: 77.0500 | acc5: 98.9800 | loss: 0.6565
2025-08-27 22:48:12,722 - INFO -   LR: 0.100000
2025-08-27 22:48:12,733 - INFO - 
Epoch: 28, lr = 0.1
2025-08-27 22:48:12,911 - INFO - Epoch: [28][0/391] Time 0.177 (0.177) Data 0.145 (0.145) Loss 0.3450 (0.3450) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:48:14,760 - INFO - Pruning info: sparsity=0.679
2025-08-27 22:48:14,761 - INFO -   Reactivation rate: 0.0034
2025-08-27 22:48:14,942 - INFO - Epoch: [28][100/391] Time 0.016 (0.022) Data 0.000 (0.004) Loss 0.4149 (0.4404) Acc@1 86.719 (84.731) Acc@5 99.219 (99.350)
2025-08-27 22:48:16,730 - INFO - Epoch: [28][200/391] Time 0.024 (0.020) Data 0.005 (0.003) Loss 0.4405 (0.4421) Acc@1 85.156 (84.628) Acc@5 99.219 (99.359)
2025-08-27 22:48:17,643 - INFO - Pruning info: sparsity=0.679
2025-08-27 22:48:17,644 - INFO -   Reactivation rate: 0.0023
2025-08-27 22:48:18,544 - INFO - Epoch: [28][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4015 (0.4427) Acc@1 81.250 (84.533) Acc@5 99.219 (99.330)
2025-08-27 22:48:20,299 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5575 (0.5575) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 22:48:21,113 - INFO - Epoch 28:
2025-08-27 22:48:21,114 - INFO -   Train: acc1: 84.5660 | acc5: 99.3720 | loss: 0.4437 | sparsity: 0.6785 | reactivation_rate: 0.0026
2025-08-27 22:48:21,114 - INFO -   Val:   acc1: 79.0200 | acc5: 99.1800 | loss: 0.6226
2025-08-27 22:48:21,114 - INFO -   LR: 0.100000
2025-08-27 22:48:21,161 - INFO - Checkpoint saved: epoch=28, metric=79.0200
2025-08-27 22:48:21,192 - INFO - 
Epoch: 29, lr = 0.1
2025-08-27 22:48:21,383 - INFO - Epoch: [29][0/391] Time 0.190 (0.190) Data 0.167 (0.167) Loss 0.5406 (0.5406) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 22:48:21,752 - INFO - Pruning info: sparsity=0.692
2025-08-27 22:48:21,752 - INFO -   Reactivation rate: 0.0038
2025-08-27 22:48:23,197 - INFO - Epoch: [29][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.4464 (0.4356) Acc@1 86.719 (84.831) Acc@5 99.219 (99.381)
2025-08-27 22:48:24,641 - INFO - Pruning info: sparsity=0.692
2025-08-27 22:48:24,641 - INFO -   Reactivation rate: 0.0025
2025-08-27 22:48:24,973 - INFO - Epoch: [29][200/391] Time 0.020 (0.019) Data 0.007 (0.003) Loss 0.4585 (0.4391) Acc@1 83.594 (84.880) Acc@5 100.000 (99.398)
2025-08-27 22:48:26,730 - INFO - Epoch: [29][300/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.4167 (0.4381) Acc@1 84.375 (84.746) Acc@5 99.219 (99.406)
2025-08-27 22:48:27,443 - INFO - Pruning info: sparsity=0.692
2025-08-27 22:48:27,443 - INFO -   Reactivation rate: 0.0018
2025-08-27 22:48:28,453 - INFO - Test: [0/79] Time 0.106 (0.106) Loss 0.5067 (0.5067) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:48:29,317 - INFO - Epoch 29:
2025-08-27 22:48:29,317 - INFO -   Train: acc1: 84.7960 | acc5: 99.3940 | loss: 0.4378 | sparsity: 0.6924 | reactivation_rate: 0.0024
2025-08-27 22:48:29,317 - INFO -   Val:   acc1: 80.5400 | acc5: 98.4400 | loss: 0.6006
2025-08-27 22:48:29,317 - INFO -   LR: 0.100000
2025-08-27 22:48:29,364 - INFO - Checkpoint saved: epoch=29, metric=80.5400
2025-08-27 22:48:29,394 - INFO - 
Epoch: 30, lr = 0.1
2025-08-27 22:48:29,575 - INFO - Epoch: [30][0/391] Time 0.180 (0.180) Data 0.151 (0.151) Loss 0.2982 (0.2982) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:48:31,327 - INFO - Epoch: [30][100/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.4237 (0.4347) Acc@1 86.719 (85.326) Acc@5 99.219 (99.435)
2025-08-27 22:48:31,466 - INFO - Pruning info: sparsity=0.706
2025-08-27 22:48:31,466 - INFO -   Reactivation rate: 0.0029
2025-08-27 22:48:33,114 - INFO - Epoch: [30][200/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.3665 (0.4417) Acc@1 86.719 (84.919) Acc@5 99.219 (99.316)
2025-08-27 22:48:34,326 - INFO - Pruning info: sparsity=0.706
2025-08-27 22:48:34,327 - INFO -   Reactivation rate: 0.0020
2025-08-27 22:48:34,869 - INFO - Epoch: [30][300/391] Time 0.012 (0.018) Data 0.000 (0.002) Loss 0.5120 (0.4411) Acc@1 83.594 (84.967) Acc@5 98.438 (99.356)
2025-08-27 22:48:36,574 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.5393 (0.5393) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 22:48:37,444 - INFO - Epoch 30:
2025-08-27 22:48:37,444 - INFO -   Train: acc1: 85.0300 | acc5: 99.3580 | loss: 0.4404 | sparsity: 0.7056 | reactivation_rate: 0.0023
2025-08-27 22:48:37,444 - INFO -   Val:   acc1: 79.6000 | acc5: 98.8000 | loss: 0.6285
2025-08-27 22:48:37,444 - INFO -   LR: 0.100000
2025-08-27 22:48:37,488 - INFO - 
Epoch: 31, lr = 0.1
2025-08-27 22:48:37,622 - INFO - Epoch: [31][0/391] Time 0.133 (0.133) Data 0.108 (0.108) Loss 0.5382 (0.5382) Acc@1 84.375 (84.375) Acc@5 98.438 (98.438)
2025-08-27 22:48:38,407 - INFO - Pruning info: sparsity=0.718
2025-08-27 22:48:38,408 - INFO -   Reactivation rate: 0.0027
2025-08-27 22:48:39,489 - INFO - Epoch: [31][100/391] Time 0.033 (0.020) Data 0.021 (0.004) Loss 0.4151 (0.4320) Acc@1 86.719 (85.094) Acc@5 100.000 (99.459)
2025-08-27 22:48:41,184 - INFO - Pruning info: sparsity=0.718
2025-08-27 22:48:41,184 - INFO -   Reactivation rate: 0.0020
2025-08-27 22:48:41,220 - INFO - Epoch: [31][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.5078 (0.4344) Acc@1 81.250 (85.051) Acc@5 99.219 (99.464)
2025-08-27 22:48:42,962 - INFO - Epoch: [31][300/391] Time 0.021 (0.018) Data 0.000 (0.003) Loss 0.4570 (0.4372) Acc@1 85.156 (84.946) Acc@5 99.219 (99.432)
2025-08-27 22:48:43,972 - INFO - Pruning info: sparsity=0.718
2025-08-27 22:48:43,973 - INFO -   Reactivation rate: 0.0016
2025-08-27 22:48:44,652 - INFO - Test: [0/79] Time 0.117 (0.117) Loss 0.6576 (0.6576) Acc@1 78.125 (78.125) Acc@5 97.656 (97.656)
2025-08-27 22:48:45,623 - INFO - Epoch 31:
2025-08-27 22:48:45,623 - INFO -   Train: acc1: 85.0460 | acc5: 99.4140 | loss: 0.4348 | sparsity: 0.7183 | reactivation_rate: 0.0021
2025-08-27 22:48:45,623 - INFO -   Val:   acc1: 76.8800 | acc5: 98.3800 | loss: 0.7290
2025-08-27 22:48:45,623 - INFO -   LR: 0.100000
2025-08-27 22:48:45,633 - INFO - 
Epoch: 32, lr = 0.1
2025-08-27 22:48:45,813 - INFO - Epoch: [32][0/391] Time 0.179 (0.179) Data 0.144 (0.144) Loss 0.5243 (0.5243) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:48:47,646 - INFO - Epoch: [32][100/391] Time 0.021 (0.020) Data 0.000 (0.002) Loss 0.3058 (0.4277) Acc@1 89.844 (85.419) Acc@5 100.000 (99.381)
2025-08-27 22:48:48,158 - INFO - Pruning info: sparsity=0.730
2025-08-27 22:48:48,159 - INFO -   Reactivation rate: 0.0023
2025-08-27 22:48:49,525 - INFO - Epoch: [32][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.5178 (0.4320) Acc@1 83.594 (85.094) Acc@5 98.438 (99.405)
2025-08-27 22:48:51,178 - INFO - Pruning info: sparsity=0.730
2025-08-27 22:48:51,179 - INFO -   Reactivation rate: 0.0018
2025-08-27 22:48:51,366 - INFO - Epoch: [32][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.3714 (0.4336) Acc@1 87.500 (85.099) Acc@5 100.000 (99.413)
2025-08-27 22:48:53,038 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.7027 (0.7027) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 22:48:53,889 - INFO - Epoch 32:
2025-08-27 22:48:53,889 - INFO -   Train: acc1: 85.0980 | acc5: 99.3980 | loss: 0.4359 | sparsity: 0.7304 | reactivation_rate: 0.0020
2025-08-27 22:48:53,889 - INFO -   Val:   acc1: 77.6300 | acc5: 98.0800 | loss: 0.7282
2025-08-27 22:48:53,889 - INFO -   LR: 0.100000
2025-08-27 22:48:53,900 - INFO - 
Epoch: 33, lr = 0.1
2025-08-27 22:48:54,073 - INFO - Epoch: [33][0/391] Time 0.173 (0.173) Data 0.140 (0.140) Loss 0.4439 (0.4439) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:48:55,120 - INFO - Pruning info: sparsity=0.742
2025-08-27 22:48:55,120 - INFO -   Reactivation rate: 0.0025
2025-08-27 22:48:55,937 - INFO - Epoch: [33][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.4145 (0.4289) Acc@1 83.594 (85.288) Acc@5 100.000 (99.381)
2025-08-27 22:48:57,742 - INFO - Epoch: [33][200/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.5157 (0.4190) Acc@1 78.906 (85.642) Acc@5 99.219 (99.409)
2025-08-27 22:48:58,072 - INFO - Pruning info: sparsity=0.742
2025-08-27 22:48:58,072 - INFO -   Reactivation rate: 0.0018
2025-08-27 22:48:59,600 - INFO - Epoch: [33][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.3713 (0.4228) Acc@1 86.719 (85.512) Acc@5 99.219 (99.398)
2025-08-27 22:49:00,963 - INFO - Pruning info: sparsity=0.742
2025-08-27 22:49:00,964 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:49:01,377 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5103 (0.5103) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:49:02,217 - INFO - Epoch 33:
2025-08-27 22:49:02,217 - INFO -   Train: acc1: 85.3460 | acc5: 99.3780 | loss: 0.4280 | sparsity: 0.7419 | reactivation_rate: 0.0019
2025-08-27 22:49:02,217 - INFO -   Val:   acc1: 81.9000 | acc5: 98.9200 | loss: 0.5623
2025-08-27 22:49:02,217 - INFO -   LR: 0.100000
2025-08-27 22:49:02,263 - INFO - Checkpoint saved: epoch=33, metric=81.9000
2025-08-27 22:49:02,295 - INFO - 
Epoch: 34, lr = 0.1
2025-08-27 22:49:02,465 - INFO - Epoch: [34][0/391] Time 0.170 (0.170) Data 0.141 (0.141) Loss 0.4027 (0.4027) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:49:04,392 - INFO - Epoch: [34][100/391] Time 0.013 (0.021) Data 0.000 (0.002) Loss 0.4720 (0.4209) Acc@1 85.938 (85.574) Acc@5 99.219 (99.412)
2025-08-27 22:49:05,195 - INFO - Pruning info: sparsity=0.753
2025-08-27 22:49:05,195 - INFO -   Reactivation rate: 0.0019
2025-08-27 22:49:06,218 - INFO - Epoch: [34][200/391] Time 0.021 (0.020) Data 0.000 (0.003) Loss 0.3413 (0.4227) Acc@1 88.281 (85.413) Acc@5 100.000 (99.401)
2025-08-27 22:49:08,075 - INFO - Epoch: [34][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.4871 (0.4256) Acc@1 82.031 (85.395) Acc@5 98.438 (99.413)
2025-08-27 22:49:08,139 - INFO - Pruning info: sparsity=0.753
2025-08-27 22:49:08,139 - INFO -   Reactivation rate: 0.0016
2025-08-27 22:49:09,798 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6158 (0.6158) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 22:49:10,623 - INFO - Epoch 34:
2025-08-27 22:49:10,623 - INFO -   Train: acc1: 85.0980 | acc5: 99.3780 | loss: 0.4327 | sparsity: 0.7530 | reactivation_rate: 0.0018
2025-08-27 22:49:10,624 - INFO -   Val:   acc1: 77.7800 | acc5: 99.0400 | loss: 0.7081
2025-08-27 22:49:10,624 - INFO -   LR: 0.100000
2025-08-27 22:49:10,636 - INFO - 
Epoch: 35, lr = 0.1
2025-08-27 22:49:10,813 - INFO - Epoch: [35][0/391] Time 0.177 (0.177) Data 0.128 (0.128) Loss 0.3523 (0.3523) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-27 22:49:12,171 - INFO - Pruning info: sparsity=0.763
2025-08-27 22:49:12,171 - INFO -   Reactivation rate: 0.0022
2025-08-27 22:49:12,619 - INFO - Epoch: [35][100/391] Time 0.013 (0.020) Data 0.000 (0.004) Loss 0.5082 (0.4220) Acc@1 84.375 (85.566) Acc@5 98.438 (99.358)
2025-08-27 22:49:14,487 - INFO - Epoch: [35][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3770 (0.4222) Acc@1 86.719 (85.506) Acc@5 99.219 (99.409)
2025-08-27 22:49:15,103 - INFO - Pruning info: sparsity=0.763
2025-08-27 22:49:15,110 - INFO -   Reactivation rate: 0.0016
2025-08-27 22:49:16,283 - INFO - Epoch: [35][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3090 (0.4264) Acc@1 91.406 (85.268) Acc@5 100.000 (99.385)
2025-08-27 22:49:18,205 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.5455 (0.5455) Acc@1 82.031 (82.031) Acc@5 98.438 (98.438)
2025-08-27 22:49:19,028 - INFO - Epoch 35:
2025-08-27 22:49:19,028 - INFO -   Train: acc1: 85.0380 | acc5: 99.3800 | loss: 0.4296 | sparsity: 0.7635 | reactivation_rate: 0.0016
2025-08-27 22:49:19,028 - INFO -   Val:   acc1: 77.8600 | acc5: 98.3500 | loss: 0.6565
2025-08-27 22:49:19,028 - INFO -   LR: 0.100000
2025-08-27 22:49:19,040 - INFO - 
Epoch: 36, lr = 0.1
2025-08-27 22:49:19,243 - INFO - Epoch: [36][0/391] Time 0.203 (0.203) Data 0.181 (0.181) Loss 0.3647 (0.3647) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:49:19,291 - INFO - Pruning info: sparsity=0.773
2025-08-27 22:49:19,296 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:49:21,119 - INFO - Epoch: [36][100/391] Time 0.016 (0.021) Data 0.000 (0.007) Loss 0.4355 (0.4252) Acc@1 84.375 (85.102) Acc@5 100.000 (99.397)
2025-08-27 22:49:22,284 - INFO - Pruning info: sparsity=0.773
2025-08-27 22:49:22,284 - INFO -   Reactivation rate: 0.0017
2025-08-27 22:49:22,934 - INFO - Epoch: [36][200/391] Time 0.020 (0.019) Data 0.005 (0.005) Loss 0.3648 (0.4276) Acc@1 89.844 (85.160) Acc@5 100.000 (99.378)
2025-08-27 22:49:24,708 - INFO - Epoch: [36][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4923 (0.4295) Acc@1 80.469 (85.151) Acc@5 100.000 (99.387)
2025-08-27 22:49:25,168 - INFO - Pruning info: sparsity=0.773
2025-08-27 22:49:25,168 - INFO -   Reactivation rate: 0.0013
2025-08-27 22:49:26,494 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.5027 (0.5027) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:49:27,329 - INFO - Epoch 36:
2025-08-27 22:49:27,329 - INFO -   Train: acc1: 85.2240 | acc5: 99.3960 | loss: 0.4301 | sparsity: 0.7735 | reactivation_rate: 0.0016
2025-08-27 22:49:27,329 - INFO -   Val:   acc1: 82.6000 | acc5: 99.3800 | loss: 0.5052
2025-08-27 22:49:27,329 - INFO -   LR: 0.100000
2025-08-27 22:49:27,371 - INFO - Checkpoint saved: epoch=36, metric=82.6000
2025-08-27 22:49:27,403 - INFO - 
Epoch: 37, lr = 0.1
2025-08-27 22:49:27,575 - INFO - Epoch: [37][0/391] Time 0.171 (0.171) Data 0.151 (0.151) Loss 0.3944 (0.3944) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:49:29,277 - INFO - Pruning info: sparsity=0.783
2025-08-27 22:49:29,283 - INFO -   Reactivation rate: 0.0019
2025-08-27 22:49:29,419 - INFO - Epoch: [37][100/391] Time 0.013 (0.020) Data 0.001 (0.004) Loss 0.4453 (0.4172) Acc@1 86.719 (85.512) Acc@5 100.000 (99.366)
2025-08-27 22:49:31,314 - INFO - Epoch: [37][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3514 (0.4346) Acc@1 85.938 (84.853) Acc@5 100.000 (99.374)
2025-08-27 22:49:32,195 - INFO - Pruning info: sparsity=0.783
2025-08-27 22:49:32,195 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:49:33,067 - INFO - Epoch: [37][300/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.6273 (0.4309) Acc@1 78.906 (85.068) Acc@5 98.438 (99.395)
2025-08-27 22:49:34,843 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5105 (0.5105) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-27 22:49:35,666 - INFO - Epoch 37:
2025-08-27 22:49:35,666 - INFO -   Train: acc1: 85.1200 | acc5: 99.3780 | loss: 0.4309 | sparsity: 0.7829 | reactivation_rate: 0.0015
2025-08-27 22:49:35,666 - INFO -   Val:   acc1: 81.5300 | acc5: 99.1700 | loss: 0.5367
2025-08-27 22:49:35,666 - INFO -   LR: 0.100000
2025-08-27 22:49:35,684 - INFO - 
Epoch: 38, lr = 0.1
2025-08-27 22:49:35,862 - INFO - Epoch: [38][0/391] Time 0.177 (0.177) Data 0.157 (0.157) Loss 0.3274 (0.3274) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:49:36,208 - INFO - Pruning info: sparsity=0.792
2025-08-27 22:49:36,208 - INFO -   Reactivation rate: 0.0020
2025-08-27 22:49:37,639 - INFO - Epoch: [38][100/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4306 (0.4105) Acc@1 84.375 (85.938) Acc@5 100.000 (99.482)
2025-08-27 22:49:39,156 - INFO - Pruning info: sparsity=0.792
2025-08-27 22:49:39,156 - INFO -   Reactivation rate: 0.0015
2025-08-27 22:49:39,543 - INFO - Epoch: [38][200/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.4377 (0.4156) Acc@1 82.812 (85.724) Acc@5 100.000 (99.468)
2025-08-27 22:49:41,334 - INFO - Epoch: [38][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.5888 (0.4183) Acc@1 79.688 (85.605) Acc@5 98.438 (99.468)
2025-08-27 22:49:42,060 - INFO - Pruning info: sparsity=0.792
2025-08-27 22:49:42,061 - INFO -   Reactivation rate: 0.0011
2025-08-27 22:49:43,053 - INFO - Test: [0/79] Time 0.114 (0.114) Loss 0.4828 (0.4828) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:49:43,905 - INFO - Epoch 38:
2025-08-27 22:49:43,905 - INFO -   Train: acc1: 85.5660 | acc5: 99.4620 | loss: 0.4210 | sparsity: 0.7919 | reactivation_rate: 0.0014
2025-08-27 22:49:43,905 - INFO -   Val:   acc1: 80.2100 | acc5: 98.6800 | loss: 0.5885
2025-08-27 22:49:43,905 - INFO -   LR: 0.100000
2025-08-27 22:49:43,917 - INFO - 
Epoch: 39, lr = 0.1
2025-08-27 22:49:44,090 - INFO - Epoch: [39][0/391] Time 0.172 (0.172) Data 0.148 (0.148) Loss 0.3681 (0.3681) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:49:45,931 - INFO - Epoch: [39][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4298 (0.4182) Acc@1 86.719 (85.791) Acc@5 99.219 (99.373)
2025-08-27 22:49:46,100 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:49:46,100 - INFO -   Reactivation rate: 0.0014
2025-08-27 22:49:47,742 - INFO - Epoch: [39][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.5817 (0.4175) Acc@1 80.469 (85.588) Acc@5 98.438 (99.479)
2025-08-27 22:49:49,023 - INFO - Pruning info: sparsity=0.800
2025-08-27 22:49:49,023 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:49:49,575 - INFO - Epoch: [39][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.4616 (0.4209) Acc@1 85.156 (85.335) Acc@5 99.219 (99.483)
2025-08-27 22:49:51,284 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5539 (0.5539) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:49:52,093 - INFO - Epoch 39:
2025-08-27 22:49:52,093 - INFO -   Train: acc1: 85.2500 | acc5: 99.4560 | loss: 0.4250 | sparsity: 0.8005 | reactivation_rate: 0.0013
2025-08-27 22:49:52,093 - INFO -   Val:   acc1: 78.6300 | acc5: 98.8100 | loss: 0.6466
2025-08-27 22:49:52,093 - INFO -   LR: 0.100000
2025-08-27 22:49:52,104 - INFO - 
Epoch: 40, lr = 0.1
2025-08-27 22:49:52,273 - INFO - Epoch: [40][0/391] Time 0.169 (0.169) Data 0.145 (0.145) Loss 0.3741 (0.3741) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-27 22:49:52,942 - INFO - Pruning info: sparsity=0.809
2025-08-27 22:49:52,942 - INFO -   Reactivation rate: 0.0017
2025-08-27 22:49:54,009 - INFO - Epoch: [40][100/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.4063 (0.4306) Acc@1 82.812 (85.141) Acc@5 100.000 (99.343)
2025-08-27 22:49:55,765 - INFO - Pruning info: sparsity=0.809
2025-08-27 22:49:55,765 - INFO -   Reactivation rate: 0.0013
2025-08-27 22:49:55,778 - INFO - Epoch: [40][200/391] Time 0.035 (0.018) Data 0.017 (0.004) Loss 0.4252 (0.4178) Acc@1 86.719 (85.549) Acc@5 99.219 (99.409)
2025-08-27 22:49:57,524 - INFO - Epoch: [40][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4616 (0.4225) Acc@1 83.594 (85.504) Acc@5 100.000 (99.387)
2025-08-27 22:49:58,516 - INFO - Pruning info: sparsity=0.809
2025-08-27 22:49:58,516 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:49:59,242 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5598 (0.5598) Acc@1 76.562 (76.562) Acc@5 100.000 (100.000)
2025-08-27 22:50:00,071 - INFO - Epoch 40:
2025-08-27 22:50:00,071 - INFO -   Train: acc1: 85.4800 | acc5: 99.3820 | loss: 0.4247 | sparsity: 0.8085 | reactivation_rate: 0.0012
2025-08-27 22:50:00,071 - INFO -   Val:   acc1: 80.9400 | acc5: 99.2400 | loss: 0.5713
2025-08-27 22:50:00,071 - INFO -   LR: 0.100000
2025-08-27 22:50:00,125 - INFO - 
Epoch: 41, lr = 0.1
2025-08-27 22:50:00,298 - INFO - Epoch: [41][0/391] Time 0.172 (0.172) Data 0.145 (0.145) Loss 0.3603 (0.3603) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-27 22:50:02,085 - INFO - Epoch: [41][100/391] Time 0.030 (0.019) Data 0.012 (0.004) Loss 0.5554 (0.4061) Acc@1 82.812 (86.200) Acc@5 98.438 (99.366)
2025-08-27 22:50:02,528 - INFO - Pruning info: sparsity=0.816
2025-08-27 22:50:02,528 - INFO -   Reactivation rate: 0.0013
2025-08-27 22:50:03,779 - INFO - Epoch: [41][200/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.3380 (0.4148) Acc@1 89.062 (85.860) Acc@5 100.000 (99.401)
2025-08-27 22:50:05,336 - INFO - Pruning info: sparsity=0.816
2025-08-27 22:50:05,336 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:50:05,544 - INFO - Epoch: [41][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.3854 (0.4195) Acc@1 83.594 (85.683) Acc@5 100.000 (99.387)
2025-08-27 22:50:07,265 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.6958 (0.6958) Acc@1 75.781 (75.781) Acc@5 97.656 (97.656)
2025-08-27 22:50:08,111 - INFO - Epoch 41:
2025-08-27 22:50:08,111 - INFO -   Train: acc1: 85.4880 | acc5: 99.3680 | loss: 0.4234 | sparsity: 0.8162 | reactivation_rate: 0.0011
2025-08-27 22:50:08,111 - INFO -   Val:   acc1: 79.0800 | acc5: 98.9100 | loss: 0.6338
2025-08-27 22:50:08,111 - INFO -   LR: 0.100000
2025-08-27 22:50:08,123 - INFO - 
Epoch: 42, lr = 0.1
2025-08-27 22:50:08,289 - INFO - Epoch: [42][0/391] Time 0.165 (0.165) Data 0.140 (0.140) Loss 0.4442 (0.4442) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:50:09,346 - INFO - Pruning info: sparsity=0.823
2025-08-27 22:50:09,346 - INFO -   Reactivation rate: 0.0013
2025-08-27 22:50:10,105 - INFO - Epoch: [42][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.5387 (0.4046) Acc@1 78.906 (86.054) Acc@5 100.000 (99.536)
2025-08-27 22:50:11,882 - INFO - Epoch: [42][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.6379 (0.4113) Acc@1 80.469 (85.906) Acc@5 98.438 (99.541)
2025-08-27 22:50:12,156 - INFO - Pruning info: sparsity=0.823
2025-08-27 22:50:12,156 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:50:13,703 - INFO - Epoch: [42][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2893 (0.4182) Acc@1 89.844 (85.631) Acc@5 100.000 (99.538)
2025-08-27 22:50:15,092 - INFO - Pruning info: sparsity=0.823
2025-08-27 22:50:15,092 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:50:15,457 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5595 (0.5595) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:50:16,294 - INFO - Epoch 42:
2025-08-27 22:50:16,294 - INFO -   Train: acc1: 85.5400 | acc5: 99.4840 | loss: 0.4221 | sparsity: 0.8233 | reactivation_rate: 0.0010
2025-08-27 22:50:16,294 - INFO -   Val:   acc1: 79.0400 | acc5: 98.8800 | loss: 0.6339
2025-08-27 22:50:16,294 - INFO -   LR: 0.100000
2025-08-27 22:50:16,307 - INFO - 
Epoch: 43, lr = 0.1
2025-08-27 22:50:16,480 - INFO - Epoch: [43][0/391] Time 0.172 (0.172) Data 0.136 (0.136) Loss 0.2920 (0.2920) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:50:18,293 - INFO - Epoch: [43][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.3162 (0.4171) Acc@1 89.062 (85.427) Acc@5 100.000 (99.451)
2025-08-27 22:50:19,106 - INFO - Pruning info: sparsity=0.830
2025-08-27 22:50:19,107 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:50:20,064 - INFO - Epoch: [43][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3427 (0.4150) Acc@1 89.062 (85.502) Acc@5 100.000 (99.401)
2025-08-27 22:50:21,963 - INFO - Epoch: [43][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2989 (0.4179) Acc@1 90.625 (85.309) Acc@5 100.000 (99.398)
2025-08-27 22:50:22,089 - INFO - Pruning info: sparsity=0.830
2025-08-27 22:50:22,089 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:50:23,754 - INFO - Test: [0/79] Time 0.098 (0.098) Loss 0.4296 (0.4296) Acc@1 87.500 (87.500) Acc@5 98.438 (98.438)
2025-08-27 22:50:24,646 - INFO - Epoch 43:
2025-08-27 22:50:24,647 - INFO -   Train: acc1: 85.3480 | acc5: 99.4100 | loss: 0.4199 | sparsity: 0.8301 | reactivation_rate: 0.0010
2025-08-27 22:50:24,647 - INFO -   Val:   acc1: 83.1100 | acc5: 99.1400 | loss: 0.4955
2025-08-27 22:50:24,647 - INFO -   LR: 0.100000
2025-08-27 22:50:24,696 - INFO - Checkpoint saved: epoch=43, metric=83.1100
2025-08-27 22:50:24,727 - INFO - 
Epoch: 44, lr = 0.1
2025-08-27 22:50:24,916 - INFO - Epoch: [44][0/391] Time 0.188 (0.188) Data 0.166 (0.166) Loss 0.3449 (0.3449) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:50:26,224 - INFO - Pruning info: sparsity=0.836
2025-08-27 22:50:26,225 - INFO -   Reactivation rate: 0.0011
2025-08-27 22:50:26,708 - INFO - Epoch: [44][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.3546 (0.4256) Acc@1 89.844 (85.520) Acc@5 100.000 (99.412)
2025-08-27 22:50:28,491 - INFO - Epoch: [44][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4002 (0.4198) Acc@1 86.719 (85.654) Acc@5 100.000 (99.394)
2025-08-27 22:50:29,184 - INFO - Pruning info: sparsity=0.836
2025-08-27 22:50:29,184 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:50:30,315 - INFO - Epoch: [44][300/391] Time 0.019 (0.019) Data 0.002 (0.003) Loss 0.2628 (0.4175) Acc@1 92.188 (85.585) Acc@5 100.000 (99.416)
2025-08-27 22:50:32,083 - INFO - Test: [0/79] Time 0.112 (0.112) Loss 0.6944 (0.6944) Acc@1 80.469 (80.469) Acc@5 97.656 (97.656)
2025-08-27 22:50:32,942 - INFO - Epoch 44:
2025-08-27 22:50:32,942 - INFO -   Train: acc1: 85.5960 | acc5: 99.4000 | loss: 0.4178 | sparsity: 0.8364 | reactivation_rate: 0.0009
2025-08-27 22:50:32,942 - INFO -   Val:   acc1: 76.8100 | acc5: 98.6200 | loss: 0.7820
2025-08-27 22:50:32,943 - INFO -   LR: 0.100000
2025-08-27 22:50:32,955 - INFO - 
Epoch: 45, lr = 0.1
2025-08-27 22:50:33,128 - INFO - Epoch: [45][0/391] Time 0.173 (0.173) Data 0.156 (0.156) Loss 0.3855 (0.3855) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:50:33,208 - INFO - Pruning info: sparsity=0.842
2025-08-27 22:50:33,209 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:50:34,898 - INFO - Epoch: [45][100/391] Time 0.023 (0.019) Data 0.010 (0.005) Loss 0.6460 (0.4264) Acc@1 80.469 (85.357) Acc@5 97.656 (99.389)
2025-08-27 22:50:36,085 - INFO - Pruning info: sparsity=0.842
2025-08-27 22:50:36,085 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:50:36,762 - INFO - Epoch: [45][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3804 (0.4250) Acc@1 85.938 (85.285) Acc@5 100.000 (99.378)
2025-08-27 22:50:38,574 - INFO - Epoch: [45][300/391] Time 0.017 (0.019) Data 0.007 (0.004) Loss 0.3934 (0.4231) Acc@1 85.156 (85.364) Acc@5 100.000 (99.413)
2025-08-27 22:50:39,064 - INFO - Pruning info: sparsity=0.842
2025-08-27 22:50:39,064 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:50:40,355 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.5162 (0.5162) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:50:41,205 - INFO - Epoch 45:
2025-08-27 22:50:41,205 - INFO -   Train: acc1: 85.4380 | acc5: 99.4020 | loss: 0.4228 | sparsity: 0.8424 | reactivation_rate: 0.0009
2025-08-27 22:50:41,205 - INFO -   Val:   acc1: 78.8400 | acc5: 98.8500 | loss: 0.6243
2025-08-27 22:50:41,205 - INFO -   LR: 0.100000
2025-08-27 22:50:41,219 - INFO - 
Epoch: 46, lr = 0.1
2025-08-27 22:50:41,396 - INFO - Epoch: [46][0/391] Time 0.176 (0.176) Data 0.158 (0.158) Loss 0.3589 (0.3589) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:50:43,023 - INFO - Pruning info: sparsity=0.848
2025-08-27 22:50:43,023 - INFO -   Reactivation rate: 0.0010
2025-08-27 22:50:43,128 - INFO - Epoch: [46][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4435 (0.4003) Acc@1 83.594 (86.541) Acc@5 100.000 (99.489)
2025-08-27 22:50:44,998 - INFO - Epoch: [46][200/391] Time 0.023 (0.019) Data 0.009 (0.004) Loss 0.3957 (0.4166) Acc@1 88.281 (85.821) Acc@5 99.219 (99.382)
2025-08-27 22:50:45,945 - INFO - Pruning info: sparsity=0.848
2025-08-27 22:50:45,946 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:50:46,818 - INFO - Epoch: [46][300/391] Time 0.030 (0.019) Data 0.000 (0.004) Loss 0.3772 (0.4163) Acc@1 87.500 (85.668) Acc@5 100.000 (99.354)
2025-08-27 22:50:48,644 - INFO - Test: [0/79] Time 0.160 (0.160) Loss 0.6359 (0.6359) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 22:50:49,460 - INFO - Epoch 46:
2025-08-27 22:50:49,461 - INFO -   Train: acc1: 85.4760 | acc5: 99.3500 | loss: 0.4214 | sparsity: 0.8480 | reactivation_rate: 0.0008
2025-08-27 22:50:49,461 - INFO -   Val:   acc1: 78.8700 | acc5: 98.8400 | loss: 0.6689
2025-08-27 22:50:49,461 - INFO -   LR: 0.100000
2025-08-27 22:50:49,472 - INFO - 
Epoch: 47, lr = 0.1
2025-08-27 22:50:49,640 - INFO - Epoch: [47][0/391] Time 0.167 (0.167) Data 0.143 (0.143) Loss 0.4169 (0.4169) Acc@1 82.812 (82.812) Acc@5 100.000 (100.000)
2025-08-27 22:50:50,032 - INFO - Pruning info: sparsity=0.853
2025-08-27 22:50:50,033 - INFO -   Reactivation rate: 0.0012
2025-08-27 22:50:51,442 - INFO - Epoch: [47][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3832 (0.4089) Acc@1 85.156 (85.667) Acc@5 100.000 (99.505)
2025-08-27 22:50:52,901 - INFO - Pruning info: sparsity=0.853
2025-08-27 22:50:52,901 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:50:53,219 - INFO - Epoch: [47][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4842 (0.4169) Acc@1 83.594 (85.498) Acc@5 100.000 (99.456)
2025-08-27 22:50:55,039 - INFO - Epoch: [47][300/391] Time 0.034 (0.018) Data 0.013 (0.003) Loss 0.3512 (0.4164) Acc@1 85.156 (85.701) Acc@5 100.000 (99.408)
2025-08-27 22:50:55,801 - INFO - Pruning info: sparsity=0.853
2025-08-27 22:50:55,801 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:50:56,763 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3979 (0.3979) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-27 22:50:57,595 - INFO - Epoch 47:
2025-08-27 22:50:57,595 - INFO -   Train: acc1: 85.6180 | acc5: 99.3760 | loss: 0.4198 | sparsity: 0.8532 | reactivation_rate: 0.0008
2025-08-27 22:50:57,596 - INFO -   Val:   acc1: 81.6200 | acc5: 98.9900 | loss: 0.5477
2025-08-27 22:50:57,596 - INFO -   LR: 0.100000
2025-08-27 22:50:57,607 - INFO - 
Epoch: 48, lr = 0.1
2025-08-27 22:50:57,806 - INFO - Epoch: [48][0/391] Time 0.198 (0.198) Data 0.151 (0.151) Loss 0.4618 (0.4618) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:50:59,643 - INFO - Epoch: [48][100/391] Time 0.022 (0.020) Data 0.000 (0.006) Loss 0.3988 (0.4095) Acc@1 88.281 (85.945) Acc@5 100.000 (99.513)
2025-08-27 22:50:59,820 - INFO - Pruning info: sparsity=0.858
2025-08-27 22:50:59,820 - INFO -   Reactivation rate: 0.0008
2025-08-27 22:51:01,368 - INFO - Epoch: [48][200/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.3861 (0.4065) Acc@1 84.375 (86.027) Acc@5 98.438 (99.448)
2025-08-27 22:51:02,697 - INFO - Pruning info: sparsity=0.858
2025-08-27 22:51:02,697 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:51:03,232 - INFO - Epoch: [48][300/391] Time 0.017 (0.019) Data 0.002 (0.003) Loss 0.4451 (0.4138) Acc@1 83.594 (85.756) Acc@5 99.219 (99.442)
2025-08-27 22:51:05,033 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.7358 (0.7358) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 22:51:05,889 - INFO - Epoch 48:
2025-08-27 22:51:05,889 - INFO -   Train: acc1: 85.6460 | acc5: 99.4040 | loss: 0.4176 | sparsity: 0.8580 | reactivation_rate: 0.0007
2025-08-27 22:51:05,889 - INFO -   Val:   acc1: 76.1900 | acc5: 98.7500 | loss: 0.7757
2025-08-27 22:51:05,889 - INFO -   LR: 0.100000
2025-08-27 22:51:05,901 - INFO - 
Epoch: 49, lr = 0.1
2025-08-27 22:51:06,088 - INFO - Epoch: [49][0/391] Time 0.186 (0.186) Data 0.165 (0.165) Loss 0.5052 (0.5052) Acc@1 82.031 (82.031) Acc@5 100.000 (100.000)
2025-08-27 22:51:06,816 - INFO - Pruning info: sparsity=0.863
2025-08-27 22:51:06,816 - INFO -   Reactivation rate: 0.0009
2025-08-27 22:51:07,866 - INFO - Epoch: [49][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4235 (0.4121) Acc@1 86.719 (85.528) Acc@5 99.219 (99.528)
2025-08-27 22:51:09,706 - INFO - Epoch: [49][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3112 (0.4140) Acc@1 90.625 (85.592) Acc@5 100.000 (99.506)
2025-08-27 22:51:09,716 - INFO - Pruning info: sparsity=0.863
2025-08-27 22:51:09,716 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:51:11,481 - INFO - Epoch: [49][300/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4377 (0.4271) Acc@1 82.812 (85.102) Acc@5 100.000 (99.429)
2025-08-27 22:51:12,618 - INFO - Pruning info: sparsity=0.863
2025-08-27 22:51:12,618 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:51:13,291 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5286 (0.5286) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:51:14,114 - INFO - Epoch 49:
2025-08-27 22:51:14,114 - INFO -   Train: acc1: 85.2160 | acc5: 99.4100 | loss: 0.4252 | sparsity: 0.8625 | reactivation_rate: 0.0007
2025-08-27 22:51:14,114 - INFO -   Val:   acc1: 80.7500 | acc5: 99.1500 | loss: 0.5861
2025-08-27 22:51:14,114 - INFO -   LR: 0.100000
2025-08-27 22:51:14,125 - INFO - 
Epoch: 50, lr = 0.1
2025-08-27 22:51:14,286 - INFO - Epoch: [50][0/391] Time 0.160 (0.160) Data 0.143 (0.143) Loss 0.2357 (0.2357) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:51:16,107 - INFO - Epoch: [50][100/391] Time 0.021 (0.020) Data 0.004 (0.004) Loss 0.4424 (0.4185) Acc@1 83.594 (85.620) Acc@5 100.000 (99.459)
2025-08-27 22:51:16,642 - INFO - Pruning info: sparsity=0.867
2025-08-27 22:51:16,647 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:51:17,852 - INFO - Epoch: [50][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2827 (0.4186) Acc@1 90.625 (85.537) Acc@5 100.000 (99.456)
2025-08-27 22:51:19,497 - INFO - Pruning info: sparsity=0.867
2025-08-27 22:51:19,497 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:51:19,662 - INFO - Epoch: [50][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3143 (0.4186) Acc@1 89.844 (85.582) Acc@5 100.000 (99.442)
2025-08-27 22:51:21,505 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5497 (0.5497) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:51:22,344 - INFO - Epoch 50:
2025-08-27 22:51:22,344 - INFO -   Train: acc1: 85.5560 | acc5: 99.4200 | loss: 0.4213 | sparsity: 0.8667 | reactivation_rate: 0.0006
2025-08-27 22:51:22,344 - INFO -   Val:   acc1: 79.6000 | acc5: 98.8600 | loss: 0.6225
2025-08-27 22:51:22,344 - INFO -   LR: 0.100000
2025-08-27 22:51:22,388 - INFO - 
Epoch: 51, lr = 0.1
2025-08-27 22:51:22,559 - INFO - Epoch: [51][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 0.5782 (0.5782) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:51:23,605 - INFO - Pruning info: sparsity=0.871
2025-08-27 22:51:23,606 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:51:24,349 - INFO - Epoch: [51][100/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.3653 (0.4087) Acc@1 86.719 (85.698) Acc@5 98.438 (99.443)
2025-08-27 22:51:26,157 - INFO - Epoch: [51][200/391] Time 0.014 (0.019) Data 0.000 (0.005) Loss 0.4162 (0.4162) Acc@1 86.719 (85.580) Acc@5 100.000 (99.448)
2025-08-27 22:51:26,516 - INFO - Pruning info: sparsity=0.871
2025-08-27 22:51:26,516 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:51:27,979 - INFO - Epoch: [51][300/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.3548 (0.4192) Acc@1 86.719 (85.452) Acc@5 99.219 (99.437)
2025-08-27 22:51:29,396 - INFO - Pruning info: sparsity=0.871
2025-08-27 22:51:29,396 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:51:29,745 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.4448 (0.4448) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:51:30,547 - INFO - Epoch 51:
2025-08-27 22:51:30,547 - INFO -   Train: acc1: 85.3680 | acc5: 99.4140 | loss: 0.4228 | sparsity: 0.8705 | reactivation_rate: 0.0006
2025-08-27 22:51:30,547 - INFO -   Val:   acc1: 81.0700 | acc5: 99.0800 | loss: 0.5761
2025-08-27 22:51:30,547 - INFO -   LR: 0.100000
2025-08-27 22:51:30,561 - INFO - 
Epoch: 52, lr = 0.1
2025-08-27 22:51:30,758 - INFO - Epoch: [52][0/391] Time 0.196 (0.196) Data 0.169 (0.169) Loss 0.4272 (0.4272) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:51:32,641 - INFO - Epoch: [52][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.3096 (0.4119) Acc@1 89.844 (85.930) Acc@5 100.000 (99.459)
2025-08-27 22:51:33,485 - INFO - Pruning info: sparsity=0.874
2025-08-27 22:51:33,485 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:51:34,406 - INFO - Epoch: [52][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4450 (0.4283) Acc@1 84.375 (85.121) Acc@5 99.219 (99.339)
2025-08-27 22:51:36,210 - INFO - Epoch: [52][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4377 (0.4263) Acc@1 83.594 (85.239) Acc@5 99.219 (99.398)
2025-08-27 22:51:36,335 - INFO - Pruning info: sparsity=0.874
2025-08-27 22:51:36,335 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:51:37,963 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.5550 (0.5550) Acc@1 82.812 (82.812) Acc@5 98.438 (98.438)
2025-08-27 22:51:38,841 - INFO - Epoch 52:
2025-08-27 22:51:38,841 - INFO -   Train: acc1: 85.1440 | acc5: 99.3880 | loss: 0.4291 | sparsity: 0.8740 | reactivation_rate: 0.0006
2025-08-27 22:51:38,841 - INFO -   Val:   acc1: 78.0900 | acc5: 98.8400 | loss: 0.6330
2025-08-27 22:51:38,841 - INFO -   LR: 0.100000
2025-08-27 22:51:38,852 - INFO - 
Epoch: 53, lr = 0.1
2025-08-27 22:51:39,023 - INFO - Epoch: [53][0/391] Time 0.170 (0.170) Data 0.137 (0.137) Loss 0.4424 (0.4424) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:51:40,518 - INFO - Pruning info: sparsity=0.877
2025-08-27 22:51:40,521 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:51:40,960 - INFO - Epoch: [53][100/391] Time 0.020 (0.021) Data 0.000 (0.004) Loss 0.4339 (0.4285) Acc@1 87.500 (85.381) Acc@5 98.438 (99.404)
2025-08-27 22:51:42,750 - INFO - Epoch: [53][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.5068 (0.4235) Acc@1 85.156 (85.401) Acc@5 100.000 (99.452)
2025-08-27 22:51:43,392 - INFO - Pruning info: sparsity=0.877
2025-08-27 22:51:43,392 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:51:44,571 - INFO - Epoch: [53][300/391] Time 0.035 (0.019) Data 0.024 (0.004) Loss 0.3630 (0.4239) Acc@1 87.500 (85.403) Acc@5 99.219 (99.465)
2025-08-27 22:51:46,372 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.7610 (0.7610) Acc@1 78.906 (78.906) Acc@5 97.656 (97.656)
2025-08-27 22:51:47,220 - INFO - Epoch 53:
2025-08-27 22:51:47,220 - INFO -   Train: acc1: 85.4980 | acc5: 99.4660 | loss: 0.4225 | sparsity: 0.8773 | reactivation_rate: 0.0005
2025-08-27 22:51:47,220 - INFO -   Val:   acc1: 76.9900 | acc5: 98.9200 | loss: 0.7715
2025-08-27 22:51:47,220 - INFO -   LR: 0.100000
2025-08-27 22:51:47,231 - INFO - 
Epoch: 54, lr = 0.1
2025-08-27 22:51:47,407 - INFO - Epoch: [54][0/391] Time 0.175 (0.175) Data 0.156 (0.156) Loss 0.3904 (0.3904) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:51:47,474 - INFO - Pruning info: sparsity=0.880
2025-08-27 22:51:47,475 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:51:49,220 - INFO - Epoch: [54][100/391] Time 0.038 (0.020) Data 0.008 (0.004) Loss 0.3166 (0.4248) Acc@1 89.844 (85.667) Acc@5 99.219 (99.459)
2025-08-27 22:51:50,401 - INFO - Pruning info: sparsity=0.880
2025-08-27 22:51:50,407 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:51:51,033 - INFO - Epoch: [54][200/391] Time 0.017 (0.019) Data 0.005 (0.003) Loss 0.5186 (0.4222) Acc@1 80.469 (85.417) Acc@5 99.219 (99.471)
2025-08-27 22:51:52,828 - INFO - Epoch: [54][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3989 (0.4179) Acc@1 86.719 (85.509) Acc@5 100.000 (99.496)
2025-08-27 22:51:53,283 - INFO - Pruning info: sparsity=0.880
2025-08-27 22:51:53,283 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:51:54,601 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5265 (0.5265) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:51:55,418 - INFO - Epoch 54:
2025-08-27 22:51:55,418 - INFO -   Train: acc1: 85.3680 | acc5: 99.4660 | loss: 0.4214 | sparsity: 0.8802 | reactivation_rate: 0.0005
2025-08-27 22:51:55,418 - INFO -   Val:   acc1: 80.7600 | acc5: 99.0400 | loss: 0.6104
2025-08-27 22:51:55,418 - INFO -   LR: 0.100000
2025-08-27 22:51:55,428 - INFO - 
Epoch: 55, lr = 0.1
2025-08-27 22:51:55,606 - INFO - Epoch: [55][0/391] Time 0.177 (0.177) Data 0.159 (0.159) Loss 0.3046 (0.3046) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:51:57,329 - INFO - Pruning info: sparsity=0.883
2025-08-27 22:51:57,330 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:51:57,409 - INFO - Epoch: [55][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.5814 (0.4184) Acc@1 82.031 (85.404) Acc@5 99.219 (99.451)
2025-08-27 22:51:59,262 - INFO - Epoch: [55][200/391] Time 0.031 (0.019) Data 0.000 (0.004) Loss 0.5116 (0.4218) Acc@1 82.031 (85.327) Acc@5 100.000 (99.479)
2025-08-27 22:52:00,232 - INFO - Pruning info: sparsity=0.883
2025-08-27 22:52:00,232 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:52:01,064 - INFO - Epoch: [55][300/391] Time 0.046 (0.019) Data 0.014 (0.004) Loss 0.3186 (0.4240) Acc@1 89.062 (85.255) Acc@5 99.219 (99.473)
2025-08-27 22:52:02,863 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5136 (0.5136) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:52:03,705 - INFO - Epoch 55:
2025-08-27 22:52:03,705 - INFO -   Train: acc1: 85.1400 | acc5: 99.4440 | loss: 0.4276 | sparsity: 0.8829 | reactivation_rate: 0.0005
2025-08-27 22:52:03,705 - INFO -   Val:   acc1: 80.0900 | acc5: 99.2800 | loss: 0.5759
2025-08-27 22:52:03,705 - INFO -   LR: 0.100000
2025-08-27 22:52:03,720 - INFO - 
Epoch: 56, lr = 0.1
2025-08-27 22:52:03,893 - INFO - Epoch: [56][0/391] Time 0.173 (0.173) Data 0.150 (0.150) Loss 0.3732 (0.3732) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:52:04,377 - INFO - Pruning info: sparsity=0.885
2025-08-27 22:52:04,377 - INFO -   Reactivation rate: 0.0007
2025-08-27 22:52:05,832 - INFO - Epoch: [56][100/391] Time 0.019 (0.021) Data 0.000 (0.003) Loss 0.5036 (0.4025) Acc@1 80.469 (86.146) Acc@5 99.219 (99.489)
2025-08-27 22:52:07,319 - INFO - Pruning info: sparsity=0.885
2025-08-27 22:52:07,319 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:52:07,640 - INFO - Epoch: [56][200/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.4495 (0.4171) Acc@1 84.375 (85.654) Acc@5 99.219 (99.495)
2025-08-27 22:52:09,444 - INFO - Epoch: [56][300/391] Time 0.011 (0.019) Data 0.000 (0.002) Loss 0.4063 (0.4210) Acc@1 83.594 (85.540) Acc@5 100.000 (99.486)
2025-08-27 22:52:10,257 - INFO - Pruning info: sparsity=0.885
2025-08-27 22:52:10,262 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:11,261 - INFO - Test: [0/79] Time 0.150 (0.150) Loss 0.5676 (0.5676) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:52:12,102 - INFO - Epoch 56:
2025-08-27 22:52:12,102 - INFO -   Train: acc1: 85.4300 | acc5: 99.4500 | loss: 0.4233 | sparsity: 0.8854 | reactivation_rate: 0.0004
2025-08-27 22:52:12,102 - INFO -   Val:   acc1: 78.9500 | acc5: 98.3000 | loss: 0.6517
2025-08-27 22:52:12,102 - INFO -   LR: 0.100000
2025-08-27 22:52:12,114 - INFO - 
Epoch: 57, lr = 0.1
2025-08-27 22:52:12,291 - INFO - Epoch: [57][0/391] Time 0.176 (0.176) Data 0.154 (0.154) Loss 0.3221 (0.3221) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:52:14,176 - INFO - Epoch: [57][100/391] Time 0.022 (0.020) Data 0.005 (0.005) Loss 0.4095 (0.4170) Acc@1 85.156 (85.783) Acc@5 99.219 (99.420)
2025-08-27 22:52:14,366 - INFO - Pruning info: sparsity=0.888
2025-08-27 22:52:14,367 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:52:16,005 - INFO - Epoch: [57][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4264 (0.4231) Acc@1 85.156 (85.459) Acc@5 100.000 (99.440)
2025-08-27 22:52:17,292 - INFO - Pruning info: sparsity=0.888
2025-08-27 22:52:17,292 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:17,787 - INFO - Epoch: [57][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4095 (0.4207) Acc@1 82.812 (85.488) Acc@5 99.219 (99.455)
2025-08-27 22:52:19,673 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.4382 (0.4382) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:52:20,510 - INFO - Epoch 57:
2025-08-27 22:52:20,510 - INFO -   Train: acc1: 85.4680 | acc5: 99.4120 | loss: 0.4233 | sparsity: 0.8876 | reactivation_rate: 0.0004
2025-08-27 22:52:20,510 - INFO -   Val:   acc1: 80.6600 | acc5: 98.9400 | loss: 0.5950
2025-08-27 22:52:20,510 - INFO -   LR: 0.100000
2025-08-27 22:52:20,524 - INFO - 
Epoch: 58, lr = 0.1
2025-08-27 22:52:20,673 - INFO - Epoch: [58][0/391] Time 0.148 (0.148) Data 0.122 (0.122) Loss 0.4722 (0.4722) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:52:21,582 - INFO - Pruning info: sparsity=0.890
2025-08-27 22:52:21,582 - INFO -   Reactivation rate: 0.0006
2025-08-27 22:52:22,781 - INFO - Epoch: [58][100/391] Time 0.014 (0.022) Data 0.000 (0.005) Loss 0.3513 (0.4185) Acc@1 88.281 (85.690) Acc@5 99.219 (99.327)
2025-08-27 22:52:24,574 - INFO - Epoch: [58][200/391] Time 0.027 (0.020) Data 0.015 (0.003) Loss 0.4061 (0.4267) Acc@1 86.719 (85.440) Acc@5 100.000 (99.370)
2025-08-27 22:52:24,599 - INFO - Pruning info: sparsity=0.890
2025-08-27 22:52:24,600 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:52:26,385 - INFO - Epoch: [58][300/391] Time 0.035 (0.019) Data 0.022 (0.003) Loss 0.3918 (0.4247) Acc@1 86.719 (85.413) Acc@5 99.219 (99.369)
2025-08-27 22:52:27,476 - INFO - Pruning info: sparsity=0.890
2025-08-27 22:52:27,477 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:28,148 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.5723 (0.5723) Acc@1 85.156 (85.156) Acc@5 99.219 (99.219)
2025-08-27 22:52:28,982 - INFO - Epoch 58:
2025-08-27 22:52:28,982 - INFO -   Train: acc1: 85.5140 | acc5: 99.4200 | loss: 0.4224 | sparsity: 0.8895 | reactivation_rate: 0.0004
2025-08-27 22:52:28,982 - INFO -   Val:   acc1: 81.3600 | acc5: 99.1200 | loss: 0.5519
2025-08-27 22:52:28,982 - INFO -   LR: 0.100000
2025-08-27 22:52:28,995 - INFO - 
Epoch: 59, lr = 0.1
2025-08-27 22:52:29,183 - INFO - Epoch: [59][0/391] Time 0.187 (0.187) Data 0.155 (0.155) Loss 0.5310 (0.5310) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 22:52:31,000 - INFO - Epoch: [59][100/391] Time 0.035 (0.020) Data 0.004 (0.004) Loss 0.4785 (0.3963) Acc@1 83.594 (86.077) Acc@5 98.438 (99.459)
2025-08-27 22:52:31,562 - INFO - Pruning info: sparsity=0.891
2025-08-27 22:52:31,562 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:52:32,886 - INFO - Epoch: [59][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5496 (0.4168) Acc@1 78.125 (85.347) Acc@5 96.875 (99.440)
2025-08-27 22:52:34,668 - INFO - Pruning info: sparsity=0.891
2025-08-27 22:52:34,669 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:34,818 - INFO - Epoch: [59][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.4105 (0.4245) Acc@1 87.500 (85.221) Acc@5 100.000 (99.434)
2025-08-27 22:52:36,615 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.7074 (0.7074) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 22:52:37,435 - INFO - Epoch 59:
2025-08-27 22:52:37,435 - INFO -   Train: acc1: 85.1740 | acc5: 99.4240 | loss: 0.4261 | sparsity: 0.8913 | reactivation_rate: 0.0004
2025-08-27 22:52:37,435 - INFO -   Val:   acc1: 76.2300 | acc5: 98.0600 | loss: 0.7666
2025-08-27 22:52:37,435 - INFO -   LR: 0.100000
2025-08-27 22:52:37,449 - INFO - 
Epoch: 60, lr = 0.1
2025-08-27 22:52:37,637 - INFO - Epoch: [60][0/391] Time 0.187 (0.187) Data 0.162 (0.162) Loss 0.4565 (0.4565) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:52:38,799 - INFO - Pruning info: sparsity=0.893
2025-08-27 22:52:38,799 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:52:39,549 - INFO - Epoch: [60][100/391] Time 0.020 (0.021) Data 0.000 (0.003) Loss 0.4427 (0.4112) Acc@1 82.812 (85.388) Acc@5 100.000 (99.389)
2025-08-27 22:52:41,308 - INFO - Epoch: [60][200/391] Time 0.016 (0.019) Data 0.005 (0.002) Loss 0.3849 (0.4226) Acc@1 85.156 (85.145) Acc@5 100.000 (99.359)
2025-08-27 22:52:41,693 - INFO - Pruning info: sparsity=0.893
2025-08-27 22:52:41,694 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:52:43,143 - INFO - Epoch: [60][300/391] Time 0.017 (0.019) Data 0.000 (0.002) Loss 0.4150 (0.4244) Acc@1 82.031 (85.169) Acc@5 100.000 (99.382)
2025-08-27 22:52:44,581 - INFO - Pruning info: sparsity=0.893
2025-08-27 22:52:44,582 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:44,920 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6171 (0.6171) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:52:45,753 - INFO - Epoch 60:
2025-08-27 22:52:45,753 - INFO -   Train: acc1: 85.2820 | acc5: 99.4060 | loss: 0.4218 | sparsity: 0.8928 | reactivation_rate: 0.0004
2025-08-27 22:52:45,753 - INFO -   Val:   acc1: 78.6400 | acc5: 98.0900 | loss: 0.6767
2025-08-27 22:52:45,753 - INFO -   LR: 0.100000
2025-08-27 22:52:45,800 - INFO - 
Epoch: 61, lr = 0.1
2025-08-27 22:52:45,974 - INFO - Epoch: [61][0/391] Time 0.173 (0.173) Data 0.152 (0.152) Loss 0.5038 (0.5038) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:52:47,810 - INFO - Epoch: [61][100/391] Time 0.024 (0.020) Data 0.000 (0.004) Loss 0.4818 (0.3958) Acc@1 84.375 (86.208) Acc@5 99.219 (99.544)
2025-08-27 22:52:48,698 - INFO - Pruning info: sparsity=0.894
2025-08-27 22:52:48,698 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:49,653 - INFO - Epoch: [61][200/391] Time 0.025 (0.019) Data 0.010 (0.003) Loss 0.3864 (0.4178) Acc@1 86.719 (85.479) Acc@5 100.000 (99.433)
2025-08-27 22:52:51,478 - INFO - Epoch: [61][300/391] Time 0.032 (0.019) Data 0.018 (0.003) Loss 0.4714 (0.4203) Acc@1 84.375 (85.491) Acc@5 100.000 (99.432)
2025-08-27 22:52:51,654 - INFO - Pruning info: sparsity=0.894
2025-08-27 22:52:51,654 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:52:53,302 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.6647 (0.6647) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:52:54,113 - INFO - Epoch 61:
2025-08-27 22:52:54,113 - INFO -   Train: acc1: 85.2880 | acc5: 99.4160 | loss: 0.4268 | sparsity: 0.8941 | reactivation_rate: 0.0003
2025-08-27 22:52:54,113 - INFO -   Val:   acc1: 79.6200 | acc5: 98.9300 | loss: 0.6456
2025-08-27 22:52:54,113 - INFO -   LR: 0.100000
2025-08-27 22:52:54,126 - INFO - 
Epoch: 62, lr = 0.1
2025-08-27 22:52:54,304 - INFO - Epoch: [62][0/391] Time 0.178 (0.178) Data 0.144 (0.144) Loss 0.3620 (0.3620) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:52:55,721 - INFO - Pruning info: sparsity=0.895
2025-08-27 22:52:55,721 - INFO -   Reactivation rate: 0.0005
2025-08-27 22:52:56,112 - INFO - Epoch: [62][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.3904 (0.3976) Acc@1 85.938 (86.030) Acc@5 100.000 (99.489)
2025-08-27 22:52:57,973 - INFO - Epoch: [62][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4042 (0.4051) Acc@1 83.594 (85.759) Acc@5 100.000 (99.518)
2025-08-27 22:52:58,648 - INFO - Pruning info: sparsity=0.895
2025-08-27 22:52:58,648 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:52:59,795 - INFO - Epoch: [62][300/391] Time 0.031 (0.019) Data 0.003 (0.003) Loss 0.4457 (0.4113) Acc@1 82.031 (85.774) Acc@5 99.219 (99.447)
2025-08-27 22:53:01,612 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.8255 (0.8255) Acc@1 76.562 (76.562) Acc@5 98.438 (98.438)
2025-08-27 22:53:02,433 - INFO - Epoch 62:
2025-08-27 22:53:02,433 - INFO -   Train: acc1: 85.5560 | acc5: 99.4140 | loss: 0.4178 | sparsity: 0.8953 | reactivation_rate: 0.0003
2025-08-27 22:53:02,433 - INFO -   Val:   acc1: 76.3000 | acc5: 98.0400 | loss: 0.7388
2025-08-27 22:53:02,433 - INFO -   LR: 0.100000
2025-08-27 22:53:02,446 - INFO - 
Epoch: 63, lr = 0.1
2025-08-27 22:53:02,625 - INFO - Epoch: [63][0/391] Time 0.178 (0.178) Data 0.147 (0.147) Loss 0.3610 (0.3610) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:53:02,743 - INFO - Pruning info: sparsity=0.896
2025-08-27 22:53:02,744 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:53:04,569 - INFO - Epoch: [63][100/391] Time 0.011 (0.021) Data 0.000 (0.005) Loss 0.4258 (0.4023) Acc@1 84.375 (85.938) Acc@5 99.219 (99.459)
2025-08-27 22:53:05,849 - INFO - Pruning info: sparsity=0.896
2025-08-27 22:53:05,849 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:53:06,471 - INFO - Epoch: [63][200/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.4985 (0.4173) Acc@1 83.594 (85.619) Acc@5 100.000 (99.479)
2025-08-27 22:53:08,313 - INFO - Epoch: [63][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3131 (0.4183) Acc@1 89.062 (85.597) Acc@5 100.000 (99.476)
2025-08-27 22:53:08,835 - INFO - Pruning info: sparsity=0.896
2025-08-27 22:53:08,836 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:10,123 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.6919 (0.6919) Acc@1 79.688 (79.688) Acc@5 97.656 (97.656)
2025-08-27 22:53:10,954 - INFO - Epoch 63:
2025-08-27 22:53:10,954 - INFO -   Train: acc1: 85.4520 | acc5: 99.4680 | loss: 0.4218 | sparsity: 0.8963 | reactivation_rate: 0.0003
2025-08-27 22:53:10,954 - INFO -   Val:   acc1: 76.7800 | acc5: 98.2100 | loss: 0.7095
2025-08-27 22:53:10,954 - INFO -   LR: 0.100000
2025-08-27 22:53:10,966 - INFO - 
Epoch: 64, lr = 0.1
2025-08-27 22:53:11,164 - INFO - Epoch: [64][0/391] Time 0.196 (0.196) Data 0.168 (0.168) Loss 0.3400 (0.3400) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:53:13,077 - INFO - Pruning info: sparsity=0.897
2025-08-27 22:53:13,077 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:53:13,171 - INFO - Epoch: [64][100/391] Time 0.012 (0.022) Data 0.000 (0.008) Loss 0.3979 (0.4169) Acc@1 85.156 (85.698) Acc@5 100.000 (99.412)
2025-08-27 22:53:15,042 - INFO - Epoch: [64][200/391] Time 0.019 (0.020) Data 0.000 (0.006) Loss 0.4154 (0.4240) Acc@1 84.375 (85.207) Acc@5 100.000 (99.409)
2025-08-27 22:53:16,010 - INFO - Pruning info: sparsity=0.897
2025-08-27 22:53:16,010 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:16,820 - INFO - Epoch: [64][300/391] Time 0.023 (0.019) Data 0.011 (0.005) Loss 0.5618 (0.4271) Acc@1 78.906 (85.216) Acc@5 99.219 (99.411)
2025-08-27 22:53:18,709 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5812 (0.5812) Acc@1 77.344 (77.344) Acc@5 100.000 (100.000)
2025-08-27 22:53:19,531 - INFO - Epoch 64:
2025-08-27 22:53:19,532 - INFO -   Train: acc1: 85.2180 | acc5: 99.3860 | loss: 0.4281 | sparsity: 0.8972 | reactivation_rate: 0.0003
2025-08-27 22:53:19,532 - INFO -   Val:   acc1: 82.0500 | acc5: 98.9300 | loss: 0.5696
2025-08-27 22:53:19,532 - INFO -   LR: 0.100000
2025-08-27 22:53:19,545 - INFO - 
Epoch: 65, lr = 0.1
2025-08-27 22:53:19,721 - INFO - Epoch: [65][0/391] Time 0.175 (0.175) Data 0.137 (0.137) Loss 0.4071 (0.4071) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:53:20,294 - INFO - Pruning info: sparsity=0.898
2025-08-27 22:53:20,295 - INFO -   Reactivation rate: 0.0004
2025-08-27 22:53:21,763 - INFO - Epoch: [65][100/391] Time 0.016 (0.022) Data 0.001 (0.005) Loss 0.3726 (0.4279) Acc@1 86.719 (84.847) Acc@5 99.219 (99.381)
2025-08-27 22:53:23,296 - INFO - Pruning info: sparsity=0.898
2025-08-27 22:53:23,296 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:23,566 - INFO - Epoch: [65][200/391] Time 0.013 (0.020) Data 0.001 (0.004) Loss 0.4389 (0.4248) Acc@1 82.812 (85.180) Acc@5 100.000 (99.417)
2025-08-27 22:53:25,464 - INFO - Epoch: [65][300/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.4369 (0.4253) Acc@1 83.594 (85.219) Acc@5 100.000 (99.411)
2025-08-27 22:53:26,281 - INFO - Pruning info: sparsity=0.898
2025-08-27 22:53:26,282 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:27,262 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5129 (0.5129) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:53:28,291 - INFO - Epoch 65:
2025-08-27 22:53:28,291 - INFO -   Train: acc1: 85.1880 | acc5: 99.4140 | loss: 0.4276 | sparsity: 0.8979 | reactivation_rate: 0.0002
2025-08-27 22:53:28,292 - INFO -   Val:   acc1: 78.6900 | acc5: 99.0400 | loss: 0.6633
2025-08-27 22:53:28,292 - INFO -   LR: 0.100000
2025-08-27 22:53:28,305 - INFO - 
Epoch: 66, lr = 0.1
2025-08-27 22:53:28,727 - INFO - Epoch: [66][0/391] Time 0.421 (0.421) Data 0.268 (0.268) Loss 0.4372 (0.4372) Acc@1 85.156 (85.156) Acc@5 98.438 (98.438)
2025-08-27 22:53:30,575 - INFO - Epoch: [66][100/391] Time 0.013 (0.022) Data 0.000 (0.004) Loss 0.3737 (0.4090) Acc@1 88.281 (86.038) Acc@5 100.000 (99.459)
2025-08-27 22:53:30,872 - INFO - Pruning info: sparsity=0.898
2025-08-27 22:53:30,872 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:53:32,403 - INFO - Epoch: [66][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.4962 (0.4209) Acc@1 78.906 (85.588) Acc@5 100.000 (99.425)
2025-08-27 22:53:33,787 - INFO - Pruning info: sparsity=0.898
2025-08-27 22:53:33,787 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:34,309 - INFO - Epoch: [66][300/391] Time 0.022 (0.020) Data 0.008 (0.003) Loss 0.5339 (0.4306) Acc@1 78.125 (85.276) Acc@5 99.219 (99.406)
2025-08-27 22:53:36,062 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5853 (0.5853) Acc@1 78.906 (78.906) Acc@5 100.000 (100.000)
2025-08-27 22:53:36,901 - INFO - Epoch 66:
2025-08-27 22:53:36,901 - INFO -   Train: acc1: 85.3280 | acc5: 99.4140 | loss: 0.4278 | sparsity: 0.8984 | reactivation_rate: 0.0002
2025-08-27 22:53:36,901 - INFO -   Val:   acc1: 77.7400 | acc5: 99.2400 | loss: 0.6769
2025-08-27 22:53:36,901 - INFO -   LR: 0.100000
2025-08-27 22:53:36,912 - INFO - 
Epoch: 67, lr = 0.1
2025-08-27 22:53:37,111 - INFO - Epoch: [67][0/391] Time 0.198 (0.198) Data 0.173 (0.173) Loss 0.3190 (0.3190) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:53:37,888 - INFO - Pruning info: sparsity=0.899
2025-08-27 22:53:37,889 - INFO -   Reactivation rate: 0.0003
2025-08-27 22:53:38,931 - INFO - Epoch: [67][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4083 (0.4149) Acc@1 83.594 (85.783) Acc@5 99.219 (99.404)
2025-08-27 22:53:40,824 - INFO - Epoch: [67][200/391] Time 0.028 (0.019) Data 0.000 (0.004) Loss 0.4010 (0.4228) Acc@1 86.719 (85.440) Acc@5 100.000 (99.355)
2025-08-27 22:53:40,878 - INFO - Pruning info: sparsity=0.899
2025-08-27 22:53:40,878 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:42,650 - INFO - Epoch: [67][300/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.2972 (0.4188) Acc@1 89.062 (85.579) Acc@5 100.000 (99.411)
2025-08-27 22:53:43,843 - INFO - Pruning info: sparsity=0.899
2025-08-27 22:53:43,844 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:53:44,523 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5093 (0.5093) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:53:45,362 - INFO - Epoch 67:
2025-08-27 22:53:45,362 - INFO -   Train: acc1: 85.4860 | acc5: 99.3680 | loss: 0.4221 | sparsity: 0.8989 | reactivation_rate: 0.0002
2025-08-27 22:53:45,362 - INFO -   Val:   acc1: 82.9600 | acc5: 98.8800 | loss: 0.5340
2025-08-27 22:53:45,362 - INFO -   LR: 0.100000
2025-08-27 22:53:45,376 - INFO - 
Epoch: 68, lr = 0.1
2025-08-27 22:53:45,561 - INFO - Epoch: [68][0/391] Time 0.183 (0.183) Data 0.162 (0.162) Loss 0.3436 (0.3436) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:53:47,436 - INFO - Epoch: [68][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.4455 (0.4188) Acc@1 85.938 (85.574) Acc@5 99.219 (99.474)
2025-08-27 22:53:47,997 - INFO - Pruning info: sparsity=0.899
2025-08-27 22:53:47,998 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:49,311 - INFO - Epoch: [68][200/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.3586 (0.4230) Acc@1 89.062 (85.491) Acc@5 100.000 (99.409)
2025-08-27 22:53:50,931 - INFO - Pruning info: sparsity=0.899
2025-08-27 22:53:50,932 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:53:51,101 - INFO - Epoch: [68][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.4884 (0.4257) Acc@1 86.719 (85.379) Acc@5 99.219 (99.445)
2025-08-27 22:53:52,941 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.7973 (0.7973) Acc@1 77.344 (77.344) Acc@5 98.438 (98.438)
2025-08-27 22:53:53,796 - INFO - Epoch 68:
2025-08-27 22:53:53,796 - INFO -   Train: acc1: 85.3560 | acc5: 99.4240 | loss: 0.4260 | sparsity: 0.8993 | reactivation_rate: 0.0002
2025-08-27 22:53:53,796 - INFO -   Val:   acc1: 71.2000 | acc5: 96.8600 | loss: 1.0599
2025-08-27 22:53:53,796 - INFO -   LR: 0.100000
2025-08-27 22:53:53,809 - INFO - 
Epoch: 69, lr = 0.1
2025-08-27 22:53:54,004 - INFO - Epoch: [69][0/391] Time 0.194 (0.194) Data 0.172 (0.172) Loss 0.4564 (0.4564) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:53:55,094 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:53:55,094 - INFO -   Reactivation rate: 0.0002
2025-08-27 22:53:55,837 - INFO - Epoch: [69][100/391] Time 0.019 (0.020) Data 0.000 (0.005) Loss 0.4439 (0.4238) Acc@1 85.156 (85.404) Acc@5 99.219 (99.482)
2025-08-27 22:53:57,674 - INFO - Epoch: [69][200/391] Time 0.026 (0.019) Data 0.001 (0.004) Loss 0.3716 (0.4213) Acc@1 88.281 (85.615) Acc@5 100.000 (99.475)
2025-08-27 22:53:58,023 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:53:58,023 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:53:59,542 - INFO - Epoch: [69][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.4884 (0.4253) Acc@1 82.812 (85.442) Acc@5 100.000 (99.486)
2025-08-27 22:54:00,918 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:00,918 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:01,237 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6829 (0.6829) Acc@1 79.688 (79.688) Acc@5 100.000 (100.000)
2025-08-27 22:54:02,086 - INFO - Epoch 69:
2025-08-27 22:54:02,086 - INFO -   Train: acc1: 85.3520 | acc5: 99.4560 | loss: 0.4270 | sparsity: 0.8995 | reactivation_rate: 0.0001
2025-08-27 22:54:02,086 - INFO -   Val:   acc1: 76.4200 | acc5: 98.9800 | loss: 0.7692
2025-08-27 22:54:02,086 - INFO -   LR: 0.100000
2025-08-27 22:54:02,101 - INFO - 
Epoch: 70, lr = 0.1
2025-08-27 22:54:02,284 - INFO - Epoch: [70][0/391] Time 0.183 (0.183) Data 0.165 (0.165) Loss 0.5520 (0.5520) Acc@1 83.594 (83.594) Acc@5 97.656 (97.656)
2025-08-27 22:54:04,154 - INFO - Epoch: [70][100/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.3646 (0.4247) Acc@1 85.156 (85.713) Acc@5 100.000 (99.304)
2025-08-27 22:54:05,086 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:05,086 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:06,036 - INFO - Epoch: [70][200/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3886 (0.4282) Acc@1 85.938 (85.549) Acc@5 100.000 (99.285)
2025-08-27 22:54:07,877 - INFO - Epoch: [70][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2402 (0.4281) Acc@1 92.188 (85.333) Acc@5 100.000 (99.346)
2025-08-27 22:54:07,985 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:07,985 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:09,657 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6086 (0.6086) Acc@1 78.125 (78.125) Acc@5 99.219 (99.219)
2025-08-27 22:54:10,501 - INFO - Epoch 70:
2025-08-27 22:54:10,502 - INFO -   Train: acc1: 85.4860 | acc5: 99.3660 | loss: 0.4222 | sparsity: 0.8997 | reactivation_rate: 0.0001
2025-08-27 22:54:10,502 - INFO -   Val:   acc1: 79.2400 | acc5: 98.9200 | loss: 0.6374
2025-08-27 22:54:10,502 - INFO -   LR: 0.100000
2025-08-27 22:54:10,550 - INFO - 
Epoch: 71, lr = 0.1
2025-08-27 22:54:10,719 - INFO - Epoch: [71][0/391] Time 0.168 (0.168) Data 0.143 (0.143) Loss 0.2986 (0.2986) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:54:12,159 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:12,159 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:12,531 - INFO - Epoch: [71][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.3874 (0.4139) Acc@1 87.500 (85.876) Acc@5 100.000 (99.443)
2025-08-27 22:54:14,349 - INFO - Epoch: [71][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.3230 (0.4210) Acc@1 91.406 (85.471) Acc@5 100.000 (99.398)
2025-08-27 22:54:15,062 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:15,062 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:16,189 - INFO - Epoch: [71][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3708 (0.4249) Acc@1 87.500 (85.372) Acc@5 99.219 (99.359)
2025-08-27 22:54:17,995 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.5135 (0.5135) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:54:18,815 - INFO - Epoch 71:
2025-08-27 22:54:18,816 - INFO -   Train: acc1: 85.2660 | acc5: 99.3440 | loss: 0.4292 | sparsity: 0.8999 | reactivation_rate: 0.0001
2025-08-27 22:54:18,816 - INFO -   Val:   acc1: 79.9700 | acc5: 99.0700 | loss: 0.5898
2025-08-27 22:54:18,816 - INFO -   LR: 0.100000
2025-08-27 22:54:18,829 - INFO - 
Epoch: 72, lr = 0.1
2025-08-27 22:54:18,984 - INFO - Epoch: [72][0/391] Time 0.154 (0.154) Data 0.124 (0.124) Loss 0.4502 (0.4502) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 22:54:19,102 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:19,102 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:20,838 - INFO - Epoch: [72][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3613 (0.4132) Acc@1 88.281 (85.489) Acc@5 99.219 (99.505)
2025-08-27 22:54:22,055 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:22,055 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:22,694 - INFO - Epoch: [72][200/391] Time 0.031 (0.019) Data 0.000 (0.002) Loss 0.4485 (0.4274) Acc@1 82.031 (85.211) Acc@5 100.000 (99.405)
2025-08-27 22:54:24,433 - INFO - Epoch: [72][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.5831 (0.4256) Acc@1 82.031 (85.273) Acc@5 98.438 (99.408)
2025-08-27 22:54:24,975 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:24,975 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:26,228 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5917 (0.5917) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:54:27,058 - INFO - Epoch 72:
2025-08-27 22:54:27,059 - INFO -   Train: acc1: 85.2820 | acc5: 99.4240 | loss: 0.4248 | sparsity: 0.8999 | reactivation_rate: 0.0001
2025-08-27 22:54:27,059 - INFO -   Val:   acc1: 78.4500 | acc5: 98.9300 | loss: 0.6866
2025-08-27 22:54:27,059 - INFO -   LR: 0.100000
2025-08-27 22:54:27,073 - INFO - 
Epoch: 73, lr = 0.1
2025-08-27 22:54:27,275 - INFO - Epoch: [73][0/391] Time 0.201 (0.201) Data 0.165 (0.165) Loss 0.4174 (0.4174) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:54:28,993 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:28,993 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:29,054 - INFO - Epoch: [73][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2999 (0.4155) Acc@1 90.625 (85.272) Acc@5 100.000 (99.528)
2025-08-27 22:54:31,038 - INFO - Epoch: [73][200/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.4579 (0.4206) Acc@1 80.469 (85.246) Acc@5 99.219 (99.436)
2025-08-27 22:54:32,101 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:32,101 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:32,994 - INFO - Epoch: [73][300/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.3293 (0.4206) Acc@1 86.719 (85.343) Acc@5 100.000 (99.432)
2025-08-27 22:54:34,745 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.6750 (0.6750) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 22:54:35,572 - INFO - Epoch 73:
2025-08-27 22:54:35,573 - INFO -   Train: acc1: 85.3740 | acc5: 99.4180 | loss: 0.4218 | sparsity: 0.9000 | reactivation_rate: 0.0001
2025-08-27 22:54:35,573 - INFO -   Val:   acc1: 75.6900 | acc5: 97.4000 | loss: 0.8478
2025-08-27 22:54:35,573 - INFO -   LR: 0.100000
2025-08-27 22:54:35,586 - INFO - 
Epoch: 74, lr = 0.1
2025-08-27 22:54:35,766 - INFO - Epoch: [74][0/391] Time 0.179 (0.179) Data 0.151 (0.151) Loss 0.4748 (0.4748) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:54:36,220 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:36,221 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:37,575 - INFO - Epoch: [74][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.3922 (0.4332) Acc@1 88.281 (84.940) Acc@5 99.219 (99.366)
2025-08-27 22:54:39,090 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:39,090 - INFO -   Reactivation rate: 0.0001
2025-08-27 22:54:39,335 - INFO - Epoch: [74][200/391] Time 0.028 (0.019) Data 0.004 (0.003) Loss 0.4913 (0.4225) Acc@1 83.594 (85.358) Acc@5 100.000 (99.378)
2025-08-27 22:54:41,282 - INFO - Epoch: [74][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3998 (0.4222) Acc@1 86.719 (85.395) Acc@5 98.438 (99.416)
2025-08-27 22:54:42,095 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:42,095 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:54:43,046 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.5828 (0.5828) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:54:43,910 - INFO - Epoch 74:
2025-08-27 22:54:43,911 - INFO -   Train: acc1: 85.3320 | acc5: 99.4280 | loss: 0.4250 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:54:43,911 - INFO -   Val:   acc1: 77.7100 | acc5: 99.1000 | loss: 0.6578
2025-08-27 22:54:43,911 - INFO -   LR: 0.100000
2025-08-27 22:54:43,923 - INFO - 
Epoch: 75, lr = 0.1
2025-08-27 22:54:44,113 - INFO - Epoch: [75][0/391] Time 0.189 (0.189) Data 0.169 (0.169) Loss 0.2766 (0.2766) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 22:54:46,056 - INFO - Epoch: [75][100/391] Time 0.018 (0.021) Data 0.000 (0.004) Loss 0.4872 (0.4118) Acc@1 82.031 (85.667) Acc@5 98.438 (99.489)
2025-08-27 22:54:46,279 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:46,288 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:54:47,809 - INFO - Epoch: [75][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.3522 (0.4188) Acc@1 89.844 (85.491) Acc@5 98.438 (99.409)
2025-08-27 22:54:49,155 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:49,155 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:54:49,637 - INFO - Epoch: [75][300/391] Time 0.030 (0.019) Data 0.019 (0.004) Loss 0.6069 (0.4229) Acc@1 75.781 (85.392) Acc@5 98.438 (99.419)
2025-08-27 22:54:51,497 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.4756 (0.4756) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 22:54:52,360 - INFO - Epoch 75:
2025-08-27 22:54:52,361 - INFO -   Train: acc1: 85.4300 | acc5: 99.4160 | loss: 0.4223 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:54:52,361 - INFO -   Val:   acc1: 79.7400 | acc5: 98.9400 | loss: 0.5969
2025-08-27 22:54:52,361 - INFO -   LR: 0.100000
2025-08-27 22:54:52,373 - INFO - 
Epoch: 76, lr = 0.1
2025-08-27 22:54:52,550 - INFO - Epoch: [76][0/391] Time 0.176 (0.176) Data 0.151 (0.151) Loss 0.4123 (0.4123) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:54:53,319 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:53,319 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:54:54,305 - INFO - Epoch: [76][100/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3934 (0.4184) Acc@1 87.500 (85.806) Acc@5 100.000 (99.343)
2025-08-27 22:54:56,153 - INFO - Epoch: [76][200/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.4886 (0.4252) Acc@1 83.594 (85.323) Acc@5 99.219 (99.359)
2025-08-27 22:54:56,218 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:56,219 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:54:57,973 - INFO - Epoch: [76][300/391] Time 0.031 (0.019) Data 0.015 (0.003) Loss 0.4250 (0.4286) Acc@1 89.062 (85.208) Acc@5 98.438 (99.349)
2025-08-27 22:54:59,140 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:54:59,140 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:54:59,736 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.7660 (0.7660) Acc@1 73.438 (73.438) Acc@5 98.438 (98.438)
2025-08-27 22:55:00,588 - INFO - Epoch 76:
2025-08-27 22:55:00,588 - INFO -   Train: acc1: 85.3200 | acc5: 99.3420 | loss: 0.4273 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:00,588 - INFO -   Val:   acc1: 76.6600 | acc5: 98.5600 | loss: 0.7225
2025-08-27 22:55:00,588 - INFO -   LR: 0.100000
2025-08-27 22:55:00,602 - INFO - 
Epoch: 77, lr = 0.1
2025-08-27 22:55:00,784 - INFO - Epoch: [77][0/391] Time 0.182 (0.182) Data 0.156 (0.156) Loss 0.3636 (0.3636) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 22:55:02,620 - INFO - Epoch: [77][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4008 (0.4229) Acc@1 87.500 (85.528) Acc@5 100.000 (99.389)
2025-08-27 22:55:03,210 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:03,210 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:04,445 - INFO - Epoch: [77][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4279 (0.4298) Acc@1 85.938 (85.152) Acc@5 99.219 (99.390)
2025-08-27 22:55:06,218 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:06,218 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:06,377 - INFO - Epoch: [77][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3501 (0.4245) Acc@1 91.406 (85.398) Acc@5 99.219 (99.419)
2025-08-27 22:55:08,277 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.6706 (0.6706) Acc@1 81.250 (81.250) Acc@5 97.656 (97.656)
2025-08-27 22:55:09,133 - INFO - Epoch 77:
2025-08-27 22:55:09,133 - INFO -   Train: acc1: 85.2320 | acc5: 99.4000 | loss: 0.4273 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:09,133 - INFO -   Val:   acc1: 79.5400 | acc5: 98.8700 | loss: 0.6190
2025-08-27 22:55:09,133 - INFO -   LR: 0.100000
2025-08-27 22:55:09,147 - INFO - 
Epoch: 78, lr = 0.1
2025-08-27 22:55:09,320 - INFO - Epoch: [78][0/391] Time 0.172 (0.172) Data 0.147 (0.147) Loss 0.4756 (0.4756) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:55:10,496 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:10,496 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:11,168 - INFO - Epoch: [78][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.3559 (0.4107) Acc@1 87.500 (85.667) Acc@5 100.000 (99.459)
2025-08-27 22:55:12,964 - INFO - Epoch: [78][200/391] Time 0.015 (0.019) Data 0.003 (0.003) Loss 0.5006 (0.4221) Acc@1 84.375 (85.463) Acc@5 98.438 (99.429)
2025-08-27 22:55:13,355 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:13,356 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:14,764 - INFO - Epoch: [78][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.6340 (0.4276) Acc@1 75.000 (85.180) Acc@5 100.000 (99.442)
2025-08-27 22:55:16,283 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:16,284 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:16,570 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.5681 (0.5681) Acc@1 83.594 (83.594) Acc@5 98.438 (98.438)
2025-08-27 22:55:17,447 - INFO - Epoch 78:
2025-08-27 22:55:17,448 - INFO -   Train: acc1: 85.0160 | acc5: 99.4240 | loss: 0.4304 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:17,448 - INFO -   Val:   acc1: 79.6300 | acc5: 98.8800 | loss: 0.6067
2025-08-27 22:55:17,448 - INFO -   LR: 0.100000
2025-08-27 22:55:17,462 - INFO - 
Epoch: 79, lr = 0.1
2025-08-27 22:55:17,621 - INFO - Epoch: [79][0/391] Time 0.159 (0.159) Data 0.133 (0.133) Loss 0.5024 (0.5024) Acc@1 84.375 (84.375) Acc@5 97.656 (97.656)
2025-08-27 22:55:19,455 - INFO - Epoch: [79][100/391] Time 0.038 (0.020) Data 0.027 (0.005) Loss 0.5225 (0.4200) Acc@1 83.594 (85.365) Acc@5 97.656 (99.343)
2025-08-27 22:55:20,392 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:20,393 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:21,246 - INFO - Epoch: [79][200/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.4185 (0.4234) Acc@1 84.375 (85.273) Acc@5 99.219 (99.409)
2025-08-27 22:55:23,135 - INFO - Epoch: [79][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5285 (0.4221) Acc@1 85.938 (85.395) Acc@5 99.219 (99.393)
2025-08-27 22:55:23,303 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:23,303 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:24,900 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.9812 (0.9812) Acc@1 72.656 (72.656) Acc@5 98.438 (98.438)
2025-08-27 22:55:25,724 - INFO - Epoch 79:
2025-08-27 22:55:25,724 - INFO -   Train: acc1: 85.1620 | acc5: 99.4020 | loss: 0.4276 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:25,724 - INFO -   Val:   acc1: 70.2800 | acc5: 97.9900 | loss: 1.0747
2025-08-27 22:55:25,724 - INFO -   LR: 0.100000
2025-08-27 22:55:25,739 - INFO - 
Epoch: 80, lr = 0.1
2025-08-27 22:55:25,930 - INFO - Epoch: [80][0/391] Time 0.191 (0.191) Data 0.165 (0.165) Loss 0.3182 (0.3182) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:55:27,398 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:27,399 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:27,750 - INFO - Epoch: [80][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.5298 (0.4168) Acc@1 80.469 (85.605) Acc@5 99.219 (99.520)
2025-08-27 22:55:29,589 - INFO - Epoch: [80][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.3561 (0.4199) Acc@1 85.938 (85.588) Acc@5 100.000 (99.495)
2025-08-27 22:55:30,279 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:30,280 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:31,417 - INFO - Epoch: [80][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.5534 (0.4220) Acc@1 81.250 (85.507) Acc@5 100.000 (99.489)
2025-08-27 22:55:33,145 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.5411 (0.5411) Acc@1 82.031 (82.031) Acc@5 99.219 (99.219)
2025-08-27 22:55:34,001 - INFO - Epoch 80:
2025-08-27 22:55:34,002 - INFO -   Train: acc1: 85.4720 | acc5: 99.4820 | loss: 0.4243 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:34,002 - INFO -   Val:   acc1: 81.1500 | acc5: 99.2300 | loss: 0.5586
2025-08-27 22:55:34,002 - INFO -   LR: 0.100000
2025-08-27 22:55:34,050 - INFO - 
Epoch: 81, lr = 0.1
2025-08-27 22:55:34,242 - INFO - Epoch: [81][0/391] Time 0.191 (0.191) Data 0.153 (0.153) Loss 0.4097 (0.4097) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:55:34,362 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:34,362 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:36,081 - INFO - Epoch: [81][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.3298 (0.4172) Acc@1 87.500 (85.520) Acc@5 100.000 (99.412)
2025-08-27 22:55:37,319 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:37,319 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:37,865 - INFO - Epoch: [81][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3826 (0.4188) Acc@1 86.719 (85.514) Acc@5 100.000 (99.398)
2025-08-27 22:55:39,741 - INFO - Epoch: [81][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.4026 (0.4210) Acc@1 85.938 (85.418) Acc@5 99.219 (99.408)
2025-08-27 22:55:40,266 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:40,267 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:41,574 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.7795 (0.7795) Acc@1 75.000 (75.000) Acc@5 96.094 (96.094)
2025-08-27 22:55:42,403 - INFO - Epoch 81:
2025-08-27 22:55:42,403 - INFO -   Train: acc1: 85.3100 | acc5: 99.3720 | loss: 0.4232 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:42,403 - INFO -   Val:   acc1: 76.0000 | acc5: 97.9600 | loss: 0.7776
2025-08-27 22:55:42,403 - INFO -   LR: 0.100000
2025-08-27 22:55:42,418 - INFO - 
Epoch: 82, lr = 0.1
2025-08-27 22:55:42,589 - INFO - Epoch: [82][0/391] Time 0.170 (0.170) Data 0.149 (0.149) Loss 0.5217 (0.5217) Acc@1 80.469 (80.469) Acc@5 100.000 (100.000)
2025-08-27 22:55:44,437 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:44,438 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:44,474 - INFO - Epoch: [82][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4820 (0.4300) Acc@1 83.594 (85.265) Acc@5 99.219 (99.381)
2025-08-27 22:55:46,181 - INFO - Epoch: [82][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3853 (0.4335) Acc@1 87.500 (84.981) Acc@5 99.219 (99.425)
2025-08-27 22:55:47,203 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:47,204 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:48,003 - INFO - Epoch: [82][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3660 (0.4319) Acc@1 89.844 (85.151) Acc@5 100.000 (99.400)
2025-08-27 22:55:49,726 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.4186 (0.4186) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:55:50,561 - INFO - Epoch 82:
2025-08-27 22:55:50,561 - INFO -   Train: acc1: 85.2740 | acc5: 99.4000 | loss: 0.4280 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:50,561 - INFO -   Val:   acc1: 81.2400 | acc5: 98.9700 | loss: 0.5443
2025-08-27 22:55:50,561 - INFO -   LR: 0.100000
2025-08-27 22:55:50,575 - INFO - 
Epoch: 83, lr = 0.1
2025-08-27 22:55:50,759 - INFO - Epoch: [83][0/391] Time 0.183 (0.183) Data 0.166 (0.166) Loss 0.5251 (0.5251) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:55:51,325 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:51,326 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:52,700 - INFO - Epoch: [83][100/391] Time 0.039 (0.021) Data 0.020 (0.004) Loss 0.4955 (0.4103) Acc@1 83.594 (85.930) Acc@5 99.219 (99.466)
2025-08-27 22:55:54,253 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:54,253 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:54,495 - INFO - Epoch: [83][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3880 (0.4141) Acc@1 85.938 (85.786) Acc@5 100.000 (99.475)
2025-08-27 22:55:56,322 - INFO - Epoch: [83][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.6486 (0.4210) Acc@1 81.250 (85.688) Acc@5 95.312 (99.434)
2025-08-27 22:55:57,213 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:55:57,213 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:55:58,140 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.9787 (0.9787) Acc@1 70.312 (70.312) Acc@5 98.438 (98.438)
2025-08-27 22:55:58,992 - INFO - Epoch 83:
2025-08-27 22:55:58,992 - INFO -   Train: acc1: 85.5380 | acc5: 99.4100 | loss: 0.4247 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:55:58,992 - INFO -   Val:   acc1: 68.1000 | acc5: 96.9600 | loss: 1.1303
2025-08-27 22:55:58,992 - INFO -   LR: 0.100000
2025-08-27 22:55:59,004 - INFO - 
Epoch: 84, lr = 0.1
2025-08-27 22:55:59,189 - INFO - Epoch: [84][0/391] Time 0.184 (0.184) Data 0.148 (0.148) Loss 0.4296 (0.4296) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:56:01,069 - INFO - Epoch: [84][100/391] Time 0.017 (0.020) Data 0.000 (0.003) Loss 0.3910 (0.4305) Acc@1 86.719 (85.218) Acc@5 100.000 (99.474)
2025-08-27 22:56:01,363 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:01,363 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:02,907 - INFO - Epoch: [84][200/391] Time 0.019 (0.019) Data 0.008 (0.002) Loss 0.4607 (0.4246) Acc@1 85.156 (85.331) Acc@5 99.219 (99.499)
2025-08-27 22:56:04,316 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:04,316 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:04,740 - INFO - Epoch: [84][300/391] Time 0.014 (0.019) Data 0.000 (0.002) Loss 0.3172 (0.4260) Acc@1 89.844 (85.143) Acc@5 100.000 (99.447)
2025-08-27 22:56:06,513 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.6624 (0.6624) Acc@1 77.344 (77.344) Acc@5 99.219 (99.219)
2025-08-27 22:56:07,354 - INFO - Epoch 84:
2025-08-27 22:56:07,354 - INFO -   Train: acc1: 85.1340 | acc5: 99.4280 | loss: 0.4289 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:07,354 - INFO -   Val:   acc1: 75.1300 | acc5: 98.7800 | loss: 0.7734
2025-08-27 22:56:07,354 - INFO -   LR: 0.100000
2025-08-27 22:56:07,369 - INFO - 
Epoch: 85, lr = 0.1
2025-08-27 22:56:07,558 - INFO - Epoch: [85][0/391] Time 0.187 (0.187) Data 0.165 (0.165) Loss 0.5376 (0.5376) Acc@1 78.125 (78.125) Acc@5 100.000 (100.000)
2025-08-27 22:56:08,414 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:08,414 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:09,421 - INFO - Epoch: [85][100/391] Time 0.011 (0.020) Data 0.000 (0.006) Loss 0.4700 (0.4232) Acc@1 82.812 (85.141) Acc@5 100.000 (99.389)
2025-08-27 22:56:11,232 - INFO - Epoch: [85][200/391] Time 0.039 (0.019) Data 0.028 (0.005) Loss 0.3564 (0.4226) Acc@1 88.281 (85.467) Acc@5 100.000 (99.386)
2025-08-27 22:56:11,312 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:11,312 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:13,058 - INFO - Epoch: [85][300/391] Time 0.018 (0.019) Data 0.002 (0.004) Loss 0.4587 (0.4206) Acc@1 83.594 (85.538) Acc@5 99.219 (99.421)
2025-08-27 22:56:14,318 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:14,318 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:14,877 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.6919 (0.6919) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 22:56:15,729 - INFO - Epoch 85:
2025-08-27 22:56:15,729 - INFO -   Train: acc1: 85.4020 | acc5: 99.4300 | loss: 0.4229 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:15,729 - INFO -   Val:   acc1: 74.0400 | acc5: 98.0000 | loss: 0.8082
2025-08-27 22:56:15,729 - INFO -   LR: 0.100000
2025-08-27 22:56:15,743 - INFO - 
Epoch: 86, lr = 0.1
2025-08-27 22:56:15,918 - INFO - Epoch: [86][0/391] Time 0.174 (0.174) Data 0.147 (0.147) Loss 0.2948 (0.2948) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:56:17,832 - INFO - Epoch: [86][100/391] Time 0.017 (0.021) Data 0.000 (0.003) Loss 0.4722 (0.4193) Acc@1 85.156 (85.497) Acc@5 99.219 (99.497)
2025-08-27 22:56:18,393 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:18,398 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:19,641 - INFO - Epoch: [86][200/391] Time 0.027 (0.019) Data 0.002 (0.003) Loss 0.3827 (0.4235) Acc@1 85.938 (85.331) Acc@5 99.219 (99.471)
2025-08-27 22:56:21,284 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:21,284 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:21,414 - INFO - Epoch: [86][300/391] Time 0.023 (0.019) Data 0.000 (0.002) Loss 0.4625 (0.4264) Acc@1 84.375 (85.244) Acc@5 100.000 (99.468)
2025-08-27 22:56:23,152 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.4661 (0.4661) Acc@1 83.594 (83.594) Acc@5 99.219 (99.219)
2025-08-27 22:56:24,012 - INFO - Epoch 86:
2025-08-27 22:56:24,012 - INFO -   Train: acc1: 85.2440 | acc5: 99.4440 | loss: 0.4253 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:24,012 - INFO -   Val:   acc1: 79.9000 | acc5: 99.1200 | loss: 0.5913
2025-08-27 22:56:24,012 - INFO -   LR: 0.100000
2025-08-27 22:56:24,025 - INFO - 
Epoch: 87, lr = 0.1
2025-08-27 22:56:24,193 - INFO - Epoch: [87][0/391] Time 0.167 (0.167) Data 0.140 (0.140) Loss 0.4027 (0.4027) Acc@1 85.938 (85.938) Acc@5 99.219 (99.219)
2025-08-27 22:56:25,315 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:25,315 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:26,031 - INFO - Epoch: [87][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.3737 (0.4275) Acc@1 85.938 (85.071) Acc@5 100.000 (99.366)
2025-08-27 22:56:27,864 - INFO - Epoch: [87][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3448 (0.4254) Acc@1 85.156 (85.273) Acc@5 100.000 (99.409)
2025-08-27 22:56:28,257 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:28,257 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:29,652 - INFO - Epoch: [87][300/391] Time 0.019 (0.019) Data 0.007 (0.003) Loss 0.5516 (0.4240) Acc@1 75.000 (85.372) Acc@5 99.219 (99.385)
2025-08-27 22:56:31,190 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:31,190 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:31,457 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 1.0596 (1.0596) Acc@1 67.969 (67.969) Acc@5 97.656 (97.656)
2025-08-27 22:56:32,284 - INFO - Epoch 87:
2025-08-27 22:56:32,284 - INFO -   Train: acc1: 85.2580 | acc5: 99.3940 | loss: 0.4265 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:32,284 - INFO -   Val:   acc1: 69.8100 | acc5: 98.1600 | loss: 1.0490
2025-08-27 22:56:32,284 - INFO -   LR: 0.100000
2025-08-27 22:56:32,299 - INFO - 
Epoch: 88, lr = 0.1
2025-08-27 22:56:32,474 - INFO - Epoch: [88][0/391] Time 0.174 (0.174) Data 0.150 (0.150) Loss 0.4251 (0.4251) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 22:56:34,267 - INFO - Epoch: [88][100/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.4073 (0.4306) Acc@1 86.719 (85.319) Acc@5 100.000 (99.474)
2025-08-27 22:56:35,268 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:35,268 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:36,147 - INFO - Epoch: [88][200/391] Time 0.026 (0.019) Data 0.007 (0.003) Loss 0.4529 (0.4246) Acc@1 85.156 (85.560) Acc@5 99.219 (99.440)
2025-08-27 22:56:37,941 - INFO - Epoch: [88][300/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.5673 (0.4235) Acc@1 77.344 (85.507) Acc@5 100.000 (99.432)
2025-08-27 22:56:38,154 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:38,154 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:39,724 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.5927 (0.5927) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 22:56:40,531 - INFO - Epoch 88:
2025-08-27 22:56:40,531 - INFO -   Train: acc1: 85.2960 | acc5: 99.4140 | loss: 0.4276 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:40,531 - INFO -   Val:   acc1: 76.9000 | acc5: 98.4900 | loss: 0.7030
2025-08-27 22:56:40,531 - INFO -   LR: 0.100000
2025-08-27 22:56:41,103 - INFO - 
Epoch: 89, lr = 0.1
2025-08-27 22:56:41,281 - INFO - Epoch: [89][0/391] Time 0.177 (0.177) Data 0.150 (0.150) Loss 0.4052 (0.4052) Acc@1 81.250 (81.250) Acc@5 100.000 (100.000)
2025-08-27 22:56:42,752 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:42,752 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:43,108 - INFO - Epoch: [89][100/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.5342 (0.4167) Acc@1 81.250 (85.914) Acc@5 98.438 (99.350)
2025-08-27 22:56:44,932 - INFO - Epoch: [89][200/391] Time 0.033 (0.019) Data 0.017 (0.003) Loss 0.3933 (0.4227) Acc@1 89.062 (85.611) Acc@5 98.438 (99.390)
2025-08-27 22:56:45,654 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:45,654 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:46,732 - INFO - Epoch: [89][300/391] Time 0.043 (0.019) Data 0.030 (0.003) Loss 0.5454 (0.4269) Acc@1 81.250 (85.491) Acc@5 99.219 (99.398)
2025-08-27 22:56:48,513 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.7671 (0.7671) Acc@1 77.344 (77.344) Acc@5 96.875 (96.875)
2025-08-27 22:56:49,378 - INFO - Epoch 89:
2025-08-27 22:56:49,378 - INFO -   Train: acc1: 85.3640 | acc5: 99.4100 | loss: 0.4283 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:49,378 - INFO -   Val:   acc1: 75.3900 | acc5: 98.4000 | loss: 0.7979
2025-08-27 22:56:49,378 - INFO -   LR: 0.100000
2025-08-27 22:56:49,393 - INFO - 
Epoch: 90, lr = 0.1
2025-08-27 22:56:49,574 - INFO - Epoch: [90][0/391] Time 0.180 (0.180) Data 0.156 (0.156) Loss 0.4453 (0.4453) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:56:49,747 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:49,748 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:51,416 - INFO - Epoch: [90][100/391] Time 0.026 (0.020) Data 0.000 (0.004) Loss 0.5970 (0.4270) Acc@1 79.688 (85.473) Acc@5 98.438 (99.343)
2025-08-27 22:56:52,666 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:52,667 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:53,206 - INFO - Epoch: [90][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.4768 (0.4283) Acc@1 81.250 (85.277) Acc@5 99.219 (99.363)
2025-08-27 22:56:55,078 - INFO - Epoch: [90][300/391] Time 0.013 (0.019) Data 0.002 (0.003) Loss 0.5533 (0.4241) Acc@1 83.594 (85.447) Acc@5 98.438 (99.367)
2025-08-27 22:56:55,603 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:55,616 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:56,808 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.5029 (0.5029) Acc@1 80.469 (80.469) Acc@5 99.219 (99.219)
2025-08-27 22:56:57,678 - INFO - Epoch 90:
2025-08-27 22:56:57,678 - INFO -   Train: acc1: 85.3960 | acc5: 99.3860 | loss: 0.4257 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:56:57,678 - INFO -   Val:   acc1: 81.2300 | acc5: 98.7400 | loss: 0.5928
2025-08-27 22:56:57,678 - INFO -   LR: 0.100000
2025-08-27 22:56:57,729 - INFO - 
Epoch: 91, lr = 0.1
2025-08-27 22:56:57,894 - INFO - Epoch: [91][0/391] Time 0.164 (0.164) Data 0.136 (0.136) Loss 0.3765 (0.3765) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:56:59,693 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:56:59,694 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:56:59,725 - INFO - Epoch: [91][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.4459 (0.3969) Acc@1 86.719 (86.340) Acc@5 99.219 (99.551)
2025-08-27 22:57:01,577 - INFO - Epoch: [91][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.4936 (0.4185) Acc@1 83.594 (85.852) Acc@5 100.000 (99.452)
2025-08-27 22:57:02,687 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:02,687 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:03,432 - INFO - Epoch: [91][300/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.3212 (0.4207) Acc@1 88.281 (85.660) Acc@5 100.000 (99.432)
2025-08-27 22:57:05,171 - INFO - Test: [0/79] Time 0.151 (0.151) Loss 0.6366 (0.6366) Acc@1 76.562 (76.562) Acc@5 99.219 (99.219)
2025-08-27 22:57:05,975 - INFO - Epoch 91:
2025-08-27 22:57:05,975 - INFO -   Train: acc1: 85.3340 | acc5: 99.4340 | loss: 0.4279 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:05,975 - INFO -   Val:   acc1: 75.0900 | acc5: 97.9300 | loss: 0.8001
2025-08-27 22:57:05,975 - INFO -   LR: 0.100000
2025-08-27 22:57:05,988 - INFO - 
Epoch: 92, lr = 0.1
2025-08-27 22:57:06,164 - INFO - Epoch: [92][0/391] Time 0.175 (0.175) Data 0.151 (0.151) Loss 0.4339 (0.4339) Acc@1 86.719 (86.719) Acc@5 99.219 (99.219)
2025-08-27 22:57:06,701 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:06,702 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:08,041 - INFO - Epoch: [92][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.3748 (0.4250) Acc@1 88.281 (85.644) Acc@5 100.000 (99.312)
2025-08-27 22:57:09,624 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:09,625 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:09,890 - INFO - Epoch: [92][200/391] Time 0.027 (0.019) Data 0.000 (0.002) Loss 0.3443 (0.4220) Acc@1 85.938 (85.549) Acc@5 100.000 (99.421)
2025-08-27 22:57:11,691 - INFO - Epoch: [92][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.3665 (0.4204) Acc@1 89.062 (85.520) Acc@5 99.219 (99.445)
2025-08-27 22:57:12,569 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:12,570 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:13,463 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.6447 (0.6447) Acc@1 77.344 (77.344) Acc@5 97.656 (97.656)
2025-08-27 22:57:14,355 - INFO - Epoch 92:
2025-08-27 22:57:14,355 - INFO -   Train: acc1: 85.4040 | acc5: 99.4300 | loss: 0.4231 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:14,355 - INFO -   Val:   acc1: 73.1300 | acc5: 98.6500 | loss: 0.8338
2025-08-27 22:57:14,355 - INFO -   LR: 0.100000
2025-08-27 22:57:14,370 - INFO - 
Epoch: 93, lr = 0.1
2025-08-27 22:57:14,547 - INFO - Epoch: [93][0/391] Time 0.177 (0.177) Data 0.153 (0.153) Loss 0.4102 (0.4102) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:57:16,359 - INFO - Epoch: [93][100/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.3666 (0.4320) Acc@1 88.281 (84.940) Acc@5 99.219 (99.312)
2025-08-27 22:57:16,620 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:16,620 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:18,116 - INFO - Epoch: [93][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.4173 (0.4220) Acc@1 85.938 (85.389) Acc@5 100.000 (99.394)
2025-08-27 22:57:19,552 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:19,563 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:19,957 - INFO - Epoch: [93][300/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.3307 (0.4260) Acc@1 87.500 (85.229) Acc@5 100.000 (99.429)
2025-08-27 22:57:21,761 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.5552 (0.5552) Acc@1 82.031 (82.031) Acc@5 97.656 (97.656)
2025-08-27 22:57:22,614 - INFO - Epoch 93:
2025-08-27 22:57:22,615 - INFO -   Train: acc1: 85.1360 | acc5: 99.4080 | loss: 0.4275 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:22,615 - INFO -   Val:   acc1: 77.2200 | acc5: 98.7600 | loss: 0.7329
2025-08-27 22:57:22,615 - INFO -   LR: 0.100000
2025-08-27 22:57:22,630 - INFO - 
Epoch: 94, lr = 0.1
2025-08-27 22:57:22,817 - INFO - Epoch: [94][0/391] Time 0.185 (0.185) Data 0.165 (0.165) Loss 0.4852 (0.4852) Acc@1 79.688 (79.688) Acc@5 99.219 (99.219)
2025-08-27 22:57:23,623 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:23,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:24,593 - INFO - Epoch: [94][100/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.4335 (0.4305) Acc@1 85.938 (85.002) Acc@5 99.219 (99.335)
2025-08-27 22:57:26,405 - INFO - Epoch: [94][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.3657 (0.4272) Acc@1 88.281 (85.121) Acc@5 100.000 (99.359)
2025-08-27 22:57:26,493 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:26,493 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:28,156 - INFO - Epoch: [94][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.5471 (0.4257) Acc@1 78.906 (85.265) Acc@5 99.219 (99.364)
2025-08-27 22:57:29,500 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:29,501 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:30,071 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.8144 (0.8144) Acc@1 74.219 (74.219) Acc@5 96.875 (96.875)
2025-08-27 22:57:30,903 - INFO - Epoch 94:
2025-08-27 22:57:30,903 - INFO -   Train: acc1: 85.1380 | acc5: 99.3820 | loss: 0.4293 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:30,903 - INFO -   Val:   acc1: 74.7900 | acc5: 98.4200 | loss: 0.7920
2025-08-27 22:57:30,903 - INFO -   LR: 0.100000
2025-08-27 22:57:30,919 - INFO - 
Epoch: 95, lr = 0.1
2025-08-27 22:57:31,087 - INFO - Epoch: [95][0/391] Time 0.167 (0.167) Data 0.151 (0.151) Loss 0.4170 (0.4170) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:57:32,855 - INFO - Epoch: [95][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.5799 (0.4214) Acc@1 79.688 (85.520) Acc@5 97.656 (99.435)
2025-08-27 22:57:33,468 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:33,468 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:34,663 - INFO - Epoch: [95][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.4808 (0.4185) Acc@1 83.594 (85.623) Acc@5 98.438 (99.390)
2025-08-27 22:57:36,400 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:36,401 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:36,521 - INFO - Epoch: [95][300/391] Time 0.030 (0.019) Data 0.014 (0.003) Loss 0.3532 (0.4253) Acc@1 85.938 (85.260) Acc@5 100.000 (99.356)
2025-08-27 22:57:38,294 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.5027 (0.5027) Acc@1 78.906 (78.906) Acc@5 99.219 (99.219)
2025-08-27 22:57:39,103 - INFO - Epoch 95:
2025-08-27 22:57:39,103 - INFO -   Train: acc1: 85.3260 | acc5: 99.3800 | loss: 0.4242 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:39,103 - INFO -   Val:   acc1: 78.8100 | acc5: 98.5000 | loss: 0.6541
2025-08-27 22:57:39,104 - INFO -   LR: 0.100000
2025-08-27 22:57:39,117 - INFO - 
Epoch: 96, lr = 0.1
2025-08-27 22:57:39,332 - INFO - Epoch: [96][0/391] Time 0.215 (0.215) Data 0.170 (0.170) Loss 0.4860 (0.4860) Acc@1 84.375 (84.375) Acc@5 99.219 (99.219)
2025-08-27 22:57:40,505 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:40,505 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:41,211 - INFO - Epoch: [96][100/391] Time 0.011 (0.021) Data 0.001 (0.007) Loss 0.4123 (0.4112) Acc@1 85.156 (85.938) Acc@5 98.438 (99.459)
2025-08-27 22:57:42,972 - INFO - Epoch: [96][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.5356 (0.4217) Acc@1 78.125 (85.452) Acc@5 98.438 (99.417)
2025-08-27 22:57:43,457 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:43,457 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:44,808 - INFO - Epoch: [96][300/391] Time 0.026 (0.019) Data 0.016 (0.004) Loss 0.3282 (0.4309) Acc@1 89.844 (85.138) Acc@5 99.219 (99.416)
2025-08-27 22:57:46,410 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:46,411 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:46,656 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.4458 (0.4458) Acc@1 84.375 (84.375) Acc@5 100.000 (100.000)
2025-08-27 22:57:47,456 - INFO - Epoch 96:
2025-08-27 22:57:47,456 - INFO -   Train: acc1: 85.2960 | acc5: 99.4100 | loss: 0.4281 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:47,456 - INFO -   Val:   acc1: 81.4900 | acc5: 98.8700 | loss: 0.5626
2025-08-27 22:57:47,456 - INFO -   LR: 0.100000
2025-08-27 22:57:47,471 - INFO - 
Epoch: 97, lr = 0.1
2025-08-27 22:57:47,656 - INFO - Epoch: [97][0/391] Time 0.183 (0.183) Data 0.165 (0.165) Loss 0.3695 (0.3695) Acc@1 85.156 (85.156) Acc@5 100.000 (100.000)
2025-08-27 22:57:49,490 - INFO - Epoch: [97][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.3388 (0.4142) Acc@1 86.719 (85.543) Acc@5 100.000 (99.474)
2025-08-27 22:57:50,453 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:50,453 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:51,345 - INFO - Epoch: [97][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4224 (0.4192) Acc@1 84.375 (85.269) Acc@5 98.438 (99.471)
2025-08-27 22:57:53,217 - INFO - Epoch: [97][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3790 (0.4234) Acc@1 90.625 (85.159) Acc@5 99.219 (99.421)
2025-08-27 22:57:53,463 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:53,463 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:55,012 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.5214 (0.5214) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 22:57:55,841 - INFO - Epoch 97:
2025-08-27 22:57:55,842 - INFO -   Train: acc1: 85.1200 | acc5: 99.3980 | loss: 0.4278 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:57:55,842 - INFO -   Val:   acc1: 80.7500 | acc5: 99.1200 | loss: 0.6052
2025-08-27 22:57:55,842 - INFO -   LR: 0.100000
2025-08-27 22:57:55,857 - INFO - 
Epoch: 98, lr = 0.1
2025-08-27 22:57:56,035 - INFO - Epoch: [98][0/391] Time 0.176 (0.176) Data 0.159 (0.159) Loss 0.4707 (0.4707) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:57:57,667 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:57:57,667 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:57:57,977 - INFO - Epoch: [98][100/391] Time 0.013 (0.021) Data 0.000 (0.004) Loss 0.3758 (0.4228) Acc@1 88.281 (85.187) Acc@5 100.000 (99.428)
2025-08-27 22:57:59,777 - INFO - Epoch: [98][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4659 (0.4291) Acc@1 83.594 (84.966) Acc@5 99.219 (99.425)
2025-08-27 22:58:00,576 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:00,587 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:01,651 - INFO - Epoch: [98][300/391] Time 0.032 (0.019) Data 0.005 (0.003) Loss 0.3326 (0.4314) Acc@1 90.625 (84.962) Acc@5 99.219 (99.416)
2025-08-27 22:58:03,452 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.6515 (0.6515) Acc@1 78.125 (78.125) Acc@5 98.438 (98.438)
2025-08-27 22:58:04,319 - INFO - Epoch 98:
2025-08-27 22:58:04,319 - INFO -   Train: acc1: 85.0520 | acc5: 99.4160 | loss: 0.4317 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:04,319 - INFO -   Val:   acc1: 78.3800 | acc5: 98.0700 | loss: 0.6903
2025-08-27 22:58:04,319 - INFO -   LR: 0.100000
2025-08-27 22:58:04,333 - INFO - 
Epoch: 99, lr = 0.1
2025-08-27 22:58:04,514 - INFO - Epoch: [99][0/391] Time 0.180 (0.180) Data 0.152 (0.152) Loss 0.4282 (0.4282) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 22:58:04,702 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:04,702 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:06,395 - INFO - Epoch: [99][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.4748 (0.4336) Acc@1 85.156 (85.234) Acc@5 98.438 (99.404)
2025-08-27 22:58:07,682 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:07,682 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:08,179 - INFO - Epoch: [99][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.4115 (0.4361) Acc@1 84.375 (85.051) Acc@5 100.000 (99.413)
2025-08-27 22:58:09,977 - INFO - Epoch: [99][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3887 (0.4290) Acc@1 86.719 (85.333) Acc@5 97.656 (99.380)
2025-08-27 22:58:10,521 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:10,521 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:11,768 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.5133 (0.5133) Acc@1 82.812 (82.812) Acc@5 99.219 (99.219)
2025-08-27 22:58:12,615 - INFO - Epoch 99:
2025-08-27 22:58:12,615 - INFO -   Train: acc1: 85.3660 | acc5: 99.3940 | loss: 0.4271 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:12,615 - INFO -   Val:   acc1: 79.8700 | acc5: 98.9600 | loss: 0.6156
2025-08-27 22:58:12,615 - INFO -   LR: 0.010000
2025-08-27 22:58:12,630 - INFO - 
Epoch: 100, lr = 0.010000000000000002
2025-08-27 22:58:12,807 - INFO - Epoch: [100][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.3553 (0.3553) Acc@1 86.719 (86.719) Acc@5 98.438 (98.438)
2025-08-27 22:58:14,579 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:14,579 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:14,594 - INFO - Epoch: [100][100/391] Time 0.020 (0.019) Data 0.000 (0.003) Loss 0.2712 (0.3508) Acc@1 89.844 (87.879) Acc@5 100.000 (99.652)
2025-08-27 22:58:16,415 - INFO - Epoch: [100][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.4264 (0.3338) Acc@1 83.594 (88.623) Acc@5 98.438 (99.635)
2025-08-27 22:58:17,477 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:17,478 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:18,201 - INFO - Epoch: [100][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.2071 (0.3241) Acc@1 92.969 (88.935) Acc@5 100.000 (99.631)
2025-08-27 22:58:20,003 - INFO - Test: [0/79] Time 0.119 (0.119) Loss 0.3005 (0.3005) Acc@1 87.500 (87.500) Acc@5 100.000 (100.000)
2025-08-27 22:58:20,846 - INFO - Epoch 100:
2025-08-27 22:58:20,846 - INFO -   Train: acc1: 89.1020 | acc5: 99.6340 | loss: 0.3179 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:20,846 - INFO -   Val:   acc1: 88.1000 | acc5: 99.6700 | loss: 0.3416
2025-08-27 22:58:20,846 - INFO -   LR: 0.010000
2025-08-27 22:58:20,895 - INFO - Checkpoint saved: epoch=100, metric=88.1000
2025-08-27 22:58:20,927 - INFO - 
Epoch: 101, lr = 0.010000000000000002
2025-08-27 22:58:21,116 - INFO - Epoch: [101][0/391] Time 0.188 (0.188) Data 0.159 (0.159) Loss 0.3346 (0.3346) Acc@1 88.281 (88.281) Acc@5 98.438 (98.438)
2025-08-27 22:58:21,692 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:21,693 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:23,010 - INFO - Epoch: [101][100/391] Time 0.041 (0.021) Data 0.012 (0.003) Loss 0.2413 (0.2831) Acc@1 91.406 (90.316) Acc@5 100.000 (99.644)
2025-08-27 22:58:24,530 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:24,530 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:24,701 - INFO - Epoch: [101][200/391] Time 0.013 (0.019) Data 0.000 (0.002) Loss 0.2539 (0.2814) Acc@1 92.969 (90.368) Acc@5 98.438 (99.681)
2025-08-27 22:58:26,584 - INFO - Epoch: [101][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2814 (0.2811) Acc@1 90.625 (90.368) Acc@5 100.000 (99.720)
2025-08-27 22:58:27,458 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:27,458 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:28,365 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.2979 (0.2979) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:58:29,191 - INFO - Epoch 101:
2025-08-27 22:58:29,191 - INFO -   Train: acc1: 90.3140 | acc5: 99.7220 | loss: 0.2821 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:29,191 - INFO -   Val:   acc1: 88.5100 | acc5: 99.6400 | loss: 0.3296
2025-08-27 22:58:29,192 - INFO -   LR: 0.010000
2025-08-27 22:58:29,240 - INFO - Checkpoint saved: epoch=101, metric=88.5100
2025-08-27 22:58:29,272 - INFO - 
Epoch: 102, lr = 0.010000000000000002
2025-08-27 22:58:29,458 - INFO - Epoch: [102][0/391] Time 0.185 (0.185) Data 0.163 (0.163) Loss 0.2805 (0.2805) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 22:58:31,360 - INFO - Epoch: [102][100/391] Time 0.018 (0.021) Data 0.006 (0.003) Loss 0.2390 (0.2776) Acc@1 92.188 (90.463) Acc@5 100.000 (99.752)
2025-08-27 22:58:31,677 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:31,677 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:33,228 - INFO - Epoch: [102][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2681 (0.2723) Acc@1 91.406 (90.827) Acc@5 100.000 (99.775)
2025-08-27 22:58:34,599 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:34,599 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:35,056 - INFO - Epoch: [102][300/391] Time 0.018 (0.019) Data 0.000 (0.002) Loss 0.2677 (0.2711) Acc@1 90.625 (90.776) Acc@5 100.000 (99.753)
2025-08-27 22:58:36,864 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3042 (0.3042) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:58:37,672 - INFO - Epoch 102:
2025-08-27 22:58:37,672 - INFO -   Train: acc1: 90.8880 | acc5: 99.7480 | loss: 0.2687 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:37,672 - INFO -   Val:   acc1: 88.6100 | acc5: 99.6600 | loss: 0.3266
2025-08-27 22:58:37,672 - INFO -   LR: 0.010000
2025-08-27 22:58:37,721 - INFO - Checkpoint saved: epoch=102, metric=88.6100
2025-08-27 22:58:37,752 - INFO - 
Epoch: 103, lr = 0.010000000000000002
2025-08-27 22:58:37,940 - INFO - Epoch: [103][0/391] Time 0.187 (0.187) Data 0.165 (0.165) Loss 0.3790 (0.3790) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:58:38,743 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:38,744 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:39,765 - INFO - Epoch: [103][100/391] Time 0.022 (0.020) Data 0.012 (0.004) Loss 0.3653 (0.2612) Acc@1 87.500 (91.081) Acc@5 100.000 (99.752)
2025-08-27 22:58:41,630 - INFO - Epoch: [103][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2330 (0.2644) Acc@1 90.625 (90.812) Acc@5 100.000 (99.755)
2025-08-27 22:58:41,737 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:41,737 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:43,520 - INFO - Epoch: [103][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3914 (0.2628) Acc@1 87.500 (91.001) Acc@5 98.438 (99.735)
2025-08-27 22:58:44,780 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:44,781 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:45,346 - INFO - Test: [0/79] Time 0.142 (0.142) Loss 0.3236 (0.3236) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:58:46,149 - INFO - Epoch 103:
2025-08-27 22:58:46,149 - INFO -   Train: acc1: 90.9680 | acc5: 99.7440 | loss: 0.2638 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:46,150 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6700 | loss: 0.3304
2025-08-27 22:58:46,150 - INFO -   LR: 0.010000
2025-08-27 22:58:46,166 - INFO - 
Epoch: 104, lr = 0.010000000000000002
2025-08-27 22:58:46,364 - INFO - Epoch: [104][0/391] Time 0.196 (0.196) Data 0.166 (0.166) Loss 0.3053 (0.3053) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 22:58:48,211 - INFO - Epoch: [104][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2811 (0.2566) Acc@1 88.281 (91.120) Acc@5 99.219 (99.760)
2025-08-27 22:58:48,826 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:48,832 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:50,028 - INFO - Epoch: [104][200/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2380 (0.2607) Acc@1 92.188 (91.068) Acc@5 99.219 (99.775)
2025-08-27 22:58:51,724 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:51,724 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:51,797 - INFO - Epoch: [104][300/391] Time 0.022 (0.019) Data 0.010 (0.002) Loss 0.2047 (0.2613) Acc@1 94.531 (91.066) Acc@5 100.000 (99.740)
2025-08-27 22:58:53,517 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.3240 (0.3240) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:58:54,355 - INFO - Epoch 104:
2025-08-27 22:58:54,355 - INFO -   Train: acc1: 90.9520 | acc5: 99.7440 | loss: 0.2636 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:58:54,355 - INFO -   Val:   acc1: 88.8500 | acc5: 99.6600 | loss: 0.3234
2025-08-27 22:58:54,355 - INFO -   LR: 0.010000
2025-08-27 22:58:54,405 - INFO - Checkpoint saved: epoch=104, metric=88.8500
2025-08-27 22:58:54,436 - INFO - 
Epoch: 105, lr = 0.010000000000000002
2025-08-27 22:58:54,611 - INFO - Epoch: [105][0/391] Time 0.171 (0.171) Data 0.145 (0.145) Loss 0.2030 (0.2030) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:58:55,781 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:55,781 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:58:56,452 - INFO - Epoch: [105][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.2788 (0.2353) Acc@1 91.406 (92.017) Acc@5 100.000 (99.845)
2025-08-27 22:58:58,369 - INFO - Epoch: [105][200/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.1858 (0.2485) Acc@1 94.531 (91.488) Acc@5 100.000 (99.829)
2025-08-27 22:58:58,789 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:58:58,789 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:00,154 - INFO - Epoch: [105][300/391] Time 0.042 (0.019) Data 0.029 (0.004) Loss 0.2983 (0.2534) Acc@1 89.844 (91.341) Acc@5 100.000 (99.808)
2025-08-27 22:59:01,715 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:01,715 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:01,948 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2971 (0.2971) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:59:02,798 - INFO - Epoch 105:
2025-08-27 22:59:02,798 - INFO -   Train: acc1: 91.3020 | acc5: 99.8020 | loss: 0.2542 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:02,798 - INFO -   Val:   acc1: 88.8500 | acc5: 99.6700 | loss: 0.3342
2025-08-27 22:59:02,798 - INFO -   LR: 0.010000
2025-08-27 22:59:02,814 - INFO - 
Epoch: 106, lr = 0.010000000000000002
2025-08-27 22:59:02,996 - INFO - Epoch: [106][0/391] Time 0.182 (0.182) Data 0.164 (0.164) Loss 0.1805 (0.1805) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 22:59:04,835 - INFO - Epoch: [106][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1686 (0.2436) Acc@1 93.750 (91.723) Acc@5 100.000 (99.776)
2025-08-27 22:59:05,820 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:05,821 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:06,607 - INFO - Epoch: [106][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2242 (0.2447) Acc@1 92.188 (91.519) Acc@5 100.000 (99.825)
2025-08-27 22:59:08,406 - INFO - Epoch: [106][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.3856 (0.2486) Acc@1 89.062 (91.357) Acc@5 100.000 (99.816)
2025-08-27 22:59:08,658 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:08,658 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:10,122 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2878 (0.2878) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 22:59:10,945 - INFO - Epoch 106:
2025-08-27 22:59:10,945 - INFO -   Train: acc1: 91.3520 | acc5: 99.8020 | loss: 0.2514 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:10,945 - INFO -   Val:   acc1: 89.0100 | acc5: 99.6400 | loss: 0.3266
2025-08-27 22:59:10,945 - INFO -   LR: 0.010000
2025-08-27 22:59:11,449 - INFO - Checkpoint saved: epoch=106, metric=89.0100
2025-08-27 22:59:11,481 - INFO - 
Epoch: 107, lr = 0.010000000000000002
2025-08-27 22:59:11,653 - INFO - Epoch: [107][0/391] Time 0.171 (0.171) Data 0.151 (0.151) Loss 0.1520 (0.1520) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 22:59:13,134 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:13,135 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:13,437 - INFO - Epoch: [107][100/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1783 (0.2483) Acc@1 92.969 (91.429) Acc@5 100.000 (99.791)
2025-08-27 22:59:15,214 - INFO - Epoch: [107][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.3420 (0.2487) Acc@1 89.844 (91.453) Acc@5 99.219 (99.767)
2025-08-27 22:59:15,965 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:15,965 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:16,984 - INFO - Epoch: [107][300/391] Time 0.025 (0.018) Data 0.003 (0.002) Loss 0.2329 (0.2487) Acc@1 92.188 (91.476) Acc@5 99.219 (99.759)
2025-08-27 22:59:18,689 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3122 (0.3122) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 22:59:19,511 - INFO - Epoch 107:
2025-08-27 22:59:19,511 - INFO -   Train: acc1: 91.4040 | acc5: 99.7580 | loss: 0.2504 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:19,511 - INFO -   Val:   acc1: 89.0100 | acc5: 99.7300 | loss: 0.3216
2025-08-27 22:59:19,511 - INFO -   LR: 0.010000
2025-08-27 22:59:19,628 - INFO - 
Epoch: 108, lr = 0.010000000000000002
2025-08-27 22:59:19,812 - INFO - Epoch: [108][0/391] Time 0.182 (0.182) Data 0.159 (0.159) Loss 0.1740 (0.1740) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 22:59:20,001 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:20,001 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:21,553 - INFO - Epoch: [108][100/391] Time 0.027 (0.019) Data 0.009 (0.004) Loss 0.2707 (0.2490) Acc@1 89.844 (91.259) Acc@5 99.219 (99.822)
2025-08-27 22:59:22,815 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:22,815 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:23,289 - INFO - Epoch: [108][200/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.2897 (0.2519) Acc@1 88.281 (91.161) Acc@5 100.000 (99.798)
2025-08-27 22:59:25,054 - INFO - Epoch: [108][300/391] Time 0.024 (0.018) Data 0.000 (0.003) Loss 0.1839 (0.2529) Acc@1 92.969 (91.131) Acc@5 100.000 (99.803)
2025-08-27 22:59:25,574 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:25,574 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:26,757 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3306 (0.3306) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 22:59:27,597 - INFO - Epoch 108:
2025-08-27 22:59:27,597 - INFO -   Train: acc1: 91.0920 | acc5: 99.7880 | loss: 0.2539 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:27,597 - INFO -   Val:   acc1: 89.3200 | acc5: 99.6600 | loss: 0.3214
2025-08-27 22:59:27,597 - INFO -   LR: 0.010000
2025-08-27 22:59:27,743 - INFO - Checkpoint saved: epoch=108, metric=89.3200
2025-08-27 22:59:27,856 - INFO - 
Epoch: 109, lr = 0.010000000000000002
2025-08-27 22:59:28,027 - INFO - Epoch: [109][0/391] Time 0.169 (0.169) Data 0.143 (0.143) Loss 0.2294 (0.2294) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 22:59:29,795 - INFO - Epoch: [109][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2825 (0.2416) Acc@1 86.719 (91.607) Acc@5 99.219 (99.791)
2025-08-27 22:59:29,800 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:29,811 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:31,554 - INFO - Epoch: [109][200/391] Time 0.028 (0.018) Data 0.018 (0.004) Loss 0.2448 (0.2424) Acc@1 91.406 (91.608) Acc@5 99.219 (99.786)
2025-08-27 22:59:32,594 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:32,594 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:33,322 - INFO - Epoch: [109][300/391] Time 0.022 (0.018) Data 0.000 (0.003) Loss 0.2289 (0.2452) Acc@1 92.969 (91.539) Acc@5 100.000 (99.795)
2025-08-27 22:59:35,025 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.3528 (0.3528) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 22:59:35,872 - INFO - Epoch 109:
2025-08-27 22:59:35,872 - INFO -   Train: acc1: 91.5280 | acc5: 99.7800 | loss: 0.2464 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:35,872 - INFO -   Val:   acc1: 88.6000 | acc5: 99.6600 | loss: 0.3256
2025-08-27 22:59:35,872 - INFO -   LR: 0.010000
2025-08-27 22:59:35,922 - INFO - 
Epoch: 110, lr = 0.010000000000000002
2025-08-27 22:59:36,097 - INFO - Epoch: [110][0/391] Time 0.174 (0.174) Data 0.146 (0.146) Loss 0.1841 (0.1841) Acc@1 95.312 (95.312) Acc@5 99.219 (99.219)
2025-08-27 22:59:36,584 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:36,584 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:37,824 - INFO - Epoch: [110][100/391] Time 0.023 (0.019) Data 0.012 (0.004) Loss 0.3031 (0.2393) Acc@1 87.500 (91.909) Acc@5 100.000 (99.791)
2025-08-27 22:59:39,461 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:39,462 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:39,614 - INFO - Epoch: [110][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1891 (0.2432) Acc@1 96.875 (91.655) Acc@5 100.000 (99.817)
2025-08-27 22:59:41,425 - INFO - Epoch: [110][300/391] Time 0.028 (0.018) Data 0.018 (0.003) Loss 0.2787 (0.2460) Acc@1 90.625 (91.489) Acc@5 100.000 (99.813)
2025-08-27 22:59:42,306 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:42,306 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:43,165 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3273 (0.3273) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 22:59:43,988 - INFO - Epoch 110:
2025-08-27 22:59:43,988 - INFO -   Train: acc1: 91.4780 | acc5: 99.8120 | loss: 0.2459 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:43,988 - INFO -   Val:   acc1: 88.7700 | acc5: 99.6800 | loss: 0.3298
2025-08-27 22:59:43,988 - INFO -   LR: 0.010000
2025-08-27 22:59:44,355 - INFO - 
Epoch: 111, lr = 0.010000000000000002
2025-08-27 22:59:44,527 - INFO - Epoch: [111][0/391] Time 0.171 (0.171) Data 0.142 (0.142) Loss 0.1441 (0.1441) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 22:59:46,309 - INFO - Epoch: [111][100/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.2664 (0.2366) Acc@1 91.406 (91.894) Acc@5 99.219 (99.783)
2025-08-27 22:59:46,635 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:46,635 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:48,142 - INFO - Epoch: [111][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.2488 (0.2416) Acc@1 89.844 (91.667) Acc@5 100.000 (99.821)
2025-08-27 22:59:49,574 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:49,574 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:50,007 - INFO - Epoch: [111][300/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.2270 (0.2444) Acc@1 92.969 (91.546) Acc@5 100.000 (99.790)
2025-08-27 22:59:51,694 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3113 (0.3113) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 22:59:52,587 - INFO - Epoch 111:
2025-08-27 22:59:52,587 - INFO -   Train: acc1: 91.5100 | acc5: 99.7820 | loss: 0.2446 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 22:59:52,587 - INFO -   Val:   acc1: 88.9300 | acc5: 99.6900 | loss: 0.3219
2025-08-27 22:59:52,587 - INFO -   LR: 0.010000
2025-08-27 22:59:52,603 - INFO - 
Epoch: 112, lr = 0.010000000000000002
2025-08-27 22:59:52,783 - INFO - Epoch: [112][0/391] Time 0.179 (0.179) Data 0.150 (0.150) Loss 0.1923 (0.1923) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 22:59:53,591 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:53,591 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:54,514 - INFO - Epoch: [112][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3458 (0.2370) Acc@1 85.156 (91.801) Acc@5 100.000 (99.853)
2025-08-27 22:59:56,312 - INFO - Epoch: [112][200/391] Time 0.018 (0.018) Data 0.000 (0.003) Loss 0.2198 (0.2370) Acc@1 91.406 (91.768) Acc@5 100.000 (99.841)
2025-08-27 22:59:56,449 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:56,452 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:58,187 - INFO - Epoch: [112][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.2202 (0.2366) Acc@1 90.625 (91.824) Acc@5 100.000 (99.831)
2025-08-27 22:59:59,425 - INFO - Pruning info: sparsity=0.900
2025-08-27 22:59:59,425 - INFO -   Reactivation rate: 0.0000
2025-08-27 22:59:59,929 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3174 (0.3174) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:00:00,767 - INFO - Epoch 112:
2025-08-27 23:00:00,767 - INFO -   Train: acc1: 91.6380 | acc5: 99.8100 | loss: 0.2419 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:00,767 - INFO -   Val:   acc1: 88.8800 | acc5: 99.6500 | loss: 0.3327
2025-08-27 23:00:00,767 - INFO -   LR: 0.010000
2025-08-27 23:00:00,781 - INFO - 
Epoch: 113, lr = 0.010000000000000002
2025-08-27 23:00:00,994 - INFO - Epoch: [113][0/391] Time 0.212 (0.212) Data 0.184 (0.184) Loss 0.2393 (0.2393) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:00:02,783 - INFO - Epoch: [113][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.2307 (0.2348) Acc@1 92.188 (92.017) Acc@5 100.000 (99.776)
2025-08-27 23:00:03,434 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:03,435 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:04,617 - INFO - Epoch: [113][200/391] Time 0.030 (0.019) Data 0.019 (0.004) Loss 0.2122 (0.2361) Acc@1 92.188 (91.927) Acc@5 100.000 (99.806)
2025-08-27 23:00:06,361 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:06,361 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:06,436 - INFO - Epoch: [113][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.3032 (0.2396) Acc@1 92.188 (91.785) Acc@5 100.000 (99.818)
2025-08-27 23:00:08,165 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3722 (0.3722) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:00:08,995 - INFO - Epoch 113:
2025-08-27 23:00:08,995 - INFO -   Train: acc1: 91.6580 | acc5: 99.7900 | loss: 0.2431 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:08,995 - INFO -   Val:   acc1: 88.7800 | acc5: 99.6900 | loss: 0.3344
2025-08-27 23:00:08,995 - INFO -   LR: 0.010000
2025-08-27 23:00:09,010 - INFO - 
Epoch: 114, lr = 0.010000000000000002
2025-08-27 23:00:09,197 - INFO - Epoch: [114][0/391] Time 0.186 (0.186) Data 0.152 (0.152) Loss 0.1501 (0.1501) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 23:00:10,406 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:10,406 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:11,008 - INFO - Epoch: [114][100/391] Time 0.024 (0.020) Data 0.008 (0.005) Loss 0.3408 (0.2359) Acc@1 90.625 (91.739) Acc@5 98.438 (99.845)
2025-08-27 23:00:12,788 - INFO - Epoch: [114][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.3042 (0.2408) Acc@1 87.500 (91.651) Acc@5 100.000 (99.790)
2025-08-27 23:00:13,223 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:13,224 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:14,536 - INFO - Epoch: [114][300/391] Time 0.023 (0.018) Data 0.000 (0.003) Loss 0.1186 (0.2415) Acc@1 97.656 (91.611) Acc@5 100.000 (99.795)
2025-08-27 23:00:16,009 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:16,010 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:16,247 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3624 (0.3624) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:00:17,130 - INFO - Epoch 114:
2025-08-27 23:00:17,130 - INFO -   Train: acc1: 91.5180 | acc5: 99.8020 | loss: 0.2440 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:17,130 - INFO -   Val:   acc1: 88.3200 | acc5: 99.6300 | loss: 0.3379
2025-08-27 23:00:17,130 - INFO -   LR: 0.010000
2025-08-27 23:00:17,146 - INFO - 
Epoch: 115, lr = 0.010000000000000002
2025-08-27 23:00:17,319 - INFO - Epoch: [115][0/391] Time 0.172 (0.172) Data 0.134 (0.134) Loss 0.2890 (0.2890) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:00:19,069 - INFO - Epoch: [115][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2691 (0.2284) Acc@1 92.188 (92.079) Acc@5 100.000 (99.830)
2025-08-27 23:00:20,014 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:20,014 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:20,834 - INFO - Epoch: [115][200/391] Time 0.025 (0.018) Data 0.000 (0.003) Loss 0.3092 (0.2305) Acc@1 91.406 (92.094) Acc@5 100.000 (99.833)
2025-08-27 23:00:22,612 - INFO - Epoch: [115][300/391] Time 0.013 (0.018) Data 0.000 (0.003) Loss 0.2812 (0.2341) Acc@1 90.625 (91.946) Acc@5 100.000 (99.798)
2025-08-27 23:00:22,889 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:22,890 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:24,355 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.3022 (0.3022) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:00:25,212 - INFO - Epoch 115:
2025-08-27 23:00:25,213 - INFO -   Train: acc1: 91.7700 | acc5: 99.7840 | loss: 0.2384 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:25,213 - INFO -   Val:   acc1: 88.9200 | acc5: 99.5800 | loss: 0.3235
2025-08-27 23:00:25,213 - INFO -   LR: 0.010000
2025-08-27 23:00:25,230 - INFO - 
Epoch: 116, lr = 0.010000000000000002
2025-08-27 23:00:25,399 - INFO - Epoch: [116][0/391] Time 0.169 (0.169) Data 0.150 (0.150) Loss 0.3809 (0.3809) Acc@1 83.594 (83.594) Acc@5 100.000 (100.000)
2025-08-27 23:00:26,845 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:26,845 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:27,141 - INFO - Epoch: [116][100/391] Time 0.044 (0.019) Data 0.028 (0.004) Loss 0.2481 (0.2361) Acc@1 89.844 (91.870) Acc@5 99.219 (99.876)
2025-08-27 23:00:28,930 - INFO - Epoch: [116][200/391] Time 0.025 (0.018) Data 0.000 (0.004) Loss 0.2631 (0.2422) Acc@1 89.062 (91.573) Acc@5 100.000 (99.821)
2025-08-27 23:00:29,661 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:29,661 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:30,626 - INFO - Epoch: [116][300/391] Time 0.031 (0.018) Data 0.021 (0.003) Loss 0.2329 (0.2414) Acc@1 89.844 (91.588) Acc@5 100.000 (99.836)
2025-08-27 23:00:32,360 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3374 (0.3374) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:00:33,212 - INFO - Epoch 116:
2025-08-27 23:00:33,212 - INFO -   Train: acc1: 91.5000 | acc5: 99.8260 | loss: 0.2436 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:33,212 - INFO -   Val:   acc1: 89.0800 | acc5: 99.7000 | loss: 0.3235
2025-08-27 23:00:33,212 - INFO -   LR: 0.010000
2025-08-27 23:00:33,229 - INFO - 
Epoch: 117, lr = 0.010000000000000002
2025-08-27 23:00:33,402 - INFO - Epoch: [117][0/391] Time 0.173 (0.173) Data 0.147 (0.147) Loss 0.2504 (0.2504) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:00:33,618 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:33,618 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:35,125 - INFO - Epoch: [117][100/391] Time 0.022 (0.019) Data 0.000 (0.004) Loss 0.2039 (0.2383) Acc@1 92.188 (91.878) Acc@5 100.000 (99.737)
2025-08-27 23:00:36,380 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:36,380 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:36,879 - INFO - Epoch: [117][200/391] Time 0.020 (0.018) Data 0.000 (0.004) Loss 0.2872 (0.2385) Acc@1 89.062 (91.741) Acc@5 99.219 (99.778)
2025-08-27 23:00:38,608 - INFO - Epoch: [117][300/391] Time 0.020 (0.018) Data 0.000 (0.003) Loss 0.2883 (0.2391) Acc@1 89.062 (91.759) Acc@5 100.000 (99.790)
2025-08-27 23:00:39,232 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:39,232 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:40,313 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.3511 (0.3511) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:00:41,169 - INFO - Epoch 117:
2025-08-27 23:00:41,169 - INFO -   Train: acc1: 91.6140 | acc5: 99.7920 | loss: 0.2422 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:41,169 - INFO -   Val:   acc1: 88.7600 | acc5: 99.6700 | loss: 0.3292
2025-08-27 23:00:41,169 - INFO -   LR: 0.010000
2025-08-27 23:00:41,185 - INFO - 
Epoch: 118, lr = 0.010000000000000002
2025-08-27 23:00:41,369 - INFO - Epoch: [118][0/391] Time 0.183 (0.183) Data 0.163 (0.163) Loss 0.2998 (0.2998) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:00:43,119 - INFO - Epoch: [118][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.3192 (0.2395) Acc@1 89.062 (91.654) Acc@5 100.000 (99.830)
2025-08-27 23:00:43,145 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:43,145 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:44,924 - INFO - Epoch: [118][200/391] Time 0.022 (0.019) Data 0.000 (0.002) Loss 0.2032 (0.2392) Acc@1 92.188 (91.717) Acc@5 100.000 (99.852)
2025-08-27 23:00:46,017 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:46,017 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:46,723 - INFO - Epoch: [118][300/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.2536 (0.2387) Acc@1 90.625 (91.720) Acc@5 100.000 (99.839)
2025-08-27 23:00:48,425 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3124 (0.3124) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:00:49,319 - INFO - Epoch 118:
2025-08-27 23:00:49,319 - INFO -   Train: acc1: 91.6000 | acc5: 99.8240 | loss: 0.2427 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:49,319 - INFO -   Val:   acc1: 88.7100 | acc5: 99.6400 | loss: 0.3349
2025-08-27 23:00:49,319 - INFO -   LR: 0.010000
2025-08-27 23:00:49,335 - INFO - 
Epoch: 119, lr = 0.010000000000000002
2025-08-27 23:00:49,480 - INFO - Epoch: [119][0/391] Time 0.145 (0.145) Data 0.123 (0.123) Loss 0.2634 (0.2634) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:00:50,014 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:50,015 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:51,289 - INFO - Epoch: [119][100/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.0885 (0.2335) Acc@1 97.656 (91.994) Acc@5 100.000 (99.822)
2025-08-27 23:00:52,868 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:52,868 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:53,043 - INFO - Epoch: [119][200/391] Time 0.024 (0.018) Data 0.000 (0.003) Loss 0.2407 (0.2368) Acc@1 91.406 (91.830) Acc@5 100.000 (99.856)
2025-08-27 23:00:54,770 - INFO - Epoch: [119][300/391] Time 0.024 (0.018) Data 0.013 (0.003) Loss 0.2525 (0.2382) Acc@1 89.844 (91.822) Acc@5 100.000 (99.839)
2025-08-27 23:00:55,660 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:55,660 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:00:56,499 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3385 (0.3385) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:00:57,350 - INFO - Epoch 119:
2025-08-27 23:00:57,350 - INFO -   Train: acc1: 91.6700 | acc5: 99.8360 | loss: 0.2405 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:00:57,350 - INFO -   Val:   acc1: 89.2000 | acc5: 99.5600 | loss: 0.3273
2025-08-27 23:00:57,350 - INFO -   LR: 0.010000
2025-08-27 23:00:57,366 - INFO - 
Epoch: 120, lr = 0.010000000000000002
2025-08-27 23:00:57,553 - INFO - Epoch: [120][0/391] Time 0.186 (0.186) Data 0.159 (0.159) Loss 0.2435 (0.2435) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:00:59,291 - INFO - Epoch: [120][100/391] Time 0.023 (0.019) Data 0.012 (0.003) Loss 0.2416 (0.2357) Acc@1 92.969 (91.855) Acc@5 99.219 (99.752)
2025-08-27 23:00:59,617 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:00:59,617 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:01,027 - INFO - Epoch: [120][200/391] Time 0.016 (0.018) Data 0.001 (0.003) Loss 0.1951 (0.2407) Acc@1 92.188 (91.803) Acc@5 100.000 (99.763)
2025-08-27 23:01:02,416 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:02,416 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:02,774 - INFO - Epoch: [120][300/391] Time 0.020 (0.018) Data 0.000 (0.003) Loss 0.2031 (0.2401) Acc@1 93.750 (91.764) Acc@5 100.000 (99.782)
2025-08-27 23:01:04,469 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3774 (0.3774) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:01:05,295 - INFO - Epoch 120:
2025-08-27 23:01:05,295 - INFO -   Train: acc1: 91.6540 | acc5: 99.7980 | loss: 0.2420 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:05,295 - INFO -   Val:   acc1: 88.3400 | acc5: 99.6100 | loss: 0.3509
2025-08-27 23:01:05,295 - INFO -   LR: 0.010000
2025-08-27 23:01:05,345 - INFO - 
Epoch: 121, lr = 0.010000000000000002
2025-08-27 23:01:05,513 - INFO - Epoch: [121][0/391] Time 0.167 (0.167) Data 0.140 (0.140) Loss 0.2463 (0.2463) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:01:06,389 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:06,389 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:07,300 - INFO - Epoch: [121][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2004 (0.2336) Acc@1 92.188 (92.102) Acc@5 100.000 (99.838)
2025-08-27 23:01:09,038 - INFO - Epoch: [121][200/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.2740 (0.2410) Acc@1 90.625 (91.655) Acc@5 99.219 (99.821)
2025-08-27 23:01:09,163 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:09,164 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:10,794 - INFO - Epoch: [121][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.4251 (0.2445) Acc@1 91.406 (91.614) Acc@5 100.000 (99.824)
2025-08-27 23:01:11,955 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:11,955 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:12,469 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.3713 (0.3713) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:01:13,309 - INFO - Epoch 121:
2025-08-27 23:01:13,309 - INFO -   Train: acc1: 91.5840 | acc5: 99.8260 | loss: 0.2444 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:13,309 - INFO -   Val:   acc1: 88.6000 | acc5: 99.5800 | loss: 0.3351
2025-08-27 23:01:13,309 - INFO -   LR: 0.010000
2025-08-27 23:01:13,326 - INFO - 
Epoch: 122, lr = 0.010000000000000002
2025-08-27 23:01:13,503 - INFO - Epoch: [122][0/391] Time 0.176 (0.176) Data 0.155 (0.155) Loss 0.1975 (0.1975) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:01:15,293 - INFO - Epoch: [122][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2875 (0.2361) Acc@1 87.500 (91.832) Acc@5 100.000 (99.830)
2025-08-27 23:01:16,076 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:16,076 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:17,145 - INFO - Epoch: [122][200/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.2272 (0.2451) Acc@1 92.188 (91.484) Acc@5 99.219 (99.817)
2025-08-27 23:01:18,956 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:18,956 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:18,996 - INFO - Epoch: [122][300/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.3183 (0.2421) Acc@1 89.844 (91.518) Acc@5 100.000 (99.798)
2025-08-27 23:01:20,872 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.3813 (0.3813) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:01:21,673 - INFO - Epoch 122:
2025-08-27 23:01:21,673 - INFO -   Train: acc1: 91.4740 | acc5: 99.7940 | loss: 0.2442 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:21,673 - INFO -   Val:   acc1: 88.1900 | acc5: 99.7000 | loss: 0.3359
2025-08-27 23:01:21,673 - INFO -   LR: 0.010000
2025-08-27 23:01:21,690 - INFO - 
Epoch: 123, lr = 0.010000000000000002
2025-08-27 23:01:21,848 - INFO - Epoch: [123][0/391] Time 0.158 (0.158) Data 0.135 (0.135) Loss 0.2353 (0.2353) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:01:23,043 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:23,043 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:23,672 - INFO - Epoch: [123][100/391] Time 0.014 (0.020) Data 0.000 (0.004) Loss 0.2070 (0.2477) Acc@1 95.312 (91.360) Acc@5 100.000 (99.822)
2025-08-27 23:01:25,461 - INFO - Epoch: [123][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2514 (0.2394) Acc@1 92.188 (91.709) Acc@5 100.000 (99.833)
2025-08-27 23:01:25,921 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:25,921 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:27,271 - INFO - Epoch: [123][300/391] Time 0.038 (0.019) Data 0.028 (0.003) Loss 0.2801 (0.2396) Acc@1 89.062 (91.591) Acc@5 100.000 (99.818)
2025-08-27 23:01:28,856 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:28,856 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:29,071 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.2891 (0.2891) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:01:29,910 - INFO - Epoch 123:
2025-08-27 23:01:29,910 - INFO -   Train: acc1: 91.4560 | acc5: 99.8120 | loss: 0.2432 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:29,910 - INFO -   Val:   acc1: 88.5700 | acc5: 99.6600 | loss: 0.3446
2025-08-27 23:01:29,910 - INFO -   LR: 0.010000
2025-08-27 23:01:29,925 - INFO - 
Epoch: 124, lr = 0.010000000000000002
2025-08-27 23:01:30,095 - INFO - Epoch: [124][0/391] Time 0.169 (0.169) Data 0.138 (0.138) Loss 0.2444 (0.2444) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:01:31,898 - INFO - Epoch: [124][100/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.2707 (0.2335) Acc@1 91.406 (92.056) Acc@5 100.000 (99.830)
2025-08-27 23:01:32,907 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:32,907 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:33,737 - INFO - Epoch: [124][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2422 (0.2391) Acc@1 91.406 (91.884) Acc@5 99.219 (99.821)
2025-08-27 23:01:35,579 - INFO - Epoch: [124][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.2174 (0.2433) Acc@1 92.188 (91.674) Acc@5 99.219 (99.813)
2025-08-27 23:01:35,820 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:35,820 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:37,328 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2913 (0.2913) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:01:38,176 - INFO - Epoch 124:
2025-08-27 23:01:38,176 - INFO -   Train: acc1: 91.5540 | acc5: 99.7980 | loss: 0.2458 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:38,176 - INFO -   Val:   acc1: 88.3000 | acc5: 99.5900 | loss: 0.3418
2025-08-27 23:01:38,176 - INFO -   LR: 0.010000
2025-08-27 23:01:38,195 - INFO - 
Epoch: 125, lr = 0.010000000000000002
2025-08-27 23:01:38,359 - INFO - Epoch: [125][0/391] Time 0.164 (0.164) Data 0.136 (0.136) Loss 0.2625 (0.2625) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:01:39,920 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:39,920 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:40,227 - INFO - Epoch: [125][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.1885 (0.2379) Acc@1 94.531 (91.785) Acc@5 100.000 (99.783)
2025-08-27 23:01:42,064 - INFO - Epoch: [125][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1759 (0.2390) Acc@1 95.312 (91.779) Acc@5 100.000 (99.817)
2025-08-27 23:01:42,860 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:42,860 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:43,891 - INFO - Epoch: [125][300/391] Time 0.023 (0.019) Data 0.000 (0.003) Loss 0.1596 (0.2429) Acc@1 94.531 (91.619) Acc@5 100.000 (99.798)
2025-08-27 23:01:45,692 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.3175 (0.3175) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:01:46,557 - INFO - Epoch 125:
2025-08-27 23:01:46,557 - INFO -   Train: acc1: 91.5680 | acc5: 99.7980 | loss: 0.2437 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:46,557 - INFO -   Val:   acc1: 88.3600 | acc5: 99.7400 | loss: 0.3397
2025-08-27 23:01:46,557 - INFO -   LR: 0.010000
2025-08-27 23:01:46,573 - INFO - 
Epoch: 126, lr = 0.010000000000000002
2025-08-27 23:01:46,782 - INFO - Epoch: [126][0/391] Time 0.208 (0.208) Data 0.185 (0.185) Loss 0.3998 (0.3998) Acc@1 89.844 (89.844) Acc@5 98.438 (98.438)
2025-08-27 23:01:47,039 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:47,039 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:48,630 - INFO - Epoch: [126][100/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.2884 (0.2440) Acc@1 90.625 (91.708) Acc@5 99.219 (99.799)
2025-08-27 23:01:49,928 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:49,928 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:50,454 - INFO - Epoch: [126][200/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.1915 (0.2468) Acc@1 92.188 (91.468) Acc@5 100.000 (99.802)
2025-08-27 23:01:52,261 - INFO - Epoch: [126][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.2497 (0.2458) Acc@1 91.406 (91.471) Acc@5 99.219 (99.805)
2025-08-27 23:01:52,834 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:52,834 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:54,011 - INFO - Test: [0/79] Time 0.149 (0.149) Loss 0.3739 (0.3739) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:01:54,845 - INFO - Epoch 126:
2025-08-27 23:01:54,846 - INFO -   Train: acc1: 91.4060 | acc5: 99.7840 | loss: 0.2485 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:01:54,846 - INFO -   Val:   acc1: 87.7500 | acc5: 99.6300 | loss: 0.3700
2025-08-27 23:01:54,846 - INFO -   LR: 0.010000
2025-08-27 23:01:54,863 - INFO - 
Epoch: 127, lr = 0.010000000000000002
2025-08-27 23:01:55,029 - INFO - Epoch: [127][0/391] Time 0.166 (0.166) Data 0.144 (0.144) Loss 0.2006 (0.2006) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:01:56,839 - INFO - Epoch: [127][100/391] Time 0.013 (0.020) Data 0.002 (0.005) Loss 0.2647 (0.2416) Acc@1 89.844 (91.754) Acc@5 100.000 (99.807)
2025-08-27 23:01:56,870 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:56,871 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:01:58,649 - INFO - Epoch: [127][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.3265 (0.2413) Acc@1 85.938 (91.647) Acc@5 99.219 (99.833)
2025-08-27 23:01:59,722 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:01:59,722 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:00,443 - INFO - Epoch: [127][300/391] Time 0.028 (0.019) Data 0.012 (0.004) Loss 0.2826 (0.2434) Acc@1 92.969 (91.572) Acc@5 100.000 (99.816)
2025-08-27 23:02:02,236 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.3317 (0.3317) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:02:03,091 - INFO - Epoch 127:
2025-08-27 23:02:03,091 - INFO -   Train: acc1: 91.4820 | acc5: 99.8040 | loss: 0.2461 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:03,091 - INFO -   Val:   acc1: 87.0700 | acc5: 99.5200 | loss: 0.3918
2025-08-27 23:02:03,091 - INFO -   LR: 0.010000
2025-08-27 23:02:03,108 - INFO - 
Epoch: 128, lr = 0.010000000000000002
2025-08-27 23:02:03,296 - INFO - Epoch: [128][0/391] Time 0.188 (0.188) Data 0.161 (0.161) Loss 0.2311 (0.2311) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:02:03,834 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:03,834 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:05,117 - INFO - Epoch: [128][100/391] Time 0.017 (0.020) Data 0.000 (0.005) Loss 0.1667 (0.2353) Acc@1 93.750 (91.832) Acc@5 100.000 (99.861)
2025-08-27 23:02:06,744 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:06,745 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:06,909 - INFO - Epoch: [128][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1702 (0.2412) Acc@1 95.312 (91.624) Acc@5 100.000 (99.817)
2025-08-27 23:02:08,755 - INFO - Epoch: [128][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1869 (0.2450) Acc@1 93.750 (91.494) Acc@5 100.000 (99.808)
2025-08-27 23:02:09,715 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:09,716 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:10,543 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3575 (0.3575) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:02:11,358 - INFO - Epoch 128:
2025-08-27 23:02:11,359 - INFO -   Train: acc1: 91.4660 | acc5: 99.8060 | loss: 0.2465 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:11,359 - INFO -   Val:   acc1: 88.9400 | acc5: 99.6300 | loss: 0.3381
2025-08-27 23:02:11,359 - INFO -   LR: 0.010000
2025-08-27 23:02:11,376 - INFO - 
Epoch: 129, lr = 0.010000000000000002
2025-08-27 23:02:11,567 - INFO - Epoch: [129][0/391] Time 0.190 (0.190) Data 0.159 (0.159) Loss 0.2009 (0.2009) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:02:13,300 - INFO - Epoch: [129][100/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.2681 (0.2448) Acc@1 90.625 (91.329) Acc@5 100.000 (99.752)
2025-08-27 23:02:13,649 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:13,649 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:15,128 - INFO - Epoch: [129][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2254 (0.2461) Acc@1 93.750 (91.453) Acc@5 100.000 (99.751)
2025-08-27 23:02:16,664 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:16,668 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:17,053 - INFO - Epoch: [129][300/391] Time 0.030 (0.019) Data 0.012 (0.002) Loss 0.2293 (0.2471) Acc@1 91.406 (91.388) Acc@5 100.000 (99.769)
2025-08-27 23:02:18,805 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3291 (0.3291) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:02:19,646 - INFO - Epoch 129:
2025-08-27 23:02:19,646 - INFO -   Train: acc1: 91.2140 | acc5: 99.7620 | loss: 0.2521 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:19,646 - INFO -   Val:   acc1: 87.5200 | acc5: 99.6600 | loss: 0.3713
2025-08-27 23:02:19,647 - INFO -   LR: 0.010000
2025-08-27 23:02:19,665 - INFO - 
Epoch: 130, lr = 0.010000000000000002
2025-08-27 23:02:19,795 - INFO - Epoch: [130][0/391] Time 0.130 (0.130) Data 0.106 (0.106) Loss 0.2701 (0.2701) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:02:20,762 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:20,762 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:21,745 - INFO - Epoch: [130][100/391] Time 0.012 (0.021) Data 0.000 (0.005) Loss 0.2284 (0.2386) Acc@1 90.625 (91.368) Acc@5 100.000 (99.853)
2025-08-27 23:02:23,538 - INFO - Epoch: [130][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1736 (0.2443) Acc@1 92.969 (91.290) Acc@5 100.000 (99.837)
2025-08-27 23:02:23,732 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:23,732 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:25,342 - INFO - Epoch: [130][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.3470 (0.2494) Acc@1 89.062 (91.214) Acc@5 100.000 (99.813)
2025-08-27 23:02:26,618 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:26,618 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:27,140 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2716 (0.2716) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:02:27,986 - INFO - Epoch 130:
2025-08-27 23:02:27,986 - INFO -   Train: acc1: 91.2600 | acc5: 99.8160 | loss: 0.2496 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:27,987 - INFO -   Val:   acc1: 88.6500 | acc5: 99.7000 | loss: 0.3318
2025-08-27 23:02:27,987 - INFO -   LR: 0.010000
2025-08-27 23:02:28,036 - INFO - 
Epoch: 131, lr = 0.010000000000000002
2025-08-27 23:02:28,213 - INFO - Epoch: [131][0/391] Time 0.176 (0.176) Data 0.154 (0.154) Loss 0.1601 (0.1601) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:02:30,038 - INFO - Epoch: [131][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2755 (0.2431) Acc@1 90.625 (91.515) Acc@5 99.219 (99.768)
2025-08-27 23:02:30,714 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:30,714 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:31,810 - INFO - Epoch: [131][200/391] Time 0.013 (0.019) Data 0.001 (0.003) Loss 0.2030 (0.2429) Acc@1 93.750 (91.500) Acc@5 100.000 (99.794)
2025-08-27 23:02:33,536 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:33,536 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:33,582 - INFO - Epoch: [131][300/391] Time 0.034 (0.018) Data 0.023 (0.003) Loss 0.4118 (0.2444) Acc@1 85.938 (91.492) Acc@5 99.219 (99.790)
2025-08-27 23:02:35,333 - INFO - Test: [0/79] Time 0.141 (0.141) Loss 0.2930 (0.2930) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:02:36,169 - INFO - Epoch 131:
2025-08-27 23:02:36,169 - INFO -   Train: acc1: 91.4220 | acc5: 99.7820 | loss: 0.2469 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:36,169 - INFO -   Val:   acc1: 88.2600 | acc5: 99.6800 | loss: 0.3474
2025-08-27 23:02:36,169 - INFO -   LR: 0.010000
2025-08-27 23:02:36,186 - INFO - 
Epoch: 132, lr = 0.010000000000000002
2025-08-27 23:02:36,382 - INFO - Epoch: [132][0/391] Time 0.195 (0.195) Data 0.169 (0.169) Loss 0.3024 (0.3024) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:02:37,552 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:37,552 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:38,111 - INFO - Epoch: [132][100/391] Time 0.031 (0.019) Data 0.000 (0.004) Loss 0.2207 (0.2464) Acc@1 93.750 (91.445) Acc@5 100.000 (99.868)
2025-08-27 23:02:39,848 - INFO - Epoch: [132][200/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1984 (0.2426) Acc@1 92.188 (91.643) Acc@5 100.000 (99.848)
2025-08-27 23:02:40,366 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:40,366 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:41,724 - INFO - Epoch: [132][300/391] Time 0.024 (0.018) Data 0.000 (0.003) Loss 0.2232 (0.2431) Acc@1 91.406 (91.546) Acc@5 100.000 (99.834)
2025-08-27 23:02:43,255 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:43,255 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:43,452 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.3274 (0.3274) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:02:44,351 - INFO - Epoch 132:
2025-08-27 23:02:44,351 - INFO -   Train: acc1: 91.3560 | acc5: 99.8200 | loss: 0.2482 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:44,351 - INFO -   Val:   acc1: 87.7900 | acc5: 99.6500 | loss: 0.3640
2025-08-27 23:02:44,351 - INFO -   LR: 0.010000
2025-08-27 23:02:44,369 - INFO - 
Epoch: 133, lr = 0.010000000000000002
2025-08-27 23:02:44,522 - INFO - Epoch: [133][0/391] Time 0.152 (0.152) Data 0.131 (0.131) Loss 0.1953 (0.1953) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:02:46,287 - INFO - Epoch: [133][100/391] Time 0.010 (0.019) Data 0.000 (0.003) Loss 0.2679 (0.2470) Acc@1 90.625 (91.476) Acc@5 99.219 (99.799)
2025-08-27 23:02:47,335 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:47,335 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:48,086 - INFO - Epoch: [133][200/391] Time 0.036 (0.018) Data 0.021 (0.003) Loss 0.2481 (0.2463) Acc@1 92.188 (91.406) Acc@5 100.000 (99.817)
2025-08-27 23:02:49,833 - INFO - Epoch: [133][300/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.2965 (0.2480) Acc@1 88.281 (91.308) Acc@5 98.438 (99.777)
2025-08-27 23:02:50,149 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:50,149 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:51,560 - INFO - Test: [0/79] Time 0.128 (0.128) Loss 0.3489 (0.3489) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:02:52,388 - INFO - Epoch 133:
2025-08-27 23:02:52,389 - INFO -   Train: acc1: 91.2800 | acc5: 99.7780 | loss: 0.2490 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:02:52,389 - INFO -   Val:   acc1: 88.3000 | acc5: 99.7600 | loss: 0.3405
2025-08-27 23:02:52,389 - INFO -   LR: 0.010000
2025-08-27 23:02:52,405 - INFO - 
Epoch: 134, lr = 0.010000000000000002
2025-08-27 23:02:52,650 - INFO - Epoch: [134][0/391] Time 0.243 (0.243) Data 0.222 (0.222) Loss 0.2170 (0.2170) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:02:54,186 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:54,187 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:54,453 - INFO - Epoch: [134][100/391] Time 0.012 (0.020) Data 0.000 (0.004) Loss 0.2792 (0.2424) Acc@1 92.969 (91.677) Acc@5 100.000 (99.830)
2025-08-27 23:02:56,253 - INFO - Epoch: [134][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2257 (0.2453) Acc@1 92.969 (91.414) Acc@5 100.000 (99.802)
2025-08-27 23:02:57,059 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:02:57,060 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:02:58,127 - INFO - Epoch: [134][300/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.3120 (0.2477) Acc@1 89.062 (91.339) Acc@5 99.219 (99.800)
2025-08-27 23:02:59,883 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3217 (0.3217) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:03:00,710 - INFO - Epoch 134:
2025-08-27 23:03:00,710 - INFO -   Train: acc1: 91.2820 | acc5: 99.8020 | loss: 0.2491 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:00,710 - INFO -   Val:   acc1: 87.3900 | acc5: 99.6200 | loss: 0.3728
2025-08-27 23:03:00,710 - INFO -   LR: 0.010000
2025-08-27 23:03:00,725 - INFO - 
Epoch: 135, lr = 0.010000000000000002
2025-08-27 23:03:00,902 - INFO - Epoch: [135][0/391] Time 0.176 (0.176) Data 0.149 (0.149) Loss 0.3217 (0.3217) Acc@1 92.188 (92.188) Acc@5 98.438 (98.438)
2025-08-27 23:03:01,169 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:01,170 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:02,681 - INFO - Epoch: [135][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2876 (0.2444) Acc@1 92.969 (91.515) Acc@5 100.000 (99.822)
2025-08-27 23:03:04,042 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:04,042 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:04,466 - INFO - Epoch: [135][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.3170 (0.2483) Acc@1 90.625 (91.527) Acc@5 100.000 (99.829)
2025-08-27 23:03:06,348 - INFO - Epoch: [135][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2507 (0.2485) Acc@1 89.844 (91.476) Acc@5 100.000 (99.821)
2025-08-27 23:03:06,939 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:06,940 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:08,077 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.2661 (0.2661) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:03:08,928 - INFO - Epoch 135:
2025-08-27 23:03:08,928 - INFO -   Train: acc1: 91.5200 | acc5: 99.7980 | loss: 0.2484 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:08,928 - INFO -   Val:   acc1: 88.5500 | acc5: 99.6500 | loss: 0.3395
2025-08-27 23:03:08,928 - INFO -   LR: 0.010000
2025-08-27 23:03:08,946 - INFO - 
Epoch: 136, lr = 0.010000000000000002
2025-08-27 23:03:09,108 - INFO - Epoch: [136][0/391] Time 0.161 (0.161) Data 0.139 (0.139) Loss 0.2036 (0.2036) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:03:10,956 - INFO - Epoch: [136][100/391] Time 0.022 (0.020) Data 0.000 (0.004) Loss 0.2391 (0.2533) Acc@1 91.406 (91.074) Acc@5 100.000 (99.791)
2025-08-27 23:03:11,011 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:11,013 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:12,691 - INFO - Epoch: [136][200/391] Time 0.031 (0.019) Data 0.000 (0.003) Loss 0.3203 (0.2510) Acc@1 86.719 (91.192) Acc@5 99.219 (99.817)
2025-08-27 23:03:13,799 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:13,799 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:14,426 - INFO - Epoch: [136][300/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.3086 (0.2525) Acc@1 89.062 (91.110) Acc@5 99.219 (99.821)
2025-08-27 23:03:16,149 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.4254 (0.4254) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:03:17,016 - INFO - Epoch 136:
2025-08-27 23:03:17,016 - INFO -   Train: acc1: 91.1700 | acc5: 99.8360 | loss: 0.2507 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:17,016 - INFO -   Val:   acc1: 87.2600 | acc5: 99.6100 | loss: 0.3888
2025-08-27 23:03:17,016 - INFO -   LR: 0.010000
2025-08-27 23:03:17,033 - INFO - 
Epoch: 137, lr = 0.010000000000000002
2025-08-27 23:03:17,205 - INFO - Epoch: [137][0/391] Time 0.170 (0.170) Data 0.133 (0.133) Loss 0.2901 (0.2901) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:03:17,795 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:17,795 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:18,997 - INFO - Epoch: [137][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1712 (0.2414) Acc@1 92.969 (91.824) Acc@5 100.000 (99.830)
2025-08-27 23:03:20,632 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:20,632 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:20,797 - INFO - Epoch: [137][200/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.2505 (0.2455) Acc@1 92.969 (91.535) Acc@5 100.000 (99.821)
2025-08-27 23:03:22,546 - INFO - Epoch: [137][300/391] Time 0.012 (0.018) Data 0.000 (0.002) Loss 0.3696 (0.2497) Acc@1 85.156 (91.409) Acc@5 99.219 (99.816)
2025-08-27 23:03:23,431 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:23,439 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:24,271 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2821 (0.2821) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:03:25,126 - INFO - Epoch 137:
2025-08-27 23:03:25,127 - INFO -   Train: acc1: 91.3220 | acc5: 99.7980 | loss: 0.2523 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:25,127 - INFO -   Val:   acc1: 88.1100 | acc5: 99.6700 | loss: 0.3494
2025-08-27 23:03:25,127 - INFO -   LR: 0.010000
2025-08-27 23:03:25,145 - INFO - 
Epoch: 138, lr = 0.010000000000000002
2025-08-27 23:03:25,303 - INFO - Epoch: [138][0/391] Time 0.158 (0.158) Data 0.138 (0.138) Loss 0.2203 (0.2203) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:03:27,067 - INFO - Epoch: [138][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2742 (0.2476) Acc@1 92.188 (91.313) Acc@5 100.000 (99.853)
2025-08-27 23:03:27,464 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:27,464 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:28,948 - INFO - Epoch: [138][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.2062 (0.2508) Acc@1 93.750 (91.200) Acc@5 100.000 (99.813)
2025-08-27 23:03:30,447 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:30,447 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:30,758 - INFO - Epoch: [138][300/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2345 (0.2523) Acc@1 92.188 (91.097) Acc@5 100.000 (99.824)
2025-08-27 23:03:32,537 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2664 (0.2664) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:03:33,387 - INFO - Epoch 138:
2025-08-27 23:03:33,388 - INFO -   Train: acc1: 91.1180 | acc5: 99.8200 | loss: 0.2512 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:33,388 - INFO -   Val:   acc1: 88.3600 | acc5: 99.6600 | loss: 0.3488
2025-08-27 23:03:33,388 - INFO -   LR: 0.010000
2025-08-27 23:03:33,403 - INFO - 
Epoch: 139, lr = 0.010000000000000002
2025-08-27 23:03:33,585 - INFO - Epoch: [139][0/391] Time 0.181 (0.181) Data 0.163 (0.163) Loss 0.3320 (0.3320) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:03:34,438 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:34,439 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:35,299 - INFO - Epoch: [139][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2637 (0.2363) Acc@1 90.625 (91.793) Acc@5 100.000 (99.838)
2025-08-27 23:03:37,109 - INFO - Epoch: [139][200/391] Time 0.015 (0.018) Data 0.000 (0.003) Loss 0.2320 (0.2457) Acc@1 92.188 (91.515) Acc@5 100.000 (99.794)
2025-08-27 23:03:37,296 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:37,296 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:38,864 - INFO - Epoch: [139][300/391] Time 0.010 (0.018) Data 0.000 (0.003) Loss 0.3195 (0.2502) Acc@1 85.938 (91.352) Acc@5 100.000 (99.800)
2025-08-27 23:03:40,090 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:40,102 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:40,622 - INFO - Test: [0/79] Time 0.157 (0.157) Loss 0.3422 (0.3422) Acc@1 88.281 (88.281) Acc@5 99.219 (99.219)
2025-08-27 23:03:41,447 - INFO - Epoch 139:
2025-08-27 23:03:41,447 - INFO -   Train: acc1: 91.2180 | acc5: 99.7780 | loss: 0.2523 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:41,447 - INFO -   Val:   acc1: 86.7900 | acc5: 99.5000 | loss: 0.4042
2025-08-27 23:03:41,447 - INFO -   LR: 0.010000
2025-08-27 23:03:41,463 - INFO - 
Epoch: 140, lr = 0.010000000000000002
2025-08-27 23:03:41,638 - INFO - Epoch: [140][0/391] Time 0.174 (0.174) Data 0.139 (0.139) Loss 0.2496 (0.2496) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:03:43,471 - INFO - Epoch: [140][100/391] Time 0.015 (0.020) Data 0.000 (0.003) Loss 0.2306 (0.2506) Acc@1 92.188 (91.259) Acc@5 100.000 (99.791)
2025-08-27 23:03:44,156 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:44,156 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:45,273 - INFO - Epoch: [140][200/391] Time 0.027 (0.019) Data 0.009 (0.002) Loss 0.2813 (0.2556) Acc@1 91.406 (91.119) Acc@5 99.219 (99.798)
2025-08-27 23:03:46,990 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:46,990 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:47,004 - INFO - Epoch: [140][300/391] Time 0.028 (0.018) Data 0.010 (0.002) Loss 0.2036 (0.2527) Acc@1 93.750 (91.222) Acc@5 100.000 (99.818)
2025-08-27 23:03:48,725 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.3106 (0.3106) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:03:49,566 - INFO - Epoch 140:
2025-08-27 23:03:49,567 - INFO -   Train: acc1: 91.1380 | acc5: 99.8020 | loss: 0.2539 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:49,567 - INFO -   Val:   acc1: 88.3900 | acc5: 99.6200 | loss: 0.3488
2025-08-27 23:03:49,567 - INFO -   LR: 0.010000
2025-08-27 23:03:49,617 - INFO - 
Epoch: 141, lr = 0.010000000000000002
2025-08-27 23:03:49,910 - INFO - Epoch: [141][0/391] Time 0.292 (0.292) Data 0.270 (0.270) Loss 0.2951 (0.2951) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:03:51,125 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:51,126 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:51,691 - INFO - Epoch: [141][100/391] Time 0.012 (0.021) Data 0.000 (0.006) Loss 0.1495 (0.2450) Acc@1 96.094 (91.576) Acc@5 100.000 (99.722)
2025-08-27 23:03:53,580 - INFO - Epoch: [141][200/391] Time 0.013 (0.020) Data 0.000 (0.005) Loss 0.1481 (0.2456) Acc@1 96.094 (91.651) Acc@5 100.000 (99.747)
2025-08-27 23:03:54,105 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:54,105 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:55,538 - INFO - Epoch: [141][300/391] Time 0.015 (0.020) Data 0.000 (0.004) Loss 0.1958 (0.2509) Acc@1 92.188 (91.518) Acc@5 100.000 (99.759)
2025-08-27 23:03:57,147 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:03:57,148 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:03:57,343 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.2903 (0.2903) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:03:58,163 - INFO - Epoch 141:
2025-08-27 23:03:58,163 - INFO -   Train: acc1: 91.4100 | acc5: 99.7620 | loss: 0.2519 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:03:58,164 - INFO -   Val:   acc1: 87.6700 | acc5: 99.7000 | loss: 0.3672
2025-08-27 23:03:58,164 - INFO -   LR: 0.010000
2025-08-27 23:03:58,181 - INFO - 
Epoch: 142, lr = 0.010000000000000002
2025-08-27 23:03:58,379 - INFO - Epoch: [142][0/391] Time 0.197 (0.197) Data 0.173 (0.173) Loss 0.2184 (0.2184) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:04:00,152 - INFO - Epoch: [142][100/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2564 (0.2507) Acc@1 90.625 (91.298) Acc@5 100.000 (99.830)
2025-08-27 23:04:01,169 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:01,169 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:01,979 - INFO - Epoch: [142][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.2515 (0.2500) Acc@1 90.625 (91.259) Acc@5 99.219 (99.825)
2025-08-27 23:04:03,808 - INFO - Epoch: [142][300/391] Time 0.027 (0.019) Data 0.012 (0.003) Loss 0.3280 (0.2502) Acc@1 89.062 (91.271) Acc@5 99.219 (99.811)
2025-08-27 23:04:04,136 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:04,136 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:05,583 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.3255 (0.3255) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:04:06,421 - INFO - Epoch 142:
2025-08-27 23:04:06,421 - INFO -   Train: acc1: 91.2000 | acc5: 99.7960 | loss: 0.2530 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:06,421 - INFO -   Val:   acc1: 88.5400 | acc5: 99.5800 | loss: 0.3414
2025-08-27 23:04:06,421 - INFO -   LR: 0.010000
2025-08-27 23:04:06,436 - INFO - 
Epoch: 143, lr = 0.010000000000000002
2025-08-27 23:04:06,625 - INFO - Epoch: [143][0/391] Time 0.188 (0.188) Data 0.172 (0.172) Loss 0.2727 (0.2727) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:04:08,275 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:08,275 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:08,478 - INFO - Epoch: [143][100/391] Time 0.024 (0.020) Data 0.000 (0.004) Loss 0.2125 (0.2443) Acc@1 92.969 (91.584) Acc@5 100.000 (99.799)
2025-08-27 23:04:10,292 - INFO - Epoch: [143][200/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.1629 (0.2491) Acc@1 92.969 (91.433) Acc@5 100.000 (99.763)
2025-08-27 23:04:11,167 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:11,167 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:12,163 - INFO - Epoch: [143][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2188 (0.2501) Acc@1 92.969 (91.437) Acc@5 100.000 (99.769)
2025-08-27 23:04:13,914 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.3555 (0.3555) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:04:14,731 - INFO - Epoch 143:
2025-08-27 23:04:14,731 - INFO -   Train: acc1: 91.2900 | acc5: 99.7880 | loss: 0.2531 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:14,731 - INFO -   Val:   acc1: 87.6800 | acc5: 99.6100 | loss: 0.3651
2025-08-27 23:04:14,731 - INFO -   LR: 0.010000
2025-08-27 23:04:14,750 - INFO - 
Epoch: 144, lr = 0.010000000000000002
2025-08-27 23:04:14,955 - INFO - Epoch: [144][0/391] Time 0.204 (0.204) Data 0.169 (0.169) Loss 0.3257 (0.3257) Acc@1 85.938 (85.938) Acc@5 100.000 (100.000)
2025-08-27 23:04:15,202 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:15,203 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:16,849 - INFO - Epoch: [144][100/391] Time 0.017 (0.021) Data 0.000 (0.004) Loss 0.2717 (0.2569) Acc@1 91.406 (91.205) Acc@5 100.000 (99.745)
2025-08-27 23:04:18,232 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:18,232 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:18,655 - INFO - Epoch: [144][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.3084 (0.2628) Acc@1 90.625 (90.897) Acc@5 100.000 (99.786)
2025-08-27 23:04:20,453 - INFO - Epoch: [144][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.2080 (0.2590) Acc@1 92.969 (90.921) Acc@5 100.000 (99.792)
2025-08-27 23:04:21,083 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:21,083 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:22,234 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3384 (0.3384) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:04:23,095 - INFO - Epoch 144:
2025-08-27 23:04:23,095 - INFO -   Train: acc1: 90.9660 | acc5: 99.7760 | loss: 0.2584 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:23,095 - INFO -   Val:   acc1: 88.1200 | acc5: 99.6400 | loss: 0.3587
2025-08-27 23:04:23,095 - INFO -   LR: 0.010000
2025-08-27 23:04:23,110 - INFO - 
Epoch: 145, lr = 0.010000000000000002
2025-08-27 23:04:23,283 - INFO - Epoch: [145][0/391] Time 0.170 (0.170) Data 0.155 (0.155) Loss 0.2729 (0.2729) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:04:25,134 - INFO - Epoch: [145][100/391] Time 0.021 (0.020) Data 0.000 (0.005) Loss 0.2357 (0.2388) Acc@1 92.188 (91.669) Acc@5 100.000 (99.830)
2025-08-27 23:04:25,186 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:25,186 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:26,999 - INFO - Epoch: [145][200/391] Time 0.017 (0.019) Data 0.000 (0.004) Loss 0.2389 (0.2461) Acc@1 92.188 (91.488) Acc@5 100.000 (99.798)
2025-08-27 23:04:28,201 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:28,202 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:28,814 - INFO - Epoch: [145][300/391] Time 0.025 (0.019) Data 0.013 (0.003) Loss 0.2386 (0.2520) Acc@1 92.188 (91.357) Acc@5 100.000 (99.790)
2025-08-27 23:04:30,584 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.4013 (0.4013) Acc@1 88.281 (88.281) Acc@5 100.000 (100.000)
2025-08-27 23:04:31,419 - INFO - Epoch 145:
2025-08-27 23:04:31,420 - INFO -   Train: acc1: 91.2780 | acc5: 99.7960 | loss: 0.2532 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:31,420 - INFO -   Val:   acc1: 86.6200 | acc5: 99.4100 | loss: 0.4079
2025-08-27 23:04:31,420 - INFO -   LR: 0.010000
2025-08-27 23:04:31,435 - INFO - 
Epoch: 146, lr = 0.010000000000000002
2025-08-27 23:04:31,631 - INFO - Epoch: [146][0/391] Time 0.195 (0.195) Data 0.173 (0.173) Loss 0.3557 (0.3557) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-27 23:04:32,212 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:32,212 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:33,495 - INFO - Epoch: [146][100/391] Time 0.013 (0.020) Data 0.000 (0.006) Loss 0.2133 (0.2462) Acc@1 92.969 (91.561) Acc@5 100.000 (99.822)
2025-08-27 23:04:35,167 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:35,167 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:35,303 - INFO - Epoch: [146][200/391] Time 0.026 (0.019) Data 0.000 (0.005) Loss 0.2144 (0.2523) Acc@1 94.531 (91.290) Acc@5 100.000 (99.786)
2025-08-27 23:04:37,152 - INFO - Epoch: [146][300/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2197 (0.2506) Acc@1 91.406 (91.357) Acc@5 100.000 (99.803)
2025-08-27 23:04:38,141 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:38,142 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:38,882 - INFO - Test: [0/79] Time 0.106 (0.106) Loss 0.2730 (0.2730) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:04:39,752 - INFO - Epoch 146:
2025-08-27 23:04:39,753 - INFO -   Train: acc1: 91.2080 | acc5: 99.8000 | loss: 0.2526 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:39,753 - INFO -   Val:   acc1: 88.5400 | acc5: 99.6400 | loss: 0.3445
2025-08-27 23:04:39,753 - INFO -   LR: 0.010000
2025-08-27 23:04:39,770 - INFO - 
Epoch: 147, lr = 0.010000000000000002
2025-08-27 23:04:39,958 - INFO - Epoch: [147][0/391] Time 0.188 (0.188) Data 0.152 (0.152) Loss 0.2248 (0.2248) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:04:41,823 - INFO - Epoch: [147][100/391] Time 0.022 (0.020) Data 0.000 (0.003) Loss 0.2194 (0.2513) Acc@1 94.531 (91.290) Acc@5 100.000 (99.845)
2025-08-27 23:04:42,173 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:42,173 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:43,586 - INFO - Epoch: [147][200/391] Time 0.024 (0.019) Data 0.014 (0.003) Loss 0.2742 (0.2542) Acc@1 90.625 (91.220) Acc@5 99.219 (99.806)
2025-08-27 23:04:45,122 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:45,123 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:45,491 - INFO - Epoch: [147][300/391] Time 0.018 (0.019) Data 0.005 (0.003) Loss 0.2724 (0.2564) Acc@1 93.750 (91.090) Acc@5 100.000 (99.821)
2025-08-27 23:04:47,283 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.2893 (0.2893) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:04:48,128 - INFO - Epoch 147:
2025-08-27 23:04:48,128 - INFO -   Train: acc1: 91.0900 | acc5: 99.8100 | loss: 0.2571 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:48,128 - INFO -   Val:   acc1: 87.6100 | acc5: 99.5900 | loss: 0.3762
2025-08-27 23:04:48,128 - INFO -   LR: 0.010000
2025-08-27 23:04:48,147 - INFO - 
Epoch: 148, lr = 0.010000000000000002
2025-08-27 23:04:48,331 - INFO - Epoch: [148][0/391] Time 0.184 (0.184) Data 0.164 (0.164) Loss 0.2726 (0.2726) Acc@1 89.062 (89.062) Acc@5 100.000 (100.000)
2025-08-27 23:04:49,252 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:49,252 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:50,123 - INFO - Epoch: [148][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.2515 (0.2537) Acc@1 92.188 (91.012) Acc@5 100.000 (99.814)
2025-08-27 23:04:51,918 - INFO - Epoch: [148][200/391] Time 0.025 (0.019) Data 0.005 (0.004) Loss 0.2708 (0.2504) Acc@1 92.969 (91.095) Acc@5 100.000 (99.782)
2025-08-27 23:04:52,144 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:52,144 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:53,771 - INFO - Epoch: [148][300/391] Time 0.023 (0.019) Data 0.000 (0.004) Loss 0.2345 (0.2524) Acc@1 91.406 (91.048) Acc@5 100.000 (99.766)
2025-08-27 23:04:55,135 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:55,135 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:04:55,606 - INFO - Test: [0/79] Time 0.144 (0.144) Loss 0.3352 (0.3352) Acc@1 90.625 (90.625) Acc@5 100.000 (100.000)
2025-08-27 23:04:56,470 - INFO - Epoch 148:
2025-08-27 23:04:56,470 - INFO -   Train: acc1: 91.0260 | acc5: 99.7700 | loss: 0.2544 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:04:56,470 - INFO -   Val:   acc1: 87.8300 | acc5: 99.5200 | loss: 0.3775
2025-08-27 23:04:56,470 - INFO -   LR: 0.010000
2025-08-27 23:04:56,487 - INFO - 
Epoch: 149, lr = 0.010000000000000002
2025-08-27 23:04:56,668 - INFO - Epoch: [149][0/391] Time 0.179 (0.179) Data 0.153 (0.153) Loss 0.3432 (0.3432) Acc@1 86.719 (86.719) Acc@5 100.000 (100.000)
2025-08-27 23:04:58,463 - INFO - Epoch: [149][100/391] Time 0.031 (0.020) Data 0.017 (0.004) Loss 0.2551 (0.2525) Acc@1 92.188 (91.236) Acc@5 100.000 (99.722)
2025-08-27 23:04:59,241 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:04:59,241 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:00,288 - INFO - Epoch: [149][200/391] Time 0.025 (0.019) Data 0.013 (0.003) Loss 0.3257 (0.2602) Acc@1 88.281 (90.932) Acc@5 99.219 (99.751)
2025-08-27 23:05:02,091 - INFO - Epoch: [149][300/391] Time 0.037 (0.019) Data 0.023 (0.003) Loss 0.2894 (0.2593) Acc@1 92.188 (90.947) Acc@5 97.656 (99.753)
2025-08-27 23:05:02,097 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:02,098 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:03,932 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3226 (0.3226) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:05:04,785 - INFO - Epoch 149:
2025-08-27 23:05:04,785 - INFO -   Train: acc1: 91.0520 | acc5: 99.7580 | loss: 0.2575 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:04,785 - INFO -   Val:   acc1: 87.6300 | acc5: 99.6200 | loss: 0.3610
2025-08-27 23:05:04,785 - INFO -   LR: 0.001000
2025-08-27 23:05:04,802 - INFO - 
Epoch: 150, lr = 0.0010000000000000002
2025-08-27 23:05:04,976 - INFO - Epoch: [150][0/391] Time 0.173 (0.173) Data 0.157 (0.157) Loss 0.2547 (0.2547) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:05:06,313 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:06,314 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:06,881 - INFO - Epoch: [150][100/391] Time 0.027 (0.021) Data 0.000 (0.004) Loss 0.1735 (0.2253) Acc@1 96.094 (92.481) Acc@5 100.000 (99.884)
2025-08-27 23:05:08,751 - INFO - Epoch: [150][200/391] Time 0.037 (0.020) Data 0.015 (0.003) Loss 0.2033 (0.2227) Acc@1 92.188 (92.498) Acc@5 100.000 (99.860)
2025-08-27 23:05:09,262 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:09,262 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:10,647 - INFO - Epoch: [150][300/391] Time 0.027 (0.019) Data 0.013 (0.003) Loss 0.2309 (0.2238) Acc@1 92.188 (92.372) Acc@5 100.000 (99.865)
2025-08-27 23:05:12,222 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:12,223 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:12,413 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2947 (0.2947) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:05:13,256 - INFO - Epoch 150:
2025-08-27 23:05:13,256 - INFO -   Train: acc1: 92.5220 | acc5: 99.8580 | loss: 0.2213 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:13,256 - INFO -   Val:   acc1: 89.8200 | acc5: 99.7300 | loss: 0.3051
2025-08-27 23:05:13,256 - INFO -   LR: 0.001000
2025-08-27 23:05:13,309 - INFO - Checkpoint saved: epoch=150, metric=89.8200
2025-08-27 23:05:13,341 - INFO - 
Epoch: 151, lr = 0.0010000000000000002
2025-08-27 23:05:13,538 - INFO - Epoch: [151][0/391] Time 0.197 (0.197) Data 0.164 (0.164) Loss 0.2560 (0.2560) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:05:15,310 - INFO - Epoch: [151][100/391] Time 0.037 (0.019) Data 0.027 (0.004) Loss 0.1705 (0.2039) Acc@1 93.750 (93.085) Acc@5 100.000 (99.892)
2025-08-27 23:05:16,419 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:16,420 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:17,145 - INFO - Epoch: [151][200/391] Time 0.021 (0.019) Data 0.011 (0.004) Loss 0.2806 (0.2111) Acc@1 91.406 (92.907) Acc@5 100.000 (99.845)
2025-08-27 23:05:19,009 - INFO - Epoch: [151][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1301 (0.2121) Acc@1 96.875 (92.805) Acc@5 100.000 (99.847)
2025-08-27 23:05:19,334 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:19,334 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:20,758 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3044 (0.3044) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:05:21,585 - INFO - Epoch 151:
2025-08-27 23:05:21,585 - INFO -   Train: acc1: 92.8020 | acc5: 99.8520 | loss: 0.2123 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:21,585 - INFO -   Val:   acc1: 89.7900 | acc5: 99.7300 | loss: 0.3027
2025-08-27 23:05:21,585 - INFO -   LR: 0.001000
2025-08-27 23:05:21,604 - INFO - 
Epoch: 152, lr = 0.0010000000000000002
2025-08-27 23:05:21,764 - INFO - Epoch: [152][0/391] Time 0.159 (0.159) Data 0.127 (0.127) Loss 0.2522 (0.2522) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:05:23,305 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:23,305 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:23,565 - INFO - Epoch: [152][100/391] Time 0.020 (0.019) Data 0.000 (0.004) Loss 0.1607 (0.2098) Acc@1 93.750 (93.062) Acc@5 100.000 (99.799)
2025-08-27 23:05:25,416 - INFO - Epoch: [152][200/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1548 (0.2086) Acc@1 96.094 (93.035) Acc@5 100.000 (99.848)
2025-08-27 23:05:26,256 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:26,256 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:27,219 - INFO - Epoch: [152][300/391] Time 0.018 (0.019) Data 0.004 (0.003) Loss 0.1945 (0.2088) Acc@1 92.188 (93.018) Acc@5 100.000 (99.844)
2025-08-27 23:05:29,051 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.2942 (0.2942) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:05:29,901 - INFO - Epoch 152:
2025-08-27 23:05:29,901 - INFO -   Train: acc1: 92.9900 | acc5: 99.8540 | loss: 0.2090 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:29,901 - INFO -   Val:   acc1: 89.9700 | acc5: 99.7300 | loss: 0.3019
2025-08-27 23:05:29,901 - INFO -   LR: 0.001000
2025-08-27 23:05:29,953 - INFO - Checkpoint saved: epoch=152, metric=89.9700
2025-08-27 23:05:29,984 - INFO - 
Epoch: 153, lr = 0.0010000000000000002
2025-08-27 23:05:30,149 - INFO - Epoch: [153][0/391] Time 0.164 (0.164) Data 0.148 (0.148) Loss 0.2468 (0.2468) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:05:30,549 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:30,549 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:32,099 - INFO - Epoch: [153][100/391] Time 0.013 (0.021) Data 0.000 (0.006) Loss 0.2060 (0.2038) Acc@1 93.750 (93.031) Acc@5 100.000 (99.868)
2025-08-27 23:05:33,559 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:33,559 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:34,001 - INFO - Epoch: [153][200/391] Time 0.019 (0.020) Data 0.000 (0.004) Loss 0.2007 (0.2033) Acc@1 94.531 (93.019) Acc@5 100.000 (99.868)
2025-08-27 23:05:35,879 - INFO - Epoch: [153][300/391] Time 0.012 (0.020) Data 0.000 (0.003) Loss 0.1497 (0.2057) Acc@1 96.094 (92.948) Acc@5 100.000 (99.852)
2025-08-27 23:05:36,526 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:36,527 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:37,670 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.3059 (0.3059) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:05:38,506 - INFO - Epoch 153:
2025-08-27 23:05:38,506 - INFO -   Train: acc1: 92.9840 | acc5: 99.8520 | loss: 0.2051 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:38,506 - INFO -   Val:   acc1: 89.8300 | acc5: 99.7400 | loss: 0.3018
2025-08-27 23:05:38,506 - INFO -   LR: 0.001000
2025-08-27 23:05:38,524 - INFO - 
Epoch: 154, lr = 0.0010000000000000002
2025-08-27 23:05:38,713 - INFO - Epoch: [154][0/391] Time 0.188 (0.188) Data 0.169 (0.169) Loss 0.1750 (0.1750) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:05:40,457 - INFO - Epoch: [154][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2498 (0.2015) Acc@1 92.188 (93.131) Acc@5 100.000 (99.838)
2025-08-27 23:05:40,571 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:40,572 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:42,282 - INFO - Epoch: [154][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.1842 (0.2043) Acc@1 92.188 (92.949) Acc@5 100.000 (99.833)
2025-08-27 23:05:43,458 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:43,469 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:44,125 - INFO - Epoch: [154][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2225 (0.2015) Acc@1 91.406 (93.148) Acc@5 100.000 (99.847)
2025-08-27 23:05:45,935 - INFO - Test: [0/79] Time 0.124 (0.124) Loss 0.2956 (0.2956) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:05:46,783 - INFO - Epoch 154:
2025-08-27 23:05:46,783 - INFO -   Train: acc1: 93.1540 | acc5: 99.8540 | loss: 0.2013 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:46,783 - INFO -   Val:   acc1: 89.9600 | acc5: 99.7300 | loss: 0.2975
2025-08-27 23:05:46,783 - INFO -   LR: 0.001000
2025-08-27 23:05:46,802 - INFO - 
Epoch: 155, lr = 0.0010000000000000002
2025-08-27 23:05:46,991 - INFO - Epoch: [155][0/391] Time 0.188 (0.188) Data 0.141 (0.141) Loss 0.2170 (0.2170) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:05:47,568 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:47,569 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:48,900 - INFO - Epoch: [155][100/391] Time 0.015 (0.021) Data 0.000 (0.003) Loss 0.1489 (0.2052) Acc@1 92.969 (93.201) Acc@5 100.000 (99.884)
2025-08-27 23:05:50,630 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:50,630 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:50,734 - INFO - Epoch: [155][200/391] Time 0.018 (0.020) Data 0.000 (0.003) Loss 0.2940 (0.2014) Acc@1 89.844 (93.183) Acc@5 98.438 (99.876)
2025-08-27 23:05:52,649 - INFO - Epoch: [155][300/391] Time 0.039 (0.019) Data 0.029 (0.004) Loss 0.2128 (0.2012) Acc@1 93.750 (93.163) Acc@5 100.000 (99.862)
2025-08-27 23:05:53,682 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:53,683 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:54,424 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.3167 (0.3167) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:05:55,277 - INFO - Epoch 155:
2025-08-27 23:05:55,277 - INFO -   Train: acc1: 93.1080 | acc5: 99.8720 | loss: 0.2025 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:05:55,277 - INFO -   Val:   acc1: 90.0400 | acc5: 99.7000 | loss: 0.2976
2025-08-27 23:05:55,277 - INFO -   LR: 0.001000
2025-08-27 23:05:55,329 - INFO - Checkpoint saved: epoch=155, metric=90.0400
2025-08-27 23:05:55,362 - INFO - 
Epoch: 156, lr = 0.0010000000000000002
2025-08-27 23:05:55,544 - INFO - Epoch: [156][0/391] Time 0.181 (0.181) Data 0.161 (0.161) Loss 0.1606 (0.1606) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:05:57,346 - INFO - Epoch: [156][100/391] Time 0.016 (0.020) Data 0.000 (0.004) Loss 0.1712 (0.2055) Acc@1 95.312 (92.737) Acc@5 100.000 (99.899)
2025-08-27 23:05:57,792 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:05:57,792 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:05:59,155 - INFO - Epoch: [156][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1852 (0.2012) Acc@1 92.969 (93.078) Acc@5 100.000 (99.899)
2025-08-27 23:06:00,649 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:00,649 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:00,981 - INFO - Epoch: [156][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.2106 (0.2021) Acc@1 92.969 (93.073) Acc@5 100.000 (99.883)
2025-08-27 23:06:02,724 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.2993 (0.2993) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:06:03,560 - INFO - Epoch 156:
2025-08-27 23:06:03,560 - INFO -   Train: acc1: 93.1520 | acc5: 99.8900 | loss: 0.2000 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:03,560 - INFO -   Val:   acc1: 89.9100 | acc5: 99.7600 | loss: 0.3003
2025-08-27 23:06:03,560 - INFO -   LR: 0.001000
2025-08-27 23:06:03,578 - INFO - 
Epoch: 157, lr = 0.0010000000000000002
2025-08-27 23:06:03,754 - INFO - Epoch: [157][0/391] Time 0.175 (0.175) Data 0.158 (0.158) Loss 0.2337 (0.2337) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:06:04,703 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:04,703 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:05,559 - INFO - Epoch: [157][100/391] Time 0.014 (0.020) Data 0.000 (0.003) Loss 0.2137 (0.1941) Acc@1 93.750 (93.502) Acc@5 98.438 (99.830)
2025-08-27 23:06:07,414 - INFO - Epoch: [157][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1808 (0.1985) Acc@1 90.625 (93.218) Acc@5 100.000 (99.872)
2025-08-27 23:06:07,642 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:07,643 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:09,236 - INFO - Epoch: [157][300/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2397 (0.1989) Acc@1 92.188 (93.192) Acc@5 100.000 (99.873)
2025-08-27 23:06:10,576 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:10,576 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:11,018 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.3060 (0.3060) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:06:11,873 - INFO - Epoch 157:
2025-08-27 23:06:11,873 - INFO -   Train: acc1: 93.2480 | acc5: 99.8740 | loss: 0.1973 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:11,873 - INFO -   Val:   acc1: 89.9900 | acc5: 99.7200 | loss: 0.3011
2025-08-27 23:06:11,873 - INFO -   LR: 0.001000
2025-08-27 23:06:11,892 - INFO - 
Epoch: 158, lr = 0.0010000000000000002
2025-08-27 23:06:12,042 - INFO - Epoch: [158][0/391] Time 0.149 (0.149) Data 0.132 (0.132) Loss 0.1813 (0.1813) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:06:13,830 - INFO - Epoch: [158][100/391] Time 0.021 (0.019) Data 0.000 (0.004) Loss 0.2370 (0.2077) Acc@1 90.625 (92.961) Acc@5 100.000 (99.853)
2025-08-27 23:06:14,588 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:14,588 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:15,598 - INFO - Epoch: [158][200/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.1781 (0.2049) Acc@1 90.625 (92.953) Acc@5 100.000 (99.852)
2025-08-27 23:06:17,508 - INFO - Epoch: [158][300/391] Time 0.012 (0.019) Data 0.000 (0.002) Loss 0.1161 (0.1993) Acc@1 95.312 (93.213) Acc@5 100.000 (99.855)
2025-08-27 23:06:17,538 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:17,539 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:19,263 - INFO - Test: [0/79] Time 0.158 (0.158) Loss 0.3083 (0.3083) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:06:20,099 - INFO - Epoch 158:
2025-08-27 23:06:20,099 - INFO -   Train: acc1: 93.2160 | acc5: 99.8580 | loss: 0.1985 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:20,099 - INFO -   Val:   acc1: 90.0800 | acc5: 99.7400 | loss: 0.3013
2025-08-27 23:06:20,100 - INFO -   LR: 0.001000
2025-08-27 23:06:20,153 - INFO - Checkpoint saved: epoch=158, metric=90.0800
2025-08-27 23:06:20,186 - INFO - 
Epoch: 159, lr = 0.0010000000000000002
2025-08-27 23:06:20,363 - INFO - Epoch: [159][0/391] Time 0.177 (0.177) Data 0.159 (0.159) Loss 0.2735 (0.2735) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:06:21,617 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:21,617 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:22,182 - INFO - Epoch: [159][100/391] Time 0.012 (0.020) Data 0.000 (0.006) Loss 0.1804 (0.1976) Acc@1 94.531 (93.332) Acc@5 100.000 (99.876)
2025-08-27 23:06:24,008 - INFO - Epoch: [159][200/391] Time 0.013 (0.019) Data 0.000 (0.004) Loss 0.2012 (0.1986) Acc@1 92.969 (93.186) Acc@5 100.000 (99.880)
2025-08-27 23:06:24,582 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:24,582 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:25,894 - INFO - Epoch: [159][300/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.2164 (0.1982) Acc@1 94.531 (93.156) Acc@5 100.000 (99.881)
2025-08-27 23:06:27,649 - INFO - Test: [0/79] Time 0.120 (0.120) Loss 0.3138 (0.3138) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:06:28,481 - INFO - Epoch 159:
2025-08-27 23:06:28,481 - INFO -   Train: acc1: 93.1500 | acc5: 99.8820 | loss: 0.1982 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:28,481 - INFO -   Val:   acc1: 90.0500 | acc5: 99.7600 | loss: 0.2988
2025-08-27 23:06:28,481 - INFO -   LR: 0.001000
2025-08-27 23:06:28,500 - INFO - 
Epoch: 160, lr = 0.0010000000000000002
2025-08-27 23:06:28,675 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:28,677 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:28,711 - INFO - Epoch: [160][0/391] Time 0.209 (0.209) Data 0.164 (0.164) Loss 0.1338 (0.1338) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:06:30,512 - INFO - Epoch: [160][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.1246 (0.1902) Acc@1 96.094 (93.680) Acc@5 100.000 (99.853)
2025-08-27 23:06:31,583 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:31,583 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:32,353 - INFO - Epoch: [160][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.2312 (0.1948) Acc@1 92.188 (93.412) Acc@5 100.000 (99.841)
2025-08-27 23:06:34,179 - INFO - Epoch: [160][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1966 (0.1959) Acc@1 92.969 (93.355) Acc@5 100.000 (99.862)
2025-08-27 23:06:34,514 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:34,515 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:35,913 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3070 (0.3070) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:06:36,721 - INFO - Epoch 160:
2025-08-27 23:06:36,722 - INFO -   Train: acc1: 93.4120 | acc5: 99.8640 | loss: 0.1955 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:36,722 - INFO -   Val:   acc1: 90.0100 | acc5: 99.7600 | loss: 0.3029
2025-08-27 23:06:36,722 - INFO -   LR: 0.001000
2025-08-27 23:06:36,771 - INFO - 
Epoch: 161, lr = 0.0010000000000000002
2025-08-27 23:06:36,957 - INFO - Epoch: [161][0/391] Time 0.185 (0.185) Data 0.161 (0.161) Loss 0.2886 (0.2886) Acc@1 89.062 (89.062) Acc@5 99.219 (99.219)
2025-08-27 23:06:38,585 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:38,585 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:38,765 - INFO - Epoch: [161][100/391] Time 0.015 (0.020) Data 0.000 (0.006) Loss 0.1911 (0.1978) Acc@1 96.094 (93.348) Acc@5 100.000 (99.845)
2025-08-27 23:06:40,559 - INFO - Epoch: [161][200/391] Time 0.010 (0.019) Data 0.000 (0.004) Loss 0.1468 (0.1949) Acc@1 96.094 (93.365) Acc@5 100.000 (99.872)
2025-08-27 23:06:41,389 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:41,389 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:42,330 - INFO - Epoch: [161][300/391] Time 0.015 (0.018) Data 0.000 (0.004) Loss 0.2014 (0.1979) Acc@1 92.188 (93.262) Acc@5 100.000 (99.855)
2025-08-27 23:06:44,082 - INFO - Test: [0/79] Time 0.121 (0.121) Loss 0.3033 (0.3033) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:06:44,993 - INFO - Epoch 161:
2025-08-27 23:06:44,993 - INFO -   Train: acc1: 93.3380 | acc5: 99.8600 | loss: 0.1967 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:44,993 - INFO -   Val:   acc1: 90.1600 | acc5: 99.7400 | loss: 0.2976
2025-08-27 23:06:44,993 - INFO -   LR: 0.001000
2025-08-27 23:06:45,047 - INFO - Checkpoint saved: epoch=161, metric=90.1600
2025-08-27 23:06:45,080 - INFO - 
Epoch: 162, lr = 0.0010000000000000002
2025-08-27 23:06:45,247 - INFO - Epoch: [162][0/391] Time 0.165 (0.165) Data 0.148 (0.148) Loss 0.1451 (0.1451) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 23:06:45,653 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:45,653 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:47,200 - INFO - Epoch: [162][100/391] Time 0.021 (0.021) Data 0.000 (0.004) Loss 0.1774 (0.1899) Acc@1 93.750 (93.618) Acc@5 100.000 (99.907)
2025-08-27 23:06:48,581 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:48,581 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:49,026 - INFO - Epoch: [162][200/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1514 (0.1911) Acc@1 95.312 (93.540) Acc@5 100.000 (99.876)
2025-08-27 23:06:50,909 - INFO - Epoch: [162][300/391] Time 0.031 (0.019) Data 0.012 (0.003) Loss 0.2035 (0.1942) Acc@1 92.969 (93.428) Acc@5 100.000 (99.883)
2025-08-27 23:06:51,546 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:51,547 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:52,733 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3065 (0.3065) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:06:53,588 - INFO - Epoch 162:
2025-08-27 23:06:53,588 - INFO -   Train: acc1: 93.4240 | acc5: 99.8880 | loss: 0.1946 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:06:53,588 - INFO -   Val:   acc1: 90.1600 | acc5: 99.7700 | loss: 0.3006
2025-08-27 23:06:53,588 - INFO -   LR: 0.001000
2025-08-27 23:06:53,606 - INFO - 
Epoch: 163, lr = 0.0010000000000000002
2025-08-27 23:06:53,815 - INFO - Epoch: [163][0/391] Time 0.207 (0.207) Data 0.175 (0.175) Loss 0.2226 (0.2226) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:06:55,742 - INFO - Epoch: [163][100/391] Time 0.016 (0.021) Data 0.000 (0.003) Loss 0.1650 (0.1867) Acc@1 92.969 (93.634) Acc@5 100.000 (99.930)
2025-08-27 23:06:55,830 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:55,830 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:57,546 - INFO - Epoch: [163][200/391] Time 0.026 (0.020) Data 0.000 (0.002) Loss 0.1728 (0.1908) Acc@1 92.969 (93.505) Acc@5 100.000 (99.911)
2025-08-27 23:06:58,786 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:06:58,786 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:06:59,386 - INFO - Epoch: [163][300/391] Time 0.024 (0.019) Data 0.000 (0.002) Loss 0.1924 (0.1930) Acc@1 94.531 (93.415) Acc@5 100.000 (99.878)
2025-08-27 23:07:01,214 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3020 (0.3020) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:07:02,069 - INFO - Epoch 163:
2025-08-27 23:07:02,069 - INFO -   Train: acc1: 93.4540 | acc5: 99.8740 | loss: 0.1926 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:02,069 - INFO -   Val:   acc1: 90.1300 | acc5: 99.7700 | loss: 0.2978
2025-08-27 23:07:02,070 - INFO -   LR: 0.001000
2025-08-27 23:07:02,087 - INFO - 
Epoch: 164, lr = 0.0010000000000000002
2025-08-27 23:07:02,264 - INFO - Epoch: [164][0/391] Time 0.176 (0.176) Data 0.150 (0.150) Loss 0.2218 (0.2218) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:07:02,882 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:02,882 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:04,047 - INFO - Epoch: [164][100/391] Time 0.024 (0.019) Data 0.000 (0.004) Loss 0.2636 (0.1945) Acc@1 94.531 (93.603) Acc@5 100.000 (99.868)
2025-08-27 23:07:05,803 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:05,803 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:05,886 - INFO - Epoch: [164][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.2117 (0.1966) Acc@1 90.625 (93.361) Acc@5 100.000 (99.848)
2025-08-27 23:07:07,698 - INFO - Epoch: [164][300/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1647 (0.1933) Acc@1 95.312 (93.493) Acc@5 100.000 (99.862)
2025-08-27 23:07:08,663 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:08,664 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:09,496 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3145 (0.3145) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:07:10,329 - INFO - Epoch 164:
2025-08-27 23:07:10,330 - INFO -   Train: acc1: 93.4280 | acc5: 99.8620 | loss: 0.1946 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:10,330 - INFO -   Val:   acc1: 89.7300 | acc5: 99.7500 | loss: 0.3019
2025-08-27 23:07:10,330 - INFO -   LR: 0.001000
2025-08-27 23:07:10,361 - INFO - 
Epoch: 165, lr = 0.0010000000000000002
2025-08-27 23:07:10,534 - INFO - Epoch: [165][0/391] Time 0.172 (0.172) Data 0.149 (0.149) Loss 0.2986 (0.2986) Acc@1 90.625 (90.625) Acc@5 98.438 (98.438)
2025-08-27 23:07:12,367 - INFO - Epoch: [165][100/391] Time 0.025 (0.020) Data 0.000 (0.003) Loss 0.1378 (0.1953) Acc@1 94.531 (93.464) Acc@5 100.000 (99.791)
2025-08-27 23:07:12,782 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:12,783 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:14,159 - INFO - Epoch: [165][200/391] Time 0.021 (0.019) Data 0.009 (0.003) Loss 0.2152 (0.1907) Acc@1 92.188 (93.486) Acc@5 99.219 (99.829)
2025-08-27 23:07:15,669 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:15,669 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:15,975 - INFO - Epoch: [165][300/391] Time 0.016 (0.019) Data 0.000 (0.002) Loss 0.1903 (0.1910) Acc@1 94.531 (93.501) Acc@5 100.000 (99.847)
2025-08-27 23:07:17,726 - INFO - Test: [0/79] Time 0.137 (0.137) Loss 0.3119 (0.3119) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:07:18,531 - INFO - Epoch 165:
2025-08-27 23:07:18,531 - INFO -   Train: acc1: 93.4560 | acc5: 99.8580 | loss: 0.1922 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:18,532 - INFO -   Val:   acc1: 90.0900 | acc5: 99.7800 | loss: 0.3010
2025-08-27 23:07:18,532 - INFO -   LR: 0.001000
2025-08-27 23:07:18,551 - INFO - 
Epoch: 166, lr = 0.0010000000000000002
2025-08-27 23:07:18,731 - INFO - Epoch: [166][0/391] Time 0.180 (0.180) Data 0.155 (0.155) Loss 0.2091 (0.2091) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:07:19,773 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:19,773 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:20,589 - INFO - Epoch: [166][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1051 (0.1861) Acc@1 97.656 (93.642) Acc@5 99.219 (99.915)
2025-08-27 23:07:22,409 - INFO - Epoch: [166][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2086 (0.1876) Acc@1 93.750 (93.618) Acc@5 100.000 (99.903)
2025-08-27 23:07:22,648 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:22,648 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:24,247 - INFO - Epoch: [166][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1090 (0.1874) Acc@1 98.438 (93.742) Acc@5 100.000 (99.901)
2025-08-27 23:07:25,590 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:25,591 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:25,988 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2840 (0.2840) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:07:26,814 - INFO - Epoch 166:
2025-08-27 23:07:26,814 - INFO -   Train: acc1: 93.6780 | acc5: 99.8880 | loss: 0.1895 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:26,814 - INFO -   Val:   acc1: 90.0100 | acc5: 99.7700 | loss: 0.3020
2025-08-27 23:07:26,814 - INFO -   LR: 0.001000
2025-08-27 23:07:26,832 - INFO - 
Epoch: 167, lr = 0.0010000000000000002
2025-08-27 23:07:27,000 - INFO - Epoch: [167][0/391] Time 0.168 (0.168) Data 0.134 (0.134) Loss 0.1850 (0.1850) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:07:28,817 - INFO - Epoch: [167][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2017 (0.1946) Acc@1 92.969 (93.502) Acc@5 100.000 (99.884)
2025-08-27 23:07:29,537 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:29,540 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:30,655 - INFO - Epoch: [167][200/391] Time 0.015 (0.019) Data 0.000 (0.003) Loss 0.1567 (0.1917) Acc@1 93.750 (93.583) Acc@5 100.000 (99.876)
2025-08-27 23:07:32,467 - INFO - Epoch: [167][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1524 (0.1901) Acc@1 96.094 (93.685) Acc@5 100.000 (99.888)
2025-08-27 23:07:32,497 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:32,497 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:34,268 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.2878 (0.2878) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:07:35,128 - INFO - Epoch 167:
2025-08-27 23:07:35,128 - INFO -   Train: acc1: 93.6780 | acc5: 99.8840 | loss: 0.1889 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:35,128 - INFO -   Val:   acc1: 90.1300 | acc5: 99.7900 | loss: 0.2988
2025-08-27 23:07:35,128 - INFO -   LR: 0.001000
2025-08-27 23:07:35,146 - INFO - 
Epoch: 168, lr = 0.0010000000000000002
2025-08-27 23:07:35,334 - INFO - Epoch: [168][0/391] Time 0.186 (0.186) Data 0.161 (0.161) Loss 0.2737 (0.2737) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:07:36,798 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:36,798 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:37,291 - INFO - Epoch: [168][100/391] Time 0.014 (0.021) Data 0.000 (0.004) Loss 0.1400 (0.1893) Acc@1 93.750 (93.588) Acc@5 100.000 (99.853)
2025-08-27 23:07:39,153 - INFO - Epoch: [168][200/391] Time 0.035 (0.020) Data 0.000 (0.004) Loss 0.1742 (0.1902) Acc@1 93.750 (93.501) Acc@5 100.000 (99.880)
2025-08-27 23:07:39,738 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:39,738 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:41,003 - INFO - Epoch: [168][300/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.2151 (0.1914) Acc@1 91.406 (93.496) Acc@5 100.000 (99.870)
2025-08-27 23:07:42,768 - INFO - Test: [0/79] Time 0.123 (0.123) Loss 0.3076 (0.3076) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:07:43,593 - INFO - Epoch 168:
2025-08-27 23:07:43,593 - INFO -   Train: acc1: 93.4240 | acc5: 99.8780 | loss: 0.1920 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:43,594 - INFO -   Val:   acc1: 90.0800 | acc5: 99.7700 | loss: 0.2990
2025-08-27 23:07:43,594 - INFO -   LR: 0.001000
2025-08-27 23:07:43,612 - INFO - 
Epoch: 169, lr = 0.0010000000000000002
2025-08-27 23:07:43,806 - INFO - Epoch: [169][0/391] Time 0.193 (0.193) Data 0.162 (0.162) Loss 0.1917 (0.1917) Acc@1 93.750 (93.750) Acc@5 100.000 (100.000)
2025-08-27 23:07:43,820 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:43,820 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:45,603 - INFO - Epoch: [169][100/391] Time 0.011 (0.020) Data 0.000 (0.003) Loss 0.2262 (0.1884) Acc@1 90.625 (93.557) Acc@5 100.000 (99.892)
2025-08-27 23:07:46,650 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:46,651 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:47,362 - INFO - Epoch: [169][200/391] Time 0.021 (0.019) Data 0.001 (0.002) Loss 0.1234 (0.1904) Acc@1 96.094 (93.536) Acc@5 100.000 (99.876)
2025-08-27 23:07:49,248 - INFO - Epoch: [169][300/391] Time 0.022 (0.019) Data 0.000 (0.003) Loss 0.2373 (0.1899) Acc@1 88.281 (93.477) Acc@5 100.000 (99.878)
2025-08-27 23:07:49,650 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:49,650 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:51,032 - INFO - Test: [0/79] Time 0.135 (0.135) Loss 0.2948 (0.2948) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:07:51,847 - INFO - Epoch 169:
2025-08-27 23:07:51,847 - INFO -   Train: acc1: 93.4840 | acc5: 99.8700 | loss: 0.1911 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:07:51,847 - INFO -   Val:   acc1: 90.1200 | acc5: 99.7700 | loss: 0.2995
2025-08-27 23:07:51,847 - INFO -   LR: 0.001000
2025-08-27 23:07:51,866 - INFO - 
Epoch: 170, lr = 0.0010000000000000002
2025-08-27 23:07:52,035 - INFO - Epoch: [170][0/391] Time 0.167 (0.167) Data 0.151 (0.151) Loss 0.2033 (0.2033) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:07:53,661 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:53,661 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:53,852 - INFO - Epoch: [170][100/391] Time 0.011 (0.020) Data 0.000 (0.005) Loss 0.1973 (0.1906) Acc@1 94.531 (93.363) Acc@5 100.000 (99.892)
2025-08-27 23:07:55,644 - INFO - Epoch: [170][200/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.1532 (0.1910) Acc@1 92.969 (93.462) Acc@5 100.000 (99.883)
2025-08-27 23:07:56,523 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:07:56,523 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:07:57,488 - INFO - Epoch: [170][300/391] Time 0.015 (0.019) Data 0.001 (0.003) Loss 0.1780 (0.1909) Acc@1 92.969 (93.498) Acc@5 100.000 (99.896)
2025-08-27 23:07:59,242 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.3276 (0.3276) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:08:00,088 - INFO - Epoch 170:
2025-08-27 23:08:00,088 - INFO -   Train: acc1: 93.5640 | acc5: 99.8940 | loss: 0.1899 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:00,088 - INFO -   Val:   acc1: 89.9900 | acc5: 99.7600 | loss: 0.2990
2025-08-27 23:08:00,088 - INFO -   LR: 0.001000
2025-08-27 23:08:00,144 - INFO - 
Epoch: 171, lr = 0.0010000000000000002
2025-08-27 23:08:00,325 - INFO - Epoch: [171][0/391] Time 0.181 (0.181) Data 0.157 (0.157) Loss 0.1902 (0.1902) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:08:00,697 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:00,698 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:02,171 - INFO - Epoch: [171][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.2183 (0.1862) Acc@1 91.406 (93.719) Acc@5 100.000 (99.907)
2025-08-27 23:08:03,551 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:03,552 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:03,978 - INFO - Epoch: [171][200/391] Time 0.017 (0.019) Data 0.000 (0.003) Loss 0.2940 (0.1886) Acc@1 88.281 (93.711) Acc@5 99.219 (99.883)
2025-08-27 23:08:05,867 - INFO - Epoch: [171][300/391] Time 0.018 (0.019) Data 0.000 (0.003) Loss 0.1999 (0.1885) Acc@1 94.531 (93.667) Acc@5 100.000 (99.891)
2025-08-27 23:08:06,587 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:06,587 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:07,654 - INFO - Test: [0/79] Time 0.130 (0.130) Loss 0.3175 (0.3175) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:08:08,519 - INFO - Epoch 171:
2025-08-27 23:08:08,519 - INFO -   Train: acc1: 93.5940 | acc5: 99.8980 | loss: 0.1900 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:08,519 - INFO -   Val:   acc1: 89.9700 | acc5: 99.7300 | loss: 0.3023
2025-08-27 23:08:08,519 - INFO -   LR: 0.001000
2025-08-27 23:08:08,540 - INFO - 
Epoch: 172, lr = 0.0010000000000000002
2025-08-27 23:08:08,729 - INFO - Epoch: [172][0/391] Time 0.188 (0.188) Data 0.164 (0.164) Loss 0.2378 (0.2378) Acc@1 89.844 (89.844) Acc@5 100.000 (100.000)
2025-08-27 23:08:10,541 - INFO - Epoch: [172][100/391] Time 0.020 (0.020) Data 0.000 (0.004) Loss 0.1787 (0.1842) Acc@1 92.969 (93.588) Acc@5 100.000 (99.822)
2025-08-27 23:08:10,681 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:10,694 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:12,381 - INFO - Epoch: [172][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1304 (0.1827) Acc@1 96.875 (93.661) Acc@5 100.000 (99.848)
2025-08-27 23:08:13,596 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:13,596 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:14,137 - INFO - Epoch: [172][300/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1422 (0.1866) Acc@1 96.875 (93.563) Acc@5 100.000 (99.849)
2025-08-27 23:08:15,899 - INFO - Test: [0/79] Time 0.122 (0.122) Loss 0.2927 (0.2927) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:08:16,740 - INFO - Epoch 172:
2025-08-27 23:08:16,740 - INFO -   Train: acc1: 93.5280 | acc5: 99.8680 | loss: 0.1872 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:16,740 - INFO -   Val:   acc1: 90.0700 | acc5: 99.7400 | loss: 0.3017
2025-08-27 23:08:16,740 - INFO -   LR: 0.001000
2025-08-27 23:08:16,760 - INFO - 
Epoch: 173, lr = 0.0010000000000000002
2025-08-27 23:08:16,927 - INFO - Epoch: [173][0/391] Time 0.167 (0.167) Data 0.141 (0.141) Loss 0.2071 (0.2071) Acc@1 92.188 (92.188) Acc@5 100.000 (100.000)
2025-08-27 23:08:17,559 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:17,560 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:18,711 - INFO - Epoch: [173][100/391] Time 0.018 (0.019) Data 0.000 (0.004) Loss 0.1897 (0.1842) Acc@1 94.531 (93.858) Acc@5 100.000 (99.907)
2025-08-27 23:08:20,581 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:20,581 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:20,639 - INFO - Epoch: [173][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1571 (0.1872) Acc@1 94.531 (93.641) Acc@5 100.000 (99.895)
2025-08-27 23:08:22,503 - INFO - Epoch: [173][300/391] Time 0.029 (0.019) Data 0.012 (0.003) Loss 0.1520 (0.1903) Acc@1 98.438 (93.462) Acc@5 100.000 (99.891)
2025-08-27 23:08:23,524 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:23,525 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:24,292 - INFO - Test: [0/79] Time 0.146 (0.146) Loss 0.2931 (0.2931) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:08:25,101 - INFO - Epoch 173:
2025-08-27 23:08:25,101 - INFO -   Train: acc1: 93.4480 | acc5: 99.8740 | loss: 0.1914 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:25,101 - INFO -   Val:   acc1: 90.1200 | acc5: 99.7700 | loss: 0.3024
2025-08-27 23:08:25,101 - INFO -   LR: 0.001000
2025-08-27 23:08:25,118 - INFO - 
Epoch: 174, lr = 0.0010000000000000002
2025-08-27 23:08:25,315 - INFO - Epoch: [174][0/391] Time 0.196 (0.196) Data 0.175 (0.175) Loss 0.1411 (0.1411) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:08:27,103 - INFO - Epoch: [174][100/391] Time 0.014 (0.020) Data 0.000 (0.005) Loss 0.2482 (0.1909) Acc@1 89.844 (93.309) Acc@5 100.000 (99.876)
2025-08-27 23:08:27,552 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:27,552 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:28,913 - INFO - Epoch: [174][200/391] Time 0.023 (0.019) Data 0.011 (0.004) Loss 0.1240 (0.1910) Acc@1 96.875 (93.392) Acc@5 100.000 (99.845)
2025-08-27 23:08:30,570 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:30,571 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:30,876 - INFO - Epoch: [174][300/391] Time 0.031 (0.019) Data 0.018 (0.004) Loss 0.1301 (0.1915) Acc@1 96.875 (93.361) Acc@5 99.219 (99.849)
2025-08-27 23:08:32,617 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2881 (0.2881) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:08:33,462 - INFO - Epoch 174:
2025-08-27 23:08:33,462 - INFO -   Train: acc1: 93.4260 | acc5: 99.8460 | loss: 0.1913 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:33,462 - INFO -   Val:   acc1: 90.0400 | acc5: 99.7400 | loss: 0.3029
2025-08-27 23:08:33,462 - INFO -   LR: 0.001000
2025-08-27 23:08:33,482 - INFO - 
Epoch: 175, lr = 0.0010000000000000002
2025-08-27 23:08:33,685 - INFO - Epoch: [175][0/391] Time 0.202 (0.202) Data 0.178 (0.178) Loss 0.2509 (0.2509) Acc@1 89.844 (89.844) Acc@5 99.219 (99.219)
2025-08-27 23:08:34,654 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:34,654 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:35,451 - INFO - Epoch: [175][100/391] Time 0.033 (0.019) Data 0.021 (0.004) Loss 0.1707 (0.1843) Acc@1 92.969 (93.688) Acc@5 100.000 (99.915)
2025-08-27 23:08:37,353 - INFO - Epoch: [175][200/391] Time 0.021 (0.019) Data 0.000 (0.003) Loss 0.2131 (0.1862) Acc@1 90.625 (93.567) Acc@5 100.000 (99.895)
2025-08-27 23:08:37,622 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:37,623 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:39,145 - INFO - Epoch: [175][300/391] Time 0.022 (0.019) Data 0.012 (0.003) Loss 0.2080 (0.1879) Acc@1 93.750 (93.561) Acc@5 100.000 (99.901)
2025-08-27 23:08:40,494 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:40,495 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:40,939 - INFO - Test: [0/79] Time 0.169 (0.169) Loss 0.3030 (0.3030) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:08:41,779 - INFO - Epoch 175:
2025-08-27 23:08:41,779 - INFO -   Train: acc1: 93.4660 | acc5: 99.8960 | loss: 0.1889 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:41,779 - INFO -   Val:   acc1: 90.0800 | acc5: 99.7000 | loss: 0.3010
2025-08-27 23:08:41,779 - INFO -   LR: 0.001000
2025-08-27 23:08:41,799 - INFO - 
Epoch: 176, lr = 0.0010000000000000002
2025-08-27 23:08:41,985 - INFO - Epoch: [176][0/391] Time 0.185 (0.185) Data 0.143 (0.143) Loss 0.1652 (0.1652) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:08:43,813 - INFO - Epoch: [176][100/391] Time 0.013 (0.020) Data 0.000 (0.003) Loss 0.2354 (0.1899) Acc@1 92.188 (93.533) Acc@5 100.000 (99.868)
2025-08-27 23:08:44,657 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:44,657 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:45,704 - INFO - Epoch: [176][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1507 (0.1889) Acc@1 94.531 (93.517) Acc@5 100.000 (99.864)
2025-08-27 23:08:47,481 - INFO - Epoch: [176][300/391] Time 0.019 (0.019) Data 0.000 (0.002) Loss 0.1912 (0.1902) Acc@1 91.406 (93.446) Acc@5 100.000 (99.865)
2025-08-27 23:08:47,556 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:47,556 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:49,227 - INFO - Test: [0/79] Time 0.136 (0.136) Loss 0.2997 (0.2997) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:08:50,072 - INFO - Epoch 176:
2025-08-27 23:08:50,072 - INFO -   Train: acc1: 93.5280 | acc5: 99.8760 | loss: 0.1890 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:50,073 - INFO -   Val:   acc1: 90.1200 | acc5: 99.7200 | loss: 0.3031
2025-08-27 23:08:50,073 - INFO -   LR: 0.001000
2025-08-27 23:08:50,094 - INFO - 
Epoch: 177, lr = 0.0010000000000000002
2025-08-27 23:08:50,273 - INFO - Epoch: [177][0/391] Time 0.177 (0.177) Data 0.158 (0.158) Loss 0.1052 (0.1052) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 23:08:51,578 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:51,578 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:52,055 - INFO - Epoch: [177][100/391] Time 0.043 (0.019) Data 0.025 (0.004) Loss 0.1299 (0.1876) Acc@1 95.312 (93.642) Acc@5 100.000 (99.868)
2025-08-27 23:08:53,888 - INFO - Epoch: [177][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1058 (0.1851) Acc@1 98.438 (93.630) Acc@5 100.000 (99.872)
2025-08-27 23:08:54,456 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:54,456 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:08:55,662 - INFO - Epoch: [177][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.3032 (0.1882) Acc@1 89.844 (93.522) Acc@5 99.219 (99.865)
2025-08-27 23:08:57,447 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2876 (0.2876) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:08:58,332 - INFO - Epoch 177:
2025-08-27 23:08:58,332 - INFO -   Train: acc1: 93.5600 | acc5: 99.8820 | loss: 0.1874 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:08:58,332 - INFO -   Val:   acc1: 90.0600 | acc5: 99.7300 | loss: 0.3036
2025-08-27 23:08:58,332 - INFO -   LR: 0.001000
2025-08-27 23:08:58,609 - INFO - 
Epoch: 178, lr = 0.0010000000000000002
2025-08-27 23:08:58,784 - INFO - Epoch: [178][0/391] Time 0.174 (0.174) Data 0.158 (0.158) Loss 0.1278 (0.1278) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 23:08:58,806 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:08:58,807 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:00,671 - INFO - Epoch: [178][100/391] Time 0.028 (0.020) Data 0.016 (0.004) Loss 0.1616 (0.1864) Acc@1 93.750 (93.649) Acc@5 99.219 (99.861)
2025-08-27 23:09:01,826 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:01,827 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:02,536 - INFO - Epoch: [178][200/391] Time 0.028 (0.020) Data 0.000 (0.003) Loss 0.2204 (0.1901) Acc@1 91.406 (93.486) Acc@5 100.000 (99.868)
2025-08-27 23:09:04,286 - INFO - Epoch: [178][300/391] Time 0.031 (0.019) Data 0.010 (0.003) Loss 0.2128 (0.1886) Acc@1 92.969 (93.532) Acc@5 100.000 (99.878)
2025-08-27 23:09:04,651 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:04,651 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:06,033 - INFO - Test: [0/79] Time 0.129 (0.129) Loss 0.2868 (0.2868) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:09:06,870 - INFO - Epoch 178:
2025-08-27 23:09:06,870 - INFO -   Train: acc1: 93.6260 | acc5: 99.8880 | loss: 0.1867 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:06,870 - INFO -   Val:   acc1: 90.0000 | acc5: 99.7400 | loss: 0.3049
2025-08-27 23:09:06,870 - INFO -   LR: 0.001000
2025-08-27 23:09:06,890 - INFO - 
Epoch: 179, lr = 0.0010000000000000002
2025-08-27 23:09:07,067 - INFO - Epoch: [179][0/391] Time 0.175 (0.175) Data 0.153 (0.153) Loss 0.2217 (0.2217) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:09:08,659 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:08,659 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:08,847 - INFO - Epoch: [179][100/391] Time 0.014 (0.019) Data 0.000 (0.004) Loss 0.1897 (0.1866) Acc@1 93.750 (93.750) Acc@5 100.000 (99.892)
2025-08-27 23:09:10,657 - INFO - Epoch: [179][200/391] Time 0.025 (0.019) Data 0.000 (0.003) Loss 0.2547 (0.1825) Acc@1 88.281 (93.902) Acc@5 100.000 (99.907)
2025-08-27 23:09:11,553 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:11,553 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:12,498 - INFO - Epoch: [179][300/391] Time 0.029 (0.019) Data 0.000 (0.003) Loss 0.1818 (0.1864) Acc@1 93.750 (93.690) Acc@5 100.000 (99.907)
2025-08-27 23:09:14,215 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3004 (0.3004) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:09:15,055 - INFO - Epoch 179:
2025-08-27 23:09:15,055 - INFO -   Train: acc1: 93.6820 | acc5: 99.8980 | loss: 0.1861 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:15,055 - INFO -   Val:   acc1: 89.9300 | acc5: 99.7500 | loss: 0.3026
2025-08-27 23:09:15,055 - INFO -   LR: 0.001000
2025-08-27 23:09:15,074 - INFO - 
Epoch: 180, lr = 0.0010000000000000002
2025-08-27 23:09:15,250 - INFO - Epoch: [180][0/391] Time 0.175 (0.175) Data 0.152 (0.152) Loss 0.3131 (0.3131) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:09:15,571 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:15,571 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:17,060 - INFO - Epoch: [180][100/391] Time 0.044 (0.020) Data 0.004 (0.004) Loss 0.1427 (0.1912) Acc@1 96.875 (93.472) Acc@5 100.000 (99.853)
2025-08-27 23:09:18,496 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:18,496 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:18,876 - INFO - Epoch: [180][200/391] Time 0.023 (0.019) Data 0.012 (0.003) Loss 0.1616 (0.1911) Acc@1 95.312 (93.482) Acc@5 100.000 (99.868)
2025-08-27 23:09:20,712 - INFO - Epoch: [180][300/391] Time 0.031 (0.019) Data 0.019 (0.003) Loss 0.1781 (0.1896) Acc@1 92.188 (93.485) Acc@5 100.000 (99.873)
2025-08-27 23:09:21,408 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:21,409 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:22,450 - INFO - Test: [0/79] Time 0.143 (0.143) Loss 0.3126 (0.3126) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:09:23,234 - INFO - Epoch 180:
2025-08-27 23:09:23,234 - INFO -   Train: acc1: 93.5200 | acc5: 99.8820 | loss: 0.1891 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:23,234 - INFO -   Val:   acc1: 90.0700 | acc5: 99.7400 | loss: 0.3022
2025-08-27 23:09:23,234 - INFO -   LR: 0.001000
2025-08-27 23:09:23,285 - INFO - 
Epoch: 181, lr = 0.0010000000000000002
2025-08-27 23:09:23,461 - INFO - Epoch: [181][0/391] Time 0.174 (0.174) Data 0.143 (0.143) Loss 0.2042 (0.2042) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:09:25,296 - INFO - Epoch: [181][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1607 (0.1827) Acc@1 94.531 (93.649) Acc@5 100.000 (99.923)
2025-08-27 23:09:25,464 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:25,465 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:27,114 - INFO - Epoch: [181][200/391] Time 0.041 (0.019) Data 0.028 (0.004) Loss 0.1436 (0.1844) Acc@1 94.531 (93.672) Acc@5 100.000 (99.903)
2025-08-27 23:09:28,378 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:28,378 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:28,908 - INFO - Epoch: [181][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1816 (0.1837) Acc@1 93.750 (93.745) Acc@5 99.219 (99.894)
2025-08-27 23:09:30,678 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3109 (0.3109) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:09:31,501 - INFO - Epoch 181:
2025-08-27 23:09:31,501 - INFO -   Train: acc1: 93.6800 | acc5: 99.9020 | loss: 0.1854 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:31,501 - INFO -   Val:   acc1: 89.8800 | acc5: 99.7700 | loss: 0.3086
2025-08-27 23:09:31,501 - INFO -   LR: 0.001000
2025-08-27 23:09:31,520 - INFO - 
Epoch: 182, lr = 0.0010000000000000002
2025-08-27 23:09:31,697 - INFO - Epoch: [182][0/391] Time 0.176 (0.176) Data 0.149 (0.149) Loss 0.1871 (0.1871) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:09:32,448 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:32,448 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:33,566 - INFO - Epoch: [182][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1207 (0.1837) Acc@1 97.656 (93.704) Acc@5 100.000 (99.946)
2025-08-27 23:09:35,348 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:35,348 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:35,387 - INFO - Epoch: [182][200/391] Time 0.016 (0.019) Data 0.000 (0.003) Loss 0.1667 (0.1826) Acc@1 94.531 (93.820) Acc@5 100.000 (99.922)
2025-08-27 23:09:37,155 - INFO - Epoch: [182][300/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1359 (0.1850) Acc@1 95.312 (93.737) Acc@5 100.000 (99.907)
2025-08-27 23:09:38,169 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:38,169 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:38,921 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2900 (0.2900) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:09:39,784 - INFO - Epoch 182:
2025-08-27 23:09:39,784 - INFO -   Train: acc1: 93.6700 | acc5: 99.9000 | loss: 0.1860 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:39,784 - INFO -   Val:   acc1: 90.1000 | acc5: 99.7200 | loss: 0.3020
2025-08-27 23:09:39,784 - INFO -   LR: 0.001000
2025-08-27 23:09:39,805 - INFO - 
Epoch: 183, lr = 0.0010000000000000002
2025-08-27 23:09:39,975 - INFO - Epoch: [183][0/391] Time 0.169 (0.169) Data 0.149 (0.149) Loss 0.1151 (0.1151) Acc@1 97.656 (97.656) Acc@5 100.000 (100.000)
2025-08-27 23:09:41,768 - INFO - Epoch: [183][100/391] Time 0.019 (0.019) Data 0.000 (0.004) Loss 0.1895 (0.1919) Acc@1 93.750 (93.580) Acc@5 99.219 (99.876)
2025-08-27 23:09:42,242 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:42,245 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:43,557 - INFO - Epoch: [183][200/391] Time 0.012 (0.019) Data 0.000 (0.003) Loss 0.1789 (0.1880) Acc@1 95.312 (93.715) Acc@5 99.219 (99.880)
2025-08-27 23:09:45,118 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:45,118 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:45,362 - INFO - Epoch: [183][300/391] Time 0.016 (0.018) Data 0.000 (0.003) Loss 0.1376 (0.1888) Acc@1 96.094 (93.649) Acc@5 100.000 (99.878)
2025-08-27 23:09:47,152 - INFO - Test: [0/79] Time 0.147 (0.147) Loss 0.3043 (0.3043) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:09:47,983 - INFO - Epoch 183:
2025-08-27 23:09:47,983 - INFO -   Train: acc1: 93.6460 | acc5: 99.8840 | loss: 0.1875 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:47,983 - INFO -   Val:   acc1: 90.2300 | acc5: 99.7400 | loss: 0.3032
2025-08-27 23:09:47,983 - INFO -   LR: 0.001000
2025-08-27 23:09:48,034 - INFO - Checkpoint saved: epoch=183, metric=90.2300
2025-08-27 23:09:48,067 - INFO - 
Epoch: 184, lr = 0.0010000000000000002
2025-08-27 23:09:48,262 - INFO - Epoch: [184][0/391] Time 0.194 (0.194) Data 0.173 (0.173) Loss 0.2364 (0.2364) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:09:49,315 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:49,315 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:50,087 - INFO - Epoch: [184][100/391] Time 0.027 (0.020) Data 0.000 (0.004) Loss 0.1497 (0.1842) Acc@1 95.312 (93.843) Acc@5 100.000 (99.930)
2025-08-27 23:09:51,870 - INFO - Epoch: [184][200/391] Time 0.028 (0.019) Data 0.000 (0.003) Loss 0.1529 (0.1841) Acc@1 93.750 (93.816) Acc@5 100.000 (99.914)
2025-08-27 23:09:52,153 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:52,153 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:53,713 - INFO - Epoch: [184][300/391] Time 0.021 (0.019) Data 0.007 (0.003) Loss 0.2073 (0.1825) Acc@1 94.531 (93.888) Acc@5 100.000 (99.909)
2025-08-27 23:09:55,088 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:55,088 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:09:55,474 - INFO - Test: [0/79] Time 0.125 (0.125) Loss 0.3048 (0.3048) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:09:56,287 - INFO - Epoch 184:
2025-08-27 23:09:56,287 - INFO -   Train: acc1: 93.8280 | acc5: 99.8880 | loss: 0.1841 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:09:56,287 - INFO -   Val:   acc1: 90.1900 | acc5: 99.7700 | loss: 0.3016
2025-08-27 23:09:56,287 - INFO -   LR: 0.001000
2025-08-27 23:09:56,307 - INFO - 
Epoch: 185, lr = 0.0010000000000000002
2025-08-27 23:09:56,504 - INFO - Epoch: [185][0/391] Time 0.197 (0.197) Data 0.174 (0.174) Loss 0.3337 (0.3337) Acc@1 87.500 (87.500) Acc@5 99.219 (99.219)
2025-08-27 23:09:58,289 - INFO - Epoch: [185][100/391] Time 0.017 (0.020) Data 0.000 (0.004) Loss 0.1661 (0.1818) Acc@1 94.531 (93.804) Acc@5 100.000 (99.907)
2025-08-27 23:09:59,048 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:09:59,048 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:00,087 - INFO - Epoch: [185][200/391] Time 0.014 (0.019) Data 0.000 (0.003) Loss 0.1885 (0.1840) Acc@1 90.625 (93.645) Acc@5 100.000 (99.887)
2025-08-27 23:10:01,883 - INFO - Epoch: [185][300/391] Time 0.039 (0.019) Data 0.028 (0.003) Loss 0.2449 (0.1856) Acc@1 93.750 (93.646) Acc@5 100.000 (99.865)
2025-08-27 23:10:01,944 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:01,944 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:03,669 - INFO - Test: [0/79] Time 0.140 (0.140) Loss 0.3168 (0.3168) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:10:04,488 - INFO - Epoch 185:
2025-08-27 23:10:04,488 - INFO -   Train: acc1: 93.5940 | acc5: 99.8720 | loss: 0.1866 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:04,488 - INFO -   Val:   acc1: 90.0300 | acc5: 99.7400 | loss: 0.3052
2025-08-27 23:10:04,488 - INFO -   LR: 0.001000
2025-08-27 23:10:04,508 - INFO - 
Epoch: 186, lr = 0.0010000000000000002
2025-08-27 23:10:04,665 - INFO - Epoch: [186][0/391] Time 0.157 (0.157) Data 0.135 (0.135) Loss 0.1838 (0.1838) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:10:05,979 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:05,979 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:06,474 - INFO - Epoch: [186][100/391] Time 0.011 (0.019) Data 0.000 (0.005) Loss 0.2031 (0.1810) Acc@1 93.750 (93.974) Acc@5 100.000 (99.915)
2025-08-27 23:10:08,299 - INFO - Epoch: [186][200/391] Time 0.015 (0.019) Data 0.000 (0.004) Loss 0.2419 (0.1837) Acc@1 90.625 (93.851) Acc@5 99.219 (99.911)
2025-08-27 23:10:08,882 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:08,882 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:10,033 - INFO - Epoch: [186][300/391] Time 0.024 (0.018) Data 0.014 (0.003) Loss 0.1503 (0.1856) Acc@1 94.531 (93.750) Acc@5 100.000 (99.888)
2025-08-27 23:10:11,818 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2851 (0.2851) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:10:12,659 - INFO - Epoch 186:
2025-08-27 23:10:12,659 - INFO -   Train: acc1: 93.6140 | acc5: 99.8880 | loss: 0.1874 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:12,659 - INFO -   Val:   acc1: 90.0300 | acc5: 99.7400 | loss: 0.3031
2025-08-27 23:10:12,659 - INFO -   LR: 0.001000
2025-08-27 23:10:12,679 - INFO - 
Epoch: 187, lr = 0.0010000000000000002
2025-08-27 23:10:12,825 - INFO - Epoch: [187][0/391] Time 0.145 (0.145) Data 0.128 (0.128) Loss 0.1750 (0.1750) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:10:12,875 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:12,875 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:14,567 - INFO - Epoch: [187][100/391] Time 0.022 (0.019) Data 0.004 (0.003) Loss 0.2132 (0.1867) Acc@1 90.625 (93.673) Acc@5 100.000 (99.830)
2025-08-27 23:10:15,656 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:15,657 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:16,371 - INFO - Epoch: [187][200/391] Time 0.028 (0.018) Data 0.003 (0.003) Loss 0.2055 (0.1840) Acc@1 92.969 (93.766) Acc@5 100.000 (99.856)
2025-08-27 23:10:18,144 - INFO - Epoch: [187][300/391] Time 0.053 (0.018) Data 0.025 (0.003) Loss 0.1228 (0.1847) Acc@1 98.438 (93.825) Acc@5 100.000 (99.891)
2025-08-27 23:10:18,491 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:18,492 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:19,822 - INFO - Test: [0/79] Time 0.131 (0.131) Loss 0.3124 (0.3124) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:10:20,628 - INFO - Epoch 187:
2025-08-27 23:10:20,628 - INFO -   Train: acc1: 93.7500 | acc5: 99.8980 | loss: 0.1849 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:20,628 - INFO -   Val:   acc1: 90.0600 | acc5: 99.7200 | loss: 0.3019
2025-08-27 23:10:20,628 - INFO -   LR: 0.001000
2025-08-27 23:10:20,647 - INFO - 
Epoch: 188, lr = 0.0010000000000000002
2025-08-27 23:10:20,839 - INFO - Epoch: [188][0/391] Time 0.191 (0.191) Data 0.168 (0.168) Loss 0.1119 (0.1119) Acc@1 96.875 (96.875) Acc@5 100.000 (100.000)
2025-08-27 23:10:22,454 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:22,455 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:22,619 - INFO - Epoch: [188][100/391] Time 0.025 (0.020) Data 0.014 (0.004) Loss 0.2109 (0.1873) Acc@1 92.969 (93.696) Acc@5 98.438 (99.884)
2025-08-27 23:10:24,446 - INFO - Epoch: [188][200/391] Time 0.038 (0.019) Data 0.027 (0.003) Loss 0.1901 (0.1853) Acc@1 92.969 (93.731) Acc@5 100.000 (99.918)
2025-08-27 23:10:25,361 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:25,361 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:26,198 - INFO - Epoch: [188][300/391] Time 0.017 (0.018) Data 0.000 (0.003) Loss 0.2121 (0.1831) Acc@1 93.750 (93.817) Acc@5 100.000 (99.914)
2025-08-27 23:10:27,928 - INFO - Test: [0/79] Time 0.148 (0.148) Loss 0.3041 (0.3041) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:10:28,755 - INFO - Epoch 188:
2025-08-27 23:10:28,756 - INFO -   Train: acc1: 93.7940 | acc5: 99.9000 | loss: 0.1833 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:28,756 - INFO -   Val:   acc1: 90.1400 | acc5: 99.7400 | loss: 0.3058
2025-08-27 23:10:28,756 - INFO -   LR: 0.001000
2025-08-27 23:10:28,775 - INFO - 
Epoch: 189, lr = 0.0010000000000000002
2025-08-27 23:10:28,943 - INFO - Epoch: [189][0/391] Time 0.166 (0.166) Data 0.145 (0.145) Loss 0.2006 (0.2006) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:10:29,276 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:29,280 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:30,695 - INFO - Epoch: [189][100/391] Time 0.057 (0.019) Data 0.035 (0.004) Loss 0.1896 (0.1854) Acc@1 92.188 (93.727) Acc@5 100.000 (99.853)
2025-08-27 23:10:32,170 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:32,170 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:32,507 - INFO - Epoch: [189][200/391] Time 0.017 (0.019) Data 0.007 (0.003) Loss 0.1487 (0.1889) Acc@1 94.531 (93.501) Acc@5 100.000 (99.868)
2025-08-27 23:10:34,227 - INFO - Epoch: [189][300/391] Time 0.014 (0.018) Data 0.001 (0.003) Loss 0.1569 (0.1850) Acc@1 94.531 (93.586) Acc@5 100.000 (99.875)
2025-08-27 23:10:34,939 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:34,939 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:35,981 - INFO - Test: [0/79] Time 0.145 (0.145) Loss 0.3080 (0.3080) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:10:36,825 - INFO - Epoch 189:
2025-08-27 23:10:36,825 - INFO -   Train: acc1: 93.5620 | acc5: 99.8680 | loss: 0.1864 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:36,825 - INFO -   Val:   acc1: 89.9500 | acc5: 99.7400 | loss: 0.3050
2025-08-27 23:10:36,825 - INFO -   LR: 0.001000
2025-08-27 23:10:36,844 - INFO - 
Epoch: 190, lr = 0.0010000000000000002
2025-08-27 23:10:37,033 - INFO - Epoch: [190][0/391] Time 0.188 (0.188) Data 0.171 (0.171) Loss 0.1904 (0.1904) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:10:38,888 - INFO - Epoch: [190][100/391] Time 0.016 (0.020) Data 0.000 (0.005) Loss 0.2361 (0.1881) Acc@1 92.188 (93.502) Acc@5 100.000 (99.884)
2025-08-27 23:10:39,025 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:39,025 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:40,705 - INFO - Epoch: [190][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1433 (0.1860) Acc@1 94.531 (93.738) Acc@5 100.000 (99.872)
2025-08-27 23:10:41,993 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:41,994 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:42,566 - INFO - Epoch: [190][300/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.1818 (0.1842) Acc@1 93.750 (93.753) Acc@5 100.000 (99.886)
2025-08-27 23:10:44,328 - INFO - Test: [0/79] Time 0.134 (0.134) Loss 0.3099 (0.3099) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:10:45,164 - INFO - Epoch 190:
2025-08-27 23:10:45,164 - INFO -   Train: acc1: 93.7560 | acc5: 99.8820 | loss: 0.1850 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:45,164 - INFO -   Val:   acc1: 90.1400 | acc5: 99.7400 | loss: 0.3052
2025-08-27 23:10:45,164 - INFO -   LR: 0.001000
2025-08-27 23:10:45,219 - INFO - 
Epoch: 191, lr = 0.0010000000000000002
2025-08-27 23:10:45,353 - INFO - Epoch: [191][0/391] Time 0.133 (0.133) Data 0.117 (0.117) Loss 0.1870 (0.1870) Acc@1 92.969 (92.969) Acc@5 100.000 (100.000)
2025-08-27 23:10:46,066 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:46,066 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:47,209 - INFO - Epoch: [191][100/391] Time 0.018 (0.020) Data 0.000 (0.004) Loss 0.1475 (0.1838) Acc@1 94.531 (93.634) Acc@5 100.000 (99.853)
2025-08-27 23:10:48,984 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:48,984 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:49,022 - INFO - Epoch: [191][200/391] Time 0.020 (0.019) Data 0.003 (0.003) Loss 0.1206 (0.1854) Acc@1 96.875 (93.661) Acc@5 100.000 (99.852)
2025-08-27 23:10:50,816 - INFO - Epoch: [191][300/391] Time 0.019 (0.019) Data 0.001 (0.003) Loss 0.2338 (0.1825) Acc@1 92.969 (93.771) Acc@5 100.000 (99.857)
2025-08-27 23:10:51,904 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:51,904 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:52,590 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2958 (0.2958) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:10:53,455 - INFO - Epoch 191:
2025-08-27 23:10:53,455 - INFO -   Train: acc1: 93.6240 | acc5: 99.8580 | loss: 0.1852 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:10:53,455 - INFO -   Val:   acc1: 90.0400 | acc5: 99.7300 | loss: 0.3066
2025-08-27 23:10:53,455 - INFO -   LR: 0.001000
2025-08-27 23:10:53,473 - INFO - 
Epoch: 192, lr = 0.0010000000000000002
2025-08-27 23:10:53,671 - INFO - Epoch: [192][0/391] Time 0.196 (0.196) Data 0.174 (0.174) Loss 0.1488 (0.1488) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:10:55,471 - INFO - Epoch: [192][100/391] Time 0.011 (0.020) Data 0.000 (0.004) Loss 0.1484 (0.1825) Acc@1 94.531 (93.789) Acc@5 100.000 (99.892)
2025-08-27 23:10:55,984 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:55,984 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:57,281 - INFO - Epoch: [192][200/391] Time 0.016 (0.019) Data 0.005 (0.003) Loss 0.2086 (0.1836) Acc@1 92.969 (93.696) Acc@5 100.000 (99.887)
2025-08-27 23:10:58,783 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:10:58,790 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:10:59,026 - INFO - Epoch: [192][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1433 (0.1836) Acc@1 93.750 (93.716) Acc@5 100.000 (99.875)
2025-08-27 23:11:00,847 - INFO - Test: [0/79] Time 0.126 (0.126) Loss 0.2775 (0.2775) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:11:01,649 - INFO - Epoch 192:
2025-08-27 23:11:01,649 - INFO -   Train: acc1: 93.6280 | acc5: 99.8800 | loss: 0.1861 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:01,649 - INFO -   Val:   acc1: 90.0900 | acc5: 99.7700 | loss: 0.3049
2025-08-27 23:11:01,649 - INFO -   LR: 0.001000
2025-08-27 23:11:01,670 - INFO - 
Epoch: 193, lr = 0.0010000000000000002
2025-08-27 23:11:01,848 - INFO - Epoch: [193][0/391] Time 0.176 (0.176) Data 0.158 (0.158) Loss 0.2378 (0.2378) Acc@1 90.625 (90.625) Acc@5 99.219 (99.219)
2025-08-27 23:11:02,833 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:02,834 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:03,638 - INFO - Epoch: [193][100/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2198 (0.1792) Acc@1 88.281 (93.943) Acc@5 100.000 (99.861)
2025-08-27 23:11:05,405 - INFO - Epoch: [193][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2024 (0.1850) Acc@1 92.969 (93.742) Acc@5 100.000 (99.876)
2025-08-27 23:11:05,701 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:05,702 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:07,245 - INFO - Epoch: [193][300/391] Time 0.013 (0.019) Data 0.000 (0.003) Loss 0.2176 (0.1854) Acc@1 93.750 (93.654) Acc@5 100.000 (99.868)
2025-08-27 23:11:08,649 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:08,649 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:09,037 - INFO - Test: [0/79] Time 0.116 (0.116) Loss 0.2941 (0.2941) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:11:09,906 - INFO - Epoch 193:
2025-08-27 23:11:09,906 - INFO -   Train: acc1: 93.6980 | acc5: 99.8640 | loss: 0.1863 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:09,906 - INFO -   Val:   acc1: 90.1200 | acc5: 99.7600 | loss: 0.3028
2025-08-27 23:11:09,907 - INFO -   LR: 0.001000
2025-08-27 23:11:09,929 - INFO - 
Epoch: 194, lr = 0.0010000000000000002
2025-08-27 23:11:10,120 - INFO - Epoch: [194][0/391] Time 0.191 (0.191) Data 0.173 (0.173) Loss 0.1416 (0.1416) Acc@1 94.531 (94.531) Acc@5 100.000 (100.000)
2025-08-27 23:11:11,887 - INFO - Epoch: [194][100/391] Time 0.013 (0.019) Data 0.000 (0.005) Loss 0.1455 (0.1826) Acc@1 95.312 (94.005) Acc@5 100.000 (99.899)
2025-08-27 23:11:12,808 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:12,808 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:13,818 - INFO - Epoch: [194][200/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1919 (0.1833) Acc@1 93.750 (93.878) Acc@5 100.000 (99.883)
2025-08-27 23:11:15,618 - INFO - Epoch: [194][300/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.1755 (0.1831) Acc@1 93.750 (93.867) Acc@5 100.000 (99.894)
2025-08-27 23:11:15,742 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:15,742 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:17,366 - INFO - Test: [0/79] Time 0.139 (0.139) Loss 0.3001 (0.3001) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:11:18,183 - INFO - Epoch 194:
2025-08-27 23:11:18,183 - INFO -   Train: acc1: 93.8380 | acc5: 99.8940 | loss: 0.1828 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:18,183 - INFO -   Val:   acc1: 90.0000 | acc5: 99.7600 | loss: 0.3091
2025-08-27 23:11:18,183 - INFO -   LR: 0.001000
2025-08-27 23:11:18,203 - INFO - 
Epoch: 195, lr = 0.0010000000000000002
2025-08-27 23:11:18,400 - INFO - Epoch: [195][0/391] Time 0.196 (0.196) Data 0.174 (0.174) Loss 0.1203 (0.1203) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:11:19,739 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:19,739 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:20,189 - INFO - Epoch: [195][100/391] Time 0.023 (0.020) Data 0.000 (0.004) Loss 0.1077 (0.1770) Acc@1 96.094 (94.083) Acc@5 100.000 (99.845)
2025-08-27 23:11:21,993 - INFO - Epoch: [195][200/391] Time 0.012 (0.019) Data 0.000 (0.004) Loss 0.2387 (0.1797) Acc@1 92.188 (93.929) Acc@5 100.000 (99.860)
2025-08-27 23:11:22,616 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:22,616 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:23,787 - INFO - Epoch: [195][300/391] Time 0.024 (0.019) Data 0.000 (0.003) Loss 0.1291 (0.1813) Acc@1 97.656 (93.952) Acc@5 100.000 (99.868)
2025-08-27 23:11:25,474 - INFO - Test: [0/79] Time 0.127 (0.127) Loss 0.2989 (0.2989) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:11:26,284 - INFO - Epoch 195:
2025-08-27 23:11:26,284 - INFO -   Train: acc1: 93.8700 | acc5: 99.8760 | loss: 0.1827 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:26,284 - INFO -   Val:   acc1: 90.1200 | acc5: 99.7100 | loss: 0.3039
2025-08-27 23:11:26,284 - INFO -   LR: 0.001000
2025-08-27 23:11:26,304 - INFO - 
Epoch: 196, lr = 0.0010000000000000002
2025-08-27 23:11:26,482 - INFO - Epoch: [196][0/391] Time 0.178 (0.178) Data 0.154 (0.154) Loss 0.2380 (0.2380) Acc@1 91.406 (91.406) Acc@5 100.000 (100.000)
2025-08-27 23:11:26,543 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:26,543 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:28,202 - INFO - Epoch: [196][100/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.1550 (0.1854) Acc@1 94.531 (93.533) Acc@5 99.219 (99.876)
2025-08-27 23:11:29,304 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:29,304 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:29,942 - INFO - Epoch: [196][200/391] Time 0.012 (0.018) Data 0.000 (0.003) Loss 0.1210 (0.1830) Acc@1 96.875 (93.645) Acc@5 100.000 (99.891)
2025-08-27 23:11:31,687 - INFO - Epoch: [196][300/391] Time 0.014 (0.018) Data 0.000 (0.003) Loss 0.1673 (0.1819) Acc@1 95.312 (93.664) Acc@5 99.219 (99.891)
2025-08-27 23:11:32,080 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:32,080 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:33,373 - INFO - Test: [0/79] Time 0.113 (0.113) Loss 0.2834 (0.2834) Acc@1 91.406 (91.406) Acc@5 99.219 (99.219)
2025-08-27 23:11:34,183 - INFO - Epoch 196:
2025-08-27 23:11:34,183 - INFO -   Train: acc1: 93.6720 | acc5: 99.8980 | loss: 0.1828 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:34,183 - INFO -   Val:   acc1: 90.1100 | acc5: 99.7200 | loss: 0.3086
2025-08-27 23:11:34,183 - INFO -   LR: 0.001000
2025-08-27 23:11:34,205 - INFO - 
Epoch: 197, lr = 0.0010000000000000002
2025-08-27 23:11:34,382 - INFO - Epoch: [197][0/391] Time 0.177 (0.177) Data 0.153 (0.153) Loss 0.1845 (0.1845) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:11:36,004 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:36,004 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:36,124 - INFO - Epoch: [197][100/391] Time 0.019 (0.019) Data 0.000 (0.003) Loss 0.2801 (0.1890) Acc@1 91.406 (93.456) Acc@5 99.219 (99.884)
2025-08-27 23:11:37,935 - INFO - Epoch: [197][200/391] Time 0.011 (0.019) Data 0.000 (0.003) Loss 0.1938 (0.1859) Acc@1 91.406 (93.482) Acc@5 100.000 (99.891)
2025-08-27 23:11:38,870 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:38,883 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:39,741 - INFO - Epoch: [197][300/391] Time 0.025 (0.018) Data 0.000 (0.003) Loss 0.1656 (0.1828) Acc@1 94.531 (93.612) Acc@5 100.000 (99.894)
2025-08-27 23:11:41,538 - INFO - Test: [0/79] Time 0.138 (0.138) Loss 0.2868 (0.2868) Acc@1 92.188 (92.188) Acc@5 99.219 (99.219)
2025-08-27 23:11:42,400 - INFO - Epoch 197:
2025-08-27 23:11:42,400 - INFO -   Train: acc1: 93.6680 | acc5: 99.9080 | loss: 0.1811 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:42,400 - INFO -   Val:   acc1: 89.9600 | acc5: 99.7200 | loss: 0.3058
2025-08-27 23:11:42,400 - INFO -   LR: 0.001000
2025-08-27 23:11:42,420 - INFO - 
Epoch: 198, lr = 0.0010000000000000002
2025-08-27 23:11:42,590 - INFO - Epoch: [198][0/391] Time 0.169 (0.169) Data 0.151 (0.151) Loss 0.1496 (0.1496) Acc@1 95.312 (95.312) Acc@5 100.000 (100.000)
2025-08-27 23:11:42,960 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:42,961 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:44,381 - INFO - Epoch: [198][100/391] Time 0.027 (0.019) Data 0.017 (0.004) Loss 0.1092 (0.1799) Acc@1 96.875 (93.727) Acc@5 100.000 (99.884)
2025-08-27 23:11:45,818 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:45,818 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:46,193 - INFO - Epoch: [198][200/391] Time 0.016 (0.019) Data 0.000 (0.004) Loss 0.2105 (0.1849) Acc@1 94.531 (93.540) Acc@5 100.000 (99.880)
2025-08-27 23:11:48,030 - INFO - Epoch: [198][300/391] Time 0.031 (0.019) Data 0.019 (0.004) Loss 0.1687 (0.1822) Acc@1 93.750 (93.672) Acc@5 100.000 (99.881)
2025-08-27 23:11:48,815 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:48,816 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:49,805 - INFO - Test: [0/79] Time 0.133 (0.133) Loss 0.2853 (0.2853) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:11:50,640 - INFO - Epoch 198:
2025-08-27 23:11:50,640 - INFO -   Train: acc1: 93.6580 | acc5: 99.8880 | loss: 0.1828 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:50,640 - INFO -   Val:   acc1: 89.9100 | acc5: 99.7200 | loss: 0.3055
2025-08-27 23:11:50,640 - INFO -   LR: 0.001000
2025-08-27 23:11:50,660 - INFO - 
Epoch: 199, lr = 0.0010000000000000002
2025-08-27 23:11:50,826 - INFO - Epoch: [199][0/391] Time 0.165 (0.165) Data 0.147 (0.147) Loss 0.1418 (0.1418) Acc@1 96.094 (96.094) Acc@5 100.000 (100.000)
2025-08-27 23:11:52,624 - INFO - Epoch: [199][100/391] Time 0.011 (0.019) Data 0.000 (0.004) Loss 0.2241 (0.1735) Acc@1 92.969 (93.990) Acc@5 99.219 (99.899)
2025-08-27 23:11:52,805 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:52,805 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:54,428 - INFO - Epoch: [199][200/391] Time 0.026 (0.019) Data 0.000 (0.003) Loss 0.1877 (0.1768) Acc@1 91.406 (93.964) Acc@5 100.000 (99.926)
2025-08-27 23:11:55,699 - INFO - Pruning info: sparsity=0.900
2025-08-27 23:11:55,699 - INFO -   Reactivation rate: 0.0000
2025-08-27 23:11:56,215 - INFO - Epoch: [199][300/391] Time 0.011 (0.018) Data 0.000 (0.003) Loss 0.1962 (0.1801) Acc@1 94.531 (93.849) Acc@5 98.438 (99.912)
2025-08-27 23:11:58,137 - INFO - Test: [0/79] Time 0.132 (0.132) Loss 0.3014 (0.3014) Acc@1 92.969 (92.969) Acc@5 99.219 (99.219)
2025-08-27 23:11:59,011 - INFO - Epoch 199:
2025-08-27 23:11:59,011 - INFO -   Train: acc1: 93.7560 | acc5: 99.9080 | loss: 0.1834 | sparsity: 0.9000 | reactivation_rate: 0.0000
2025-08-27 23:11:59,011 - INFO -   Val:   acc1: 89.9600 | acc5: 99.7700 | loss: 0.3033
2025-08-27 23:11:59,011 - INFO -   LR: 0.001000
2025-08-27 23:11:59,032 - INFO - training time: 00h 27m 38.13s
2025-08-27 23:11:59,032 - INFO - 
Training completed!
2025-08-27 23:11:59,032 - INFO - Best accuracy: 90.2300
2025-08-27 23:11:59,032 - INFO - Total training time: 0.46 hours
2025-08-27 23:11:59,032 - INFO - total_experiment time: 00h 27m 39.35s
2025-08-27 23:11:59,033 - INFO - Experiment completed successfully
2025-08-27 23:11:59,033 - INFO - Total time: 0.46 hours
