# Neural Network Pruning with Comprehensive MIA Vulnerability Analysis

í†µí•© í›ˆë ¨ ë° ë©¤ë²„ì‹­ ì¶”ë¡  ê³µê²©(MIA) ì·¨ì•½ì„± ë¶„ì„ì„ ìœ„í•œ ì‹ ê²½ë§ ê°€ì§€ì¹˜ê¸° í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. Dense, Static, Dynamic Pruning with Feedback(DPF) ë°©ë²•ë¡ ì„ ë¹„êµí•˜ê³ , ê° ë°©ë²•ì˜ MIA ì·¨ì•½ì„±ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” íŠ¹ì§•

### ì§€ì›í•˜ëŠ” Pruning ë°©ë²•
- **Dense**: ê¸°ë³¸ ë°€ë„ ëª¨ë¸ (baseline)
- **Static**: ì •ì  ê°€ì§€ì¹˜ê¸° (ê°€ì¤‘ì¹˜ ì œê±° í›„ ê³ ì •)
- **DPF**: Dynamic Pruning with Feedback (ë™ì  ì¬í™œì„±í™” ì§€ì›)

### ì§€ì› ìŠ¤íŒŒì‹œí‹° ë ˆë²¨
- 50%, 70%, 80%, 90%, 95% ìŠ¤íŒŒì‹œí‹°

### ì¢…í•©ì ì¸ MIA í‰ê°€
**Advanced MIA Attacks**:
- LiRA (Likelihood Ratio Attack)
- Shokri-NN Attack
- Top3-NN Attack  
- Class Label-NN Attack
- SAMIA Attack

**WeMeM MIA Attacks**:
- Confidence-based Attack
- Entropy-based Attack
- Modified Entropy Attack
- Neural Network-based Attack

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ (í›ˆë ¨ + MIA í‰ê°€)
```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ëª¨ë“  ë°©ë²• í›ˆë ¨ ë° MIA í‰ê°€
python train.py

# íŠ¹ì • ë°©ë²•ë§Œ í›ˆë ¨
python train.py --methods dense static --sparsities 0.7 0.8 0.9

# Wandb ë¡œê¹… í™œì„±í™”
python train.py --wandb --wandb-project my-project --wandb-entity my-username
```

### ê°œë³„ ëª¨ë¸ í›ˆë ¨
```bash
# Dense ëª¨ë¸
python run_experiment.py --name dense_cifar10 --dataset cifar10 --epochs 200

# Static ê°€ì§€ì¹˜ê¸° (80% ìŠ¤íŒŒì‹œí‹°)
python run_experiment.py --name static_80 --prune --prune-method static --sparsity 0.8

# DPF ê°€ì§€ì¹˜ê¸° (90% ìŠ¤íŒŒì‹œí‹°)
python run_experiment.py --name dpf_90 --prune --prune-method dpf --sparsity 0.9
```

### MIA í‰ê°€ë§Œ ì‹¤í–‰
```bash
# ê¸°ì¡´ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì— ëŒ€í•´ ì¢…í•© MIA í‰ê°€
python mia/unified_mia_evaluation.py --runs-dir ./runs

# Advanced MIAë§Œ ì‹¤í–‰
python mia/mia_advanced.py --runs-dir ./runs

# WeMeM MIAë§Œ ì‹¤í–‰  
python mia/mia_wemem.py --runs-dir ./runs
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# MIA í‰ê°€ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
python test_mia.py --runs-dir ./runs
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
â”œâ”€â”€ train.py                       # í†µí•© í›ˆë ¨ ë° MIA í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ run_experiment.py              # ê°œë³„ ì‹¤í—˜ ì‹¤í–‰ê¸°
â”œâ”€â”€ test_mia.py                    # MIA í‰ê°€ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ configs/                       # ì„¤ì • ê´€ë¦¬
â”‚   â”œâ”€â”€ config.py                 # ì‹¤í—˜ ì„¤ì • í´ë˜ìŠ¤
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ models/                        # ëª¨ë¸ ì •ì˜
â”‚   â”œâ”€â”€ resnet.py                 # ResNet êµ¬í˜„
â”‚   â”œâ”€â”€ wideresnet.py             # Wide ResNet êµ¬í˜„
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ mia/                          # MIA í‰ê°€ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ mia_advanced.py           # Advanced MIA ê³µê²©ë“¤
â”‚   â”œâ”€â”€ mia_classic.py              # WeMeM MIA ê³µê²©ë“¤
â”‚   â”œâ”€â”€ unified_mia_evaluation.py # í†µí•© MIA í‰ê°€
â”‚   â””â”€â”€ run_mia_evaluation.py     # ê°œë³„ ëª¨ë¸ MIA í‰ê°€
â”‚
â”œâ”€â”€ runs/                         # í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ dense/cifar10/           # Dense ëª¨ë¸ ê²°ê³¼
â”‚   â”œâ”€â”€ static/sparsity_X/cifar10/ # Static ê°€ì§€ì¹˜ê¸° ê²°ê³¼
â”‚   â””â”€â”€ dpf/sparsity_X/cifar10/  # DPF ê°€ì§€ì¹˜ê¸° ê²°ê³¼
â”‚
â”œâ”€â”€ results/                      # MIA í‰ê°€ ê²°ê³¼
â”‚   â”œâ”€â”€ mia/                     # í†µí•© MIA ê²°ê³¼
â”‚   â”œâ”€â”€ advanced/                # Advanced MIA ê²°ê³¼
â”‚   â””â”€â”€ wemem/                   # WeMeM MIA ê²°ê³¼
â”‚
â”œâ”€â”€ training_results.csv          # í›ˆë ¨ ì„±ëŠ¥ ìš”ì•½
â””â”€â”€ comprehensive_mia_results.csv # ì¢…í•© MIA ì·¨ì•½ì„± ê²°ê³¼
```

## ğŸ”¬ ë°©ë²•ë¡  ë¹„êµ

### Dense Model
- ê¸°ë³¸ ë°€ë„ ì‹ ê²½ë§
- ëª¨ë“  ê°€ì¤‘ì¹˜ í™œì„±í™” ìƒíƒœ
- ë†’ì€ ì •í™•ë„, ë†’ì€ MIA ì·¨ì•½ì„±

### Static Pruning
```python
# Forward pass
output = input * mask

# Backward pass  
gradient = gradient * mask  # ì œê±°ëœ ê°€ì¤‘ì¹˜ëŠ” ì˜ì›íˆ 0
```
- ê°€ì§€ì¹˜ê¸° í›„ ë§ˆìŠ¤í¬ ê³ ì •
- í¬ì†Œí•œ ê·¸ë˜ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì , ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì •í™•ë„

### DPF (Dynamic Pruning with Feedback)
```python
# Forward pass
output = input * mask

# Backward pass
gradient = gradient  # ì „ì²´ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° (ì¬í™œì„±í™” ê°€ëŠ¥)
```
- ë™ì  ê°€ì¤‘ì¹˜ ì¬í™œì„±í™”
- ë°€ë„ ê·¸ë˜ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸
- Staticë³´ë‹¤ ë†’ì€ ì •í™•ë„, ë³µì¡í•œ í›ˆë ¨ ê³¼ì •

## ğŸ“Š ê²°ê³¼ ë¶„ì„

### í›ˆë ¨ ì„±ëŠ¥ ê²°ê³¼
- `training_results.csv`: ê° ë°©ë²•ë³„ ì •í™•ë„, ì†ì‹¤, í›ˆë ¨ ì‹œê°„
- `runs/*/experiment_summary.json`: ìƒì„¸ í›ˆë ¨ ë©”íŠ¸ë¦­

### MIA ì·¨ì•½ì„± ê²°ê³¼
- `comprehensive_mia_results.csv`: ëª¨ë“  MIA ê³µê²© ê²°ê³¼ í†µí•©
- `results/mia/advanced/`: LiRA, Shokri-NN ë“± ê³ ê¸‰ ê³µê²© ê²°ê³¼
- `results/mia/wemem/`: Confidence, Entropy ê¸°ë°˜ ê³µê²© ê²°ê³¼

### ì£¼ìš” ë©”íŠ¸ë¦­
```csv
experiment,method,sparsity,lira_auc,confidence_accuracy,neural_network_auc,samia_accuracy,...
dense_cifar10,dense,0.0,0.85,0.78,0.82,0.76,...
static_sparsity_0.8_cifar10,static,0.8,0.72,0.65,0.68,0.63,...
dpf_sparsity_0.8_cifar10,dpf,0.8,0.74,0.67,0.71,0.65,...
```

## âš™ï¸ ì„¤ì • ì˜µì…˜

### í›ˆë ¨ ì„¤ì •
```bash
python train.py \
    --methods dense static dpf \
    --sparsities 0.5 0.7 0.8 0.9 0.95 \
    --dataset cifar10 \
    --arch resnet \
    --epochs 200 \
    --skip-existing
```

### Wandb ë¡œê¹…
```bash
python train.py \
    --wandb \
    --wandb-project dcil-pytorch \
    --wandb-entity your-username \
    --wandb-tags pruning mia-analysis cifar10
```

### MIA í‰ê°€ ì„¤ì •
```bash
python mia/unified_mia_evaluation.py \
    --runs-dir ./runs \
    --results-dir ./results/unified_mia
```

## ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

### ëª¨ë¸ ì„±ëŠ¥ (ì •í™•ë„)
```
Dense > DPF > Static (ë™ì¼ ìŠ¤íŒŒì‹œí‹°ì—ì„œ)
ë‚®ì€ ìŠ¤íŒŒì‹œí‹° > ë†’ì€ ìŠ¤íŒŒì‹œí‹°
```

### MIA ì·¨ì•½ì„± (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
```
Dense (ê°€ì¥ ì·¨ì•½) > DPF â‰ˆ Static (ê³µê²© ìœ í˜•ì— ë”°ë¼ ì°¨ì´)
ë†’ì€ ìŠ¤íŒŒì‹œí‹°ì—ì„œ ì·¨ì•½ì„± ê°ì†Œ ê²½í–¥
```

### Privacy-Utility Trade-off
- Dense: ë†’ì€ ì„±ëŠ¥, ë†’ì€ ì·¨ì•½ì„±
- Static: ì¤‘ê°„ ì„±ëŠ¥, ì¤‘ê°„ ì·¨ì•½ì„±  
- DPF: ë†’ì€ ì„±ëŠ¥, Staticê³¼ ìœ ì‚¬í•œ ì·¨ì•½ì„±

## ğŸ› ï¸ ì˜ì¡´ì„±

### í•„ìˆ˜ íŒ¨í‚¤ì§€
```bash
torch>=1.9.0
torchvision
numpy
pandas  
scikit-learn
matplotlib
seaborn
wandb  # ì„ íƒì‚¬í•­
```

### ì„¤ì¹˜
```bash
pip install torch torchvision numpy pandas scikit-learn matplotlib seaborn wandb
```

## ğŸ“‹ ì‚¬ìš© ì˜ˆì‹œ

### 1. ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
```bash
# Denseì™€ Static 80%ë§Œ ë¹„êµ
python train.py --methods dense static --sparsities 0.8 --epochs 50
```

### 2. ì „ì²´ ë²¤ì¹˜ë§ˆí¬
```bash
# ëª¨ë“  ë°©ë²•ê³¼ ìŠ¤íŒŒì‹œí‹° ë ˆë²¨ë¡œ ì™„ì „í•œ ì‹¤í—˜
python train.py --epochs 200 --wandb
```

### 3. íŠ¹ì • MIA ê³µê²©ë§Œ í‰ê°€
```bash
# LiRA ê³µê²©ë§Œ ì‹¤í–‰
python mia/mia_advanced.py --attacks lira --runs-dir ./runs
```

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°: `--batch-size 64`
   - ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©: `--arch resnet --layers 20`

2. **Wandb ì—°ê²° ë¬¸ì œ**
   - ì—”í‹°í‹° í™•ì¸: `--wandb-entity your-correct-username`
   - í”„ë¡œì íŠ¸ ê¶Œí•œ í™•ì¸

3. **MIA í‰ê°€ ì‹¤íŒ¨**
   - ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸: `ls runs/*/best_model.pth`
   - ì„¤ì • íŒŒì¼ í™•ì¸: `ls runs/*/config.json`

### ë¡œê·¸ ë° ë””ë²„ê¹…
```bash
# ìƒì„¸ ë¡œê·¸ë¡œ ì‹¤í–‰
python train.py --verbose

# íŠ¹ì • ì‹¤í—˜ë§Œ ì¬ì‹¤í–‰
python train.py --methods static --sparsities 0.8 --skip-existing
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [LiRA Paper](https://arxiv.org/abs/2112.03570)
- [WeMeM Framework](https://github.com/example/wemem)
- [Neural Network Pruning Survey](https://arxiv.org/abs/2103.00249)
