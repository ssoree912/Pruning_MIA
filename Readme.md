# Dense vs Static vs DPF Pruning: MIA Vulnerability Analysis

A comprehensive comparison of Dense, Static, and Dynamic Pruning with Feedback (DPF) methods and their vulnerability to Membership Inference Attacks (MIA).

## ğŸ¯ Experiment Overview

This experiment evaluates **11 target models**:
- **1 Dense model** (baseline)
- **5 Static pruned models** (50%, 70%, 80%, 90%, 95% sparsity)
- **5 DPF pruned models** (50%, 70%, 80%, 90%, 95% sparsity)

**MIA Evaluation** using WeMeM methodology:
- Confidence-based attacks
- Entropy-based attacks  
- Modified entropy attacks
- Neural network-based attacks

## ğŸš€ Quick Start

### Run MIA Evaluation on Existing Models
```bash
./run_mia_evaluation.sh
```

### Run Complete Experiment (Training + MIA)
```bash
./full_experiment_with_mia.sh
```

### Single Model Training
```bash
# Dense model
python run_experiment.py --name dense_baseline --dataset cifar10 --epochs 200

# Static pruning (80% sparsity)
python run_experiment.py --name static_80 --prune --prune-method static --sparsity 0.8 --epochs 200

# DPF pruning (80% sparsity)  
python run_experiment.py --name dpf_80 --prune --prune-method dpf --sparsity 0.8 --epochs 200
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ run_experiment.py              # Main experiment runner
â”œâ”€â”€ mia_wemem.py                   # WeMeM MIA evaluation
â”œâ”€â”€ full_experiment_with_mia.sh    # Complete experiment script
â”œâ”€â”€ run_mia_evaluation.sh          # MIA evaluation only
â”‚
â”œâ”€â”€ pruning/                       # Pruning implementations
â”‚   â”œâ”€â”€ dcil/mnn.py               # MaskerStatic & MaskerDynamic
â”‚   â””â”€â”€ models/resnet_mask.py     # Prunable ResNet
â”‚
â”œâ”€â”€ models/                        # Dense model definitions
â”œâ”€â”€ mia/lira.py                    # LiRA implementation
â”œâ”€â”€ experiments/                   # Training scripts
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚
â”œâ”€â”€ runs/                          # Trained models & results
â”œâ”€â”€ results/                       # MIA evaluation results
â””â”€â”€ final_results/                 # Comprehensive reports
```

## ğŸ”¬ Methods Comparison

### Static Pruning
- **Forward**: `output = x * mask` 
- **Backward**: `grad = grad * mask` (dead weights stay dead)
- **Characteristic**: Sparse gradient updates

### DPF (Dynamic Pruning with Feedback)
- **Forward**: `output = x * mask`
- **Backward**: `grad = grad` (full gradient, weights can reactivate)
- **Characteristic**: Dense gradient updates with selective reactivation

## ğŸ“Š Results

### Model Performance
Results saved in `runs/final_report/`:
- `experiments_comparison.csv`: Accuracy vs Sparsity comparison
- `comprehensive_report.json`: Detailed training metrics

### MIA Vulnerability  
Results saved in `results/wemem_mia/`:
- `wemem_mia_summary.csv`: Attack success rates comparison
- `wemem_mia_results.json`: Detailed attack results

## ğŸ› ï¸ Dependencies

```bash
# Setup environment
conda env create -f environment.yml
conda activate dcil-mia
```

Required packages:
- PyTorch >= 1.9.0
- torchvision
- numpy, pandas
- scikit-learn
- matplotlib, seaborn

## ğŸ“ˆ Expected Results

**Utility (Accuracy)**:
- Dense > DPF > Static (at same sparsity)
- Higher sparsity â†’ Lower accuracy

**Privacy (MIA Resistance)**:  
- Dense models most vulnerable
- Static vs DPF comparison varies by attack type
- Higher sparsity may reduce MIA vulnerability

## ğŸ” Citation

```bibtex
@article{dcil_mia_2024,
  title={Membership Inference Vulnerability in Pruned Neural Networks: Dense vs Static vs Dynamic Comparison},
  author={Your Name},
  journal={Experiment Report},
  year={2024}
}
```

## ğŸ“ Usage

For detailed usage and configuration options:
```bash
python run_experiment.py --help
python mia_wemem.py --help
```